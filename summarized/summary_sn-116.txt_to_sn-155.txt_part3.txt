GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#116

DATE:		November 1, 2007

TITLE:		Listener Feedback Q&A #27

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-116.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 116 for November 1, 2007:  Your questions, Steve's answers.



It's time for Security Now! Episode 116, a brand new month.  And Steve Gibson, our security guru, is here.



STEVE GIBSON:  Hey, Leo.



LEO:  Hello, Steve.  Good to talk to you.



STEVE:  Great to be with you.



LEO:  So we are going to do a little Q&A thing in just a little bit.  Number 27.  We've been doing quite a few of these.  I didn't realize we'd gotten so many in.  That's exciting.



STEVE:  And I'll tell you, as I read through the email, I just - we're getting such great feedback from our listeners.  I just - it's just delightful to read...



LEO:  Well, we have smart listeners, which is kind of neat.



STEVE:  Yeah, with definitely involved listeners, for sure.



LEO:  Yeah, yeah.  So we'll get to that in just a second.  Do you have any errata or things you want to talk about?



STEVE:  Yes.  I've got two things.  There was a lot of commentary that I received about our talking about the Firefox Master Password.  And our listeners brought two things to my attention.  One is that there is a very frightening piece of freeware called IE PassView.  You and I did a spot on your radio show last weekend, Leo.  And you'll remember that we were talking about the importance of setting the master password in Firefox, as we also discussed on the podcast, because without that anyone could come along and look at all of the sites, usernames, and passwords that Firefox had stored.  Setting a master password protects it and encrypts it.  But on Firefox it turns out that there is a brute force attack, and several open source pieces of software that will successfully brute-force reverse-engineer your master password.  So I wanted for our listeners to know that all the rules about a really hard-to-guess password must be applied to Firefox.



LEO:  Now, people would have to get access to your physical system to use these attacks.



STEVE:  Correct, correct.  Although it's an offline attack, so you could grab the files and then attack them separately.  On IE, things are a little bit worse because most users are not familiar with this notion.  You asked me on your radio show whether IE had the same sort of facility that Firefox does.  And when I said no, what I meant was there was no way to display them, although IE certainly does offer to remember them.  When you're typing in a username and password it'll say IE can remember this for you, would you like IE to do so.  Many people say yes.  Well, this freeware that I mentioned called IE PassView, you put it into Google, IE space PassView, it's the first bunch of links that come up from a company called NirSoft, NirSoft.net, that's a company I know, and they're good guys.  They've got a piece of freeware that shows the same thing as Firefox.



LEO:  Great.



STEVE:  But because IE has no protection at all, it's wide open.  And so I, when I learned about this, I ran it.  And it's like, oh, look at that.  I mean, it was like a little bit of a blast from the past.  I've been looking at websites...



LEO:  Every site you ever logged into, yeah.



STEVE:  Yes, no, I'm not kidding.  It's all there.  And it's like, oh my god.  I mean, so...



LEO:  As I remember, these were stored in the registry.  That's - so you could even go into the registry and look at them.  It's not like they're encrypted.



STEVE:  They're wide open in the registry?



LEO:  Yeah, I think so, yeah.



STEVE:  Well, there's something called password-protected web space or something.  I think Microsoft has been attempting to do a better job.  One thing this utility does allow you to do is delete them.  So that's nice.



LEO:  That's good, yeah.



STEVE:  So anyway, I just wanted to tell our users, make them aware that there is this tool for IE.  So they need to know that their username and passwords - oh, and this thing will even dump it out into HTML or into a file.  So...



LEO:  Oh, great.



STEVE:  So, I mean, it's dangerous.



LEO:  Yeah.  All right, well, that's good to know.  And once again, I think you probably should not be using IE to remember your passwords, since you can't protect it, and use something like AI RoboForm, which is encrypted and will remember the passwords and, I think, replace the IE password mechanism so you don't have to worry about IE...



[Talking simultaneously]



LEO:  ...as well, yeah.



STEVE:  That's great.



LEO:  Good.



STEVE:  And then my other last little blurb here is I had another fun, and always different, SpinRite story.  This is from Robert in Aberdeen, Scotland, who says, "I've been using SpinRite for a while now, ever since it saved my data."  And he says fortnightly backups, 13 busy days, then his hard drive fails half an hour into a more recent backup.  So he was in trouble.  Anyway, he says, "So one day my dad's laptop refuses to boot.  The problem is, he's about 400 miles away from me, and neither of us had the time to go to see the other for a few days.  And I couldn't mail the trusty SpinRite boot CD to him because there was a postal strike.  So email and SpinRite's small ISO file came to the rescue.  I talked him through getting his machine to boot from a SpinRite CD, which he burned from the SpinRite ISO, and getting SpinRite going.  I heard nothing for about an hour.  Then I got the 'thanks' phone call.  Needless to say, that's another sale you're getting from the, 'Here, try this,' method of advertising.  Thanks for such a great product and a great podcast.  I really feel from the podcast that I know you, and as a fellow geek, enough to know that all of the above would be fine with you."



LEO:  Oh, that's neat.



STEVE:  Meaning, you know, did I mind him sending his dad a copy of the ISO?  Of course not.  And I appreciate that his dad bought a copy as a consequence.



LEO:  See, that's the way to do it.  I mean, you know, people will pay for stuff if it benefits them, if they use it and they love it.  And you only get the negative by locking it down so tight.  Then people don't - they go, ah, screw 'em.  So I'm proud of you, Steve.  And I think that's a great story.  That's really a nice story.  Are you ready, Steve, for 12 questions?



STEVE:  Let's go.



LEO:  And 12 answers from Mr. Steve Gibson, starting with number one, Dave F. in San Francisco.  He's asking about what we talked about last week, the Perfect Paper Passwords:  Steve, it seems to me as though your policy of no passcode reuse for any given four-character key in the PPP system weakens the system.  An attacker knowing this can watch the keyspace for a long time and gradually weaken the system by crossing off potential keys.  Well, now, we talked last week about how many keys there are.  Sure, it would take a long time to use the system enough, but every login would reduce the future choice space.  If instead you have a practical constraint on duplication, say no duplication in the span of 12 cards, and your PRNG, or Pseudorandom Number Generator, is good, then you get the benefits of no local replays being viable, but the keyspace not being reduced.  That's not a bad point.  What's the flaw, he says.



STEVE:  Well, okay.  I think it was a bit of a terminology problem.  When I talked about never reusing a passcode, I meant never reusing it by its position in the passcode sequence.  Essentially what...



LEO:  So reused by - purely randomly.



STEVE:  That's exactly right.  Every single time there is a one in 16.77 blah blah blah million chance of any one of those passcodes appearing.



LEO:  So you do reuse them.



STEVE:  Well, yes.  What I'm not reusing is I'm not reusing the sequence.  I'm never going back and saying, oh, well, let's start...



LEO:  Let's use it again.



STEVE:  Let's start at number one and go forward again.  It's like, no, we've got so many of them, I mean, a gazillion gazillion of them, there's no reason not to just keep going forward, or choose a new sequence key that will generate a new sequence of them.  So it's not that I'm not reusing individual codes; it's very possible that, well, not very, somewhat possible, okay, it's very possible but very unlikely that two codes will occur very close to each other that are the same.  And certainly there's no benefit in guessing because any one of them could be any of those 16 million, 770-some thousand possible passcodes.



LEO:  Okay.  And by the way, because it's 16.7 million, it's not like crossing them off is going to be much use to a hacker.  I mean, it's only a theoretical reduction in security.



Ron Goodbin of Clifton, New Jersey needs some IP spoofing clarification.  Steve, you've talked about how when a client establishes a TCI/IP connection to a server, there's no way the client can spoof their IP.  When a client establishes a connection to a server, there's no way the client can spoof their IP.  If so, what is an IP spoofing attack?  Is there absolutely no way someone can fake their IP when you've established a TCP/IP connection?  Some clarity on this would be much appreciated.  Well, he raises a good issue.  I thought you could spoof an IP.



STEVE:  Nope, not with a TCP connection.  The reason is, the way a connection is made is...



LEO:  Oh, it has to get back to you.



STEVE:  Exactly.  It's that three-way handshake.  It requires two roundtrips, that is, the so-called SYN packet, short for "synchronized," that goes from the client that's initiating the connection to the server that has the open port which is waiting for the connection.  The server receives that, and it sends back its SYN/ACK, which is to say its own SYN packet combined with an ACK, an acknowledgement of the receipt of the client SYN.  Well, it sends it back to the IP that was the source IP on the packet coming in is now the destination IP on that SYN/ACK going back out.  If that were a spoofed IP from the original sender, then the SYN/ACK would be sent to that spoofed IP, not back to the sender.  So, while, sure, you're able to spoof incoming SYN packets, and that is in fact what a spoofed IP attack is, is just flooding a server with random, made-up...



LEO:  Because you don't care about the return.



STEVE:  Exactly.  You're not trying - there you're trying to do an attack, a bandwidth attack on the server.  You're not trying to actually establish connections.  So in order to establish a connection you have to be sending the packet from a valid IP.  And then the SYN/ACK comes back to that IP, and that's the second leg of the three-way handshake.  And finally, the client sends its acknowledgement packet back to the server.  And the beautiful thing about that is that, from the original designers of the Internet, that requires two roundtrips, one from the client to the server and back, one from the server to the client and back.  And that verifies that the routing between those two endpoints is in place for packets traveling in both directions.  So it makes sure that everything is intact, and it does validate and verify the IP addresses of each endpoint.



LEO:  That's, you know, we didn't talk about this last week.  But when the Rockies put their World Series tickets on sale for the first time last week, they decided not to send - you remember this story.  They decided not to sell them at the ticket booths.  They sold it all online.  They got 8.5 million requests in the first hour and a half, so many that they were only able to sell 500 tickets.  That was probably a SYN flood; right?



STEVE:  That's also question number five.



LEO:  Oh, well, we'll get to it in a second.  Sorry, I didn't read ahead.  Let's move on.  Ferruccio, writing from Sharon, Mass., raises a good point:  Steve, after the discussion of why no one would write or should write their own encryption routines for production use, which I wholeheartedly agree with, I was surprised to hear you say you wrote your own random number generator.  Well, no one should be writing custom random number generators for exactly the same reason they shouldn't be writing their own encryption code.  It's a solved problem.  There are many excellent algorithms for generating pseudorandom numbers.  It may well be that your algorithm works perfectly, but I'd never use a custom random number generator without having a really good reason to do so.  And I would at least run it by someone who has a lot more math/crypto experience than me.  So what's the deal, Steve?



STEVE:  Well, I got a kick out of his point because he was essentially turning the point I was making back around on me.



LEO:  Yeah.



STEVE:  He's completely correct, although remember that last week I did mention that the Perfect Passwords page on GRC was using a pseudorandom number generator that I assumed would be super high quality because I got it from...



LEO:  It came from VeriSign.



STEVE:  Yeah, actually, Leo, it was from RSA Labs.



LEO:  RSA, that's right, yeah.



STEVE:  The major crypto people.  And it turned out it was a pretty crappy random number generator.  We had some guys that did an analysis by sucking down a gazillion of those Perfect Password pages and then analyzing it and determining that its entropy was not as high as it could be.  I mean, it was good, but it wasn't fantastic.  So I wrote my own, and now it's fantastic.  



LEO:  So it was validated by the entropy test?



STEVE:  Oh, yes.  It's got, like, 7.99997 or something bits of entropy out of a possible eight.  Because it's, you know, it's doing bytes.  And so the maximum possible entropy would be 8.0.  None of them do 8.0.  Mine's as good as anyone.  And it's the fastest one that has been tested among any random number generators because I based it on the Rijndael crypto, which is an implementation I wrote myself in Assembly language.



LEO:  So you didn't invent the algorithm.  You just wrote your own implementation of an existing algorithm.



STEVE:  Well, I wrote my own implementation of Rijndael.  And remember that, if you put anything into a really good, state-of-the-art cipher, what comes out is pseudorandom.  And so I just run a counter on the input.  And what comes out is really good pseudorandom.



LEO:  Okay.  So you really didn't create a whole new algorithm for pseudo number generation, random number generation.  You used Rijndael.



STEVE:  No.  I didn't do something like that wacko with the virtual matrix encryption last time.



LEO:  Right, right, right, that makes sense.  Mike Gray, who listens in Tacoma, which bills itself as the world's most wired city, is plugged directly into the Internet.  Good for you, Mike.  I only have one computer.  Do I still need a router, or is my firewall enough?  Isn't a router just a hardware firewall?



STEVE:  Well, that's a good question.  I mean, I would feel relatively naked if I had a publicly routable IP, and a Windows machine was just sitting right on it.  On the other hand, servers are publicly routable IPs, and they're sitting right on the Internet.  So...



LEO:  But they're hardened by professionals, too.



STEVE:  That's generally the case.  You absolutely want to make sure, I mean you want to make sure, that your software firewall is running.  And that's...



LEO:  I'd still use a router.



STEVE:  I would, too, Leo.  I mean, the Achilles heel with Windows is - and you and Paul were talking about it on Windows Weekly in the last couple weeks, is the idea of putting Windows on the Internet with no protection, I mean, it's just like game over.  You're just taking - your Windows machine is just taken over almost immediately.  Certainly, if you were also in the process of, like, trying to download updates to the original XP build, that has years of exploits wandering around the Internet right now, you would never get a chance to get Windows Update updated and up to speed.



LEO:  Well, you've also pointed out that, because software is running on the computer, the same computer that is running other applications, those other - if you get malware on that computer, it can see this firewall and disable it.



STEVE:  That's exactly the case, yes.



LEO:  A hardware router is just a dumb box.  And it's a lot harder to hack a dumb box because you can't get software onto it.



STEVE:  Well, yes.  As long as you make sure you change the default administration username and password.  One of the things that Mark Roberts did when he was testing all those 66 routers that he has was...



LEO:  Mark Thompson.



STEVE:  Mark Thompson, sorry, Mark Thompson of AnalogX, is that he developed some code that attempted to log into routers just using a bunch of sort of standard logins.  And more often than not he was able to.  And we know that there is malware now which is attempting to log into your local router in order to change settings.  Which means there's malware we know that is trying to shut down your Windows firewall.  I just - a firewall is so important that I would no longer trust any software firewall to be up and running all the time.  And it has to be up and running all the time.  So routers are so inexpensive at $49 that it just - it's really good security to have a second line of defense.



LEO:  There's also another advantage to a router if you're a DSL subscriber, and that is the router will do the PPPoE negotiation, so you don't have to have any special software on your computer.  Often that software is just junk.



STEVE:  Right.  And remember that we've also talked about that most software can't detect what your public IP address is.  So software running behind a router gets a 192.168.*.* address, some nonroutable IP.  Software can't give away information it doesn't have.  So not letting software know where you're located, even your own software, is a little bit more secure also.  It's just a good thing to have a little bit of hardware there.



LEO:  It's cheaper than buying a software firewall, frankly.



STEVE:  Yeah.



LEO:  Brian F. in Denver, Colorado - here's a question - wonders, crash or no crash?  He says:  I'm a long-time listener to Security Now!, a SpinRite user, and my local GRC enthusiast.  The other day I saw on the news a story about server problems with the Colorado Rockies website - I have an affiliate in Colorado, KCOL, and did a couple of interviews over there about this.



STEVE:  Wow.



LEO:  Yeah.  I thought you might be interested in hearing it.  Apparently the Rockies decided to sell all their World Series tickets online only, and had set a time to put them on sale.  After only 500 tickets were sold, the servers went down.  They claim malicious attackers took the site down.  And seeing that there were over 8.5 million connection attempts in 90 minutes, sounds possible.  But I wonder if it was just that they were unprepared for the flood of traffic they received.  8.5 million hits in 90 minutes is a whole lot, but could this really have been just an angry sports geek with a bot network and a friendly DDoS button, or could that be a lot of fans hitting reload and trying to get their tickets?  I'm not a big sports fan, but I found the story interesting.  Thought of you guys, and I'd like to hear your take on it.  I'd like to hear your take, too, because that was the question, of course, that these radio stations wanted to know, is the Rockies claim it was a DDoS attack.  Was it a DDoS attack?



STEVE:  No.



LEO:  8.5 million in 90 minutes?  Is that too many for it to just be fans?



STEVE:  No, I don't really think it is too many, given what it is that they were selling and the popularity of it.  Also I don't know what 8.5 million hits means.  How were they counting hits?  In a DDoS attack these days you get 8.5 million packets in a minute.



LEO:  So 90 minutes is not a big deal.



STEVE:  Exactly.  What I think is probably happening, and I don't know if you've noticed this, Leo, is that web pages have so much technology behind them now, and that technology is anything but optimized, says Mr. Assembly Language here, that these things are taking a long time to go.  It might very well be that they had some sort of a - certainly they're going to have some sort of an active site that's doing things with cookies, and it's got code running behind the ticket site.  Maybe they've got a system where fans are able to choose which seating they want.  They're able to, you know, who knows how much processor time behind the scenes was going into servicing an individual ticket purchase.



LEO:  We know a little bit more now, by the way.  They had a CAPTCHA on the site.  And the reason they think it was malicious is because they were getting all these bogus CAPTCHA entries.  But that doesn't mean it's a DDoS attack.  In fact, what it probably is is scalpers using bots to try to buy tickets.



STEVE:  Wow, interesting.



LEO:  So, and by the way, the next day they revamped their system in ways that they didn't specify, and they were able to sell all 50,000 tickets in about two and a half hours.



STEVE:  Yeah, I think that demonstrates that something was wrong with their system that was causing them some sort of a serious slowdown, and it wasn't an attack.



LEO:  Yeah.  In fact, McAfee Avert Labs, Dave Marcus there said, you know, it sounds like they didn't configure their software right.  They should have kicked off users that tried to trick the system.  He said, quote, "I wouldn't call it malicious, it's just somebody trying to buy more tickets than they're allowed to in an automated way."



STEVE:  Right.



LEO:  Alves said it was malicious because it was an attempt to disrupt the ticket distribution method, but that's not a DDoS attack.



STEVE:  Right.



LEO:  Yeah.  Really interesting story, an example of, frankly, not being prepared.



STEVE:  Exactly.  I think they'll know better next time.



LEO:  Everyone will.  Don Ramm in Chula Vista isn't convinced:  Steve liked the idea of not entering the digits from the PayPal token when entering the password, to cause PayPal to come back and ask for it.  In fact, I've been doing that ever since you said that, Steve.



STEVE:  Me, too, Leo.



LEO:  Since only PayPal knows you have a PayPal token, this would foil a phishing site.  However, if one did end up at a phishing site, when you enter your PayPal credentials, couldn't that site immediately send that info to PayPal and react accordingly?  That is, you know, because PayPal would say, okay, now give me the second part.  And when the phishing site sees that, it could then ask you for the token.



STEVE:  Yup, he's absolutely right.  I didn't intend to indicate that this was foolproof anti-phishing detection.  But it's just one additional thing.  I mean, we know that security is as good as it can be, but often far from perfect.  So we do things which are trying to raise the bar, just because raising the bar is a good thing.  I've had occasion several times to purchase things ever since that great idea we got two weeks ago.  And I now enter my password separately.  I mean, I'm still making sure that I'm really on PayPal, doing my standard anti-phishing tests.  But I really thought that that was a good point is that right now phishing sites are probably not turning around and checking PayPal.



LEO:  Not enough people use keys, I think, so that it's not worth it for their...



STEVE:  Exactly.



LEO:  Yeah.  So it's just, you know, it's a little more security.  It's not perfect.



STEVE:  But Don is clever, and he's absolutely right.  You could certainly do more of a proxy attack like he's talking about, in which case it is possible for one site to emulate another, even if it's got that kind of active behavior.



LEO:  James Lewis of Colorado Springs has some good news.  The PayPal hardware token is washing machine safe.  He says:  I was very glad to learn of the token security key from PayPal.  I ordered mine as soon as I got to a PC.  The other day I searched and searched my house for it because I needed access to my PayPal account.  When I finally found my key, it was in the washing machine.  Oops.  After letting it dry out overnight - good thinking.



STEVE:  I love this.  It started generating codes again.



LEO:  It just did.  However, the codes were no longer valid on PayPal or eBay.  My guess is the wash probably caused the internal timer to reset, which put me out of sync.  But all I had to do was reactivate the key, and it was good again.  Oh, how interesting.  I just thought you and your listeners would like to know.  That's funny.



STEVE:  Isn't that great?  I love that, you know.  So clearly he got it out, you know, he fished around and rolled up his sleeves and pulled it out of the water, but it was still dead.  So he shook it out and then waited for it to dry.  And then it came back to life, but it was no longer in the proper location in terms of its sequence of time-based keys.  So then he resynced it, and he was good to go again.



LEO:  So what happened is it probably stopped working for a period of time, and that's how it got out of sequence?



STEVE:  I would think, yeah.



LEO:  Jeffrey Wurzbach in San Diego wants to know more about the games Comcast has been playing lately.  We talked about this on TWiT.  An Associated Press reporter says that Comcast has a new method for shaping traffic.  From what the story suggests, it looks like a man-in-the-middle attack on the subscriber's computer.  Is this really a man-in-the-middle attack?  Is Comcast's system application specific?  In other words, would it block only Torrent/P2P networks?  Or does it say, look, there's a lot of upstream traffic, kill it?  The MSNBC story says it's not app specific, but I question the accuracy.



It's always hard when you read mainstream media reports of this stuff to know what happened.  Just to recap what the AP reporter said, is it looked like Comcast was interrupting the P2P connection and spoofing your software to say, disconnect please, I don't want any more.  So it was disconnecting your peer-to-peer connection without your permission, which is kind of an interesting thing to do.



He says:  Is it ethical for Comcast to do this?  Is it even legal?  From my understanding, this kind of denial of a service on somebody else's system is illegal.  And certainly there are people who are saying that now, the Electronic Frontier Foundation and others.



STEVE:  Well, it's interesting.  I asked Mark Thompson about this.  Mark has written a very popular and successful BitTorrent client.



LEO:  Oh, so he would know a lot about this.



STEVE:  Well, actually he knows everything about it.  It turns out, well, actually between the two of us, because he was - apparently some ISPs have been doing something like this for several years.  So aspects of this is not new.  And there have been some BitTorrent client pushback against this.  If you are BitTorrent aware, you are able to look at the protocol.  And there's a bitmap showing the segments of the torrent which are available and which are still necessary.  And so that's how the torrents are able to assemble themselves in individual chunks.  What some ISPs were doing, and I don't know that this is exactly what Comcast is doing, but what they were doing is their intention was to allow someone to download something, but not allow them to upload it.  And so what they would do is they would come in at the last moment, when this bitmap was almost complete, and interrupt the connection.  Well, now I know what's going on because all that you would need to do, somebody doesn't really have to be a man in the middle.  They can just be a passive observer.  And if you see the traffic going back and forth over a TCP connection, you simply send that a TCP reset packet.  And it will...



LEO:  That's what happened, yeah.



STEVE:  It will drop the connection.  And so essentially it is absolutely possible for an ISP that wants to be belligerent against its users to essentially drop connections by sending them end-of-connection packets spoofing the source IP.  You also have to have the synchronization number in the packet within a valid range, which is easily done when you're monitoring their traffic.



LEO:  But they do have to have your IP address in that reset packet, as well as that synchronization key.



STEVE:  It's got to be both.  It's got to be the source and destination IP.  Otherwise the receiving stack will reject it.



LEO:  Oh, I see.  This apparently is a technology that is used by a Canadian company called Sandvine.  Some Internet service providers use Sandvine.  Apparently Sandvine is not saying whether they're being used.  Comcast won't say what they use.  But that's what BitTorrent, Inc., President Ashwin Navin said.  He said this is consistent with how Sandvine works.  And that would make sense.  I don't think Comcast is writing code to do this.  As to the legality of it, we'll just have to leave that for somebody else.



STEVE:  Yeah, I would agree that it's a relatively high-tech attack for your typical ISP to go through.  It's entirely believable that some third party would come up with something that any ISP could tack onto their network in order to do this.  And I'm glad it's getting some attention.  I mean, there's this whole issue of Net Neutrality that we haven't ever really discussed on this podcast, but this notion that ISPs are wanting to treat different classes of traffic in different ways.  For example, an ISP that's offering telephone service might be giving its Skype users a lower quality of service for Skype traffic than their own users receive.



LEO:  Right, right.  Yeah, Skype's, I mean, Sandvine's Intelligent Traffic Management does exactly, exactly what we're talking about.  They even bill it that way.  So it is a - promises to save bandwidth for Internet service providers by managing and redirecting filesharing traffic.  Yeah.  Redirecting like, go away.



STEVE:  Then, yeah, snipping the string that connects the two computers.



LEO:  Go away.  Bye bye.  Matthew Paulson in Madison, San Diego - I'm sorry, Madison, South Dakota - wonders about the security of onscreen keyboards.  We've talked about this before.  I know that keyloggers are a major way for malicious individuals to steal account information from users.  I was wondering, if a bank's website were to implement an onscreen keyboard, where the user clicks on the keys to enter their password, would that be more secure?  I know that keyloggers can also measure mouse-click positions.  So if the key layouts were randomized at each time, would this be a secure means of authentication that's immune to keyloggers?  I think we - he's doing this actually as an undergraduate research project.  I think we talked about this recently, didn't we?



STEVE:  Yeah, we did because it was - in fact, it was in last week or two weeks ago's episode.  Someone was asking about the notion of a keyboard jumping around the screen.  And the sense was that, well, the reason I included this question was that I want to always reinforce this notion that security is not absolute.  It's a relative thing.  You can design systems which are absolutely secure as you can make them within the constraints.  So, for example, having a keyboard that randomizes its key positions is going to be better than not randomizing its key positions, which is going to be better than not having an onscreen keyboard and using a physical keyboard, which is really not very good because it's really prone to keystroke logging.



So absolutely, the more you can do to confuse things and to slow down the bad guys, the better.  You're going to have a lower chance of being compromised.  But again, if your model is perfect information, that is, anybody logging in can see what you can see, then even an onscreen keyboard could be mapped and tracked.  Which is why, for example, in last week's episode I talked about this Perfect Paper Password system where its key is, so to speak, it never reuses the same login twice.  Which means the act of logging in obsoletes that login so that even somebody with perfect knowledge can't use that knowledge.  So, I mean, that's substantially stronger than anything that uses a repetitive login and some sort of a puzzle.  You might even consider that, like, moving the keys around the keyboard is sort of a puzzle.  Lord knows it's going to confuse your users.  Wait a minute, where did the "E" go?  I saw it over here just a second ago.



LEO:  It's going to drive them crazy.  That's my only complaint is it's going to make them nuts.



STEVE:  Right.



LEO:  Let's see.  Frank S. Werren of Sherman, New York needs random numbers to go:  I sometime work on networks within a closed environment - this guy's probably working for the NSA - with no access to the external Internet.  It'd be nice to have GRC's Perfect Password page packed into a zip file that could be unzipped at a remote location, or a GRC utility that has a pseudorandom number password generator in a nice, neat file.  I trust you, Steve, and you make the right software with no holes in it.  And I know I could install your utilities with no fear of compromise.  Any thoughts?  Yeah, could you make this a standalone?



STEVE:  Well, it's interesting because one of the offshoots of the Perfect Paper Password system is that little EXE, remember that's 11K, and it depends upon a 17K DLL.  So together, what are we, at 28K.  Actually 8K of that combined is just Authenticode.  But it has a very high-quality pseudorandom sequence generator in it.  If you say PPP space and then a null string, just open and closed quotes, that tells the EXE to generate a sequence key, which is hex for a 384-bit extremely random output.  So anybody can just grab the PPP EXE and the PPP DLL and have a very portable, high-quality, pseudorandom number generator.



LEO:  Very cool.  And just run it via command line.



STEVE:  Exactly.



LEO:  Steve.  That's a nice side effect.



STEVE:  Yeah, it's neat.



LEO:  I never even thought of that.  Fred Zanegood of Orlando, Florida wants some OpenID Delegation clarification:  A few episodes ago you briefly mentioned OpenID delegation.  Can you explain this further with detailed information on its purpose, implementation - didn't we do a whole series, an episode on this?



STEVE:  We did one on OpenID.  We didn't talk about delegation too much, so I thought I would just answer his question really quickly.



LEO:  Okay.  He wants to know exactly how it's used, its purpose, its implementation.  I understand the concept of creating an easier identity alias for the somewhat cryptic and lengthy one used by VeriSign.  But beyond that, I don't see how it actually gets utilized.  Unfortunately, there doesn't seem to be much information on this yet.  You and Leo also spoke about using SeatBelt for Firefox.  How does this fit into the picture?  Does using SeatBelt preclude you from having to add the few lines of HTML to your home site?  Leo mentioned he uses Leoville.com, I believe - that's correct - for his delegation home base.



So the idea of this is with OpenID, when you log onto a site that supports OpenID, it will then ask you for your domain.  You could say - and give it Leoville.com, and it will then go to the right OpenID provider and give you the OpenID login.  Why do you need this extra step, I guess is what he's asking.



STEVE:  Well, yeah.  So I just wanted to clarify for Fred's understanding here that you could go to a site that wanted you to use OpenID to authenticate and give them your, for example, steve.gibson.pip.verisignlabs.com URL, essentially.  In which case that site would go directly to - basically to that URL in order to pick up the OpenID to begin the whole authentication process.  However, delegation allows you to give it a nicer URL that you control because the first thing that the server will do is look on the page, the HTML page that comes up for specific OpenID delegation instructions up in the metatags of the page.  So the idea is that instead I could simply give it, just as you do, Leo, giving Leoville.com, I could give it GRC.com.  So the site that is asking for my credentials, I give it GRC.com, and the first thing it does is look in the metatags of the default page that comes up at that URL for delegation instructions.  And that then contains the gnarly URL pointing it to my actual OpenID delegator.



LEO:  So it's just easier to say GRC.com or Leoville.com.



STEVE:  Way easier, yeah.



LEO:  But that's the only - in fact, if you look at the HTML code you embed, it's really pretty much just saying, oh, go over there.



STEVE:  Exactly.



LEO:  It's too long.



STEVE:  It's just a pointer to another site.



LEO:  Right, it's very simple.  So unnecessary, a convenience, that all.  No additional security.  Finally, Tim Knittel of Lexington, Kentucky wins this week's clever idea award.  And now, ladies and gentlemen, our winner of the great idea of the week contest, which is not a contest, and he's not a winner.



STEVE:  But it's a great idea.



LEO:  It is a good - we could find some stuff to give away.  I'll think about it.  It occurred to me while I was listening to your award-winning podcast - did we mention that this is the best science and technology podcast?  I don't think we did.



STEVE:  I don't think I did.  But I think everybody knows because they made it happen.



LEO:  That's right.  That there's a fundamental difference between the way blind website users and spambots interpret alt tags.  The difference presents a possible solution for allowing blind users to understand and use image-labeled form fields while still preventing the spambots from understanding them.  The difference is spambots read alt tags.  Blind users listen to alt tags.  Therefore, to a blind user it's equivalent to write "email" or "ee-meyl" because it's pronounced the same.  The spambot doesn't know what ee-meyl is, or any variant thereof.  So he suggests for "subject" to do "suhb-jikt"; for "your name," "yohr neym" and so on.  That's actually a clever idea.



STEVE:  I think that's why he won the clever idea award.



LEO:  And there's no canonical phonetic spelling.  So it's not like a spambot can learn all the different ways of doing it.



STEVE:  Yeah, no spambot's going to start going for phonetic interpretation of - it's going to do a string match on the alt tag to see if it can figure out how to fill out the form.  But this is going to be like, you know, a phonetic version.  I thought it was very clever because it nicely obscures it from the spambot while still being completely screen reader friendly.



LEO:  Very clever.  Well, we thank you for your good suggestion.  We thank you all for your emails.  And if people want to send you questions, it's not really email.  There's a form, as we mentioned.



STEVE:  Yup.  In fact, we tried email, and that was a disaster because the spammers found it immediately.  So, yes, it's an online form at GRC.com/feedback.



LEO:  All right.  Just go there, fill it out.  And of course there's a great security forum there, as well, where you can talk to other security experts.  That's GRC.com.  That's where you'll find SpinRite, everybody's favorite disk recovery and maintenance utility.  It is the program you must have for all your disk drive needs.  And lots of great stuff from Steve for free, including ShieldsUP! and all his free programs and his Perfect Paper Password generator.  That's GRC.com/ppp, by the way.  And if you go to GRC.com/securitynow, you'll find 16KB versions of this show for your friends with dialup connections, Elaine's great transcriptions, all the show notes, and a lot more.  GRC.com.  Steve, a great job once again.



STEVE:  Always a pleasure, Leo, and we'll be talking next week.



Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#117

DATE:		November 8, 2007

TITLE:		Even More Perfect Paper Passwords

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-117.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the updated second version of Steve's Perfect Paper Passwords (PPP) system and examine a number of interesting subtle questions such as whether it's better to have fully random equally probable passwords or true one-time-only passwords; and how, whether, and why attack strategies affect that decision.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 117 for November 8, 2007:  Even More Perfect Paper Passwords.



It's time for Security Now! with the even more perfect, the better than ever Steve Gibson.  Hello, Steve Gibson.



STEVE GIBSON:  Hello, Leo.  Great to talk to you again.



LEO:  This is the Even More Perfect Paper Password episode.  Steve, we can't go any farther than this.  There cannot be any more perfect paper passwords than this.  Because then even more is, like, it.



STEVE:  Well, we have had a really active two weeks of amazing, really amazing think tank work.  And actually the newsgroup is called GRC.thinktank over in the newsgroups.  It's been two weeks since we unveiled the Perfect Paper Passwords system.  It's in Version 2.  I want to talk about what's changed.  And some really interesting issues have come up and been battled with.  So this is going to be - this is sort of a propellerhead episode.  Technically it's about Even More Perfect Paper Passwords.  But I think people are going to find it really interesting because of some of the sort of edge conditions which have come up and we've addressed.



LEO:  Very cool.  Well, let's - where should we start?  Do you want to do anything from previous episodes?



STEVE:  I don't really have any errata.  And the one thing that Sue, my operations manager, who's been with me for 20 years, has asked me a couple times to mention and I keep forgetting it, is that relative to SpinRite licenses she keeps running across companies that aren't aware that we have an enterprise license in addition to a site license, the idea being that an enterprise license is a multi-site license.  And it's really my fault because I don't have anything on our website about the enterprise license.



LEO:  Well, come on.



STEVE:  But - yeah, I know.  But we came up with it because there were big companies like IBM and others who really did want a multi-site license.  And it didn't make any sense for us to ask them to buy four copies of SpinRite for every one of their sites.  So I'm going to get my pages updated so that I explicitly explain that.  But the idea is that any company that wants an enterprise license, that is, a multi-site license where they can use it within their entire organization, what we've done is we've divided the world into U.S. and non-U.S.  And a domestic enterprise license is just 10 copies of SpinRite.  And if a company is maintaining 10 copies of SpinRite at its current version, then they are enterprise licensed, and they can use SpinRite anywhere in the U.S.  And then we similarly have anywhere outside the U.S. is another 10.  So if it's an international company, and they want both inside the U.S. and outside, that would be a total of 20 copies.  Or they could have one or the other, if not both.  And...



LEO:  Can you put this on the website?



STEVE:  I've got to put this on the website.  But I just, you know...



LEO:  I can't even follow it.



STEVE:  Sue's been bugging me because the way we have a - an individual can just buy one copy, have one license.  Then we decided, okay, if someone has four, then that qualifies them as a site license, where they can use it on all the machines they've got in a single physical location.  And then we said, okay, and if someone has 10 copies of SpinRite, then they're able to use it enterprise wide.  So I just - I've said it now, and I've been promising Sue that I would.  I will get this updated on our website so that people who haven't heard this will know, too.



LEO:  Thank goodness.  Even more - even more perfect...



STEVE:  Well, I just realized that I could have talked about something that I want to definitely talk about before and kind of put it in the errata section, although it's really not errata.  I want to start first, before we get into Even More Perfect Paper Passwords, bringing people up to speed on some really cool news from VeriSign.  I FedExed one to you, which you've - yesterday.  There is a new form factor for the six-digit one-time password authentication solutions offered by VeriSign.



LEO:  Does this replace the keychain fob thing?



STEVE:  Yes.  And there's even better news, Leo.  VeriSign's backend server system was recently updated to allow the simultaneous testing of up to five tokens, five hardware credentials.  And PayPal supports it.  So, and I've already done it, and it works.



LEO:  So I can lose the fob.



STEVE:  Yes.  Well, A, you can lose the fob; or you can register multiple fobs; or this new thing, and we didn't really describe it yet.  What they've done is they've got, I mean, an absolutely credit card perfect form factor.  It's the size of a credit card.  There's no lumps or bumps.  I mean, it's an amazing little piece of technology.  It's got a - actually it's an eight-digit eInk window, so it uses eInk that you and I are fans of with the Sony Reader and other readers coming in the future.  So it uses no power.  It has a three-year warranty from VeriSign.  It's more expensive than the fob from PayPal, which you remember because PayPal was supporting its adoption.  That was only $5 from PayPal.  But so I think it's like $48 from VeriSign.



LEO:  But the convenience compared to the fob, you can stick this in your wallet.



STEVE:  Oh, well, that's just it.  I mean, I have my wallet in my back pocket, and so it's with me whenever I have my pants on, which is pretty much all the time.



LEO:  I hope so.



STEVE:  More often than I would like.  And so, I mean, it's always with me.  It's no longer a blob on my key ring.  And so this, for example, works with OpenID, works with eBay, works with PayPal, and any other people who are part of this VeriSign identity protection backend.  So the URL, and we'll have it on our show notes also, for people who are interested in just, like, seeing it, it's IDProtect.verisign.com.  IDProtect.verisign.com will take you to the page where you see both what I call the "football," the original football fob token credential dongle thingy, and this really new credit card.  But because their server can simultaneously test for five, up to five, for example, on my PayPal account I've got my original PayPal credential and also this credit card gizmo, both registered as PayPal authentication.  So, for example, that allows me to keep my - because my own physical environment here where I'm working is secure, I can keep the little football guy here next to me on my desk and have the credit card in my wallet.  So if I'm ever out and about or am using my laptop at a Starbucks or something, I'm still able to  use PayPal using that very cool form factor, this credit card form factor, and at the same time still have access to the little football token.



LEO:  So I could use either one.  Either one would work.



STEVE:  Exactly.



LEO:  Oh, neat.  Now, how do I tell - well, this is a little personal support.



STEVE:  It's in there.  I stumbled around in PayPal.  But it's under Security Key and...



LEO:  You can add an additional security key, basically.



STEVE:  Yes.  And it shows you, I mean, it says on the UI, remove one, add one, I think you can disable one.  It's got a whole nice little UI, like things you can do.  And it'll give you up to five that you're simultaneously able to register.  And this all uses VeriSign on the back end.



I also should mention that - I mentioned, I guess it was a couple weeks ago, that I never heard back from VeriSign on their pursuit of allowing me to play with their API for doing this backend authentication because I just sort of wanted to see what it was like.  They have provided since all of the documentation for their API.  And I have to say, I mean, I haven't yet had a chance to bring it up to speed.  But I'm going to because I want to actually use it and get the experience of talking to their backend servers.  But I've looked at the protocol extensively, and it is as clean as it could possibly be from a privacy standpoint.  That is, they're collecting no information they don't need.  There's no user identification in there.  It's just essentially the serial number of the token.  And you say here's a serial number of the token; here's the current display being showed by the token.  Is this valid or not?  So it's absolutely, absolutely clean.



LEO:  Well, thank you for sending me one.  I didn't realize they were that expensive.  I appreciate this.



STEVE:  Well, they actually sent me two.



LEO:  Oh, good, okay.



STEVE:  So, and then I got a couple more because I actually think that I will use this in addition to the Perfect Paper Password system for GRC's authentication.  I'm going to implement it and give it a try and get a sense for how it works.



LEO:  Well, I can't wait.  I'm going to figure out how to do this right now.



STEVE:  Oh, I mean, you add yourself to PayPal.  And now, as you said, you've got that in your wallet.  And again, as this spreads, I mean, it's an OpenID authentication because it's completely compatible with the whole pip.verisignlabs.com OpenID system that we've talked about before, as well.



LEO:  I have to add it, I guess, to my PIP account, as well.



STEVE:  Probably.



LEO:  Yeah, yeah.  Cool.



STEVE:  So I wanted to bring people up to speed on that.



LEO:  We're moving ahead with this system.  It's really great.



STEVE:  Yeah, it really is evolving nicely.



LEO:  Yeah, I'm glad...



STEVE:  Okay.  So Even More Perfect Paper Passwords.



LEO:  Even more, ladies and gentlemen.  It couldn't be any better, you thought.  No, yes, they're even more perfect.



STEVE:  Well, first of all we are at Version 2, and the algorithm has changed.



LEO:  Oh.  Now, why is that?



STEVE:  Well, because I realized that the 128 bits that I was using to add to the input of the Rijndael cipher was buying us almost no additional security.  It was completely dumb.



LEO:  Why is that?



STEVE:  Well, what happened was - okay.  Just to refresh users' memories, the system has a 384-bit key.  384 is 128 plus 256.  The 256 bits of the key are used to directly key the Rijndael cipher.  So that's the key that goes into the cipher that scrambles things.  The other 128 bits I was adding to a counter, and that was the data.  The result of that addition was the data which was going into the Rijndael cipher.  And the output of that cipher was then where we got the Perfect Paper Password passcodes.



So someone posted - I had made a posting saying, gee, I wonder whether it would have been better to use an XOR than an add because then the bits would be scrambled around rather than just being - creating an offset.  Well, the person correctly pointed out that it really didn't matter, neither of those were better or worse than the other because, since it was a cipher, if you had a collection of passcodes that are 24 bits each, you could assemble them back into one of the 128-bit blocks of the Rijndael cipher and decrypt that back into what was put in.  And if you took two of those in succession, then what would come out would be the counter's value or the XOR value that was just differed by one bit.  In other words, it really provided no additional security.  You could essentially trivially reverse engineer what the counter value was and what those 128 bits were.  So essentially it would require you to do two operations rather than one.  So adding 128 bits only doubled the strength, like having one more bit of key.  But here we had 128 bits more.  So I thought, this guy's absolutely right.  That was a dumb thing to do.  Let's get rid of it now.



LEO:  This is why, by the way, I think in security peer review is so valuable.



STEVE:  Oh, it's - absolutely.  It helps so much to have multiple people looking at the same thing.  And in fact, you know, that's been the way the last couple weeks have been spent is in just amazingly interesting dialogues with people over on the GRC newsgroups, really pounding on this and hashing it around.  And I just, yes, I could have left it alone.  But it just, you know, when I realized that 128 bits being added to the input really wasn't buying us, I mean, it was buying us one bit worth of additional security, essentially, I just thought, okay, let's get rid of this right now before this goes any further.



So we created Version 2, which is substantially cleaner.  Essentially the 128-bit counter now just feeds directly into Rijndael.  The sequence key is just the Rijndael key.  We take the output from the Rijndael cipher, which is 128 bits, group those in sets of 24 bits, each of which is a passcode.  So, I mean, it's cleaner than it was.  And someone might say, oh, well, but you've made it only half as strong.  And it's like, yes, but 256 bits is way more than we ever needed.  I mean, you could argue, many people feel that 128 bits on a symmetric cipher is already secure enough because the number of possible combinations literally goes up exponentially.  You know, every time you add a bit, you double the strength.  And when you've done that 128 times, you're already up there way high.  So we're going further just because why not, it's convenient, to 256 bits, which is just phenomenally uncrackable.  So there was just, you know...



LEO:  I like that.  Phenomenally uncrackable.



STEVE:  Phenomenally uncrackable.  There just was no reason to leave it the way it was.  Okay.  So the other thing that has happened is, in this last two weeks since the introduction of Perfect Paper Passwords, is we've had a really gratifying reaction from people implementing their own open source solutions.  And they're all listed.  And I'll be maintaining a list of this as this continues to grow over on the other PPP software page.



LEO:  There's a link right at the bottom that says additional implement- or additional software or something like that, yeah.



STEVE:  Right.  There's a set of pages that shows the algorithm and implementation, usage notes and everything.  Every one of those pages has a little link block at the bottom.  And so it's page six at the moment, other PPP software.  But we've got, for example, open source implementations in C.  I think we mentioned before that there was going to be a Mac OS X PAM, a Pluggable Authentication Module, and that's done.  And also for Linux.  People are using it to log into Macs and Linux machines over SSH, the Secure Shell login, and being prompted for passcodes.



LEO:  Oh, that's neat.



STEVE:  So, I mean, it's done, and it's working, and a bunch of people have been using it.  We've got an open source implementation of Windows, also several other for UNIX.  There's one written for PHP.  And there are some PHP test pages where you're able to get passcards and log in using PHP.  All this is open source.  There's a .NET wrapper around my DLL that I provided.  So people who are using C# and .NET platform from Microsoft are able to use it.  There's a complete implementation in Java that is in the language Java, so that if someone were Java-centric, then they could do the authentication, print the passcards, and everything.  And there's one coming in Perl that's not yet available.  So...



LEO:  Speaking of Perl, I got an email from Randal Schwartz, who's a Perl guru and a security guy and is on a cruise right now, so he's not listening at the moment.  But he asked is this anything like S/Key, which has been implemented in BSD for a while.  In fact, actually it's been kind of deprecated in BSD for a while.  Same idea.  Are you familiar with it?  Do they talk about this at all in the forums?



STEVE:  No, I haven't heard.  But I've heard of S/Key.



LEO:  It's a one-time-password system for authentication, similar, I guess.



STEVE:  Of course we did talk about OPIE, the one-time password - I can't even remember what the acronym stands for.  But OPIE is a one-time-password system that's available over on FreeBSD.  And it uses a very different scheme where they've got a vocabulary of 2048, that is to say, 11 bits' worth, 2048 short real English words.  And then they choose six of those, and that's your one-time key.



LEO:  Oh, interesting.  All right.



STEVE:  And so it's six different actual English-language words.  And so, I mean, it's a nice solution, although it ends up of course being much more bulky than the PPP system.  One of the things that people have really liked and reacted positively to is that we're just using these cute little four-character passcodes...



LEO:  Easy to remember, but carry it in your wallet, I love that idea.



STEVE:  Exactly.  And a little credit card-size printout will hold 70 of them.  And in fact I modified the printout page since our first podcast to bring them closer together.  So you could either cut them out as individual cards, or it's now easy to cut them out like a three-high card, which you then fold inwards to create just sort of a little booklet of three cards.  And by folding them inwards you conceal what they are.  As long as it's folded together, no one can see what the codes are.  Because there were some people who said, wait a minute, you know, what if someone took a picture of your...



LEO:  Right.



STEVE:  Well, and it's like, that's absolutely true, I mean, it's certainly the case that there are tradeoffs associated with a printed passcard that you don't have with a one-time token, which is only showing you the currently valid code every time you press the button.  It's definitely the case that you have those sorts of tradeoffs.  But this is zero hardware, no batteries to run down.  And it's just - it's a nice solution.  So we have a large array now of open source implementations.  And just Googling Perfect Paper Passwords around the 'Net I've seen a lot of adoption happening.  There's SSL-Explorer that's in the process of getting it.  And it's all over the place.



LEO:  Wow, that's really neat, Steve.  You must be very gratified.



STEVE:  It's, well, it's cool because it's a solution that of course I came up for us.  And I want to, I do plan to be offering it in some future remote authentication applications.  Now, one really interesting point was raised, which became known as the "Peabody Dilemma."



LEO:  I love it.



STEVE:  Because someone whose handle is "Peabody," he said, you know, I really like the idea and the whole system and this notion of random passwords.  But if they're random, then they're really not one time because two of them could be next to each other.  That is, you know, you could have - there's nothing to prevent you from, if every single one is random, and the chances of any particular one being one in 2 to the 24th power, which is to say one in 16,777,216, then there's that chance, one in 16-plus million, that you'll have two passwords the same, right next to each other.



LEO:  Okay.  So...



STEVE:  So how is that one time?  And it's like, oh.  Well, that's true.  Our use is one-time use, the idea being that it's changing every time.  But he said, okay, but it's not really changing every time.  It's changing most of the time.



LEO:  Like a lot of most of the time, but okay.



STEVE:  Oh, yeah, like, exactly.  You're like, you know, there's a one in 16 million chance.  But then as you increase the window, as you say not just the one just before, but maybe the one two before, or three before...



LEO:  Yeah, that's true, that goes up, sure.



STEVE:  ...then the probability - because, well, and you sort of get into a little bit of sort of like the birthday paradox.  Okay, so that sent us off on a really interesting tangent for quite a while because he had a point.  And here was the point.  It really doesn't matter if an attacker has no knowledge, that is, someone trying to attack the system has no knowledge of prior passcodes because every one of them is going to be random, and there's only a one in 16.77-plus million chance of an attacker ever guessing correctly.  But Peabody made the point that, okay, but keystroke logging is one of the things we're trying to prevent against.  That is, the reason we do this is that we know that one possible bad thing that could happen would be keystroke loggers, who don't know about the PPP system, but they see somebody log in with their username and their secret password and their PPP code.



LEO:  And now they have it.  And there's one in 2.6 million chances it'll work the next time.



STEVE:  Exactly.  And so his point was that wouldn't a true one-time-password system be more secure in the presence of keystroke logging than a random password system.



LEO:  Yes.



STEVE:  And he's right.  He's absolutely right.  And so then we said, okay, well, wait a minute now.  What does that mean?  Well, if we had a true one-time-password system where no password could ever occur a second time, then a couple things happen.  First of all, in the face of somebody with perfect knowledge, as we've talked about before, somebody who, for example, was recording everything you did, they would not know what the next password was.  But in knowing what all of the ones that had come before were, if they knew that they were never going to happen again...



LEO:  Ah, they'd reduce the set.



STEVE:  Yes.  Exactly.  It allows them to know never to guess anything that he'd already seen because the system was designed never to allow that to happen again.  So you're right.  It reduces the set.  And so, I mean, but not a lot.  But again, it is shortening up the number of possible passwords that they could choose between.  Now, again, we've got 16,777,216.  So even if you recorded all of the last eight million of them, well, you'd still have another eight million to choose from.  So, which, again, is a lot of strength.  And I'll remind everybody that that's still eight times more strength than any of the hardware dongles have because they're just one million possible combinations because they're just six decimal digits, 000000 to 999999.  But the point was an interesting one.



So the reason we have duplicates, and this is sort of an interesting aspect of this, is if we had passcodes that used all 128 bits of our cipher, remember that we have a counter which is incrementing, and it's never decrementing.  It's only going upwards.  So every value in that counter, we have 128-bit counter which goes into the Rijndael cipher, and out comes another very different 128 bits.  And what we know is that every single counter value will map into a different output.  So those never repeat.  That is, the 128 bits never, never, never repeats.  But the reason we get repetition is we're only using a chunk of those at a time.  We're only using 24 bits out of the 128.  And then we're using the next 24 bits and the next 24 bits, sort of going along those 128.  And so the idea is we can get repetition because we're using 24 bits, and it might be that another output from the cipher would arrive where we would have the same little chunk of 24 bits that we'd seen somewhere else, even though all the other ones out of the entire 128-bit cipher were unique.  So that's guaranteed.



So what this means is, if we wanted to have a true one-time-password system, then we would need a 24-bit block cipher.  That is, we would need a 24-bit counter feeding into a 24-bit cipher, which mapped that then to - essentially permuted those 2 to the 24 into an entirely different set of 2 to the 24 combinations.  That would give us a one-time-password system.  But the problem with that is that 2 to the 24 isn't a huge number from the standpoint of, like, recording them all.  That is, 2 to the 24 is 16 million, as we know, 16 million passcodes.  Well, we can store that in RAM.  I mean, we can - 16 million would be, what, 64 megabytes.  Or, no, even - it would be not even 64 megabytes, 48 megabytes because it's three bytes per.  So it's possible to make a table which we start filling in of these things.



The reason that, I mean, the specific reason that ciphers have larger block length nowadays, that is, 64 is considered very strong.  32 is no longer strong enough because there just aren't that - it's possible to build a table of the inputs and the outputs from a 32-bit block length cipher and begin to attack it that way, a so-called "electronic codebook attack" where you actually record the outputs, because we've got enough RAM to do that.  We don't have enough RAM, when you talk about 64 bits, or certainly not 128 bits.  There are just too many of them.  So we really do want a large block length cipher.  And but that means, if we're not going to have passcodes which use all of those 128 bits, we're going to have repetition.



And so we went back and forth, had some really great discussions about, okay, what does this mean?  Well, and I proposed a couple schemes for, like, going back in time, for example.  And if you don't really have to verify that you've never seen a passcode before, but because the presence of the possibility of keystroke logging, the idea that an attacker might use passcodes you had recently used, wouldn't it be worthwhile then to make sure you don't have repetitions within, sort of like within the near term, like within the last 250 passcodes, for example, that you haven't already used those.



So I said, well, okay.  What if we went back, and we looked at the prior 250 passcodes.  And if the next passcode was going to be a duplicate, we add one to each of its bytes, turning it into something different, just to sort of, like, brute force a nonlocal repetition of passcodes.  Well, the problem with that, it was pointed out, is that if you're going to do that, then in order to know what those 250 were before, you've got to look at the 250 before them, and the 250 before them, and the 250 before them.  In other words, you would always have to go from the very beginning and make sure that you had no repetitions.  So it ends up sort of being recursive and not feasible to do this.



So anyway, we had some really interesting discussions of this notion of the difference between true one-time-passwords and basically random passwords, which is clearly what the PPP system is, is random passwords.  But one thing that came out of this is the notion, then, that not all keys, not all sequence keys are created equal.  That is, you could spend some time looking at random sequence keys until you found a better one.  You might look at a sequence key and sort of basically run the codes on it for the first 100,000 codes, and if you happened to get one with lots of close duplicate passcodes, just say, eh, we don't like that one, and pull another random one and check it.



Well, it turns out that that's what I have ended up liking to do.  This is not going to be part of the Perfect Password system.  But, for example - Perfect Paper Passwords, rather.  But, for example, when I do this for our keys for my GRC employees, and when I implement this in my own use of the system in our commercial authentication product that is coming downstream, there's no reason, it seems to me, not to spend a little time upfront, in terms of computing time, and we're only talking four or five seconds, probably, just to not grab the first sequence key that comes out of our random sequence key generator, but grab, I don't know, look at a hundred or a thousand of them and scan them to see if there's one that's better than another.  Because the point is, yes, in the case of an attacker who has no knowledge of prior passcodes, then random is absolutely good. And random is what we've got.  But because the world has keystroke loggers, that biases the attacks a little bit toward re-use.  And re-use is something we'd rather not have.  So there's no reason not to choose sequence keys which, for the first likely span of passcodes, 100,000 passcodes, don't have any repeats.  And I've done the research, and it turns out it is very possible to find passcodes - actually I looked at the first 200,000.  Turns out that there's lots of sequence keys that have zero repeats in the first 200,000 passcodes.  And so we get the best of both worlds.



LEO:  That was a good idea, yeah.  Simple thing to do, yeah.



STEVE:  Yeah.  It's very simple.



LEO:  And if not, you generate a new set until you find one that does.



STEVE:  Exactly.  It turns out you don't have to look very long.  I did it by hand, and I found a bunch just by hand.  Well, I didn't really check 200,000 passcodes.  But I've altered my code to check it.  And what I like about that is that sequence keys are issued rarely.  That is, they're issued infrequently, and they're used for a long time.  So it makes sense, I mean, it's economically feasible to spend some compute time upfront to develop this notion of better and worse sequence keys and choose one, for example, where in the first 200,000 passcodes there's zero duplicates.  Turns out there's lots of those.  And so why not use one?  And then you've solved the problem of keystroke logging.  You get the equivalent of a one-time-password system within a reasonable horizon of passcodes, I mean, 200,000 passcodes is going to last a long time, no matter how much, you know, how often you use them.  And...



LEO:  How did - go ahead.



STEVE:  And we still end up with this notion of their actually being chosen at random, even though, again, if an attacker had perfect knowledge of the fact that we had chosen a good key, they would know not to guess any that we had already chosen.  But again, that presumes somebody has access to every passcode you've ever used.  And even if they did, the possible universe of still-unused passcodes is still bigger than 15 million.  So you haven't really lost any power.



LEO:  And how did Peabody feel about all this?



STEVE:  Well, he likes it.  It was funny, too, because he was making the point over and over and over, and everyone was telling him, no, no, no, they're random, they're random, don't worry about it, you know, they're random.  But what I liked about his point was, he said, yes, but we know that keystroke loggers exist.  And so what we're trying to prevent against is re-use.  And so why not prevent them from being reused?  And it's like, that's better than random.  He's right, that's better than random.



LEO:  And as it turned out, I mean, the simple solution that you came up with gets the job done, and there you go.



STEVE:  Well, I like it, again, from an economic standpoint, to me it makes sense to spend some time - and we're only talking a few seconds because all this is very fast - spend some time to find the best sequence key you can where "best" means no repetitions within a certain length of time.  Or not near repetition, not two or three passcodes apart, but maybe at least 50 or some.  And what I should say is that I found many where there were no repetitions within 250 passcodes in a horizon of 200,000 passcodes.  That is, looking that far down in the future, you never saw any repetitions within 250.  So it's like, okay, that's, you know, we're really, really safe.



LEO:  Yeah, good enough.



STEVE:  Now, one thing that I mentioned erroneously generated a lot of mail two weeks ago.  I talked about the idea of skipping passcodes, that is, skipping forward.  And I don't even really remember what I said, but I must have said something like somehow the system would automatically skip forward.  Because many people commented that that could allow a denial of service attack on the Perfect Paper Password system because an attacker could force you, like could force the next passcode, like, far enough ahead that the user would run out of passcodes and would no longer have them.  So I misspoke when I said that.  That was never really my intention.  I certainly would only - my original notion was that you'd have to have the username and the secret password and the passcode all correct, obviously, in order to authenticate, and that maybe if only the passcode was incorrect, then under some circumstances you would move forward.  Well, again, we hashed this around in the newsgroups a lot and came up with what I think is a very nice solution.  One of the problems of four-letter words is, I mean, four-letter words is, in the English language, at least, is recognized slang for words that are not popular or should not be used in polite conversation.  You know, like four-letter words.



LEO:  Ah hah, yes.



STEVE:  Know a bunch of them.  Well, so imagine a system, Leo, where you are being asked to enter a four-letter word that makes you uncomfortable.



LEO:  That's right.



STEVE:  I mean, it could happen.



LEO:  It could easily happen.



STEVE:  It could easily happen.  Well, yes, I mean, in fact, every one of the possible four-letter words that exists could occur because we're just choosing four-letter things at random.  Now, one person, I mean, this had been discussed before, before we even talked about it.  Like someone said, well, what about eliminating vowels?  Then that would make it hard.  It was like, well, okay, but in general eliminating vowels meant that we had to then use more strange characters, which might be difficult to find or you might not have on a cell phone, for example.  So I decided that there was - the system, to be user friendly, ought to not force someone to enter the next four-letter word if they just didn't feel comfortable for whatever reason typing it into a computer screen.  So the idea...



LEO:  You can't prevent them from seeing it.



STEVE:  You can't prevent them from seeing it.  I don't think it makes sense to, like, have a dictionary of all possible offensive four-letter words and search even longer for sequence keys where none of those occur.  That seems like overkill.  So the idea would be, if you're presented with a word that you don't want to enter, or, for example, someone's got an inkjet printer that's on the fritz and they can't read one of the characters, I mean, that was the idea of allowing people to move forward, was what if for whatever reason you could not read a passcode, or your passcard of 70 passcodes went through the wash by mistake, and it's no longer legible.  The idea was you want to be able to obsolete and move forward.



So the solution turned out to be simple.  That is, normally you're being prompted for the next passcode.  If for whatever reason you either don't want to enter it or you can't enter it, or for example, say that you think maybe that your whole set of three cards, your passcards may have been compromised, you have some reason to believe someone may have seen them, you want to be able to immediately obsolete them all.



LEO:  Right, right, right.



STEVE:  So the idea is, normally the server says, here's the card and row and column of the next passcode, please enter it.  But you always have the option of saying, no, I want to tell you which one I'm going to enter.



LEO:  Ah, perfect.



STEVE:  That's all there is - yeah, well, see, there's my favorite word, Leo, you've just used it.



LEO:  Even more perfect.



STEVE:  So all you have to do is say no.  You always have the option of saying, no, I want to tell you which one I want to enter.  Then it gives you a second form with the passcard number, the row and column as blanks that you can fill in, rather than them being prefilled for you.  And you simply - the only limitation is you have to move forward, obviously.  You would never want to allow the user to move backwards because that would no longer then be perfect.  So they're able to skip over the next code, the next five codes, the next line, the next card.  As long as they move forward from where they were being prompted before, no problem, that advances their pointer, they enter the code that corresponds to that at the same time, and that authenticates them.



LEO:  Very nice.  Very, very nice.



STEVE:  So it ended up being a really nice solution.  There were a couple people who said, you know, for cell phone entry, these funny characters that we've used...



LEO:  Oh, could be tricky, yeah.



STEVE:  Those could be tricky.  Needless to say, on an iPod or an iTouch or iPhone getting some of those can be a little tricky, too.  So someone said, you know, you're using 24 bits.  So you're using six bits for four characters.  I'm going to use four bits for six characters.  In other words...



LEO:  Oh, okay.  So you get the same strength...



STEVE:  You get the same strength...



LEO:  ...just eliminate some of the characters that you can't type.



STEVE:  Well, of course four bits is hex.  So zero through nine, A, B, C, D, E, and F.  And it's funny, too, because he said, you know, even though it's counterintuitive, there are people who will think that a six-character token, that is, a six-character passcode, is more secure than a four-character passcode, even though the four characters has the same bit strength because there are 64 characters per position rather than 16.  And he's like, he's absolutely correct that it's the same strength.  It's like, okay, well, certainly an implementation like that works the same, it's just as strong.  And I could see, for example, in cell phone authentication it might make sense, or in applications where you don't have access to the full alphabet that could make sense.



LEO:  Yeah, six characters isn't a big deal anyway.  You do eight characters for a phone number.  So I think that's great.  That's a very clever way to do it.  What I think people love about this is the - and this is what's great about programming is the problem and then the solution, the challenge of figuring out the solution.  And it's really kind of an intellectual exercise.  It's just enjoyable.



STEVE:  Yeah.  And we've had a lot of fun over the last two weeks, and I wanted to share with our listeners the Peabody Dilemma.  And it was really funny, too, because, I mean, for a long time he was taking a lot of heat because everyone was saying, look, you can't do better than random.  And it's like, but that's true if the attacker had no knowledge of the past.  But if the attacker has knowledge of the past, then you can do better than random by explicitly eliminating the codes that have come before.  You know, why not?  And so we looked at algorithms to do that and just ended up settling on this notion of, okay, not all sequence keys are created equal.  There are better ones.  And since you only need to create it once, and then you get to use it probably for months or years, why not take a little time to find a good one?  And so that's how we ended up with Even More Perfect Paper Passwords.  And 256-bit sequence keys now, down from 384, eliminating those 128 bits that really weren't buying us any additional strength.



LEO:  Are the third-party implementations, do they incorporate your modifications?  Or are these...



STEVE:  Yup, they're all up to Version 2 now.



LEO:  Oh, that's cool.  For 16KB versions of this podcast, for transcripts, for details, for show notes, for implementations of the Even More Perfect Passwords system, you go to GRC.com, that's the place.  GRC.com/securitynow for the show notes; GRC.com for all of Steve's free programs that are so great to help you with your security, everything from ShieldsUP! to Shoot The Messenger and DCOMbobulator.  And his Perfect Password implementation, too, I almost forgot.  Also, of course, don't forget SpinRite.  Can't forget that, everybody's favorite disk recovery and maintenance utility.  That's from GRC.com.  Steve, we've wrapped up another episode of Perfect Passwords, Even More.



STEVE:  Even More Perfect Passwords.  And we will do one of our fun Q&A episodes next week and then move forward into other topics.



LEO:  All right.  I really appreciate it, Steve.  Have a great weekend, and we'll talk to you next week.



STEVE:  Thanks, Leo.





Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#118

DATE:		November 15, 2007

TITLE:		Listener Feedback #28

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-118.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 118 for November 15, 2007:  Your questions, Steve's answers.  This show, and the entire TWiT broadcast network, is brought to you by donations from listeners like you.  Thanks.



Time for Security Now!, Leo Laporte here.  Steve Gibson is in Irvine, and we are ready to talk about protecting yourself online.  Hey, Steve.



STEVE GIBSON:  Hey, Leo, great to be back with you again.



LEO:  Little disappointed because I had high hopes that we could use this new iChat client that's supposed to use a really high-quality codec.  But we're still using Skype because Skype works.  And iChat did not.  I mean, it worked, but it was awful.



STEVE:  Yeah, and we really, you know, we actually spend a lot of time dialing Skype in over time.  And I think maybe if we had given iChat some more time, I mean, for example, I don't know anything about it relative to relaying and passing through our firewalls and all that.  I've got static ports mapped for Skype and so forth, so...



LEO:  Yeah, we didn't do any port forwarding.  So maybe that would help.  But still.  You know, AAC-LD, the codec they're using, or purportedly using, is the same one I use for the radio show.  It's a very high-quality codec, designed for - LD stands for Load Delay.  It's designed for latent networks, but...



STEVE:  Hey, you know, we didn't set any changes or specify the codec.  Is it just changed globally?



LEO:  Yeah, maybe - I'll do some research.  Because, you know, Amber and I want to use it, for not just audio but also for video.  So I'll have to see if we can figure out how to get it working.  There's other stuff we might try down the road, too.  We're always looking for other ways.  Skype's been so good, though, it's hard to beat Skype.



STEVE:  Yeah.



LEO:  Congratulations, by the way, you're now on the Zune.



STEVE:  On the who, what, what?



LEO:  On the Zune.  You've heard of that, have you?  It's a Microsoft product.



STEVE:  It's that brown thing, isn't it?



LEO:  Yeah, well, now they also have khaki green, army green, and some other colors.  The Zune...



STEVE:  Get a clue.



LEO:  Well, it's a little better.  The new Zunes actually look like only one-generation-old [indiscernible].  So that's not, you know, they're getting close.  But the thing, and I won't be flip about this because I really am excited about it, they are supporting podcasts finally, natively.  I mean, there's podcasts right on the front menu.  The Zune Marketplace now has a podcast page, makes it easy to subscribe.  And if you go, if you are a Zune - own the new Zune, or if you've updated your old Zune, and you go to our Security Now! page at TWiT.tv and check the subscribe links, you can now subscribe via the Zune Marketplace.  You just select Zune from your list.  So I'm just, you know why I'm excited about it, with a big company like Microsoft behind podcasts - Yahoo! has dropped out, Odeo's dropped out, PodNova's dropped out, iPodX has dropped out...



STEVE:  Whoa, whoa, they have?



LEO:  All of these people are gone.



STEVE:  Wow.



LEO:  And so, frankly, it's an iTunes world.  And while I'm thrilled that at least somebody still supports podcasts, it's great to have another player in there, and a big one.  Now all they have to do is sell some Zunes.



STEVE:  Well, that would be good.  And of course it's also good just in general from a standpoint of increasing the potential listener base.  I mean, you know...



LEO:  Well, that's exactly my point.  I mean, we're frozen now.  You know, we...



STEVE:  Yeah.  When you first mentioned to me, what, two and a half years ago, more than that I guess now, coming up on three years, you said, hey, Steve, how about doing a weekly podcast?  I said, a what cast?  Literally, I had never heard the term.



LEO:  People still say a what cast, and that's the problem.  I don't have an iPod, they say.  So but, you know, we grew very quickly.  You're the number two podcast on the network, right after This Week in Tech.  And it's, you know, obviously still very popular.  But it hasn't grown much in the last few months, and it concerns me.  And I think that that's really that we've just saturated the iTunes listeners.  And I think particularly for this and Windows Weekly, which are really more Windows-centric, it will really help to have Microsoft in our ballpark.  So anyway, thank you, Microsoft.  We also have a Microsoft update.



STEVE:  Oh, boy.



LEO:  A no thank you, Microsoft.



STEVE:  I was just going to say, yes, and being a security podcast, you know, being tied in with Microsoft, you know, makes some sense here.  Yesterday on - or, I'm sorry, day before yesterday, on Tuesday was the standard second Tuesday of the month update.  And I wanted just to bring to everyone's attention that this one is really important.  It's regarded as not even just critical, but highly critical.



LEO:  Oh, boy.



STEVE:  This is something they've been working on for a couple of months, and it's actually a vulnerability which, refreshingly, does not involve Vista this time.



LEO:  So Vista is not impacted.  Because I noticed I didn't get the download on my Vista machine.



STEVE:  Yes, Vista is not impacted.  This is actually a glitch in one of the core XP and Server 2003 DLLs, the shell32.dll.  And it has the - essentially the effect is that specially crafted URIs, you know, things like news://nntp, telnet, http and so forth, those sorts of references that also include a percent sign are not being parsed correctly.  Now, it turns out that there are multiple sort of exploit vectors for this problem.  The real problem is in this shell32.dll.  However, Firefox users, for example Firefox v2.0.0.5 is vulnerable, and Netscape Navigator, and IRC client, even PDF files.  Adobe has pushed out immediately an update to their Acrobat Reader and Acrobat.  They're now at v8.1.1 as a consequence because just downloading and opening a specially crafted PDF that contained one of these URIs to take advantage of this could cause a remote code execution on people's machines.



LEO:  Wow.  So it's not nearly enough for Microsoft to update its shell DLL.



STEVE:  Well, no, that really is the problem.  The problem is in shell32.dll.  Microsoft has said that IE7 also has to be installed on the system because apparently the installation of IE7 interacts with the OS and changes the way URIs are processed by other applications.



LEO:  Adobe still has to do an update itself, as well.



STEVE:  Well, I think they're doing it preemptively.  They have done it, although I don't think they had to do it if Microsoft had fixed it.



LEO:  So just in case you didn't do the Microsoft update, you would do the Adobe update.  Although we're not sure, so you probably should do both.



STEVE:  Well, and it's worth noting that the original release of this was on October 24, which I believe is when Adobe fixed this.  So they fixed their particular vector of this well before Microsoft has.  And Microsoft is fixing the root problem.  So anyway, for people who are still using XP - I'm not yet using XP.  But XP and...



LEO:  Wait a minute.  Let me get this straight.  You're not yet using XP.  What are you using, Windows 2000 still?



STEVE:  Yes, yeah.  I heard you talking on one of the other podcasts, I think you were talking to Paul, he said, yeah, well, you know, Gibson's still over on Windows 2000, he says.  You could hear him scratching his head.  And I'm going, okay.



LEO:  I love that.  "I've not yet gone to XP."



STEVE:  But I'm close.



LEO:  Someday you will, yes.



STEVE:  Yeah.  That's the plan.



LEO:  Well, XP's been so heavily patched now it's probably the most secure version of Windows except for - now we find another big hole in it, but...



STEVE:  Yeah, yeah.  So anyway, this is an important one.  As long as XP users run Windows Update or click on the little yellow shield if they don't have their system automatically installing updates, this is one you want to get installed very quickly.  Oh, and exploits are in the wild.  There are Firefox exploits.  There are malicious PDFs that are already using this.  So this is not just a theoretical problem.  This is something everyone absolutely wants to take care of in order to secure their machines.



LEO:  Yeah.  Interesting that Vista is not bit.  Is that just because it had its own shell32.dll, or is it because it's more secure?



STEVE:  Microsoft hasn't said.  My guess is it will have its own shell32.dll, so it probably never had the problem.  And again, we do know that Vista is more secure.  Have you seen the new Mac commercial, the Mac ad?



LEO:  Yeah, I love it.  Vista is giving a speech.  Ladies and gentlemen, do not go back to XP.  Stay with Vista.  And Mac says, what's going on?  He says, people are downgrading to XP because it's better than Vista.  Oh, wow.  That's okay, I already have.  You know, it's very funny.  It's very, very funny.



STEVE:  They did a good job.



LEO:  However, maybe not completely fair.  I don't know.  I mean, they're picking up on the fact that a lot of people are saying they don't like Vista.



STEVE:  I don't, and we know a lot of gurus who tried to use Vista and then thought, well, this just isn't worth the hassle, and they went back to XP, so...



LEO:  I've been pretty happy with Vista.  And I think one thing we have to say is it is more secure; right?



STEVE:  It absolutely is.  Microsoft really has learned a lot of lessons.  And to give them credit, they've done - I would argue they've done everything they possibly could without breaking it any more than they have.  I mean, we talk about security as being a tradeoff.  And there's definitely more they could have done, but it would have been at the expense of backward compatibility.  And that's just something they will not do.  And, arguably, probably should not do.  So, I mean, they're moving forward, I think, as well as they can.  And Vista is absolutely a step in the right direction.



LEO:  We're going to get to your questions.  It's a question-and-answer session.  We've got some really good questions and suggestions and conversation.  Our listener feedback sessions really have become our most popular.  Any other addenda?



STEVE:  Two things.  Someone did an analysis of the numbers being generated by his PayPal VeriSign token, the little - what I call the "football," the oval thing that we first talked about, the so-called Security Key that PayPal was offering for just $5, and which you could also purchase from VeriSign.  What he discovered, he was writing down successive numbers, and he noted that the first digit wasn't pseudorandom at all.  It was counting, 0, 1, 2, 3, and back around.



LEO:  Let me try that.  I just got 415892.  I'm still doing that.  So it should be 5 and something?



STEVE:  The next one you get will begin with a 5.



LEO:  Well, that's not very random.



STEVE:  And after that with a 6.  Well, what it means is...



LEO:  Yeah, 5.  Wow.



STEVE:  Yeah.  In retrospect it makes sense because this is a time-based token, and it's going to tend to have some clock drift relative to, you know, galactic central.  So it makes sense that, if you didn't use it for a long time, the first digit essentially sort of creates a plus or minus five effect, where the system would be saying - I mean the dongle, the token, the fob, whatever you're going to call it is going to be saying, here's number 3...



LEO:  Where I am in the sequence, yeah.



STEVE:  Exactly.  And so that allows a - it allows more drift and more lock for their servers.  The bad news is, of course, it weakens the whole system.  We were saying that there were a million possibilities.  Well, there are, but you can guess one tenth of them if you have any sense for where your token is in its 10-cycle phase with the first digit simply counting 0 through 9 and back again.  So it really does reduce the effective strength down from what we thought was a million, down to 100,000.



LEO:  Yeah, but really, and this reminds me of the Peabody Paradox from last time...



STEVE:  That yes, it's enough.



LEO:  Yeah, exactly.  Of course there's the theoretical issues, but then there's the practical issues.  And you still have to guess where you are in the sequence of 10.  I don't know if that would change much as it is.  Now, you know what I'm doing, I'm going to get that card you sent me from VeriSign.  I'm wondering if it's doing...



STEVE:  No, because the credit cards are event-based rather than time-based.



LEO:  Oh, that's right, it doesn't generate a new number till you press the button.



STEVE:  Exactly, and it's not free running.  I don't even think you could fit any kind of a timer crystal in something...



LEO:  It's too small.



STEVE:  ...that is that thin.  So it really does make sense.  It's a different algorithm and a different approach on the credit card form factor than on the little timer-based footballs.



LEO:  So we might be, theoretically, anyway, more secure.



STEVE:  Yeah, I actually think probably would be.



LEO:  I'll just try that.  I've got a 6 here.  You know...



STEVE:  You're going to be going, oh, wait a minute, here's a 7.  Oh...



LEO:  No, now it's a 9, it's different, you're right, you're right.  That makes sense.  It wouldn't work, and so you don't need to synchronize by time.



STEVE:  Well, I mean, they wouldn't have - they didn't have to do it that way.  They could have, for example, searched their expected code space for the code that was presented in order to sort of synchronize.  But it would have taken a little more time over on the server end.  And again, you know, the fact that you're getting a unique code, one out of a hundred thousand, that's still arguably enough, given that it's only intended to be one of multiple factors and intended to prevent, you know, various sorts of replay attacks.  So, yeah, it's still good.



The last thing I want to talk about, and this is something - actually a link from you when this first surfaced must have been the first way I found out about it, but many of our listeners forwarded notices saying would you and Leo talk about this.  And this is this very disturbing breach of faith, essentially, that HushMail perpetrated.



LEO:  Yeah, and I feel a little responsible because I've been recommending HushMail since day one.  And, you know, Phil Zimmermann, the creator of PGP, has worked with HushMail to make sure their algorithms are reliable.  And if you read carefully, you'll realize that there is still a safe way to use HushMail.



STEVE:  Yes.  Essentially what happened was - and there's multiple parties involved.  As I understand it, there's something involving Canada or something, I'm not really sure if they were the ones or not.  But essentially what happened was that the federal government issued them a subpoena saying we need to get the supposedly secure email for the following people.  And it...



LEO:  And you might say, what?  How could they do that?  Because HushMail has said over and over again, even we can't decrypt your mail.



STEVE:  Right.  It turns out that that is sort of true.  Sort of true.  And, I mean, it's a perfect topic for us to discuss here because I've talked about the acronym TNO, Trust No One.  And it turns out that the original implementation of HushMail was extremely secure, but a bit of a pain for users to set up and use.  That is, it was a client-side encryption using a Java applet that did the encryption.



LEO:  So you would download the applet and run it on your computer.



STEVE:  And you had to install Java, the Java Runtime on your computer.  That was sort of one additional step that people didn't want to take.  Now, I'm not sure why they couldn't have used JavaScript in order to do this.  It would seem to me that they ought to be able to use just JavaScript, in which case you'd be downloading essentially the encryption every time you went to the webpage.  But that's not what they were doing.  So you were using a Java applet that was locally encrypting so that what the HushMail servers received was truly opaque, and they were unable to decrypt it.  Well, what happened was they weakened the system in order to increase convenience.



LEO:  Oh, yeah.



STEVE:  When have we heard that before?  So they switched over to a...



LEO:  They still use both systems, but they gave you the option of...



STEVE:  Oh, good point.  Yes, yes, yes.  They added the option which was much more convenient for people of not needing to use a local Java client, but instead just using an SSL connection where their servers would perform the encryption for you and store it that way and so it would go.  The problem is, as soon as they're doing that, as soon as that's over on the server side, well, they know the password used to encrypt your mail.  And so the federal government was able to serve them a subpoena saying we want the email of the following companies.  And I guess these were - I think they were illegal steroid suppliers or some...



LEO:  Steroid investigation, yeah.  The interesting thing is they only know the password briefly, as it goes through the system.  They aren't logging them.  They claim they're not logging them and saving them.  So the subpoena said you need to watch as these guys use the system and record the passwords and record the email so that we can get into it.  So that's kind of interesting.  It wasn't that they were logging it.  But if the Java runs on their side, that's the problem.  So you can still use HushMail with the Java running on your side, and you would be still secure, as I understand it.



STEVE:  And it's really a good lesson.  I mean, it is exactly, for example, what we were talking about a few weeks ago when we were talking about the Amazon S3 service and Jungle Disk, which we're going to be talking about in the future.  I have confirmed that it is possible to set it up, that is, Amazon S3 and Jungle Disk, as fully TNO, that is, fully trust no one.  But it is not the default.  So you have to know what you're doing and push it further than it would otherwise.  In the default case, Amazon does have the key and could be forced, compelled, to respond to a subpoena and turn over all of your files.  So again it's, you know, these sort of things are possible.  But unfortunately the easy way of using them isn't necessarily secure.  And, I mean, we're seeing example after example where, you know, where companies can be compelled to release what information they have.  The only secure thing to do is not let them have it.



LEO:  Very interesting.  And I think scary because people really felt like, oh, HushMail, we should trust them.  They probably should have warned people.  I think they did, but maybe should have warned them in bigger letters that by doing - letting them do the Java was potentially compromising.



STEVE:  Yeah.  I would argue that, if they were offering a system with that kind of security, then they should absolutely not have allowed it to change in a way that was insecure, that is, people were assuming what HushMail was saying would continue to be true.  When they couldn't come up with a way that would prevent them from being able to respond to, for example, this sort of subpoena, then they should have just discontinued it.  They should not have offered an insecure alternative because people are going to take it.



LEO:  Yeah.  That makes sense.  Are you ready, Mr. Gibson?



STEVE:  Let's plow in, Leo.



LEO:  Okay.  We can do that.  Our first question of the day, from Aye Mossum in Redlands, California.  He's using Perfect Paper Passwords.  He's using them for his work.  He says:  Thank you so much for your recent talk on PPP.  He just installed the PAM module by Tom Fors onto his own servers at his workplace.  He says:  I'm the IT department.  I am the entire IT department.  And I feel so much better knowing that I carry in my wallet the keys to get into my server, that no one else can get in without, like, picking my pocket and some seriously nefarious means.  He says:  Thank you both for such a great podcast.  As a result, every week or two I'm implementing some new security measure in my network.  And thanks, Steve, for SpinRite.  Oh, he uses that, too.  He says:  It's saved my bacon twice so far.  That's nice.



STEVE:  Well, I wanted to let people know that we are continuing to have additional open source submissions.  Also we're in the process of taking Perfect Paper Passwords to version 3, which is a major update to it.  There was a lot of discussion after last week's podcast about this issue of the so-called problems with dirty words, that is, you know, there were a lot of people who were saying, you know, I'd like to use this in a commercial setting, but if this thing spit out a word that...



LEO:  A four-letter word.



STEVE:  Yeah, because, I mean, I use those four-letter passcodes.  So it could spit out, I mean, basically every four-letter word is possible.



LEO:  Right.



STEVE:  And so, you know, people were saying, eh, you know, it's just - I'm not going to feel comfortable doing that.  My boss would fire me if one of these little passcards spit out particular four-letter words.  And so it's like, okay, well, that's a reasonable problem.  So we discussed it in the newsgroup.  Some people were also just saying, you know, I'd rather have a character set that needed no shift key.  Somebody else said, you know, I like hex, and you don't have to worry about four-letter words with hex because...



LEO:  Or any words, right.



STEVE:  ...they're all boring.  And so I was sort of thinking about that.  And so I thought, okay, well, what if we reduced the size of the character set.  We had a 64-character character set.  And I experimented with reducing it to a funky number, that is to say, 35.  Because it turns out that there's nothing says character sets have to be even powers of two.  Normally people think in terms of like four bits would be 16 characters for hex.  Five bits would be 32 characters.  Six bits would be 64.  But you could also have strange numbers.  Anyway, what we've done is we've extended the whole concept so that essentially now it's a metasystem.  It's a one-time password metasystem that allows any user-specified character set and any length of token, that is, any number of characters.  And I've got mine running.  A couple other people have theirs running in PHP and C so far.



And what this essentially will do is, it allows you to specify how you would like to use it.  If you would like a larger alphabet, and you're not worried about ambiguous-looking characters because you trust yourself or your particular users in order to be able to determine the difference between a zero and an alphabetic "O," for example, you could use a larger character set.  It would give you substantially greater security.  If you would rather have - there was one guy participating in the newsgroups who said, you know, for a one-time password system, this is already overkill.  I've got my userID.  I've got my passphrase.  I just want to use a three-character token.  Well, version 3 of PPP will allow you to do that.



LEO:  Any length at all.



STEVE:  Any length at all.  Or you might say, I want to use this thing to generate static passwords, sort of like of the kind that I get from GRC's Perfect Passwords page, but I'd like them to be printed out.  So there you could use a longer key that is not changing all the time.  So you want it to be longer so that it's stronger.  So anyway, we're in the process now of revamping all the software.  I've got to rewrite all the pages again.  I've done it twice so far.



LEO:  Maybe you want to wait for version 4?



STEVE:  And I just want to get it done.  So I'll talk about it a little bit more next week.  But then this thing, this topic will finally be behind us.  But we'll end up with something far cooler than we started out with.



LEO:  Good, good.  That's really neat.  Version 3.  There's never a final version in software.



STEVE:  Well, I think this one, we've just about beat this thing to death.  So, yeah, 3 ought to take care of it.  The third time's a charm.



LEO:  Brian Scallan in London, he's worried about the security of SSL or TLS:  You guys have probably heard about researchers in Israel who cracked the PRNG...



STEVE:  The pseudorandom number generator.



LEO:  ...in Windows 2000.  As a result, Windows SSL appears to be compromised, which is worrying because of course online banking and secure transactions rely on it.  It's suggested the flaw might affect later versions of Windows and even reveal past and future SSL keys.  This has shattered my confidence in online security.  Have you any advice that can restore it, Steve?



STEVE:  Well, first of all, he's completely correct.  And this is another issue that is...



LEO:  I hadn't heard about this.



STEVE:  ...right now generating a whole lot of concern and fervor within the security community and with a lot of end users like Brian.  Here's the story.  The guys who implemented the pseudorandom number generator in Windows came up with sort of an ad hoc, very secure-seeming solution.  But it does have some problems.  And they're problems that could have been avoided but were not.  The nature of the problem is - well, there are several natures of the problem.  But primarily, in order to determine the next numbers being generated by Windows' pseudorandom number generator, you need to determine the state of the pseudorandom number generator.  It turns out that it's up in user space, and it's a per-process pseudorandom number generator.  So, for example, if you're running IE, that creates an instance of the pseudorandom number generator in the Internet Explorer's user space.



LEO:  Now, this is true of all pseudo number random generators, like when you say PRNG, that if you know where it is, and you know enough about it, you can tell what the next number will be; right?



STEVE:  Well, yes, except that you could also constantly be mixing in updates.  For example...



LEO:  It could change the seed periodically.



STEVE:  Well, actually constantly.  For example, in all Intel-based systems you're able to read the number of clock cycles which have occurred ever since the last reset of the chip.  So, for example, that could be mixed in on the fly so that you'd really, you'd have a big pool of randomness.  But you're doing something that is constantly churning it.  Unfortunately, Windows' pool of randomness is static, and it is only re-randomized after it's generated 128K of random output.



LEO:  Oh, that's a lot.



STEVE:  Well, yes.  It's turns out that, based on the rate of which, for example, IE pulls random numbers to generate its SSL keys...



LEO:  That could be days, months, years.



STEVE:  Yes.  It could be from the time the user powered on their computer until they turn it off.  I mean, so in a whole session-long series.  Now, the reason this is not really a big problem is that there's no way somebody in a man-in-the-middle attack, which is really what SSL is designed to prevent, gets any benefit from this.  That is, it's only by being in the machine which is initiating the SSL connection, that is, a Windows machine, that would allow you to get the whole state of the pseudorandom number generator, which would then allow you to predict - turns out it's both ways.  You can predict keys that have been issued before and keys that will be issued in the future.  But you have to be in the machine that is on your end of the SSL connection anyway.  So if you're in the machine, and you're a malicious trojan, you can just get the data before it's been encrypted.



So anyway, this is a bit of a tempest in a teapot.  It is the case that Windows 2000 and apparently later versions of Windows, although these researchers who did this work did not look at XP and Vista, I wouldn't be at all surprised if Microsoft ends up revving their pseudorandom number generator to be continually mixing in new data.  It's interesting, there was a comment on the fifth page of this report from the Israeli guys, they talk about how you could simply use AES in a counter mode to generate as good a source of randomness as all the hoops these guys jump through.  Well, AES in counter mode is what Perfect Paper Passwords happens to be using because it is good enough.  I mean, it's all you need as a really good cipher.  And you just stick a counter on one end of it.  Although you would obviously need to be doing more in order to get actual entropy because Windows' applications for the randomness is different than ours is with Perfect Paper Passwords because we want the Perfect Paper Passwords to be deterministic and reproducible and so forth.



But the point is, Brian, who's worried about SSL, need not worry because SSL was not ever intended to prevent an attack on either endpoint.  It does not do that; it cannot do that.  It was intended to prevent an attack from man-in-the-middle attacks, to prevent people sniffing your traffic and being able to decrypt it.  And even this weakness in Windows' pseudorandom number generator does nothing to make it possible for someone being a man in the middle to know what that key is or the prior keys or the future keys.  The only way you can is by looking, basically getting the whole state, exactly as you said, Leo.  Once you have the state of a static pseudorandom number generator like Windows is using, then you're obviously able to algorithmically march it forward and see what it's going to be doing next, just like Windows does.



LEO:  So to summarize, this isn't anything to worry about unless somebody has access to your machine.  If they do have access to your machine, there are far many more things to worry about than this.  And it doesn't compromise SSL's ability to do what it's supposed to do, which is protect you when you're logging into your bank.



STEVE:  Right.  Exactly.  It is meant to protect anybody, that is, SSL and TLS are meant to protect you from anybody listening in on your conversation, and they still can't.



LEO:  Yeah.  Excellent, thank you.  No need to worry, Brian.  Lil in Long Island has little WiFi gizmos.  Lil says:  I've noticed more and more MP3 players and handheld videogames are now coming out with the ability to wirelessly sync to your home network.  Since they support WEP security, it's obvious they must store the network WEP key in flash memory.  Since these also connect wirelessly with other units, is it possible to sniff the information on the player and get the WEP key for my home network?  Hmm.



STEVE:  Well, I wanted to mention a couple things.  First of all, we all know from listening to these podcasts that WEP is now really broken.  We did a podcast a few months back called Even More Badly Broken WEP or WiFi.  Essentially it's so bad now that there are freely available, publicly downloadable WEP-cracking tools that can crack WEP in about a minute.  So it's almost easier to crack it than it is to enter the complex password into your own...



LEO:  Faster.



STEVE:  ...yeah, into your own machine.  But relative to Lil's specific question, I mean, it brings up a problem.  I've only seen one router that solves the problem, and that is that you may have devices, like many people have had TiVos which only support WEP, or the Wii, or the Nintendo DS may only support WEP; whereas you're running your network with good WPA encryption, which is what you really need.  There is a Buffalo Tech router which supports both at the same time, which is really a wonderful solution because it allows you to maintain the full security of WPA for, like, the links between your laptop that you use and your router.  But when friends come over, or if you have devices which don't support WPA encryption, then you're able to run them in a less secure mode, conscious of the fact that it is less secure and that that dialogue could potentially be cracked, while at the same time not requiring you to downgrade the security of your entire router to the lowest common denominator.  And I really hope we're going to be seeing more routers that will allow multiple levels of security encryption at the same time because people really need to keep their machines running, their main connections running very securely with WPA.  And it's a shame to force the whole WiFi network down to the weakest security of the device that you want to use.



LEO:  Is there a reason why these devices use WEP?  Is it maybe a little bit easier to do WEP, so some of the devices are more likely to use it, or...



STEVE:  It's just - I think it's just - it was probably in the pipeline longer or...



LEO:  They're older.



STEVE:  Exactly.  They're older devices; they haven't been updated.  Remember that WPA was deliberately designed so as to have a secure mode that was not more computationally costly than WPA.  Because WPA still uses RC2, or, I mean, RC4.  It just uses it in the right fashion...



LEO:  I see.



STEVE:  ...not in the wrong way.



LEO:  So it's no harder to implement.



STEVE:  Correct.



LEO:  Yeah, we demonstrated, I think it was that Buffalo router on the lab.  And it's very cool.  And other people just use two routers.  They have a bridged router that's doing the WEP.  I mean, you have to buy another wireless router, but that's another way to do it, of course.



STEVE:  Yes, absolutely.



LEO:  Adrian Jimenez in El Paso, Texas would love to win the lottery:  With your Perfect Paper Passwords system, you say there are 16,777,216 possible combinations of four characters for any given passcode on one of the PPP passcards.  While this sounds like a high number, let's put this in perspective, shall we?  The odds of winning the Texas State Lottery are one in 25 million.  Does this mean I have better odds of guessing one of your passcodes than winning the lottery?  Yes.  But then he goes on to say:  Couldn't you increase the number of characters to five and thereby increasing the odds to one in a billion?  I know it's a tradeoff.  But people win the lottery all the time.  Maybe I missed something, or maybe it's just the case that four characters is plenty, and I'm just disheartened by the realization I'll never be a millionaire.  This is a very common statistical fallacy.



STEVE:  Yeah.  What's happening of course with the lottery is that, even though the odds are higher, we've got a ton of people all playing at the same time.  It would be like simultaneously guessing all of the possible Perfect Paper Passwords.  So if you were able to do so, then yes, it is the case that the PPP system, from that one aspect of a multifactor authentication system, is less able to withstand a massive parallel attack than the Texas State Lottery.  Although remember that it's one factor of multiple, so you have to have the user's ID, their secret passphrase that does not change and is hopefully strong, and this one-time passcode that does change every time.  So it wasn't meant to stand alone.



However, I also like the fact that he talked about increasing it to five characters, which of course the version 3 of our PPP system does seamlessly allow people to do.  And I expect that some people may like, just feel more comfortable with longer passcodes.  However, again, the idea of a one-time password system is that it's changing every time.  So you've got some limited possible number of codes that an attacker could guess with.  They're not just guessing that.  They've also got a username and a passcode, or a passphrase, that they need to get correct also.  And it changes every time.  And after five wrong guesses it's easy for the server to lock out that IP and say, look, we don't think you're really an authorized user, go away.



LEO:  People, though, I hear this all the time, well, somebody's got to win the lottery.  Somebody's going to win it.  And that doesn't mean you're more likely to win it at all.



STEVE:  Well, yeah.  And in fact the perfect example, which is counterintuitive, is that if you toss a coin 10 times in the air, and it comes down heads, it's like, wow, I got 10 heads in a row.  The sense is that you're owed some tails, that somehow for like the world to be in balance you have to have more tails now.  But it's not the case.  It's just - it's very unlikely you're going to get 10 heads in a row. But it can happen.  But that 11th toss is still 50-50.



LEO:  Just to put this in perspective, he said the odds of winning the Texas State Lottery are one in 25 million.  The odds of getting struck by lightning are one in 576,000.  You're much more likely to get hit by lightning.  The odds of getting killed by lighting are one in 2.3 million.  You're 10 times more likely to get killed by lightning than to win the Texas State Lottery.  And in fact the odds of becoming a saint are one in 20 million, even better than your odds of winning the Texas State Lottery.  So I think you're protected pretty well.



STEVE:  Yeah, I think so.



LEO:  And you are, by the way, the odds of winning the California State Lottery are one in 13 million; so come here, you'll win.  You'll have a much better chance.  James Earl Ford in Apple Valley - is that Minnesota or Montana?  Minnesota, I think.  MN, right?  Just learned of another multifactor.  We were talking about multifactor authentication.  I just sat in on a webinar for a product named "BioPassword" that may be a candidate for one piece of the multifactor authentication process.  The company website, biopassword.com.  If you think it has some possibilities, you might want to review it on Security Now!.  I've learned so much from your show.  Keep up the great work.  Also, more than once, SpinRite has saved disks for me that I thought were toast.  Great product.  Thank you, James Earl Ford.  Here's what BioPasswords says on their site.  I've never seen this:



"BioPassword offers the only multifactor authentication software that combines a user's login credential," you know, the login and ID and password, "with the behavioral biometric of keystroke dynamics," that is, your unique typing rhythm.  I've heard this before, that everybody has a unique typing rhythm.  And they use this "to provide a low-cost accurate security solution that is specific to the user, requires no change in user behavior, monitors and authenticates credentials and is immediately deployable across the organization."  Or course, you don't have to buy a thumb scanner or an iris scanner.  You just probably run some software that watches them type.  Have you heard about this kind of stuff?  What do you think of that?



STEVE:  Well, I thought that was an interesting issue.  To me, it seems sort of flaky.  I mean, I guess if you had a large enough sample, I mean, I'm sure it's the case that if you had a large enough sample of people typing, you could differentiate people.  The good news is, with a userID and password, this is a third factor.  So you already know who the person is claiming to be.  It's sort of like we were talking about, for example, when I go to check in on our equipment at Level 3, I give them my card, my RFID card to sniff, and they measure my hand.  So my hand is confirmation that nobody else has my card, instead of being able to recognize me uniquely.  As I understand it, Stanford did a bunch of this study and apparently obtained some patents which this company purchased the licenses to from Stanford and have commercialized this.



What would really be nice would be if keyboards had essentially strain gauges in the keys, that is, so you could measure not only the timing, but the speed and force and pressure.  Because, you know, my sense is that in order for this to be really robust, you need more data than just somebody doing a hunt and peck on the keyboard.  I mean, touch-typists are going to have, I would think, much more specific characteristics than somebody who's pecking out their username and password, like using one or two fingers on a keyboard.  So, I mean, I'm [audio gap] see some real evidence that this provides enough specificity to be something that you can trust reliably.  And you do have to have something running on the client side.  That is to say, a web server running remotely is not able to get the timing of you entering things on your keyboard.  So you'd have to have some JavaScript at the least, or an ActiveX control or something, that's able to be local on the client side in order to watch you typing every single key and measure the timing of that.



LEO:  Oh, well.  Seemed like a good idea.



STEVE:  Yeah.



LEO:  I'd heard that everybody is unique in that respect.  But...



STEVE:  Yeah, I think that's probably the case.  But I just, I don't know, I'd rather have something stronger for a third token.



LEO:  And I think you're right.  If you're not hearing - you're only timing.  That isn't quite as - of course, if it narrows it down to one in a hundred, that's a pretty good third, I mean, third token doesn't have to be perfect.  Even if it narrows it down to you have one chance of a hundred being the same.  Right?



STEVE:  No.  In fact, and that was my point about saying that, for example, with Level 3 I have my passcard which says, okay, this is the one we issued to Steve.  And then it measures my hand to see if it believes it's really me.  So it's not that my hand uniquely identifies me.  My hand simply confirms.



LEO:  Confirms, confirms, right, right.



STEVE:  Yes.  And so...



LEO:  And so probably there aren't that many different hand measurements.



STEVE:  Exactly.  I'm sure other people have the same hand size that I do.  And it would be very insecure to try to use my hand to just open the door all by itself, yes.



LEO:  Michael Peksa in High Wycombe, U.K., wants some free security consulting:  Hi, Steve and Leo.  A question, if I may.  I've caught up with the entire back catalog of Security Now! over the past four months.  It's about eight days of listening.  Oh, wow.  I'm trying to think of the secure implications wherever possible.  My company is rolling out a web application to a large client.  The client wants to make access for his users as easy as possible.  I want to make it as secure as possible.  We're going to restrict access to the web server to only allow our IP range and the IP address range of the client through.  The application itself is SSL-encrypted throughout.



The client would like to remove passwords to access the app.  Since we'll all be sure that a connection comes from the premises, because they'll look at the IP addresses, how safe is this?  I've raised the issue that passwords, however imperfect, will help prevent casual, unauthorized access, say by a visitor to their HQ or by a cleaner late at night.  If someone malicious were to get access to their corporate network, that person would have access to much higher value confidential information than he'd get on our servers, so I'm not overly concerned by this.  But I have a gut feeling that I'm missing something obvious - oh, yeah - and I'm keen not to leave a back door open to the bad guys.  Any advice on this?



STEVE:  Well, I thought this was an interesting question because he's asking, essentially, he knows that this feels risky, but he's wondering if...



LEO:  Why.



STEVE:  ...basically if IP address range restriction is sufficient.



LEO:  So let me understand this.  He's saying we know our IP address.  By looking at the incoming IP address we'll know if somebody is doing this from our network.  If they are, we say go ahead.  If not, we don't let them in.



STEVE:  Well, yeah.  The idea would be they're going to be offering some sort of web-based services which they want to - for which they want restricted access.



LEO:  This is how Intranets have worked for years.



STEVE:  Yes.  And, well, but it's going to be going out across over the Internet, and it'll be SSL encrypted.  The client, who's a remote corporation, the client says, hey, we've got a block of IP addresses that are not changing.  They've been assigned by our ISP.  And we want to make access to these web services as easy as possible, meaning we don't want our users, that is, our employees, to be hassled about passwords.  So set things up so that anyone coming from our range of IPs that are static and assigned by our ISP can have access to the web systems, to these web services.



LEO:  Well, I could see one problem right off the bat.  It's very easy to spoof IP addresses.



STEVE:  Well, but remember, not for TCP connections.



LEO:  Oh, it's an SSL connection.



STEVE:  Right.  And so SSL runs over TCP.  So there is no way to spoof it.  And so I don't really think Michael has missed anything.  I think he's asking for some excuse he could use to tell this client that this is not very safe.



LEO:  Right.



STEVE:  And frankly, I mean, as long as he understands, and the client understands, that any connection coming from the client's IP range will be authenticated, then - and there are many ways for that to happen.  I mean, Michael mentions the night janitor could have access.  So that does raise one possibility, and that would be to say, okay, restrict access to working hours during the weekday.  So from 8:00 to 5:00 Monday through Friday, if the firewall has the ability to do time and date-based rule sets, then that would be one thing he could do which would lock out the night janitor because then no one after working hours would have access into the web server.  Also it's the case that any sort of proxying, any malware that got on any employees' machines, I mean, essentially it seems creepy not to have passwords.  But all you're really doing with a password is saying I'm a human who has one additional factor of authentication.  I know the password.  Maybe you don't need to identify individual people.  Maybe they've got cookies on the client machines to identify which machine it is, or the machine's IP.  But essentially there really isn't anything that he's missing, as long as everyone understands that IPs cannot be spoofed, but essentially he's statically authenticating any connections coming from that IP range and giving them unrestricted access into his server.  What he's written evidences that he understands that.  And so with the convenience comes the risk.



LEO:  So you're saying it is safe.



STEVE:  Yeah, I don't see anything wrong with it as long as they understand that it's going to be easy for anyone to access those services from within that client company.  But I don't see any other problem with it.



LEO:  See, I thought about the spoofing, but you say SSL you can't spoof, so it's safe.  They'd absolutely have to be coming from that company.



STEVE:  Yeah.  The one thing you could do also would be to require client-side certificates.  That's easy to establish.



LEO:  Then you can limit it to certain machines, too.



STEVE:  Right.  And you'd have client-side certificates, you would require client-side certificates for access to the web server.  And that would also create an audit trail so that anyone - and so that you knew who, definitively who is using those web services.  If the corporation, for example, had their IPs behind a big NAT, then you would be losing that information from clients running through NAT because their local client machine IP would be changed to a public IP when it went across the Internet to go to the web services.  But using client-side certificates would give you some additional authentication, and it would allow people, for example, maybe you don't want anybody in the shipping department to have access to this because it's nothing to do with their job.  You only want the accounting people to have access to this.  So you install those client-side certificates only on those accounting machines.  So that's one simple thing you could do to increase the security, limit the access within that block of IPs, and also obtain some accountability.



LEO:  And who doesn't like the idea of just having it run without having to enter a password.



STEVE:  Yeah.  It certainly is convenient.



LEO:  That's neat.  Okay, well, I thought it was a terrible idea, but I was wrong.  Bill, with nicely trimmed grass in Grand Rapids, Michigan - I'm sure we'll learn why we say that.  Steve does these, it's so funny - writes:  I've been an avid listener of Security Now! since Episode Numero Uno.  I listen to it while mowing my lawn - ah, see, the explanation becomes clear - which has made that tedious chore much more enjoyable.  I actually look forward to getting the lawnmower out now.  My question is regarding passwords.  I've been using a long random password from the GRC website for a year now.  GRC.com/passwords.  Of course I can't remember it, and I don't want to type it in each time, so I saved it in a simple text file in My Documents.  I worry that perhaps the bad guys might find it and guess what it's for, so when I copy and paste it into the password field, I replace a few of the characters with my normal, not-so-random password which contains letters and numbers.  Does this decrease the effectiveness of my totally random password, or have I come up with a useful idea?



STEVE:  That's a great idea, Bill.



LEO:  Makes it unique.



STEVE:  It absolutely does.  All the other debris in the super-long password, it just makes it impossible to brute force it.  But if you say, okay, an attacker could take that existing password and try to find some small changes to it that would crack it, but it's just - it's so unlikely.  He talks about how he adds his own password that contains letters and numbers.  I mean, there's just no way anyone is going to figure out what this guy has done.  So I think that's a great idea of essentially statically having a bunch of random junk to which you add your own password, so that by itself it's not useful, but together with something you know and something you have, meaning that little file, you've got multifactor authentication.



LEO:  So moving along, Andrew in Australia had an interesting question about MAC addresses:  Is there any way, he says, for a server or website to receive and block a MAC address of the hardware connected to it?  He asks this because the user group he contributes to is running onto problems with people who are consistently registering accounts using proxy servers after their regular IP address is banned.  You see this a lot in chatrooms, too.  I know that MAC addresses can be changed, although this would stop a large majority of troublemakers who are not overly computer savvy, in other words, they know how to use a proxy server but not change their MAC address.  I've tried by blacklisting known proxies, although this also seems to affect legit AOL users.  Can you please help me?



STEVE:  Well, the problem with using a MAC address is that it never leaves the local LAN.



LEO:  You can't get the information.



STEVE:  Exactly.  The idea is, MAC addresses are used to transport the IP packets from one machine to another within the local area network.  But when it crosses a router, what a router does by its nature is it takes the MAC address wrapper, actually the Ethernet wrapper because it's an Ethernet packet while it moves over the LAN.  It takes the Ethernet envelope off, leaving an IP packet.  It then decides, based on the IP address, which of the various router interfaces that packet should be sent to.  It then - the packet moves to that interface, and it gets wrapped with the Ethernet packet for its transit over the next link of the router.  So essentially, if you look at the Internet as being a whole bunch of routers that are linked together, and each of those links is a little LAN, the packet is constantly being changed.  The Ethernet wrapper gets taken off, it goes to the next interface, a new Ethernet wrapper gets put on, and that allows it to transit to the next link of the network.  So a packet essentially has as many different MAC address and Ethernet wrappers briefly encapsulating it as there are jumps from one machine or one LAN to another as it crosses the Internet.  So when the packet finally comes to you, the MAC address, that is, the source MAC address will be of your own router.  Your own NAT router will be the device which most recently sent that packet over your own LAN to you.  So unfortunately there's no way to know what the original MAC address of the actual sender was.



LEO:  Oh, well.  Is there anything he can do?



STEVE:  I can't think of anything.  I mean, if they're creating accounts, I mean, you could do things like we talked about before, for example, like client certificates, and revoke the...



LEO:  That's complicated, though.



STEVE:  Well, it's complex, and it really doesn't solve the problem because bad guys are just as capable of masquerading as a new person, and then they misbehave themselves, you revoke their certificate, and they masquerade as another new person.  In an open environment, it really is a problem.  And it's just part of the - it's the fundamental abuse of the freedom and flexibility of the Internet that unfortunately it's a mixed blessing.



LEO:  It's the bane of anybody who's ever run a chatroom or a forum or website of any kind where people log in.  You should see the amount of comment spam I get on my blog.  I mean, hundreds and hundreds of them a day.  And it's just, you know, there's nothing you can do about it.  You just have to filter it out.



Allan Blomquist in Belmont, California is absolutely right.  Allan says:  I was just listening to your discussion of true one-time use versus pseudorandom passwords in the latest Security Now!.  People love this PPP thing.



STEVE:  It's been incredibly popular, Leo.  I mean, it just captured everyone's imagination, I think.



LEO:  Yeah, it's fun.  He says:  I do have to disagree with the conclusion you came to at the end.  You said that the existence of keystroke loggers will tend to bias attacks towards replaying recently used passwords.  But this is certainly not the case for an attacker with perfect knowledge.  Unless you're relying on a form of security through obscurity, the attacker is going to know what your policy is regarding password generation and would therefore choose to cross off recently used passwords, in this case, as opposed to replaying them.  Granted, this would increase their odds of correctly guessing the next password by a negligible amount.  But it is an increase nonetheless, not a decrease as intended.  You'd have to listen to this episode to understand what he's talking about.  Seems to me that in the face of an attacker with the perfect information, not only about the user's actions, but also about the algorithms and policies on the server side, as well, you really can't beat a completely pseudorandom password.



STEVE:  And as I said at the beginning, he is absolutely right.



LEO:  Right you are, sir.



STEVE:  And the reason I put this in here is that we got a phenomenal number of virtually identical comments.  And I wanted to acknowledge everyone who said this in various ways.  They're right.  And the point I was making was we don't know who our attacker will be.  We don't know that our attacker will have perfect knowledge.  It might be that it's a dumb attacker using a keystroke logger who doesn't know any better than to simply repeat what was recently done.  In the case, for example, of making note, as Allan suggested, of the last 20 or 30 passphrases, passcodes, well, so you're subtracting those from, in the first and the second versions of the PPP system, you're subtracting 20 or 30 from 16 million.  So, yes, don't guess those 20 or 30 if you know that the system won't have local repeated passcodes.  On the flipside, an attacker could be a dumb keystroke logger, and all we were trying to do was just prevent, guard against the case that it was not an attacker who had any knowledge of the Perfect Paper Password system, but just someone who was saying, hey, I just saw this userID, this passphrase, and this other strange code typed in.  I'm going to try them again.  It's easy not to have those recently used codes present, just to give a little additional defense against an attack that we know exists.  We don't know that there's an attacker with perfect knowledge of everything we've done before that exists.  But we do know that keystroke loggers exist.  So it's like, okay...



LEO:  Much more likely.



STEVE:  Exactly.  And so I agree with everybody.  Just I want to make sure everyone gets it, that I absolutely agree that pseudorandom is the best, except that given that keystroke loggers do exist, they are relatively common, why not choose a key?  And this is what I ended up doing.  I did a bunch of research after last week's podcast.  And the new code for me has a key finder.  You're able to say, give me a good key, a good key being one that tends to have no repeats within a certain window.  And it turns out it's easy to find one that doesn't repeat any codes within a thousand.  So we get the best of both worlds.  We're still using completely random passcodes.  It is the case that we're not going to reuse any in a short period.  So, yes, somebody with perfect knowledge who knew the system would be able to reduce their possible guesses from 16,777,000 to 16,776,000.  It's like, knock yourself out.



LEO:  Fun.  John in Fort Worth, Texas, has a computer that's a little too memorable.  He says:  Apparently, banks are now required by the FFIEC regulation - that's the Federal Financial Institutions Examination Council, they regulate...



STEVE:  Wow.



LEO:  ...all this stuff.  I looked it up.



STEVE:  I was very impressed.



LEO:  I looked it up - to require multifactor authentication for online banking.  My bank has a feature when you first log in that allows it to remember your computer - I think mine does, too, it uses cookies, I believe - effectively bypassing the second factor of authentication, a challenge question, and only use the first factor, userID/password.  How does the bank remember my computer?  I thought maybe it was using cookies, but I deleted all my cookies and cleared my browser cache.  Oh, well, maybe it isn't cookies.  I then tried logging in again, and it still remembers my computer.  Surely it's not using an IP address as IP addresses can change with DNS.  Any ideas?



STEVE:  Well, my first thought as I was reading John's question was hey, you know, obviously it's just putting a cookie on your computer.



LEO:  Yeah, I thought that.  My bank does the same thing.  If I log into my bank with a computer I've not used before, not location, so if I'm on the road and I have my laptop, it still knows it's me.



STEVE:  Right.



LEO:  It's the computer.



STEVE:  Right.  Well, the answer is, if we're to assume that John's right, and deleted all of his cookies, and it still remembered his machine, there is nothing to prevent something that the client-side scripting is doing from saving local information.  That is, maybe there's an ActiveX control.  If you run an ActiveX control, all bets are off.  You're running basically a DLL provided dynamically by the remote server on your machine.  So it could be storing footprints and things in the registry, or squirreled away in some random directory on your machine.  So as soon as you're allowing scripting, again, all bets are off.  It could be doing anything it wants to to maintain some state over on the client.  Which if John's right, that's what it sounds like is going on somehow.



LEO:  So even if you delete cookies, it doesn't matter because you're not deleting that particular state-saving exercises.



STEVE:  Exactly.  It's been squirreled away somewhere else.



LEO:  But JavaScript can't do that, can it?



STEVE:  As I understand it, DHTML and AJAX allows you - and AJAX is, you know, the AJ stands for Asynchronous JavaScript.  And as I understand, there is some ability to store state over on the client side.



LEO:  Tell you what.  I'm going to download a completely different browser, which presumably doesn't share cookies with anything, and try to log into my bank.  Because my bank knows this machine.  So that would be one way to see if it's a cookie-based thing; right?



STEVE:  Yeah, um...



LEO:  No, it wouldn't be, would it, because if the script runs, and it saves it somewhere else...



STEVE:  Right.



LEO:  But if it is cookies, it wouldn't work.  But if it's some other system it will work.



STEVE:  Correct.  Although, well, it's hard to say.  I mean, there are just so many variables, Leo.  And anything could be going on over on the client side based on what code the bank is running on the user's machine.



LEO:  Wow, very interesting.



STEVE:  However, if scripting were disabled, it's difficult to see how that creates an opportunity for any local state to get saved, if it's not cookies.



LEO:  Huh.  Now I'm puzzled.  I just always assumed it was cookies.  Well, before this show is over, I'm downloading a browser I've never used before.  We'll see.  Dan Gardner in San Antonio, Texas wants to keep an eye on his network.  He says:  Is there any low-cost or free software that will let me monitor network traffic on my own network?  I specifically want to be able to track bandwidth being used by each system connected to my router.  I get this a lot on the radio show.  People want to watch their roommates and make sure they're not using more than their share, things like that.



STEVE:  Well, it takes a couple things.  First of all, the most popular and really spectacular software, which has been developed within the open source community, is now called Wireshark.



LEO:  Oh, yes.  That was Ethereal.



STEVE:  That was, exactly, that was Ethereal, which has been around for years and been maturing steadily.  It's got a ton of features.  And you are able to do things.  It's got a statistics package that allows you to sample a bunch of bandwidth and then run statistics over it to, like, get a sense for, you know, in all kinds of different ways.  And there are various byte count summation things.  So I would absolutely point Dan at Wireshark, which is the new name for  Ethereal.  And I think it's up, like, at 0.99.6 or something.  I just updated my copy actually yesterday.  And so it's almost at 1.0.  But it's just a spectacular program.



The second thing you need to do, though, is you need to recognize that any kind of a switch as opposed to a hub will insulate or isolate your computer from all the others.   So you do need to play around a little bit with your network topology in order to be able to sniff across a switch.  What that essentially means is that, as we've talked about before early, early on in Security Now! episodes, a switch provides isolation among its various spokes, essentially.  So that if there were other people or other machines plugged into a router's switch, you would be - Ethereal, now called Wireshark, would be able to see your own machine's traffic, but it would not able to see theirs.



In order to see all the traffic in the network, you would either need to plug yourself in on the WAN side of the NAT router, which gets tricky for a whole bunch of other reasons; but more easily would be to, if you had like an older standard Ethernet switch and a hub, then you'd basically, from a wiring standpoint, you would run from your regular border NAT router, you would run that through a hub to a switch, where you plug everybody else except you, and you plug your computer into the hub.  Now what's happened is essentially, because a hub does not provide this isolation, you're able to see all the traffic going between these two switches, between the NAT router's switch and the switch which has everything else plugged into it.  And then you're able to monitor all the traffic on your LAN.  And, you know, you'll find all kinds of interesting things.



LEO:  Yeah.  Cool.  And then you could run a proxy server like Squid on a Linux box if you wanted to gate people's bandwidth.  You could say only this much bandwidth can be used.  There's all sorts of tricks for doing stuff like that.  I turned off scripting, by the way.  And I still - my bank still knew who I was.



STEVE:  And did you delete cookies?



LEO:  I haven't deleted cookies yet because I don't want to do that.  So I'm going to use a different browser.



STEVE:  Right.



LEO:  Kokaly in Hamilton, Ontario - I'll have a report on that in a moment.  Kokaly in Hamilton, Ontario is feeling insecure about Gmail:  Is Google's Gmail safe?  I'm asking this because when I log onto Gmail, I log in over a secure connection.  But after logging in, no secure connection is maintained.  The lock icon is gone from my browser, and displaying the page info in Firefox shows the connection is not encrypted.  Why?  Why?  Am I missing something, or what?  Are my emails being sent in the clear text?  What about when I use a mail client?  Are my emails being sent as clear text?



STEVE:  Well, we've addressed this specifically a couple times before.  But it does come up from time to time, so I just wanted to take a minute to remind people about how this works with Gmail.  First of all, unless you see that you have maintained an SSL connection, that is, it says https:// while you're looking at your Gmail, while you're opening your notes and so forth, then yes, you are not encrypted.  You are not safe.  Your email is moving in the clear.  What Gmail does is, for example, when you initially connect to Gmail, you'll use something like http://mail.google.com or a number of the various aliases for that URL.  The point is that, if you start with a non-secure URL, Gmail will briefly  move you to a secure connection only for logging on, and will then revert you to an insecure connection.  If, however, you initially connect securely with https://mail.google.com, then you stay secure throughout your entire use of Google Mail.  So what you absolutely should do is update your bookmark, your browser tab or whatever it is you've got for going to Gmail, and just add an "S" after the http so that you would initially make a secure connection.  And then Gmail will leave you secure throughout the entire session.



LEO:  By the way, there's a great - if you're using Firefox, there's a great extension called "Customize Google" that allows you to set that to be always the case, that it's always https, so you don't even have to worry about the bookmark.  It just always uses https, which is one of the very good reasons to use it.  All right.  I deleted cookies on this new browser, and it doesn't know who I am anymore.



STEVE:  Yeah.  I really suspect it is cookies.



LEO:  Yeah.  And I've turned off scripting.  So, yeah, it doesn't know who I am, says who are you?  And now it's asking me - it says unable - yeah, it's cookies.  It's cookies.  So he probably didn't delete them all properly or whatever.  But at least on my system here it was cookies.



STEVE:  Cool.



LEO:  Well, Steve, we've completed 12 fascinating questions, 12 fascinating answers.  I don't know how you do it every time.  But thank you, it's really fascinating.  I love the Q&A sessions.



STEVE:  Well, and our listeners love it.  And again, in terms of how I do it, it's just being driven by the questions that we get.  We've got lots of smart people who are listening and asking great questions.



LEO:  That's why I do talk radio because you know you're talking about what people want to know about.  Works really well.  Steve Gibson is at GRC.com.  That's a great place to go if you want to get Security Now! podcasts in the full version, the full-quality version, or the 16KB version.  He's got transcripts, he's got show notes, he's got links to all his good stuff including the PPP page, his security passwords at GRC.com/passwords, and tons of free software including the world-famous ShieldsUP! firewall tester.  It's all at GRC.com.  And while you're there you might want to take a look at SpinRite, which is without a doubt, as many will tell you, the world's finest hard drive maintenance and recovery solution.  GRC.com.  You know what we're going to talk about next week yet, Steve?



STEVE:  We are, yes, we are finally going to talk about this relationship which is disturbing between PayPal and DoubleClick.



LEO:  Oh, you've done some research, eh?



STEVE:  As I said, it is very disturbing.  Many, many people have said, hey, whatever happened to that, did it fall through the cracks, did it fall through the cracks?  Well, no, actually the Perfect Paper Passwords thing happened, and it continued to burn up more time that I expected.  But yes, we're going to talk about what it means that you actually get a DoubleClick URL when you try to download the, well, actually from many links over on the PayPal side.  We're going to explain the consequences of that.



LEO:  I will be listening with great interest, since I use PayPal all the time.



STEVE:  I do, too.



LEO:  Yeah.  Hey, Steve, thanks so much.  We'll talk again next week.  Is it Thanksgiving next week already?



STEVE:  Yeah, next week is Thanksgiving week.



LEO:  Oh, my goodness.  Are we going to do a show on Thanksgiving?



STEVE:  Absolutely, Leo.  We're never missing one.



LEO:  So after the turkey, make sure you tune in Security Now! Thanksgiving Edition.  Thanks to everybody.  We give you our thanks for listening and for all the donations which keep this show afloat and the support you've given us.  We greatly appreciate all the participation.  I'm Leo Laporte with Steve Gibson.  Thanks for joining us.  We'll see you next time, Steve, on Security Now!.





Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#119

DATE:		November 22, 2007

TITLE:		PayPal and DoubleClick

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-119.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  Steve and Leo dissect the "Links" on PayPal's site with an eye toward reverse engineering the reason for many of them routing PayPal's users through servers owned by DoubleClick.  They carefully explain the nature of the significant privacy concerns raised by this practice.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 119 for Thursday, November 22, 2007:  Third-Party Cookies.



This is Security Now!, ladies and gentlemen, the show where we answer your questions.



STEVE GIBSON:  But not this week.



LEO:  Not this week, no, no.  You didn't know what the question was.  Help, help, I'm in security denial, I'm in security limbo.  Steve Gibson is here from GRC.com, the security wizard.  And we've been having fun talking about all sorts of different topics.  Are we going to talk about DoubleClick and PayPal today?  Is this the day?



STEVE:  Yes, yes, yes.  And I'd have to say, Leo, this is probably the most requested topic.  We've never really had a most-requested topic.  But when I was scanning through all the email for last week's Q&A #28 for last week's show #118, many people were saying, hey, you never followed through on that.  You didn't, you know, whatever happened with that?  You said you were going to talk about it, blah blah blah. Well, of course what happened was the Perfect Paper Passwords exploded into something much bigger than I expected, and so we gave it a number of weeks.  And that pushed our coverage of this interesting PayPal/DoubleClick relationship into the future, to today.



LEO:  Well, I know that you stirred up a hornet's nest when you mentioned this, so we'll find out what it's all about.  Before we get to that, do you have any errenda or - errenda - addenda or errata?



STEVE:  I don't, but I got one really nice email regarding SpinRite that I wanted to share with our listeners because it's from a guy who, as you'll hear in listening to this mail, has a good grip on PCs and a sense that he knows how to fix things.  Anyway, he wrote on November 19.  I got his note forwarded to me through my tech support guy.  His name is Frank Barker, and he says, "I had a situation where a Windows XP PC would no longer boot.  This PC contained more than 50 gigabytes of pictures, videos, and other very important data which, of course, was not backed up.  Not a good situation.  I tried various commonly used techniques to correct the booting problem but was unsuccessful.  Normally I would simply add the problem drive as the second drive in another good PC and copy the data from it.  In this case, Windows on the second PC would not even recognize a valid partition on the problem drive.  Each time I attempted to access it, Windows asked if I would like to format the drive.  Obviously an unwelcome question.  After nine-plus hours of wracking my brain, attempting various methods and a few utilities, I was able to recover only a few meg of data.  Basically nothing."



LEO:  Oh, boy.



STEVE:  So he says, "Mentally exhausted and borderline desperate, I decided to spend the money and download SpinRite."  Clearly his last resort is how he was thinking of it.



LEO:  Well, and I hope he hadn't screwed up the drive with all the other recovery attempts.



STEVE:  Yeah, it sounds like probably it was just him trying to read from it, you know.  But you're right, it's a little risky when you start doing other utility things.  So he says, "I decided to spend the money and download SpinRite.  Although I was skeptical of any success, I kicked off SpinRite at Level 2.  SpinRite ran for nearly two hours and found a few defects on the hard drive, some recoverable, some not.  Nothing SpinRite displayed particularly led me to believe I had gained much, if anything.  Nonetheless, I again added the problem drive as a second drive in an existing system.  I again attempted to open the drive through Windows Explorer, except this time I was shocked and amazed to see the folders and files in the root folder of the drive.  Still skeptical, I drilled down into the folder structure to where the data was.  To my surprise, the navigation continued, step by step, to work.  And I was able to copy all of the data from the problem drive.  I can't begin to describe my relief.  After so many hours of struggling, loss of nearly all hope, and then full access to the drive and all the files it contained, I was stunned.  Thanks for developing and providing a product that delivers on the claims."



LEO:  That's great.  Wow.



STEVE:  So I was really, I mean, this guy was about as hard to convince as anyone could ever be.  He tried everything else he could think of.  And he said, oh, okay, fine, [indiscernible].



LEO:  I give up.



STEVE:  I don't think it's going to work, but I'm going to try it anyway.



LEO:  So it sounds like probably there was a flaky sector in his file allocation table maybe, or his partition table?



STEVE:  Yeah, it would have had to have been a serious problem because Windows was unable looking at the drive to see that...



LEO:  Didn't even think it was formatted.



STEVE:  ...there was even a - exactly, that there was a valid file system.  And so it said, hey, you know, here's an empty drive, do you want to format it?  And he said, uh, no, it's not what I had in mind, actually.



LEO:  But, you know, all it takes is a bad sector in the partition table that Windows can't read, and sure it would have that reaction.



STEVE:  Yeah, the NTFS file system is supposed to have redundancy and other ways of getting around things.  What bugs me, and I understand this because obviously he didn't believe that this utility, that SpinRite was going to provide any value.  So he's also someone who certainly wasn't running SpinRite on this machine prior to it getting into this shape.  And one of the things that we've seen through all these testimonials that I've shared with our listeners over the last couple years, is people are always waiting until it's almost too late, and then SpinRite brings them back from the precipice.



LEO:  Same thing with backup.  People don't do any of this stuff until it's often too late.  So how often would you run - I mean, I confess, Steve, I have SpinRite, I don't run it all the time.  How often should I be running SpinRite?



STEVE:  Well, see, then again, that's human nature.  The good news is there's enough plasticity in drives that SpinRite is able normally to bring something back from the precipice.  And I think that's pretty much what we all rely on now is, oh, well, if something's going to happen, SpinRite will fix me.  It's like, okay, well, let's hope so.



LEO:  I back up like crazy, too.  I mean, that's the main thing.



STEVE:  Actually, you really do.  And from my own standpoint I'm Mr. RAID.  I mean, nothing anywhere is critical that I don't have, essentially, redundancy thanks to RAID.  So...



LEO:  I have RAID 5 backup.  So I don't have RAID 5 online, but it's offline.  The backups all go to RAID 5 drives. 



STEVE:  Right.



LEO:  But our web - actually I take it back because our web servers, I mean, I have two dedicated servers.  Those are both running RAID 5 with Raptors for speed and redundancy.  And I back up.  I still back up like crazy.



All right.  So we're going to get to this issue, this fascinating issue of why PayPal gets its files from DoubleClick.  And I can't wait to hear what you've found out.  All right.  So this all started - was it an email that you got, or how did you find out about this?



STEVE:  Well, okay.  It was really interesting.  This was one of our questions from a while ago, at least a month or two ago.  One of our listeners was using PayPal, and I think he was going to the virtual debit card is the link he was using.  And he couldn't get there.  The PayPal website to him seemed to be broken because he was clicking on the link and nothing happened.  And through some analysis of his own, he determined that his hosts file which he had in his machine set up to block access to a number of sites he did not want his machine to visit under any circumstances, the hosts file had an entry for DoubleClick.net.  And that entry was preventing PayPal, the PayPal website from functioning.



And so he wrote to us and said hey, you know, what's this about?  And it immediately raised a red flag for me.  I don't think I had noticed before, looking carefully at the URLs as I hovered my mouse around the various links on PayPal, what the URLs were aimed at.  But what was immediately apparent is that there is a relationship between PayPal and DoubleClick that goes beyond the typical advertising model relationship.  And so we're going to pull back and look at the way this normal advertising relationship works, sort of do a little quick refresher in the way browser URLs and headers work relative to cookies and tracking and so forth, and then expressly look at what it means that PayPal's links do not go to PayPal, many of them actually go to DoubleClick.  And so it demonstrates, while we're not able to say definitively this is the data that is being shared, by taking a look at what's going on there's a lot that can be inferred.  And there is only really one good reason that this is being done.



So stepping back from this a bit, the way - all Internet users are certainly familiar with this wacky http://www.domainname.com and the way that operates.  There's a lot that goes on behind the scenes that we've talked about in prior episodes of Security Now!.  I'm going to sort of pull specific aspects of those that are relevant to this particular issue and sort of refresh our listeners' awareness of what's happening.



First of all, when you send a URL to your browser, you give your browser a URL, it looks up the IP address of the domain in the domain portion of the URL and establishes a connection to the remote server at that location.  So www.paypal.com, for example, that is translated by DNS into an IP.  And probably in the case of PayPal, like the large websites, they'll actually have a large pool of IPs which the DNS server rotates among so that the load is automatically spread among all of the machines that are set up to receive incoming traffic.  So www.paypal.com, probably every time you look it up you may get a different IP.  That's often the case.  Or it might be a single IP and then there's some sort of a load-balancing system on PayPal's end that is then distributing incoming queries all to a single IP to, again, a large - a farm of individual machines.  But so one way or another, your browser gets a connection to a machine at, for example in this case, PayPal.



Now, several things happen.  If you had visited PayPal before, that is, if your browser had visited PayPal itself and received a page in the past from PayPal, there are headers that are not part of the page.  That is, it's sort of like it's preamble information that has sort of metadata about the page, things typically like how long this page should be considered valid before it should be considered expired by the browser.  That allows your browser to keep the page.  For example, if you went to a different page and then you hit your back button, the browser would see that it has that page recently received.  And if it's recent enough, if it's allowed to be presented to you as non-expired, then the browser is able to save time by simply presenting that page from its local cache rather than having to go and fetch it and all of its contents again.  So there are some nice optimization capabilities built into the whole web system.



So there's a bunch of these, this metadata.  For example, there is a tag that indicates what flavor and version of HTML you're using.  In case there is evolution in HTML, it would help the browser to interpret the rest of the data.  So this is stuff that you don't see, but it's at the beginning of the response for any sort of a web asset, whether it's a page, an image, other types of media and so forth.  There's always these browser headers.



Well, one of the headers in there was designed originally by the Netscape folks to allow a stateful relationship with the server, meaning that because each page query comes in with a connection to a server and sort of stands alone, it's difficult to associate a person on a website who's moving from page to page with themselves.  That is, oh, look, this person is somebody who asked for that page, now they've asked for this page.  Because, you know, there's a world of people all clicking on links, and they all look like they're separate.  There's really no way to maintain a relationship with someone as they move around a website.



So Netscape invented this notion of a cookie, the idea being that it's just some sort of a blob, it's considered an opaque token, meaning that it doesn't necessarily have any real meaning except to the server that issues it.  So one of the items in this metadata that comes in, never seen by users when you're normally looking at a web page, one of them is this thing called a cookie, where the server offers it back to the browser, and the browser in normal configuration will save that cookie as, essentially, sort of as a local ID for itself.  And then any subsequent queries that are made by the browser to the same domain, that is, even if it goes to a different IP or to a different machine, the browser only concerns itself with, for example in this case, www.paypal.com.



And so the cookie is stored locally in the user's machine, in their browser memory, tagged with www.paypal.com.  So that if, again, any query is made to that domain name, www.paypal.com, the browser is always looking through this library of cookies to see whether it's got one that it had previously received from a prior query to PayPal, if it has one.  If so, and if it's not otherwise configured not to do so, that is, in all browsers' default configuration they offer that cookie back.  In other words, we see that we're asking for http://www.paypal.com.



But queries, that is, queries out to servers also have metadata as part of what's called the "query header."  And there are things in there, for example, in the old days browsers used to say, oh, my screen is 1024x768.  The idea was that, oh, that might help the server to give you back a page that would fit your screen better.  So there are things that your browser is also sharing that we don't see going out.  Again, it's part of query metadata on the way out.  We see the URL.  There's actually more stuff that is being sent by the browser.  And one of those things is this cookie.  If it matches the domain name, and if the browser is in its default configuration, it'll say, oh, look, once upon a time you gave me, you server, PayPal.com, gave me this token.  And I don't know what it is or what it means, and I don't have to.  But the deal is I'll give it back to you.  And so what this allows is it essentially - this is one of the core enablers for a much richer experience on the World Wide Web.  We are able to, quote, "log-on" to a remote service, whether it's PayPal or Yahoo! or MSN or Gmail or whatever.



And once we authenticate ourselves, we receive a credential, in the form of a cookie typically.  And the browser keeps offering it back every time it asks for other things from that same site.  And that allows our log-in to be stateful, that is, it allows us to move from page to page and be remembered as we're sitting at this computer, we logged in X number of minutes ago.  And so as long as I'm active here, keep me logged in.  If 30 minutes transpires and nothing has happened, then the remote server is able to say, okay, we're going to expire his log-in.  And so if you then come back to your computer and try to use the site again, even if you left it up on your browser, many people have had the experience of the thing saying, sorry, your log-in has expired, please reauthenticate.



So all these mechanisms are enabled by this notion of some sort of state being saved.  So this was all sort of cool and good.  Then unfortunately some clever people back in the - I was going to say the dim past of the Internet, but it's only been a decade - someone figured out that there was another way cookies could be used, which was never intended by the Netscape folks, but neither was it explicitly prevented.  And so browsers did this.  The idea was that, as advertising began to surface, sites would not be presenting their own ads.  They would go to a third-party service, and that third-party service would populate the page with ads.  So, for example - GRC's a bad example since I don't have any.  But, you know, many sites get some revenue because they're willing to host advertisements on their pages.



LEO:  Well, we've got a banner ad on TWiT.



STEVE:  Yeah, exactly.  And presumably...



LEO:  And that usually doesn't come from, in this case does not come from our server, it comes from Podtrac's advertising server.



STEVE:  Okay, exactly.  So, for example, in that case, when someone brings up the TWiT.tv page, the HTML for the page comes to their browser.  And part of the HTML contains a URL to Podtrac, meaning it says in this area of the page go to the Podtrac advertising server to get the image to put here.



LEO:  It's actually - it's interesting.  And in our case it's a little bit of JavaScript.  And there's a good reason for that because the number of impressions are counted, and that's how we get paid.



STEVE:  Well, and that was the cleverness about this model is that the advertisers, and of course DoubleClick.net, DoubleClick Corporation, was an early one in this game.  The idea was that a popular site would have many people looking at its pages.  And so every time one of those pages was displayed, the user's browser would go get content for the ad, not from the site they were visiting.  That is, not from PayPal, not from TWiT, but from a different location that was referenced by the page that was being displayed.  And the beauty is, the idea being that the more popular the site, the more page impressions people were seeing, the more ads would get pulled from this third-party server.  And third-party is the key because what we've been talking about here so far with a user and their browser is considered a first-party relationship, meaning this is the site I've gone to.  I've gone to PayPal.com.  That's where I am  But PayPal, the page that comes up has a reference to a third-party that is not the one, you know, is not PayPal, it's some other server.  And so my browser, the user's local browser, goes and fetches the content under direction from the first-party page.  It goes and fetches the content from this third party.



Well, the hook here is that that fetch, that query and response is also cookie-enabled by default.  Meaning not only can PayPal track us as we move around PayPal's site, but DoubleClick, someone with whom we have no relationship, we have not gone to DoubleClick's server, we may not particularly have any interest in anything DoubleClick has to offer us.  But our browser has now a DoubleClick cookie which it is carrying.  If our first contact with DoubleClick did not offer a cookie, DoubleClick's server sends one back.  Which, again, every browser currently set up defaults to allowing this behavior.  It will carry DoubleClick's cookie.



So whereas PayPal uses the first-party cookie to track us as we move around PayPal's site, if many different sites on the Internet all have contracts with DoubleClick, then their pages are all referencing DoubleClick.  And because of the so-called third-party cookies, that is, cookies that are offered by not a site we're visiting, but by a site whose content is coming to the pages of the sites we're visiting, those third parties are able to track us across the entire Internet.  And so it's not just a single website because a company like DoubleClick may have and does have contracts with a huge number of companies and websites worldwide across the entire 'Net.  Our browser will continue this association with a company like DoubleClick.net through its cookie and through all the ads that we receive from these sites.  Now...



LEO:  I have to say, I mean, this is how it works, and this is normal.  Ours, actually it was Podtrac, they go through AdvertPRO, which is a business that does this, just like DoubleClick, I guess.  And that's the way it has to happen; right?



STEVE:  Well, okay.  So a little more about what goes on.  There's another one of these metadata items which is called the "referrer field."  Remember, we talked about like there's an expires field, or an expires header, that tells the web browser how long it's able to keep the page, what the conditions of caching the page locally are.  And there of course are the cookie fields.  One of the things that goes out with a query, that is, from the browser to a remote server, is when a page comes in it contains, as we were saying, pointers, URLs, to other assets - images, pictures, media, other chunks of text, various things, which it then makes secondary requests in order to get all of the images to make the page complete.  Those requests are made to the URLs specified by that page.



But part of that request contains a referrer field, meaning it contains the URL of the page which contains the pointer to this asset.  Meaning that it sort of knits all this together so that somebody receiving the queries that result from the display of a page also obtain as part of that query the URL of the page that made that request.  And that's where this tracking comes in because that means that, for example, from the vantage point of DoubleClick, they are receiving queries for ads from all over the 'Net.  They are also receiving cookies with those queries in their default condition, their default configuration.  And they are receiving referrer data, meaning they also know where all of these users are going.



Now, so far this is a completely anonymous relationship.  That is to say that there has at this point been no explicit identification leakage.  So DoubleClick knows that an anonymous person, an anonymous browser received a cookie on a certain date for the first time.  And no doubt DoubleClick's got mega databases.  Hard disk drives are not expensive anymore.  So DoubleClick knows that an anonymous machine received its first DoubleClick cookie on a certain date.  DoubleClick then knows everywhere that machine has gone subsequently on the Internet for sites which host DoubleClick ads because every time that machine brings up a page that contains a DoubleClick ad, again with all things in their default settings, that page makes a query from DoubleClick returning the same cookie that it received.  And DoubleClick is able to evolve these cookies over time and track their changes.



So it's basically this third party has locked onto this anonymous browser and is able to compile and does compile, we know that this is what these companies are doing because they brag about it.  They say that they're able to profile users anonymously and build up some idea of who they are, ostensibly for the purpose of presenting them with more relevant ads.  I mean, when I first heard, it's like, okay, well, I'm not sure I like the idea of anything tracking me.  But if the ads are more about things that would interest me, they would be less annoying, presumably, on pages.  And I've seen this concept work.  TiVo, for example, has this notion of automatically recording shows that are similar to the things you've explicitly said or you've given "Thumbs Up" to in the past.  I often stumble on something when I'm at Amazon because Amazon has this notion of, oh, look, people who purchased the book you just purchased also purchased these books.  Maybe this would be of interest to you, too.  So there are ways of networking and aggregating and making this sort of relationship work.



LEO:  Yeah, but there's a big difference there.  You have a relationship with Amazon and TiVo, and they're the ones doing that.



STEVE:  Exactly.  Well, and the other thing is, there are ways that we know information, that is, anonymous information can leak into a third party.  The classic way is when we used to fill out forms.  And this has largely been deprecated now, so that this is not happening to the degree it used to.  But it used to be, when you would fill out a form you'd put your name, address - back in the good old days before everything became really problematic on the Internet - your name and address, your telephone number, your email address, whatever.  And you would press "Submit" because you were submitting it to a site you were visiting.



Well, many people, certainly the veterans among us, will remember that information used to be in the URL.  It would be - you would see http://www.paypal.com or whatever site dot com, and then a page or two, and then a question mark.  The question mark was this delimiter that said, okay, stop the URL now.  Everything after the question mark are parameters.  That is, this was the means for data going in the other direction.  Remember that when HTTP was originally designed and the web was conceived, we were going to be clients, they were going to be servers, and it was a one-way relationship.  We would click on links, and we'd see these static pages.  There was no notion of us sending information back to servers.  That came later.  Of course it's critical for everything we do now on the World Wide Web.  But the notion was this whole web was going to be read-only.  We would just be getting these pages and happily browsing around this huge Internet.



So the question, the dilemma, was how do we get something back?  How do we send something back to a server?  Well, what we were always sending to the server was the URL of the next page we want to bring up.  So the smart HTTP folks said, hey, we can add data at the end of the URL.  We'll put a question mark there to say, okay, this is the end of the actual page specification.  Anything afterwards is parameters, it's data.  And so it was a clever way of sending data back to a server.  The huge problem was that that URL is the referrer, meaning that, if I've submitted a form at a site where the page that came up next, that is, I fill in the form, I push "Submit."  The page that comes up next has an ad from, for example, DoubleClick.net.  Well, my web browser, with the best of intentions, knows it needs to go get the contents of this image from something called DoubleClick.net.  And, oh, what do you know, it's already got a cookie for DoubleClick.net.  So it sends the cookie.  And as part of the HTTP specification, it fills in the referrer field with the URL of the page.



The problem is, the URL of the page contains the data that I submitted in the form - my name, my address, my phone number, my email address, whatever it is I submitted was tacked onto the end of the URL.  And that's part of the referrer field.  And it was well known years ago that these third-party aggregators were anxious to know as much about us as they could.  And there are confirmed instances where people would go to web pages, fill out, I mean, passively - sorry - passively look at web pages, fill out no information at all, and then receive a telephone call from a telemarketing firm that knew who they were, had their phone number, and knew what page they were browsing.



LEO:  This happened to a friend of yours.



STEVE:  It actually did.  It happened to a Canadian reporter who was freaked out by this.  He went to the New York Philharmonic website just to see what the calendar, what the schedule of upcoming concerts was because he was going to be coming down from Toronto to New York for a trip.  And he browsed around, saw what was going on, turned off the computer, went out into the back yard and was doing some gardening.  The phone rang, and this was the Philharmonic marketing company that said, hey, we understand that you're interested in the symphony.  We wanted to make sure you knew of a special offer.  Well, he was stunned that pushing no buttons, filling out no forms, somebody knew something about him that was clearly, he felt, a breach of his privacy.



So, okay.  So that's the whole scenario of how tracking works among websites, how data can leak back.  Now, that was such a problem that a different way of sending data was created.  And that is, there's a way of sending data that is not in the URL, using what's called a "post" as opposed to a "get" request.  So it's a different way of sending the data that does not pollute the URL with the contents being sent back.  And that does blind third parties from being able to access data through this URL leakage.  Of course the other thing that's happened is that savvy people who are made uncomfortable by this whole notion of third-party cookies have started disabling third-party cookie tracking.  All web browsers - I know that Safari does, I know that IE does...



LEO:  Firefox doesn't.



STEVE:  It's weird.  You have to go through some real hoops in order to disable third-party cookies in the most recent version of Firefox.  1.5 had it in the UI.



LEO:  The rationale the Firefox folks gave was that it never worked, and so they didn't want to expose it in the preferences because it doesn't work.  Doesn't do anything.  I don't know if it doesn't work because Firefox can't do it or because - I think my impression was they believe that it's impossible to block third-party cookies through the browser for some reason.



STEVE:  That's not true.  What they were saying was it's an imperfect solution.  I don't understand why they did this.  It's the dumbest thing I can imagine.  I mean, essentially they had to have been saying it is impossible to prevent all kinds of third-party leakage; therefore we're not going to do any.  Which is completely contrary to everything we know about security.  We know, all of us know who've been listening to this podcast, that security is not black and white, that you use multiple layers, you do as many of the best things as you are able to, recognizing that none of them is perfect.  But, you know, raising your defenses as high as you can is a good thing to do.  So, yeah, I mean, so there is a way to block third-party cookies.



So we ought to - basically the idea is that all browsers that are currently configured will offer back a cookie to a site other than the one you are logged onto, that is, that your browser's query has gone to.  So, for example, in this picture I've been painting with PayPal, by default, if PayPal were to display a DoubleClick image, then my browser would give back a DoubleClick cookie to DoubleClick if it had one which it had picked up from any prior contact with DoubleClick.net in the past.  It is possible to go in and disable that explicitly.  You're able to say, in IE and in Safari and in Opera, and there is a way under the new Firefox, although you have to edit some funky data, there is a way...



LEO:  Use the about:config setting in the Firefox.



STEVE:  That's exactly right.  And so what that does is that tells your browser that you're somebody who is privacy conscious.  You do not approve of the idea that a site you're not visiting could have a cookie transaction with your browser.  Okay.  So...



LEO:  I still am a little angry at Firefox.  If they say it doesn't work or it's an imperfect solution, but they still don't offer it, that's odd.



STEVE:  I completely agree.  And I think there are probably other means of circumventing this.  For example, you could probably use scripting in order to maintain some sort of stateful relationship.  So the problem is, we've got a very powerful and ever more powerful protocol with the whole web browser experience.  And the notion is, if somebody wants to do this, they're going to find a way.  Well, that brings us to the whole point of this podcast, which is that PayPal has found a way to explicitly force a cookie relationship between us and DoubleClick, and there is - except for breaking PayPal or being very diligent about cookie management, it is incredibly difficult to block.



LEO:  But I don't want a cookie relationship with DoubleClick.



STEVE:  With DoubleClick.  I think, well, so here's the real concern.  First of all, if you - and I did this this morning.  I started off clear with my browser, fired it up.  I logged onto PayPal.  That is, I went to www.paypal.com.  I hadn't even at that point identified myself.  And I got this big, this happy screen that said, "Ready, set, shop.  PayPal Plus."  This was offering me the PayPal Plus credit card.



LEO:  Yeah, which I always say no to.



STEVE:  Well, there was a big happy orange button there that said "Apply Now."  I hover the mouse over that and look down at the status line of the browser, using Firefox.  And I see https://ad.doubleclick.net/clk: and then a big number, 118531265, then another semicolon.  Sorry, the first one was a semicolon.  Second semicolon and then 11466062, another semicolon, and then a bunch of other mumbo jumbo, then a question mark followed by https://www.paypal.com/us/cgi-bin blah blah blah.  Essentially, the button that you press saying I want to apply for a PayPal Plus credit card is actually a DoubleClick URL.  The URL you want, that you actually want to get to, that is, the PayPal URL, if you wanted to apply for this card, that's been added to the end, just like we were saying before, as data to that DoubleClick.net URL.  The problem with this is that this then creates a first-party relationship between your browser and DoubleClick.



LEO:  Well, you've gone to the DoubleClick site.



STEVE:  Yes.  You are explicitly saying I want to go to DoubleClick.  So whereas...



LEO:  You don't know you're saying that.  That's the problem we have with this.



STEVE:  Well, yeah.  I mean, you have to be a sophisticated user.  You have to hover your mouse.  You have to look down at the status line.  You have to know what all that mumbo jumbo gobbledygook means.  And so essentially - so you are clicking a DoubleClick URL.  So that if you have - you're a person who has expressed their desire not to be tracked, not to have third-party relationships, you've disabled that in your browser, this specifically circumvents that.  Now, the other worrying thing is these numbers which have been tacked on here.  I watched them, and it's very clear to me they identify me.



LEO:  Oh, boy.



STEVE:  That is, this is...



LEO:  Is it always the same when you do it?



STEVE:  Yes.



LEO:  Ugh.  Oh, that's awful.



STEVE:  So what this is saying is, that is, I brought up a custom page at PayPal.  PayPal has on-the-fly designed these links so that there is information about me that is in the URL going to DoubleClick.



LEO:  PayPal knows who you are, obviously.  I think they know a lot about you.



STEVE:  Yes.  They've got my bank account number.  They've got my credit card number.  They've got, you know, I've got little SecurID tokens, I mean, you know, the VIP PIP tokens.  I mean, I've got an extensive relationship with PayPal which is apparently now being shared deliberately with DoubleClick.  And so there's one thing to know here.  First of all, you could argue, you could forgive a website that wanted to get revenue from having a DoubleClick.net ad on their page.  Yu could forgive them the fact that DoubleClick is using third-party cookies to track people who go to their site.  It's sort of like, okay, well, cookies weren't meant to allow that, but they do.  But all browsers one way or another have a way of turning that off for security and privacy-minded people who don't want that kind of relationship.  This circumvents that.  This creates a first-party query to DoubleClick with the actual URL you want to go to on the end.  So what DoubleClick does is after they capture your identity and the cookie, which your server will be sending back, which cannot be blocked through any third-party mechanism, then they send you to the PayPal page.



LEO:  Oh, so you go back to the PayPal page.



STEVE:  Yes, because remember, the end of the...



LEO:  You're still getting it from PayPal.



STEVE:  Well, you go to DoubleClick.  And after that question...



LEO:  It says hi, I know you, I have a relationship with you.  And now let's go back to PayPal.



STEVE:  Yes.  And now we're going to return you to your regularly scheduled page.  And so the URL tail is the PayPal URL that that button should have pointed to, but you were taken through DoubleClick in the process.  And it looks to me like this is a static PayPal account ID given to DoubleClick, identifying me.  Now, you know, it doesn't have my name.  However, we don't know what sort of a relationship, we don't know how deep this relationship goes.  It could very well be that DoubleClick has backend access to PayPal's database or vice versa, and there's some sort of information sharing going on.



LEO:  Well, now, here's the question, is when do you get this?  I mean, I guess if you're clicking on what is clearly an ad for a PayPal MasterCard, maybe that makes sense.



STEVE:  Ah, and I'm glad you asked the question.  Because I then logged in to my PayPal account.  And most of the links on the left-hand side of the page were similarly embellished.



LEO:  Even non-paid links.



STEVE:  Yes.  For example, at the top was "Enhance Your Account."  And so here again I was being offered the PayPal Plus credit card.  Then there was an ad with - and this was - I got a kick out of this.  Unfortunately it was for the PayPal Security Key.  So that also runs through DoubleClick.net.  But worse, the very last link in the column was PayPal's policy updates dated August 30, 2007.  The link I click on for PayPal's policy updates...



LEO:  Oh, yeah, ad.doubleclick.net.



STEVE:  Yes.



LEO:  I'm looking at it right now.



STEVE:  So absolutely non-advertising related.  I mean, even privacy policy issues, you bend over and you are routed through DoubleClick in order to get to the page you actually want to with some sort of account ID information.  Again, this is opaque.  We don't know what it means.  But here is my point.  There is only one reason to do this.  I mean, there's no reason that these links should be taking me out of PayPal to a known advertising aggregating service with opaque data added to it and then making it all transparent so that all I see is my browser landing back at the PayPal page that I was clicking.



LEO:  You could easily get around this by by-hand copying and pasting the URL and then just taking the end of it.  And I'm sure somebody could write, and probably will now that you've brought this up, write a Greasemonkey script of some other extension from Firefox that would strip off these DoubleClick links and go right to the redirect.  I can understand if it's an ad.  But when you, I mean, look.  If it's a legitimate thing, I want to read the policy updates, this has nothing to do with an ad, it's routing me through DoubleClick for no reason.



STEVE:  I don't want to be tracked while I look at PayPal's policy updates.  Unless it says, oh, and by the way, we reserve the right to share your account information with anyone we choose.



LEO:  Well, it must say that somewhere.



STEVE:  It probably does in the fine print.



LEO:  Trusted third parties.



STEVE:  Oh, exactly.  Approved and screened, trusted third parties.



LEO:  Yeah, we trust them.  Now, I'm looking at all the links on here.  And it is true that almost all the other links are just PayPal direct links.



STEVE:  Correct.  They do keep you within the site.



LEO:  It's the ad links.  But the one that's troubling is this policy updates.  Everything else, I mean, yeah, if you want to get recommended steps for merchants, that's an ad.  Exchange...



STEVE:  Well, okay, how about - I love this one, too.  "Free alerts help protect you from ID theft."



LEO:  Well, yeah, that shouldn't be an ad.  Oh, but it is an ad.



STEVE:  And that takes you through DoubleClick.



LEO:  Right.



STEVE:  Yeah, protect yourself from ID theft by going to DoubleClick.



LEO:  Well, now, we haven't contacted PayPal to get a response from them.  I mean, we don't need a response.  It's obvious what they're doing.



STEVE:  Well, and I'll tell you, Leo, I mean, I am, after everything is said and done, and I've just here been ranting for three quarters of an hour about the technology that's used, I use PayPal.  I don't know of any company that is more ripe for competition than PayPal.  I mean, I love the idea that I am aggregating my web purchases through them.  PayPal is number one in this segment.  Of course, you know, Google...



LEO:  Well, here's the irony of this.  I mean, Google has a merchant's card, merchant service, PayPal kind of service.



STEVE:  Here it comes.  And...



LEO:  But Google owns DoubleClick.  So Google doesn't need to route it through DoubleClick.  So, you know, this could be happening with everything you do.  In fact, it is, in effect, because I don't know what Google shares with their subsidiary, DoubleClick.  But presumably they share everything with them.



STEVE:  Whatever they want to, certainly.  So you could argue that the fact that this is - at least it's transparent on the PayPal site.  And as you said, it would be possible to write some sort of a page-scraping system that would remove these DoubleClick references and replace them with the actual PayPal URL.



LEO:  It's to do, actually.  Yeah, you just strip off everything up to the question mark.



STEVE:  Yeah.  The only thing, I mean, okay.  So I wanted to just get on the record that I use PayPal.  I'm happy that I've got, I mean, I'm not a...



LEO:  We use PayPal.  We actually are actively encouraging people to use PayPal to donate to the podcasts.  It drives me - this drives me crazy.



[Talking simultaneously]



LEO:  ...clearly an unsafe situation.



STEVE:  Well, unsavory, at least.



LEO:  Unsavory.



STEVE:  Yeah.  I mean, so we need more competition in this space.  We need - there's clearly a need.  I mean, we've talked about PayPal before.  I mean, I'm happy that we've got the really cool VeriSign dongle.  I use it.  I love it.  I now have associated it also with my credit card form factor that's in my wallet.  So I'm no longer in a situation that I used to be of my little football being at home, but I'm at Starbucks with my laptop, and I want to buy something, now I can do that.  And I love the idea that while I'm - unfortunately, I need to trust PayPal.  Hard as it is, I would rather they kept all my credit card information when I'm going to random, small, one-off websites I'm never going to go to again.  I do not want to create an account.  I do not want to share my credit card information with them.  And so I swallow, and I use PayPal because it's better than doing that.



But, you know, again, this all feels like early stages of the development of the future of eCommerce.  And at the moment PayPal is the organization that we are pretty much forced to deal with because that's the option we get when we go to a site is, oh, would you like to buy with PayPal.  Yes, much more than giving you my credit card information.  Horrible as PayPal is in these - as much as this raises a concern.  The problem is, why do these links go through DoubleClick?  Why is there...



LEO:  What possible reason could there be?



STEVE:  Yes.  Exactly.



LEO:  Except to know what we're doing and what we buy and - because once we've established - now, here's the question.  Once we've established a relationship like this with PayPal - I mean with DoubleClick - they're not - they can't track us within PayPal as we buy things, for instance.



STEVE:  Well, we don't know, as I said, we don't know the nature of their behind-the-scenes database connection.  I mean, who knows what sort of money they're raising from each other by what kind of information they've decided they're going to share.  I mean, it could be anything.  PayPal has a complete chronology of everything I have purchased because, again, this is the danger of a third-party aggregator, and PayPal is one.  You know, it's like, oh, click the history button, here's all your account activity.  So they know what I'm - how much I'm paying for what, and where I'm buying my stuff from.  PayPal knows that.  So here we've got this...



LEO:  Just to look at PayPal's privacy statement, they essentially say at the beginning of the privacy statement that they collect everything.  Of course they do.  Including credit card information, home addresses and stuff.  So they  know everything.  We may share your personal information with members of our corporate family, which include eBay, Shopping.com, and Skype; service providers under contract who help us with parts of our business operation...



STEVE:  Gee, I would say that having a URL on the first page of PayPal, I guess that qualifies it as being helped.



LEO:  They do say our contracts dictate that these service providers only use your information in connection with the services they perform for us and not for their own benefit.  That's good.  Financial institutions we partner with to jointly create and offer a product like the PayPal - oh, here we go, now they're talking about DoubleClick - such as the PayPal Plus credit card.  Oh, no, that says where we share information with GE Money Bank.  That's for the approval.  Credit bureaus, companies we plan to merge with or be acquired by.  Law enforcement and other third parties...



STEVE:  Look at all the data we have that you'll be able to get when you buy us.



LEO:  They certainly have a lot of information.  Now, you can - it says you can restrict PayPal from sharing your personal information, some types.  I don't know, I'm going to go look and see what kinds of things.  It doesn't sound like I have much control over this.



STEVE:  Well, I want to absolutely extend an invitation to anyone from PayPal to explain this.  I mean, we understand the technology.  This really looks bad.  And I know that our listeners are passionately interested in this issue because they've been bugging me to spend the time to talk about it.  And now we have.



LEO:  Well, it also shakes the foundations of our whole trust system because TRUSTe is their trusty licensee.  And TRUSTe validates their privacy statement.  Which means to me, well, if TRUSTe's validating this, and somehow within this legalese they're saying we can do this...



STEVE:  Well, but Leo...



LEO:  ...we're not safe anywhere.



STEVE:  What you just read does give them the permission to share whatever they want to with DoubleClick.



LEO:  Well, it's worded, though, in such a way that DoubleClick can only use it in ways that PayPal says they can use it.



STEVE:  Well, no, in ways that are in line with the relationship.



LEO:  Services they perform for us and not for their own benefit.



STEVE:  Yeah, okay, well, so we don't know what those are.



LEO:  Right.



STEVE:  Anyway, I want to say to anyone at PayPal, we want to keep this balanced.  If there's a way to explain why this is being done, why PayPal links take me through DoubleClick's server with this account number-looking information, and only then do we go back to PayPal, what possible purpose does this have other than violating our privacy.



LEO:  Right.  Well, I think that's pretty clear.



STEVE:  Yeah, I'm just saying, you know...



LEO:  Maybe there is a bond there could be, who knows.



STEVE:  The technology is very clear.  I just don't know how this could be defended.  Just it's really sad to see.  And again, as I said, I can't imagine a company more in desperate need of competition than PayPal.



LEO:  Absolutely.  Absolutely.  Well, you've raised such an interesting issue.  And it scares and frankly depresses me because we are so reliant on them for what we do.  I don't know, I mean, I guess I could start using another merchant account system, but everybody uses PayPal.



STEVE:  Well, and as I said, the obscure sites I go to that I don't want to trust with my credit card information...



LEO:  You trust PayPal.



STEVE:  Yeah.  Yeah, exactly.  Oh, and I have tried, as I mentioned once before, this virtual debit card, looks like a fantastic system, where you download a little applet on your machine.  And in fact - oh, there's another problem.  The download link for that applet is a DoubleClick link.



LEO:  Yeah, see, that baffles me, too.  What, you know, what possible rationale could they have for that?



STEVE:  I know.  But my point was that due to something squirrelly in my own personal credit reports that are held by the three main credit clearinghouses, there's something that prevented me from getting automated approval.  This whole thing is supposed to take 20 seconds, and you automate it, I mean, because I would love to be using this virtual debt card.  This issues you a temporary one-use credit card number on the fly to use in these sites that don't support PayPal, where you don't want to give them your real credit card.  I would love - I've tried three times to get this.  But something squirrelly in my own credit report prevents the automated system from functioning.  And I have been on hold for hours.  I have tried over and over and over.  I've never been able to talk to a human being to get this thing resolved.  So it's like, okay, I just - for whatever reason, I can't have one of those, much as I would like to.  So, I mean, PayPal is difficult to actually talk to.  They're an automated faade.  And people who breathe just - they don't seem to have much interest in talking to us.



LEO:  Well, that's pretty much the state of the union anyway, isn't it?  After all, that's where everything's headed.  But we're going to fight against it.  We're going to fight for your privacy and fight for companies that will actually talk to you.  And people can vote with their feet.  Although, you know, our server company takes its payment directly through PayPal.  Many of our providers, our web designers, take their payment through PayPal.  I can't - I couldn't get out of PayPal if I wanted to at this point.



STEVE:  Exactly.  I mean, they're in a position where they have this much power.  And I guess what we're seeing now is them really not caring.



LEO:  Well, the word goes out.  Let us know, PayPal.  The nerdy Steve Gibson can be found at GRC.com.  That's where Steve lives.  His site is everything, everything's there.  ShieldsUP, all his free security programs, the new PPP software.  I just forwarded you a message, somebody rewrote it for Perl.



STEVE:  Yup, got it yesterday, Leo, thank you.



LEO:  That is so cool.  You can also, by the way, get ShieldsUP, try ShieldsUP there.  That's the program that lets you test your firewall or your router.  And of course who could forget SpinRite, the ultimate disk recovery and maintenance utility.  It's all at GRC.com, along with this podcast in 16KB versions, transcripts by the great Elaine, who's working on Thanksgiving Day.  We didn't mention that, by the way.  Happy Thanksgiving for our U.S. listeners.  Turkey Day today.  Actually we're recording this ahead of time.  What do you do for Thanksgiving?  You going to have a turkey?



STEVE:  I would normally - I used to travel up north to visit my family in Northern California.  But after 9/11, you know, travel just became so, I mean, it was already the busiest and most annoying travel day of the year.  But it just became too tough.  So I hang out with a bunch of friends who are also sans family for Thanksgiving, and we make up our own little virtual family.



LEO:  That sounds great.  That sounds wonderful.  Well, have a great Thanksgiving, Steve, and have a happy Turkey Day, everyone.  Or most likely you're listening to this after your turkey.  Well, maybe not.



[Talking simultaneously]



LEO:  If you're still listening after your turkey, you must have had some coffee, too.



STEVE:  Dedicated nerds.



LEO:  Dedicated nerds.  Some people, you know, after the big meal they go watch the football game.  The real nerds listen to Security Now!.  We'll be back next week.  We'll have your questions and answers for Episode 120.  And I will see you then.  Thank you, Steve.



STEVE:  Thanks, Leo.



LEO:  Have a great day, a great weekend.  Happy Thanksgiving.



Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#120

DATE:		November 29, 2007

TITLE:		Listener Feedback #29

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-120.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 120 for November 29, 2007:  Your questions, Steve's answers.



It's time for Security Now!, everybody's favorite security podcast with Steve Gibson, the king of security.  I don't know.  You wouldn't style yourself the king of security, I know.



STEVE GIBSON:  No, I wouldn't.  I just, you know, I've been thinking about it for a while.



LEO:  Thinking about being the king?



STEVE:  No, thinking about security and messing around with it and wrestling with it and all that kind of good stuff.



LEO:  So this week we do our question-and-answer session, so we'll be talking about a lot of different security topics in just a little bit.



STEVE:  Yup, bunch of good questions from people.



LEO:  We are prerecording because of last week's holiday, Thanksgiving, and I'm in Vancouver this week.  So we don't have any errata from the previous episode.  Not to say that it was perfect, but we just haven't had time to receive...



STEVE:  Right.  We're recording this before anybody else has heard what last week's...



LEO:  Right, right.  And that'll be interesting.  I'm sure we'll hear from PayPal if nobody else.  Well, I at least hope we'll hear from PayPal.



STEVE:  That would be great.  I'd love to hear some defense of them.  It turns out, when I exchanged email with Elaine, our illustrious transcriptionist, turns out she was one of the people also who - she described herself as being bated breath, waiting to hear the complete analysis of that PayPal/DoubleClick relationship.  And her comment was, well, you know, I could give up on PayPal and delete everything; but whatever they have, they already have, and I'm already in the galactic database.  So what the hell.



LEO:  What the hell.  You're kind of stuck.  What can you do?



STEVE:  Right, right.  I did get an interesting and fun sort of SpinRite story that made me think of what we were talking about last week because we were talking about RAID and how, for stuff that absolutely, positively can't be lost, what you want is you want redundancy thanks to RAID.  And of course backing up is absolutely what you want to do when you don't have the option of RAID, and even when you do have RAID.  Because, for example, malware can still infect a RAID-based system, and then you've got much more reliable malware, even though that's not what you want, thanks to RAID.  So...



LEO:  More reliable malware.  I never thought of that as a side effect, but you're absolutely right.



STEVE:  So it still makes sense to take checkpoints.  But I got a really fun testimonial from a guy named Brian Kinder, who - it hit me because he is very computer savvy, and he recognized that this was sort of like the reverse of the RAID success.  He starts off saying, "Just another success story of SpinRite."  Just one more.  Just another one.  He says, "My boss has in his home a small workgroup network, and he was using an old Win2K box as data storage.  He called me in a panic that he could not get to any of his 11,000 photos that he had taken over the course of six years from all of his many travels.  I went over to his home and discovered that, of course, he has no backups."



LEO:  Now, why would you have 11,000 photos and no backup?



STEVE:  Well, you know, I think this is one of the traps that people get into is that, well, it worked yesterday, and it worked today, so why wouldn't it work tomorrow?  So anyway, so he says, "The previous 'technician' had set up his 2000 box with disk spanning.  It had a 160-gig, a 30-gig, and an 80-gig disk set up in a span to form one single volume that was shared to the rest of his network."



LEO:  Now, correct me if I'm wrong, but that makes it four times as likely to fail.



STEVE:  Well, three times because he's got three drives.



LEO:  Three drives.  So it's multiplied by each drive; right?  Because if any one fails, the whole span fails.



STEVE:  Exactly.  I mean, like the reverse of RAID.  And of course it is only as strong as the weakest link, so you're multiplying the failure probabilities.  So he says, "Well, you know as well as I..." and clearly Leo, he didn't say that, but I'm putting that in...



LEO:  Thank you for including me.



STEVE:  "...that any drive in that group fails, the whole volume fails.  So I run my trusty SpinRite and see what happens.  It took about a day and a half, but all three drives finished the process.  The 30-gigabyte drive in particular had many, many errors.  But with your data recovery procedures, it was able to make it through.  So now we boot up the unit with the three recovered drives, and of course the span volume comes up fine, and now he could get to the many thousands of photos he had stored.  And of course we have to set up a more sensible drive redundancy and a backup procedure for him to follow.  So again, thanks for a great program.  I've been using it since Version 2, and it has never failed to get the results I need.  Signed, Brian Kinder."



LEO:  I hope that guy, that photographer fell on his knees and thanked you, because...



STEVE:  Oh.  Well, and again, it's funny because we've seen hard drive storage just dropping in cost.  And we've had some people write and say, hey, you know, I can get a drive for less than SpinRite, so why would I use SpinRite to recover a drive when I could just replace it for less?  And it's like, well, okay, two things.  First of all, you can only buy one drive for less than SpinRite, yet you get to use SpinRite on all the drives you have for as long as you have SpinRite.  And secondly, of course, what we're seeing is, as a consequence of storage getting so cheap and digital media coming on so strong with photos and music and, you know, there are people who have huge servers, and they've ripped all their DVDs because they want to store them on hard drive for instant access or for access on various machines around the house.  So we're obviously moving into a digital media world where the contents of the drive is what's valuable now, more than the container itself.



LEO:  And, you know, if everybody backed up, they wouldn't need SpinRite.



STEVE:  True, if they backed up, like, constantly, you're right.



LEO:  If they were religious about backups, you could just say, eh, that drive died, oh, well.



STEVE:  Although SpinRite, of course, does also keep drives alive longer.  So it can help the drive to fix itself in order to, I mean, there are people who, after they have a problem, continue using the drives that SpinRite repaired for them.



LEO:  I'm doing that right now.



STEVE:  Yeah, exactly.



LEO:  And I feel fairly confident that whatever was the bad sector has been moved off.  Although I should be pretty religious about backing up.  Not merely backing up, but SpinRite-ing these drives, just to make sure.



STEVE:  Yeah, it's a good thing.  And I did not answer your question last week when you said about how often.  And of course - oh, there's Elaine sending something.  She just responded to my sending the Q&A stuff.



LEO:  She doesn't listen live, does she?



STEVE:  No, but we have never mentioned the fact that - or are we doing it this time?



LEO:  We did last time.  And we will probably - what we do is I stream, as I do my production day, my recording day - because we do most of the shows, obviously all the podcasts are recorded ahead of time.  And I think people would like to listen live.  So what I do is I keep a stream going at Ustream.tv of the recording.  And then I have a chatroom going at irc.dslextreme.com in the #townsquare chatroom.  So people - it is eventually going to be - my idea is eventually to be a little more live and interactive.  But at least this is kind of a poor man's way to listen as we do it live.  Not today, I haven't put it on today because I'm having trouble with Verizon.  It's just not reliable enough.  I have to get a second channel in here, probably get a T1, or I was thinking I could just get a cable modem and have the cable modem and the DSL, and that's kind of a nice set of redundancies.



STEVE:  Yeah.



LEO:  Yeah.  Anyway, so, yeah, she could be watching live, but she's not today.



STEVE:  No, not in this case.  So anyway, I never answered your question last week about how often you should run SpinRite.  And of course the answer is, well, run it before your drive fails.



LEO:  Yeah, okay.



STEVE:  But my sense is that most people have years of life on their drive before they start having any problems.  There are infant mortality problems, of course, that we've talked about in the past as one of the ways that drives can fail.  But, you know, maybe three times a year, I would think that's often enough to allow SpinRite to help the drive realize that it's got problems and move any endangered data out of the way.  It also works the drive.  I mean, when people talk about it running for a day, that's serious data transfer that is occurring that also allows the SMART system in the drive to discover if there are any problems.  So it sort of just gives it a real good shaking to make sure that not too many bits fall out.



LEO:  Yeah.  I like that.  Shake your drive regularly to make sure no bits are falling.



STEVE:  Yeah, find the loose bits.



LEO:  Find the loose bits.  Before we get to our questions - and we have, let me see, looks like we have 12 excellent questions, including the Clever Observation of the Week Award.



STEVE:  Exactly.



LEO:  That'll be fun.  All right.  Are you ready for some questions?



STEVE:  Absolutely.



LEO:  Absolutely.  I've got a dozen good ones, starting with Erik in Palo Alto.  He wants to give his credit union some credit.  Dear Steve and Leo, he writes, yesterday I got an email from my credit union, Patelco, telling me that they are now going to require multifactor authentication for customers who want to use online banking.  Being the geek I am, I got all excited.  Maybe they listen to Security Now! as well.



So I quickly went to their website and started reading about it, then signed up immediately for the beta test.  The thing that surprised me was their method of multifactor authentication was a bit different than those I recall hearing you talk about.  Their system works by having you authorize specific Internet service providers that you can log onto their system from.  So he's with SBC.  So when he logs on for the first time it says, ah, you're on SBC, I'm going to add that to your safe providers list.  Note, you are not able to manually add ISPs.  You actually have to log in from them.  So you have to be on an SBC connection, and then they'll ask and allow you to add that to your providers list.



This morning when I got to work, logged onto the bank account again.  After I entered my account number and password, I was taken to a screen that said you need to enter a new password, we're going to send it to you because the domain you're connecting from is not on the list.  So he said, I could have the password emailed to me or have a text message sent to my cell phone - I like that, that's very convenient - since email addresses and cell phones are on file with them.  So he chose email.  Within a few seconds he got a four-character alphanumeric password that allowed him to access the account.  The password expires after two hours.  Kind of like a PPP.  Well, not exactly, because yours you just use it and then it's done.



STEVE:  Right.



LEO:  Now that I've logged in from here, my work's domain appears on the list of approved providers, and I don't have to go through that rigmarole again.  However, should I want to always be prompted for an additional password - oh, he's asking, should I always ask this?  I have the option to set it up that way.  I was interested in hearing your comments on how good the system is and what flaws, if any, you see in it.  Well, that's a simple way to do multifactor authentication.



STEVE:  Well, it's - yeah.



LEO:  It's kind of weak authentication.



STEVE:  Yeah, I wouldn't quite call it multifactor.  I guess there are - and I should be more up to speed on government regulations.  But there are new regulations, I know, that are coming onstream that are requiring "multifactor authentication," that is, something more than just username and password.  So I guess this would qualify, where obviously another factor is, in this case, the domain from which you're connecting.  So...



LEO:  It would work better if you were on a small Internet service provider.



STEVE:  Exactly.



LEO:  If you're on AOL, that means anybody on AOL can attempt to hack you.



STEVE:  Exactly.  What they're clearly doing is they're doing something that we've talked about in the past, a so-called "reverse DNS" lookup.  Normal DNS, as we also know, takes you from a human readable style URL, like www.grc.com, and that translates it into GRC.com's IP address, which is the 32-bit destination where our servers live, which is shown as the four groups of numbers.  I think GRC.com is 4.79.142.203 for the www.grc.com.  And so that's what DNS does.  Reverse DNS, like the name sounds, does the reverse.  That is, you give it an IP address, and it can tell you what the machine name, the domain name is that's associated with it.  So, for example, if you do a reverse DNS lookup on GRC's IP address, you'll get www.grc.com.



Now, we all know that DNS is a good and generally robust system, but not ever designed to be ultra secure.  There are various types of DNS spoofs and poisoning attacks and so forth that can be done.  Also, clearly this was designed to, for example, allow in your case, Leo, an AOL user, if they're like an older style dialup user, they're going to get a different IP address every time they dial into a large modem pool.  And of course, as we know, even cable providers that are using DHCP to distribute their relatively limited IP pool around in their customers, you know, there is re-use of that.  So that, for example, if you had your cable modem unplugged for a couple of days and then reconnected it, you'd very likely get a different IP address than you had before.  If you keep the power on, and you've got a NAT router which is sort of anchoring that IP, they generally are more static, although Mark Thompson in Phoenix was telling me that he's now seeing, for whatever reason, his Cox networking provider is changing his IP, like, daily now, whereas others tend to stay much more static.  But anyway, the point is that clearly they designed this to say, okay, we're not going to concern ourselves with the user's IP, which is changing.  We're going to concern ourselves with the ISP's domain name.



Now, when you do a reverse lookup, for example on a Cox cable modem IP, you will see the - typically it's the IP address first, then sometimes they'll have something that's sort of like regional, like I remember sd.sd.cox.net - sd.sd happened to be San Diego in the case of someone who long ago was attacking GRC - or oc.oc for Orange County .cox.net.  So the bank or other institution that's using this style would - they would ignore those earlier chunks of the DNS result, which might be and probably are based on the specific IP the user has at this time.  But they go back further down in the domain name to say, okay, he's at cox.net.  He's at aol.com.  He's at...



LEO:  I guess on big providers they could know what the range of IP addresses the provider - what Class C domains the provider owns; right?  They could just add all of them.



STEVE:  Well, yeah.  And in fact that's the problem is it's not one-to-one authentication.



LEO:  Oh, I see, yeah, yeah.  It's not your IP address because it can't be, because it changes.



STEVE:  Exactly.  And as you said, anyone who is trying to spoof, for example, the "other factor" of an AOL user, well, if they were on AOL, then when they're spoofed, their spoofing attack comes in, and the reverse DNS is made, they're going to be on AOL, which might match one of the, quote, "safe providers" on that user's safe providers list.  So the problem with this, and the reason I was skeptical about calling it really multifactor authentication is, well, yes, it's another factor, but it's not a one-to-one factor.  For example, one of the cool things about Perfect Paper Passwords that we've talked about is you're the only one with this printed out little password token list.  Nobody else has one.  If other people had them, we'd be much less enthusiastic about it.



LEO:  Right, right.



STEVE:  Because there'd be the opportunity for a collision there.  So the fact that every one of them is unique is where it gets its strength.  Similarly, if many people used the same password, even though their log-on was the same, but their password, like where there's a high incidence of password collision, that would weaken the system substantially.  So, I mean, yes, this is better than not having it.  But it's really not as secure as we would hope it would be.  On the flipside, it offers more security than not having it at all.  Some random attacker in another country would have a difficult time spoofing their IP into a specific safe provider.  But even that's not impossible because the way reverse DNS works is you ask - essentially reverse DNS goes through a process of narrowing down the location of the ISP that the user is using until they come, essentially, to the ISP's DNS servers.  Well, it would be entirely possible for someone located anywhere else to pretend to be SBC or AOL.  That is, it's not AOL's servers that uniquely provide that reverse mapping.  It's the server associated with that IP.  So you could easily have some Russian or Chinese or anyone, essentially, who has control of that IP space could say that they're AOL.com.  And there's no way to know that they're not.  So again, it's a better thing than not doing this at all.  But I'm skeptical about this thing really qualifying as a strong additional factor.



LEO:  We should find out what the regulations are.  It may be that they're not - I bet you anything the banking lobby said, well, don't make it too hard.  You know, allow this.



STEVE:  Oh, yeah, if we make it too hard, no one will do it, so we want to make it, you know.  And again, it's better than not having it.  But it would really be better if they adopted a good multifactor solution as another factor.



LEO:  I just want everybody to use these PIP cards, these VeriSign cards.  It just seems like such a great way to do it.



STEVE:  Oh, it's a beautiful solution, Leo.



[Talking simultaneously]



LEO:  ...carry the card around and...



STEVE:  Yup, I just signed the agreement, in fact yesterday, with VeriSign, an evaluation agreement that will give me access to their back end so I can actually play with the API.  I mentioned a couple weeks ago that I had looked at it, and looked at the spec, and it looked absolutely clean and robust.  So I'm going to enjoy writing some code to actually make it jump around and be able to authenticate my little credit cards.  And I will certainly tell our listeners how that looks.



LEO:  And you wouldn't really need PPP if this were universal.  You could use this for your PPP; right?



STEVE:  That's absolutely right.  And in fact I purchased six of those credit card form factor units, and I fully intend to actually use the VeriSign system as my primary authentication for myself and Sue and Greg...



LEO:  Oh, no.



STEVE:  ...because it is just very cool.



LEO:  As soon as you publicize PPP, you replace it.



STEVE:  I know.  I know.  But I'm glad I did PPP.  And that'll always be our fallback.  If for any reason I lose this relationship with VeriSign, then it'll be like, okay, fine, that was good while it lasted, and we'll be able to fall back to the Perfect Paper Passwords.



LEO:  I'm sure VeriSign must intend to charge people who want to implement this; right?



STEVE:  Oh, absolutely.  And their model is a big company model.  I mean, I don't know if it would ever be feasible for a little ones-y guy like me to be involved.  It's a PayPal and eBay and a BofA scale solution.  But I agree with you completely, Leo.  Based on what I've seen, I mean, I've got the card in my wallet.  I was never carrying a football around with me because it was just - I didn't want to end up with a necklace of them, and it just wasn't so convenient.  But I already have some credit cards, and this thing is no different than - as you know, you've got one.  It's no different than a credit card.



LEO:  You know what I'd really love to see is them - what happens with PayPal, you don't have your card, you can ask the security questions.  It's always the same two, totally easy to fake this one.  What I'd love to see is maybe them use this backend Bank of America's using where it says, okay, as this guy's did, now we need to send your code to your cell phone or your email to verify.  I would prefer that as a second fallback position.  Because you can't assume that people will always have the dongle or the card, or they won't have lost it or that kind of thing.  So you always need kind of a back door to it.  But let's make it a better back door.



STEVE:  No, I absolutely agree.  And remember, as one of our fundamental lemmas of security is, if it's more secure, it's less convenient.  I mean, it's a tradeoff.  And so, yes, I'm now glad that my PayPal account is locked with these two hardware tokens.  I've got both a football and my little credit card, both from VeriSign, hooked onto this account.  And I'm really happy that I've done that.  But I wasn't really happy until I had the credit card format token because that's easy for me to have with me all the time.  There were several cases where I was at Starbucks and wanted to buy something, but the football was at home.  I was going, eh, oh, darn.



LEO:  So you were able to convert - you decertified the football and used the VeriSign identity protection card instead?



STEVE:  No, no, no.  That's the cool thing is that VeriSign recently brought up, in the most recent version, which is now current, you can have five hardware tokens simultaneously registered to a VeriSign account, and PayPal supports that.  So you can leave your football authenticated on PayPal right now and add your credit card to your PayPal account.



LEO:  Through PayPal, not through VeriSign.



STEVE:  Through PayPal.  There is a UI at PayPal, which is where I did it, and it knew that I could have up to five different hardware VIP tokens of different form factors, either the original football or the new credit card form factor, simultaneously on my account.  So I've got both of them on mine.



LEO:  Yeah, that's not a bad idea.  I mean, then you have kind of a backup.  If you lose one, you still have the other.



STEVE:  Well, and for example, I've got the football sitting here right next to me.  And my wallet happens to be in the back of the house because I'm here in my sweats right now and not in my outdoor clothes.  So it's perfect.  It's like absolutely no overhead because now I can have multiple tokens simultaneously authenticatable.



LEO:  Cool.



STEVE:  It works.



LEO:  I'm sorry.  We've now just made it, like, 15 questions because I just snuck in three.  Sorry.



STEVE:  No problem.



LEO:  Bob Gusek in High Point, North Carolina wonders, if once is good, is twice better?  I've been thinking about encryption and brute-force attacks, says Bob, actually probably any kind of attack, and how they classify success in breaking some encryption.  I'm not sure if there's something I'm missing.  And I figured with the amount of work you've done on encryption, you'd be able to identify an issue with this approach.  In the process of encrypting blocks of text that I may be sending to someone, in other words, encrypting a file, I've experimented with doing double encryption.  What I do is take my clear text, encrypt it first with one key, then take this encrypted text, encrypt it with a second key.  If someone should ever try to brute force this, from what I understand, they try combinations of keys until they get clear text.  But of course they'll never get clear text because I've encrypted it twice.  Am I missing something?



STEVE:  I think this was a really great question.  So to paraphrase what Bob said, he recognizes, and we've mentioned this many times, that the way brute-force attacks work is essentially like with a dictionary or just starting at zero and counting up.  You attempt to decrypt the encrypted text, waiting until something recognizable comes out of the decryption.  And if suddenly you see something, chunks of text that is readable, you go, whoa, we just got the key because that's the only way that you're going to be able to decrypt the encrypted text is with the proper key to run the decryption.  So he says, okay, what if I do it twice?  Then no matter what anyone did, all you could ever get, even if you got the proper key for the second encryption, you would be taking that wrapper of second encryption off, and you'd have the first encryption.  But that's going to be random because we know that what good encryption does is basically create a random mapping between so-called clear text and the cipher text.  So you wouldn't be able to tell that you had ever gotten the second key by examining it as you would with a single encryption because all you're going to get is more noise, and it's going to be indistinguishable from any of the other random noise that you get when you don't have the right second key.  So he's absolutely right.



However, I'll point out that this really would pertain only if you had weak keys.  That is to say, all contemporary symmetric encryption, which is essentially what we're talking about, is going to use 128-bit key.  Well, that 128 bits is phenomenal strength, given that the bits of the key are chosen randomly.  They're not chosen randomly if, for example, you took the simple password "dog" and hashed it into 128 bits because somebody else could put dog into the hash, get those 128 bits, and apply that to the decryption, and essentially reverse your code.  So what you could do is, if for some reason you needed to use weak passwords, then certainly using two of them would be, that is, exactly as he suggests, encrypt, and then use a different weak password to encrypt it again.  Or for that matter, if no one knew that you had double encrypted, you could use the same password.  Because, again, they're not going to know you double encrypted, so they're going to decrypt it once and see noise and go, okay, well, I got the wrong one, even though if they did it again they'd get the clear text out.  So it's an interesting idea.  But if you have, for example, a really random 128-bit encryption key, that's already so strong against any kind of brute-force attack that doing it twice doesn't really buy you any more because you've already got something that isn't going to be reversible in the first place.  But there's nothing he's missing.  It's a clever idea.



LEO:  Why do I think that PGP uses double encryption?  It's using 128 bits to encrypt the passphrase; right?



STEVE:  Well, correct.  And PGP is a public key-based system, so it's got a much longer key, probably 124 bits, for the public side.  And then but because you can't encrypt the bulk payload with public key because it's too slow, the idea is that PGP will generate a random number that is a random 128-bit key, or maybe it's longer, and then it'll just encrypt the key using the public key.  So there are multiple layers of encryption.  One is public key, and then one is symmetric key because symmetric key is high speed, and that's how you do your bulk encryption.  And then you encrypt the key using just the public key side.



LEO:  Right, right, right.  Matthew Beacher in Pottstown, PA has also been having fun with crypto.  Got a lot of crypto questions today.  I've been a listener of the show since Episode 1, and I think the advanced topics have helped a lot.  I'm writing a PHP-based web application.  I'm currently working on the login system.  As a matter of convenience, I'm foregoing SSL and instead engaging in client-side JavaScript one-way encryption.  So here's what he's doing.  I'm taking the user's supplied password, concatenating a known string from the GRC.com Perfect Passwords page - hmm, interesting - doing an MD5 hash, concatenating a second known string, and doing a SHA1 hash of that.  Then I take...



STEVE:  He's not done yet.



LEO:  Then I take this blob and do an HMAC SHA1 hash with a key from the PHP version of Perfect Paper Passwords, and I turn that into a hex string.  All this in JavaScript.  This is then compared with a string on the server that was hashed the same way.  On the server I'm storing passwords hashed with MD5 and SHA1, then adding HMAC SHA1 hash to authenticate.  I have three questions.  I hope you're following this, Steve.  One, am I doing enough to protect the passwords without using SSL?  Two, should I be using HMAC - I don't even know what that is, H-M-A-C.



STEVE:  We'll talk about that in a SEC.



LEO:  To hash the passwords before putting them into the database.  Three, do I need to do something more to protect passwords when creating accounts for the first time, knowing that whenever or whatever the client sends will have to go into the database?  Should I be doing an HMAC hash before sending the password, then a regular SHA1 hash before storing in the database?  Folks, that's a lot of hash.



STEVE:  You know, I'll bet you that Matthew wears both a belt and suspenders.



LEO:  This is a belt and suspenders system.



STEVE:  This thing, Matthew, nobody is ever going to figure out...



LEO:  What you did.



STEVE:  ...by doing a monitoring of your wire between the client and server, what the password was that went in the front end of this grinder machine that you've built that manages to have, I mean, it's amazing to me that the same data comes out the other end each time you put the...



LEO:  I don't understand how he synchronizes the Perfect Paper Passwords server and client-side.  Not the PPP, but the GRC password.



STEVE:  Yeah.  From what he said, I'm not sure what he's doing with PPP, how that fits in there.  He mentions HMAC, and it's something we've never talked about.



LEO:  I know what MD5 is, and SHA1.  Those are both hashes; right?



STEVE:  Right.  And we've talked about hashing, where basically you can put any size of stuff you want in one end, and what you get is a fixed-size sort of a fingerprint, the so-called "hash," of the input.  And so, for example, MD5 stands for Message Digest.  These hashes, another word for "hash" is a "digest."



LEO:  And they're cryptographically strong.  They're unique.



STEVE:  Yes.  Newer ones stronger than older ones.  For example, Perfect Paper Passwords is based on, or uses, SHA256, where you put a whole bunch of stuff in, and you get 256 bits out, which is stronger than MD5, which is 128, and stronger than SHA1, which is 160 bits.  But still those are strong.  And, for example, SHA1, remember there have been some - a flurry of concern because people were mistakenly saying that it had been cracked, or it had been broken.  Well, that wasn't the case.  What was found, however, is that it wasn't as perfect a hash as we would like.  There were some collisions, meaning that to a higher degree than would be statistically likely, you could put different things in the front end and get a collision.  That is to say, the same 156 bits out the other end.  And so that made people a little uncomfortable about it, that is, it wasn't as completely strong and unpredictable and random or pseudorandom as we would like the output to be.



So what an HMAC is, HMAC stands for Hash Message Authentication Code.  And that's like a hash, but it's keyed, meaning that in the same way that we have, for example, a symmetric encryption, like Rijndael is keyed where it will - you give it 128 bits with Rijndael, that is, and out comes a different 128 bits where there's a one-to-one mapping between the input 128 and the output 128, but that mapping is entirely determined by the Rijndael key, that is, the symmetric key.  In the case of an HMAC, that is a keyed hash, meaning that it's a hash inasmuch as you can put as much stuff in as you want, but then you always get out the same size result, being a hash.  But the key determines the result that comes out in the same way that a key on crypto determines the result that comes out.



So what this is useful for is, if we look at the use of a non-keyed hash, like SHA1 or MD5 or any of the non-keyed hashes, you put something in, and you get essentially a fingerprint, a hash of that document.  So that's useful for saying, if you were to say to someone - and in fact this is how a lot of hashes on the web are used.  You'll see, like, someone in the open source community will say, here's the source for this build of something, and here's the MD5 hash of it.  That allows you to independently hash the same stuff that they did and compare the MD5 hash output to make sure that it's the same.



LEO:  Evaluate it that way.



STEVE:  Exactly.  Basically it's like a fingerprint, the hash is a fingerprint of what you feed in.  But the point is that anyone can do this and get the same result.  So what's unique about a keyed hash is that, not only can it verify that exactly what went in resulted in the proper output; but by being keyed, if the key is secret, then you can also verify who did it, that is, who hashed it, because somebody with a key had to have that key and that content in order to get the result.  So it also allows authentication in addition to verification that something wasn't changed.  It allows you to authenticate who provided the hash output, rather than just the fact that somebody did.



So anyway, Matthew has, again, I mean, he's come up with something very strong by taking the password, adding to it a big blob of randomness from our Perfect Passwords page, then doing an MD5 of that, adding another known string, doing an SHA1 hash of that, then using an HMAC where the key of the HMAC is one of the Perfect Paper Passwords keys, and then he turned that into a hex string, and that's what he sends to his server.  So it's like, okay.  So, wow.  It strikes me as massive overkill.  But he's obviously been having fun writing JavaScript, and so I think that's fine.



LEO:  Whatever rocks your boat.



STEVE:  The big problem is that he says he's foregoing SSL, which means that he has absolutely strongly encrypted the logon aspect, that is, the logon phase.  But apparently he's not using SSL.



LEO:  So nothing else is encrypted.



STEVE:  Exactly.  And then the problem or the question is, if he's creating a logon relationship, then state is being saved somewhere.  For example, he may be returning a cookie to the client, which is the client's session cookie, which if no SSL is being used, it completely exposes him to a so-called sidejacking attack because anybody monitoring the wire, and of course the only reason he's gone through all these, jumped through all these hoops, is that he's protecting himself against somebody sniffing his traffic.  Well, anybody sniffing the traffic would see everything else that's being done, including whatever he's doing to maintain state.  Which if it's not wrapped in an SSL tunnel to make it snoop-proof, then somebody could grab the cookie, assuming that he's using cookies to maintain state, or whatever else, and instantly impersonate that logged-on user.  So what he's done is he's protected the event of logging on, but he's made it unnecessary.



LEO:  He's closed the barn door before the horse got away, but the horse wasn't ever in there.



STEVE:  The horse went out the window.



LEO:  There you go.  Interesting, yeah.



STEVE:  So, I mean, that's really the problem is he protected the event of logging on, but unfortunately the rest of his dialogue, the rest of the conversation, without being protected by a secure tunnel, everything he does from then on not only can be recorded and sniffed, but I don't see how he's protecting anybody from obtaining whatever ongoing credential was established by that one-time galactically secure logon.  I mean, no one will ever figure out what that hex string should be, but now they don't have to.  All they have to do is grab the cookie that gets returned, and they are able to impersonate the person who painfully logged on the first time.



LEO:  Oh, well.



STEVE:  So, neat idea, Matthew, but I don't know, unless you are continuing to - he said client-side JavaScript one-way encryption, which to me meant he's going through all this to encrypt the logon, but nothing else.



LEO:  You could encrypt the rest of the conversation by hand, I guess.



STEVE:  You certainly could.  And that's what would be necessary in order to - and that gets pretty tricky, though, because you would need to do it in a way that was snoop-proof.  And I guess my point is that that's all been done.  That's all worked out with SSL.  So rather than foregoing that, I think it's probably a good idea.



LEO:  Now, Steve, you can't tell people to not reinvent the wheel.  You like to do that yourself.



STEVE:  That's true.  And so I would say that Matt has taken a great first step by nailing down the logon phase.  Now he's got to, you know, if he still has any energy left after all that JavaScript coding of all the crypto.



LEO:  Oh, that's a nightmare, too.  But, I mean, I think that's why you do something like that.  He's obviously a student, probably a computer science student.  And you do that to learn all this stuff.



STEVE:  Well, I hope he's listening because he's probably going, oh, shoot, I didn't even think about that.  I'm glad he asked the question.



LEO:  It is a great question.  Brian Dewey in Crestwood, Kentucky needs 89 security patches, and by now who knows.



STEVE:  Exactly.



LEO:  90, 91, 92?  Steve, I've just been tasked to reload Windows XP on my father-in-law's computer.  I'm concerned that Microsoft hasn't yet released Service Pack 3 for XP.  That comes out early next year, I think.



STEVE:  Oh, well, it's in beta now.  Is it going to be that - well, of course early next year is not that far away.



LEO:  It's a couple months, yeah.  Yeah, it is in beta now.  I think they said 2008.  I'll have to check.  I've been searching the Internet and have located a few websites that offer third-party slipstreaming of the hotfixes.  I personally only trust - boy, third-party slipstreaming.  I only trust downloading my patches directly from Microsoft.  What I haven't located is a reputable and authoritative list of hotfixes that are essential before I connect the computer to the Internet.  Are you aware of a master list of redistributable hotfixes and associated URLs?  Even though I've put this PC behind a NAT router, I'd feel safer if I could download and write to CD all the patches since August 2004.  Am I safe if I only visit update.microsoft.com?  Brian Dewey, SpinRite customer since Version 3.1.



STEVE:  First of all, I don't think they would fit on a CD.  You'd probably need a DVD.



LEO:  Well, let's see, the Service Pack 2 was 273 megabytes.



STEVE:  Yeah, and there have been some big ones since then.  Okay, so this is an interesting question.  It sounds like, first of all, he's concerned about putting a raw Windows machine on the Internet.  And in fact, that's sort of an interesting, fun, controversial issue because he's right.  If you were to reload XP and hook it without protection onto the Internet in order to get it updated, before it had a chance to get patched it would be taken over.



LEO:  Unless you have the firewall turned on.



STEVE:  And that's exactly right, Leo.  Now, I think he said, he says, even though I have put his PC, meaning his father-in-law's PC, behind a NAT router, I would feel safer if I could download and write to CD all - and we know it's going to take a DVD probably - all the patches released since August 2004.



LEO:  Let me just say one thing right away.  If he only goes to Microsoft.com to get these updates, and he's got his firewall on, he's safe; right?



STEVE:  Yes.  Either his firewall or behind a NAT router.



LEO:  So as long as he doesn't go to malicious websites, he's not going to get anything else.



STEVE:  Well, there are two natures of attack.  There are all the services that the original build of, what was it, the build number?  I've forgotten now, used to know, the original build of XP had some funky, like, it was a round number.  Oh, 2600, was that it?



LEO:  I guarantee you it wasn't 2600.



STEVE:  I might be confusing it with another OS.  But...



LEO:  I think it was 3000 for Vista.  But I can't remember what it was.  Yeah, they tried to get a round number out.



[Talking simultaneously]



STEVE:  Yeah.  So anyway, so the point is that that original build of XP, as we know, famously had a firewall that was turned off by default.  And thus the reason that there were so many problems.  And the malware, the worms, the viruses, the things that were able to infect those versions of XP, those initial problems that XP had are out on the Internet still sending packets at random all over the place, and we'll probably never get the Internet cleared of all that.



LEO:  There's always going to be some Windows 98 machine that's sitting in a corner, collecting dust, that nobody's touched in years, it's spreading Sasser.  That's all it does is spread Sasser.



STEVE:  So again, there are two types of attacks.  There's the unsolicited attack which is packets from the outside coming in through no protection, hitting any of the many services that were vulnerable in that original build of XP.  I mean, it just makes me shudder, you know, how much we've gone through since that original build of XP.  Then, as you mentioned, the other class of attack are where you visit a web page that is taking advantage of problems that have now been known for years, but is hoping to get people who don't have Windows XP patched up to date.



So yes, Leo, if he were to only go to Microsoft.com, or I'm sure that that first version of XP had the Windows Update button in the Start Menu because I push it all the time when I'm setting up a brand new Windows XP system.  So, I mean, and I guess I'm a good example.  I'm behind strong NAT, and I put these machines on the 'Net, and the first thing I do is go to Windows Update, and then I go make a fresh pot of coffee because it's 89 and counting security patches, and you've got to reboot I think about five or six times now because the patches have patches, as we've discussed before.  And then if you add any of the optional stuff, like the .NET stuff is still optional, then there's been a lot of security fixes for those, too.



So but there apparently is a place on Microsoft's site where they are listing patches that can be manually downloaded.  The problem is, I don't know how current and up to date it is, and there really is nothing wrong, as long as you're behind a NAT router, or if you did not have a NAT router, just turning the built-in original XP firewall on will give you enough protection to get yourself patched and updated.



LEO:  All right.  And by the way, you can go to Windows Update, and if you go to the network administrator mode, you can download these updates standalone.  So the default mode on Windows Update is to download and install and not save them.  But you can change your Windows Update mode to a mode that will allow you to download those files. So you could go to another computer, get a list of all the hotfixes, which is what he was asking for, and then put those hotfixes on a CD or, as you said, a DVD or two.



STEVE:  And then march through them one by one and install them.



LEO:  It's not a roll-up, and that's what's great about service pack, it's all rolled up into one.  But at least you can do that.  Now, I'm looking at Windows Update, and I can't remember - and I'm looking at the Vista version.  I change settings - you have to change into a network, a different mode, a network - a sysadmin mode, basically.  I'm not sure exactly where to do that.  They've changed how this looks.  But you can, I know you can do it.  I've answered that question a few times on the show.  So you can get those files individually on another computer.  That would be another way to do it.  A painful way to do it, but you could do it.



William Marquiss in Mt. Vernon, Washington can't find his NAT.  Where's my NAT?  I know it's here somewhere.  Steve, help.  I'm starting a small business.  While shopping at the various stores, I can't seem to find no stinking NAT routers.  Not one store employee seems to know what I'm talking about.  I want to actually look at and hold what I purchase.  Where are those NAT routers hiding?  There's no NATs.



STEVE:  I love the question because I can see poor William walking into a Staples or Circuit City or something and saying "NAT," and they, huh?  You want a what router?  I want a NAT router.  I've been listening to Security Now!, and Steve and Leo keep saying, you know, I want to be behind a NAT router.  And the guy at the store says, well, we've got routers, but I don't think we have any NAT routers.  I don't think our routers have NATs.



LEO:  What is NATs?  What are NATs?



STEVE:  Anyway, I loved the question.  William, all routers are NAT routers.  I guess I just say "NAT routers" because I'm a geek or a nerd or something.  I don't think you could, I mean, it's not the case that, for example, high-end Cisco routers are NAT routers, although they have NAT capability built into them.  But all of those little consumer boxes for $49, I don't think there's ever been one that wasn't a NAT router because the reason they were created was for IP sharing, which is what NAT is all about.  NAT, of course, standing for Network Address Translation.  So you can confidently go into whatever store you've been going into and confusing the poor salespeople and just say I want a router.  And any of the consumer routers have NAT built in, and you'll be getting NAT protection because they've all got it.



LEO:  Yeah.  Just when it says a broadband router, that's what it is.  Not a switch, a switch wouldn't have NAT necessarily, or a hub, or a bridge.  But a router, that's what routing is.



STEVE:  Exactly.



LEO:  Andy Leidy of Escondido, California has an interesting phishing idea for you, Steve.  He says, you've done a great job discussing the benefits of using the VeriSign/PayPal security fob, a.k.a. "the football."  I liked the recent suggestion about waiting for a prompt to enter the security number as an additional anti-phishing measure.  But the system still seems vulnerable to a one-time phishing event if a user is duped into providing his code to a phishing site.  Even if the bad guys can only use the code once, that one-time use could be pretty bad.



What if we turned the security code concept around and asked PayPal to provide a security code to us for verification they really are PayPal?  Oh, I like this.  When I enter my username, PayPal could display a code that should match the code on my fob within the next, say, 30 to 60 seconds.  If it does match, I could then reply with my password and a subsequent code, feeling quite confident I wasn't being phished.  Obviously PayPal would have to change their system to enable this, and there would be some issues with time syncing.  But it seems like this would be a pretty strong anti-phishing method.  Some users wouldn't be happy with the extra delay and would opt out, but others may be willing to take the extra time in order to increase their security.  What do you think?



STEVE:  Well, you're right.  I have to say it was really clever.



LEO:  Very clever.



STEVE:  Just think about this.  A very good friend of mine who is probably smiling as he's listening to us because he listens to Security Now!, had suggested this several times in email.  And I've been just swamped and haven't gotten back to him about it.  But he was suggesting it relative to Perfect Paper Passwords because he observed that the server in the PPP system knows the sequence of passcodes that are printed.  So you could further strengthen the Perfect Paper Password system by having it first tell you what is the next code, and then you enter the one afterwards.  That process would consume two Perfect Paper Password passcodes, but you would get some authentication that you were really talking to a server that knew where you were in the sequence and get some good anti-phishing protection.  And in fact it's a little more direct with Perfect Paper Passwords because there isn't this issue of time.



Now, we could strengthen Andy's idea a little bit based on the revelation that we shared last week.  I think it was last week, maybe the week before.  Remember where another observant person who hangs out in our newsgroups realized that the first digit of the football, because the football is time based, the first digit is not random, it's sequential.  It goes 0 through 9 and wraps around again, the reason being that if the clock has drifted, then when you give the six-digit code to PayPal, who of course forwards it through their backend server relationship to VeriSign where the actual verification is performed, that allows the server to deal with sort of plus or minus - let's see.  If the code changes every 30 seconds, then that means in 10 of those, that's 300 seconds, which is going to be five minutes.  So you could essentially handle a plus or minus 2.5-minute drift in the clock in the football and not harass the user by saying you've got to enter more codes.  Anyway, my point is that we could strengthen Andy's idea and solve the time sync problem by having the server that is going to provide us with a code, instead we push the button.



LEO:  We start.



STEVE:  Yes, we start, but only give it the first digit.  So we push the button, give it the first digit.  It should then definitively be able to tell us the other five because, by giving it the first digit, we've compensated for any sync loss that might have occurred since we used it before, as long as it's not more than 2.5 minutes, in which case we couldn't be sure of whether we were 2.5 minutes behind or 2.5 minutes before because we would have wrapped around.  But if we give it the first digit within that window, it should be able to definitively give us the other five.  And we would then know that we were talking to a site that knew who we were because we'd given it our username, it had looked up our football ID and figured out what should be on the display at that time.  Then we would, in order to prove to it that we were really us, we'd have to wait for a 30-second boundary to occur where that first digit would change to the next incremental one, but we get a new five.  And so we would then give it the next, essentially all six digits and say, okay, and we're convinced you're you, and here we are, we're us.



LEO:  Right, right.



STEVE:  So it's a cool idea.



LEO:  I like it.  Of course the people who are most likely to get phished, I mean, in other words, if you're smart enough to have the thing, the football, to do all this, you're not going to get phished.



STEVE:  Right.  Right.



LEO:  The people who are going to get phished are grandma, my wife - who's not sophisticated.  She's not going to do all this.



STEVE:  Right.  But it's a neat idea.  Now, here's the big problem with all of this, is that all of this assumes that you have an SSL connection, and you have verified that your certificate is HTTPS:, that is, you have an SSL connection, and you checked the certificate and verified that it's www.paypal.com and that the chain of authority goes back to VeriSign, from whom PayPal gets their certificates.  In other words, none of this works due to the possibility of a man in the middle.  If a site were phishing us, and we did not have a secure connection, then everything we've talked about, whether Andy's idea or my friend John's idea about the idea of the server telling you something first, then if there's somebody in the middle, then that person, that entity in the middle could simulate everything we've just talked about.  That is, they would get the site from PayPal, show it to you.  If you gave, for example, an enhanced version of Andy's idea, you give it the 0, you're really giving it to the phishing site, which turns around and gives the 0 to PayPal.  PayPal sends it back the five digits to prove that it's PayPal, but it's not, it's the phishing site.  I mean, PayPal is, sends it to the phishing site, the phishing site sends those five digits to you.  So the problem is you have more strength in your belief that this is not a phishing site when in fact it is.  And this is the problem with any of these approaches is...



LEO:  The man in the middle.  The man in the middle.



STEVE:  Yes.  And so this would absolutely defeat a less clever, non-man-in-the-middle phishing site, and there are many of those that are just static websites pretending to be PayPal.  But it isn't absolute proof that you don't have somebody in the middle.  The absolute proof is that you've got an SSL connection, and you have taken the time to verify that you've got a certificate that was issued to PayPal and signed by VeriSign, in which case you're golden, and there's no one able to sniff what's going on between you and that site.  But a neat idea.  I really liked that idea.



LEO:  Jay in New Hampshire poses a question which suggests some interesting issues.  He says:  Hi, Steve and Leo.  I had quick question about a discussion I had with a friend the other day.  I was telling my friend she should use a secure connection when she's using a public computer, since all you've got to do is put an "S" in the HTTP line.  The question she asked was if the server she's currently using can decrypt the sessions at will.  The server she's currently using can decrypt the sessions at will.  We both work for the government and are well aware of Big Brother watching us.  Oh, really.



STEVE:  Yeah, that was encouraging.



LEO:  Hmm, hmm.  Wonder what...



STEVE:  We work for Big Brother, and we realize Big Brother is watching us.



LEO:  ...what branch they work for.



STEVE:  I wonder.



LEO:  Which is why I said stick to personal time.  But the question is valid:  Is Big Brother watching us when we use HTTPS?  You tell us, Jay.



STEVE:  Well, you're right that his question was a little ambiguous.  I wasn't quite sure what he was talking about.  But it brought up a couple interesting points.  First of all, he was suggesting that you could always put an "S" after the HTTP.



LEO:  Not true.



STEVE:  Exactly, to create HTTPS, which is not necessarily the case.  It is, well, because in order for that to work, the server must support SSL connections.  Meaning that it must have the SSL port open, which is not 80, which is what normal web browsing uses, but is 443 instead.  So it must have that open.  And it must have an SSL certificate signed by somebody who your browser trusts.  And we've talked about this whole notion of certificate authorities where our browsers have a long list of authorities whose signatures they trust.  So the problem is that these certificates are not free, and many smaller sites won't be spending whatever it is, $700 a year, in order to allow users to make secure connections.  Typically it's only sites which have a need for a secure connection that have gone out of their way to make that possible.



So it's certainly not the case that any site you're visiting can accept an "S."  And in some cases, for example, the machine at a given domain which can accept an "S," that is, the HTTPS and SSL connection, may be different than the normal web machine.  For example, people who have been paying attention may have noticed sometimes it'll say secure.domain.com, meaning that that's a machine that's able to do secure connections.  It'll say that in addition to HTTPS.  But if they normally go to just a non-HTTPS connection, there'll be, like, www.domain.com.  So there's that.



But essentially her question was if the server she's currently using can decrypt the sessions at will.  I think what Jay was asking was whether - it sounds like she was doing something of a personal nature at work, not on her personal time.  And he was suggesting that somebody like local IT could be monitoring her web traffic if she was not using an SSL connection.  So of course he's been listening to Security Now!.  Obviously he's a listener because he sent this to us.  So he knows that if she uses SSL, it'll create a secure connection to the remote server.  And of course that server decrypts it.  So the idea is that - I think what Jay was suggesting was that using a secure connection she could get out past the local network watchers, out onto the Internet, and to a remote server, where it would be decrypted.  And the point is that SSL is a point-to-point security, that is, a point-to-point encryption.  It encrypts it at your browser, and it decrypts it at its destination, whatever that is.  But at that point it's back in the clear.  So the server can certainly decrypt it.  It has to, in order to be able to provide the services that she's asking for through that encrypted tunnel.



LEO:  So in other words, yes, right.  So in other words you can't always use "S"; and even if you did, you couldn't always be safe.



STEVE:  Right.



LEO:  Unless you use VPN.  Or something.  That's why it's unclear.  Did he mean the server side?  Because if he means the server side, of course it's unencrypted then, otherwise they wouldn't be able to deal with you.



STEVE:  Yeah, I think - he says we both work for the government and are well aware of Big Brother watching us, which is why I said stick to personal time.



LEO:  Yeah.  So he means if you use it at work, can they see what you're doing, and the answer is yes, as we said before.



STEVE:  Exactly.  And so by all means, if that's a concern, try to add the "S," and you will get a secure connection if the far side is able to accept one.



LEO:  Right.  Dusan Maletic in Babylon, New York solves PC tracking mystery.  It comes as...



STEVE:  That was well done, Leo.



LEO:  It came as a surprise to me that the last question addressed in Episode 118, while partially answered, did not lead to the discussion about Flash cookies, particularly as I first learned about them during an earlier Security Now! episode - hey, we know so much that we forget things - and that info provided then answered identical questions I've had in the past.  It turns out that three out of three financial institutions I use online plant Flash cookies - wow - to track users' status, including BofA.  I hope many other listeners alert you to this, leading to a good discussion of such semi-hidden techniques which are important for computer security in general.  I'm particularly angered by this practice as the designers obviously have chosen an object poorly understood, if at all known to most of the public, and have not disclosed it to the users in clear manner.  Well, fooled me.  Typical spyware-like methods deserving critique and raised alertness to it.  So that's interesting because remember I went through this whole rigmarole where I turned off cookies and stuff and so forth and so on, and it needed to be - I determined it was cookies.  But maybe it is Flash cookies.



STEVE:  Well, and maybe - you and I talked about this, we've talked about it before here.  We also did a whole session on it when you and I were in Toronto a couple years ago and showed the viewers of your Call For Help show where to go and how to turn these off.



LEO:  Which I'd completely forgotten.



STEVE:  So I wanted to mention that to everyone who's listening because many people wrote in having done this experiment.  They deleted their cookies, they emptied their browser cache, they shut down their browser, they rebooted their computer, they took their laptop to somewhere else, and they were - and literally at least 40 people wrote in and said, "It still knew me.  How did it know me?"  And so I appreciated this confirmation that this use of Flash cookies is becoming more widespread, clearly in this case, as he says three out of the three financial institutions he used plant Flash cookies.



So to all listeners, into Google you want to put "Flash player settings manager."  Just put in "Flash player settings manager," and you get a link to Macromedia, maybe it says Adobe now, I'm not sure, I don't remember whether they've changed the URL.  But the point is, most of us have Flash loaded in our machines now, which unfortunately is why the banks have all started using it.  It's something that survives, as many listeners have discovered, it survives casual cookie deletion.  And exactly as this guy has mentioned, it annoys him because it is unknown and is unclear.



The good news is, it's possible to control these settings and to prevent sites from using Flash cookies if for some reason you really didn't want that, or to restrict sites that you have specifically allowed.  Anyway, there's good Flash cookie management available, and it's a web-based interface.  You don't use your local Flash player, running it like standalone, because it is an embedded web page object.  Instead, if you put in "Flash player settings manager," that'll take you to the Flash site, where you're then able to go to some web pages to bring up a little tabbed interface.  Basically it runs your Flash player on the page and gives you access to a user interface you never knew you had.  And you're able to browse through and see the domains that have registered cookies on your machine.  You can delete them right there.  You're able to change settings.  You're able to do some worrisome things, like you can tell it don't ever turn on my microphone and camera without letting me know.  It's like, okay, well, that's probably a good thing to tell it.  So you're able to do that and a number of other things.



So again, "Flash player settings manager," and poke around in there.   You'll find out who has stored cookies, so you know.   You're able to delete them.  You're able to then block them and prevent them from changing.  Anyway, there's a whole bunch of tabs and settings that are definitely worth poking around in.



LEO:  I don't see Bank of America in my cookies, however, so I don't know.  Maybe I'm special.  And wouldn't you need to see - wouldn't you see somewhere that Flash was running?



STEVE:  You don't see it.  It's completely done behind the scenes using JavaScript.



LEO:  So you can uncheck the box that says allow third-party Flash content to store data on your computer.  It doesn't - JavaScript doesn't even have Flash going.  Wow, that's interesting.



STEVE:  Now, is there a chance you would have changed these settings in the past?



LEO:  Yes.  Oh, of course, I had set it storage to zero.  But there's more than that.  You also probably want to deny all cookies and so forth.  But then you have the same problem denying cookies on a browser, as well, which is that some sites don't like it.  I see, I'm looking at the sites that have placed cookies on, you know, visited websites.  And they're all, you know, they're mostly sites that do Flash media in one way or the other, like YouTube and Blip TV, Ustream.  I don't see my bank.  So I don't - anyway, I don't know.  Twitter uses it for some reason.  That's interesting.



STEVE:  My guess is that the banks probably issue standard cookies and Flash cookies.  They probably just throw as much state...



LEO:  As they can.



STEVE:  I'm sure they do.  They throw as much state at you as they can, and anything they get back helps them to recognize you.



LEO:  Right, which is fine.  And in that case I want them to have some sort of way to recognize me.



STEVE:  Agreed.



LEO:  Interesting.  Thank you, Dusan, for that.  Now, where did the questions go?  Oh, here they are.



STEVE:  They got buried under your Flash browser.



LEO:  800 pages of browsers.  Dan in Needmore, Pennsylvania needs more help with his PayPal token:  Hi, Steve.  Just heard you mention the first number on the PayPal security fob increments sequentially.  I tried mine; it doesn't.  First digit was a two, second a five, and third a nine.



STEVE:  And I'm reading it, and I'm thinking, oh, no.



LEO:  What?



STEVE:  And then he said...



LEO:  These attempts were several minutes apart.  So you have to do it one after the other.



STEVE:  Exactly.  I wanted Dan to know, to put his mind at rest, that the digits are changing, even if you're not seeing them.



LEO:  Every 30 seconds.



STEVE:  Because - exactly.  Because the football, as we fondly refer to it, unlike the credit card, the VeriSign credit card, the PayPal/eBay/VeriSign football is clock based.  So those digits are changing, cycling 0 through 9, the first digit, 0 through 9 and back again as we were talking about before, whether you're displaying them or not.  So...



LEO:  So you just have to keep pushing it every few seconds to really...



STEVE:  And catch it across those 30 second boundaries.  And then you will absolutely see this thing incrementing sequentially.



LEO:  Yeah, makes sense.  James Kilner in Israel has a correction, and then needs a suggestion.  Steve, Leo, you're wrong about the use of the Firefox master password.  I was listening to you talk on the Tech Guy radio show, #403, podcast version, about Firefox's master password.  What caught my ear in particular was you claimed that this password can be subjected to a brute-force attack, so you should make it long and make sure it uses different types of characters.  You then said you'll only ever need to type it in when you want to view all of the stored passwords.  That's wrong.  No, no, you didn't say that.  I would have corrected you on that.



STEVE:  Yeah, I didn't think I said that.  But I thought, oops, if I did, then we want to make that a correction for the record.



LEO:  I enter it every time I launch Firefox, or actually every time I launch Firefox and then go to a page that needs a password.



STEVE:  So does this guy.



LEO:  Yeah.  I use Firefox to store my passwords, for example, for Gmail, so I don't have to remember them all the time.  That's the point of being able to have Firefox remember your passwords.  When I start up Firefox in the morning and load up Gmail or any other site that has a password stored, I have to type in the master password.  Right.  Me, too.  If I have to close down Firefox for any reason, for example, it's leaking memory again, and then restart it, I have to put in the master password again.  So it's not as simple as you suggest to just make the password something really long and difficult to brute force because you'll only have to use it to view all the passwords.  That's not the case.  Can you suggest a way to store a long password securely so I can copy and paste it in on a regular basis?



STEVE:  And that's why I really put the question up here, because I first wanted to correct the record, if I had said that you only needed to type it in in order to see all your other passwords.  But also because he asked an interesting question.  How could he have, for example, one of those nasty passwords from GRC's Perfect Passwords page, and store it on his computer, yet still use it, because he wouldn't want someone to discover that.  Well, one thing you could do is you could look at that wacky-looking thing, which is impossible to memorize or do anything with, and find something in it that is memorable as a split point.  And when you - so essentially you store it that way, but you enter it in a different order.  You take that split point and copy, like, the last X characters of it.  Maybe it's got, like, an exclamation point pound sign, and that's memorable to you.  So you do it from the pound sign to the end and paste that in, then do it from the front of that wacky password to the exclamation point, that is, do the front portion, and then paste that in second.  So essentially you've taken - you've cut it at some point, and you reversed those pieces.



Well, that means that anyone who got that password from your computer first of all has no idea that you're a person who does this, nor whether you chopped it in one place or in two places.  And if they tried to use it with Firefox as is, it wouldn't work.  You have some way of mutating it so that it does.  Or you could just add a couple of your own characters to the end of it or in the middle or wherever.  So you take something like that, which is already absolutely strong against brute force, and change it some way.



LEO:  Yeah.  I just, you know, I just have one that's hard to brute force but easy to remember.  It's possible to create those, as well.



STEVE:  Yeah, for example, many people, after we were originally talking about passwords, said what about the first letters of the lyrics of a song that we like.



LEO:  Right.



STEVE:  It's like, yeah, there's a good source of a pseudorandom character stream which nobody else would be able to guess, but which you can, by running the lyrics through your mind and typing the characters as you say them, you can reproduce the password.



LEO:  You create the string algorithmically, and you can remember the algorithm because it's simple.  Another one I've heard before, but don't use, is you do the first initials of the last - the initials of the last name of the 10 presidents, capitalizing them if they're Republican.  Something like that, so you know.



STEVE:  Well, that would lock me out.  I'd have to figure out...



LEO:  You'd have to remember it.



STEVE:  I'd have to get a paper and pencil.



LEO:  You start with Nixon.  So capital N, go to capital F, and then a lowercase c for Carter, and then a capital R for Reagan, and then a lowercase c for Clinton.  Oh, no, I left out a Bush in there somewhere.  There's a B, and then a lowercase c - capital B, lowercase c.  So that would work.  You'd have to...



STEVE:  And the problem is, if this election goes the way we're thinking, it's always going to end up with a BcBc.



LEO:  BcBcBcBc.  That's a good point.  Didn't think of that one.  Let us move on to question 11, and then we're going to take a break before our special question, our brilliant idea of the month.  But first, Jeff in Manila in the Philippines and many others have been paying close attention:  Steve and Leo, quick question regarding the Buffalo wireless router that Leo and Paul discussed on our last episode, actually two episodes ago, of Windows Weekly, the Zune episode.  Leo suggested getting the Buffalo router since it supports both WEP and WPA because the Zune 30, the old Zune, doesn't support WPA.  From my understanding of previous Security Now! episodes, WEP is just as good as not employing any sort of protection on your network.  Wouldn't the WEP part of it be a vector for attack and eventually compromise your network, even if you had WPA on?



STEVE:  And I think he's probably right.



LEO:  No, no, because these routers are designed to segregate the two.



STEVE:  They are for sure?



LEO:  Pretty sure.



STEVE:  Okay.  Well, I didn't know.  And so many people also wrote in about this.  Many people said, wait a minute, you know...



LEO:  You'd want to make sure, obviously, that the WEP network was as if it were a separate network, didn't give you access to the full network, just to the Internet.



STEVE:  And that's my problem, is that I would think, I mean, we've talked about relatively sophisticated active attacks, for example, ARP spoofing, where if you were able to get access to WiFi, then you could fool the other machines on the network into believing that your machine was the gateway and route all the traffic through you.  So I'm worried that the WEP leg might just be on a switch in the same way that the WPA leg would be, and that they may...



LEO:  That would be sufficient, huh.



STEVE:  ...really be - yeah.  So I think I'm going to have to pursue this because, I mean, so many people were interested that it's worth me tracking down a Buffalo router that has this and do a little research because...



LEO:  There are a couple of routers designed for this situation, where you have some devices that are WEP only.  And I just assumed they did it the right way, but that was probably a mistake.  I should probably find out.



STEVE:  In any event, it's certainly the case that you wouldn't want to leave WEP on all the time.  So unfortunately somebody who's a Zune user, like a first-generation Zune, who needs WEP all the time, would tend to have it on all the time.  I was originally discussing this as a solution for what if your friends came over, and they had a laptop that didn't support WEP, how would you let them in without having to give them your precious WPA password?  It's like, okay, you can have it on for a while, that reduces your window of exposure.  But again from an absolutely how-strong-can-we-be security standpoint, all the people who wrote in about this question are correct because, if the router allowed the WEP network to touch the WPA network, all bets are off.



LEO:  Right.  They have this One-Touch Secure System.



STEVE:  Right.  That's I think their acronym and their...



[Talking simultaneously]



LEO:  Yeah.  I'm reading the specs, trying to figure out if it talks about that, but it's not clear.  When two or more AOSS clients attach to the AOSS network, the client router automatically negotiates the highest level of security the router can support.  So if one supports WEP and the other WPA, it automatically adjusts the security to a level both clients support.  See, that's not it, then.



STEVE:  And in fact, what that sort of says is that it will lower the security of your network to the lowest encryption that any given device is able to have.



LEO:  Right, lowest common denominator.  But that stinks.



STEVE:  And Leo, it must be in fact that these networks are together because who would, you know, if you Zuned, if you use Zune over WEP to get to your router, the point is you want to then get to your server where all your Zune music is stored.



LEO:  See, I was thinking it was - ah, right.  I was thinking it was like having two routers, where one was set for WEP, and that was then bridging to a WPA router.



STEVE:  It would be nice if it were so.  But to me it sounds like it's not because, you know, you're going to want to be able to get to any other machine in your network.



LEO:  Right.  Well, if you want to do that, you're right, you're absolutely right.  If the Zune needs to then get to a PC, you couldn't do it that way.  I was just thinking, oh, it gives something like a Nintendo DS access to the Internet without giving it access to the subnet, but apparently that's not the case.  It sounds like it lowers, no, I'm reading the specs, it says specifically it lowers the security of the network to match the new thing.



STEVE:  Well, I'm sure on a device-by-device level, so that - and that's really the cool part of this is that a given laptop...



LEO:  Yeah, because it couldn't change the WPA.  If it's a WPA laptop, it's not going to change it all of a sudden to WEP.



STEVE:  Exactly, exactly.  So it's able to establish individual encryption links at the highest encryption level that each device can handle.  The problem is, you bring one WEP device in...



LEO:  That's a vector.



STEVE:  Exactly.



LEO:  An attack vector.  All right.  Coming up in just a bit, Ernie Moreau from Kelowna, B.C., with a Clever Observation of the Week Award.  Are you ready for the last question?



STEVE:  Absolutely.



LEO:  The last question.



STEVE:  The last observation.



LEO:  It's not even a question.



STEVE:  Not even a question.



LEO:  Ernie Moreau in Kelowna, B.C. wins the Clever Observation of the Week Award.  He says:  In Episode 118 James Earl Ford from Apple Valley mentioned the following:  BioPassword offers the only multifactor authentication software that combines a user's login credential, you know, the login and ID and password - login, ID, and password - with the behavioral biometric of keystroke dynamics, that is, your unique typing rhythm.  I just wanted to mention, this sounds great until keystroke loggers become more sophisticated and also log the timing.  Then you're hooped.  Good point.



STEVE:  That's right.  We are seeing serious evolution of technology in keystroke loggers.  I've been noticing some reports out on the web that this notion, remember we talked about keyboards, clicking on keys and having the keyboards jump around the screen so that the coordinates were different?  Well, it is absolutely the case that keystroke loggers are now being found on machines which take snapshots of the screen and are specifically designed to literally do as good a job as the designers can of capturing the login experience.  And so if they don't already log timing, and if timing with this biometric keystroke dynamics, which I'm still sort of skeptical about anyway, if that ended up being a popular thing to do, well, they're certainly capable of logging the timing on the client side and reproducing the timing when they want to pretend to be somebody that they're not.



LEO:  Well, there you go.



STEVE:  I just thought that was a clever observation.  And Ernie wins the Clever Observation of the Week Award.



LEO:  Now, how do people, if they want to ask questions for next time or make suggestions or make clever observations, how do they do that?  I forgot.  I have no idea.



STEVE:  No, it's GRC.com/feedback.



LEO:  There you go.



STEVE:  That'll take you to a page where there's a form, you fill it out, and it comes to me directly.



LEO:  And of course GRC.com is a great site to remember for a lot of things:  Steve's vast array of free security software, including ShieldsUP, the most trusted firewall test, absolutely free.  You get all kinds of programs, including demos of his PPP program, Perfect Paper Passwords.  It's all at GRC.com.  You also can get 16KB versions of this show.  That way you can share it with your bandwidth-impaired friends.  And transcripts, which make it a little easier to follow.  You can read along or get in bed and read.  Put it on your Kindle.



STEVE:  Yes, in fact we should mention that you and I have both ordered the new Amazon Kindle.



LEO:  I resisted.



STEVE:  Yeah, you tried.  I didn't.  I just went right for it because I've got to mess around with this thing, see what it's like, how it works.  So we'll probably have some impressions to share in two weeks when we record our next episode.



LEO:  Not even that long.  Who knows, maybe even next week.  You know they're back-ordered.



STEVE:  No kidding.



LEO:  Oh, yeah.  I'm not going to be able to get mine until early December.



STEVE:  Yay.  Oh, I'm sorry, don't...



LEO:  Did you just say yay?



STEVE:  Well, no.  What I was going to say was I got confirmation that mine has been shipped, so...



LEO:  Yeah, I should have ordered it sooner.  And I know Amazon, that they often under-promise and over-deliver.  So they say December 3rd, but I may have it before the next, well, December 3rd would still be before the next episode.  You know why I succumbed?  I don't like the form factor.  I have a Sony, the newest Sony Reader, as you do.



STEVE:  Well, it's the ugliest looking thing I've ever seen, Leo.



LEO:  Yeah.  Same screen, too, although it isn't exactly the same.  Fewer shades of gray may make it crisper, I don't know.  I'll be interested.



STEVE:  That's a little worrisome, actually, because the original PRS-500, the first Sony Reader, it had four shades of gray.  I hope that this thing didn't get locked in with the previous Sony style screen, or we're not going to be happy.



LEO:  No, we will not.



STEVE:  Because the 505 is a much better screen on the new Sony.  And I read with it every morning.



LEO:  The thing that's put me over the top, I get several newspapers.  I get The Wall Street Journal, The New York Times, the San Francisco Chronicle.  That's a lot of papers stacking up.



STEVE:  You stay so connected.



LEO:  Well, that's part of my job.  But it stacks up, and I'm killing a lot of trees.  And you can get all those cheaper on the Kindle, automatically delivered every morning.



STEVE:  I just hate the ink rubbing off on my hands with newsprint.



LEO:  Well, there's things I could do with newsprint, like clip things, and I don't know if I'll be able to do those with a Kindle.  I'm very interested if I can somehow bookmark or somehow clip this content.  You know you can email me your PDFs from now on on the Kindle?



STEVE:  Ooh.  Although I get charged 10 cents, I think.  And I don't think PDFs transfer very well.



LEO:  Say Word documents.  And so maybe they don't want to send PDFs.  You have to Mobi-ize them.



STEVE:  Exactly, exactly.



LEO:  I subscribe to a couple of newspapers - Salon, which I'm a premium subscriber to anyway.  Just because it would be nice to be able to consume that content.  I think the wireless is the key.  I may use the Sony for books and use this for ephemera, for content.



STEVE:  Well, again, the idea of wireless where you subscribe to blogs or newspapers or something, and it just all is in there, I think that's very cool.  And the fact that you have - they did it right from a hardware standpoint.  They're over on Sprint's network with EVDO, which is much better bandwidth than unfortunately the iPhone, which is over with AT&T and the Edge network, which does not have the bandwidth performance that EVDO...



LEO:  Although these files aren't that big.



STEVE:  True, in fact that's absolutely the case.



LEO:  It doesn't really matter.  But anyway, they did a deal with Sprint.  And there's no extra charge for that, which I find interesting.  I guess it's built into everything you buy because everything you buy is copy protected and costs something.



STEVE:  Yeah, well, I also bought the same book, both for the Sony 505 and for the Kindle, so that I'm able - I'll be able to do some side-by-side comparison of how the books look.



LEO:  You are dedicated.



STEVE:  So, yeah, well, I just love - I love the eInk format.  I've been an eBook user forever.



LEO:  Yeah, we're early adopters on this.  I mean, I know most people - somebody told me, I think Scott Bourne told me that the Sony eBook Reader has only sold in the tens of thousands of units.  It's not a huge seller.



STEVE:  Yeah, and I'm not surprised.



LEO:  No, it's a specialty.  And I wonder if Amazon, I mean, it's gotten so much attention for the Kindle, I wonder if it'll break through.  I have a feeling it will not.  It's the kind of thing I think that's going to be gathering dust on a lot of people's shelves.  But you and I both do use these eBook readers, so if it works for us - anyway, we'll have a review next week.  At least you will.  Mine might not be here yet.



STEVE:  I'll wait for you, Leo.



LEO:  No.  I don't mind.  GRC.com is also the home of SpinRite, everybody's favorite hard drive recovery and maintenance utility.  It is a must-have.  If you've got hard drives, you need SpinRite.  GRC.com.  Steve, have a great week.  We'll be back next week.  Who knows what we're going to be talking about?  It's a mystery.  Do you know?



STEVE:  To me, too.  Oh, I have a list here of topics we'll be getting to very soon, so I'll choose one.



LEO:  We'll choose one.  Maybe it'll be the Kindle, who knows.  We could talk about the DRM they're using.  That might be an interesting security issue.  And also how soon before I start getting spam at my Kindle address.



STEVE:  Oh, yes.  How soon before the Kindles get hacked.



LEO:  That'll be interesting.  Thank you, Steve.  We'll talk again next week.





Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#121

DATE:		December 6, 2007

TITLE:		Is Privacy Dead?

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-121.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo take a break from the details of bits and bytes to discuss and explore the many issues surrounding the gradual and inexorable ebbing of individual privacy as we (consumers) rely increasingly upon the seductive power of digital-domain services.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 121 for December 6, 2007:  Is Privacy Dead?  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now! with Mr. Steve Gibson, the guru of technology and security and privacy.  Hello, Steve.



STEVE GIBSON:  Ah, Leo, I think after, well, we're in our third year now.  You and I have known each other for decades.  You can drop the "Mr."



LEO:  Decades.



STEVE:  Ah, yes.



LEO:  Decades?  Is it really...



STEVE:  Has it been decades?



LEO:  Well, yeah, Tech TV was launched, well, we have the 10th anniversary of Tech TV is in May.  Almost a decade.



STEVE:  And of course we knew of each other well before that.



LEO:  Oh, well, you're world famous.  The creator of the Apple II light pen.  Many don't know that.



STEVE:  Ah, yes.



LEO:  And then SpinRite, of course, has been going - how many years old is SpinRite?



STEVE:  SpinRite is 20 years old.



LEO:  Whoa.  Really.  Wow.



STEVE:  Yep, it's - I guess not quite.  Sue, who's been with me for seems like forever, this month she celebrates her 20th anniversary in my employ.  And my tech support guy, Greg, sent me an email, like, last week, saying, hey, just didn't know if you noticed it, but I've been with you for 17 years.  So that's stability for you.



LEO:  Yeah.  And you know, I think a lot of software vendors might not say - might not trumpet the fact that they've been around for two decades.  But you are on Version 6, and you have been updating it.  And in many ways I think because how hard drives operate really doesn't change that much, right, I mean...



STEVE:  Well, exactly.  I think the issue is that I really went down to the fundamentals with SpinRite.  And those haven't changed.  And you know, god knows drives have gotten insane.  I will never forget when I sent my lead tech guy out to get a bigger drive for our server.  And he went off to Fry's, our local electronics retailer.  And he came back, and we thought maybe, oh, wow, you know, could it be 800 megs?  That would be so much more than we have now.  I think we probably had, like, 120 or something.  And he came back with sort of a sheepish look on his face.  And he says, I hope this is okay.  And I said, what?  His name was Jim Ralph.  And he said, well, I got a gig.  I said, a gig?  I mean, no one had ever seen such a thing, a gigabyte.  It was like one of the full, five and a quarter inch, full height drives with a huge tower of heads inside, just crammed with platters in order to get a gigabyte.



LEO:  Amazing, amazing.



STEVE:  So it's like, whoa, times have changed.  But SpinRite, as we know, has kept up with it.  And but still the fundamentals of drives have not changed.  So all that has remained the same.



LEO:  It's pretty amazing.  Yeah, I remember very well my first 20MB drive.  That was a big deal, when they went to MFM.



STEVE:  Well, in fact I think that was in my first XP, a real steel tank IBM XP, had 20 megabytes.  It's like, oh...



LEO:  XT.



STEVE:  Oh, sure, right, XT, of course.



LEO:  And I think that was an extreme, or extended.  That was the one that went - because the first IBM PC had a 4.something 77 MHz processor.



STEVE:  4.77 MHz, 8008 processor.  And a cassette interface.



LEO:  No drives.  Not even a hard - not a hard drive, not even a floppy.  And then the XT was the first with a hard drive.  And then the AT was 286, wasn't it?  I'm trying to remember now.  We'll get emails...



STEVE:  Yeah, the AT, the Advanced Technology.  It was a PC/AT, and that was a 286.



LEO:  I think that was 8 MHz.  And then if you got a clone AT, I remember we got clone ATs that were, ooh, 10 MHz, but they were very unreliable.  They couldn't - the memory couldn't keep up with the processor.



STEVE:  Right, they were sort of being overclocked.



LEO:  They were basically overclocked.



STEVE:  Well, it works.  And then, of course, the clone market happened, and Asia got involved.  And so things really went wild at that point.



LEO:  We were trying to run a BBS, I set up a BBS for one of the first Mac stores in San Francisco.  And it just was horribly unreliable, and it's because we put it on a 10 MHz processor, an AT clone.  And now in retrospect I know exactly what was wrong, we were overclocking the thing, and we weren't - it just was failing all the time.



STEVE:  Right, and there were all kinds of third-party tools that were like, you know, they were called the "overthruster" and the "overdrive" and all kinds of, I mean, literally with a potentiometer, you know, a dial sticking out the back.



LEO:  You'd turn it up.



STEVE:  You'd turn it up until the machine locked up and stopped working.  And then you'd back it off a little bit.  Oh, I mean, it was the Wild, Wild West back then.



LEO:  Man, it was funny.  Well, we're going to come back to the 21st century now.  Although some day I really want to do, maybe get together a number of people like you with histories going back that far and do a computer history show.



STEVE:  Jerry Pournelle would be perfect, too.



LEO:  Pournelle, yeah.  Wouldn't that be fun?



STEVE:  And Dvorak.  It really would be, just a nostalgic, old cranky old men, this is the way things used to be.



LEO:  Yeah, we'll do that.  I've always wanted to do that, yeah.



STEVE:  You know, speaking of contemporary stuff, I forgot to ask you when we were talking before we began recording, did you get your Kindle?



LEO:  Not yet.  Did you get yours?



STEVE:  Oh, yeah.



LEO:  Mine's supposed to come today or tomorrow.



STEVE:  Okay.  Well, we'll wait to talk about it until you've had some experience with it.  I really...



LEO:  Are you happy so far?



STEVE:  I really - I'm addicted.



LEO:  I would like to wait, frankly, because I think the best thing to do on something like this is to give it a few weeks.



STEVE:  Yes, I agree.



LEO:  So maybe after the holidays because we're going to be pretaping a lot of shows over the next week or so.  But maybe after we've both had time.  I'm going to probably take it to Egypt and really have an experience with it.  Maybe early next year we can talk about the Kindle.



STEVE:  Yeah, that'd be good.  I wanted to use the power of the podcast to ask our listeners, if they are Amazon users, to check out my review, which is online, and give it a thumbs-up if they think it's worthy because there are - what happened is, the Kindle, if nothing else, is incredibly controversial.  It's just phenomenal how many people hate it without ever using it or seeing it.  And so if you look up the Kindle on Amazon, there's more negatives, that is to say, one stars, than there are five stars; yet none of the one-star people own it or have ever seen it or used it.  They just know they hate it.  And so anyway, what I did was I created a simple URL for our listeners, if they'll just go, use a web browser, and put in snipurl/skr [snipurl.com/skr], stands for Steve's Kindle Review, that'll take you to my review of the Kindle, what I think about it, what I think it means.  And the problem is there are already so many, and I'm late in the game because a lot of beta testers were sticking reviews up, that no one is seeing mine.  So I'd love it if our listeners would put in snipurl/skr [snipurl.com/skr] for Steve's Kindle Review.  And much as they were able to vote this podcast the #1 Technology and Science Podcast, it would be really cool if people would say, yes, this review was useful to me, which would raise its score so that people who are actually considering buying a Kindle might have a chance to find mine.  Because right now I'm, like, down on the fourth endless page of reviews.  And...



LEO:  Well, it won't be too long because it said now 248 people have found this review helpful, so...



STEVE:  Except that 2,800 and some odd have found other people's reviews helpful.  The reviews have been there for so long.  And mine, you know, I waited until I owned it.  And as you suggested, I waited a week of using it and really got a sense for how it is and compared it to the other eBook readers and so forth.  So anyway...



LEO:  I don't see how to vote on...



STEVE:  It's down at the very bottom, at the bottom of the review.  There should be a, yes, I found this helpful.



LEO:  And each comment it says - oh, no, that's the comment.  Oh, I have to go to page 2.  You have two pages of...



STEVE:  Wow.



LEO:  Was this review helpful to you?



STEVE:  There it is.



LEO:  But then it doesn't give me anything.  It just says report this.  Maybe I'm not logged in?  No, I'm logged in.  Anyway, I'm going to vote for you because you obviously put a lot of thought into this.



STEVE:  Thank you.  And 248 or 58 or however many people have also found the button to say yes, it was useful, so it must be there somewhere.



LEO:  Apparently I'm not smart enough.  Or my browser, I'm using Safari, maybe my browser isn't smart enough.  Anyway, that's, yeah.  And again, I want to kind of give it a long chance.  Now, you and I are kind of - the other thing is, you and I are avid eBook readers, so...



STEVE:  And that's, yes, that's the way I...



LEO:  We're an unusual crowd.



STEVE:  Yes, that's the way I start out.  I explain who I am and that I really want it to be a good thing.  I want it to work.  I want to believe, like in Tinker Bell, so her light gets brighter, I want to believe in eBooks and want them to succeed.  And I'm really happy with the Kindle, so.



LEO:  Great.  Let us move on to the topic at hand.  Now, last week we talked about third-party cookies, and particularly in relationship to this whole issue of PayPal and DoubleClick.  Have you heard from anybody from PayPal or DoubleClick?  I haven't.



STEVE:  Nope.  Not a peep.



LEO:  Not a word.



STEVE:  Not a peep.



LEO:  Not - isn't that weird.



STEVE:  Well, I just think, I mean, frankly, as we said, I guess it was, what, two weeks ago because we did a Q&A last week, my sense is that PayPal is a company desperately in need of competition.  They, I mean, they really have cornered the market.  And in my own endeavors to get any kind of contact with a human, it's just been hugely thwarted.  It's just impossible to find anyone there.  And I've heard, anecdotally again, from people, I mean, I've personally never had a problem using PayPal services of any sort, except that I would love to get that virtual debit card, and I can't because the automated process doesn't recognize me properly.  And I've tried several times, literally for hours, with my phone on speakerphone, on hold, trying to get a hold of someone.  And it's just virtually impossible to find a human being.  So, I mean, they're sort of a classic Internet service.  Unfortunately, you know, they're also a behemoth.  And for whatever reason, despite the fact that our podcast has proven reach, it didn't reach anybody at PayPal.  Or at least they didn't reach back.



LEO:  Well, maybe they didn't have anything to say.  Maybe they have no answer for us, you know?  Weird, just weird.  But, yeah, no, nothing from my half, my side, either.  Anything else you want to cover before we get underway here with our new show?



STEVE:  I did have and do have a really fun, this is sort of a different and humorous, even, SpinRite story to share with people.  It came in at the beginning of November from Thomas Martin, who said, "I've listened to so many people talk about how SpinRite has either helped them get lucky or saved the day.  My story is not as exciting, but it made me the savior of many.  I have a Generation 3 iPod that had..." - or he says, "I had a Generation 3 iPod that had a hard drive issue a couple of years back.  And I was so pissed, I actually made it a doorstop for my office.  Over time, all my friends and their friends started giving me their iPods that had stopped working due to hard drive issues.  Now, the funny thing is, over about three years I collected exactly 26 dead iPods."



LEO:  Wow.



STEVE:  "I had paperweights, bookends, doorstops.  It was just a running joke.  Considering how many episodes of Security Now! I've listened to, I should be slapped for not thinking about SpinRite sooner."  He says, "Recently with my  Generation 5 iPod I had Vista tell me it could repair the drive on my storage device.  Then synching failed.  At that time I was listening to you talk about how some guy got lucky dating a woman thanks to SpinRite.  Then it was like that light bulb went off.  I went..."



LEO:  Okay.



STEVE:  He says, "I went to GRC and purchased a copy during the episode.  And like magic, my Gen 5 iPod was working again.  Then I started looking around my office at all the bookends and decided to try it on them."  He said, parens, the iPods he collected from his friends.



LEO:  I guess once you, I mean, it's hard to get an iPod working with SpinRite because you have to get a connector and everything.  But once you do it once, it's easy because now you've got all the hardware.



STEVE:  You've got the cables and things.  He says, "Go figure, it worked time and time again.  I found myself over the next week calling friends and telling them their iPods worked.  Thank God most of my friends filled out owner information."  Funny, it's not until I'm just reading this now to you, Leo, that I realized what he meant by that.  That's how he was able to figure out who...



LEO:  Whose was whose.



STEVE:  Exactly, which iPod belonged to who.



LEO:  Otherwise they all look the same.



STEVE:  I guess now we've got iPods filled with oldies.   But anyway, he says, "Maybe I should have sold them all on eBay.  But my goodness, I felt silly having listened to you for this long and never drawing the relationship between SpinRite and my broken doorstops."



LEO:  Great story.



STEVE:  So I thought that was...



LEO:  Does he say how many total that he had, I wonder?



STEVE:  Well, yeah, he says he had 26.



LEO:  26.



STEVE:  26 dead iPods.  So he must have just had, like, an iPod circus in his office, with bookends...



LEO:  Interesting.  He was the one people went to.  I guess once you have the first 10, people start to recognize you as the guy to give your - I have a dead iPod.  If I had known, I would have given him my dead iPod.



STEVE:  Donate your dead iPods, and Thomas Martin will fix them for you.



LEO:  See, I know that SpinRite will fix this.  I know it's a hard drive thing.  But I just - it's the pain of getting all the, you know, the equipment and the connectors and all that stuff.



STEVE:  Yeah, well, and Leo, it's why I didn't own an iPod until they took the hard drive out.  Because it's just - you just, I mean...



LEO:  You know better than anyone they're going to fail.



STEVE:  I was going to say, no one knows better than I do how flaky spinning magnetic drives are, especially in a little consumer device that you're inherently going to sort of just toss around.



LEO:  Right.  Yeah, exactly.  And now, ladies and gentlemen, without further ado, let us move on to our topic of the day.



STEVE:  You know, I wanted to sort of address explicitly something that we've touched on tangentially many times, but you and I have never really discussed.  And I know you've got interesting and probably some strong feelings about the issue.  And that is the way technology is impinging on our privacy, I mean, to an increasing degree.



LEO:  Well, and this kind of takes off of what we were talking about with DoubleClick and PayPal.



STEVE:  Exactly.



LEO:  Because as you surf the 'Net you assume that there are some protections of your privacy.  But as it turns out, as we learn more and more, there aren't.



STEVE:  Well, and it's pervasive, too.  Certainly with computers we have the problem.  But even with more and more technology we're seeing an increasing level of, well, first of all, just sort of passive action, but then also increasingly aggressive action.  I mean, there was a funny episode of a TV show, it was a sitcom with Paul Reiser, I can't think of the name of the...



LEO:  Oh, I loved that.  "Mad About You."



STEVE:  "Mad About You."  Yeah, he and his wife, it was - actually I thought it was really very, very clever.



LEO:  Great show.  I enjoyed that show.



STEVE:  And there was one episode where he was really upset with his TiVo because, as he explained it to his wife, his TiVo had decided that he was gay.  And...



LEO:  And that, by the way, is a takeoff on a famous Wall Street Journal story, "My TiVo Thinks I'm Gay."



STEVE:  Okay.



LEO:  Yeah.



STEVE:  And of course so, you know, we know that TiVo, those users who have TiVo, it has this facility where you can give shows thumbs up and thumbs down, sort of basically rating shows that you like or dislike.  And the idea is that using sort of this network awareness technology that we're seeing more and more, sort of an early form of social networking, you'd be training your TiVo about the things you like, and then it would be recording things that are like the things, that it thinks are like the things that you like, based on some sort of networking model.  But the other thing that's going on, of course, and again, it's in the privacy statement as you go to the TiVo website, they tell you that everything you do with the TiVo is recorded.  They know when you fast-forward through commercials.  They know when you stop watching a show midway.  They know exactly what your season pass schedule is, that is, all the shows that you've elected to have TiVo record for you.  I mean, basically it's like having a Nielsen box sitting there watching everything you do.  And in issues of privacy discussions with people, they've said, yes, except that families who are Nielsen families, who are knowing that they're being monitored, they're being reimbursed for having themselves monitored.  Whereas with TiVo you actually pay a subscription fee in order...



LEO:  I can tell you, TiVo makes a lot of money selling that information, by the way, because I've seen those reports, and they have offered them, they offer them at Tech TV to us.  And they're very expensive.



STEVE:  No kidding.  So you've actually seen, like, that kind of data. 



LEO:  But, and I have to say this, and this is the case in a lot of these privacy invasions, it's aggregate data.  It's not about any individual.  I can't find out what Steve Gibson watches, TiVo [indiscernible].



STEVE:  Of course.



LEO:  But I can't buy that information.  But I can buy what everybody who watched the Screensavers - they gave us once a report for the Screensavers, and it's a graph.  You can watch how many times each episode, each part was rewound, watched, watched again.  There's spikes where people apparently rewind several times.  It's very, for a television programmer, hugely valuable.



STEVE:  Yeah, I can see that.  Now, of course, the problem is that TiVo does know me...



LEO:  They know.  You bet.



STEVE:  ...because, yeah, exactly, they know.  And as we know, unfortunately, anything that any company knows can be forced from them by subpoena.



LEO:  By government.



STEVE:  Exactly.  So again, clearly they're producing aggregate, anonymized summaries, which is all that anyone would want in general anyway.  And I can't imagine why it represents a specific privacy threat to me for Uncle Sam to know specifically what shows I'm watching.  And you can argue I guess maybe that, I don't know, do terrorists watch different shows than regular people?



LEO:  I think in the case of your TiVo, it probably isn't a huge loss.  But think about your library card or what movies you rent.  In fact, the Patriot Act allows the government to find out from grocery stores what food you buy.  And they've asked in the past, who's buying hummus?  And...



STEVE:  Well, yes.  And in fact I posted to our newsgroups that I was going to - I wanted to discuss this topic, and asked people sort of in general, are there any pet peeves that they have.  And there was a report from one of our posters who mentioned that his wife needed to do something, I don't remember exactly what the details were, but she was able to look up on the website everything they had ever purchased at the grocery store.  So, I mean, you know, that sort of data exists.  And I'm sure it's useful for improving the quality of their service at some level.  But it is there, and it's being aggregated.



LEO:  Do you have a grocery store club card?  There you go.  Every time you use it...



STEVE:  Yeah, it's funny, I spoke to some security conference years ago, and I don't remember now, I don't remember which one it was.  But I was followed on my talk by another privacy guy.  And, I mean, this was sort of at the rabid end of privacy, sort of an EFF sort of person, who literally told the audience and recommended that they do what he does, which is when he's in line at the supermarket, he turns to the person behind him and invites them to swap supermarket cards.  And he said, and I suggest you do this, and pass the idea along.  The idea being it's just...



LEO:  Screw with them.



STEVE:  It's completely, yes, it's completely scrambling up their database.  And certainly, if this thing were - if that were to become viral, and everyone were swapping cards with someone else, you can argue, okay, well, some of the same data is still being collected.  But there's certainly no longer any value to the idea that this person is buying this because there is no sense anymore of a certain individual there.



LEO:  Right.  Somebody told me that club cards, you can ask for the house club card, an anonymous - you can either get an anonymous club card, which you can always do, or ask for the house club card and swipe that one.  And apparently there's some sort of, because of privacy issues...



STEVE:  Oh, so there's a law that they have to...



LEO:  I think in some cases.  You should ask about that, yeah.



STEVE:  That does make sense.



LEO:  Now, an interesting point that many privacy, maybe kind of more equitable privacy advocates would say is, well, here's the deal.  If it's explicit, in other words, if a company says we're going to aggregate and sell your data, and the company offers compensation to you, something of value - in the case of a grocery store club card you get big, big discounts.  There's a real incentive to use them.  And as long as they're upfront with this is what we're doing, this is who's getting the data, and this is the, you know, we know you're giving us valuable information, so here's your compensation, what's wrong with that?



STEVE:  Right, I know, I completely agree with you.  I think there are a number of things, a number of perspectives into this.  There's the issue of the benefit tradeoff, disclosure, transparency, and control.



LEO:  Perfect, perfect.



STEVE:  And so for example you want to, for example, transparency is - I want access to the data that you have about me.  I want you to be transparent about what you're collecting, what you have collected.  And then the control issue is, and I want to be able to delete some of it that I don't...



LEO:  I love that.



STEVE:  ...that I don't want you to have.  I want to be able to make you either selectively or in whole forget what you know about me.



LEO:  And that's - I like that.  And of course, you know, also not only what you collect and give me control of it, but what you might be doing with it, as well, who you might be giving this to.



STEVE:  Ah, indeed.  And yes, repurposing of collected data is a real danger because you could argue that Company 

A is in a certain business, and its users, its customers have agreed to, you know, the general benignness of what Company A would do with the data that they collect.  But when Company B purchases Company A, who has a whole 'nother agenda, I mean, I think it's one of the reasons that people are very uncomfortable about the idea of Google purchasing DoubleClick.  It's like, okay, DoubleClick was sort of bad enough by themselves.  Google, I mean, search is another perfect example of knowledge-based aggregation because we know that Google is a rabid cookie planter.  They're planting cookies everywhere they can.  And they know about everything I search on.



LEO:  Boy, and we also know that even if they don't collect personal information, those searches in aggregate say a lot about you, as we found out when a reporter got that AOL search information and was able to track down the person based on the search information alone.



STEVE:  Right.



LEO:  Because it tells you so much about you in aggregate.



STEVE:  Yeah, I think that the other issue is what I call the "benefit tradeoff."  And, for example, I would argue that we TiVo users probably get very little benefit from the fact that TiVo is getting tremendous benefit from selling our data, except maybe that it's keeping TiVo from going out of business, and we'd like TiVo not to go...



LEO:  It's part of the business model, yeah.  But no, you make a point.  We don't get - otherwise we don't get anything out of it.



STEVE:  Right.  And as you were saying, the club cards give you a substantial discount.  So there's a substantial benefit being returned for our willingness to recognize that what we're getting in trade for that benefit is a discount, and that we're providing a benefit to the club.  Similarly, I find myself more and more using the fact that Amazon knows a lot about me.  The fact that TiVo knows a lot about me doesn't help me.  But using that networking model now, Amazon knowing a lot about me often is suggesting things that I find interesting.  It's like, oh, I mean, the whole idea of people who bought this book also bought these books.  And it's like, oh, look at that.  Well, that might be a book that I'm interested in also, or a service or whatever.  So, I mean, there I could see - it seems more transparent to me.  I'm acknowledging, I guess I'm implicitly assuming, because Amazon is being very transparent, if they say that people that bought or looked at these things that I'm looking at also looked at these, well, they're telling me that that data was aggregated about those people.  So it's obvious that it's being aggregated about me.



LEO:  Right.  Well, that's what they say.  You bought this, you might like this, as a result.



STEVE:  And the other thing, some - and I know that, Leo, you and I are about the same age.  Sometimes I'll go to get some, like, especially DVDs because I've sort of lost track of them all now, I mean, I have so many movies.  I'll go, I'll see something about a DVD, I go, oh, I've got to get that.



LEO:  And you already have it.



STEVE:  Yes.  Yes.  And it's so nice now because Amazon warns me, says, oh, by the way, did you realize that six weeks ago...



LEO:  You bought that?



STEVE:  You already bought this?  It's like, oh, gosh.



LEO:  That's nice.



STEVE:  You know, it's got to be around here somewhere.



LEO:  They have a new feature which allows you to publish publicly everything you've bought or some things that you've bought on Amazon.  And there's a social networking aspect of that.  And they give you the, you know, you have to opt in.  You have to explicitly say it.  I actually did it just the other day.  The thing is, Amazon also gives you a reward.  They encourage you, and this is a very smart move on their part, with this Amazon Associates.  In fact, many book authors make more money by selling their book through Amazon with the associates fee than they get from their publisher.  It's several bucks sometimes from Amazon when people click a link on your web page to buy a book.



STEVE:  Right.



LEO:  So Amazon is smart that way.



STEVE:  Well, another example of a concern that people may not be aware of is, for example, there is a third-party DNS facility.  We've talked about OpenDNS...



LEO:  I use it, yeah.



STEVE:  ...a couple times.  Unfortunately, their privacy statement has raised concerns among people.  Basically they're saying, if anyone asks us to let people know who's performed what lookups, we're going to provide that information.



LEO:  Anyone, or any government agency?



STEVE:  Oh, I'm sure government agency.  You know, someone gives them reason to compel them to turn over their logs, they'll do that.  Well...



LEO:  I'm sure your Internet service provide would do exactly the same thing.



STEVE:  Right, although our ISP would have to be filtering and explicitly logging our DNS lookups in order to do that.  OpenDNS is saying, yes, we're keeping logs.  And we're making them available if we need to.  So again it's - by aiming your PCs at a single DNS service, you're essentially telling them, based on your IP - and there is no cookie transaction, thank goodness, in DNS.  So it is purely IP based; although, again, by subpoenaing records from your ISP, all the IPs you've had and when you've had them can be known.  So again, it would be possible for a government entity to determine all of the websites that you have, you or your computer, has gone to during the window through which these logs are valid.



LEO:  Right.



STEVE:  So again, it's something that's happening to an increasing degree as we become more and more reliant on technology.



LEO:  And you know, this example of me releasing my Amazon information, I think some of us are just kind of accepting of the fact that everybody knows what we do, and aren't too shy about what we do.  But it's probably good to be aware of it.  Another thing that's concerning is that the Patriot Act allows government to ask for any of this information and prohibits the person they're asking from telling you, or anybody else, or going public in any way with it.



STEVE:  Well, and in fact I think that's one of the reasons - oh, relative to the issue of concern, what I have found in spending a lot of time over many years talking to people is there is really a spectrum of concern.



LEO:  Yeah, yeah.



STEVE:  There are people who just - who have given up.



LEO:  Well, I'm a public figure, so it doesn't - I have no privacy.



STEVE:  Well, exactly.  Or there are people who have just said, look, you know, I have no illusions about the fact that we're being tracked and watched and aggregated, and I have nothing to hide, so it's no concern for me, you know, that sort of person.  And on the other - there is, however, another end of the spectrum, which are people who, just for their own reasons, are really concerned.  I mean, they want the knowledge of what's going on.  They want the control.  And I think more on principle than anything else.  It's not that they're doing anything wrong.  They're just sort of, on principle they object to the idea that entities they don't know are profiting from the information being gathered, might do so, might be compelled to release it, I mean, they just don't like the idea, just sort of on principle as opposed to for some specific reason.



LEO:  Well, I liken them to you because, for instance, you will tell us about not using scripting, the absolute most secure way to be.  And many of us are not willing to trade the convenience.  I'm going to continue to run scripts because it's so convenient.  But I'm glad that people like you exist, and I'm glad that these hardcore privacy advocates exist, so that at least we are given the choice.  And that's the point, right?



STEVE:  Well, I think that's exactly right.  And relative to the Patriot Act, one of the concerns about technology and this database aggregation is that the Patriot Act, as an example, represents a dramatic change in policy that does affect, exactly as you said, Leo, it affects the nature of what can be done with the data, which is to say, five years ago when these things were going on pre-Patriot Act in the U.S., the bar was much higher for what a third-party entity like the government had to do in order to obtain that information.  But by a change in legislation, suddenly the laws have changed, yet the same kind of data aggregation that was going on then is going on now, yet it's far more accessible to entities that wish it, under terms that are much easier.  And as you said, under disclosure laws that prevent them from even acknowledging that they've been asked for this.



LEO:  Yeah, the secrecy scares me a little bit.  And frankly, that's the other side of it.  It's one thing if DoubleClick knows what I'm up to.  You know, I'm more worried about the government doing this.  I think that's the first step towards repressive government.



STEVE:  Well, and I have to say, I mean, yes.  I hate the idea that we're being, for example, spied on; that I might send an innocent piece of email that uses some hot keywords in an innocent context, and it's just going to set off some alarm bell somewhere and bring my email to someone's attention.  It's like, wait a minute, I'm doing nothing wrong, just I object to the idea that something innocent could come under scrutiny.  To me that seems to cross a line.  I'm not exactly sure how to describe the line that it crosses.  But it just - that bugs me.



LEO:  Well, you expect that.  If you live in China, you expect your government to be watching on you.  It's part and parcel of what the government does in repressive nations.  We live in a free nation where we believe that we have the right to certain privileges, including privacy.  Privacy may not be specifically in the Constitution, but I think it's accepted that it is one of our fundamental rights.



STEVE:  One week ago, or I guess it was last week, I'm sure you heard in the news that some wacko strapped a bunch of flares onto himself and went into one of Hillary Clinton's campaign offices.  And as I was listening to the news, I noted that they very quickly determined that he had purchased flares earlier that day.  And I was thinking, running through my mind as a security guy, it's like, okay, interesting.



LEO:  How did they know that?



STEVE:  They figured out, yeah, they figured out who he was.  And then was there an immediate pull of his credit card charges to determine what he had been doing in the recent past?  And it's like, okay, well, I don't know that that's the technique that was used.  But here we've got a guy, and it's really important to know whether this is really a bomb, if he just needs roadside assistance, you know, in a critical way.  And I guess I feel of two ways about that.  It's like, well, I mean, I'm glad that they were able to determine with some level of confidence that these were automobile flares, automotive flares, and not TNT that he had stuck to himself.  But you hope that some due process was in place that protects all of us from that kind of scrutiny.  And again, that the bar is high enough for the obtaining of that kind of information.



LEO:  Well, the CEO of Sun, Scott McNealy, very famously said, and it was some years ago, "Get over it, privacy is dead."  And I don't think he was talking about government privacy.  But it certainly has deteriorated even then, even since he said that.  And I think it's true that computers in many ways pose the greatest threat, computers and widespread Internet databases pose the greatest threat to privacy in our history.



STEVE:  Well, and even email.  Back in the old days, when you would type out a letter or even print it on your Series 1 HP laser printer, which predated the Internet, and you'd fold it up and stick it in an envelope, lick it, and off it would go, lick the stamp and so forth, I mean, your paper mail was probably private.  It wasn't guaranteed to be private, but...



LEO:  Well, it was by law, that doesn't mean somebody couldn't have read it.



STEVE:  Exactly, I mean, steaming open the letter is a standard mechanism.



LEO:  But that's a onesie-twosie, and that's what's changed in the computer era of they can scan this stuff en masse, they can scan it, as you said, for keywords.  They can watch us much more effectively than they ever could before computers.



STEVE:  Yes.  I think that's exactly the thing that has changed is that, as our lives have moved more into an electronic mode, I mean, what isn't online, Leo?  Frankly, I use my Visa card as cash.  I don't use cash, counting out change in my wallet any longer.  It just, you know, it's not as convenient.  Which means that there is a record of every single thing I purchase available from the people that I have my cards with.



LEO:  This is sometimes called your "data smog," or your "data trail."  And we all have one.  Unless you fall off, drop off the grid entirely, I don't know how you avoid that.  And I think, you know, this is a security show, but it really does - security and privacy are tightly linked.  I mean, one of the reasons you want to be secure is to preserve your privacy, one of the most important reasons.



STEVE:  Yes.  Well, I do know people, we've talked about this before, who routinely delete their cookies.  They understand about cookies, they delete them just as part of their process because they would just like to shed, even though the expectation is that this is anonymous, they just - they're people out on that end of the spectrum who just say I'm going to do what I can to shed this kind of surveillance.  I mean, they're probably people - another example is the electronic highway toll systems.  I have a little EZ Pass puck in my glove compartment.  And when I'm going to go on a toll road down here in Southern California, I'll stick it up underneath my window.  And it goes beep-beep when I drive through.  And so somewhere someone knows that I've just driven down the freeway at that point.  So again, there's an increasing level of this kind of surveillance, passive and active, just in our lives.  And even cell phones.  My cell phone is on all the time.  I carry it with me when I go out.  And presumably, based on which cell tower I'm nearest, it's pretty much possible to figure out where I am at any given point.



LEO:  Yeah, in fact the point I guess some people make is that it's not only the toll plaza that you go through, but in theory government could hide these receivers all over the place and track you in much more detail.  Not only do they know you went through the bridge at the toll booth, but they could know where you are every moment of the day.



STEVE:  So yes, so I'm sure there are people who don't carry cell phones because they're aware that it allows them to be located.  They will not take toll roads when there are alternatives...



LEO:  It's getting harder and harder.



STEVE:  ...because they would rather not feed that information.  They don't use TiVo because they don't want their television-watching habits...



LEO:  They don't use the credit cards.  They don't use the Internet.  They don't fly anywhere.



STEVE:  Yeah.  Yeah, you're right, Leo.



LEO:  Pretty soon you're living in a log cabin in Idaho.



STEVE:  Yeah.



LEO:  You're Ted Kaczynski.



STEVE:  I think that, in conclusion, it's the case that no modern lifestyle today can conveniently, as you say, be off the grid.  And the best people can do is to be aware of what's going on and decide where they fall in the spectrum of concern.  And that for people who are concerned, I would really hope that there is transparency and control that gives them control over this kind of aggregation.



LEO:  But again, maybe Scott McNealy wasn't so far off when he said privacy is dead.  But we certainly will do our best on this show to help you do what you can, at least in a reasonable, sensible way, to protect your privacy.  I don't think it's time to give up yet.



STEVE:  No.  And I don't want, I mean, I want the convenience of my Visa card.  I want the convenience of not having to stop for the toll booth when I go - and there's the alternative, too.  I mean, even though I've got the little electronic puck that bings when I go through, if I were that concerned, I could go through the manual side and throw coins into the fountain and have the arm go up.  So...



LEO:  Or put it in the Mylar bag when you're not going through the toll booth.  I'm sure people do that.



STEVE:  Oh, that's interesting, yeah.



LEO:  They give you that little Mylar bag to block it if you don't want to use it.



STEVE:  To block RF, yeah.



LEO:  Right, right.  Well, Steve, I hope we haven't brought people down with this discussion.  But I think it's important to talk about.



STEVE:  I think the goal was just to raise awareness.  I mean, again, we've said there's nothing we can do to really be functional in a contemporary, technological, connected society and avoid this kind of surveillance.  But again, it's a matter of the knowledge, you know, let people know what's going on.  They can decide where they fall in the spectrum.  And as you said, we'll give people tools to help them give them some control.



LEO:  A lot of security really is about privacy, after all.  If you want to know more, for instance, if you want transcripts, if you want 16KB versions for the bandwidth impaired, please go to Steve's site, GRC.com/securitynow.  GRC.com/securitynow.  GRC's a great place to go, though, for other things.  Steve has a whole array now, a complete toolkit of free security utilities, everything from ShieldsUP to Unplug N' Pray, Shoot The Messenger, DCOMbobulator, his new Perfect Paper Passwords, it's all at GRC.com.  And that's also where you'll find SpinRite, which is the best, bar none, hard drive maintenance and recovery utility, GRC.com.  Next week, questions and answers - your questions, Steve's answers.  Steve, is it too late - I guess it's too late for next week because we're going to tape that one ahead.  But if people want to ask questions for future shows, and I know you can't answer them individually, but where should they go?



STEVE:  Absolutely, I want to encourage people, I really have a good time reading through these things, and I get ideas for future show topics.  And of course that's where we get the content for our Q&As.  It's GRC.com/feedback.  So just anytime, GRC.com/feedback.  That takes you to a page with a form where you can anonymously or non-anonymously send me a note that I will receive.



LEO:  Nonamonomynous.



STEVE:  Yeah, I did look this morning because I pulled from the server the accumulated updates since the last time.  Just to give some people a sense for why they may not hear from us, or we may not read their question, I had 18,000.



LEO:  From what?  From just...



STEVE:  Just accumulated, 18,000 submissions.  Which is not to say I don't want more because, I mean, I really do want people to keep them coming as our shows raise questions in their minds, or life raises questions in their minds.



LEO:  Yeah, yeah.  But we, you know, and I say the same thing about my own email, I try to answer as much as I can.  And I have help, I've hired somebody to answer some.  But you can't always get a response from me, certainly not a substantive response, because I just get too much email.



STEVE:  Well, and one of the nice things is that there are many questions which come up again and again and again.  And so...



LEO:  We can answer those, absolutely, yeah.



STEVE:  Well, I'm able to see sort of a trend in questions, and then choose a good representative one for the Q&A.  So even though I'm not answering a specific individual's question, I've answered a question that has been asked ten times when I've been scanning them.



LEO:  Right.  Want to pass along a little holiday gift from us to you our listeners.  The folks at ScotteVest, and I know you know Scott Jordan, and you - do you wear any ScotteVest stuff?



STEVE:  I don't because it's so hot down here.  All I can think of is like the hoodies and things.  And...



LEO:  They have polo shirts.  You should look at the polo shirts.  They have stuff for men and women.  They do have great hoodies.  I wear their pants.  They have shorts, they have vests, they have jackets, hoodies, everything you could want, and it's all for geeks because it's got pockets galore.  Their patented PAN, Personal Area Network, that allows you to run the cords from your iPod or MP3 player or your phone through special channels in your jacket or your hoodie.  They even have hats that have a space for an iPod.  I'll tell you, this is a really great place, ScotteVest.com.  And our gift to you - thanks to Scott, by the way, for doing this - is 20 percent off anything on the website if you use my name, Leo, when you check out.  That's the coupon code, LEO.  So thank you, Scott, for doing that.  Some part of the proceeds goes to TWiT, but it's also a gift to you guys.  20 percent off anything on the ScotteVest site.  Does not include TWiT merchandise sold from ThinkGeek.  That's a separate deal.  But anything sold on the ScotteVest site.  ScotteVest.com, use my name, LEO, for 20 percent off.  Kind of a little way of saying Happy Holidays from TWiT and ScotteVest.



STEVE:  Very cool.



LEO:  Now, we're going to take a break, come back next week.  We're getting closer and closer to the holidays.  I should say Happy Hanukah to you.  It began this week.



STEVE:  Merry Christmas.



LEO:  Yeah, Merry Christmas is coming up.  I'm going to be in Egypt for Christmas.  But guess what?  We are not going to miss an episode.



STEVE:  That's right.



LEO:  I don't know how.



STEVE:  Actually I was just going to say, we're doing double episodes for the next two weeks and then cramming one fifth one in, just so that we can maintain our record of never having missed a week.



LEO:  Ah.  Never having missed a week.  That means we're going to tape five in the next two weeks.  But that's okay, we're going to do it.  Thank you, Steve.  Have a great day.  Have a great week.  We'll talk again next week on Security Now!.



Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#122

DATE:		December 13, 2007

TITLE:		Listener Feedback #30

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-122.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 122 for December 13, 2007:  Listener Feedback #30.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now!, the podcast where we teach you how to protect yourself, your security, and your privacy, as we learned last week.  Steve Gibson is here from Irvine.  Hi, Steve.



STEVE GIBSON:  Hello, Leo, great to be back with you.



LEO:  Good to talk to you again.  We've got - it's a question-and-answer session.  So we're going to do something fun this time, aren't we.



STEVE:  Well, yeah.  We actually had some great questions that I just really liked a lot.  And we sort of - we had a couple questions pulling up the rear that were really fun.  And the first one I ran across, I had to just call it the Horrifying Show-Stopper Question of the Week, which is our last one, #12.  And then someone had a great idea which I thought, well, this is the Great Tip of the Week.  And someone else had a really fun, anecdotal story about Perfect Paper Passwords.  So I thought, well, that's the Perfect PPP Quandary of the Week.  So those will be our final three, will be that little lineup.



LEO:  I like that.  That'll be a lot of fun.  And we don't have any addenda from our privacy discussion, except that I think we probably sent a chill down the spine of more than a few people.  But it's good to be aware of, and that's the point.  It's not that necessarily there's anything you can do.  And certainly are some things you can do, but ultimately you may not have a lot of choice without dropping off the grid.  But at least it's good to be aware of and make those choices where you can.



STEVE:  Exactly.



LEO:  Any SpinRite news?



STEVE:  I did have one real short little fun anecdote from a lifelong Mac user.



LEO:  Uh-oh.



STEVE:  And of course, you know, SpinRite - yeah.  SpinRite has always been PC only.  And in fact it's tied to the PC because it still uses the BIOS, the Basic I/O System, BIOS, that was part of the original IBM PC specification.  And of course the Mac, the Intel Macs, they use something called EFI, which it serves the same purpose.  That stands for Extensible Firmware Interface.  But the two are not compatible.  But anyway...



LEO:  There's no INT 13 call in EFI.



STEVE:  Precisely.  And believe me, SpinRite uses that like crazy.



LEO:  But there must be some comparable call.



STEVE:  Yes.  Well, I have to say there has to be, although I've never even gotten around to looking at it.



LEO:  And you'd better, because I think EFI is not something Apple made up, it's a Microsoft Intel specification.



STEVE:  That's exactly right.



LEO:  So eventually PCs are going to be using it, too, I guess.



STEVE:  There may be ultimately some migration.



LEO:  Although, you know, this is what keeps PCs from evolving is this install base, is all these people like you who've written to BIOS, and they can't change it.  So maybe they never do change it, I don't know.



STEVE:  So anyway, Phillip Shiver, he describes himself, he says, as a lifelong Macintosh user and PC technician.  "I want to say thanks for SpinRite.  When nothing in the Mac OS world can recover lost data..."



LEO:  That's true.



STEVE:  "...I depend upon any available PC and SpinRite to fix Mac drives."



LEO:  There's no analog to SpinRite in the Mac world.  There are data recovery utilities.  There are disk, you know - because SpinRite doesn't work at the file system level.  So there are file system recovery tools.



STEVE:  Correct.



LEO:  There are unerase tools.  But as far as I know, there is no disk-level tool like SpinRite on the Mac side.



STEVE:  He says, "I started using it at work in 1992 to" - so what's that, 15, 16 years - "to recover data on" - get this - "on full-height 5MB drives, and also from floppies.  And SpinRite has been making me look like a hero ever since.  No IT department or serious Mac technician should be without SpinRite in their toolbox."



LEO:  But you do need a PC to hook it up to.



STEVE:  Yup.  He says, "Now, if we could just get a Mac-bootable native version to enable the use of SpinRite for regular maintenance, my world would approach nirvana."  So his best regards, Phillip Shiver.  So for what it's worth - or, I'm sorry, Shivers.  Phillip Shiver.  Noted.



LEO:  Yes.  But there's nothing we can do.



STEVE:  Not at the moment, but...



LEO:  There's got to be an analog because of course that's what things like VMware and Parallels do is they map those INT 13 calls and other BIOS calls to EFI.



STEVE:  I'm sure there is.  And the fact is, with SpinRite 6, I removed a lot of SpinRite's BIOS dependence, but not all of it.  So I - it is in Assembler, so at some point, probably 6.something or 7, I will make that jump.  And it'd be really fun to be able to make a bootable ISO that just - from which you burn a CD, and it just boots on a Mac.



LEO:  Well, you do make one for PCs.



STEVE:  Yes.



LEO:  That's what the PC does.  But we should be cross-platform.  It should say, oh, it's EFI.  I'll do it this way.  Oh, it's BIOS.  I'll do it this way.  You can do that, Steve.



STEVE:  I can do it, Leo.



LEO:  All right, here's what we're going to do.  Anybody who has an easy way to map an INT 13 call to EFI, you know, one we do for EFI, send me an email, and I'll make sure Steve sees it.  You don't have to field these.  No, no, no, you don't have to field these.  But there's got to be somebody who's sitting there saying, well, is it just the INT 13 call or the other calls you need?



STEVE:  It's INT 13 screen and keyboard.  So it's...



LEO:  Oh, it's a screen and keyboard, yeah.



STEVE:  Keyboard, screen, and the drive.



LEO:  I'm sure the screen and keyboard's pretty straightforward.  I mean, they have a pretty good toolkit for on the Mac side.  And I used to write Assembly language code for the Mac using the toolkit.  So it's not undoable.



STEVE:  Yeah, maybe even a little translation layer, you know, [indiscernible] the drive or something.  Anyway...



LEO:  You would make a lot of Mac users very happy, Steve.



STEVE:  It'll happen.



LEO:  Really?



STEVE:  Oh, yeah.  But no one knows when.



LEO:  It may be your grandson that does it.  Okay, it's that kind of open-ended.  Shall we get right to the questions?



STEVE:  We should.  I did want to ask our listeners, if anyone had intended to go check out my Kindle review over on Amazon but forgot last week, I wanted to remind people that it's snipurl/skr [snipurl.com/skr], stands for Steve's Kindle Review.  I would love if people - if we could use the clout of the size of our listenership to help me boost this review up in popularity so that people can actually see it.  It's many pages down.  And the ones that were there first are the ones that typically get seen.  So there's really no way for an unseen review ever to get itself voted higher unless something like this happens.  So...



LEO:  And yours is very thoughtful, and you took the time to review it after you had used it for a week, unlike many of these reviews, some of whom have never used it at all.



STEVE:  Well, the reason I wrote this thing was that there were more people giving it bad reviews and one star than positives.  And none of the people with one star own it.  I mean, it's not like...



LEO:  It's like politics.  It was, like, political.



STEVE:  Yeah, it was like, well, I just know I hate this because it doesn't do, you know, HD-DVD.  And it's like, yes, that's not what it is.  It's an eBook reader.  So, I mean, there were just - it just drove me nuts that something which I think is going to change the industry is just getting panned by people who are posting reviews when they don't own it.  I mean, so it's not a review.  So anyway, I wanted to ask our listeners if they would go to snipurl/skr [snipurl.com/skr]...



LEO:  How did you get that special skr?



STEVE:  The snipurl.com site.  Oh, I wasn't saying dotcom, snipurl.com/skr.  It allows you - it'll assign you a random token, or you can give it one.  And if it hasn't already been used by someone, then it'll assign one that you provide.  So it's just - it's very handy because it allows you...



LEO:  I didn't know you could give it your own.  I thought you had to just take the random one it assigned you.  That's really great.



STEVE:  Isn't that neat?  Yeah, it's really nice.  So again, it's snipurl.com - I think I forgot to be saying dotcom - snipurl.com/skr.  And if you...



LEO:  I don't know if it's me, Steve, but I have tried now, and there is no button I can click to vote for you.  I see the text that says, if you found this commentary helpful, click the button below to help its ranking.



STEVE:  Could you have clicked already?  Because I think if you click it once, it won't allow you to do it again.



LEO:  Oh.  Well, I don't think so.



STEVE:  Yeah, I don't think so.



LEO:  Maybe I did.  I mean, maybe I read your review, and I was unconscious and clicked it.  Let me try it on Internet Explorer on the Mac.  No, I don't see, you know, it says, "Was this review helpful to you?"  And there's no button.  There's something - I'll come back.  There's something wrong with Amazon right now.  Maybe it's just me.  So but, you know, I'm getting my Kindle any day now, and I will add my thoughts, too.  But like you, I want to use it for a while.



STEVE:  Yes.



LEO:  And we're both serious eBook readers.  So we know what to expect.  We've used this screen before on the Sony.



STEVE:  Yes.  And Leo, the thing you said to me, the reason, the motivation you had to buy it - it was either you said it to me, or maybe I listened to it on TWiT or on one of your other podcasts, but you said it's the connectivity.  You subscribe to a whole bunch of newspapers.  You've got them lying all over the place.  And the idea of the connectivity - and I've got to tell you that it is really comforting.  It's something about the fact that it's just - it's connected into the world.  And I've subscribed to a magazine and two newspapers - no, I'm sorry, a newspaper and two magazines.  And it's really cool.  They're just there in the morning.



LEO:  Yeah.  That's what I'm very interested in trying out.  And I'm going to cancel my Chronicle and Wall Street Journal and, I mean, I have so many - I wish The New Yorker came out on this.  Man.



STEVE:  Well, and I read The Economist every week.



LEO:  Is The Economist on it?



STEVE:  No, not yet.  But I have the same wish you did.  I mean, if The Economist is on it, bang.



LEO:  I'd buy that.



STEVE:  I'm canceling my paper subscription instantly.



LEO:  In a heartbeat.  And I am going to get The Nation on it.  But I wish, you know, and maybe these magazines are sitting back and watching to see.  But I would love to see The New Yorker and The Economist.  And then I wouldn't feel so guilty about all that paper I waste every week.  Because sometimes I don't get to read it, like most of the time.



All right.  I am going to read the questions.  Now's the time.  Listener Feedback #30, starting with Perry Harris of Bluffton, Indiana.  He needs to be more careful when he sits down.  Does he have one of those exercise balls he sits on, too?  He says, we've used RSA SecurID key fobs and credit card fobs for a while now.  We've learned that both need to be treated with care.  The key fobs can stop working if you bang them around with keys on your key ring.  The wallet card should never be put in your wallet - uh-oh.  That's where mine is.  If you place your wallet in your back pocket, the act of sitting on the wallet causes enough pressure to curve it and cards within, and that breaks the card by cracking the LCD - actually it's an eInk screen.  I don't know if VeriSign's card has the same problem or not.



STEVE:  And that's...



LEO:  Oh, his are LCD.



STEVE:  Exactly, that's why I brought this up is RSA's cards are - you have a glass LCD screen.



LEO:  Oh.  [Indiscernible].



STEVE:  Yes.  And I wanted to make sure that people knew that VeriSign's cards are different.  And mine's in my wallet, and I plop my butt down on hard chairs without a second thought.  I mean, it is amazing that this VeriSign card is as flexible as it is.  It is, I mean, there's nothing about it that is stiff or unlike a regular credit card.  And I've had mine in my wallet.  I take it out and show it to people every so often.  And it just - it is really robust.  So I wanted Perry to know that the VeriSign cards are in fact different from the RSA cards in that you really can carry it in your wallet with confidence.



LEO:  You know, it's not good to sit on your wallet, though.  You can get sciatica.



STEVE:  Okay, well...



LEO:  Keep your wallet in your hip pocket.



STEVE:  Good idea.



LEO:  Unless you have a really thin wallet.  Let's see.  I have a thick wallet.  I have lots of crap in it.  All right.  So, good, that's good to know.  There's a difference between the two cards.



STEVE:  It really is, and it really is flexible.  That VeriSign card is really built to last.  And they have a three-year warranty on it.  So if you did do something, they'd replace it for you.



LEO:  I love mine.  I don't use the fob anymore because the card's with me always.



STEVE:  Yup, exactly.



LEO:  That's the whole point, I can keep it in my wallet.



STEVE:  We call it the football, Leo, by the way.  That is the official name now.  In fact, in these questions you'll see people referring to it as the "football," which is I guess the name we came up with.  I think it's perfect.



LEO:  I like it.  Yay.  Jeff Parsons of Issaquah, Washington had a PayPal/DoubleClick observation.  We talked about this a couple of weeks ago, very big deal.  Couldn't PayPal be even sneakier by linking their Apply Now button straight to the target PayPal page, instead of having an image file like a GIF on that target page that's hosted by DoubleClick?  See, that's not how it's - well, anyway.  The URL to that image file could be similarly encoded with a PayPal user-specific ID, which DoubleClick could record and then simply return the expected image.  Assuming browsers transmit cookie data for image GET requests just as they do for user-initiated GET requests, it seems there are many ways the privacy of even the most vigilant user would be at risk.



STEVE:  Yeah, there was a couple things here.  First of all, Jeff has described the common practice of putting DoubleClick-sourced ads or images on a destination page, which then causes your browser to go fetch that image.  And we know that, unless explicitly disabled, the so-called third-party requests, that is, requests out to a third-party server, are cookie-based requests.  It also turns out that the vast majority of people are allowing their browsers to do this.  I have some technology on the GRC site which has been in place now for quite a while, I think at least a year, which is generating statistics on the number of people who are browsing with third-party cookies enabled.  And it's something like 89 percent of all the people who come to GRC, whom you would expect to be a little more security conscious and privacy conscious than your typical Internet user, they've got third-party cookies enabled.  So it is the case that what Jeff is describing is the typical way that this is being done.  However, the only reason I can see that PayPal would be explicitly linking to DoubleClick, as we described in our discussion, what, three weeks ago, is that they want to avoid users who disable third-party cookies by making it a first-party request, which is, as we described, the whole point of this.



LEO:  Yeah, yeah.  But I guess you could do other sneaky things.  Because we talked about how you could cut the URL up and hand-write the URL and avoid that redirect.  But nobody's going to do that.  I don't even do that.



STEVE:  Yes.  And I think Jeff's point was that you could also put some data in the image URL, like the user-specific ID stuff could be in the image URL, so it's not just a generic ad fetch, it's an ad fetch with additional information, which is absolutely true.  There's a little bit of a worrisome next-generation feature that's not well known yet.  It's in the next HTML spec.  At least it's in 5.0.  I'm not sure if it's in any of the 4.x specs.  But it's an attribute in a link tag, in a standard <a href> tag, called "ping."  And believe it or not, Leo, it is specifically for acknowledging to third parties when you the user have clicked on an object on an HTML page.  It literally sends a ping fetch off to another third-party site, just saying, oh, just to let you know this link was clicked.  It's like, oh, my goodness.  Well, so much for privacy.



LEO:  You know, they've just done everything they can to make it easier for them to invade our privacy.  Corby in Reno, Nevada isn't so sure that twice is better than once.  I had this question, too, actually.  I'm glad Corby asked.



STEVE:  Well, Corby - well, yeah, okay.  You read it.



LEO:  In Episode 120 you answered a question regarding double encryption.  You were asked if encrypting a file twice would provide twice the protection.  I don't think your answer was entirely correct.  I have no proof, but I'm willing to bet if you encrypt a file with Key A, and then again with Key B, the resulting file would be no more secure than a single encryption.  I would guess that a brute force attack would find a third key - oh, that's interesting - that would decrypt the message.  If two very weak keys were used to encrypt the original message, I would guess that a brute force attack would reveal a weak third key that would decrypt the cipher text.



And in the same vein, Mat Ludlam of Wybridge, London, England says:  If we take some clear text and encrypt it with Key X and then Key Y, one way of decrypting it is to reverse the process.  But isn't it possible that Key Z would work alone?  Or Key Zed in his case.  For example, XOR functions - actually that's right.  For simple XOR functions, this logic works.  But I've never looked into how proper encryption algorithms work.



And also Carlos - boy, you got a lot of feedback.  So Carlos Gonzalez in San Jose, Costa Rica - all over the world, I might add - says in Listener 120 - Listener Feedback 29 you answered a question from a listener regarding the use of double encryption in order to protect from a brute-force attack.   You and Leo endorsed the idea, saying it would make it more difficult to brute-force decrypt the text since you'd have to figure out both keys, and you wouldn't know if you've got the first key since you get random stuff back.  Seems to me if you're using symmetric encryption to double-encrypt a text, first with Key A, then with Key B, the resulting text would be decryptable by using a new key, let's call it C, which would be equal to A XOR B.  It's kind of interesting.  It's kind of the same thing that Corby was suspecting without the mathematics behind it.  So double-encrypting a text doesn't make it any harder to decrypt using brute-force methods.  It just creates a new, unique key which will decrypt the text entirely.  So you're right back where you were.  Is that true?



STEVE:  No.  It turns out - well, but so many people asked the question.  First of all, I was delighted that people were thinking...



LEO:  They're using their thinking caps.



STEVE:  Exactly.  I mean, obviously it was a question and answer that interested a lot of people because I just chose three out of a great many more people who suggested the same sort of idea.  What we know about symmetric encryption is that it is fundamentally different than, for example, the encryption we talked about early on in the Security Now! series when we were talking about the weak encryption that was provided by WEP, and actually is the same encryption that is used by WPA, the good WiFi encryption, except that the algorithm has been fixed so that it's not broken.



But our listeners may remember that back then the way that encryption worked was that there is a cipher known as RC4, which is a pseudorandom data generator.  So you give it a key, and you get it started, and this thing produces a series of pseudorandom bytes which are so good when you use it correctly that it takes, it's estimated, as I remember it's about a billion bytes, that is, a gigabyte of data, even to be able to determine that it's not completely random.  So it's really, really random.  And we know that if you mix random data with nonrandom data, the result is random data.  That is, if you XOR, which is the operation that a couple of these guys talked about, basically it randomly inverts bits in your data.  And that results in something just as random as the original random data, even though it sort of, well, it does have the plaintext encoded in it, such that, naturally, if you reinvert the same bits, you'll get your data back.  Well, that is a form of symmetric encryption, but that's a symmetric stream cipher, or symmetric stream encryption, where you mix, using XOR, you mix your data with something pseudorandom.  And then when you mix it again, you get your data back.



Block encryption, that is, a block cipher, which is for example what Rijndael is using - and I don't remember now whether the person who posed the question specified which type of cipher he was using.  I assumed he was using a block cipher.  Block ciphers work completely differently.  And the math of them, which we can explain sort of at a high level, shows why this notion of double encrypting really does work.  Remember, as we talked about symmetric block ciphers, you have a chunk of data that is relatively wide in terms of its bit size.  In the case of Rijndael, it's 128 bits.  And so you put 128 bits in.  And what comes out is a different 128 bits.  And what the cipher guarantees is that, for every single possible 128-bit combination, you're going to get a different 128-bit combination out.  And there's a one-to-one relationship.  That is, you can't get something out twice when, well, there are no missing patterns.  That is, for all 128 possible combinations in, you're going to get a different 128 bits out for every possible combination in.  And the key on the cipher, that is, the key that you give the cipher, determines which one of that many keyed mappings there are.



Okay, but if we stand back a minute, look at the number of possible mappings.  If we had, say, all zeroes, and we put that in, that's going to map to one pattern of 128 bits.  Then we have the - I'm sorry, I sort of started off wrong there.  The idea is, if we know that we have 2 to the 128th possible patterns that we can put in, the question is, how many mappings are there?  Well, the number of mappings is 2 to the 128th factorial, because for any pattern in, the output might be any one of the other possible 2 to the 128th bit patterns.  Then for the next pattern in, the output might be any one of those except the first one.  So we have 2 to the 128th times 2 to the 128th minus 1, times 2 to the 128th minus 2.  In other words, it's 2 to the power of 128 factorial possible mappings.  Which is an astronomically large number.



LEO:  Yeah, no kidding.



STEVE:  I mean, it's just phenomenally large, how many possible mappings there are.  But consider the key.  The key is, for example, the maximum key that Rijndael uses, it can use either 128-bit, 192, or 256-bit key.  Well, we know that that, of course, has 2 to the 256 different combinations.  Well, that number is far smaller.  In fact, you know, 2 to the 128 is just 2 to the 128 times 2 to the 128.  So essentially it's like there are 2 to the 126 factorial mappings missing.  So my point is that the 256-bit key can only access a tiny, tiny, tiny fraction of the possible mappings between the input and the output of the cipher.  So the fact is, what the cipher is doing is, driven by the key, the key is able to select a minuscule number of possible mappings, meaning that there is just a vanishingly small chance that double encrypting with different keys would be equivalent to a single encryption with a third key.



LEO:  I'll take your word for it because I didn't follow that at all.



STEVE:  It's like the chance would be 1 over 2 to the 126 factorial.  I mean, it's just ridiculously small.  So double encrypting works.



LEO:  Right.  And aren't you sorry you asked, Corby and Mat and Carlos.  Joel Bialek in Syracuse, New York is looking for a new image:  A long time back there was a topic you and Leo mentioned briefly I'm really interested in.  You and Leo were discussing how you make images, snapshots of your systems when you first build them, then routinely make further backup images as you go.  You mentioned specific software that you preferred.  And for the life of me I can't remember which episode it was, and I can't find it.  And don't worry, we know what it is.  I've used backup systems like Maxtor's OneTouch, but I don't like having all the other software running on my system, you know, the .NET, HD Retrospect, et cetera.  I'd love something that could either be parsed to DVDs or, better yet, an external USB hard drive that doesn't require other programs running in the background all the time.  All that being said, what are your top three recommendations regarding this type of software?  Would Windows Home Server work?



STEVE:  Well, the program we referred to, Joel, is still my absolute favorite.  And that's called Drive Snapshot.  That's PC based, so it's Windows only.  Drive Snapshot is just a program which you run whenever you want to make a snapshot, so it's not running all the time.  It's not going to be able to unwind changes or move back in time, any of that.  You need to tell it when you want to have it make a snapshot.  What I like about it is that it does a very good job of compressing the file system.  You are able to tell it if you want to limit the size of the individual image files.  So, for example, you could tell it to make them no bigger than 4.7 gigabytes, in which case if your image was larger than that, it would split it into multiple files for burning to DVD.  Another cool thing is you can mount those snapshots.  So if you had a snapshot from another system, or an earlier snapshot and you've deleted some files, you could literally double-click the snapshot file, open it using Drive Snapshot, and browse it just like you would any folder  hierarchy and file hierarchy in Windows Explorer.  And then finally, you run this thing - if you did have your system die, you can run it from a DOS prompt, that is, the lowest level available OS, and it will reconstitute an entire partition from the snapshot.  So I really like the program.  I use it all the time when I'm configuring laptops and want to be able to step back if I make a misstep.  I really recommend it.



LEO:  I was just doing some math, I'm sorry, the calculator started talking.



STEVE:  I didn't hear it.



LEO:  I know you didn't hear it.  You know, that's DriveSnapshot.de, if you want to know more about that.  And I recommend it, too.  I use it, too.  The problem with that as a backup solution is you have to image everything.  And you know, a lot of times we think of backups as backing up everything.  And I think that's kind of because business does it that way.  And so we get it in our heads.  And business does it that way because they need to restore fast.  Every minute that you're down is lost revenue.  So in business, where you have drones that are paid to do this kind of thing, it's okay to spend more time at the front end so you spend less time at the back end.  I think it's the opposite for end users.  The less time you spend backing up, the more likely you are to do it.  And should disaster happen, it doesn't matter if it takes longer to get back up as long as you can get back up.  So I don't recommend backing up Windows and all the applications.  So I do like you do, Steve.  I make an image of my first install because I don't want to go through the Windows install ever again.



STEVE:  Right.



LEO:  Including the activation.  Just restore that.  But...



STEVE:  And the 89 security patches now for XP.



LEO:  Right.  The problem is that that is out of date almost immediately because there's another security patch next week.  And so it's hard to keep an image file up to date.  So what I do is I make that so I can do a quick install, and then I backup my data just by copying it to the hard drive.  And actually I use Second Copy, which does it automatically, does a synchronize.  On the Mac I use ChronoSync.  These are background copiers.  They do run in the background.  They're very small.  And basically every hour or so they say, hey, is there any change between the main drive and the backup drive?  If there is, copy that stuff over, too.  So you always kind of have a backup.



And that, to me, imaging is too hard.  You're not going to do that.  You do that once a week, so what happens if it goes down halfway through the week, you've lost stuff.  Imaging is really more for that first build of the operating system.  And remember, it's going to get out of date pretty quickly.  So if you want to keep applications up to date, if you want to keep the operating system up to date, every maybe six months you might want to strip it down, reinstall, add the updates, and make a new image.  That's the problem with this is you have to do this pretty - you have to be pretty careful about it and do it...



STEVE:  I should mention, too, along the lines of a file-by-file backup, I have another program that I love.  It's called FileBack PC.  If you just Google FileBack PC, you will find it.  And it's one I've used for years.  I like it.  And in fact, I've got it monitoring my Assembly language subdirectory and...



LEO:  You don't want to lose one iota of that programming.



STEVE:  Exactly.  And what I love about it, too, is you're able to tell it how many copies of each file you want to maintain; which files you want to maintain using file extension filters; and, for example, what limit on number of copies within a certain length of time.  It's got very powerful backup description options.  So, for example, I'm able to say I want to keep 20, up to 20 previous instances of my Assembly language files, no closer together than an hour apart, no more than 10 a day kind of thing.  And it just - that way I know that my work is always going to be safe.



LEO:  I have to get that.  That's from MaxOutput.com, and it's 55 bucks.



STEVE:  It really is good, Leo.  I've used it for years, and I just really like it.



LEO:  Yeah, I use Second Copy, which is about 30 or 40 bucks.  And it's not as flexible, though.  This looks much more - this is a more serious product.



STEVE:  It's a serious tool.  And it also understands about fileshares.  It's able to link and to log onto remote drives over Windows networking with no problem.



LEO:  Yeah, see, that's what I do.  I map the network attached storage drive to my Windows machine and just automatically backup to that.  So it's not even the same machine.  But, yeah, this is where an external USB drive is so useful.  But as you get more serious, network-attached storage really is the best way to back up.  And then don't forget an offsite backup.  Because if you, you know, look what happened to Francis Ford Coppola.  They stole his computer and his backup drive.  So he had nothing.  So I use Carbonite to backup online.  It's a sponsor of the radio show, but I use that.  And now I have, like, boy, I have, like, 18 different ways I can restore.  But you've got to do that.



STEVE:  You're safe.



LEO:  That's the way you have peace of mind.  James Wilcox of Rapid City, South Dakota wants to keep his router.  I don't want to lose my router.  I don't want to.  Thanks for such a terrific podcast.  Thank you, James, for listening.  I have a football on my keychain that I love showing off to friends and family as I explain multifactor authentication and watch their eyes glaze over.  Really great for the holidays.  Anyway, I was doing a little reading on IPv6, and I had a question.  This guy must be great at parties.  According to MS's help file in XP, part of the problem with IPv4 is it didn't anticipate such a large demand for IP addresses.  NAT routers, of course, get around that issue.  But when IPv6 comes around with its 3.48 times 10 to the 38th addresses, won't routers be obsolete?  If that's true, then I guess our handy routers as firewalls will go away, won't they?  Maybe that's a good plug for Astaro.  First of all, where is, you know, is IPv6 imminent?  And what happens if it comes out?



STEVE:  I don't know.  I have said that it's never going to happen, and then I get a bunch of hate mail from people saying, oh, it's already happening, don't you know what's going on, you're clueless, and things like that.  The problem is that the real incentive for it was largely this IP space depletion and consumption, which has not happened because of NAT routers, exactly as James Wilcox here suggests.  My sense is that routers are so good for security that clearly, if we originally had 128-bit IP addresses, which is what IPv6 gives us, had we had 128-bit IP addresses, routers may have never happened in the first place.  But now that they have, and they do such a good job of protecting us on the 'Net, I'll be surprised if, even when we do get 128-bit IP addresses, if that ever happens, I'd be surprised if they go away because they happened, and they're inexpensive, and it's just sort of a nice place for you to plug everything in.  I mean, if you didn't have a router, then we'd go back to having a hub or a switch.  Which is not as smart.  But those don't cost that much less now than routers do.  So I think this is something - I don't think James needs to worry about losing his router.  I think he'll always be able to have a router.



LEO:  Yeah, and I think many routers handle IPv6.  So it's not like your router is, I mean, you'll still have a router.  This router may be obsolete.  My router can do IPv6, I think.



STEVE:  Yes.  And of course that was a big deal in Vista.  And I think XP has a v6 stack also.  So again, it's sort of happening, but it requires that our ISPs basically swap out a lot of the hardware that they've been using.



LEO:  A lot of infrastructure, yeah.



STEVE:  Yup, a lot of infrastructure has to be upgraded.  And there's not a great deal of pressure to do it.



LEO:  I think it'll happen.  I think it is happening.  I think it's gradual.  The question is, how long before IPv6 is obsoleted?  And that may take forever.  Who knows how long that'll take.



STEVE:  That'll never happen because IPv4 is already accommodated in a little corner of IPv6.  So you can keep using IPv4, and the IPv6 transport will translate back and forth.



LEO:  See, that's the real question, is when are they going to phase out v4, and they're not.



STEVE:  Right, right.



LEO:  Jim Bassett in Pleasant Hill, California also uses the Patelco Credit Union.  We were talking about that on Listener Feedback 29.  He said he wanted to follow up on the first question regarding multifactor authentication at Patelco.  The questioner explained that Patelco was using reverse DNS to authenticate logons.  He discussed the trouble with relying too heavily on that.  Jim wants to point out Patelco allows you the option to not keep a trusted provider on file, thus requiring you to receive a new password via email or SMS for each log-in.  Wow.  Would this be - well, all right.  Would this be a more acceptable use of this type of multifactor authentication?  I, too, am a Patelco member and will be implementing this as well and would like your feedback.  I regularly access my account from both home and work.  I for sure would not have my work ISP as a trusted provider - rightfully so, I think.  And I'm thinking of doing the same for my home provider, Comcast, despite the minor inconvenience of needing to get a new password via email each time I access my account.



STEVE:  It's interesting.  So essentially what's happening is we apparently had a system where a username and password could once be used from anywhere.  Then they added this notion of wanting to, well, I guess actually it's not even a notion, it's a government regulation is coming downstream saying you must have multifactor authentication.  So they're saying, okay, we're going to use reverse DNS for multifactor authentication.  We recognize, though, that it's not a safe practice, that is, it's not as strong another factor as necessary.  But what Jim is saying is that, in response to that, you can tell Patelco to never trust anyone, and that will force them to send you a password via email or SMS every single time, which, yes, I think is much more secure.  So that's what I would do, as you said, Leo.  It's certainly a bit of a hassle.  But unless you're logging onto your credit union site all the time, I would think it's probably worth the security.



LEO:  Via SMS isn't too bad of a problem.  And, you know, it just comes to - I've noticed when I use this, Bank of America will do this as its secondary form of authentication.  It's instant.  So you press the button, bzzz, there's your phone, there's the number.  I think that's probably a good way to do it.  In fact, I would like to do it that way.



Aaron Mashburn, writing from the Republic of Panama, has an SSL question:  The recent PPP episodes, Perfect Paper Passwords, sparked my interest in crypto.  So I went back and redownloaded episodes 31 through 37 as a refresher course.  Good idea, by the way.  That's a good thing to keep in mind.  We've covered these subjects, you know, kind of the primers on these subjects in past episodes.  So if you go back you can look at those.  He says as he listened to Episode 37:  A question popped into my mind.  I understand an SSL certificate verifies the identity of my server.  But is the cert used at all in the encryption process for the SSL?



STEVE:  Well, it was a neat question.  And in fact we've had a number of questions like this such that I've made a note in our upcoming show plan to specifically talk about SSL.  We've talked about the need for it.  We've talked about the certificate side.  But we've never actually looked at the protocol itself.  And as is so often the case, it's extremely understandable.  So I want to give it an entire episode in the future.



In the meantime I wanted to respond to Aaron's question and say that, yes, there are aspects of the certificate which are used for the HTTPS connection.  Specifically, what the remote server does is it provides the client with its certificate which has been signed by the certificate authority, which as we know allows the client to verify the signature.  It also provides - it's the public key of its public/private key pair.  It provides the public key so the client can then choose a random number, uses a pseudorandom number to obtain a symmetric key which they will use for bulk encryption during their conversation.  You cannot use the public key for bulk encryption because it's much too time-consuming to do that.  So you use the public key just to encrypt the symmetric key.



So the remote server provides the client with its public key.  The client encrypts the randomly chosen symmetric key using the server's public key and sends it back.  And the beauty of public key crypto, which is what Aaron relearned in episodes 31 through 37 of Security Now!, is that someone could see that, could sniff the wire and see that going by.  They could literally see the publicly encrypted symmetric key chosen by the client and be absolutely unable to decrypt it.  Only the server that has the matching secret key in this public and private key pair is able to decrypt that which was encrypted with its public key in order to obtain the symmetric key which they then use for communicating.  So that's how that works.  And we're going to do an episode that really - that covers this because there's a lot more features and options in it.  And we're just depending upon SSL for so much these days.



LEO:  Oh, yeah.  Oh, yeah, all the time.  Jack's a little worried about being spied on in Australia.  He says:  Is it possible to strip the security of HTTPS - that SSL we were just talking about - and decode the encryption so that it could be read by the Internet service provider or other government agencies in Australia?



STEVE:  And the answer is a resounding no.  You have to be careful that, for example, your ISP has not given your browser a certificate authority and is able to proxy your HTTPS connections.  But...



LEO:  But you would know that because the certificate would say your ISP's name and not the site's name.



STEVE:  Yes.  It would show that the ISP had signed that site certificate, which it would be creating on the fly, rather than, for example, VeriSign having signed it.  So you absolutely, if you were at a site and you verified the chain of signing authority for the certificate, and you see that it goes back to one of the very common root certificate providers, then there is no way, given that, that anybody sniffing the wire is able to, as Jack said, strip off the security.  I mean, that's the whole point of SSL.  And it is a well-known public standard with no ways around it.



LEO:  Clarify for me, though.  Okay, so I'm at work, and I know that my Internet is going through a server at work, and that they're probably doing this certificate shuffle here.  So I'm on Amazon.com.  I've got a certificate.  If I get info or look at the security on the page, will it still say, the certificate, will it say Amazon.com, or will it say my office?



STEVE:  It would say Amazon.com.



LEO:  It would still say Amazon.com.



STEVE:  And then it would show that it was signed by your company.  And so...



LEO:  So it's the signing is what you want to look at.



STEVE:  Yes.  You want to see who it is that signed the certificate.  And...



LEO:  Now, you're screwed if you work for VeriSign.



STEVE:  That's a very good point.  I never thought about that.



LEO:  [Indiscernible] VeriSign, and you can't tell if it's the right, you know, if it's...



STEVE:  Yes, that's a very good point.  They could certainly be - and we assume that they're not.  We don't know they're not, but I've never thought about that before.  But you're right.  Since they're the signing authority, they could be signing certificates that they're making on the fly, and everyone's browser would accept them.  That's a very interesting hack, Leo.



LEO:  Now, it's different in each browser to get that information.  But in most browsers you can right-click on the page and say, what, View Certificate or...



STEVE:  You'd look at the page properties, and then View Certificate.  And then you'll see the first certificate.  And then you could look at details.  And it'll sort of show you normally a hierarchy of signatures going back to some root.  And so it's the root that has signed all the certificates in the chain of trust.  And if that goes back to someone like VeriSign or eTrust or one of these - or Thawte, for example, then those are mainstream certificate-signing authorities, and you know that the site you're going to had its certificate signed by them.



LEO:  Got it.  Got it.  Zacc Cooley in Gilbert, Arizona wants the world to stop spinning:  I was wondering how the new solid state hard drives - we just got one at the Lab, by the way, 64 gigs, 2,500 bucks.



STEVE:  Yeah.



LEO:  I was wondering how the new solid state hard drives are going to change how we as consumers back up our data.  Do the bits in a solid state hard drive function like the bits on the spinning platter hard drive in that they can become corrupted?  Hell, yeah.  Will I still need SpinRite to use on my solid state drive over time?  Will we need to defrag them?  Will we need to back up the data on solid state hard drives as much as we do now?  I've got questions.  Is there a battery inside like motherboard batteries that keeps the data in there than could die and cause data loss?  What, Steve, tell me, what?



STEVE:  Well, there's essentially no relationship between solid state hard drives and physical hard drives.



LEO:  Well, they store bits.



STEVE:  Well, okay, exactly.  But no, in terms of the technology, they are absolutely different.  So, for example, there's no need to defrag them because...



LEO:  Oh, interesting, really.



STEVE:  Yes.  There is no physical seeking going on.



LEO:  Oh, so it doesn't matter.  It's a read cycle from any address is the same.



STEVE:  Exactly.



LEO:  Oh, interesting.



STEVE:  There's no battery inside.  What they use is an electrostatic technology where essentially it's possible to strand electrons on a little tiny bit of metal that's insulated.  And the electrostatic influence of the electrons is sensed on the other side of the insulator, and that's what determines if it's a one or a zero.  So basically sort of you squirt the electrons, you force them through the insulator, and they get stranded there.  Or you suck them out, and then they're no longer there.  So it's a very different technology, completely different from a hard drive.



The problem is that that process of squirting electrons through the insulator, known as tunneling, it actually creates some physical damage and some wear over time.  So there is a problem with this technology in terms of the number of times you can write to it.  You can read to it easily just by saying - just by querying whether or not this little transistor is on or off.  But the process of writing is just a little tiny bit destructive to the system.  The reason writing is so slow is that it actually requires a higher voltage in order to inject the electrons.  And that requires something called a charge pump to charge itself up in order to cause this injection to occur.  And that's why writing to these non-volatile RAMs is much slower than reading from them.



But the other thing that happens is, if you write to them over and over and over, they die.  So they don't die fast.  It's like on the order of 10 to the 5 write cycles, so like 100,000 write cycles.  But not infinite.  Hard drives are infinite.  That is, it doesn't hurt them in any way to change the data on them.  It actually hurts non-volatile memory to change its data.  So in order to mitigate the damage, non-volatile RAM has a technology that spreads the actual writing around the surface of the RAM.  So that even if you are reading and writing the same area, that is, the same address of the RAM over and over and over, it's actually occurring in a distributed fashion across different physical areas of the RAM.  They do that in order to spread out the damage caused by writing to it.  So you really don't want to defrag because that's needlessly writing to a technology which has a limited number of write cycles.  You certainly don't want to run SpinRite on it because SpinRite just writes like crazy.  I mean, that's good for hard drives.  It's bad for non-volatile, solid state hard drives.



LEO:  So don't run SpinRite on it.



STEVE:  You don't want to run SpinRite.



LEO:  Would it work?  I mean, it's an IDE interface, isn't it?



STEVE:  It does work.  Mark Thompson, my buddy at AnalogX, years ago he was curious about whether non-volatile RAM really was hurt by writing.  So he used a PCMCIA EEPROM, a non-volatile memory.  And he set it up as a Windows swap drive.



LEO:  Oh, boy.



STEVE:  Windows killed it in one hour.



LEO:  Whoa.



STEVE:  Just killed it dead.



LEO:  There you go.



STEVE:  It just was game over.



LEO:  He's got money to burn, that kid.



STEVE:  He's crazy.



LEO:  So but that's interesting because ReadyBoost, this ReadyBoost and ReadyDrive technology that Microsoft Vista supports is solid state.  But it's not writing to it a lot.  It writes to it once, then it uses it as a cache.



STEVE:  Exactly.  It's very much - reading is no problem.  And also you'll notice that other mature technologies, they will use RAM; and only very seldomly do they flush that out to the non-volatile.  So mature technologies understand that you cannot write to these things all the time.  You must - you can read from them easily, but writing is something you want to tend not to do.  And as you said, Leo, it's still very expensive.



LEO:  Oh, yeah.  It's not - we're way off from this being common.



STEVE:  Yes.



LEO:  I was surprised how expensive that was.  All right, Steve.  Are you ready?  It's time for the Perfect PPP Quandary of the Week.  Sean Reiser of Astoria, New York says:  First off, this is not a story about a flaw in the PPP system, just a reminder of the saying "because there is no patch for human stupidity."  PPP in and of itself is excellent.  We just need to eliminate humans from the equation.  PEBKAC, baby.  I've been piloting an implementation of Perfect Paper Passwords on a corporate site to replace RSA key fobs - oh, really, neat - and encountered a problem I didn't expect.  Once we expanded the pilot beyond the techs into some of the business units, I noticed users tend to take advantage of the blank backside of the paper to note little things like the site URL, their username, their password.  Oh, boy.  No matter how much education we did, even if the users were specifically told not to write this information on the cards, there were always users who did it.  Barring lobotomies or summary execution, I really don't know how to handle this.  I'd appreciate any ideas you have.  That's, I mean, but what are you going to do about that?



STEVE:  Yeah.  The only thing I could think, I mean, I was thinking, well, that's interesting.  So essentially by writing their username and password on the back of their PPP card...



LEO:  It's right there.



STEVE:  ...they've completely scrapped all the security that is available if they lose physical access to their card.



LEO:  Especially if they're crossing off the PPPs as they use them.  You even know what the next PPP is.



STEVE:  Yup.  And so the idea of something that they know and something that they have, well, if a bad guy gets a hold of it, then he knows what they know, and you've lost all of your multifactor strength.  The only thing I could think was to put - first I was thinking, okay, well, how about if you print it double-sided, and you just put like a cross-hatch on the backside?  People might still write over that.  So then I was thinking, okay, there's nothing that would prevent you from making double-sided PPP cards.  That is...



LEO:  Oh, good idea.



STEVE:  ...instead of just printing one web page that contains three, print two, so that you have cards 1, 2, 3, and 4, 5, 6 on the second page, which will print out, when you print it double-sided, on the back side.  So now the card...



LEO:  People would still write it, though, in the little bit of space there.



STEVE:  I know.



LEO:  You've got to laminate them.  Laminate them.  Then they couldn't - they'd have to use a grease pencil.



STEVE:  That's probably a good idea, Leo.



LEO:  Just laminate them.



STEVE:  So it just will not take ink.



LEO:  Right.



STEVE:  There you go.



LEO:  I don't know what - take the pens away from them.  I don't know what you can do.  There must be, you know, it's funny, I have great sympathy for IT professionals.  And I know how much they hate users.  And it's hard.



STEVE:  The real world is a real problem.



LEO:  Yeah.  And you go in, and I'm sure every IT professional goes in, you know, gung ho, excited about their users, they want to help them, and they slowly grind you down.  You start out with all the goodwill in the world, but slowly they grind you down.  And I don't know a single IT pro who doesn't have a horror story or two or three or four.  Are you ready for the Great Tip of the Week?



STEVE:  Yeah.



LEO:  This is from Patrick on Montreal:  Perhaps you've already had a slew of people tell you this, but just in case no one did...



STEVE:  And nobody did, by the way, Patrick.



LEO:  You're the one.  An easy way of accessing the Flash Player Settings Manager is to right-click a Flash object on a web page, then choose Settings, which brings up the basic settings panel on which there is an Advanced button right on the first tab there.  It'll take you directly to the right Adobe/Macromedia page which contains the Flash Player Settings Manager.  Also might be worth mentioning that settings should be adjusted by accessing the panel while browsing in Firefox as well as IE because they are browser specific, I guess.



STEVE:  Yes, exactly.  There's a different plug-in for the Firefox from Adobe than there is for the IE.  And I didn't verify this, but I'm assuming Patrick is saying that they're not sharing settings on a single machine.  So you need to go there both.  But I really liked his suggestion because it's, I mean, many people wrote to say, hey, my bank is using Flash cookies.  I've never heard of Flash cookies before, but that's what they're doing.  So our mentioning this and talking about this to our listeners a couple weeks ago brought this to the fore.  And of course people want to have control over what their machine is doing and the trackability.  They may have been people who were disabling third-party cookies, but never even thought or knew about Flash cookies.



So I liked Patrick's note because it makes it very easy.  In order to check this out, I just went to MSNBC.com, and I went to CNN.com.  Both of them, I mean, just assuming they would have Flash stuff.  And sure enough, Flash began jumping around on their page, doing animation.  And I just right-clicked, hit Settings, and then clicked the Advanced button.  And that took me to the Adobe page, just exactly as Patrick said.  So I loved his idea.



LEO:  Excellent.  Very, very.  All right.  It is time for our last question of the day from Brian W., also in Montreal.  He asks the Horrifying Show-Stopper Question of the Week:  I've been a listener since Episode 1, and I love the show.  Thank you, Brian.  I know you guys have covered keystroke loggers in the past.  I am one of the probably millions that love using wireless keyboards, but I never considered the security risk.  Yeah.  I saw a Black Hat presentation on wireless keyloggers.  What really worried me was that the encryption, if you could call it that, on Microsoft's wireless keyboards was a 1-bit shift register.  Is this, like, industry wide?



STEVE:  Well, I did some research after Brian...



LEO:  Somebody asked me this on the radio show, you know?  And I didn't know.  And I'm glad Brian asked this question.



STEVE:  Yup.  Get a load of this.  It's not a 1-bit shift register.  It's a 1-byte static byte that is XORed with the data from the keyboard.



LEO:  So would that be pretty easy to reverse engineer?



STEVE:  Leo, it'd be hard not to reverse engineer.  It is  horrifying.  It's horrifying.



LEO:  And this is true not just for Microsoft, but do other keyboards do it this way?



STEVE:  Well, apparently Logitech has recognized that this is a problem that's sooner or later going to get exposed.  Microsoft's wireless keyboards do this.  The 1000 series and the 2000 series have been examined.  The 3000 and the 4000 have not been.  But it appears to be the same for them.  Logitech has, like, a secure connect...



LEO:  They have an encrypted keyboard, yeah.



STEVE:  Yeah.  And so they're boasting about that.  But the extremely popular Microsoft keyboards, during the so-called "association phase," the keyboard chooses a random byte, one byte of randomness, and provides it to the reader.  Then the keystrokes you type are XORed with that one byte.  Which means, as we know, there are 256 possible combinations of one byte, that the one byte can have.  All you have to do is suck in a bunch of characters, you know, wait a few minutes for someone to type 20 or 30, and then in a heartbeat you could check every possible byte.  One of them will turn what they're typing into English or clear text or whatever language they're typing in.  In that case, at that point, their keyboard is decrypted for all intents and purposes, deciphered.  What this means, of course, is that in a situation where people are within sniffing distance, radio distance of a keyboard, you absolutely have to consider that it is not safe.  Keyboards are using a low frequency, 27MHz, which is extremely easy to receive, meaning that in an apartment building, neighbors who have a wireless keyboard could have everything they're typing trivially decrypted, if it's at least on these Microsoft Series 1000 and 2000 keyboards, and probably other keyboards.  So it's definitely a concern.



LEO:  Good to know.  And so the Logitech ones that stay encrypted, do you know what technique they use?



STEVE:  I don't, and it's something definitely worth some research.  We know that it's actually not very easy to perform really good encryption against man-in-the-middle attacks.  It's absolutely possible, and several times we've talked about the technologies to enable that.  But you've got to have some serious work being done on each end in order for a conversation in the clear that can be monitored, as any radio conversation can be, to have that kind of a conversation secure.  It's definitely possible to do it.  But you've got to really want to.  So I'm wondering if Logitech's approach is way secure, or just less hard to crack.  But again, it'd be - I don't know if you could make anything less hard to crack than what Microsoft has done, which is just choose a single byte and XOR your data with it.  It's like, why even bother?



LEO:  Well, in their defense, they don't say it's an encrypted secure keyboard, do they?



STEVE:  No, they don't.



LEO:  And so it's probably more to prevent crosstalk from other keyboards in the same area.



STEVE:  It doesn't, no, it doesn't do that.  And it turns out that there is now technology on the 'Net that will simultaneously record and decrypt from all the keyboards within range at the same time.  Because the keyboards do have a unique identifier that allows you to disambiguate the data coming in from all the different keyboards.  I mean, it's unbelievable.



LEO:  That's crazy.  They can log everybody in the whole office without even touching their computers.



STEVE:  Yes, just put on your tinfoil cap and connect a wire to it and send it in to your keyboard receiver, and you can monitor what everybody's typing.



LEO:  Unbelievable.  Well, we've come to the end of another fantastic and fascinating edition of your questions, Steve's answers.  We thank you, Steve.  It's great stuff.  I want to remind everybody to go to Steve's site, GRC.com.  That's where you'll find 16KB versions of every single episode ever of Security Now!, all 122 of them.  You also have transcripts, which is great.  Do you have transcripts for every episode?



STEVE:  Every single one.  I had Elaine go back, and she started from #1 and came forward.



LEO:  Oh, that's great.  And lots of great free stuff, including ShieldsUP; PPP, the Perfect Paper Passwords, some sample implementations and so forth; his great security forums; lots of simple and useful utilities like Wizmo; and of course everybody's favorite hard drive maintenance and recovery utility, but don't use it on your Flash drives, SpinRite.  You can use it on your spinning - well, it's SpinRite.  You don't have FlashRite.



STEVE:  No, not doing FlashRite yet.



LEO:  SpinRite.  GRC.com.  Steve, so much fun.  Thank you so much.  I appreciate your time.



STEVE:  And I yours, Leo.



LEO:  Are you going to take Christmas off?  What are we going to do here?  We going to keep going?



STEVE:  We're going to keep going.  We're not going to miss a single week.



LEO:  You just want to catch up with TWiT.



STEVE:  Even though - yeah, I'm going to pass them up this time finally.  Even though you're going to be off in Egypt for a couple weeks; right?



LEO:  I will.  Christmas Eve I'm leaving, which is just five days from now.  I'm going to leave to go to Providence, spend Christmas with my Mom and sister and my family.  And then all of us, my family, the four of us are going to go to Egypt on the 27th.  We'll be in Cairo.  If we have any Security Now! listeners in Cairo, say hello.  I'll be the one on the donkey.  Or the camel, I'm not sure.  And then we come back January 6th.  So we'll get back, the network itself will get back in the swing of things kind of slowly after the 6th.  I probably will miss at least two TWiTs or three TWiTs, which means you'll be ahead by then.  Finally.  And then we're doing a MacWorld, which is January 15th through 18th, we're doing a live podcast every day there in the West Conference Hall.  If you come up, we'll do a Security Now! up there, if you come up.



STEVE:  Oh, I'll think about that.



LEO:  I can get you in.



STEVE:  Cool.



LEO:  I have friends.



STEVE:  I like that.



LEO:  Yeah, it'll be fun.  And then I do want to remind everybody that we do have that holiday coupon still for ScotteVest merchandise.  Anything on the ScotteVest site, as you check out, use the coupon code LEO, and you'll get 20 percent off the top, right there.  It does not include the TWiT merchandise available through ThinkGeek, just the ScotteVest merchandise at ScotteVest.com.  20 percent off, use the coupon code LEO.  And that's just our little way of saying thank you for being such great listeners all year long.



And I would be remiss if I didn't thank the folks who donate.  Because I think people hear the ads, on this show especially we've had full sponsorship.  We're sold out.  We'll never have more than two ads.  And we have been sold out all year.  And I think probably some people think, oh, well, they don't need our money.  We do, because sponsorship frankly does not cover the costs.  The money from sponsorships goes to the hosts.  The costs, the day-to-day costs are coming from your donations, things like the server, the rent, Dane's salary comes from your donations because those are consistent, and advertising is not.



So please, we do appreciate your donations.  Don't stop.  Keep them up.  We thank you so much for your support.  Just go to TWiT.tv and click those links.  Even $2 a month is plenty.  That's enough just to show you care.  All right, Steve.  Have a great week.  We'll talk again, boy, we're going to be getting close to Christmas when we talk next.  It'll be the 20th, 12/20.



STEVE:  Thanks, Leo.



LEO:  All right.  Take care.





Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#123

DATE:		December 20, 2007

TITLE:		Jungle Disk

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		Dave Wright, Creator of Jungle Disk

SOURCE FILE:	http://media.GRC.com/sn/SN-123.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo invite Jungle Disk's creator, Dave Wright, to join the podcast to talk about his $20 product that allows for extremely economical, efficient, seamless and absolutely secure online storage of any user data within Amazon's high=performance, high-reliability "S3" storage facility.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 123 for December 20, 2007:  Jungle Disk.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!.  Here we are just a few days away from Christmas, celebrating the holiday season.  And most of the TWiT shows have gone dark and are quiet, and there's - we put up the stockings by the chimney with care, and not a mouse in the house.  But no, Steve Gibson, he's an animal.  He says, "I'm not missing a show, dagnabit."  So we're do a show this week.  We'll do a show next week.  We'll even do a show the week after.



STEVE GIBSON:  We're doing a show while you and your family are in Egypt, Leo.



LEO:  Right now, let's see, we're not there as this airs.  But we will in a few days.  And so next week's show, by then I'll be in Egypt.



STEVE:  And a week after.



LEO:  I'm training Dane on how to post these, so if it's late, it's not my fault.  I didn't do it.  No, it'll all be fine.  In fact, I think I can get wireless in Cairo.  The hotel we're staying at I believe has wireless Internet.  So Happy Holidays, first of all.



STEVE:  Yes, to all of our listeners.



LEO:  Yeah, and to you, too, Steve.  And I guess we should - coming up in just a little bit we're going to talk to the guy who writes Jungle Disk.  Tell me a little about that.  He's Dave Wright.



STEVE:  Dave Wright, W-r-i-g-h-t.  It's funny, in their online forum postings he goes by "Jungle Dave."



LEO:  I like that.



STEVE:  And this is something I think that a questioner, one of our Q&A people, brought to my attention, said hey, what about Jungle Disk and the Amazon S3 service?  Is it secure?  And I took a look at it...



LEO:  Well, the best way to find out is to ask the guy who wrote it.



STEVE:  Exactly.  So we have him on the show today.  And he's going to answer all of our questions.



LEO:  We, I'm sure, also have some errata.  Before we get into that, some follow-ups, and in fact the first one I know is something that's been bugging me, but we'll talk about that.  And then we both have our Kindles, and we'll talk a little bit about the Kindle.  Let's start by answering my question.  It was bugging me.  I keep trying to vote for you, your Kindle review.



STEVE:  Oh, Leo, you and a large body of our listeners.



LEO:  Oh, good.



STEVE:  First of all, of course, I spaced out last week and the week before because I was saying "snipurl/skr," forgot to say "snipurl.com."



LEO:  Oh, well, everybody knew that.



STEVE:  Well, I hope so.  Anyway, it turns out that you were exactly right when you were trying to do this when I was giving you that shortcut.  It must be that Amazon has some bot prevention technology.



LEO:  Oh, so you can't go directly in.



STEVE:  Exactly.  And of course we know from our episodes about how the web works that if you click on a link from within Amazon, there will be a referrer field in the query that says hey, the user was on this page and clicked a link to come here.  So it's trivial for them to, for example, remove the voting buttons if you jump directly into Amazon rather than click on links in Amazon to go here.



LEO:  They don't like deep linking probably.  That's probably what it is.



STEVE:  Exactly.  So a bunch of users wrote and said hey, Steve, love to vote for you, but Leo's right, there's no buttons.  Well, enough people apparently poked around, I know that Elaine is one of them, our transcriptionist...



LEO:  She really wanted to give you her vote.  That's cute.



STEVE:  Yeah.  So I was back on like the fourth really, really long page back, and I thought I would never surface.  But enough listeners made the trek in that I'm now on the - my review of the Kindle is now, like, the fifth one on the first page.



LEO:  Oh, good.  We're trying - we should explain.  The reason is there's so many reviews of the Kindle that aren't really very substantive, in fact many of them by people who don't own Kindles.  And so we've been just trying to get Steve's ranking up a little bit on the Amazon page so people can read a thoughtful, I think a very thoughtful review.



STEVE:  Well, and Leo, most of them are by people who don't own a Kindle.  They just think it's a bad idea.  And it's like, okay, well, that's not a review.  That's just sort of an annoyed opinion.  Anyway, so...



LEO:  Right.  Well, most reviews are annoyed opinions, let's face it.



STEVE:  Well, anyway, so I did want to tell our listeners, if anyone was confused, I'd still love to have people's votes just to kind of keep me in the running there with all the others because, again, the reviews are generally long, and it does take some bit of slogging along still to get down to mine.  So if anyone goes to the Kindle page, a link near the top of the page is Read Reviews.  And then, I don't know, I'm like the fifth or sixth one down.  But again, if people like what I wrote and would say yes, we thought that was useful, that would help to keep me up there in the ranking.



LEO:  So I got my Kindle about a week ago, and I traveled with it.  You know, I was gone to New Haven for five days, and it was a really good time to try it.  And my initial reaction is, if you're going to buy an eBook reader, it's certainly the one to get.  There's just - there's no question.  It's easy, it's actually, because of their choice of fonts, it's much easier to read.



STEVE:  Yes, the fonts are much better, aren't they.



LEO:  Yeah.  And you can get the font size bigger, which as a person over 40 I appreciate.  And the wireless, as we've talked about, the wireless really does make it so much easier to put stuff on it.  I haven't ever hooked it up to a computer.  I get a number of newspapers.  And so for that reason alone the hundred dollars differential between that and the Sony is, I think, well worth it.  But I think that there are also lots of people, a great many people, probably the vast majority of people who will never buy an eBook reader, at least not until the eInk technology improves and is crisper and so forth.  Those people aren't going to like it anymore than they'd like the Sony.  But I think it's certainly true, if you're going to choose between a Sony and the Kindle, that the Kindle is far superior.



STEVE:  I agree.  I think certainly people who own prior generation eBooks, I mean, if somebody already has a Sony, they'll probably be inclined to continue purchasing Sony eBook content, even though Sony has only about a quarter of the...



LEO:  Much more limited, much more expensive, and much more difficult to put on.  You need Windows; you need a USB connection.  I just, you know - for instance, I was looking for a book on Egypt.  I wanted to do some reading before we go to Egypt.  I went, I searched, found several hundred volumes on Egypt, available through the Kindle store.  You can search online.  And I bought a book.  Wasn't cheap.  Now, it's funny, they have very expensive books on Egypt, I guess.  And it was 35 bucks, which was still cheaper than the hardcover.



STEVE:  The pyramids are those pointy things, Leo.



LEO:  Yeah.  See, that's the problem, is most of the books -oh, another thing I want to say that I love that you can't do in the Sony store is you can get samples.  And so instead of buying kind of sight unseen, I was able to get - I got samples of the top five books I was interested in, read one, and it was just so bad, I was able to reject it.  So I was able to pick the right one.  And that saved me a lot of money right there.  And if you're into the bestsellers, you could before you go on a trip get samples of all of them, read them on the plane, and pick the ones you want to finish.



STEVE:  I think also you are able to have multiple Kindles associated with the same account.



LEO:  Oh, that's interesting.



STEVE:  Yes.  And so you're able to buy a book once and read it on multiple Kindles.



LEO:  Now, why would you do that?



STEVE:  Well, husband and wife might.  I know a lot of couples who, like, hand books to each other.  It's like, okay, I'm done with this, you want to read it?  And so you're unable to do that with the periodical content.  You have to individually associate those with individual readers because they don't want that to be shared.  But book content you explicitly can share among multiple Kindles.



LEO:  That's interesting.  And that is one of the complaints, and I think rightly so, although it's inevitable, that people have is the copy protection on the Kindle.  But there's no way a publisher is - that's not an Amazon issue, that's a publisher issue.



STEVE:  Exactly.  That's not going to go away.  And the point I made in my review was that I've already got copy-protected content spread around.  I was an early adopter of the Mobipocket format, which of course Amazon ended up buying as part of their move into eBooks.  And then Palm, and then Sony, and finally now Amazon.  And my feeling is, okay, sure, this feels like the first-generation device.  The screen's going to get better.  The UI is going to get better.  There will be lots of things about it that improve over time.  I mean, that's been the history of eBooks, rocky as it's been.  But if I'm going to be investing now in a format, it seems to me Amazon's going to win this.



LEO:  Yeah, I agree.



STEVE:  Already, right out of the gate, this is the best eBook reader there is.



LEO:  You know, the paperback is not going away.  And I will still buy books.  So it's going to be more the stuff that I read once and I don't want to have a copy of it.  So I'm not really too worried about whether I'm going to be transferring stuff over to a new Kindle.  I have to say the cover stinks.  They've got to get a better cover.



STEVE:  Yeah, the cover's not good.



LEO:  The Sony cover is, in fact, in general the Sony design is much more elegant all around.



STEVE:  I was thinking that I was forgiving the fact that there was a keyboard there because you end up holding it down...



LEO:  You have to.



STEVE:  ...in the keyboard area.



LEO:  There's nowhere else to hold it.



STEVE:  Exactly, because if you hold it anywhere else it changes pages on you.  But then I'm like, I've never used the keyboard.  Well, maybe once or twice.  But it's the most underused aspect of it for...



LEO:  I've used it because I've searched for books and purchased books that way.  So you need, you have to have it.  Although I guess you could have some sort of strange selection technique.  But I think you have to have it.  And it is where you hold the darn thing.



STEVE:  We ought to say, though, Leo, that the comment you made early on, the reason that you made the decision to purchase was the fact that you subscribe to a bunch of newspapers.  And for me, I think the connectivity is very cool because the content is just there in the morning when you go off to coffee, and you've got your newspapers and magazines and things.



LEO:  One thing that is really cool that wireless allows.  So I'm reading along in a book, and the guy says, "No more 'mute inglorious Milton,'" in quotes.  And I'm going, boy, I know that quote, "mute inglorious."  Where could that be?  You scroll to that part of this thing, you click the button, you search for it, it says Search on Wikipedia, Search on Google.  I searched on Google, immediately found Thomas Gray's "Elegy Written in a Graveyard" ["Elegy Written in a Country Churchyard"], which is - that's the poem it's from.  Got the full text of the poem and was able to read it.  And that is a very interesting addition to a reader.  You can look up words.  It's got a built-in dictionary.  But you can also go on the 'Net and look it up on Wikipedia, or even do a general Google search.  And that kind of changes how I read.  I mean, I think that's really great.  Something you can't do unless you're at home with your reference library.



STEVE:  Yeah, it truly is connected.



LEO:  Yeah.  So anyway, I know people sometimes, there's a small percentage of our audience goes, no more electronic book stuff.  All right.  We're going to talk about security, don't worry.  But I just thought we should finish that up since I have had one now.



STEVE:  We just lost our bandwidth.



LEO:  I know, I don't know what happened.  You know, I think it's probably because I went to the Kindle site.  That was my mistake.  It's a very - it'll get better in a second.



STEVE:  You want to drop me and reconnect?



LEO:  You sound fine.



STEVE:  Oh, really, okay.



LEO:  You sound a little crunchy, but not badly, so.



STEVE:  Okay, cool.



LEO:  Let's see.  So I guess we should - oh, wait a minute.  Any other errenda?  Errata and addenda?



STEVE:  I have nothing else except I do have a really unique and interesting SpinRite story to share.  Around the middle of last month, middle of November, Chris Wickersham wrote an email saying, "SpinRite Saves the Encrypted Day."  And he said, "Hey, Steve, I know you get a lot of emails detailing how SpinRite saved the day.  But I thought my situation was unique enough that you might enjoy hearing my story."  Well, you know, parenthetically, I like hearing everyone's story.



LEO:  As long as it's good about SpinRite, why not?



STEVE:  Please keep them coming.  Anyway, he says, "I work for American Express, and we have an exclusive contract with IBM to do our desktop support.  We all use ThinkPad laptops.  And somewhat recently, to my great relief, our hard drives have been encrypted with a PGP tool."



LEO:  Oh, that's neat.



STEVE:  "This makes me feel much safer as it rides home with me every day after work.  Well, after a long weekend of work, I booted the machine Monday morning to check my mail, and the unthinkable happened.  Windows repeatedly bluescreened during the boot process, saying that it had an unmountable boot disk.  I traced the problem to a driver that was corrupted on disk and was hoping that IBM would be able to replace the fouled driver and get me back up and running once I got into work.  Unfortunately, I had not checked my work into CVS when I shut down Sunday night, so I was very anxious.  Well, shock of all shocks, the tech guys at work were unable to repair the corrupted file on the drive because of the encryption."



LEO:  Oh.  We've talked about this before because it's a big binary blob.



STEVE:  Exactly, I mean, it's not a file system.  You can't - if it won't mount and boot it's just, I mean, it's completely opaque.  Anyway, so he says, "Worse than that, they had no way to mount the drive so I could recover my data because of the encryption.  They used several tools to recover the drive, but to no avail.  So I threw caution to the wind and asked if I could take the drive home and try SpinRite.  Surprise.  After about an hour, SpinRite recovered several damaged sectors, and my machine successfully booted into Windows."



LEO:  The big surprise is that they let him take his computer home to work on it with SpinRite.  That's the real surprise.



STEVE:  He says, "I can't wait to tell them how well SpinRite worked.  And I hope that this leads to another site license for you, as I can't imagine I will be the last person to lose some important information on an encrypted hard drive.  Take care, and thank you for SpinRite."



LEO:  That's a nice story.  But really important to remember if you've encrypted is that you've got to back up because you don't have any - there's no file recovery.



STEVE:  Exactly.



LEO:  You're kind of in trouble.  All right.  We're going to - let's introduce Dave.  He's ready to go.  And he is - David Wright is the author of Jungle Disk.  Where are you calling from?



DAVE WRIGHT:  I'm in Atlanta.



LEO:  Great.  Well, sounds very good.  Steve's in Irvine.  I'm in Petaluma, Northern California.



STEVE:  Yeah, we've had actually - David contacted me after we first responded to, I don't know if it was a user question.  I think it might have been driven by a user who said hey, you know, what's the story with Jungle Disk and the Amazon S3 service.  And I took a first look at it, and sort of from a cursory standpoint I was impressed.  And the question I had, that I had not answered for our listeners, was whether it supported, you know, my acronym that I like is TNO, for Trust No One, did it support a mode where it operated completely free of any sort of oversight, whether the data being stored on behalf of the Jungle Disk system was stored opaquely from Amazon's standpoint so that it was impossible for them to decrypt it and so forth.  And so David shot me back a piece of email and said yes, it does support TNO.



LEO:  Trust no one.



STEVE:  Trust no one, exactly.  And then since that time we've had a bunch of listeners sort of pretty continuously, a little constant flow in the background, saying hey, whatever happened with Jungle Disk?  What's the story?  So I thought we'd get Dave on and talk to the man who put it all together.



LEO:  So Jungle Disk is kind of like a shareware deal; right?  How exactly do you do it?



DAVE:  Yeah, I mean, it's a pretty typical software model.  There's a free trial of the software available for 30 days.  You still have to sign up for an Amazon S3 account.  But after 30 days, if you like the software, you can purchase it for 20 bucks.  It's a one-time purchase.  We have free lifetime upgrades, as well, so you're never going to have to worry about getting the latest version.



LEO:  And for people who want to use S3 as kind of a backup system, Jungle Disk just makes that completely straightforward and easy.



DAVE:  Yeah, Jungle Disk has a built-in automatic backup feature.  So you can just tell it what files and directories you want to keep backed up.  But it also is fairly unique in that it exposes the S3 storage as a local drive letter, or a mounted volume on Mac, which allows you to use third-party backup software, too.  So if you're got other backup or synch software that you prefer to use instead of the built-in functionality, you're free to use that, as well.



LEO:  Why would I want to use a third-party app?



DAVE:  Well, you know, the built-in automatic backup is probably sufficient for 90 or 95 percent of our users.  But some users have very specific backup requirements in terms of what they want to back up, when they want to back up, either very advanced scheduling or just finer control over what they're backing up than the built-in automatic backup provides.  But we find that - go ahead.



STEVE:  No, I'm sorry, I was just going to say, I'm actually a really good example of that.  And we were talking about this just the other week, Leo.  I use something called FileBack PC, which is a very sophisticated backup tool that allows all kinds of wildcard expressions and, like, bizarre limitations on the minimum and maximum rate at which files can be backed up.  It allows you to do versioning and multiple versions and things.  So basically I could just aim my existing tool that I'm already aware of and I own and I'm comfortable with, at a Jungle Disk volume.  And these things then go to Amazon rather than being stored on another drive locally.



LEO:  And the nice thing about Amazon storage is it's very inexpensive.



DAVE:  Yeah, I mean, it's extremely cost effective.  The basic rate is 15 cents per gigabyte per month, which is very inexpensive.  Now, they do have additional fees based on the amount that you upload and download.  But over the long run the bulk of your cost is going to be your monthly storage fees because that's what you're having to pay each month.  And at only 15 cents per gigabyte, most Jungle Disk users are only paying, you know, a couple bucks, one, two, three dollars a month, for the actual storage that they're using.  So it's pretty cost effective.



STEVE:  Well, now, it's also multiplatform.  You've got Windows support and Mac support and Linux support.  And then additionally you're able to run this, which I think is very cool, from a USB device so that it runs in a no-install sort of mode.  So literally, if you had a little USB dongle, you can carry that around with you.  You stick it into any machine.  It's able to connect through that machine's Internet connection to Amazon.  And you have then access, you basically have secure roaming access to your whole archive of data stored by Amazon.



DAVE:  Yeah, that's right.  That's something that we got quite a few requests from for people that wanted to use the software remotely without having to install it or keep any files on that local machine.  They can just bring their USB keychain, plug it in.  It's got their configuration already on it.  It's got their encryption keys already on that keychain.  Fire it up, copy down the files they need, upload any new files they need, pull the keychain out, and it's all gone from the machine.



STEVE:  So, okay.  You have a 30-day trial.  Right now you're calling it an introductory offer for $20 that allows you essentially lifetime use of this.  What's the model?  Is there a deal with S3 where you get a piece of Amazon's action?



DAVE:  No, no, no, not right now.  The user pays Amazon monthly for that service, and that money goes to Amazon and pays to keep the service running.  You know, our model is pretty straightforward.  We're selling the software.  And we're able to have the rate that low just because this is a mass-market product.  This is something that at least we think everybody needs on their computer, that everybody needs to be doing backup.  And online backup is really the way to go these days.  So we've got a huge target audience that we're looking to sell into.  And we don't want to limit ourselves by pricing it, you know, at 50 or a hundred bucks or something like that.  We want to make it as easy as possible for people to sign up, download it, and start using it right away.



STEVE:  Very cool.  So really, so the motive for you was you saw the service that Amazon was providing and said hey, you know, we can write a really cool and unique front end to the Amazon S3 service, which is not itself a turnkey end-user sort of consumer-level service, it's always meant to be a back-end data storage solution, and that it needs other front ends like Jungle Disk in order to actually make it useful for end-users.



DAVE:  Yeah, I mean, a lot of people ask, well, you know, if I'm signing up with Amazon, then why do I need Jungle Disk at all?  And the answer is that, like you say, there's no front end to Amazon S3.   You can't go to an Amazon S3 website and browse your files or upload files.  And Amazon doesn't provide any software for it yourself.  So you have to use a third-party application like Jungle Disk to get access to S3.  And Jungle Disk is even fairly unique in that area.  A lot of other companies are using S3 as back-end storage for their filesharing or backup or whatever company.  But they don't actually allow you to have your own Amazon account and have control over your own data on Amazon.  Jungle Disk is fairly unique in that respect, at least among the commercial software, because even though you're buying this commercial piece of software you still have your own Amazon S3 account.  You still have complete control over your data.  And our company doesn't see or have access to your data at all.



STEVE:  I have to say, I've spent a lot of time now going over your website, reading the FAQ, looking at the instructions.  I've got it installed on several of my machines.  And that's one of the other nice things that you explicitly allow is one copy, one registered copy of Jungle Disk can be used on a single individual's different machines and give them then sort of like centralized access to this repository in the sky which Amazon maintains.  Amazon is storing things redundantly within their own network, which is obviously robustly connected to the Internet.



DAVE:  Right.  I mean, that's something we heard pretty strongly from users is that they wanted to use the software on many machines, home machines, work machines, laptop machines.  And so it really didn't make sense to try to sell the software on a per machine basis.  Some of our users would have to buy five, six, seven copies.  So we just said, look, you know, we're going to make it as simple as possible.  Buy one copy, put it on as many machines as you want.  You know, it can only be used with your Amazon S3 account.  So if your buddy wants the software he's going to have to buy it himself.  But we don't try to limit them on what machines they can put it on or even what platforms.  When you buy it, you get all three platforms.  So if you've got Mac and Windows machines and you want to share files between them, this is certainly a good way to do it.



STEVE:  Now, in use there is a little contact by the Jungle Disk client back to you guys.  What's that about?



DAVE:  Well, you know, on startup we have a typical automatic update check.  It reports to us the version and some information about the client so that we know who's using the software, and for the trial users we know when their trial period is up.  Once you purchase the software, though, you have the option to turn that off completely.  So if you're one of those super paranoid people that doesn't want the software talking to anybody but Amazon, you can certainly do that.  We recommend users keep it enabled because it does provide update notifications, which can certainly be important for software like this.  If some kind of security issue was discovered, we want people to be able to find out about it.  So we do provide the option to turn that off, though.



STEVE:  That sounds cool.  I mean, it's everything that I know that our listeners want.



DAVE:  Sure.



LEO:  I have - I use ChronoSync, and I'll probably use your program, too, Steve, on my PC.  So that sounds like - I've been trying to figure out a good way to get this working with S3.  Also trying to get it to work for my web server because it would be really nice to back up web server stuff to S3.



DAVE:  Yeah, we've got, you know, we've got a few people already that are using it on servers.  And it's not really targeted towards that market right now.  It's really designed to be a desktop consumer product.  But, you know, there's a lot of people that are interested in using it in offices or in servers, too.  So, you know, you can certainly use this current version of the software in that space.  But we're probably going to be developing some additional editions of the software that's more directly targeted towards server platforms, for example, in the future.



LEO:  That'd be great.



STEVE:  Well, and speaking of servers, I know that, Leo, you and Paul have been talking a lot about Windows Home Server.  And Paul's a big fan of that.  And there is a version of Jungle Disk specifically for Windows Home Server.  How does that differ, and how does that operate, Dave?



DAVE:  Yeah, that's right.  In conjunction with a contest that Microsoft was running earlier this year, we developed an add-in for Windows Home Server that's based on the same technology as Jungle Disk, but it is a separate product, and it does work a little bit differently.  But basically what it allows you to do is install this Jungle Disk from Windows Home Server directly on your home server machine and select which files on your home server machine you want to have backed up online.  And from there it takes care of it automatically.  It just keeps everything backed up that you've selected on your home server.  And if you ever need to restore it because your home server crashes or because, you know, you accidentally delete something, you can use the Windows Home Server console to select the files and restore it directly back to the Windows Home Server box.



LEO:  That's neat.



DAVE:  So that edition of the software is in beta right now.  There's actually a free beta version of it people can download from our website.  And so far the response for it's been very good.  We actually came in second in the Microsoft contest, so that was exciting.  But the Windows Home Server audience is obviously very interested in data protection, and this really just increases the level of security that you get by backing up your important files offsite.



LEO:  Well, Paul must have seen it.  He was a judge in that Home Server contest.  So I'm sure he voted for you.



DAVE:  Yeah, yeah, Paul was.



LEO:  Yeah, I'm sure he voted for you.  Very cool.  Very neat.  And Amazon is to be praised for not only providing the service, but providing APIs that developers like you could hook into.  Was it pretty easy to write this software?



DAVE:  Well, you know, the initial version, it took a little bit of time to get together because Amazon built it as a very generic service.  They didn't build a lot of the things that would be very handy for a backup service.  But because it's a generic platform and they want it to be used a lot of different ways, they provide a very sparse API.  So we've had to build a lot of functionality around it to get it to work well for customers.  So...



LEO:  Are they using WebDAV, or are they doing something else?



DAVE:  No, they have a proprietary REST API, and they also have a SOAP API available.  Now, one of the secrets to Jungle Disk in terms of how it actually works is that it exposes a local WebDAV server and proxies and changes that request into a proprietary S3 request.  So on your local machine, and this is the way the drive mapping works, it actually exposes a little WebDAV server so that your local operating system can talk to it over WebDAV.  And then it translates that request into the proprietary S3 API.



LEO:  So that's how you do it.  That's very clever.



STEVE:  Yeah.  A perfect example, I think, of the sparsity is, for example, the way Jungle Disk handles file renaming.



DAVE:  Yeah.  For example, Amazon S3 doesn't have built-in support for renaming files, which would seem really simple.  But again, in their design they wanted it to be a bulk object storage-oriented interface.  And so they didn't provide a way to rename objects.  And so what we've done is we made use of another service offered by Amazon, which is called EC2, which is a virtual hosting service that allows you to host servers within Amazon datacenters.  We made use of EC2 to build functionality that allows you to rename files without pulling them down to your machine and reuploading them back to Amazon.  And so it does it in a fast and secure way, directly on the Amazon network.



STEVE:  And I guess really the last thing to talk about, well, I don't know if it's the last thing to talk about, but really the genesis of this whole question of Trust No One is the way Jungle Disk works with sort of the keys you always have when you work with Amazon, and then the ability to create your own sort of pre-Amazon encryption which is completely separate from anything Amazon has any knowledge of.



DAVE:  Yeah, that's right.  So Amazon provides, you know, pretty typical authentication through a secret key that, you know, is shared between you and them.  And that's used to authenticate access to your account, prevent anybody else from getting access to your files.  But then on top of that Jungle Disk layers its own encryption that takes place on the client, so Amazon never sees the unencrypted content at all.  The encryption takes place on the client.  You can select a custom key, anything you want.  It's 256-bit AES encryption, so it's extremely secure.  The encrypted content gets uploaded to Amazon.  And when you need to pull a file back, it pulls the encrypted data back from Amazon and decrypts it locally with your key.  And if you don't have the key, you don't get the files.



STEVE:  Do you think that Amazon themselves uses the user's key to encrypt the data when it's stored statically at their end?  Or do they just, like, just store whatever you give them and make no attempt to protect it from, like, people over on their side?



DAVE:  You know, they don't really say a lot about the internals of how the service works and whether they encrypt it or not.  One of the things I certainly know about it is that they use a very proprietary back end and storage system for this.  So it's not like they're just dumping it on a file server that somebody even at Amazon could go browse around.  It's stored in a very, you know, unique, proprietary format.  So I don't know whether they layer encryption on top of that or not.  But we always tell users, if you're concerned about that type of privacy for your data, then you definitely need to encrypt it on your client before it goes up because that's the only way you can have complete confidence in the security.



STEVE:  Right.  And then I also like the way you guys have handled the issue of key migration, that is, if you have a bunch of content already encrypted up on Amazon, and for whatever reason you decide you want to change the key, the problem is of course that that prior content has been encrypted with your first key.  Now you want to go to a second key.  You put a little header and some metadata on the front of each file to identify which of the user's keys was used for encryption without actually having the key there, so nothing in the metadata at the top of the file allows anyone to decrypt it.  However, it allows Jungle Disk to still be able to access old content encrypted with a prior key, so long as you've left that key in a list of keys that Jungle Disk has access to.



DAVE:  Yeah, exactly.  We basically allow you to change your key anytime you want.  But again, because the encrypted content is already stored at Amazon, unless you want to reupload your file to reencrypt it with a different key, you know, we need to keep a list of your previous key so that if you ever go access that content that was encrypted with an older key, it can still be accessed.  And we keep track of the key that's used for each file in a special metadata section that Amazon provides.  And that lets us know how to decrypt the file when it comes back.  But it's done in such a way that's secure and that it doesn't tell anybody anything about which key was used for which file, and they don't know anything about the keys.



STEVE:  Right.  Well, I just love it.  I think it's, you know, it answers, I think, a huge need, especially as people become more mobile.  I like the idea, for me, not only of being able to back things up, but to keep copies of files that I'm working on that are like ongoing references.  Like I run my life on outlines.  And so to be able to put the outlines there and keep them synchronized so that I'm not having to manually synchronize my various machines, I mean, it's just - it's a really cool solution.



DAVE:  Yeah, I think so.  I mean, that's really what our customers are saying.  Everybody's been talking for a long time about storage moving into the cloud.  And, you know, there's been a lot of issues around that, specifically around trust.  And so that's one of the big things we've tried to address, both on the back end by having Amazon  manage the back end as a large, trusted company that you know isn't going to disappear tomorrow or run off with your data; but then also address the security on the client side with the encryption so that you know that nobody, even Amazon, is able to actually access and see your data.  It's completely under your control.  And I think that those two things together are what are finally enabling people to say, you know what, I finally can trust to put some of my important data on the 'Net and access it, you know, wherever I travel.



LEO:  That's cool.  Jungle Disk is free for 30 days, $20 for a lifetime license.  You can get it from JungleDisk.com.  And of course Amazon S3 is an additional charge, 15 cents per gigabyte storage per month.  But it ends up being very, very affordable.  And, yeah, a great place to have it in the cloud.  There are, of course, packaged solutions like Mozy and Carbonite that are easier probably for people to use, but not as portable by any means.  Thank you so much, Dave.



DAVE:  All right, well, thank you very much.



LEO:  Really appreciate your time.



STEVE:  Thanks, Dave.



LEO:  That's Dave Wright from Jungle Disk.



STEVE:  I'm really glad we've covered this, Leo.  As I've said a couple times, I've had a constant stream of our listeners sort of pinging me every few weeks saying hey, Steve, you were going to check in on the Trust No One operation.  And I've got to say, I mean, you get a feel for things as you use them.  And I really got - I have a really good feel about this.  To me, the operation of the tool is very transparent.  Their motivation is very transparent.  They even provide an open source set of files that shows how they access Amazon.  And although for $20 I don't think there's anyone who's going to go develop their own client copying Jungle Disk, and it doesn't have all the features that their client does.  But the whole thing feels just solid and open.  And it's just - it's done right.  So as a solution for what this is, that is, the idea of being able to use Amazon's S3 service in a very, very trust-no-one secure fashion, Jungle Disk does it.



LEO:  It's neat.  It's really neat.  Again, I think it's cool that Amazon does API.  And it's not a very sophis- as he said, it's not a very sophisticated API.  It's basically just using existing technologies like REST and SOAP.  But a lot of programs know how to interface with REST and SOAP.  And so you kind of - it's a little bit of lowest common denominator; but at the same time you're kind of guaranteeing people are going to be able to figure it out, which is obviously important to let this kind of thing happen.



Let me see.  I have a high recommendation for a website that I know called GRC.com.  If you are a happy listener and you're looking for transcripts, if you're looking for 16KB versions, if you're looking for more information about security, that's the place to go.  And of course SpinRite's there, too, and all of Steve's stuff, the free stuff, too, like ShieldsUP and Shoot The Messenger and DCOMbobulator and PPP and Wizmo and all that, GRC.com.  And GRC.com/securitynow for show notes.  There's also a great security forum there.  And feedback is there, too.  Is it GRC.com/feedback?



STEVE:  That's exactly what it is, and I really want to encourage people to keep the feedback coming.  It helps us steer the show and tells us what you're interested in hearing about.  Many people have said hey, you know, you guys used to do more of sort of like current events in security, a little more on, like, what happened in security this week.



LEO:  We can do that.  We could do that.



STEVE:  And I'm going to make a New Year's resolution for Security Now! as we start into '08.  I'm going to return us  more, well, a little bit to that, just sort of to touch in and check in and make sure that our users know of anything important that happened during the week in security.



LEO:  Good idea.



STEVE:  After all, as someone did write, they said, you know, it's called Security Now!.  It's like, oh, good point.



LEO:  Well, I don't know if that means what's happening in security now.  I mean, just be secure right now.  Doesn't necessarily mean security current events.



STEVE:  That's true.



LEO:  It could be a lot of different things.  But, yeah, sure, of course.  Whatever you want, that's the point.  Securitynow.com/feedback [GRC.com/feedback].



And I'll remind everybody that we've got the TWiT discounts on ScotteVest now.  I know we're all ScotteVest wearers.  And if you want to give a gift for a geek, there's nothing better than a ScotteVest.  Any gear on the site, ScotteVest.com.  On checkout, use my name LEO as a promo code, you get 20 percent off, right off the top.  This doesn't include ScotteVest material on ThinkGeek.  That's a separate system.  But on the ScotteVest site.



And Scott called and said, apologies that we're selling them out like hotcakes.  Those fleece - I think the hoodies and the fleeces, they're backordered, and you may not get it by Christmas.  In fact, I don't think you will.  It's too late to get it by Christmastime.  But just check the site.  They'll let you know what you can get in time for the holidays.  But what a great - I wanted to give you a couple - last chance, I guess, to take advantage of this at ScotteVest.com.  Use my name, LEO, for the coupon code at the end and save 20 percent.  We thank Scott, too for his support of the shows and the TWiT network and for all his great stuff that I wear all the time.



Steve, next week we'll do a Q&A session, speaking of feedback.  That'll be our kind of mid - post-Christmas, pre-New Year's episode.  So we'll see you then next Thursday, folks.  Have a great Christmas, a great holiday, Steve.  I hope you enjoy your time - I was going to say "time off."  Whatever it is you do.  You don't take time off, so I hope you enjoy the week.  And we'll talk again next week.



STEVE:  Right-o.



Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#124

DATE:		December 27, 2007

TITLE:		Listener Feedback #31

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-124.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 124 for December 27, 2007:  Listener Questions #31.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now! with Steve Gibson, the post-Christmas, pre-New Year's edition.  Leo Laporte here.  Steve Gibson is in Irvine.  And we should just say that we are not yet eggnogged out because we're recording this before Christmas.



STEVE GIBSON:  Yes, we are.  We wouldn't miss an episode, and we wouldn't leave our listeners hanging and saying, wait a minute.



LEO:  You're amazing, Steve.  And I'm in Egypt.  That's the other reason.



STEVE:  You've made time for this, Leo, so I really appreciate that.  And I know our listeners do.



LEO:  Oh, no, yeah, no, you will now - I believe you will now have surpassed TWiT for the number of shows, at least after this one.



STEVE:  Finally.



LEO:  Damn that Steve Gibson.  Damn you.  So we're going to do a Q&A this week, Listener Feedback #31.  And we've got 12 great questions, including the official Duh! of the Week Award and the Fantastic Tip of the Week Award.  I love that.  Do you have any addenda, anything you want to handle before we get into the meat of the matter?



STEVE:  I did want to say at the beginning of the show something that I mentioned at the end of our show last week.  And that is that I've had a number of people who have written in using the feedback form.  I want to remind people about that as you always do, Leo, GRC.com/feedback, to allow people to send us their notes and thoughts.  I get ideas for show topics and sort of some - it's an informal steering committee that I do pay attention to.  A number of people have said, you know, the show is called Security Now!.  Let's have a little bit more of the "now" in that.  And they're right.  We were probably a little better in our first year or two about talking about things that had happened that week, important things that came up.  But I've gotten a little sort of out of focus on that.  So my New Year's Resolution for the show is that in '08 and on we're going to - I'm going to be a little more focused on and maybe sort of add a little section at the top of each show about anything important that happened in the week in security news that we need to make sure our listeners are aware of.



LEO:  But not this week because we're taping it ahead.



STEVE:  Exactly.



LEO:  So we don't know what's happened.  But nothing's happened, it's the week after Christmas.  What could go wrong?



STEVE:  And we did have a listener, actually this is the one I noted, although a couple of people made a point of mentioning that I misstated the processor in the - remember we were in our little nostalgic phase a couple weeks ago.  And I said that the chip in the original PC was the 8008, when in fact...



LEO:  It was the 8088.



STEVE:  Exactly.  The 8088 had sort of some 16-bit stuff in it.  It was still largely...



LEO:  It used a weird address space, as you well know, that weird extended address space.



STEVE:  Oh, as an Assembly language, yes, as an Assembly language programmer I found out about segmented address spaces.  And I was really glad to go to a 32-bit flat address model when we finally got there.



LEO:  Right about when that came out I was writing Assembly code for the 68000, which had a flat space.



STEVE:  Oh, and a much nicer chip, too.



LEO:  It was a really elegant instruction set.  It was very easy.  My friend, Tim Pozar was writing Assembly code for the - we were both learning Assembly code at the same time.  He was writing it for the X86, the 8088.  And I've looked at the hoops he had to jump through to do memory addressing, and I thought, that is - because you have to rotate it over and, oh, it's just crazy.  They had, what, a 20-bit, was it a 20-bit address space that they extended to make look 32?  Or was it 24?



STEVE:  Good memory, Leo.



LEO:  Was it 20?



STEVE:  No, it was 20-bit.  Because in 16 bits you're able to access 64K.  And that's where the 640K sort of came from was they added 4 bits, and then you were - so you're able to use those to access the total address space of the system.



LEO:  Right.  I apologize that Steve's quality all of a sudden - for some reason Adobe decided to download a 386-megabyte update to Photoshop.  Stop it.  Bad Adobe.  Okay, it's stopped now.  You'll sound better in a second.  This is a problem, you know, with Skype, Skype sounds great if you have all the bandwidth dedicated to it.  But as soon as - and computers nowadays, they're always doing something in the background, something without asking permission.  So I think you'll sound better now.  So it's an 8088.



STEVE:  It's an, yes, 8088 is the chip that was in that one.  And then an 8086, no, I'm sorry, the 8286...



LEO:  80286, yeah.  That was the AT.



STEVE:  That's what was in the PC AT, yeah.  So correction in errata mode.



LEO:  Hey, that was a long time ago.  Come on.  You can't expect us to remember all that.  It's pretty amazing that we remember as much as we do.



STEVE:  If and when we do our old fart show with the old geezers, I'm sure there'll be all kinds of things where we're saying, wait a minute, like correcting each other in our aging.



LEO:  That'll be fun.  I'll have Wikipedia open as we do it, just to keep us honest.  I thought you said 8088 because I wasn't listening closely enough.  I mean, come on.  But it's good to know we believe in getting things right.  You got any great SpinRite - I bet you do - SpinRite stories?



STEVE:  What would make you think that?



LEO:  I don't know, I just thought you might.



STEVE:  Okay, get this one, Leo.  SpinRite aids hearing.



LEO:  No, come on.  Now you've gone over the top.



STEVE:  SpinRite helps you hear better.  This one we received toward the end of November from a SpinRite user, Steve Nicholas, who said, "I'd just like to share a SpinRite success story with you guys.  I'm a freelance IT consultant.  And last week I got a call from a client of mine who's an audiologist.  They have a dedicated PC link to some hearing testing and hearing aid programming equipment.  This particular day they had switched on the PC, and Windows loaded, gave them an error about missing DLL, and then they had no desktops or any other option but to turn the PC off.  Luckily this was a quiet day for them" - so to speak, the audiologists.  Anyway, "This was a quiet day for them."



LEO:  I get it.



STEVE:  "But they had lots of hearing assessments booked in for the following day.  I looked at the PC and tried to start in Safe Mode, but still nothing worked.  I then booted from a Windows XP CD and ran Check Disk.  Alas, Check Disk reported that there were bad sectors on the drive and unrecoverable errors.  I informed the client that they'd need to replace the hard drive and might possibly have to reinstall the OS and the apps from scratch.  He looked even more worried and explained that he didn't have the CDs for the audiology software as it had been installed by the equipment manufacturer and was a nightmare to calibrate from a new install.  I said I'd try my best and took the PC back to my workshop with the intention of cloning the partition to a new disk.  But unfortunately the cloning software said there was a fatal error reading the drive.  It was not looking good for the PC or my client.



"I then fired up SpinRite and left it running on the PC overnight.  The following morning SpinRite had fixed the drive.  And hey, presto, the PC booted up as normal.  The BIOS SMART monitor said the drive was in danger of imminent failure, so I quickly cloned it onto a new disk and had my client's PC and audiometer equipment up and running by 9:00 a.m., and no appointments had to be canceled, and the practice could operate as normal, much to the relief of my client and his patients.  Great work at GRC."



LEO:  Yeah, that's a lifesaver.  Wow.  There you go.



STEVE:  So SpinRite does it again.



LEO:  Got to keep, you know, we hear you, SpinRite, we hear you.  So let's talk a little bit - actually, speaking of hearing you, we have listener feedback.  Not that kind of feedback, feedback from our listeners.  So let's get to our first call if you would like.



STEVE:  Absolutely.



LEO:  Or first email, I guess.  Stephan Buys in South Africa.  He says - you say he scrutinizes every cookie:  In the light of the recent privacy discussion, I wanted to offer the following advice - by the way, that was a great show.  That was Episode 121, I believe, we talked about privacy.



STEVE:  "Is Privacy Dead," yes, right.



LEO:  I wanted to offer the following advice regarding cookie management.  Perhaps my approach is slightly over the top, but I found it does not impact my day-to-day surfing.  See, that's my problem.  You turn off cookies, and everything stops working.  Apart from disabling and managing JavaScript using the Firefox NoScript plug-in, I've disabled all cookies in Firefox in preferences.  You do this by unticking the "accept cookies from sites" box under the Privacy tab.  Okay.  You can then go to the exceptions button on the same page and manually enable cookies by site as you need them.  I've explicitly enabled cookies for things like Audible where I choose to stay logged in, but most sites are blocked.  So it's kind of similar to the NoScript, where you opt out unless you specifically, explicitly opt in.



STEVE:  Yeah.  I liked his idea because I know that we've got listeners who really want control and who want to go even further than somebody who, for example, wants to just block third-party cookies.  My normal practice is to allow first-party cookies but to disable third-party cookies.  However, we've seen, for example, that there are still ways around that, such as we discussed in the PayPal/DoubleClick episode, where if PayPal hosted a link to DoubleClick that bounced you back to PayPal, then you'd be doing a first-party DoubleClick cookie.  So what Stephan is talking about is, you know, goes further.  And it would even block that sort of first-party cookie approach.  So he's disabling even first-party cookies by default, and then he makes exceptions.  As you said, Leo, he's opting into specific cookies that he wants to allow.



I'll mention that IE offers the same feature.  That is, you are able to say I want to disable all cookies and then manually allow cookies only for specific sites.  So if that fits people's way of operating, I wanted to make sure that they knew that was a possibility.  You could allow MSN and Amazon and PayPal and explicitly the sites where you want to maintain an ongoing relationship with the site.  You want to be able to stay logged on or be able to browse around.  If the site is really broken, as frankly a lot of sites will be, then you can - but you say, okay, I care about this site, then you explicitly enable cookies only for that domain.  And so the browser defaults to not ever sending cookies back even when it receives them, and only does so on the sites where you permit it.  So again, it's a more restrictive policy, but it's going to be protection against even the first-party referrer approach that we described in the PayPal DoubleClick episode not too long ago.



LEO:  The problem is, of course, knowing who to trust.  And especially since, I mean, you'd think you'd trust PayPal.  I guess I trust Amazon.  But now what we've learned is more and more that these sites have deals with advertising companies like DoubleClick.  And I don't know, can you?



STEVE:  In fact there was a blurb in the news a couple weeks ago, Leo, that sort of raised my hair a little bit.  There's another company that is a major mail-order, physical world company that is talking also about combining that with online presence.  That is, they're explicitly saying we're going to partner with people who are companies like PayPal, like Google perhaps, who do know your actual name and address, and who have given you cookies in order to match you up, to match your offline existence...



LEO:  Ooh, that's really scary.



STEVE:  I know, it really is - to match your offline presence with your online presence in order to cross that boundary.  And it's, I mean, it's something to be concerned about.  And of course we've got Google purchasing DoubleClick that's one of the - well, in fact, DoubleClick apparently purchased a company some years ago that talked about doing this.  And the outcry that came up ended up pushing them away from that practice because people were so upset with the idea of not only being tracked on the Internet anonymously, but making it non-anonymous.



LEO:  Oh, boy.  Well, let's hope - I think that awareness is so key.  And as consumers do kick up, people, you know, nobody wants to make their customers angry.  So there is some hope because when consumers kick up they do back off.  We just have to stay aware of it, I think.  That's really the key on this.  So good suggestion, Stephen, or Stephan, I should say.



Ryan in Indiana had an interesting suggestion for WiFi security:  I was listening to your podcast regarding using SSL, VPN, and SSH, one or the other, I guess, whilst traveling hotels and such, when needing to use a nonsecure network.  My question is, while it's a great idea to use VPN to your home router while away, why not use VPN in your home to secure your wireless?  It could be in lieu of or in conjunction with WPA, especially if you're using hardware or devices such as media extenders that don't support WPA.  Would that - well, but if they don't support WPA, are they going to support VPNs?



STEVE:  Well, for example, we know that one of the show's sponsors, Astaro, offers SSL VPN, which tends to be the most compatible.  We talked about this back in our early VPN episodes, that there were real problems with the traditional IPSec and PPTP protocols because they just weren't very flexible.  But it absolutely is the case that this is - it's a workable idea.  If for whatever reason your wireless did not support WPA, yet you had a router or some device that did support a VPN, and you're able to connect to it from your laptop, that is an absolutely rigorously secure connection which is proof against man-in-the-middle attacks of any sort, any kind of ARP sort of poisoning games.  It's an absolutely workable solution for protecting your traffic.  Somebody who was to hack, for example, your WEP key, or even leave your wireless open if you're not concerned about people connecting to your network by mistake, they would only see random noise packets going back and forth and would ever be able to get up to any mischief except that it, again, would be able to use your connection, which might or might not be a problem.



LEO:  Oh, that's interesting.  So that would be a way, if you wanted to open a connection up, that would be a way to do that.  That's interesting.



Jeffrey in Columbia, Maryland has an idea about his system's hosts file.  In past episodes we spoke about hosts files and how using it can limit your computer's exposure to some of the unwanted sites out there.  Just to recap, you change your hosts file on your system, and you can block sites that way, point their IP address toward a localhost, for instance.  So I was wondering, would entering your bank's URL and the IP it resolves to in the hosts file protect you from phishing attempts and/or man-in-the-middle attacks?  That makes sense.  So you have a BankofAmerica.com, and you hardwire it to their IP address.



STEVE:  Well, yeah.  I mean, that is the idea, although I wanted to sort of clarify for Jeffrey and other users what the hosts file does.  We've talked often about DNS, the Domain Name System, and how when you put in, for example, www.mybank.com, your computer goes out to the registered DNS server - typically that's offered by the ISP, it's running by the ISP - and asks that server if it happens to have a local copy of the IP address for www.mybank.com.  If not, then it may resolve it for you.  It'll go and find the current IP address for that and then end up returning that result to you.  The hosts file is like a place your computer checks in before it makes an external query.  So if you had in your hosts file www.mybank.com, and then the IP address that is the IP address for that domain, then one thing it is is faster because you're not having to go out and look it up.  So there is a speed boost.  However, most phishing attacks aren't trying to change the IP address associated with a domain name.  They're, for example, misspelling it to mybank2.com, hoping that you're not going to notice that there's a numeral 2 after mybank.com.



LEO:  So that's not going to fix it.



STEVE:  Exactly.  So it would not prevent that kind of phishing attack.  Now, I'm not sure what he means by man-in-the-middle.  There are DNS man-in-the-middle attacks.  So that, for example, if someone could infect the DNS system, and there are various types of DNS poisoning that have been done, then somebody could artificially change the IP returned for an external query to mybank.com and then end up intercepting anybody who was affected by that DNS poisoning and route them to essentially a hostile service and perform essentially a man-in-the-middle attack that way.  So in that case, hardwiring the IP for your bank in your hosts file would prevent that kind of attack.  The only other problem with doing so is that DNS can be used for load balancing.  Major sites, for example AOL...



LEO:  They change the DNS.



STEVE:  Exactly.  Major sites like AOL will not have a single IP for AOL.com.  They'll have a block of maybe, I mean, they may have a block of a hundred.  But on any given query you'll typically have, like, five.  And they'll rotate every time the query is made.  The DNS server has logic in it which rotates that list so that there's a balancing effect.  Everybody who asks for AOL.com has the IPs spread out among a number of different servers so that no one of them ends up carrying all the load.  So if you were to hardwire one IP, then you would not get the benefit of that kind of load balancing.  And of course the other problem is, if the bank's IP changed, you would suddenly find, because your hosts file would not be updating itself, you would think that your bank had gone offline.  And in fact you'd be using the wrong IP for your bank if the DNS changed but your hosts file didn't.



So, I mean, it can give you a speed boost.  It can prevent a DNS poisoning attack from succeeding.  But on balance it's probably better to use it to block things you know are malicious.  For example, we know that if you put DoubleClick.net into your hosts file and aimed it at 127.0.0.1, which is the so-called localhost IP, it will prevent your computer from ever having contact with the actual DoubleClick domain under all circumstances.  So it's probably more useful to block things you know you want to block rather than trying to hardwire IPs for things that you want to prevent DNS from causing any problems from.



LEO:  Good point.  Very good point.  It was a try.



STEVE:  Yeah.



LEO:  Yeah.  Anthony DiSante in New Tripoli, Pennsylvania likes pushing buttons:  I love the podcast, and many of Leo's other podcasts, too.  Thank you, Anthony.  I purchased the PayPal football as soon as you guys mentioned it, and I feel much safer now that my account requires it, although I wish they didn't use the simple account number check as a fallback for when you don't have the football with you.  I agree.  That really obviates the whole thing.  I also purchased the VeriSign VIP card when you brought it up.  The card is so cool.  However, I think I've discovered one big downside to it.  You must use every number it generates in order, or else it gets out of sync with the PayPal server, which then starts rejecting its numbers.  Now, I haven't found that to be the case, but...



STEVE:  I know.



LEO:  Because the card is so cool, I've been showing it off to my friends, and naturally I'm pushing its button to generate a new number in order to show off the display technology.  But apparently with the VIP you just can't do that.  You can't throw away numbers as you can with a football and its time-based algorithm.  Is this indeed the case?



STEVE:  Sort of yes and sort of no.  I'm in the process of coming up to speed on the details of this.  I have the documentation from VeriSign, and they've followed through now and created a formal evaluation account which will allow me to use these tokens in order to do validation.  I'm hoping to get to that over the holidays.  So probably by the time people are hearing this I may have been able to cross that bridge.  But I have everything I need to from them, so I'm excited to spend some time doing this.  The way VeriSign's back ends work, they're aware of people that might be pushing the button.  I think that Anthony probably really likes to push the button.



LEO:  Yeah, I haven't had any trouble at all.  It seems to keep up fine.  So it's not doing what the football did.  The football generates based on - the number is based on timing; right?  So...



STEVE:  Right.  In the API there is absolutely a window.  In the case of the football, that is based on time, you have a plus and minus window so that you can decide how far into the past or into the future, that is, how much desynchronization between the football's time-based token and the VeriSign servers are allowed.  In the case of the credit card form factor, there's no backwards.  There's only forwards.  But so there is a window that says how far into the future of codes do you want to accept?  How tolerant do you want to be of people like Anthony who are pushing his button all the time on the card and advancing the counter forward?  And individual users of the VeriSign authentication system have the choice of how restrictive they want to be.  So I'm not sure who he's authenticating with.  But for example, if he's authenticating with PayPal, then it may be that PayPal has decided they want to be rather narrow and not allow, for example, more than 10 or 15 numbers ahead.  Although certainly, once you resync yourself with PayPal...



LEO:  Now, how do you resync?  By having a correct entry?



STEVE:  Yes.  I believe it's two in a row.  That is, you give them one too far in the future, and they say, okay, we see you, give us the next one.  And then by asking for two in a row that relocks them and proves that you have the card because you know not only this one but the immediate next one.



LEO:  I see.  Some people have said, oh, it's asked - and I've said it's happened to me - it's asked again after you enter it once.  So that's what's going on, it's resyncing.  



STEVE:  Yes.  That's why the double request.



LEO:  Okay.  I guess I don't push it as much as Anthony does.  I mean, I have.  I play with it.  But, well...



STEVE:  It's fun, yeah, yeah.



LEO:  I don't play with it all the time.  Chris in Los Gatos, California has been studying his RSA SecurID token.  Is that the one we're talking about?  Is that the same one?



STEVE:  No, no.  Now, we've been talking about VeriSign, and RSA is very different.



LEO:  They're a competitor.  He says:  I found an error with your comments about the RSA SecurID.  It seems like the PayPal keys that you and many people have talked about are different than the ones I use at work.  I work for a large aerospace company.  I do mean large.  Everyone's probably heard of the company; the initials are LM.



STEVE:  I think that might be Lockheed Martin.



LEO:  Lockheed Martin?  Or Leo's Machinery?  I don't know.  You have said that the PayPal keys have a sequential first digit, add one to the value of the first digit for the next key number.  My RSA SecurID that I use for corporate VPN does not have any sequential digits, and there's no predictable pattern in any of the six digits that appear on my key.  And as we know, that's a better thing.  Does this mean I have more security than your PayPal key, since I have six digits of random numbers and yours only has five?  Considering the company I work for, we have a very good reason to keep what we work on as secure as possible.



STEVE:  Well, I wanted - I'll correct Chris a little bit.  He said that there's no predictable pattern in any of the six digits that appear on the key.  I would say, well, there's no...



LEO:  He can't predict it.



STEVE:  Exactly.  There's no trivially predictable pattern.  But it's certainly the case that it's based on a pseudorandom sequence which is absolutely predictable, although you need a crypto algorithm in order to figure out what they're going to be next.  But he's right about his point that the so-called PayPal football, as we refer to it, the time-based token that those guys use does have, as we've discussed, the first digit increments sequentially, which is used as a shortcut, allowing the server to guess within a plus or minus couple minute window which key you're on.



Now, as to is it more or less secure, it's like, well, okay, I suppose - and as we've discussed also, that the fact that you've made one digit predictable then brings the challenge down from one in a million to one in a hundred thousand.  On the other hand, it's changing every 60, I'm sorry, every 30 seconds.  So the only reasonable attack would be some sort of brute force attack.  But the target of the brute force attack changes every 30 seconds.  And you're always authenticating about a back-end server.  So the back-end server can say, wait a minute, this guy has just missed five attempts.  We're going to lock him out.  Or we're going to slow down our responses.  Or we're going to wait on purpose for another 30-second window to pass by in order to prevent that kind of attack from happening.  So I guess what I'm saying is that, yes, technically the PayPal football approach that has one predictable digit is one tenth as secure.  However, it's already way more secure than it needs to be because it's being time based, and the target of any attack is changing every 30 seconds.



LEO:  Yeah.  But I can also see, I mean, so why - they do that so that - we talked about this in detail, I just forgot.  Why do they put that sequential number in there?  Makes it easier for it to sync up.



STEVE:  Exactly.  Exactly.  They have to do less work in order to check against codes.  And in a heavy use environment, it's going to...



LEO:  Save server, save server work.



STEVE:  Exactly.



LEO:  Okay.  And so Lockheed Martin has far fewer users, and so they can afford the server time.



STEVE:  Right.



LEO:  Bob Thibodeau from Coral Springs, Florida is worried because he's got both WEP and WPA at the same time:  During Episode 118 you guys discussed using a router that had both WEP and WPA available at the same time so that WEP-enabled devices can attach to the network.  You seemed to indicate that this was a safe way to accommodate WEP-only devices.  Actually I don't know if that's what we said.  I can see that using WPA on my computers and WEP for my ReplayTV will keep my computer traffic from being sniffed.  But doesn't the WEP hole in my network allow someone to get on my network and see any shares?  And of course they would have access to my Internet connection.  If they were able to get into some illicit trafficking, wouldn't I be liable?  So I think you said that.  I think that exactly was your point.



STEVE:  Yes.  As we've discussed, due to the problem with ARP poisoning that we discussed some time ago, which allows somebody bad who had accessed your network to insert themselves, essentially create a man-in-the-middle and be able to filter any traffic coming and going from your Internet gateway, which is absolutely possible.  That means that any access to your packet traffic is a problem.  The only safe way that I can see to solve the problem is to have three routers.  You would have your main router, which is your Internet connection.  Then you would have a router running WEP and a router running WPA, both connected to that first router.  So you essentially have a Y, and two routers running different WiFi.  The reason this works is that you still have the potential for an ARP poisoning problem except that ARP will not cross a router.  ARP is only used within a local Ethernet.  So you end up with essentially three Ethernets.  You've got an Ethernet on the inside of your WPA router, an Ethernet on the inside of your WEP router, and then you've got a little tiny Ethernet that's linking those three routers.



Well, that ends up being sacred, that little three-router Ethernet, because there's no way for anybody even who breaks your WEP security to mess around with the little network that links the routers.  So essentially the routers provide isolation.  But if you allowed WEP access to, for example, your main core router, the router on the outside, then it would be able, if that were hacked, to gain access to all your network traffic.  So there's no way to do it that I've been able to think of with two routers.  You would need three.  But if you had three routers you would be able to use WEP services on one, WPA services on the other, and there's no way that even somebody with access to the WEP router would be able to gain access to any of your WPA traffic.



LEO:  Okay.  So it's somewhat more secure.  At least they can't sniff you.



STEVE:  Yeah.  Well, they can't sniff you.  Now, on the other hand, you also have complete isolation between those two networks.  There would also be - there would be no way for filesharing to work across them.  So they would be completely isolated segments.



LEO:  That makes sense, yeah.  Ken Keating in North Carolina is taking no chances:  Having become even more aware of cookies thanks to your recent episodes of Security Now!, I noticed that VeriSign's OpenID tool, when using Seatbelt in Firefox, creates a cookie, even when you don't log in.  Wow, that's interesting.  I have now disabled Seatbelt until I can figure out what state it thinks it deserves to save about me when I haven't even logged into OpenID.



STEVE:  Yeah.  What's happening there is that Firefox, running as a plug-in, has web browser-level capabilities.  So it's autonomously able to create a relationship with VeriSign's OpenID back end just to sort of be there and be present, even if you're not logged in.  I've spoken to the guys at VeriSign.  I've had a number of phone conversations with them, the techie guys in the back room and the more marketing-oriented people upfront.  I just know they're on our side, and there's just no way that they're doing anything wrong with Seatbelt and Firefox.  They really, I mean, they're pro users, they're pro security.  They recognize that Seatbelt with Firefox really provides additional security for people who want to use OpenID.  So I think the fact that it is creating a cookie is a completely benign side effect of the fact that it's a client of the browser running as a plug-in in the browser, and that it creating a cookie is just a fact that the VeriSign server is sending cookies back with the response traffic from Seatbelt, and the browser is just saying, okay, I'm going to store this cookie.



LEO:  It makes the point that, yeah, we may not like cookies, but there's a lot of functionality they provide that's kind of needed.  I mean, it's how you save state.



STEVE:  Exactly.  It's certainly the case, and we've talked about this extensively, that cookies can be abused.  But boy, are they handy.



LEO:  Yeah.  If cookies did not exist, we would have had to invent them.  Mark in Fort Collins, Colorado wants his data really gone:  I was using DBAN, says Mark, Darik's Boot And Nuke - that's a program I recommend all the time, dban.sourceforge.net - on a hard drive to wipe the drive before formatting and use it as a boot drive, and I was puzzled with the options given to me by the program.  I've heard that writing zeroes to a drive, or zero-filling it, does not necessarily mean that the drive data is gone.  In fact, it needs to be zero-filled several times to ensure the information is truly gone.  But why?  Why, why, why are three to five passes more effective than one pass when it comes to ones and zeroes on a hard drive platter?  If a drive is zero-filled even just once, come on, how can information still be retrieved?  But doing it three to five times makes it more unrecoverable?  What's going on, Steve?



STEVE:  What's happening is that the magnetic impression that the hard drive's head makes on the ferrous surface of the disk is an additive process.  So if you write, for example, zeroes on the drive, what you're actually doing is putting down a pattern of flux reversals...



LEO:  Whoa.



STEVE:  ...in the magnetic surface of the platter.  And you're writing them strongly so that, for example, when you come back around and read them, they're what you're going to read.  But you're essentially, in putting down flux reversals, you are overwriting the pattern of flux reversals that was there before, but you're doing so in an additive way.  That is to say that, if you were somebody doing forensic recovery, who didn't want to read what was last written on the drive, but instead what was written before what was last written, it would be possible to subtract out that last written major footprint on the drive and figure out what had been there before.



LEO:  Really.



STEVE:  There is vestigial magnetism, that is, a vestigial pattern underneath what has most recently been written.  The drive...



LEO:  From a practical point of view, how hard is that to read?



STEVE:  Oh, it's tough.  I mean, you have to be NSA sort of guys in serious data recovery, national security sort of mode.  But it's been shown that that data can be recovered.  And that's what Darik's Boot And Nuke is all about is that it is - and it's actually, Darik's Boot And Nuke is going a little overboard because current technology has evolved so far that even when you're writing zeroes on a hard drive, there's all kinds of things that make the actual pattern nonpredictable.  And it's necessary that you have a predictability to understand how the flux reversals map back into the data.  What drives are doing now, drives go through, like, four different levels of conversion to go from user data to final flux reversal timing in order to do all kinds of work, in order to allow them to get the density up to where it is today.  So back in the old MFM and RLL days where we had 20 megabytes and 30 megabytes, this sort of data recovery was more practical.  I would argue that, you know, probably writing zeroes is just fine.  But if you've got time, and you really want the data gone, then writing more than once is a useful thing to do.



LEO:   Simson Garfinkel, who was an MIT grad student who did a study of drives, he did an interesting thing.  He bought a variety of used drives on eBay and a variety of places, got them from recycling centers, and studied them.  Some huge percentage, it was like 80 percent, still had all the data on there.  He got credit card numbers and all sorts of stuff.  But I asked him when we were talking about - and this was a couple of years ago - if it was necessary to write over and over and over.  He said, you know, no.  He said overwrite them once is fine unless they've got some pretty - nobody's going to find it.  And, you know, even in the NSA I wonder.  But I guess if you're running from the federal government, okay.  And it is the Department of Defense.  I mean, this is a Department of Defense spec, this writing and erasing, writing and erasing.



STEVE:  Right.  One of the things, actually it's an interesting little tidbit, if you were to write zeroes to your drive, then if you were a SpinRite owner and ran SpinRite on it, SpinRite reads and inverts the data and then rewrites it, reads it, reinverts it, and rewrites it.  And remember it flips all the zeroes to ones and ones to zeroes and back again.  And so it has the effect of pushing that history of what was on the drive back into the past further.  So it's sort of a simple way of - you would need to zero it first, otherwise obviously you're going to end up with the same thing.  But if you zeroed it first, then ran SpinRite on it, it would have the effect of doing that multi-pass, really push the data gone, gone, gone.



LEO:  There you go.



STEVE:  There you go.



LEO:  Matt in Ohio needs heavyweight encryption without any fluff.  Steve, he says, I'm in need of securing/encrypting files at work on a shared network drive.  I cannot install anything on the computers I frequent, or the server.  This is pretty common in business.  The department I'm in shares a single logon on several department machines.  At most I can use a thumb drive.  I would save everything to that except that, one, I need a backup, servers are backed up daily; and, two, there's too much to save on a thumb drive.  Okay, well, I guess never mind.  Is there something I can use where the software is loaded on a thumb drive and is used as the key to unlock files?  In other words, he wants to encrypt on the hard drive, but using software running on the thumb drive.



STEVE:  Exactly.  It turns out that most of the encryption tools around offer the benefit or the feature of integrating with the Windows Explorer context menus, meaning that they need to be installed, they're making changes to the registry, they're not just a simple little lightweight standalone tool.  However, there is a really nice little lightweight standalone tool that I wanted to tell Matt about and tell all of our listeners about.  I don't know what the name of this thing comes from, but it's called Omziff.



LEO:  Well, at least you can Google it.



STEVE:  Exactly.  If you put "Omziff" into Google, it'll find it for you.  I've checked it out relatively thoroughly.  It's not very big.  It's about 400K, so it'll fit easily on the smallest of thumb drives.  And it runs perfectly from a thumb drive.  It uses state-of-the-art encryption.  A whole bunch of different crypto algorithms are there.  My favorite, Rijndael, is among them.  And you're able to give it a password, and it will encrypt a drive.  So, I mean, it just does - it's a very, very clean, simple, lightweight, standalone encryption system.  And for example, if you just have one file that you are sensitive about and you want to encrypt, this is a perfect little tool for doing it.  It just zips through it and encrypts it; and then you reverse the process, and it'll decrypt it.



LEO:  Thank you for asking that question, Matt, that's really cool.



STEVE:  Omziff.



LEO:  Omziff.  So TruCrypt is too heavy to - it has to modify stuff to do that.



STEVE:  Oh, boy, yeah, it's - I mean, now you could install that on your thumb drive, but...



LEO:  That's what I thought.



STEVE:  ...that wasn't what Matt was wanting to do.  He was wanting, essentially, to encrypt a file and then store the encrypted file on his corporate server, and then take advantage of the fact that they're going to be backed up, the servers are going to be backing up an opaque blob that they're no longer able to read, and nobody in his company is going to be able to read it.  So, I mean, for anybody, it allows you to just do a simple, standalone encryption of a file and then do anything with it you want to safely.  It turns the file into, as we know, absolutely random noise.  And the only way to get it back is by decrypting it with the same key.



LEO:  Very nifty.  Security Now! listener Tom in Buffalo, New York brings us this week's Protecting Users From Themselves even if they don't want it note.  And boy, I agree with you, Tom, on this one.  He's talking about Western Digital's new Anywhere Access.  This is a - it's only on their terabyte network-attached storage drive they're doing this so far.  And one hopes if everybody kicks up enough dust they'll drop the whole idea entirely.  But this is some software that they've put on their network-attached storage drive, their terabyte drive, their MyBook, that prohibits what?



STEVE:  Well, yes.  Cory Doctorow made a posting in Boing Boing that Tom referred me to.  And I did a little research to find out what was going on.  Get a load of this, Leo.  They refuse, by filename extension, to allow certain files to be made available on this hard drive that they're saying - it's like a server that allows people to access it from anywhere, except if the file has an AAC or an AIF or an AVI or a CDA or a DVI or an MP3.  You can't store MP3 files on your own hardware.  This thing says no.



LEO:  You can store it, you can't share it, I think is the...



STEVE:  Exactly, exactly.  It will not allow you to access those.  And I love it because...



LEO:  Which means why store it because you can't access it.



STEVE:  Yes, exactly.  In their own online facility they ask the question of themselves, what files cannot be shared by WD Anywhere Access?  Answer:  Due to the - get this - due to the unverifiable media license authentication, the following file types cannot be shared by different users using WD Anywhere Access.  So they're...



LEO:  Why would they do this?  It's insane.



STEVE:  So they're saying, because these files tend to be...



LEO:  We can't be sure you're not stealing, so we're not going to let you do it.



STEVE:  Yeah.



LEO:  And who would buy this?  The problem is that a lot of people buy it because it's not obvious that it's doing that till you get it home.



STEVE:  Yup.  So I wanted to make sure - I loved Tom's question, and I wanted to make sure that all of our listeners knew that this was the case with WD Anywhere Access, that they were proactively, preemptively, and without anyone knowing it, saying no, we're not going to allow you to share these types of files, by file extension.  I mean, which is dumb because all you have to do is change MP3 to MPE or something. Oh, sorry, no, that one is an MPEG video format.  You can't use MPE either, or MPEG, or MPG.



LEO:  To TMP.  Oh, no, you can't do TMP files, either.  Well, as a matter of fact, don't buy this stupid drive.  Oh, this makes me mad.  You know, it's not too late to have them win the Dumb Move of the Year Award.  It comes towards the end of the year.  But I think this is easily the dumbest thing I've heard all year.  Unbelievable.  Just bad for business.  And boy, I feel sorry for anybody who's bought this thing.  We'll put a link to the Boing Boing article so you can read this.  And so far, as far as I can tell, it's only on one particular model of the MyBook.  I bought a MyBook.  I like the MyBook.  I've been recommending the MyBook.  This is those big Western Digital drives.  But these new terabyte network-connected hard drives I'm never going to - and I have to say I don't think I'll buy anymore Western Digital products.



[http://www.boingboing.net/2007/12/06/western-digital-netw.html]



STEVE:  Nope.



LEO:  No, don't think so.  Why take a chance?  Are you ready, Steve Gibson, for the Fantastic Tip of the Week Award?  Josef Ender from Neuheim, Switzerland writes:  In Episode 120 Brian Dewey asked for a possibility to download all the patches and fixes for Windows XP.  c't, a great German magazine, created an offline update script for many MS systems.  Oh, that's neat.  And you'll find it at Heise Security, that's heise-security.co.uk.



STEVE:  Yes.  People can just Google "offline-update" in order to find it quickly.  This thing is so cool.  When I learned about this from Josef, I grabbed a copy, downloaded it.  It's a ZIP that you expand to a little directory.  Basically it's an EXE.  It's got a beautiful UI.  You say, I want to build an ISO CD of all the updates from, like, from the beginning of Windows XP.  And this thing uses Microsoft's own tools in order to access Microsoft's site.  It downloads all the security patches.  It downloaded Service Pack 2 and everything since, and ended up building a single 680-meg ISO which you could then burn to a CD, and you've got a single disk that brings any newly installed, freshly installed Windows XP right up to speed.  Or Windows 2000, or Office 2000 and 2003, Office XP, I mean, it's completely multilingual.  I mean, it is really cool.



A number of people responded to, as Josef did, to Brian Dewey's question because I had remembered that there was some way, somewhere on Microsoft where you could get a list of these things.  A number of people talked about something called RyanVM, I think it was, but then bemoaned the fact that it hadn't been updated since June, which of course it's like, well, okay, you're a lot further along than you were with just Service Pack 2, so maybe you only had to install, you know, 50 patches instead of 95.  But this thing, because it uses the realtime data directly from Microsoft's Windows Update site, it knows how to parse all of the metadata.  It downloaded all the patches, merged them all together, and built one single ISO image.  It's just extremely cool.



LEO:  So I guess, you know, I had mentioned a system that worked in XP and within Windows Update of going to the network update, network updates, and seeing the list there.  But this makes it so much simpler.



STEVE:  Well, yes.  And if you're someone who's installing XP, I mean, the real question was...



LEO:  Reboot, reboot, reboot, how long is this going to take, and have to do it over and over.



STEVE:  Well, and as I remember Brian's question, he did not want to be on the 'Net.  And so my response was, well, now, as long as you've got Service Pack 2, if you've got Windows XP with Service Pack 2 you've got the firewall turned on by default.  Even if you didn't have Service Pack 2 you could make sure your Windows firewall was on, and you're probably safe.  But the beauty of this is this is an offline update.  So you install Windows XP.  You then use this CD, and it will bring you absolutely current with never going on the Internet.  And this site is very nice, too, because it demonstrates the Microsoft Baseline Security Advisor, that BSA tool that's able to analyze the state of your machine, it shows a before and after where just by applying the CD that this system builds, the Baseline Security Advisor is completely satisfied.  It says, okay, you are absolutely current.  So this thing does it with no network connection.



LEO:  But, well, it has to get an Internet connection initially to download everything; right?



STEVE:  Yes, yeah.  So, exactly, so you would have a machine on the 'Net that you would use to build this ISO.  But then it builds one, I mean, this is what I'm doing from now on, Leo.  I just did a Windows install the other day.  And it's like, oh, here we go, you know, reboot reboot reboot, download download download, blah blah blah.  Now I've got this disk, it's what I will do after I install Windows XP, before I go any further.  So even if you didn't build one of these immediately, until Service Pack 3 comes out for Windows XP, which we know is in beta somewhere, until that comes out, this brings you, like, up to now.  And then you'd only have to do, you know, whatever patches had come out in the second Tuesday of the month cycles since then.  So, I mean, it just brings you much closer.



LEO:  Really cool.  Again, just Google online - or I'm sorry, "offline-update."  And it is the first item that shows up there.  But it's from heise-security.de, and then click on the English flag to get to the UK site.  And Karsten Violka and Torsten Wittrock are the two that worked on this.  Really neat.  That's a neat idea.  That's the way to do it.



STEVE:  And I've got to tell you, the execution, I just think they did such a nice job.



LEO:  Is it batch files?  How are they doing it?



STEVE:  No.  Well, it's an EXE and then a bunch of command scripts.  And all of it's there.  You can browse it, you can - I mean, I was thinking, hey, how did they make this ISO?  Because, I mean, there it is, there's an ISO you can burn to CD.  And they just - they did the whole job.  It's trivial to use.  It's a fantastic system.



LEO:  And you pick the version.  It actually works for Windows 2000, XP, and Server 2003.  So you can pick your version.



STEVE:  And every language you ever heard of.



LEO:  Really neat.  Really neat.



STEVE:  Oh, and all the Office stuff, also.



LEO:  Oh, really.  Oh, great.  So if anybody's got to build Windows systems, XP systems or 2000 systems, this is a must.  It's a must.  Thank you, Josef.  Really good recommendation.  And finally, the Tim Hoolihan from Akron, Ohio Duh! Award of the Week.



STEVE:  I read this, and it's like, uh, duh.



LEO:  Duh.  Several weeks ago you guys discussed a listener's logon encryption scheme.  In discussing the JavaScript hashing encryption that this listener asked about, I believe Steve said it was sufficient, except that the session cookie could later be sniffed.  Maybe I'm missing something about the system, but I think the system is still susceptible to sniffing problems during the logon process.  My understanding is that a form provides a user and password field, and as the form's data is being submitted, some JavaScript does an elaborate process of three hashing systems with some salting values thrown in.  This is described as a one-way process.  You'd be correct to say that it would be tough - read impossible - to guess the password if you sniffed those values.  However, I don't need the password.  If the process is one way, then the server has the hashed version stored, and that's what's authenticated.  For instance, user "bob" logs in with a password "spot."  The resulting hashed password is, I don't know, X12345.  If I sniff and see a form post with fields user:bob and pass:X12345, I could build a simple HTML form that posts those values to the same URL.  I'd be authenticated and redirected to the same page as a valid user.  Ooh, yeah.



STEVE:  You remember, we were talking about that guy...



LEO:  He had that crazy scheme.



STEVE:  Well, yeah, he took the password, and he ran it through an MD5, and then he added some other stuff, some random stuff.  At some point he got gobbledy-gook from GRC's Passwords page.  He mixed that in, and then he did an SHA1 hash, and he went up, you know, I mean, really just hashed it to pieces and ended up with this no doubt, you know, bizarre output from either the MD5 hash or the SHA1.  And we were all kind of, our eyes were crossed, it was like, oh my goodness, you're never going to figure out what that was.  But he did it because he didn't want to use SSL.  And so we ended up saying, yeah, well, that's really not a replacement for SSL.  Well, the beauty of what Tim points out is that, if he's not encrypting the submission, then the result of all that, even though it is so distantly related from his original password that you could never get back to the password from that...



LEO:  You don't need to because it's sent in the clear.



STEVE:  Exactly.  So you've sniffed that.  And it's like, okay, I don't know what the password was, and I don't...



LEO:  Who cares?



STEVE:  I don't care.



LEO:  Don't need it.



STEVE:  Duh.



LEO:  Whoops.



STEVE:  Anyway, so Tim, you were absolutely right.  You didn't miss anything.  I should have picked up on that and mentioned it myself because it's the obvious weakness.  Sure, you could catch the cookies going back and forth.  But there's no need to do that.  If you did catch the original submission, you could certainly logon in the same fashion anytime you wanted.



LEO:  There you go.  Just that simple.  And that's why you need many eyes looking at security because nobody is perfect all the time.  And that concludes our 12 fascinating questions from 12 brilliant listeners.  If you'd like to submit a question for our next listener questions episode, you can go to Security Now!, the Security Now! website, which is GRC.com/feedback.  Right?



STEVE:  Yup.  That'll give you a form.  And again, I want to encourage people to please give me ideas for shows they want to see, or hear; ideas for questions for our Q&A episodes; and just in general any sort of feedback.  I get way more than I'm able to read, but I absolutely do read them.  I respond when I can.  And they do form the basis for our even-episode Q&As.  So keep those questions and feedback coming.



LEO:  Keep those cards and letters coming in, boys and girls.  We really appreciate your listening to the show, everybody.  We do remind you that you can get 16KB versions for the bandwidth-impaired at GRC.com, along with Elaine's great transcriptions, show notes and more, GRC.com/securitynow.  And while you're there, make sure you check out SpinRite, everybody's favorite disk recovery utility, disk recovery and maintenance utility, really great program.  Also Steve's freebies, like ShieldsUP and Perfect Paper Passwords and all that great stuff.  The forums are there, too.  It's really a good site:  GRC.com.



And I understand, Scott Jordan at ScotteVest tells me they're going to extend the coupon code till the end of the year.  So you have a couple more days if you want to get some great deals on ScotteVest.  Maybe you were waiting for something under the tree and it didn't come.  ScotteVest.com, use my name, LEO, as you check out, as the coupon code that'll knock 20 percent right off the top of the price.  So and there's still lots of good stuff.  In fact, they have some clearance deals and so forth.  Everything on the site, 20 percent off when you use my name, LEO, as the coupon code.  Steve, it's been a great year.



STEVE:  It's been a fantastic year.  I wanted to thank our listeners for all the help and support that they have provided to us both...



LEO:  You bet.



STEVE:  ...this year.  And we're plowing into 2008.  I'm going to work to honor my, as I've mentioned in the last couple weeks, my New Year's resolution is to add a little more of really current information about what happened during the week as a regular section in the podcast moving forward.  And again, we won't be able to do that next week because we're recording that one tomorrow, many weeks in advance.  But starting with the second one of 2008, that content will be there.



LEO:  We're busy.  Busy, busy, busy.  Well, Steve, have a great New Years.  And we'll see you in the New Year.  This will be our, what, entering our third year of Security Now, or is it our fourth year of Security Now!?



STEVE:  Yeah, we're in our third.  So we're at about three and a half, I guess, at this point.



LEO:  Unbelievable.  Wow, that's great.  Well, thank you so much for a great show and a lot of great information.  I feel like I'm a lot smarter about security and privacy and all those concerns since we started doing this.  I really appreciate it.  Happy New Year, buddy, and we'll see you in 2008.



STEVE:  Talk to you soon, my friend.



Copyright (c) 2007 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#125

DATE:		January 3, 2008

TITLE:		Symmetric Ciphers

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-125.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve explains, very carefully and clearly this time, why and how multiple encryption increases security.  Steve also carefully and in full details explains the operation of the new global encryption AES cipher:  Rijndael.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 125 for January 3, 2008:  Symmetric Ciphers.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now!.  And here he is, ladies and gentlemen, ready for a new year of security, Steve Gibson.  Happy New Year, Steve.



STEVE GIBSON:  Hey, Leo.  Happy New Year to you.  And we're going to kick off the new year of Security Now! with a - well, I'm really excited about this.  I've been doing extra research and getting my notes together.  And I'm going to tackle something that I think people are really going to like.  And it comes from really that bungling attempt I made a couple weeks ago when, well, it was the issue of double encryption, the question we answered several Q&As ago where some guy said hey, you know, what if I encrypt something with one key, then I encrypt it again with another key?  Isn't that, like, much better than encrypting it just once?  And I absolutely know that it is, and I know why it is.  And I realized that in the several years intervening from the time I first talked about symmetric cryptography and symmetric ciphers, I've written a bunch.  I mean, I've implemented Rijndael, which is the AES standard, in Assembly language.  I know exactly how it works.  And then when I was trying to explain subsequently in the next Q&A why that was the case, I got into all this 2 to the power of 128 factorial stuff, and everyone's eyes crossed, and you were saying, okay, Steve, okay.



LEO:  We'll take your word for it, Steve.



STEVE:  So first of all it bugged me that - well, and actually people didn't know that you and I were under time pressure for that, too.  Your schedule had been packed here toward the end of last year.  So I was feeling like, oh, I can't really just, like, stop and really explain this.



LEO:  Well, we've done, I think, three or four shows in a couple of days, so...



STEVE:  Yeah, actually we did five shows in eight days.



LEO:  Geez.  Including this one.



STEVE:  Two the prior week, two yesterday, and then one today.  So...



LEO:  I'm sorry, Steve, but you get six weeks or five or something off.  You get some time off, anyway.



STEVE:  Exactly.  I'm going to forget the name of our podcast by next time.



LEO:  And by the way, I want everybody to know, I said this to you, oh, good, we don't have to do any shows, we're going to take a couple of weeks off, the whole network's going to shut down for December.  And he said, "Over my dead body.  No way.  I want to catch up with TWiT."  And you have.  Congratulations.



STEVE:  We've passed up TWiT.  I'll never catch up with the Giz Wiz because you spit those things out one a day, so...



LEO:  We even took a week off with the Giz Wiz, and it's still, like, we're close to Episode 500.



STEVE:  Yeah, okay.  Well, I'm just not going to...



LEO:  Don't worry about it.  But for the weekly shows, you are now number one.  For the once-a-week shows.



STEVE:  Yay.  I like number one.  Number one's my favorite number.  So anyway, I don't know what exactly are we going to call this?  Anatomy of a Symmetric Cipher, or...



LEO:  Yeah, just Symmetric Ciphers.  I think people are very - first of all, we're going to get into this in detail in just a second.  But first, can you kind of distinguish what symmetric cipher is?  What is it we're going to be talking about?  I mean, I know ciphers are codes.  And we use encryption all the time.



STEVE:  Right.  And the reason, okay, there are a couple reasons that symmetric ciphers are cool and powerful and neat.  First of all, symmetric ciphers are the workhorse of encryption.  Symmetric ciphers do all of the heavy lifting.  They are sort of the bulk encryption technology which fundamentally protects everything.  That is, for example, we've talked about asymmetric ciphers, which means you have one key to encrypt and one key to decrypt, and those keys are different.  Well, those are cool because that's where you get so-called public key encryption, that is to say where one of those keys might be kept secret.  Doesn't have to be, but typically it is.  So the idea being you can publish one of the keys, which could be used to encrypt the contents, and you keep the other key private.  Well, only the matching key to the one that you exposed can be used to decrypt the contents.  And so there are all kinds of things you can do with this.



The problem with that is it is excruciatingly math number crunchy intensive just to do a little bit of encryption with an asymmetric cipher.  So nobody uses an asymmetric cipher for bulk encryption.  You just can't.  So what instead they do is they use the asymmetric cipher, which is so time consuming, just to encrypt the key, that is a symmetric cipher key.  So you use the time-consuming but very powerful public key crypto to encrypt the private key.  I mean, I'm sorry, to encrypt the symmetric key.  And then you use a symmetric cipher which runs really fast.  And so really you still depend upon both.  But the symmetric cipher performance is super high, but that's really what we're depending upon.  So if there's, like, a blob of data, like for example we were talking about Jungle Disk, Jungle Disk uses Rijndael, the Rijndael cipher, to encrypt all of the data that it sends up to Amazon's S3 servers when you give it a key that you want to use.  So there's all that bulk data sitting there.  And it is the strength of the symmetric cipher which is protecting it, the fact that there just is no practical way to decrypt it.  So, for example - well, okay.  So there's why symmetric ciphers are cool.



LEO:  Right.  So now that we understand what symmetric ciphers are, are you going to - you're going to actually - now, Steve, before we got started said "I'm going to explain it so that you understand it, Leo.  By the end of the show, you will go, oh, that's easy.  That's simple."  I said, "Steve, you're a little ambitious.  You're giving me a lot more credit than I deserve."



STEVE:  We don't have any errata this week, since we've been cranking out shows so fast there's been no chance for any errata to sneak in.



LEO:  Oh, and I thought it was just because we were perfect.



STEVE:  There's been no chance for any feedback.  But I did have one really nice sort of Christmas story relating to SpinRite that I wanted to share real quickly.  This was Scott Keoseyan.  He wrote to us and said, "SpinRite = Success," was his - it was a little formula with an equal sign there.  He said, "Steve, I just wanted to share a SpinRite story.  My 12-year-old son came to me Saturday evening with his laptop, parens, my old laptop, a Dell Inspiron 8600, that would no longer boot.  On boot it would bluescreen, saying that the primary partition was unmountable due to errors."  He said, "I had purchased SpinRite a couple of months previous to fix another machine, but it turned out the issue with that machine was with the main board on the machine, so I was unable to really put SpinRite to the test.  Anyway, I went ahead and popped the disk into my son's computer and let it run overnight.  When I came back the next morning, I rebooted the machine, and all was well again.  While my son doesn't keep anything irreplaceable on the machine, having to rebuild his machine from scratch would have been a four-to-six-hour ordeal.  My time is definitely worth more than the $89 I spent on SpinRite.  And just having to rebuild that machine would have ruined my whole weekend.  I was very glad to have access to SpinRite and that it worked so well.  Thanks," signed Scott.



LEO:  Isn't that great.



STEVE:  So, yeah.  And you know, I have to say, all these testimonials and feedback that we receive on SpinRite, it's so often about machines that no longer boot because the system just keeps on going until it finally collapses to the point...



LEO:  It just can't - yeah.



STEVE:  ...that it just can't get going.



LEO:  It can't go on.  And that's - it's sad because people really don't - they defer everything.  And it's like with the house or anything else.  You defer maintenance on your car until it stops running.  And then you go, uh-uh.



STEVE:  That's exactly right.  And again, I know it's - SpinRite's $89.  It's not something that people think of, like oh, look, I've got an extra $89.  But the fact is, if SpinRite were used prior to systems finally collapsing to this level where they just bluescreen, then these problems would be prevented.  So for what it's worth...



LEO:  Well, I think people look at 89 bucks, and they say, well, I can get a new hard drive for that.  They forget, we're not talking about the hard drive, we're talking about your data.



STEVE:  Precisely.  And the point Scott makes is a good one, too.  I mean, I sort of enjoy setting up machines because it's like, okay, it's interesting for me.  But I find myself now trying to do multiple things at once because it takes so long to get Windows XP installed and then update all the patches and get it going and then tuned, and load your apps and get them registered and all that.  It's like, okay, really, what's your time worth?



LEO:  Exactly.  What's your data worth?



STEVE:  Yeah, that, too.



LEO:  All right.



STEVE:  So you're right.  Here's the goal that I have for our listeners and for you.  Symmetric ciphers are incredibly cool.  And I realized I have a really much better handle on the internals of them as a consequence of having written some, implemented some that of course have been designed by crypto geniuses.  And I'm not a crypto designer, but I've implemented the actual code.  And...



LEO:  So how do you do that?  Is there a spec?  Do you work from an algorithm list?



STEVE:  I'm actually, in this episode, we're going to understand the new AES standard, Rijndael.  I can explain what's inside so that afterwards people are going to be going, oh, is that all?  That's all there is?  And that's so bulletproof and strong and amazing?  It's like, yes.  I mean, it turns out it's not that hard, and it can be explained in a way that's pretty simple.  But I want to, also in the process, I want to answer the question that so many people had.  I mean, it's amazing.  I'm looking at another that I was going to sort of use as an intro to this.  Adam in Ottawa, Ontario, he said, "Steve, I've been a listener for a long time.  And as a graduate from a computer science program with an interest in security, I enjoy listening to the show.  In the past I've disagreed with you on some topics, but never so much that I felt compelled to write in.  Now I am."



LEO:  Uh-oh.



STEVE:  "Last week, Episode 120" - so it's last week for him when he sent this - "you answered a question about whether encrypting something twice was more secure than encrypting it just once.  You said that it was, but I'm not so sure.  If good encryption maps plaintext, something intelligible, to something completely random, using a key, wouldn't mapping plaintext to random, then to random again, be the same as just mapping to random once using a different key?"  And of course that's what everyone has thought.  I mean, so many people have thought this.  So I'm jazzed at the fact that people are taking the time to think about this and scratch their heads and write in and tell me that they think I'm wrong, in fact, which is totally cool.



And so he goes on, he says, "What I mean is, if I use key K1 to encrypt my plaintext to something random, then use key K2 to encrypt that into something random again, isn't that the same as using some unknown key, K3, to encrypt my plain text just once?"  And then he goes on to more detail, but we understand that this, I mean, this is really what people have been talking about.  And I want to explain why it's not the case, and in the process what I was trying to explain when I got us all mumble-jumbled up in that 2 to the power of 128 factorial stuff.



LEO:  So they just think, and I guess this is reasonable, that instead of two keys there must just be one magic key that would take the final scrambled version all the way back to text.



STEVE:  Correct.



LEO:  And I don't know, I'm not sure why they assume that.  I'm not sure I would leap to that.  But I guess it makes sense.



STEVE:  Well, okay.  It's a really - to answer that particular question, it's a matter of scale.  So let's, instead of talking about Rijndael, that is a 128-bit block cipher with a 256-bit key, let's create a dumb, simple little cipher that's much easier to talk about.



LEO:  Perfect for me, okay.



STEVE:  So this is...



LEO:  You know, a simple little host.



STEVE:  This is the Romper Room cipher.



LEO:  Okay.



STEVE:  It's just 4 bits.  That is, it takes 4 bits at a time, and it encrypts it into a different 4 bits, and it has a 1-byte key.  So an 8-bit key.  So it's similar to what we were talking about inasmuch as the Rijndael cipher, for example, that Perfect Paper Passwords uses, and that is used often, is a 128-bit block with a 256-bit key.  So the key is twice as long as the block that you encipher each time.  So we've got that.  Now, in the Romper Room cipher we've got a 4-bit block that's controlled by a 256 - I'm sorry, by an 8-bit key.  Okay.  So first of all, if we're going to encrypt a 4-bit block, we're going to take 4 binary bits, which we know has 16 possible combinations.  You can have 0000, 1000, 0100 and so on, until you get 1111.  So there's 16 combinations, 16 possible combinations of 4 binary bits.  This little Romper Room cipher will take any 4 of those bits we put in and translate them to a different 4 bits out, under the influence of this key.



So, okay, now the problem - there are several problems with the Romper Room cipher.  I mean, no matter how good the cipher is, the problems are that there just aren't enough bits.  That is to say, if you didn't know what the key was, and you didn't really even care what the key was, you wanted just to map the cipher, all you would have to do would be, if you had access to the plaintext, that is, what's not encrypted - and many times people do have access.  For example, you could encrypt your own data through the cipher and get out the cipher text.  Well, since there's only 16 combinations of 4 bits, you could just write down - you can create a little table.  You just write down, okay, 0000 is turned into 0100, 0001 is turned into - since there's only 4 bits, there's only 16 possible inputs, and so it's easy to create a table of the 16 corresponding outputs.  You don't have to care what the key is.  You don't have to even look at it because you're able to just build, write down what the cipher does.  And obviously, looking at that table, you could then take other encrypted text and decrypt it.  You just use the table backwards.



LEO:  It'd be like a transposition cipher where you'd have an alphabet, and you'd say A=Z, B=A, C=B...



STEVE:  Ah, that's a very good point because a transposition cipher that you were just mentioning, that would be adding a constant to each of them.



LEO:  Ah, it's not as random, okay.



STEVE:  Exactly.  So, for example, if you just added 4, you're right that 0 would become 4, 1 would become 5, 2 would become 6 and so on.  And when you get to the end, you wrap around.



LEO:  So this is a little better.  So it'd be like randomly A=Z, B=Y, C=F.



STEVE:  Exactly.  Now, that leads me to the perfect next question, which is, okay, one of the reasons this thing is dumb - it's the Romper Room cipher, after all - is that there's only 16 possibilities.  But how many ciphers are possible?  That is, how many possible tables - remember we just talked about a table where we just write down, you know, we have 16 entries in this table with each one of the possible inputs and the corresponding output.  How many tables could there be?



LEO:  Well, you said there was a 1-byte key, so I'm going to guess 256.



STEVE:  Well, exactly.  Now a 1-byte key going into the cipher, as we know, 8 bits gives us 256 possible combinations.  So the Romper Room cipher that operates under the influence of a 1-byte key, as you said, Leo, can have 256 tables.  But the question I was asking is a little different, and this is why it's so important.  How many possible mappings are there?  That is, we can access 256 of those with the key.  So we know there's at least 256.  Well, we hope there are, otherwise some keys would give us the same cipher.  But the question is, how many possible mappings could there be?  So think about it this way.  If we put in a 0 as our first test, we could get out 1 of 16 possibilities.  We could get out 0, 1, 2, 3, 4, 5, 6, all the way up - I'm sorry, 0 through 15, which is 16 possibilities.  So in terms of, like, the possible combinations, we put in 0.  For a given, say that we have a given cipher, we put in 0, we could get out 1 of 16.  Now we put in 1.  Well...



LEO:  So it's 16 squared.



STEVE:  No.



LEO:  Oh, I'm so slow.



STEVE:  That's what's so cool is we put in 1.  Now we've used up one of our outputs when we put in 0.  So we've got 15 left.  So that is when we put in 1, we could get 1 of 15 remaining outputs.



LEO:  Ah, it's a factorial.



STEVE:  There you go.  When we put in 2, we could get one of 14 remaining outputs because we're consuming one each time.  So it is 16 factorial.



LEO:  That makes sense.  Okay.



STEVE:  So I want to make sure everyone gets that, that is, the total number of possible ciphers is 16 factorial.



LEO:  16, that's 15 times 14 times 13 times 12 times 11 and on.



STEVE:  Exactly.  So as we're doing this, when we get all the way down to putting in - we started at 0, so the last one would be 15.  We've used up all the others.  There's only 1 left because the other ones use it up.  That's the total number of possible mappings of just 4 bits into 4 bits.  And what's so counterintuitive, 16 factorial is 20 trillion, 922 billion, 789 million, 888 thousand...



LEO:  Wow, I had no idea...



STEVE:  I know.  Factorials are huge.  So it's 20,922,789,888,000.  That's the number you get if you just multiply 16 times 15 times 14 times 13 times 12 times...



LEO:  Okay, you can stop.  It's not the 12 Days of Christmas.  We get it.



STEVE:  Okay, okay.  So my point is 20,922,789,888,000 possible mappings.  Now, how many of those can we access?  256.



LEO:  Ah, right.  So that's - we need a bigger key.



STEVE:  Well, exactly.  So my point is that, even though it's counterintuitive, until it hits you, the size of these numbers, it's like, wait a minute, I'll just find a key that gives me the mapping that I want.  Well, good luck, because - and my point is, most of the mappings are not available.



LEO:  Are not available, you only get a few.



STEVE:  With just 4 bits, if there's 20-trillion-plus possible mappings, but with an 8-bit key we can only get to 256 of them.  Okay.  So what that means is, now let's stop here and now switch to Rijndael.  Let me tell you, Leo, it was hard to find out what the factorial would be for 2 to the 128.  So remember with real Rijndael, with a real cipher, not the Romper Room cipher but with a real cipher, we don't have 16 bits.  We've got 128 bits.  Okay?  So we're talking about the total, what we're looking at, remember is the reason we were doing on the Romper Room cipher 16 was it was 2 to the power of 4.  2 to the power of 4, and you take that, and you take the factorial of that.  So 2 to the 4, of course, is 16.  That's why we were doing 16 factorial.  We know that's 20 trillion.  Okay.  So that means that the number of possible mappings on a real cipher, an industrial-strength cipher like Rijndael with 128 bits, is 2 to the 128 power.  You take that and do the factorial of it.



LEO:  Okay.  Big number.



STEVE:  Now, Leo, I found some math genius somewhere on the Internet who she spent her whole life coming up with cool ways to do factorials.  I have the size of that number, thanks to her.  It is - okay.  It is a number, I can't even say the number.  I don't think there's a possibility to say it.  It is a number with 1,296 billion billion billion billion digits.



LEO:  Digits.



STEVE:  Digits.



LEO:  Okay.  It's a big number.



STEVE:  1,296 billion billion billion billion digits.  That's how many possible mappings...



LEO:  I never heard of such a big number.  That's 10 to the - geez.



STEVE:  This is the biggest number that's ever been written.  It blew up three computers when I was trying - no.  And so this is what I understood, but I didn't explain it properly a couple weeks ago, that is, that's the number of possible mappings that a 128-bit block symmetric cipher could have is a number that has 1,296 billion billion billion billion digits.



LEO:  Now, you only get to pick from a subset of that, though, because of the key size.



STEVE:  And that's exactly my point.  And that is, okay.  So Rijndael can operate at different key lengths.  You can use it with a 128-bit key, a 192 or 196, I can't think of which...



LEO:  196, yeah, and then 256, and then...



STEVE:  Yes.  So, okay.  So a number like 2 to the 256 is the number of keys that Rijndael can have.  Now, that's a big number also, but it's not anywhere nearly as big.  I'm looking at it here, and it's...



LEO:  How are the keys selected from the superset?



STEVE:  Well, that's what we're about to do.  That's the next part of this podcast is how does Rijndael itself actually work?  But what I wanted to explain was that 2 to the 256 is not a huge number.  I mean, it's a big number, and it needs to be big because, if we look back at the Romper Room cipher, the other problem with it, not only was there a problem that the block length was too short, it was only 4 bits.  So we could simply write down a table to figure out all the mappings.  But the Romper Room used a 1-byte key, which as you pointed out there are only 256 of them.  Which means the other way to crack the cipher, if you didn't want to just - if, for example, if you had no access to the plaintext, okay, remember that if we had the plaintext we could just run it through the Romper Room cipher, not caring what the key is, and create a simple little 16-line table that shows all the mappings.  Well, you cannot do that with a 128-bit cipher because it's got 2 to the 128-bit possible combinations.



LEO:  Big table, yeah.



STEVE:  Big table.  And so in fact that's even why - that's why short block-length ciphers like DES, the prior standard, was a 64-bit cipher.  And so it would encipher 64 bits at a time.  Well, that's strong.  But it turns out that people like the EFF - the EFF created a blob of hardware that was able to crack DES, any given instance of DES, in a day or two.



LEO:  You could map a table 2 to 64.



STEVE:  Yeah.  You wouldn't want to.  I mean, that's still a lot.



LEO:  Yeah, but a computer can do it.



STEVE:  Big computers.  Certainly there's enough data around on the Internet to do that.  But it's still - it's big, but it's not too big.  But just remember, when we double the bit length, we're not doubling the table size.  We're squaring the table size.  So 2 to the 128 is - you cannot do a table that's that big.  Okay.  So in fact it is - do I have it in front of me?  It's roughly 3 times 10 to the 38.  That would be the length of the table.  So that would be 3 and, well, 3 and 39 - or a total of 39 digits.  So that's a really long number.  So, but the problem with the Romper Room cipher with an 8-bit key was a brute-force attack.  We've talked about that a lot before.  If you only had the ciphered text, and it was all gibberish, you could try using key 0, then key 1, then key 2.  Well, you've only got 256 of them.  So in a short time you could figure out what that was.  And in fact, that's the same key length, if you want to call it that, used on the wireless keyboards that we talked about.  There's only 256 possible bytes that could be XORed with the keystroke data.  So it's trivial to try them all.



So that's the problem with the Romper Room cipher is the key is too small.  And that was the problem with DES was that a DES key was only 56 bits.  And so that was, like, way too small because equipment really got much faster much more quickly, and DES just ran out of steam because the key wasn't long enough to prevent a brute-force attack.  So Rijndael, that runs with 128-bit key minimum, or 196, or 256, those keys are so big that it's just - it's absolutely impractical to try them all, which is the way a brute-force attack works.  So, okay, so I just wanted to put to rest this - or to give people a sense for the size of the total number of possible mappings that a symmetric block cipher offers.  So we've got that.



Now let's talk about how Rijndael works, that is, up to this point in all of our podcasts we've talked about this as a black box.  It's a black box, and that's true of all of these ciphers, although we have explained, for example, the inner workings of public key crypto.  Remember we talked about exponentiation and how it's possible to do an exact exponentiation, but incredibly time consuming to reverse that, to do an exact logarithm in order to reverse that.  And public key crypto uses the fact that it's a so-called one-way function, or at least one way easy, the other way really, really hard, and no one's ever figured out how to do that.  And prime factorization is the other thing.  It's very - it's trivial to multiply two big primes.  It turns out that, if you don't know what they are, and you only have the product of two primes, it's incredibly time consuming to go the other direction, to do a prime factorization of that number.  So public key crypto uses the concept that it's easy to go one way but not the other in order to create its security.



So but in terms of a symmetric block cipher, we've never looked inside one.  And that's what we're going to do for the rest of this podcast is understand how Rijndael functions, that is, actually how does it encrypt data.  And what's a little distressing is that it's really not that complex.  All of these symmetric ciphers use the notion of a round, that is, they're iterative.  You put data in, and they do something to it a number of times.  And the strength of the cipher is based on how good what you do to it is and how many times you do it because basically it's making it much more difficult for anyone on the outside of this black box, which is what a cryptanalysis is, it's like trying to figure out something about his that will find some weakness in it.



Rijndael won in the competition because it was very clear and a very clean algorithm.  The designers were able to explain every aspect of it and why they made the decisions they did.  And they deliberately designed it to be efficient on 8-bit processors, which are the very slow and on low-power processors, for example, used in smart cards.  So they wanted a cipher that you could express the algorithm efficiently in an 8-bit processor.  So things needed to be able to be done easily with just 8 bits.  And they also wanted it to be fast on 32-bit architecture, the architectures of the day.



So what happens is it starts with the key.  We take the key, and there's something called the "key schedule."  In symmetric ciphers a key schedule is the algorithm used to expand the size of the key to create much more material which will be used throughout the encryption process.  So the idea is, essentially, you have a bunch of carefully chosen random data, and the key is used, mixed with and to select from a pool of random data.  And this is, it's random, but it's always the same.  So that part of the specification of the Rijndael cipher and many similar ciphers is blocks of data that, when you look at it, it's like, okay, I hope I don't have a typo in here anywhere because you've got to get it exactly right.  So the key is, through an algorithm that is specified, is mixed with this random data in order to create a much longer - essentially it's like an internal key.  It's called "key expansion."



The way Rijndael works is that the block length, for example, is - there are various block lengths of Rijndael.  You can actually implement Rijndael in a block length that's any multiple of 32 bits.  But the standard that was chosen is 128 bits because that's enough that you could make a 256-bit block Rijndael.  But it's like, okay, 128 is already so many in terms of the number of combinations, there just isn't a practical need to go any further.  So the standard was set at 128-bit block length.  The way Rijndael works is the key is expanded to a length which is a multiple of the block length.  And this expanded key, different pieces of it are used for each of the internal cycles, or rounds, of the cipher.



So say that we had a cipher with 14 rounds, that is, we were using Rijndael with 14 rounds, which is the number of internal cycles Rijndael uses if you use a 256-bit key and the standard 128-bit block.  If you use a half-size key, that is, 128-bit key and a 128-bit block, then you only need 10 rounds.  For a longer key you need more in order to get the equivalent protection.  So the 256-bit key Rijndael uses 14 rounds.  It uses one more set of key material than rounds.  That is to say, so 15 sets of key material.  So the key expansion expands this 256-bit key that we give it to 15 sets of 128 bits.  So we've got 15, essentially 15 block widths of stuff, which is created using this pool of randomness that is part of the cipher.



So the data comes in from the outside of the cipher, and it's XORed with the first of this 128 bits that was derived from the key, just a simple XOR operation.  Then it goes through a process of mixing the data, which is essentially three different steps.  There's a thing called an S-box which is commonly used in crypto that takes a byte in and maps it to a byte out.  That's all it is.  It's a 256-entry lookup table called an S-box.  And so the bytes of the cipher that come from the XOR, each byte goes through this standard lookup table.  And there's only one of them, and it's always the same.  So that doesn't change.  It just maps 1 byte in to 1 byte out.  Then the way to visualize the way Rijndael works is, if you take the 32 - I'm sorry.  You take the 128-bit block, and you put it into a grid of bytes so that you've got 4 bytes down and 4 bytes across.  So you've got a 4x4 grid of bytes.  Then the next thing that happens is that the rows of this grid are shifted.  And each row is shifted a different amount of bytes over.



So again, first of all we've got - we have a byte translation table.  Then we're just shifting bytes around.  Then the final thing is that the columns of this 4x4 grid of bytes, they're mixed within themselves, that is, so a column of 4 bytes is going to be 32 bits.  That's mixed with a matrix multiplication which implements a polynomial which only has the factors of 0, 1, 2, and 3 because it's easy to multiply by 0, 1, 2, and 3.  Well, obviously multiplying by 1 does nothing.  Multiplying by 2 is just a shift operation in binary.  And multiplying by 3 is just you shift and then you add the original in, so you've got 2 plus 1 is 3.  So the designers of Rijndael carefully chose these things to be easy to do.



Okay, now, that's all there is in Rijndael.  That is, you do the XOR, then you do the lookup table, you shift the rows over, and you mix the columns.  And you do that 14 times, and you're done.  And it turns out that there are attacks that have been found on so-called "reduced rounds" versions of Rijndael.  That is, if you, for example, only ran through that process five or six times, it turns out that things are not yet mixed up enough that it's not possible to find, like by analyzing just from the outside, it's still possible to, like, determine some bits of the key because things haven't been obscured sufficiently.  So and in fact that's exactly why they chose 10 rounds.  They added four rounds to six, where six was the last point at which any weakness could be found because from a crypto standpoint they understood what each round did, and two rounds was enough to create bit dependencies that couldn't be tracked.  So they added - they thought of it as that six rounds with two ahead and two afterwards to give them a total of 10.  And they were able to demonstrate that that is extremely conservative and absolutely safe.



And then if you think about it, they've essentially - they've XORed a chunk of this internal key for each round.  So as the data goes through, it then XORs the next 128 bits.  Then it runs through this simple process of byte mapping, shifting, and mixing the rows of columns.  Then it XORs the next chunk of the internal key and does it again.  The next chunk, it does it again.  Well, that process is reversible, that is, everything - and then of course you have to have reversibility because that's where you get decryption.  There's no, like, magic other way to decrypt it.  Literally decryption is just running Rijndael in reverse.  And this is the way...



LEO:  That's where people got the idea that you could kind of skip, if you did it doubly, you could just - because it's reversible.



STEVE:  Yes.  And so...



LEO:  Like an XOR.



STEVE:  So, well, exactly.  But it's reversible.  The reason you cannot simply say I'm going to use one key and encrypt and another key and encrypt and there's a third key somewhere that's equivalent is the key space.  I mean, we were talking about that.  The number of possible mappings that that simple process produces is that thing with 1,296 billion billion billion billion...



LEO:  And you have no way of knowing which one it was.



STEVE:  Exactly.  And remember, too, that the key - we have a much, much, much smaller key space.  That is, the total number of keys, 2 to the 256, even though that's a big number, I mean, it's so big we can't, I mean, it's strong against brute force because brute force means trying them all.  Well, the fact is, and unfortunately I'm not enough of a cryptographer to be able to state this definitively, that is, that there is no third key that is equivalent to the first two.  But it is phenomenally unlikely because - and there may be a way of demonstrating and proving definitely that there is no third key that is equivalent of the first two.  But just in terms of the number of possible mappings, you would - it would have to be that two keys selected two mappings such that there happened to be another one that a key could select.  And that's the point I'm trying to make is that that hypothetical third mapping would have to be available by some Rijndael key.



LEO:  And it's a pretty low chance that it would be, given the size of the...



STEVE:  Precisely, the size of the total number of possible mappings that 128-bit cipher can have, I mean, it's just so ridiculously small.  And as you said, Leo, you'd still have to find it.  And you can't find it because 2 to the 56 is a massively large number that's completely infeasible to brute force.  So essentially this is how Rijndael works.  Internally it's not complex.  It's pretty simple to implement.  They designed it to be easy enough that an 8-bit processor running on a smart card would be able to do it.  And it would be very fast on 32-bit machines.  And essentially it owes its strength to the fact that it's a bunch of simple operations where each cycle does a good job of mixing stuff up.  And when you do it 14 times, it's so mixed up that no analysis from the outside can figure out where the bits went when they went inside.  They just got all scrambled around and all interdependent in a way that nobody could figure out from the outside.



LEO:  Very clever.



STEVE:  So the fact is, the original question that was asked back on Episode 120 was, if I encrypt it twice, with different keys, isn't that better than once?  And it's absolutely the case that it is because, remember, somebody would be looking at the output from the second encryption, and the only attack is a brute force attack trying keys, you know, like a dictionary attack.  And they would be looking for it to get plaintext out of the decryption.  But the plaintext out of the second encryption is the encryption from the first, which means there is never going to be any plaintext.  And as we've seen, the key spaces are such that there's just no chance another one of those keys, I mean, virtually no chance another one of those keys is going to magically perform the double encryption for you.  That's just not - you have no access to the total number of mappings that are possible through a 128-bit block cipher.



LEO:  It's a numbers game.  It's just too vast a universe.



STEVE:  And really that's all crypto is.  Crypto is just a numbers game.  I mean, as we saw, the Romper Room cipher that uses 4-bit block size and 128-bit key, it's trivial because the numbers, there just aren't enough of them.  It's a nice cipher.  I like it.  We were able to explain how it works.  But it's just - it's not useful because there aren't enough bits to make it nontrivial.  But as soon as you start increasing the width of the cipher, there are 2 to that many bits factorial possible mappings, it just goes out the window.



LEO:  Wow.  Well, you know what, I didn't think you could do it, but even my thick skull kind of gets it.



STEVE:  Yeah, I mean, I'm looking here at equation...



LEO:  It's not that complicated, actually.



STEVE:  It's really not.  And that's all that's going on in what has now been - it's the universal standard, this is what everyone's using, Europe apparently has adopted it, as we have here, as our new federal computing cipher.  It was all done in an academic environment.  It's been implemented all over the place in lots of different languages.  The PPP system uses Rijndael, and it's been - on our software page, it's in virtually every language.  So it's completely available because it's just not that hard to do.



LEO:  Now, when you - okay, I'm going to ask a question about public key cryptography and how that's different from symmetric key in just a second.  And I know that's another subject, but I just want to understand that.  All right.  So I gave you a little time because I know I gave you a touch one.  Symmetric versus public key.



STEVE:  Yes.  Okay.  Or really the way to say it is symmetric versus asymmetric, that is, nonsymmetric.  What it is that is symmetric, that is, the symmetricness is that the same key is used to encrypt as decrypt.  And we just saw why because lord knows, who knows what other key could possibly provide a reverse mapping.



LEO:  Good point, good point.



STEVE:  No one is going to come up with a key that's going to undo that nightmare of scrambling and shifting and mixing over and over 14 times.  So you use exactly the same key.  You expand that key to the internal key material.  And basically you run Rijndael in reverse in order to step-by-step unscramble the data that was put in, in order to get back out what the encryption had put in.  But the only way to decrypt it is to run it backwards.



LEO:  But the negative of that is that both you and the person receiving the cipher have to have the key.  So you have this difficulty of getting them the key.



STEVE:  Yes, exactly.  And that's why it's regarded as a so-called, like a secret key approach, is that anybody who has the key that was used to encrypt it is able to decrypt it.  So what's different about an asymmetric cipher and the asymmetry is the keys.  One key encrypts, and that key cannot be used to decrypt.  So, I mean, literally it's a one-way function of encryption.  And then only the matching, the key that was made, along with the encryption key comes a decryption key, although people who have really been paying attention will remember that there's no difference between them except that one is one and one is the other, meaning that you produce a key pair.  One will undo what the other does.  But that one can't undo what it does, nor can the other undo what it does.



LEO:  And see, that's great because you can publish your public key, and anybody can send an encrypted message to you, but nobody can decrypt it except you.  Is it less strong, then, as a result?



STEVE:  Well, yes.  The algorithms fundamentally function differently.  So, for example, public keys, where we were talking about 128 bits being all the strength you would ever need, public keys need to be 1024 bits in order to have the equivalent strength.  And now there are 2048-bit public keys, again because the nature of the algorithm is such that there are different attacks on them.  So to have, for example, a 128-bit symmetric key is about equivalent to a 1000-bit asymmetric key.  And that's part of the reason that the process of using them is so slow, is there's just a much - much more work needing to be done for public key crypto.  And it's just - it's absolutely infeasible to use it for encrypting, like, a whole file.  And so people don't.  What they do is, they will choose - they'll get a very good random number, and they use that as a symmetric key to encrypt the file.  Then they use the public key cryptography, that is to say an asymmetric cipher, to encrypt that random number.  So then all you have to do is give that random number which has been encrypted and this blob while is the file, you give that to someone.  If they have the matching decryption key, they will take the random number which has been encrypted with the public key, decrypt it into the actual symmetric key which was used with a bulk encryption algorithm like Rijndael to encrypt the blob, and then they decrypt it.



LEO:  Got it.



STEVE:  And there you go.



LEO:  So that's why symmetric is used and is necessary for every kind of encryption.



STEVE:  Yes, exactly.  You will always have that.  And it's why I really thought it would be fun to kick off the new year by explaining exactly how Rijndael, which is now, you know, everyone's going to see it around.  It's what Jungle Disk uses for its encryption.  It's what, you know, we talked about that Omziff program last week, the cute little standalone.  It's got a bunch of crypto in it.  You could choose, I think, Twofish and Blowfish and some others, and Rijndael is also there.



LEO:  So Rijndael has replaced Triple DES and all of these others?  It's kind of the one everybody's using?



STEVE:  Well, yes.  And in fact Triple DES, that's another example of where multiple encryption is good because that's all Triple DES is.



LEO:  Yes, a 64-bit DES encryption done three times.



STEVE:  Exactly.  Because 56 bits was not enough, you use a key which is three times 56 bits, and you use the first third and encrypt something, then you use the second third and encrypt it again with DES, and then you use the third third and encrypt it a third time.  And by the time that 64 bits comes out, it is really confused.  But that's a way of giving you the equivalent of a much larger key length is just by multiple symmetric encrypting with different keys.  Which is really just what that guy back in Episode 120 asked us.



LEO:  That's what he was doing.  So that's interesting.  So because Rijndael seems to me a little newer than the others that I've known about like Blowfish and DES, Triple DES.



STEVE:  Yeah.  It is certainly - it is newer.  It uses a state-of-the-art understanding of crypto and attacks on crypto.  One of the other cool things, there's an attack known as a side-channel attack.  And that is that some crypto algorithms give away information about what they're doing inside based on their power consumption, or the time it takes.  So somebody who's really serious about attacking - this is all NSA sort of stuff - they can look at variations in the power consumed by the processor during encryption, and that will reveal bits of the key.  Or because many ciphers do different things based on what the key is.



So again, the guys who did Rijndael said okay, we're aware of side-channel attacks.  We're going to make what Rijndael does not key dependent.  And so what's so cool is the only thing - and this is what's sort of mind-boggling is the only thing that the key is used for is producing that expanded set of blocks of key material which is XORed for every round, that all that internal stuff, that S-box, the shifting of the rows, the mixing of the columns, that never changes.  That's not dependent upon the key.  And so Rijndael was designed not to give away any information by someone looking at it, that is to say its timing never changes and its power doesn't change because the key is only used for XORing the data as it comes out of each cycle of round.  It's never used to, like, go down different crypto pathways.



LEO:  Very interesting.



STEVE:  It's all you need.  And believe me, I'll be using it a lot in the future.



LEO:  And obviously easy to implement because it's, I mean, it's just so simple.



STEVE:  Yes, exactly.  It's very straightforward.  And it's one of the things that makes it a modern cipher is there's nothing screwy where it's - remember the old cartoon with some guy, I guess it was Einstein, who was working on how E=MC squared.  And he comes to the end, and he scratches his head, and he says, "And then a miracle happens."



LEO:  And there you go.  And now you have it.



STEVE:  Yeah.  Rijndael has no miracles, it's just really simple, straightforward.  And every step of the way these guys were able to say this is why we chose this polynomial.  This is why we chose this S-box.  This is why we're shifting the rows this way.  And the result is a really, really strong scrambling of bits, a mapping between all these possible input bit combinations and output.



LEO:  That's neat.  Very cool.  I'm glad, you know, I have to say I enjoy these shows where you really explain stuff so much.  And we've kind of gotten away from it a little bit.  So I'm glad we could do this, and I hope we'll do more of these where the basic technique - I guess what happened is early on we kind of covered all these basic technologies, and so we didn't need to go back and do more.  But I love this, and I love learning how all this stuff works.  And you're very good at explaining it.



STEVE:  I love explaining.



LEO:  If you want more, including transcripts of this show or any of our 125 episodes, or 16KB versions, Steve keeps those on his site, GRC.com/securitynow.  It's a great place to go because not only can you get all the information, the show notes and everything, you can also get Steve's free, and there are many of them, security utilities.  You can use ShieldsUP to test your router, Unplug N' Pray to turn off Plug and Play, DCOMbobulator, Shoot The Messenger.  That's where he keeps his Perfect Paper Password algorithms, all the different versions of that.  And the forums, too, where you can contribute.  And you can submit your questions at GRC.com/feedback.  But don't forget, that's also where you'll find SpinRite, the world's best, everybody's favorite, my favorite, hard drive maintenance and recovery utility, GRC.com.



STEVE:  Now, I do want to remind everyone, please do not use the Romper Room cipher.



LEO:  That would be bad.



STEVE:  That was presented for demonstration purposes only.



LEO:  You know, it'd probably work, though, if your kid brother's not too swift.  But other than that.  Thank you Miss Nancy.  Steve, we'll talk again next week with lots more stuff.  And as we said, we're going to start covering some security news starting the next week, as well.



STEVE:  Absolutely.



LEO:  Keep you up to date on what's going on in the security world.  Thanks, Steve.  Have a Happy New Year, and we'll see you next week.



STEVE:  Right-o.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#126

DATE:		January 10, 2008

TITLE:		Listener Feedback #32

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-126.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 126 for January 11, 2008:  Listener Feedback #32.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now!.  I am back.  We are late.  And actually it's my fault.  I apologize.  I got back from Egypt with a raging cold - which I didn't catch in Egypt, I caught on the plane back, of course.

 

STEVE GIBSON:  You're sounding a little, I mean, like, you know, okay, but like a little more throaty, I guess.



LEO:  A little Barry White going on there.  That's probably all the drugs I'm on right now.  I'm feeling better, but we couldn't do it at our normal time.  Then you had an important business occasion yesterday.



STEVE:  Yup, yesterday was burned up for me, so.



LEO:  Well, that's fine.  We're a day late, but not a dollar short.  We've got lots to talk about.  Hello, Steve Gibson.



STEVE:  Leo, it's great to be back with you.  And officially now, Happy New Year.  This is the first time we've spoken since '08 began.



LEO:  Yes.  And it's been a very good year so far.



STEVE:  Your trip to Egypt was a good one?



LEO:  Fascinating.  Fascinating.  I'm going to - I've posted all the pictures.  I posted, you know, I took over 2,000.  But I had the good sense to narrow them down a lot.  So if you go to my blog, they're all there in the photo section.  About 125.  Maybe not even that many.  80.  Something like that.  And we had just - it's fascinating.  You know, it's a very challenging country.  And, you know, the ancient ruins are interesting.  But we also, you know, we're part, I mean, it's the world's largest Islamic city, 16 million people.  Population's growing 100,000 a month.



STEVE:  Whoa.



LEO:  Got huge population crisis.  And so it's, you know, it's very - it was very interesting.  I think we learned a lot about the Islamic world, as well.  I'm going to write a longer essay, I think, for the blog.



STEVE:  Is population growing through immigration or birth?



LEO:  No.  It's an authoritarian state.  There is neither immigration nor emigration.  It's birth.  And it's mostly birth in the rural areas.  But what happens is they move into the city.  So Cairo is just a sprawling, teeming metropolis.  Which, you know, one block from the hotel there are dirt roads.  It is a very interesting place.  I have a lot to say about it, but I'll...



STEVE:  And the kids also enjoyed their...



LEO:  Yeah.  I mean, they learned a lot.  And they saw, I mean, we saw every, you know, important monument.  And they're incredible.  These ancient Egyptians 4,000 years ago, they were doing art that is modern and beautiful.  We saw the world's oldest sculpture, 4 or 5,000-year-old wooden sculpture.  And it's perfect, it's beautiful.  And so it's really stunning what they accomplished all those years ago.  And I think that for the Egyptian people that is a little bit frustrating because one of the questions they seem to be asking themselves is, what happened?  You know, we were this dominant culture for so long, and now we're essentially a Third World nation.  So it's tough times for them.  But there were some very interesting people on the trip, as well.  Met a lot of great people.  So I had a blast.



STEVE:  Very cool.



LEO:  Yeah.  But I missed you guys, I really did, and I'm glad to be back at work, cold or not.  This is a Q&A segment.  We've got lots of listener questions.



STEVE:  Yes.  We've got, well, and it's a bizarre coincidence that we had promised to get more focused on sort of current...



LEO:  News, yeah.



STEVE:  ...events in security because there's just a whopper, a whopper in Windows.



LEO:  You know, it's funny, I haven't seen word one about this.  All the coverage on CES, which by the way there was  nothing worth covering, and not one word about the security flaw.



STEVE:  This is - I've seen people saying that this is the worst Internet security flaw in history.



[Talking simultaneously]



STEVE:  ...all about it.



LEO:  Is it Vista?  Is it Vista, or is it...



STEVE:  Even XP.



LEO:  XP and Vista?



STEVE:  And Vista.  It's a remote code execution flaw.  We'll get to that in a second, but I had some errata that I wanted to share.  First of all, I wanted to thank our listeners for, one way or another, finding the vote buttons on my Kindle review.



LEO:  I did.



STEVE:  Yes.  Even though the link that I had posted took people to a buttonless, you know, voting button-free instance, enough people did that my review is now the featured review, the number one review.



LEO:  Oh, good.  As it should be.



STEVE:  Like by a large margin, like by two to one, I think.  When I last looked there were 6,755 votes, and 98.4 percent of them said that they found the review helpful.



LEO:  That's great.



STEVE:  I know that some of our listeners are among them because I've looked through the comments on my review.  And some people have talked about you or me or the podcast or, hey, you know, there were no buttons on the link you said, but I found the buttons, blah blah blah.  So but I think now it's in the first-place position it's got a life of its own.  So I absolutely wanted to thank our listeners for making another one of my wishes come true.



LEO:  Happy New Year.



STEVE:  And actually there are - it's very clear, too, that a lot of people are reading it who are not Security Now! listeners but really do honestly find it very helpful to them, so...



LEO:  I brought my Kindle along, and that was how I read, and it was great.  Even though I didn't have wireless in Egypt, obviously.  And I showed it to a number of people who were thinking about the Kindle.  And to a man they said, oh, okay, that's it, I'm going to get one.  You know, it's not perfect, as you say.  It's got warts.  But it's pretty darn useful.



STEVE:  Yeah.  Well, it's funny, too, because, on one of the other little errata notes I had, I wanted to mention that Kindle hacking is underway.



LEO:  Oh, boy.



STEVE:  There are - people have not only physically taken it apart, but they've gone into the software.  And there's, for example, pages of all kinds of hidden features.  Apparently Google Maps is built in somewhere.  And there's things where you can change justification options, which is one of the things I really wanted because I like ragged right more than flush left.



LEO:  Yes, I'd love to turn that off, flush left.



STEVE:  Yeah, I just - I don't know.  Just the programmer in me, I see like a long word on a line which prevents wrapping where it would be nice if it could.  And this is like, oh, it just bugs me.  So, but there's all kinds of undocumented things, so that's all beginning to surface.  So Kindle hacking is happening.  Also I wanted to mention Jungle Disk, which we talked about several weeks ago.  I asked the author whether he'd had any effect from our mentioning it because I was curious about that.  And he says, oh, yeah, he said, I mean, even over the holidays things were much busier.  And a lot of Security Now! listeners had apparently posted in a blog that they learned about it from our podcast and were excited to check it out and try it out.



So, and the reason I actually wrote to him was I was curious if it was really effective in a situation where, for example, you want to keep a laptop backed up as you're coming and going, as connectivity is changing, you're visiting WiFi hotspots, you're just basically not even thinking about keeping your laptop backed up.  And of course I wouldn't ever back up an entire laptop.  But, for example, the My Documents folder, where most of your documents - and, for example, your desktop.  And he said absolutely, it's designed with that I mind.  So I have been using it in that fashion experimentally.  And I've set up a couple friends who are not very tech savvy with their own Amazon accounts and am using it as sort of just a background constant, just out of your way, don't even think about it, it's just going to - it's going to keep your laptop backed up in case it should ever - the hard drive should get damaged or the laptop be stolen.



LEO:  Yeah, yeah.



STEVE:  Well, anyway, Jungle Disk, I'm just - and it's been working that way really well for me now for a couple weeks.  So I'm really pleased.



LEO:  I think online backup is really the way to go.



STEVE:  I think that's the right thing to do, yes, for nave users.  And I wanted to share, as I always do, a fun SpinRite story.  This one is a little longer, but it was really well written.  So it was from a guy named David Bins who sent email to GRC with the subject "SpinRite Success Story."  And he says, "I'm an IT consultant who has just bought a copy of SpinRite.  I've been," he says, "I've been listening to Security Now! podcasts since around Episode 40 and have meant to buy a copy of SpinRite as I got a lot from the podcast and felt guilty that they were free."  He says...



LEO:  [Indiscernible] guilty they're free.  That's okay.



STEVE:  No, no.  He says, "I was all prepared" - well, see, but we got him anyway.  He says, "I was all prepared to buy a copy when I got to discussing Security Now! with a work colleague who also listens every week.  He had purchased a copy and ran it on his machines regularly.  He hadn't had any problems, and SpinRite hadn't ever found any problems with his drive.  He suspected either his hardware was perfect or SpinRite wasn't all it was cracked up to be.  So I held off buying a copy for myself."



Now, of course, we know that what's going on is the act of running SpinRite is  maintaining his drives.  Which is not to say that his drive wouldn't be fine without SpinRite.  But by running SpinRite on a drive that is even perfect, it has the option or the opportunity of showing the drive that it's got problems it wasn't aware of because a drive only knows it has a problem when it tries to read a sector.  It doesn't know it has a problem until it tries to read a sector.  So that's how SpinRite functions good from a maintenance standpoint.  And because this sector relocation is, literally, it's hidden, there isn't any way for me to say, oh, look, we relocated X number of sectors.  I mean, that information isn't published by the drive.  So you kind of have to take it on faith.  On the other hand, this guy's using SpinRite, and his drives are not failing.  So there you go.  Anyway...



LEO:  Wouldn't you rather have it be that way.



STEVE:  Yeah.  David continues, saying, "I'm the sort of person" - and this is where it gets interesting - "who backs things up from one computer to another and also to a USB-attached hard drive at regular intervals, but even a couple of days of lost work can mean a lot to me.  So I was particularly annoyed when my USB hard drive failed.  It's a Hitachi drive, and all it does is play a tune at me when I plug it in.  I've attached it to a power supply, but it doesn't spin up.  I wasn't too concerned, as most of the data I needed was on my laptop.  It was the first hard disk that I have had fail on me in probably the last 18 years."  He says, parens, "(outside of work).  So I felt I was due to experience some sort of data loss.  My USB drive failed on 12/31/2007."  Okay, so New Year's Eve.  "And last night at around 11:00 p.m., January 7, my laptop drive failed, and my laptop would not boot, giving an unreadable drive error just after the BIOS screen."



LEO:  Oh, I hate that.



STEVE:  Uh-huh.  He says, "I recognized this as a failed drive and assumed I had lost a whole lot of data, including the accounts and invoices for my company.  I did have a copy of the data on the failed USB drive, and also a copy from around three months ago on another laptop.  But I had lost a lot of information and last night had a sleepless night, thinking about how I would reconstruct what I had lost.  I know I should have tried SpinRite immediately, but it just didn't occur to me at first.  I purchased a copy this evening."  Oh, so he said, "I purchased a copy this evening at about 9:45.  After downloading the software I created a boot CD and ran it on my laptop.  SpinRite was running through the recovery process by about 10:00 p.m."  So 15 minutes later.



He says, "I was impressed at how quick it was for me to purchase the software and have it running.  I can't tell you how happy I am after seeing SpinRite recover data from bad sectors.  I'm writing this email on the laptop I was about to throw away, which is now completely up and running.  It is 11:46 p.m., about two hours after buying your software, and everything is back to normal and running perfectly.  If you ever need anything - advice about database administration or service management, which are my areas of expertise - give me a shout, as you've helped me enormously, and I feel I need to return the favor.  Many thanks."



Well, of course he already has helped us by purchasing a copy of SpinRite, which is all I would ever ask.  And I thank you, David, for the tremendous testimonial.  I really appreciate it.



LEO:  GRC.com, that's where you can get your copy of SpinRite.  A must-have.  Are you ready for some questions?  Do we have anymore...



STEVE:  Uh-oh.



LEO:  Wait a minute, we want to talk about this Microsoft problem.



STEVE:  Oh, we haven't gotten started yet.



LEO:  Oh, man.  Okay.



STEVE:  Okay.  Now, okay.  The takeaway message is absolutely everyone needs to run Windows Update.  Last Tuesday was the second Tuesday of the year.  Since the first Tuesday, of course, was January 1st, it was January 8 was the so-called "Patch Tuesday," when Microsoft releases their security updates.  This week we had a doozy.  It turns out that private parties informed Microsoft of a very low-level buffer overflow which permits remote code execution in the Windows TCP/IP stack itself.  So, and this is...



LEO:  Oh, is it the new stack that they wrote, or is this the old stack?



STEVE:  Well, this is XP's stack.  And it's believed that there is a problem in Windows 2000 as well.  So this has been around for a long time.  What makes this specifically bad is this is down - it's in what's called the IGMP, the Internet Group Management Protocol.  That's a multicast protocol.  And but the point is, this is not like a service running with an open port where the service has the problem.  This is the core of the stack itself.



LEO:  So if you've got it running, which everybody does, you're vulnerable.



STEVE:  If Windows is running, exactly.  And, Leo, none of the built-in firewalls block this.



LEO:  Really.



STEVE:  Yes.  Because this is, I mean, this is not something that, like, at the application level, where firewalls are blocking ports.  This is more like, you know, like, well, it's very related to the ICMP, the Internet Control Management Protocol.



LEO:  So how would this exploit be triggered?



STEVE:  Okay.  One packet hits an unprotected machine, and it's taken over.



LEO:  Oh, well, that's fast.



STEVE:  So, okay.  What this means is, as far as we know...



LEO:  It's a packet on what port?



STEVE:  It would be, well, it's not port based, and that's the problem.



LEO:  So it could be anywhere.



STEVE:  It's more like - well, there are no ports for IGMP.  It's a multicast protocol.  So, see, ports are related to applications.  So, like, port 80 is web services, port 22 is FTP, and so forth.  So this is more like ICMP.  You know, people are familiar, for example, with pinging and tracerouting, where that's - for example, the ICMP protocol is built into the stack as part of its plumbing.  So that by definition of the RFCs, any stack which - any IP stack will have ICMP support, so that you're able to sort of, like, manage the connectivity of the stack on the Internet at a low level.  Well...



LEO:  But how does a computer know that that traffic is aimed at it?



STEVE:  Well, oh, because there is an IP address.



LEO:  I see.



STEVE:  So it's an IP address, but not an IP and port.  So, okay.  So first of all, the good news is, NAT routers do block this.  So here's another reason why it would have always been good to be behind a NAT router.



LEO:  So a software router will not stop this, but a NAT router, a hardware router would.



STEVE:  Well, it's certainly possible that a software firewall could stop it.  But Microsoft's built-in firewalls do not.  So, and this is still very new.  Essentially what it means is there is virtual certainty that we are going to see a worm because this is a perfect opportunity for a worm to propagate across the Internet, finding unpatched XP and Vista machines that...



LEO:  Now, wait a minute now.  Vista has a whole new stack.  Remember we talked about Vista's virgin stack.



STEVE:  Yes.  Except it, you know, no doubt someone took a blob of source code...



LEO:  The IGMP implementation's the same.



STEVE:  Exactly.  They took a blob of source code...



LEO:  So this affects XP, it affects Vista, affects Windows 2000.



STEVE:  Yes, yes.



LEO:  Now, Microsoft patched it on Tuesday.



STEVE:  And that's my point, yes.  So first of all, you know, the takeaway is make sure you run Windows Update, I mean, critically, on any computer that would be on the Internet not behind a NAT router.  Now, when you're in like a T-Mobile hotspot at Starbucks or a FedEx Kinko's, you know, you're behind that location's NAT router, looking at - and you're in a 10. space most likely.



LEO:  So you're safe there.



STEVE:  Yes.  And again, and most people are going to have a NAT router at home because, you know, and we've been promoting the inherent firewall virtue of a NAT router.  So a NAT router, even if it were vulnerable, and it's not because it probably doesn't support IGMP protocol, which is a multicast protocol, it's going to drop that packet dead right there.  There's no way it can gobble through to a specific machine because a router would have no way to know where it should send the packet because it really shouldn't send it anywhere.



But the danger is any Windows 2000 with Service Pack 4, the latest service pack, XP or Vista machine which is placed on the Internet unpatched and not behind a NAT router, that is, with an actual public IP, what is virtually foreseeable is that the patch will be reverse engineered.  We've already seen Microsoft's patches reverse engineered where the bad guys look at what changed and then figure out what the vulnerability was from the change that was made.  So it's virtually certain that this patch will be reverse engineered.  Bad guys are going to figure out where the buffer overflow is in IGMP.  And maybe they wouldn't even have to reverse engineer.  Knowing that there is one there, they could just find it the same way the good guys, the good hackers did, who informed Microsoft about this some time ago.  So what'll happen then is a worm will be planted on...



LEO:  Did you say some time ago?  We're talking June of 2006.



STEVE:  I know.



LEO:  I'm looking back at Microsoft's report.  This fixes - this is something really a long time ago.



STEVE:  Yeah.



LEO:  Wow.  So, now, Microsoft says that it is only a denial-of-service attack on 2000.  But on XP and Vista it's a...



STEVE:  Yes, exactly.  So in 2000 it will basically crash your stack.  There isn't a vector that they have found that allows a remote code to be injected as part of the packet.  But as you said, under XP and Vista the incoming packet can carry executable code payload, which in classic buffer overrun mode will be run when this specially malformed single packet hits your computer.  So if, I mean, it has to be, based on all the experience we have, that we're going to see a worm, that there will be enough unpatched Windows XP and Vista machines, even with their firewalls running, this thing cuts through their firewall.  And they're going to get infected, and then they're going to turn around and start spraying random packets out at random IPs, as worms do, looking for other vulnerable machines.  So you absolutely want to make sure your machine is patched, especially if you're someone who, you know, roams around with a laptop and might ever get a public IP address.  It won't be long before the Internet will be sprayed with this IGMP protocol carrying one or more malicious types of code.



LEO:  Microsoft gives credit to the IBM security people for discovering this.



STEVE:  Yeah, the X-Force people.



LEO:  X-Force, yeah.  Wow, that's - boy, that's pretty scary.



STEVE:  Yeah.  There was another one, an MLD protocol, Multicast Listener Discovery, which is part of the IPv6 protocol.  It's a little bit less severe.  It can cause a denial of service, and there's less vulnerability associated with it.  But it was also patched.  The big one, though, is this remote code execution.  And again, the thing that makes it special is it is not blocked by the built-in firewalls.  It is basically a function of the stack running in the kernel.  So it runs, not for example with the security credentials of a service which could be sandboxed or could be running with restricted credentials.  It runs with the full power of the kernel when the buffer overflow - because, I mean, this is too tasty for the bad guys not to jump on and try to exploit.



LEO:  And I don't want to be self-serving here, but it's one reason why it's important to listen to this show.  Because I'm looking through all the major tech news sources, and they were so busy covering CNET, I don't see anything about this.  And partly they were covering - CES.  I just said CNET.  CES.  But partly, I think, it's, oh, another Windows security flaw.  We're tired of that.



STEVE:  Right.  Well, it'll certainly get some news when this thing turns into a worm.  And we don't know when it's going to happen.  We'll certainly let our listeners know.  But just it can't help but to happen.  Now, people might say, oh, well, but wait a minute, you know, won't all of these machines be patched?  Well, that brings me to another interesting bit of news from the beginning of this year.  Due to another flaw in Microsoft's database for their SQL, there is an SQL injection attack which was launched, and more than 70,000 Microsoft-based websites have been infected in a way that refers people to a malicious website which attempts to install keystroke loggers, using a number of various browser-based vulnerabilities.  So, okay, and get this.  This was fixed in April of 2006.  This was fixed then.  So almost two years ago this was fixed.  Yet there are 70,000 websites that are not patched current.



So this demonstrates conclusively that for whatever reason there are web servers, for example, which are not keeping up with Microsoft patches.  Because if they had patched once in the last almost two years, this would have been fixed.  Yet they have SQL exposed in a way that a malicious agent was able to scan these websites and alter - and we talked about SQL injection attacks - basically scan all of the SQL tables, adding their own JavaScript into the tables, which are then being used to present web pages.  So it's a way of them injecting - they use an SQL injection attack to put their own JavaScript onto the 70,000-plus websites, which then of course browsers execute.  And you know how I feel about JavaScript.  But, you know, I understand you have to have it most of the time in order for contemporary websites to work.  So your browser then executes this malicious JavaScript which was injected into a benign server that, you know, was innocent except it hadn't been patched in the last two years.  So...



LEO:  That I understand a little bit better than, you know, servers, people don't want to patch them a lot of times.  A, they're not paying much attention; B, you're always nervous what the patch is going to do.  But I would hope that all desktop computers are kind of running automatic updates.



STEVE:  Yes, let's hope.  Another news item that has gotten a lot of attention lately, Slashdot picked it up, relates to the so-called "stealth MBR rootkit."  MBR is the so-called Master Boot Record, which is to say it's the first sector on our hard disks.  And what's not understood, most people think of that as the partition table because it does contain the partition table.  But that first sector is actually executable and executed code.  So the way this works is when any - excuse me, a little hiccup.  When any PC is first booted, the contents of the first sector are copied into memory, and the computer starts executing code from the very first instruction, which actually contains a - typically contains a jump instruction.  But basically it means that that first sector is executed.



Well, this has been used to good advantage, for example, by people doing multiboot managers where they'll put additional code in other sectors on the first track of the hard drive, which is normally not used.  A contemporary hard drive track contains 63 sectors.  So the first one is the so-called partition sector, which is also the master boot record.  Then the other 62 sectors are typically unused, and the first partition starts at the end of the first track with the beginning of the second track.



LEO:  This was a very common technique for viruses years ago, Michelangelo and others.  You'd put an infected master boot record on a floppy, and it would spread itself that way.



STEVE:  Well, what's now been done is there is an MBR rootkit that patches the Windows kernel on the fly in order to install a rootkit into the Windows kernel whenever it boots.  So, you know, we've talked about who's on first as being the competition with a rootkit versus the operating system.  And if something is able to run before the OS is able to protect itself from anything that could run subsequently, well, it's compromised.  And this, you know, this does now exist.  It has been found in the wild.



LEO:  Wow.  So how would you get - I guess you'd have to have maybe a boot CD?



STEVE:  Oh, no.  I mean, it would - it turns out that Windows protects everything except that first track of the hard drive.  So you could get this installed in the standard spyware...



LEO:  Just running an application...



STEVE:  Yes, exactly.



LEO:  Oh, dear.



STEVE:  Exactly.  So it is, it's worth mentioning that this exists.  It's not a good thing.  But it was even foreseen some number of years ago.  It's like, okay, well, this is theoretically possible.  And that theory has now been turned into reality.  So, and I did note that the iPhone has its first trojan.  There is now a trojan for the iPhone which, you know, people go browse a malicious website, and unfortunately it uses some vulnerabilities in the iPhone browser in order to install a trojan which causes a great deal of grief, apparently, when it's removed because it's difficult to remove it cleanly, and people end up messing up their iPhones as a consequence.



LEO:  All right.



STEVE:  So anyway, lots of interesting security concerns here at the beginning of '08.  And we'll be keeping our listeners informed week by week and blow by blow.



LEO:  Yeah.  I'm glad we're going to start doing that.  And clearly this is the week to start.  Boy.



STEVE:  Absolutely.



LEO:  Are you ready to do some questions now, Mr. G.?



STEVE:  Let's do some Q&A.



LEO:  12 great questions from 12 wonderful listeners, starting with J.P. in Sydney, Australia.  He wanted some VeriSign token clarification.  You and I both have used that football and now use that VeriSign card, which I love, my VIP card.  He said:  If somebody were to get a hold of the VIP event-based credit card token for a short time, couldn't they push the button a few times, write those numbers down to be used later, assuming they also know your username and password?  I'm guessing this wouldn't work with the football since it's time based.



STEVE:  Yeah.  This was a great point that was raised.  And it raises a few sort of interesting points.  First of all he says, well, if someone gets your credit card, your VIP credit card, which is event based, meaning that when you press the button you get the next number, you press it again, you get another number.  But that's entirely deterministic.  That is there's a counter which is being incremented.  The counter is being encrypted and hashed through a well-understood and well-known algorithm to produce that unpredictable number, well I should say unpredictable to someone who doesn't know the key which that card also contains, the cryptographic key.



LEO:  Which is everybody except the site you're going to.



STEVE:  Well, actually it's everybody but VeriSign.  VeriSign knows, and the site you're going to then checks in with VeriSign to say is this the proper next number for this guy.  And of course as we've discussed there's a window of those.  Remember we had a listener who liked to push his button on his card a lot, and he'd moved that counter so far ahead it was outside of the tolerance window that VeriSign maintains, and so he had to go through the extra resynchronization process because he was just having too much fun...



LEO:  It's not a big deal.  You just enter the number a couple more times so it can figure out where you are.



STEVE:  Exactly.



LEO:  So once you use a number, it can't be used again.  But this guy's saying, well, you could get a couple of numbers, you could stack them up.  But it's only going to be good until I use it, though; right?



STEVE:  Well, but what he's saying is he's saying, okay, if I borrowed your or sneakily got a hold of your VIP event-based card and wrote down a few numbers, and I also knew your username and password - well, okay, stop.  What he's saying is, if I have all of your multifactors, then I could log in.



LEO:  Right, yes, you could.



STEVE:  I'm like, yes, absolutely.  You know?  If you've got something I know and something I have...



LEO:  But here's the question.  Okay, so he gets a couple of those numbers and gets it back in my wallet.  But as soon as I use that card again and give the current number, all of those older numbers are invalidated anyway; right?



STEVE:  That's absolutely true.



LEO:  Okay.  So it's for a limited time those are going to be any good.



STEVE:  Well, it's not limited time except in the sense of limit he'd spend.



LEO:  Eventually I'd use my card, yeah.



STEVE:  I would say a limited event.  Now, the point is, though, he says, that won't work with the so-called football because we know that it changes every 30 seconds.  And there's a window of what is it, plus or minus three minutes or something.  I mean, it's 30 seconds, and it's plus or minus five.  So, yes, three minutes.  So if he didn't use the number on the football, and he did have your username and password, then that wouldn't work.  And so first of all, he's correct.  Secondly, I wish our VeriSign cards were time based rather than event based, for exactly this reason.  Except I don't think you can do, practically at this point, a time-based system...



LEO:  They're not smart enough.



STEVE:  Well, these things are thin.  I mean, you'd have to have a crystal time base somehow in something that is literally no thicker than a credit card, and also have plastic on both sides and some goo in the middle of the sandwich.  I mean, it just - I don't know how you'd do that.  And time is a problem because that would be consuming much more power.  The beauty of the event-based card, which uses the eInk display, as we know, eInk requires zero power to keep it displayed.  So literally, when you press the button, there's a moment of power usage from a no doubt very small and low-capacity battery which has also somehow been sandwiched into this thing, I mean, the reason we love the card is it's in our wallets.  The reason we're not so crazy about the football is if you stick that in your wallet, you're going to need to go to a chiropractor.



LEO:  And as you point out, they'd have to get physical access to your wallet, your card, write that down without your knowing.  I think...



STEVE:  Well, yes.  I mean, his question is, if I had all the factors of your multifactor, you know, wouldn't I be able to log in?  It's like, yes, you would.  But the point is, you know, you're not supposed to get all the factors of our multifactor.  And he's right, though, that the football, because it's changing constantly, one of the factors, that is to say, that coming from the football, it gets stale.  It's going to be stale in three minutes.  And so if you got it you'd have to use it quickly.  You couldn't write a bunch down and then be logging in until, as you said, Leo, until you used yours, which would immediately obsolete all previous numbers.



LEO:  Robin in Langley, BC - British Columbia - has been thinking about Matthew's Mega Hash login dilemma.  I loved that.  If you don't remember that, listen back to Episode 120.  It's funny.  Anyway, he says, Robin says:  I realize the problem with Matthew's login scheme which you described in Episode 120 - multiple secure hashing, then just capturing the results since the connection is not encrypted.  However, it occurs to me that there may be a simple way to fix the problem.  I was wondering what you think of this solution.  Since Matthew is creating both the client and server sides of his web app - the whole idea of this, though, was that Matthew didn't have to use SSL, he could create his own kind of security system.  Couldn't he simply have the server generate and supply a unique login ID, a serial number of some sort, to the client, with the original login form generated by the server?  Then, using the client script, hash - I'm trying to follow this.  You can follow it.  I won't try to follow it.  Then using the client script would hash both this ID and the user's password data using Matthew's Mega Magic encryption scheme, using an encrypted blob that is sent back to the server for authentication.  A man-in-the-middle replay attack would be useless then since the encrypted blob would be unique for each login.  Obviously this won't work if Matthew is trying to specifically not use encryption/decryption on the server side.  Your thoughts?



STEVE:  Well, this is a great idea.  And several listeners, astute listeners, who are clearly enjoying coming up to speed about crypto technology, responded about this.  The idea being that what Matthew described to us was he would have an algorithm in JavaScript code that was being delivered from the server, that would run on the browser client.  So that basically when the user logged in, it would obscure the user's login name and password by hashing it down into a cryptographic blob, which would then be sent back to the server.  The server would know what the proper cryptographic blob was.



People, and we had discussed this before, recognized, wait a minute, all you have to do if you're monitoring and have the opportunity of being the man in the middle, all you have to do is capture the blob and then send the blob yourself.  You don't have to know what the original username and password is because the whole point of this is that Matthew is not going to be encrypting his connection.  And so of course that's absolutely right.



So what Robin has suggested, as well as some other listeners, the server could send something to the client which is different every time.  And in cryptography it's called the "nonce," that is, something which is just used once and never again, the idea being so it would send, like, a serial number to the client.  The client would add that to the hash.  And what that would do is, that would mean that this blob would be different every time because this nonce coming from the server would never be duplicated.  And that would prevent a replay attack.  That is, essentially the blob could only be used for authentication once and never again.



Now, that's certainly the case that you could do this.  But if you were an active man in the middle, that is, if you had the ability to filter the traffic going in each direction, you could simply log in by capturing these nonces and essentially using the client to solve this puzzle for you, intercept its response, and then use that to log yourself in.  So again, it's still, I mean, it is a real problem with not having a secured, cryptographically strong connection because there are all kinds of games that can be played, depending upon what level of access an attacker is able to get to your connection.  But certainly it was another interesting application of all the crypto that we've been talking about in prior weeks.



LEO:  It's a thought exercise.



STEVE:  Yeah.



LEO:  Tyler Menezes in Redmond, Washington had an ALT-ernate password idea:  While setting type for a brochure, I thought of an interesting idea.  If you were to use a nonbreaking space, instead of hitting the spacebar you hit ALT+160, actually 0160 on the number pad for Windows, in your password, wouldn't this make it much harder for keyloggers to get your password?  The attacker would see a normal space, which is not the same as a nonbreaking space bit for bit.  So the application would reject it.  If I'm worried about someone intercepting my keystrokes or perhaps looking at my saved Firefox passwords, if I didn't save a master password, would this be a good solution?  I'm a big fan of the show.  Keep the awesome shows coming.  P.S.:  SpinRite rocks.



STEVE:  Well, I thought this was sort of an interesting idea.  I use the ALT key myself.  I think ALT+249, or maybe it's 0249, is a bullet.  And so even in my source code, where I wanted, like, to put in some bulleted points, I'll just use that.  It's a PC-only sort of feature, which has always been around, where you're able to hold down the ALT key, and then on the number pad you're able to sort of manually dial in a code which doesn't have to be within the normal 256 ASCII characters, but it allows you to access a much wider range of characters.  The problem is that it is - it tends to be application specific, that is, some applications understand that keyboard sequence, and others don't.  So I would say, well, your mileage may vary.  It's certainly an interesting idea.



And so, for example, if Firefox did allow you to put in the so-called High ASCII or Unicode characters, that is, characters outside of the normal character set, so if Firefox allowed that, then you could certainly obscure the fact that a space in a password was not really a space, it just looked like a space, while not actually being that.  So, I mean, that's certainly a possibility.



LEO:  The problem is a keystroke logger is logging the actual keys you type.  So it knows exactly what you type.



STEVE:  Exactly.



LEO:  It's not fooled by how it looks because it's not looking at it.



STEVE:  The problem is there is a complex interaction of different layers of keyboard handling.  So at some level the output from the keyboard is going to just be ASCII, or it might be 16-bit Unicode.  Somewhere else it's actually the individual events of keys going up and down.



LEO:  The scan codes, yeah.



STEVE:  Yes.  So, exactly, scan codes from the keyboard.  So if you had a keystroke logger that was intercepting at the scan code level, and it was able to interpret those scan codes into their equivalent Unicode, I mean, I guess...



LEO:  Well, if it's ASCII, the nonbreaking space is a different ASCII symbol.  So even at ASCII level it's going to catch it.



STEVE:  Correct.



LEO:  It only works if somebody's looking.  I guess if they're looking at your Firefox passwords, they might not notice that.



STEVE:  That's exactly what I was going to say, was that if you had passwords that had obvious spaces in them, and if Firefox treated these alternate characters in a compatible way, then it could work.  So it's an interesting idea.  And I would say the reason I think your mileage may vary is, well, try it, but don't count on it because you might find out, first of all, that a keystroke logger could be smart enough to track the individual scan code events and figure that out; or you might have applications that are incompatible with the whole concept.



LEO:  John Campbell in chilly Bozeman, Montana, looks up DNS without the help of his ISP:  In a past episode you talked about having your Internet service provider's DNS server track your movements.  I found a solution, not for the faint of heart:  TreeWalkDNS.com.  This is a DNS server you set up on your local machine that bypasses your ISP and does the DNS lookups directly.  It can also be used as an ad blocker and to block access to hostile sites.  I use it on my laptop and at my house.  The DNS software is simple to install.  Setting it up to do ad and hostile site blocking is not so simple.  It also has the advantage that you are not depending on your overloaded ISP's DNS servers, and it caches DNS lookups locally.  I wish they had a Donate button on their site.



STEVE:  Well, this is an interesting piece of email for me because the two guys who are behind TreeWalk DNS are longtime GRC newsgroup participators; and a whole bunch of GRC newsgroup users, because there's been lots of dialogue in our newsgroups about this, do use and love TreeWalk DNS.  So a couple comments.  First of all, I should have mentioned at the top of this, but I'll say it now, the show notes for this episode, Episode 126, has a whole page of URLs.  So TreeWalkDNS.com is spelled exactly as it sounds, but there's also a link to it on our show notes page.  And we've got a bunch of other URLs we'll be coming to in subsequent questions, which there's no way to pronounce them or spell them out.  So I wanted to make sure that people listening to this know that the show notes for this episode contain all the links that we're talking about.



LEO:  Okay.  And we do that in the show notes on the site, too.



STEVE:  Right.  One of the things that ISPs are sort of notorious for is referred to in this email, and that is the overloaded DNS servers.  Many ISPs sort of regard DNS as the unwanted stepchild service that they have to offer their users.  They often have servers that are small or old, sort of dusty things in the corner that never get much attention.  DNS is not a very glamorous service.  ISPs have to offer it.  But it can be the case that the DNS servers are old and slow and in fact overloaded.  Because the ISP grows and grows and grows, increases the number of users they've got.  All users' computers are generally aimed at their ISP's DNS servers to perform the recursive DNS lookup on behalf of their requests.  So those DNS servers end up being slow.  And as we know, anytime you put a URL into your browser, unless your local machine already has it cached from being used before or if that URL exists in your hosts file, which is a substitute for the whole DNS process, if neither of those is the case, your computer then asks typically your ISP's DNS server to look up the IP.  So everything comes to a grinding halt until you get a response affirmatively or negatively from that DNS server about what's going on.



So the idea here that John is talking about is to, instead of using your ISP's DNS servers at all, run your own.  That is, have a DNS server running in your computer, and have it do exactly what the ISP server would have done on your behalf.  And so the potential advantage is, first of all, presumably your own server would never be overloaded because it's not doing any serving for anyone but you.  The downside is that an ISP's servers might already have, for example, and would probably have, for example, www.aol.com in its local cache, and Microsoft and MSN and Amazon and, I mean, all of the common URLs might already be there.  In which case you're taking advantage of all the other users who have asked that common DNS server, because all of the ISP's customers are sharing that DNS server, you're taking advantage of the fact that the popularity of popular sites would have caused the result, the IP already to be known by that local server.  On the other hand, it's just as likely if you're browsing around that that's not going to be the case.  And so having a server running in your own machine would allow you to get more performance.



Now, John also mentioned the privacy aspect, which is what we had touched on a couple weeks ago.  And that is that, you know, if anyone cared, if an ISP cared, they're able to determine where your computer goes because your computer is always asking for it, that is, the ISP's DNS server to look up the IP of any domains you want.  So from a privacy standpoint there is some compromise there in that your ISP could be tracking that.  If you run your own DNS server, you're not asking your ISP, but you are asking other servers, other DNS servers on the 'Net, and the request is coming from you.  So it's sort of a privacy tradeoff.  On one hand, your ISP would know if you were asking for a specific site and know who you were.  But the site and the servers that it has to ask would only see the request coming from the ISP and not from you.  So it does, by using your own DNS, it cuts out the middleman, which can be a benefit for performance.  But it does mean that your own IP is the one which is now making these requests, rather than your ISP's on behalf of you.



Still, from a performance standpoint, what I hear is that it's a win.  And I should say I'm running my own DNS servers.  I have a DNS server that we run, GRC runs at our facility at Level 3.  And I ever have one here at home on a UNIX box.  And it was these guys who did TreeWalk DNS that helped me through the initial hurdles of getting my own local DNS server set up correctly and running.  And they really do know what they're talking about with DNS.



LEO:  I have to say that there's a potential, as you point out, for it to be much slower that you don't have - the lookups haven't been done on a lot of the sites you're going to go to.  So you're actually going out to a more distant server than your own ISP's server to get that information.  You've got to get it looked up somewhere.  I just, you know, if you're worried about, you know, if your ISP has a lousy server, you don't have to use your ISP's server.  I know a lot of people use, believe it or not, Verizon's ISP servers because they have - or DNS servers, I should say.  They have notoriously fast DNS servers.  I don't really recommend that.  I use a company called OpenDNS, absolutely free, it's OpenDNS.com.  And they're faster servers, and they have some additional features, including filtering.  Doesn't solve the problems of privacy issue, but I'm not sure you've solved the privacy issue by running your own server anyway.



STEVE:  Right.  And I guess OpenDNS also supports an additional set of sort of off-the-beaten-path, top-level domain names.



LEO:  Right.  Also if you mistype .com, they'll fix that.  And they have a very helpful, instead of a 404 they'll give you a search results, which is how they've monetized themselves.  There's some advertising on the right there.  But actually if you create a free account with OpenDNS.com, you can turn on filtering, which I use at home.  And unless your kids are smart enough to change, manually change the DNS server on their computers, you're set.  You just set it on the router, and you're good.  And it works very well.  They have no idea.  So, I mean, I guess there's some advantages of having, running your own DNS server.  But it seems like a lot of work.



STEVE:  Well, our more techie users do enjoy it.  And the TreeWalk DNS server is well packaged.  Basically it is a Windows port, or a Windows build, of the Internet standard BIND.



LEO:  Oh, it's BIND, oh, okay.



STEVE:  It's BIND.  Yeah, basically it's BIND running on Windows.



LEO:  Well, then there's another issue you should be aware of, because BIND just has a notorious - notorious for security flaws.  So remember, you're running a server now.  And that means you're opening yourself up to possible attack.  I'm not sure - all right.  If you want to do this, go ahead.  Be aware of what you're doing.  OpenDNS would probably be better for most people.



Athol Wilson in Auckland, New Zealand had a thought about the Romper Room Cipher:  Your Symmetric Ciphers podcast did the trick.  Finally the penny dropped.  With 2^128 having so many billions of zeroes, it's now obvious that even a 5GHz processor could drop 10 zeroes off the end, and there would still be an awful lot of seconds, hours, days, millennia left.  I did expect you to cover double encryption using Double RRC - Double Romper Cipher, though.  I have never heard of this.  Where of course to succeed in a brute force attack one would have to retry each of the 256 keys 256 times to find any plaintext.  I also - maybe you can explain that.  I also discovered a great Flash animation of the Rijndael - is that how you say it?



STEVE:  Rijndael.



LEO:  Oh, Rijndael.  I never saw it spelled out.  I've heard you say it many times - Rijndael encryption process.  It would be great to share it with other listeners.  We'll put, again, that link in our show notes:  http://www.iaik.tu-graz.ac.at/research/krypto/aes/old/~rijmen/rijndael.



STEVE:  Yeah.  It's funny because I started out talking about symmetric ciphers in the context of explaining why it was clear that for a symmetric cipher like we've been talking about, double encrypting with different keys would give you fabulously more strength, essentially, you know, a lot more strength.  And at the same time, I developed this notion, because I also wanted to clearly explain how that was and why, we developed the so-called Romper Room Cipher, which you will remember was a trivial little cipher that used I think a 4-bit key...



LEO:  Oh, this was your explanation of how they worked, okay.  Yeah,  yeah, yeah.



STEVE:  Exactly.  It was a 4-bit key and an 8-bit, that is, a 1-byte cipher, 1-byte block length.  So he was saying that, gee, you know, you went to the trouble of developing this concept of a simple Romper Room Cipher, but then never used that to explain how, in that context, how double encrypting would work and, as he said, how you would have to try all of the keys twice, that is, each key, and then try all the other keys against that, basically, you know, reverse engineering or doing a brute-force attack on double encryption.  So I thought, yeah, he made a really great point.  He also found, or actually reminded me of an animation I had once seen a long time ago.  And we've got the link in the show notes.  It's a Shockwave Flash animation.  It is so good that I grabbed a copy of it to keep local in case it ever goes away.  And also it gives the credits to its authors in the Flash, so I didn't think anyone would mind if I, you know, pulled a copy off of the original website.



LEO:  Oh, good.  So he gave us an Austrian website which is just, you know, long.  But you're going to host it?



STEVE:  Yes, I am hosting it.  And the link, I think, is GRC.com/miscfiles/RijndaelAnimation.zip.  I zipped it because it got half the size.  And it is really nice.  It's a little on the techie side.  I mean, so you'd have to sort of be comfortable with binary and so forth.  But the guys that put this together, I think if you coupled that with listening to Episode 125, last week's episode on symmetric ciphers, where I describe how Rijndael works, together, these are like the diagrams I never drew for this description.  And it's beautifully animated, showing things XORing and the code zipping around in loops, going through the multiple rounds and all that.  So anyway, for our listeners who are interested in seeing something happen with animation, check out the link in the show notes.  It's really worth taking a look at.



LEO:  Cool.  Rijndael is, for those like me who've only heard Steve mention it, R-i-j-n-d-a-e-l.



STEVE:  It's actually sort of a contraction of parts of the last names of the two designers of the cipher.  So it's sort of a synthetic word.



LEO:  It's Dutch.  Andrew Ayre in Perth, Australia, wants to make use of Rijndael:  Hi, Steve.  I work for a small software development company where I and all of my colleagues are regular listeners to Security Now!, as well as some of Leo's other podcasts.  So an interesting debate arose within our office after last week's episode, Symmetric  Ciphers #125.  We're wondering if you could settle it for us.  Does this happen to you a lot?  Can you settle a bet for us?



We're in the process of implementing a .NET web service application that makes use of Rijndael 256-bit symmetric encryption to encrypt data that is then passed to the web service rather than in the clear.  We originally intended to hard code a Rijndael key and initialization vector on both ends, client and server.  But we are now thinking that might not be such a good idea as we'll need to reuse this hard-coded key and IV over and over again.  I think this might be equivalent to reusing a one-time pad over and over again, a big no-no.  I don't think we'd be susceptible to a brute-force attack, but we might be susceptible to some kind of, I don't know, statistical attack?  One approach suggested to get around this possible program is to somehow use the current date/time as a way of salting the Rijndael key or IV in some way.  That way the one-time use pad is never reused, and we can still hard code the Rijndael key and IV on both the client and server.  Just hash it, I guess.  We'd all be very interested in your opinion of our dilemma.



STEVE:  Well, this was a really great application question for security.  There are a couple ways of using a symmetric cipher like Rijndael to encrypt communication.  The simplest way is called the Electronic Code Book, or ECB, which is really just a way of saying you simply take 128 bits at a time, or that is to say the block length of the cipher, that is, you know, the number of bits that you feed into the cipher to get that same number of bits mapped to a different combination out.  And in the case of Rijndael, no matter how long the key is, Rijndael is, as we know, a 128-bit cipher.  So you would take 128 bits, like the first 128 bits of your message, encrypt it into a different 128 bits, and that's your cipher text.  Then you take the next 128 bits, encrypt it, and that's the next block of cipher text.  And so you go along.  And that's a so-called Electronic Code Book, which is just a shorthand for saying, you know, the cipher is the so-called code book, and all you do is take blocks of plaintext, run it through the code book cipher, turn it into cipher text, and then take the next block.



That makes people uncomfortable, even though Rijndael is very strong, even though we know with 256 bits it's infeasible to do a brute-force attack.  The reason it makes cryptologists uncomfortable is that every time the same 128 bits appeared in the message, it would encipher to the same resulting 128 bits, given the same key.  So if the key didn't change, it's very clear that some information is sort of leaking out, you might call it "inferential leakage," because given enough analysis of the communication, it might be possible for someone to infer meaning just from the repetition of certain parts of certain types of repetition.  I mean, there is some leakage of something.  Which makes the cryptographers say, uh, you know, can't we avoid that, too?



In order to do so, they came up with this notion of block chaining.  Cipher Block Chaining, CBC, is the most popular of these.  With Cipher Block Chaining, you take a so-called initialization vector.  Now, notice in the standard Electronic Code Book there was no initialization vector.  That is, you simply took the message, the first 128 bits, you enciphered it, and that was your 128-bit result, then you go to the next block.  With what's called Cipher Block Chaining, you start off with a so-called initialization vector, which is the same size, the same width in bits as the cipher.  And so in the case of Rijndael it would be an 128-bit IV, or initialization vector.  You XOR the first block that you're encrypting with this initialization vector.  And as we know, what an XOR operation does is it conditionally inverts the bits.  So where the initialization vector contains 1 bits, the bits being input will be inverted.  And that's nice because it's a reversible process.  Remember, anything we encrypt is only useful to us if we're able to decrypt it at the other end.



So we take this initialization vector, XOR it with the first block of our plaintext, and then that's what we encrypt.  We encrypt that XORed result as our first block of cipher text.  Then we take that first block of cipher text and XOR it with the second block of plaintext that we're encrypting.  And we then encrypt that to create the second block of encrypted results.  And similarly, we take that result, XOR it with the third block of our input, and encrypt it to produce our third block of encrypted output.



What that does is, first of all, it introduces another 128 bits of uncertainty into the process.  We already had, for example, a 256-bit Rijndael key.  Now we're adding another 128 bits, which is unknown to an attacker.  If we weren't doing that, then the attacker's problem would only be the 256 bits.  On the other hand, we know that's a big problem.  So that's not, you know, making it even more impossible, you know, when it was already impossible.  It's like, okay, well, I guess we're even safer than we were, even though we were safe enough.



But more importantly, what it means is that this initialization vector is propagated through the entire message.  Because we take the output of the first encrypted block and XOR it with the input of the second encrypted block, everything about the message, the initialization vector and all the preceding bytes affect, that is to say, influence everything that comes afterwards.  So no longer do we have the situation we did before with the so-called codebook approach, where each block of 128 bits stands by itself.  Now the entire history of the message affects the next byte's result.  Which means that even if the plaintext had repetition in it to any degree, all of that would be masked in the result.  And the beauty of this chaining approach, where the result from one is mixed into the input of the second, is it's reversible.  You're able to decrypt this knowing both the original key and the original initialization vector and undo all of this, which of course is required for decryption.



So now that we've got this sort of background, all these guys have to do is include with their encrypted data a randomly chosen initialization vector.  That's all they have to do.  Essentially what that will do - and this initialization vector is also - it would be called a nonce, a one-time token which is not going to be reused again for security.  And even though it would be in the clear, that is, it itself would not be encrypted, that doesn't matter because it's changing every time.  And you could have it added to a secret initialization vector, that is to say like XORed, so that even the true initialization vector that was being mixed into the plaintext was never known.



And so the idea is, in this client and server mode, the system would have a 256-bit symmetric encryption key which would be secret for the client and for the server, as Andrew described it.  When you wanted to send a message what was securely encrypted in either direction, you would send a first 128 bits which is the initialization vector, followed by the encrypted result.  And the receiver would receive the initialization vector and use that to start the process of decryption.  And so since the initialization vector is changing every time, but it is obscuring all of the patterns in the cipher, it's entirely secure to let the initialization vector be known in the communication channel.  You don't have to, for example, secretly use the time of day or date or somehow otherwise synchronize the encryption and decryption of the endpoints.  You have the originator who's doing the encryption just choose a random number or an incrementing number, whatever they want, stick it on the beginning of the message, send it to the other end.  And even though that would be done unencrypted, in fact, that channel would be in the clear, an attacker could see the IV, that 128-bit initialization vector, and it wouldn't help them in any way to decipher the rest of the message because it's solving the problem of statistical patterns which would otherwise be present.  And then we're relying on the strength of Rijndael's 256-bit key, which we already know is massive strength.



LEO:  Massive strength.



STEVE:  Massive.



LEO:  Massive.  Well, there you go, Andrew.  Talk about free consultation.  David Eckard in Durham has been counting his toes:  Steve, he says, I have listened to all 125 Security Now! programs.  It is possible to pronounce the number of digits in 2^128, which you were talking about in Security Now 125.  The exact value of just 2^128, not its factorial, is - and by the way, you are now going to understand why scientists use scientific notation instead of actual numbers - 340 undecillion, 282 decillion, 366 nonillion, 920 octillion, 938 septillion, 463 sextillion, 463 quintillion, 374 quadrillion, 607 trillion, 431 billion, 768 million, 211 thousand, 456.  And now you want that number factorial?  Sheesh.  Just the number of digits in 2^128 factorial is 1 duodecillion, 296 undecillion.  Do we go above - I guess we could.  We could keep going on.



STEVE:  There apparently is a web page, and I think David referred to it in his message.  But it seemed a little bit superfluous.  There's a web page which explains how you can keep going forever.



LEO:  Oh, that's funny.



STEVE:  I mean, there is a - it's a well-known...



LEO:  I'd have to be.  It'd have to be.



STEVE:  Yeah, well, yeah, okay, I guess you're right, there would have to be.  But there's a well-known discipline for just continuing out as many, as far out as you wanted to go.  But he spelled all this out for us, so I thought our listeners would get a kick out of that.  And of course we're doing cryptography, so we're all about big numbers.



LEO:  Big numbers.  But really, scientific notation is just fine.  Keith Stein in College Station, Texas is feeling disconnected:  Steve, I've become increasingly dependent on Skype over the past couple of years.  I know how you feel, Keith.  I work for a company of 50 employees.  We use Skype as a major communications tool, mostly for the texting feature, of all things.  We were notified today by our IT department that the security group has identified Skype as a security risk - oh, please - and they'll now be removing it from all our systems.  I know you use Skype for your podcasts with Leo.  How much, if any, is it a security risk?  I haven't heard anything about a security risk in Skype.



STEVE:  No.  Well, okay.  So let's discuss theoretical security risk because that's really the only thing we can discuss meaningfully.



LEO:  Now, it is an open source.  So there could be all sorts of holes in Skype nobody knows about.



STEVE:  Well, precisely.  So, for example, most typical Skype users are behind NAT routers, our ever-loving NAT router that we preach about here.  I mean, I'd be behind a NAT router even if I only had one computer on the Internet because they only cost $49 now, and you can even find them for less than that.  And as we know, when we were talking about this nightmarish new security vulnerability in the Windows stack, you really want to be behind something other than your computer's own local personal firewall.  So most people behind - I'm sorry.  Most people using Skype are going to be behind NAT routers, which is going to protect them.



On the other hand, as we know and we've discussed before, there's the problem with the so-called Skype Supernode, which is inherently an exposed and accessible Skype client, meaning it's someone running Skype whose machine has a publicly accessible Internet address, you know, 70.326. whatever, I mean, something, you know, or 224. or any of those that you typically see your router's IP being, your router's public IP.  If someone actually has their computer on the 'Net, and they've got Skype running in a supernode node, meaning that it's able to accept incoming packets, and if there were, as you were just saying, Leo, some sort of buffer overrun, not widely known or unpatched problem, then potentially people could look around for those Skype clients.  And as is the case with any server, because that's what a supernode is, a supernode is a server, could use that in order to attack them.



LEO:  So the risk is because Skype bypasses firewalls.  It's bringing stuff in that you can't control.



STEVE:  I would say the risk is that because Skype would - Skype is always trying to be a supernode.



LEO:  Right, they're offering a service, in other words.



STEVE:  Right, well, it - yeah.  Because it would like to be a traffic relay in order to help those who are behind unfriendly NAT routers, where it's unable to do the NAT penetration for you.  In that case, if both users are behind unfriendly NAT routers, then there is no way for Skype Central to negotiate the connection between two clients both behind unfriendly NAT routers.  Skype does not themselves offer a relay service, where for example Google Talk does offer a relay service.  Instead, the Skype system looks around for exposed Skype clients, that is, that are not behind any kind of NAT router, and uses them, without their owners' explicit permission or knowledge, uses them to relay traffic to clients that are behind unfriendly NAT routers.  So if Skype had a security problem, and if it were operating successfully as a supernode, then it would be accessible for attack.  Also, even if normal Skype were behind NAT routers, I mean, it is a peer-to-peer network.  And I think frankly that's probably what the IT...



LEO:  That's the real problem, yeah.



STEVE:  Yes.  I think that, you know, peer-to-peer has gotten such a bad reputation that it may just be the fact that it's a peer-to-peer network that has got the IT department spooked.  They just don't like the idea that you are connecting to another peer.  On the other hand, as we read, or as we know from the beginning of this podcast, 70,000 web servers, actually many of them were belonging to .gov and .edu and .mil networks, they were just taken over because they hadn't been patched in almost two years.  So it's not like a client-server relationship is necessarily any safer to use than a peer-to-peer network.



LEO:  So I guess I'll take it back.  I guess there are risks, and you should be aware of them.  And if your company says don't, you can't.  I wonder if there is, well, of course there's web solutions that don't - they're not peer-to-peer, they don't do NAT traversal.



STEVE:  Well, yeah, in fact I was just wondering whether - I couldn't really tell from Keith's note whether they're using Skype's texting...



LEO:  Sounds like they're using it for an IM client.



STEVE:  Well, that's exactly what I was going to say.  And it sounds like they're using it within their corporate perimeter, in which case there's lots of solutions for just texting the guy two offices down.



LEO:  Well, there's encrypted chat, too, which you probably should use.



STEVE:  Right.



LEO:  Rob in Pennsylvania wants to watch his cores closely:  I thought I heard Leo say on an episode he had a program to monitor each individual core on his quad core machine.  I do.  I just built my first quad core monster.  I thought it would be cool to see how much each core is being used.  But I'm on a Mac, so I'm not going to be able to help you.



STEVE:  Well, so I thought I would ask you to remind us what you use for monitoring your quad cores, and then I will tell everybody what I use for monitoring mine on my Windows machine.



LEO:  Yeah.  So on the Mac I have a little thing called MenuMeters that is a really handy little menu bar item, and it lets you do a lot of things, including CPU.  But you can also watch disks, memory, network usage, and more.  But I just keep the CPUs up.  And it's very helpful, you know, if your system's starting to get bogged down, you can look up and say, oh, I see why.  Something's going on.  Now, you know, Apple just announced its eight core.  So I presume this would work with eight cores, too.  Now, I'm sure there are a lot of choices on the Windows side.



STEVE:  Well, actually the one I use is just the one that's built in, the good old Windows Task Manager.  If you click to the processors tab, it will show you however many windows you've got threads of execution.  That is, even on a single-core, hyperthreaded chip, it'll show you two windows.  And on my quad core machine I get four.  So it's just - it's built into Windows.  It's just the Task Manager, which is easy to bring up.  And one of those tabs will allow you to see what each of your different cores is doing, showing you a little graph, you know, in real time.  And, for example, I recently updated my favorite MPEG compressor to take advantage of all the cores.  And my goodness, does it run fast on that machine.



LEO:  Oh, that makes a big difference.



STEVE:  I mean, it just saturates all four of them, and it just cruises through media for compression purposes.  I mean, that's an example of something that really can take advantage of quad cores.  Most of the time all four of those are sitting around looking at me, saying, okay, you know...



LEO:  Give me something to do.



STEVE:  You got four of us here.



LEO:  Give me something to do.



STEVE:  Yeah.



LEO:  You know, the Windows Vista gadget bar has a CPU monitor.  I imagine it would look at all four processors.  And you said that it comes with Windows.  Of course it comes with the Mac, too.  There's an activity monitor does exactly the same thing.  There are lots of little gadgets that do this.  It is nice.  It's kind of fun.  I was worried that these things are using up cycles, and maybe I shouldn't be running them in the background, but...



STEVE:  I did discover one thing, speaking of that, Leo.  Running it on my laptop, I mean, traditionally I have had the Task Manager, a shortcut to Task Manager, in my startup folder so that it just always runs.  I have it set up to start minimized.  And there's an option to minimize to the tray.  And that way I just have a little cute little rectangle down in my tray that shows me how much the computer's working, which is just, you know, as a techie I find it useful.  The problem is, running it on a laptop, every single time it updates it pings the hard drive.  And it keeps the hard drive from ever shutting down to conserve battery life and to keep the laptop running cool.  So I've learned, oopsie, and that's a habit I need to break for my laptops because I like them to be able to spin down, instead of having some dumb Task Manager sitting there going ping, ping, ping.



LEO:  Wonder why it hits the hard drive?  It doesn't really need to hit the hard drive.



STEVE:  Eh, Windows, you know, what are you going to do?



LEO:  It could keep SpeedStep from kicking in, though.  It might say, oh, I'm never idle.  I'm always busy looking at how busy I am.



STEVE:  I wouldn't be surprised.



LEO:  I'm not idle, I'm busy.  Ryan Couture of Enfield, Connecticut is wondering about more iron in his diet:  Steve and Leo, I've been listening to your show since Episode 1, and I must say you've taught me more about security than I could ever have learned on my own.  Keep up the amazing work.  Thank you.  I had a question about a product that I saw while looking for a flash drive online.  It's the IronKey thumb drive, IronKey.com.  It claims that it uses hardware encryption to protect your files and has a crypto chip that will self-destruct the encryption keys if a physical attack occurs.  It looks good, and I was hoping to have a second opinion to the technology.  I was wondering if you could do a mini review of it, or at least clarify if it's worth the premium.  Thanks again, keep up the good work.



STEVE:  Well, I know what he means when he says "worth the premium" because I bought two of them.  It was - the 4-gig one from Amazon was $138.



LEO:  That's outrageous, yeah.



STEVE:  However, I put Ryan's question here, and I went to Amazon and clicked the "yeah, send it to me" button because I have to find out.  Many, many, many listeners have asked about IronKey.



LEO:  We've shown them on the TV show.  I mean, they were nicely made.



STEVE:  Well, in fact, I clicked - you and I are recording this podcast two days late because you were under the weather when you got back from your vacation.  So I had done all of the production work for the podcast and ordered these IronKeys, the first of which came yesterday.  Then I looked at it, and it's gorgeous looking.  And it's like, okay.  And the reason I bought two is I'm going to open one up.



LEO:  Oh, you did?



STEVE:  Oh, yeah.  Yeah, yeah.  I've got to find out if it, you know, it's like some weird smoke and some - and if I hear "Mission Impossible" music, you know...



LEO:  Right [vocalizing].  This key will self-destruct.



STEVE:  And I'm a little annoyed that the box says "military grade encryption."  It's like, okay, well, what encryption?  Tell me.  So I'm going to do as Ryan and a huge number of listeners asked and check out the IronKey flash drive as thoroughly as I can, and I will report back.



LEO:  Good, good.  Anand K. in Detroit, Michigan discovered something worrisome about Opera's Mini Browser.  Mini Me.  I use it.  He says:  I use a Blackberry Curve and dislike the default browser that comes with it, so I downloaded Opera Mini.  I have, too.  Got it right here on my Curve.



STEVE:  Keep listening, Leo.



LEO:  Tried to run it.  It won't connect to the Internet.  So I had to do some debugging what was going on before I could get it to work.  In this process I realized that Opera Mini actually talks to a transcoder server, which I assume is like a proxy to get its data.  All requests go to this transcoder server.  After searching for documentation on this behavior, I found that it's documented on the Opera Help site.



STEVE:  And we've got the URL also in the show notes.



LEO:  OperaMini.com.  In a nutshell, the mandatory use of this transcoder server makes it impossible to provide end-to-end SSL security for client connections.  Oh.



STEVE:  Uh-huh.



LEO:  So all of my cookies, userIDs, passwords, and other sensitive information I had so far assumed was secure going over SSL was actually going through this proxy server and getting decrypted there.  Even though it's documented, I'm not convinced a browser should do this.  I'm not, either. Hmm.  Opera's site explains why they need to do this at the URL I referenced above.  But I'm not convinced.  They should have left the SSL connection alone, direct, with end-to-end security, and used this optimization for plaintext connections.  Secondly, there's no indication given by the software for the user to know clearly that this is what's happening behind the scenes.  Is this reasonable in your book?  Thoughts on if/how they could have done it differently.  Wow.



STEVE:  Well, this is a perfect example of something we have touched on many times in the last two and a half years, and that is the idea of a proxy server that is terminating the SSL connections itself.  That is, essentially decrypting connections that you thought were encrypted in order to have access to the nonencrypted data that is inside the SSL tunnel.  Now, the reason they're doing this is that this server that the Opera Mini browser connects to is really doing a lot of good work for the user.  It is rewriting pages, web pages on the fly, rewriting JavaScript on the fly, essentially turning web pages that were never designed to be seen on a very small screen on a very lightweight and lower powered browser, making them work.



And so if they didn't do that, that is, if they did pass SSL through end to end, first of all, your browser, that is, that you're holding in your hand, running on presumably a lower power chip, it would need to be able to do SSL, which is a little compute intensive, although I would argue these days that could be handled easily enough.  And they would then no longer be able to perform this filtering which apparently the Opera Mini Browser depends upon.  On their security page where they address this, they're not quite as upfront as I wish they were.  I mean, Anand K., who's a Security Now! listener, he's obviously astute enough to sort of read between the lines.



LEO:  I know.  I didn't.  I didn't know, and I've been using this.



STEVE:  Yeah, you have to read between the lines to get what it is they're doing.



LEO:  I'm mad.



STEVE:  And, yes, I know, I mean, this is not good for it to be less clear for people.  Apparently they're providing some sort of tunnel encryption of their own, not SSL.  But that, you know, so your data is protected itself going to them.  But then it's completely open.  I mean, it's as though you're trusting the Opera Mini server, proxy server.  Everything you do, your passwords, your secure login, I mean, literally your username and login that you thought was over SSL...



LEO:  Unbelievable.



STEVE:  ...is unencrypted.  And finally, at the end of this FAQ page, someone asks the hypothetical question, well, what if I don't like that?  And their answer is, well, then, you can't use Opera Mini.  Go use, you know, the regular Opera non-mini browser, sorry.  And so, I mean, I don't really have an opinion one way or the other, although I don't think I'm going to use it.



LEO:  I just deleted it.  I'm kind of stunned.



STEVE:  So that's annoying.  And I really thank Anand for the...



LEO:  Yeah.  I would not have known.  I'm looking at their website right now.  It doesn't say that it's doing that. 



STEVE:  No.  I mean, again, in their FAQ it says, is there any end-to-end security between my handset and, for example, PayPal.com or my bank?  Okay, first word, no.



LEO:  First word, bye.



STEVE:  If you need full end-to-end encryption, you should use a full web browser such as Opera Mobile.  Opera Mini users a transcoder server, as they call it, to translate HTML, CSS, JavaScript into a more compact format.  It will also shrink any images to fit the screen of your handset.  This translation step makes Opera Mini fast, small, and also very cheap to use.  To be able to do this translation the Opera Mini server needs to have access to the unencrypted version of the web page.  Therefore, no end-to-end encryption between the client and the remote web server is possible.



LEO:  You know, I understand why they're doing that.  But they really should say - that should be very clear on the front page.  Wow.  I haven't used it much, so I feel all right.  But...



STEVE:  For what it's worth, I mean, they say - another of their made-up questions.  Can Opera software, Opera Software Company, see my passwords and credit card numbers in cleartext?  What is the encryption good for, then?  The answer, the encryption is introduced to protect the communication from any third party between the client, the browser on your handset, and the Opera Mini transcoder server, meaning - so they're talking about the encryption between your handset and Opera's server.  If you do not trust Opera software, make sure - and I'll say, and everyone who works for Opera software - make sure you do not use our application to enter any kind of sensitive information.  It's like, okay.  As you said, Leo, bye bye.



LEO:  I deleted it.  Ron Bailey in Dallas, Texas has got to have his options outlined:  Steve, in Episode 123 of Security Now!, during the Jungle Disk discussion, you mentioned that you keep everything in outlines.  I'm an avid outliner, too, and I'm always on the lookout for new, better ways to work these things.  How do you manage your outlines?  Do you use software?  Is it a text?  I gots to know, says Ron.



STEVE:  Well, ever since - what was the very - was the very first one, ThinkTank, I think.



LEO:  ThinkTank, yeah.



STEVE:  I'm sure you remember that, Leo.



LEO:  Oh, yeah, great program.



STEVE:  I think it was on the Apple II.  And it survived a while.  It got ported to the PC.



LEO:  I think that was Dave Winer's original company.



STEVE:  I believe that that's exactly right.  And then there was someone named John Friend, he did one called GrandView.  And Symantec bought them at one point.  GrandView was another great - and these were text-based outliners.  That is to say they ran, you know, back in the DOS era.  And I actually still have GrandView here, and it works, although it's a little funky, and I've pretty much moved over into GUI land.  Then there was something really wacky for a while called Ecco, E-c-c-o.



LEO:  Oh, I remember Ecco, yeah.



STEVE:  Yeah, which was - I don't think anybody except the authors knew how that program worked.



LEO:  That was really freeform, shall we say.



STEVE:  It was so powerful that you'd just say, okay, I guess I'm much more stupid than I thought I was.  I mean, it was intimidating.  But it had some really neat groupware features, well before I think that term was even coined.  Anyway, today I'm using something called ThoughtManager Desktop.  ThoughtManager began on the Palm.  It was a Palm app.  And I do use it there, although I find that my Palm is much more useful for reference, for like reading from, than trying to type into.  And of course that's the advantage, the Palm is mostly like if you have your contacts, your contact book there, you just give it a few keystrokes, and it finds what you're looking for.  So it's used more as a reference device.  But they did ThoughtManager Desktop in order to create a Windows-based companion, much like the Palm Desktop, where you're able to synchronize your contacts and the data in your Palm.  And this works.  Although ThoughtManager Desktop is so good, I just use it standalone.



And every maybe year or so I go out, and I look around at all the outliners that are available.  And in fact outlining is so popular there are sites that are just about outlining.  And I always find the same site when I Google "Windows-based outlining" or "outlining" or something.  And there are different ways for outliners to work.  Some of them have two panes; some of them have three panes.  Anyway, what ends up happening is I always am reminded how glad I am about ThoughtManager Desktop.  So I would encourage people who are interested in outlining, I mean, I'm literally sitting here, Leo, looking at an outline for Security Now! 126.  And I have outlines going all the way back to #1.



LEO:  You're kidding.  Wow.



STEVE:  No, I mean, and I have an outline on antispam email, article ideas, Bam-Bam work, I mean, literally I have 43 outlines that I'm - this is the way I run my life.



LEO:  That sounds like you use it as a List Manager more than anything else.



STEVE:  I guess I do, except that I've got indentation.  And so like I've got an Errata line, and then Weekly Security Update, and then Q&A.  And then underneath those are the sub-subjects.  And underneath them are little things I don't want to forget to mention.  And I'll tell you, for example, when I'm brainstorming a new product, I think I've talked about Crypto Link is the next thing I'm going to do, a cryptographic communications product.  I've got outlines, I mean, everything about Crypto Link is in a ThoughtManager outline because, as I think of things, I just put it in.  And I just want to know that I'm not going to forget it.  It'll be there.  I've captured it.



And then I literally use, well, the thing that's cool about computer outlining is you can move things around.  You use the ALT key and the arrows to, like, grab whole chunks and all their subsidiaries and, like, move them around to somewhere else.  So you're able to take, you know, just random brainstorming stuff.  And as you begin to see, oh, wait, this is like this, and that's kind of like that, we'll put them together, and we'll give them a heading.  And so, I mean, I just - I'm a - oh, and of course the ability to open and collapse the levels of outline that are being shown.  So you're able to easily see an overview and then go, okay, now, what's under this?  And so you click it to open it, very much like a - sort of like a Windows folder tree.  Anyway, it's just a spectacularly useful way, or something useful for a PC to do, you know, much like word processing and database and spreadsheets.  Outlining is an application that's always been near the top of my list of what I'm glad someone figured out they could do on a computer.



LEO:  Wow.  I'm so impressed.  I thought I knew everything about you.  I haven't seen these little lists that you have all around you.



STEVE:  Next time we're together in Vancouver I'll show you.  I mean, I carry them with me.  And in fact, that's what I'm using through Jungle Disk because - so I've got my whole outline folder up on Amazon, accessible from any machine where I happen to be, using Jungle Disk to make the connection to Amazon in the sky.



LEO:  Now, that's a good idea.  So you always have it available.



STEVE:  Right.



LEO:  Well, Steve, we have done 12.  We've wrapped them up.  It's been a long episode.  We had a lot of catching up to do, some big security news.  And I think you've earned yourself a break for the week.



STEVE:  Well, we'll be back with another episode...



LEO:  On time.



STEVE:  ...next Thursday.



LEO:  Next Thursday.



STEVE:  On time.



LEO:  Although we have a little, you know, Macworld Expo, we're up against the clock on that one.  So we'll have to figure out how to do that.  I might have to do that earlier in the morning with you.  We'll figure it out.



STEVE:  We always figure it out, Leo.  I'm glad you're feeling better.  And I told Elaine not to worry about the timing of the transcript.  I imagine we'll put this up as soon as you...



LEO:  I'll put it up right away.



STEVE:  As you're able to do it.  And then so the transcripts will follow, you know, whenever Elaine is able to catch up with us.



LEO:  That's where you go for the transcripts, GRC.com.  That's Steve's site.  GRC.com/securitynow has show notes.  As he said, he'll have links there to all the stuff we've  mentioned.  I also will have the links in the RSS feed for the show and on the website.  And you can also go to GRC.com for 16KB versions, if you want the small little versions of the file.  And the transcripts, when Elaine gets around to this one she'll have that one up.  But all 125 episodes are up there already.  And of course go there for GRC's fabulous -  Steve's fabulous SpinRite, the world's best hard drive maintenance and recovery utility.  SpinRite at GRC.com.  Steve, have a great week.



STEVE:  Thank you so much, Leo.  It's great to talk to you again.  Welcome back from your vacation.  And we'll kick off next week's episode, as we're going to from now on, with any important security events since we last talked to our listeners.



LEO:  Excellent news.  All right, Steve, take care.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#127

DATE:		January 17, 2008

TITLE:		Corporate Security

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-127.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events, then use a listener's story of his organization's security challenges to set the stage for their discussion of the types of challenges corporations face in attempting to provide a secure computing environment.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 127 for January 17, 2008:  Securing the Enterprise.  Security Now! is brought to you by listeners like you.  Thanks for your support.



Time for Security Now!.  I'm Leo Laporte, feeling a little bit better.  Steve Gibson is, as always, the peak of health because he never leaves his Irvine security lab.



STEVE GIBSON:  That's right, my antivirus, disinfected tower of health.



LEO:  I tell you, I'm going to start wearing surgical masks on planes, I think.  I really - this is the worst.  Although, you know, I don't know if it's consolation, but I've talked to so many people who've had terrible colds this year.  Whatever that cold is that's going around is a doozy. Don't get it.



STEVE:  I'm going to work on that.



LEO:  That would be my advice to you.  Stay away from it.  So we had a fun time last week answering a lot of questions.  What are we going to do this week to top that?



STEVE:  Well, actually one listener wrote a long sort of, well, explanation about his company's problems with enforcing security policy.  And I really liked it.  And it sort of brought up the whole issue to me that we haven't ever really discussed before of the challenges of corporate IT security policy and enforcement, the inherent tension between the security staff, you know, IT and employees.  So I just sort of wanted to talk about some of the things that I think that both employees face and corporations face in this battle to secure a typically very heterogeneous, complex, and more complex every day environment.



LEO:  Yeah.  It is, it's a real - I do not envy our IT pro friends because they've got a real task.  Even worse, I mean, imagine how hard it is - it's bad enough you have to lock your own system down - locking down the systems of hundreds of thousands of users, all of whom have their own ideas about what they want to do on that computer.



STEVE:  Exactly.



LEO:  But before we do that, is there any news in the security...



STEVE:  Oh, there was a bunch of stuff this week that was really sort of interesting and fun.  Last week we talked about, you may remember, Master Boot Record, that is to say, MBR rootkits.  Okay?  Last week they were theory.  This week they are in the wild.



LEO:  Wow, that was fast.



STEVE:  It turns out that there are four vulnerabilities which are known and have been patched.  Microsoft has a JVM, a Java Virtual Machine byte-verify vulnerability; a problem with MDAP, which is one of their database APIs; a different problem with Internet Explorer's Vector Markup Language, the VML vulnerability; and a problem with XML core services.  Those four different problems are being used to install, currently install, a new set of Master Boot Record rootkits.  These have been found in the wild.  So when someone visits a hostile web page - and we talked about before, this is sort of pretty much the typical way bad stuff now gets in your machine is that one way or another you are tricked into going somewhere bad.  And a known vulnerability, hopefully a known vulnerability, which hopefully you've patched, will try to do something bad to you.



Again, if you're current, and if Microsoft knows about this - or I don't mean to just blame Microsoft.  I mean, there are in fact, for example, there's now proof-of-concept code out for a new QuickTime remote code execution vulnerability that affects both Mac and Windows.  Now, of course, it would have to be different code in order to run in a Mac than would run in Windows.  So the same exploit of that vulnerability could not be used across both platforms.  But both of them are vulnerable because they both are using QuickTime.  And this was something that came out with zero day, so Apple wasn't even aware that this existed when this thing first showed up.  So this is typically what's happening.



The really scary thing is, being a rootkit, this thing gets control of and patches the OS before it loads.  That is, in this case it is a Windows-only MBR rootkit.  And it makes itself undetectable by antivirus software.  So it's a rootkit in the pure sense of getting in and modifying the kernel prior to loading in order to protect itself.



LEO:  Now, the anti-rootkit programs like RootkitRevealer from Mark Russinovich, BlackLight from Frisk, those would work against something like this; right?



STEVE:  I don't know at this point.  This is so new that not much research has been done.  I haven't seen this myself, and I haven't read much about it except that these things are now in the wild.  And what's sort of interesting, too, is that this is what we faced 15 years ago with the very first viruses.  I mean, when people were using so-called "sneakernet" to - by mistake you'd get floppies that would be infected, and you'd stick a floppy in someone's computer.  And when you accessed it, it would install itself over on that machine's hard drive.  I mean, this is - we've seen in the old days Master Boot Record viruses that sort of were all in fashion for a while, then went away.  And as security has tightened up everywhere else, this is one little hole that has never been patched in our newer machines.  And so it's been sort of rediscovered as, hey, look, we can still infect the MBR, and that'll give us control before the OS boots.  And using state-of-the-art techniques now to analyze code, it's much easier to patch someone on the fly and modify the kernel as it comes up.



LEO:  Right.  A traditional rootkit would get run at some point during boot-up, just not so early.



STEVE:  Exactly.  Normally, if, for example, it installs itself as a device driver, a boot-time device driver, which the OS would unwittingly load, and then being in the kernel as device drivers are, gives that thing a lot of control.  They would then go about patching the kernel in order to obscure its own presence.



LEO:  So by loading in the Master Boot Record, what is the advantage?



STEVE:  Well, the advantage is that literally nothing is running.  That is, the way...



LEO:  No security software, nothing.



STEVE:  Well, literally yes, nothing.



LEO:  Not even Windows.



STEVE:  That first sector is loaded into raw memory.  And in fact the system is not even in protected mode.  It's in real mode, which is the way this code runs.  So there aren't even protection services available from the chipset at that point.  I mean, it is literally - the BIOS has run at that point.  But then the system's in real mode.  That one sector, that 512 bytes, is copied into a location in low memory.  Then that sector is jumped into, that is, that chunk of memory is jumped into and executed.  That normally then goes about finding the beginning sectors of the bootable partition, which it then loads into memory and then runs.  In this case, it loads more of itself, that is, more of the first track of the hard drive where this thing lives in order to get conscious enough to do the kind of damage that it needs to.  It then goes out and patches, on the fly patches the operating system, which then boots, although it's already been infected.



So it's spooky stuff.  No doubt the AV people will get on this.  Microsoft will get on this because you are running in Windows when you are caught by one of these Microsoft vulnerabilities, which then allows the Windows executing code to install that Master Boot Record code on the hard drive.  So that's the hole that next needs to get plugged.



LEO:  Right, right.  That's when security software's running, and you can watch for that kind of thing.



STEVE:  Right.  Also last week we talked about how 70,000-plus sites had been infected by malware recently.  That is, it was JavaScript that was being installed, taking advantage of some SQL vulnerabilities in order to compromise websites with exactly this kind of malicious software.  What's just turned up recently is a new twist on this.  The way they knew it was 70,000 is that this malicious JavaScript was appearing on web pages of sites that were being dynamically generated.  You know, basically there was an SQL database on the backend that was serving pages dynamically.  That got infected, that is, the SQL tables got infected, which caused it to put this malicious JavaScript on these pages.  Well, the way people knew, for example, it was 70,000 was that they simply Googled some of the malicious JavaScript, and Google had already been out there browsing around, dutifully cataloging all these pages, so it was easy to find.  The newest twist, which has just appeared, is there is now polymorphic JavaScript that has been created which renames itself and reorganizes itself and is not broadly searchable in the way that static JavaScript can be.



LEO:  It's different on every page.



STEVE:  Exactly.  So naturally, I mean, what we're seeing here in the standard sort of cat-and-mouse game between malware and antimalware forces, is that the bad guys have said, okay, we don't want you to know that it's 70,000 sites.  In fact, we don't want you to be able to find us at all.  So what they've done is they've just upped the ante again by making their own malicious script modify itself so that you can't use a search in order to quickly find it all, notify those websites, and get this stuff removed.  So this is a serious increase in escalation of this problem.  Also in this week's news - you're going to get a kick out of this one, Leo.  The gray hat hackers have been zeroing in on taking advantage of UPnP-enabled routers.



LEO:  Ah ha.  You've been warning against UPnP for some time now.



STEVE:  From, yes, from the first moment this bad idea appeared I've been saying, and I know that you've been repeating, for example, in your various other venues, the danger, the inherent danger of leaving UPnP enabled on routers.  There are now some hacker sites that have succeeded in using, first, cross-site scripting; and, more recently, known vulnerabilities in Flash v8 or later.  In other words, they're able to take Flash content, and Flash v8 has become so powerful, there is a navigate-to-URL function and a URL request object that can be used to generate local LAN traffic.  That's all you need in order to talk to a router that has Universal Plug and Play enabled and use the UPnP technology to rewrite the DNS server or open holes through the router to allow ports to be exposed to the outside.  All of that's been done.  So we don't yet have any malicious - we don't know yet that there is any malicious code which is doing this.



But this is what, you know, I've been predicting would happen from the beginning because it's just - it's too powerful, and there's no security model associated with this first version of Universal Plug and Play that all routers, now all consumer routers have, and which most have, unfortunately, enabled by default.  So again, this is different than the Windows defect which was discovered a long time ago and for which I created the Unplug n' Pray freeware.  What that did was, there was a remote code execution vulnerability in the original Windows XP Universal Plug and Play service that was running on Windows by default.  I was arguing that - and of course we had no XP firewall on by default.  And it wasn't until Service Pack 2 of XP that the Windows XP firewall was running.  So I argued that there was no reason to have that server running.  And so my little Unplug n' Pray utility just disables, it stops and disables the SSDP service, which is the Simple Service Discovery Protocol, in Windows XP.



Well, that's different from routers, that is, the NAT routers that everyone is using now, hopefully everyone, to protect their borders and to allow them to share a single IP, a single public IP among multiple machines in their own LAN.  Most of the routers have this Universal Plug and Play technology, the idea being that it solves the problem of NAT traversal simply by opening ports through the router to allow, hopefully, expected and solicited traffic to come back in through the router.  The problem is, there's no security model for that.  That is to say, any packets that are generated on the LAN inside can discover the presence of Universal Plug and Play services and talk to them and cause them to do things.



So I would once again say to all of our listeners to take this seriously.  What this means is that at some point in the future, as we've been predicting, there will be malware which, once it gets on your machine, reconfigures your router behind your back to do things you don't want to do, or don't want it to do.  For example, changing your DNS to something fraudulent means that all of the machines you've got will be going to some bogus DNS server to pick up the IPs of common URLs, which is, I mean, that's everything that phishing sites want.  I mean, it's like the holy grail of redirecting your computers to malicious spoofing sites.  So we're getting closer to it.



LEO:  So the best thing to do is go into your router and disable UPnP.



STEVE:  Yes, yes.



LEO:  I mean, you've been saying that for some time.



STEVE:  Exactly.  Now, there are going to be some side effects to it.



LEO:  You know what I hear from people a lot is Xbox Live.   Unfortunately, Xbox Live has this little feature where you can check - I forgot what they call it.  But it's definitely a euphemism.  But you could check your accessibility to other players.



STEVE:  Right.  And I think there are, like, three grades of accessibility.  It turns out...



LEO:  They encourage you, basically, to turn on UPnP.



STEVE:  Unfortunately they do.  It turns out, though, that there is a very simple set of static ports which you could map through.  You could disable Universal Plug and Play, reboot your router so that you flush any existing mappings that may have already been set up.  Then you can do your own static port forwarding of just a couple ports.  And it's not many.  It might even only be one.  But I remember that it's at the most just a few.  Map them through to the IP of your Xbox, and then you're okay.  Then it's happy, it's completely on the 'Net, it's fully game enabled; yet you haven't had to turn Universal Plug and Play on in your router in order to get there.



LEO:  It's unfortunate because most people who want to play Xbox aren't necessarily that sophisticated.



STEVE:  Exactly.



LEO:  It is two ports.  It's UDP 88 and 3074 on UDP and TCP.  I'll put a link in our show notes for the settings and Microsoft's tech note on how to do that, for people who want to do that.  Maybe help your friends.  Because unfortunately what's happening is a lot of kids are basically disabling their router's security so they could play Xbox Live games with their friends.  It's kind of the problem.



STEVE:  Okay.  Alex Eckelberry, our friend at Sunbelt Software, reported in his blog and has some nice screenshots of, get this, a new trojan.  It's called the Delf.ctk trojan.  When you get your computer infected with this thing, it puts up a screen that looks convincingly like Microsoft's Security Center, informing you that - it says, quote:  "Error.  Browser's security and anti-adware software component license exprited."  Got their little typo there.  It meant to say "expired," but it got a couple letters wrong, "exprited."  It says...



LEO:  That's what you always look for, by the way, is grammatical and spelling errors.



STEVE:  Exactly.  Well, yes.  Then it says:  "Surfing porn, adult and some other kind of sites you like without this software is dangerous and threatens with infection of your computer by harmful viruses, adware, spyware, et cetera."



LEO:  And its recommendation would be...



STEVE:  Oh, first of all, it takes over your machine, locks it up.  There's nothing you can do.  It requires that you make a call to a 900 number.



LEO:  Oh, dear.



STEVE:  Which costs $35.  So basically this is a $35 phone call extortion trojan.



LEO:  Oh, my goodness.



STEVE:  And one of the - there are several numbers it gives.  One of them, for example, is a number that ends up going to the West African nation of Cameroon, where there is a call center.  You have to enter a PIN, I mean, the screens are, you know, obviously not grammatically very convincing.  But the user has no choice.  I mean, literally you have to call...



LEO:  There must be something you can do.  You don't have to call that number, do you?



STEVE:  Well, Alex says that your machine is locked up.  And the only way to get this thing to leave you alone is to call the number, you enter some PINs that come up on the screen in order to - which costs $35 - in order to get your computer back.



LEO:  That's appalling.  That is just appalling.  Now, you would get - this is a trojan.  So you get it in your email and you run it, or you get it by going to a website that's been compromised, and you haven't done your updates, things like that.



STEVE:  Yup.  It gets onto your machine, and then it says, okay, we're going to charge you $35 to have your computer back.



LEO:  Now, if you have an antivirus running, and you accidentally open this file, will it still infect you?



STEVE:  I don't know whether AV is yet up to speed.  This apparently is pretty new.  So certainly, again, standard practice is keep your AV patterns up to date.



LEO:  Sure.  But even then, don't open attachments.



STEVE:  Yup.  There was another little blurb that I wanted to mention.  I was just setting up a brand new little HP machine.  I got a couple little HP Pavilions just because they were sort of small and cute, and they're nice for various single purposes.  I was shocked by the amount of what now the industry is beginning to call "crapware" that was preinstalled on this thing.  I mean, it was unbelievable.  Well, the point is that it turns out that there is now the third in a series of zero-day remote code execution flaws in the preinstalled HP software.  So...



LEO:  Oh, my god.



STEVE:  Yeah.  So not only is this stuff annoying, all this demoware and junk that you didn't ask for, but the problem is that it's got security flaws also which are generally much less maintained than the stuff from Microsoft.  So I did have an experience also with both a Dell laptop and a Dell desktop recently.  And I was holding my breath when I booted them the first time, thinking, oh, god, you know, how much junk is there going to be on it?  And the answer was, like, none.



LEO:  Well, Dell has this new thing where you can order it without the crapware.



STEVE:  And, yes, on their site they're even boasting that there is no demoware installed on these machines.  And I thought, well, that's, I mean, it has been my experience with two recent Dell machines that they're no longer loaded with all this junk that you don't want.



LEO:  They're listening to their customers.  Do you know what the HP demo is that has this exploit in it?



STEVE:  It is HP's Remote System Update.



LEO:  Oh, good.  Now, presumably HP will patch this.



STEVE:  They have before.  Three times this has happened.  And there's now another instance of it.



LEO:  Good lord.



STEVE:  So, yes, and so it's not just a matter of this stuff being unwanted.  It's also insecure.



LEO:  Dangerous, yeah.



STEVE:  Okay.  And finally, this is just too bizarre, but I had to share this with our listeners.  Digital picture frames are now infecting PCs with malware.



LEO:  You're just full of good news today.



STEVE:  There have been multiple reports of people using a USB key to transfer photos to digital picture frames, which in turn, the firmware on the frames installs PC malware onto their USB drives, which then, when plugged back into the PC, take over the PC.



LEO:  Wow.



STEVE:  And these are brand new, from the factory, digital picture frames.



LEO:  Which manufacturer?



STEVE:  I don't have any names.



LEO:  Geez.  All right.



STEVE:  But because there have been multiple reports of picture frames doing this.  In some cases, some of them were resold.  But it has been also confirmed in brand new digital picture frames that there is malware installed on them that then jumps to the USB storage and then over to a PC.



LEO:  Wow.  This is from Security Focus, this story.  So I'll put a link in the show notes to this, as well.



STEVE:  Yeah, and I think Computer World also reported that, as well.  So it's just like, oh, my god.  I mean, this is the law and the rule that we learn about security is, if it can be done, it will be done.  This is what led me to believe Universal Plug and Play from the first moment I saw it was a bad idea.  And similarly, the MBR rootkit is another example of that.  It's just...



LEO:  We're going to see more of this, too, because, you know, these digital picture frames are a perfect example.  We are now surrounding ourselves in our lives with little computers executing code. 



STEVE:  Right.



LEO:  And they talk to everything.  You know, that's scary.



STEVE:  Yup.  Well, I did want to share a short and sort of fun SpinRite anecdote with our listeners.  This is from a guy named Charles Hayes, who wrote to us, oh, on the 12th, so just five days ago.  He says, "I purchased SpinRite around May or June of 2006..."  So that was about a year and a half ago.  He says, "...and it saved me from reinstalling Windows.  My computer would reboot every time I clicked on one particular email.  Also when I tried to compress the folders in email it would reboot.  And I could not run Windows Defrag.  I remembered about SpinRite on the Screensavers..."  You know, your old show on Tech TV, Leo.  And he said, "...and I purchased it.  I ran it, and it fixed the problem completely."  So that's a year and a half ago.



And he says, "A few days ago my computer would reboot on its own, usually within 30 minutes to an hour after I logged in.  I tried different memory, and that didn't help.  I thought I might have to buy another motherboard.  But I ran SpinRite again, and it found one area with unrecoverable data and repaired it."  He says, "I figured that may be the problem.  And sure enough, when I rebooted back into Windows, it's been running perfectly ever since."  He says, "This product has been a lifesaver for me more than once.  I'll just have to start running it more often.  Thanks."



And that really is the lesson that I wanted to convey in this little note is, you know, Charles had it, it fixed his problem a year and a half ago.  And another problem obviously occurred on that same drive.  And at that point it was really causing him trouble.  Clearly, had he run SpinRite every six months, I mean, I recognize it takes a long time to run because it's doing a lot of work on drives which have become massive.  So it's not something convenient to do weekly.  But every six months, for example, would have prevented this problem from occurring, and it would have probably been able to recover whatever data was in that sector.  And I'm not sure that it wasn't able to, or perhaps did a partial recovery.  But again, you really don't want to let too much time go by.  So if nothing else, I would remind current SpinRite owners that they can get some benefit from running it even when it hasn't - when it's no longer a matter of life and death.



LEO:  Prophylactically, as we say.



STEVE:  Yes, exactly.



LEO:  All right, let's hear this letter from your IT professional.



STEVE:  Yes, this is Dennis in Halifax, Nova Scotia.  He said, "Hi, Steve.  I work on a help desk in a government department in Nova Scotia, Canada.  Including our department and other agencies, we support about a thousand users."  So he's on a help desk in a government agency with a thousand users that he supports with his help desk.  He says, "The problem I have is that no one here seems to take electronic records, computer security, or data integrity at all seriously.  The data we deal with is extremely sensitive and includes a lot of personal data - medical records, health information, and much more.  Not only do we have problems with computer-related security, but also with physical security.  The building I work in is really a joke.  We have a security person down on one of the main floors, and the doors all have key cards.  But during normal business hours all it takes is a walk around the back of the building to get to the floor below, then a short ride in the elevator to get you to any floor in the building.  Once on any given floor, there's a keypad on each door.  But the code has only been changed once in the past few years."



LEO:  So everybody who ever worked there knows it.



STEVE:  And he said, "Every employee and former employee knows the code to almost every door because it's the same for each floor.  Oh, and almost every employee will let just about anyone standing by the door in without any question, whether they recognize them or not."



LEO:  What do they call that, tailgating?



STEVE:  Exactly, tailgating.  And in fact it's funny because when I was setting up my access to Level 3 I was specifically told, you scan your card, you stick hand in the biometric hand scanner, and the door unlocks.  And they said, we're sorry, but do not let somebody else who approaches you in.  Apologize to them and say, I'm sure you understand, I can't let you in.  Close the door and then make them go through the same process.  So, yeah, but again, it's hard to enforce that social policy.



LEO:  It is.  And Canadians are friendly.  That's your problem right there.  They're nice guys.



STEVE:  Exactly.  He says, "Recently a new policy came down from our CIO's office stating some key security points.  The main ones were:  Laptops must have encryption; Blackberries must be password protected; we're not allowed to use any means, parens, (electronic or otherwise), to remember passwords; we must also..."



LEO:  Really.  They can't use, like, RoboForm or some other...



STEVE:  Apparently no electronic or otherwise means to remember passwords.  You just have to memorize them.  Of course we know the problem with that is then people will choose easily guessable passwords.  He says, "We also have a draft, but considered the working copy, Acceptable Use Policy - AUP - that prohibits the use of peer-to-peer software such as LimeWire, BitTorrent, et cetera..."



LEO:  Or Skype, as we were talking about last week.



STEVE:  Exactly.  "This policy also prohibits the use of any instant messaging software such as MSN, ICQ, AIM, et cetera, because they are supposedly not secure."  He says, "The problem with this new policy and AUP is that no one is willing to enforce it.  I brought it up at a staff meeting with our team, including the manager, and was basically shot down and told that we can't do what the policy says we need to do.  Does this seem wrong?  I mean, the policy is not something that I would consider to be at our discretion to enforce.  I assume, maybe incorrectly, that a policy is above us all, especially when signed off by the highest ranking person in our organization.



"I suggested in this staff meeting that we really should look at whole-disk encryption because more and more users have been purchasing notebooks and are traveling all over the world with them.  I was told there was not enough information in this policy for us to know what we need to do.  I agree with that because it didn't mention any level of encryption or which methods should be used.  But it really wouldn't be hard to find out by asking the right questions.  I'm guessing that that part might be left enough at our discretion since the people who created the policies are not overly technical.



"The last sore point I have is that our organization doesn't even have a data classification scheme.  We have no way of telling how confidential or public our documents, files, and records are.  I believe this would be the first step we need to take in order to help provide the groundwork needed to base the rest of our security process and procedures on.  The whole thing is very frustrating because I believe I have a decent grasp of security concepts.  But since I am just a low-level help desk staffer, the higher-ups don't pay any attention to what I have to say.  Do you have any advice on how to help convince my organization that security is important?  P.S.: My apologies for writing such a long message.  Thanks, Dennis."



LEO:  Well, but he raised so many interesting questions.



STEVE:  Yes.  I just - I really - I liked his note because, I mean, you can imagine how many people are sitting around feeling a similar level of frustration.  And, I mean, we sort of - we've talked around these things in many of our podcasts.  We've never really talked about the challenge that corporate IT faces when it comes to enforcing security policies.



LEO:  Well, it's especially difficult when you're a government agency because you also have - and this is not just true of government agencies, but healthcare agencies.  A lot of companies have a higher responsibility for security even than just a normal enterprise.



STEVE:  I have a really good buddy who spends a lot of time working with corporate - working in corporate environments, generally small companies, trying to help them with their security and interacting with the employees.  And one of the things that I think is a fundamental sort of like root cause of a lot of the problems is that the computers that people use in their corporate environment are almost universally exactly like the machines they use at home.



LEO:  Right.  Why can't I do the same things I do at home?



STEVE:  Exactly.  Or they've got - they're like, well, wait a minute, my eight year old is able to use this machine and doesn't seem to have any problems.  Why can't I do on my work machine the same things I do at home?



LEO:  I think it's a communications issue, too.  I think, if you're going to insist on an onerous, what's a seemingly onerous policy, you've got to be very clear and spend a lot of time with your employees explaining why it's necessary and what the risks are.  I think a lot of it is people just underestimate the need for security.



STEVE:  Well, yes, and we hear enough now that people are receiving email, clicking on a link, and getting malware installed on their machines just by doing that.  So of course then corporations say, okay, we're not going to allow attachments.  And so then people are upset because it's like, okay, wait a minute, but what about good attachments?  And the IT policy is, well, there's no way to really be sure that it's a good attachment, so we're just going to say no attachments.



LEO:  Right.  It's very difficult.  And I don't envy the guys who have to do it.  And I also am sympathetic with employees because imagine being the IT guy at Tech TV, where you have all of these tech-savvy people who are not easily going to go along with anything you say and who are going to try to get around anything you do.



STEVE:  And that's a very good point, Leo.  It's one that I had on my little outline for things I wanted to remember to mention.  And that is exactly that, because computers are so ubiquitous now, to some degree even the common users feel like I know what I'm doing.  I have one at home.  My eight year old has one.  I've got a laptop.  Who are you to tell me what I can and cannot do?  Because, I mean, everyone to some degree feels like they're something of an expert.



It used to be, remember in the mainframe days you literally had the computer on an elevated floor in an air-conditioned area.  And, you know, technicians walked around in white lab coats.  And there was this sense of, oh, you know, I don't know what all that is.  But, whoa, that seems very impressive.   Well, nothing is impressive now seeming about a work machine.  It looks like just the same machine people have at home.  And so I think the sense that employees know all that they need to know about their work machines, just exactly as you said, further creates tension in the workplace.



LEO:  Well, and that's where, as much work as it is, additional work as it is, a really explicit policy that - and IT pros who take the time to explain why this is being implemented might help.  I think employees, you know, they want to be good employees.  They don't want to cause unnecessary trouble.  They just don't understand what the issues are.



STEVE:  Well, one of the things that I have suggested, and we've talked about it, we touched on it briefly in the past under the issue of corporate monitoring of employee machines, is to literally, I mean, Draconian as it seems, put a couple-line message on the bezel of the display monitor on every single company machine that says, "This computer, which is property of XYZ Corporation, is subject to continuous monitoring and filtering of all activity; this is not your property," or something to that effect.  I'd leave off the end part.  But the idea being, it's like, look, make it very clear to users that this is not their property.



And then the other thing that I think makes sense, sort of as a safety valve, is a company could certainly set up, like, a break room or sort of the equivalent of an Internet caf where employees could take their laptops and plug into a secure and unfiltered, unrestricted network connection, the idea being that you have a break room or a coffee room or something, and IT could easily set up a router there that is not in the corporate network, that has no connection to the rest of the network in any of the machines or resources within the corporation, but just to allow users who want to check their personal email, who want to be able to use a laptop that they bring to work, allow them sort of a safety valve in order to access the network in a safe way.



LEO:  It's that kind of creative thinking it's going to take, I think.  You can't just be authoritarian and say, no, this is the policy, you know, shut up, you're an employee, do what we say.  Because unfortunately, as much as you'd like to say that, I'm sure, employees will find a way around it.  You've got to enlist their help.  You've got to enlist their support.



STEVE:  And we've also sort of talked about, very much along these lines, how, for example, Hamachi could be used in a peer-to-peer fashion in order to circumvent some employee protections to allow people to potentially get themselves in trouble.



LEO:  Yeah, we deal with that all the time.  I certainly do on the radio show because all the time I'll get employees calling me, saying I'd like to circumvent these restrictions.



STEVE:  I mean, literally asking you how to get around these problems.



LEO:  And, you know, I'm torn because, on the one hand, I'm on the side of users, and I want to say, yeah, you can.  But on the other hand, and I usually try to do this, I also need to explain that, first of all, the law is in your employer's favor, the law is very clear, courts have always been very clear that employers own the hardware, they own the software, and they can totally control what you do when you're at work.  That's their property.  So you don't have any rights when it comes to that.  And furthermore, you could be risking your job if you start to try to get around these things.  So I usually try to tell people that.  But I sympathize, too, as a user.  I'm no longer a user.  I'm my own IT guy.  But as a user in the old days I often chafed at those restrictions.



STEVE:  Yeah, well, and again, I think if there was some alternative that was reasonable, some way for example that, I mean, a corporate-sponsored solution like giving people a safe place that they can plug their laptops in that's protected.  And it's like, okay, look, during the day this is what you do on the corporate machine.  And if you want to take a break to check your email, lord knows what you want to do, but bring your own machine, your own laptop, and we will give you an isolated network that you're able to do this with.



LEO:  Now, what about employees who have company laptops?  That is a huge security risk because they bring them out into the unsecured open, and they can bring back all sorts of nasties.



STEVE:  Yeah, I mean, I don't see a good solution.  There is an interesting technology which Microsoft has completed work on.  There was something that they had for Windows XP that used to be called the Shared Computer Toolkit.  Microsoft Shared Computer Toolkit for Windows XP was the full name.  They've repackaged it and renamed it Windows SteadyState.  I've begun to explore it as a solution for corporate desktops.  It's sort of targeted more, its default configuration is targeted more to, as the original name implied, shared computer environment, for example like in a library or in an Internet caf when you want to essentially lock down a Windows-based PC so that anonymous and untrusted users can use the machine.  And when they're done with it, it's basically anything that they did - and what they can do itself could be restricted.  But the idea being that anything that happens is flushed out of the system.



LEO:  Right.  There are some third-party apps like that, too, like you might use it at a hotel.  So you have a default setup, you know, the guy comes in, he's going to do - he's going to mess around on that computer.  You let him mess around.  But as soon as he leaves the machine, you reboot, and it goes right back to the default configuration.



STEVE:  Exactly.  Exactly.  And it turns out that, now, that would be a problem in your typical corporate environment.



LEO:  Because you're destroying documents.



STEVE:  Well, yeah, exactly.  But it turns out that, although it's not the default configuration, and it does require repartitioning, that is, creating another drive, because SteadyState is only able to return an entire drive to its original condition.  But if you create another drive and put the user's profile information and desktop and documents folders there, then you can create a really interesting free solution which is protected from anything they do and won't execute code from this other drive, but still allows them to use it as their own workstation.  So anyway, I'll be exploring that, and we're going to do at some point here before too long a podcast talking about the specific configurations of this.  But it's an interesting notion for locking down a work machine so it's not absolutely restrictive, but it protects itself.



LEO:  Right, right.  Interesting, yeah.  And, you know, we're on both sides.  We're on the side of the user, but we also are very sympathetic, I think, to the IT guy who's got to deal with this.



STEVE:  Well, yeah.  And I'm sure that our listeners probably find themselves on both sides, too, even if they're, you know, even with their own family or children, where they're trying to say, look, you just can't do this because it's going to infect all of our home network.  I mean, after all, to some degree anybody with a router and multiple machines is a little environment that depends upon the security of each of the players within that community.



LEO:  And that's the truth.  That's the truth.  Well, very interesting subject.  I'd love to hear from our audience about what they think.  Next week will be a question-and-answer session.  That might be a good time to include your thoughts on this, and maybe your clever solutions, if you're an IT pro and you've found ways to solve some of these issues.  I'm sure we'd like to hear from you.



STEVE:  Yup, GRC.com/feedback.



LEO:  There you go.  GRC.com is the place to go for Steve Gibson, of course, all of Steve Gibson, not only this show.  And you can get 16KB versions there, too, by the way, as well as transcriptions of each and every show.  But also all of his free security software, his very useful notes like the Perfect Paper Passwords series.  And let's not forget SpinRite, world's finest, the best, the one and only, hard drive maintenance - and I'm going to underscore "maintenance" today - and recovery utility.  It is a great program that everyone should have.  GRC.com.



Well, Steve, I'm going to work on getting rid of this cold.  It's almost gone now.  I didn't cough once during the show, I think, so we'll see if I can do it in the next week.  And I thank you for joining us.  We'll see you next time.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#128

DATE:		January 24, 2008

TITLE:		Listener Feedback Q&A #33

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-128.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss questions asked by listeners of their previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous  installments, and present real world "application notes" for any of the security technologies and issues they have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 128 for January 24, 2008:  Your Questions, Steve's Answers, #33.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



Well, here it is, ladies and gentlemen, the one show where we're not going to mention Heath Ledger, we're not going to mention the stock market crash, we're not going to mention Bernanke's drop of the interest rate or the Federal Reserve Board.  This is the show where you don't hear any of that stuff.  This is the show where we talk about security.  Steve Gibson, hello, how are you today?



STEVE GIBSON:  Oh, Leo.  Well, it sounds like your voice is  back to full strength here.



LEO:  It's cracking a little bit.  Every once in a while I go tenor.



STEVE:  Okay, well, our listeners are now prepared.



LEO:  I was practicing singing high notes a little earlier on, and I actually was able to hit notes I haven't hit in a long time.  Isn't that odd that a cold would change the register of my voice?  It's a little weird.



STEVE:  You sound fine here, so...



LEO:  You never got it, did you.



STEVE:  No, no.



LEO:  Knock on wood.



STEVE:  Exactly.



LEO:  Do you have any wood in the fortress of security?



STEVE:  Underneath the Formica I think there must be some.  I'm not sure if that qualifies as wood, though.  That's like that pressboard stuff that we use to kind of...



LEO:  I've never been to your lab.  But I just think, I feel, it's probably very modern and, you know, kind of masculine.



STEVE:  Oh, it's definitely masculine.  When my ex wandered off, I covered over the fireplace with bookcases because I needed more shelf space.



LEO:  I knew it.



STEVE:  Yeah, you can't cover up your fireplace when there's a wife around.  That does not go over really well.



LEO:  Nowadays they're saying don't burn wood, don't burn wood, it's making people sick, stop burning...



STEVE:  Oh, and I mean, I'm in Southern California.  I just had to turn the AC off here on January 23rd so that we didn't have the background sound of the air rushing through our podcast.



LEO:  Steve, there are people listening who just had 37 inches of snow.



STEVE:  So my point is, I hardly need a fireplace down here.



LEO:  I guess you're right.  It's the last thing you need in Southern California.  So this is a Q&A episode.  Every other episode now, and on even episodes we do listener feedback.  But we've also made a pledge to give you the latest security news.  Anything going on in the world of security out there?



STEVE:  Well, one or two big things.  But more than last week, it was a rather quiet week.



LEO:  Thank you.



STEVE:  Yes.  The really significant news is that there is now a remote code execution exploit of the horrible Microsoft Windows TCP/IP problem, the vulnerability that we talked about last week.



LEO:  That's the one they patched Patch Tuesday of this month.



STEVE:  Yes.  So it's absolutely been patched.  But it is, you know, I was saying last week there is just no question this is going to be an Internet worm because there are still so many machines that are not being patched, whether it's because they don't pass the Windows validation test and so they're no longer able to be patched, as they used to be sort of, you know, pirated copies either way, or who knows why these machines are not getting patched.  And there is now, it has been found - and in fact, in some of the security discussions, Microsoft was apparently mitigating the severity.  I know that's hard to believe.  But they were saying, oh, it's really going to be difficult to exploit this.  Well, [buzzer sound], no.  It turns out, no, it took one week.  You know, so...



LEO:  Since zero-day exploits are the norm, that was difficult.  Took them a whole week.



STEVE:  Right.  So it is now in the wild.  And I expect that it won't be long before we see this demonstration of the vulnerability turned into a worm that works on propagating itself for whatever purpose around the 'Net.  I mean, the good news is that most of these 'Net-wide worms have just been created for the sake of proving that they could be done.  You know, the original ones, of course MSBlast was different, it had a destructive payload aimed at Microsoft.  But Code Red and Nimda, they just sort of wanted to see how long they could live and how far they could go, so they weren't doing much, although you really would expect now, with bots being as popular as they are, that we might see a worm based on this with an express purpose of creating new zombie machines.  So that's something we never saw really before.  You know, sort of general...



LEO:  When you say the exploits are out there, there isn't yet a worm exploit, just a script's exploiting it from a web page?



STEVE:  Right.  It's easy to say that it isn't yet a worm because the whole industry will know the instant a worm happens.  I mean, it will be another major event where it's like, okay, suddenly everyone's routers are getting pinged with this nonsense from a worm trying to propagate.  I mean, we'll all know when that happens because it'll explode on the Internet.



LEO:  Well, and remember the last time, it must be the last time there was a worm of this potential was Zotob.  And that hit CNN and a lot of people.  But one good thing is that, when these things happen and they get a lot of publicity, people respond by changing their security policies.



STEVE:  Right.  That's a very good point.  So each one of these events does have the nice side effect of further maturing people's understanding that they need to keep their Windows systems patched.



LEO:  And they seem to dampen, because of that, it dampens down.  So next time's not as bad.



STEVE:  Right.



LEO:  One hopes.



STEVE:  Well, although, I mean, this is exactly - oh, I'm sorry, I see what you mean.  People have learned to patch, so they're now going to be keeping their machines in general more secure because they've realized this is a real problem.



LEO:  And as an example, I'm sure that the companies that got bit by Zotob now run internal firewalls on all their machines because they mostly got bit when people brought laptops, infected laptops into the network behind the firewall.  And so as these things happen, people kind of build defenses.  Of course it's always closing the barn door after the horse is gone.  But it at least keeps the horse from running out that door again.



STEVE:  Right.  And the second bit of news is, and I saw this when I turned on my little Mac in order to set up our Skype session today, Apple has confirmed and patched a rather serious QuickTime vulnerability.



LEO:  Yes, I downloaded it today, yeah.



STEVE:  Which exists in all versions of QuickTime prior to version 7.4, which the industry has now moved up to.  Everyone who turns on their Macs will get this.  And but it affects both - we referred to this I think last week because this seemed familiar to me when I saw the patch coming in.  It's like, okay, this is what we were learning about last week for the first time because this is both OS X and Windows.  And the problem is that it's a remote code execution vulnerability which can take hold of a machine anytime you run a QuickTime video, an image file, or a stream.  So pretty significant.  And that's been patched, too.  So the good news is people who are using Macs and - what's the - I don't even know about QuickTime auto-patching for Windows.



LEO:  It does the same thing.  It's very similar.  And it happened on my Windows machine.  In fact, there was an iTunes update at the same time.  So I opened my Windows machine, I think this was yesterday or the day before, opened my Windows machine, it said there's a QuickTime patch and an iTunes update, would you like to download those.  And it looks very similar to any kind of automatic update.  If you've installed QuickTime, unless you've explicitly turned it off, and I don't even know how to do that, it should do that automatically.



STEVE:  Yeah.  I do know that I get the little QuickTime "Q" sitting in my tray all the time.  It's like, eh, I don't know what that's there for.



LEO:  Wish it wouldn't do that.  Everybody's does that, but it always annoys me.  You know, it's like, oh, that starts it up quicker.  Yeah, thanks.



STEVE:  I think they just want a little chunk of my screen.



LEO:  It's an ad.



STEVE:  Exactly, it's an ad.  So that's all we really have.



LEO:  I've turned that off on my system.  I think you can actually turn that off.



STEVE:  Oh, suppress the icon?  Oh, I'm going to go searching for that, then.  That will be a good thing.



LEO:  Definitely worth doing.  I like it best when, if you right-click on the icon in the system tray and say "Exit," it says, okay, but we'll come back unless you don't - do you not want us to start up automatically ever again?  And I think QuickTime is one of the programs that actually has that what I consider good behavior.



STEVE:  Yup, that's a good thing.



LEO:  All right.  So that's our update.



STEVE:  So that's all we had there.  I do have a fun, short SpinRite tale to tell.



LEO:  Yeah, I thought you might.



STEVE:  This one was - when did we get this, we got this one in - Aaron, who is, well, it's a sort of interesting story.  He says - I was looking for the subject line.  He said, "Just a SpinRite Story."  He said, "Back in 2003, long before I had heard of SpinRite and Steve Gibson, my hard drive crashed in my Dell desktop computer with all of my digital pictures on it.  I heard clicking noises, so I was 'sure,' he says in quotes, that it was a total hardware drive failure.  Dell send out a replacement drive.  I reinstalled, and I was able to reload most of my stuff from a month-old backup.  So I lost a month's worth of precious family photos.  The data recovery software I tried" - clearly not SpinRite - "could not help.  So I called for estimates from some data recovery companies."  Clearly he really wished he had his month's worth of family photos.  He says, "I just couldn't afford that, so I put the drive in a box for the next four years."



LEO:  But at least he saved it.



STEVE:  Yes.  He says, "...just in case."



LEO:  That's great.  That's like having your - that's what Walt Disney did.  With his head.  Just in case.



STEVE:  Yes, somewhere in cryo storage right now.



LEO:  Yeah, just in case, down the road, something comes along that could fix your hard drive.



STEVE:  So he says, "In early 2007, parens, {three computers later)" - this guy goes through computers quickly.  And he says, "I learned of SpinRite while listening to a weekly," oh, he says, "while listening to a newly discovered security podcast."



LEO:  Hey.



STEVE:  "I had a current computer problem and decided to try SpinRite.  It fixed my 2007 problem easily, and my mind was then drawn to that old hard drive in a box in a drawer.  Could it fix that, I wondered.  I connected that old drive to an old computer that was lying around and let SpinRite run for the next 26 hours.  Well, after four years locked in a failed hard drive, we finally got that month's worth of pictures out of the hard drive."



LEO:  Hey, yeah.



STEVE:  "The moral of the story is, regular backups are a good first line of defense."  And he says, parens, "(Remember, I did have a month-old backup.)"  He says, "And SpinRite is a great second line of defense.  Thanks, Steve.



LEO:  That is a nice story.  And I love the idea that he put his drive in cryogenic storage just in case.



STEVE:  It's like, it's very much actually like Walt Disney.  But, well, maybe someday something will come along that will be able to recover these.



LEO:  And, you know, it's a good bet.



STEVE:  Yeah.



LEO:  Even for Walt Disney I think it's a good bet.  I mean, I'm not going to do that, but I would do it with a hard drive.



STEVE:  Sure.



LEO:  Of course SpinRite's been around 20 years before he had the problem, he'd just never heard of it.



STEVE:  Exactly.



LEO:  I had to laugh when you said that because, I mean, it's like you hear about it in 2003, wait, this is...



STEVE:  Yeah, what year is it?



LEO:  Yeah, really.  Anyway, let's get down.  I have some great questions for you.  Are you ready to talk about listener feedback?



STEVE:  You betcha.



LEO:  We start with Eddie in Watsonville, California.  He confesses he shortened his key:  Dear Steve, I've been a listener of yours for probably a year and a half now, converted my wireless network to WPA some time ago, and used one of your 63 random printable character Perfect Passwords to do it.  That's GRC.com/passwords.  All was well as long as I only had computers that I could copy-and-paste the password into.  Then I bought myself a PSP, a Sony PlayStation Portable.  After six failed attempts - oh, dear - at entering the WPA key, I decided I didn't really want to take my PSP on the Internet anyway.  Oh, it's a pain because it doesn't have a keyboard.  You have to do it all, oh, gosh, I can't...



STEVE:  And I still don't have my iPod Touch on my WiFi.  I  mean, I hear that it's got WiFi, but I can't type my key into that thing.



LEO:  That's why I don't use the long...



STEVE:  I know.



LEO:  Then for Christmas I received a WiFi desktop Internet radio.  It supported WPA.  I knew I had no chance of entering that ungodly key correctly, so I went back to GRC.com/passwords, copied the first 24 characters of the random alphanumeric string.  Still took two attempts on the radio and three on the PSP, but - and the good news is you only do it once - they're all happily on the network.  My question is - and this is a really good question - how much less secure is 24 random alphanumeric characters than 63 random printable characters?  I understand that the 63 is, as you might say, phenomenally more secure, but I'd like a number.  Would it take a hacker decades instead of millennia, months instead of centuries?  I would imagine even the most determined hacker would give up after only a few days.  Just how much security have I given up?  Great question.



STEVE:  Great question.  Okay.  So here's what happens.  When you put a passphrase into WPA, any passphrase a user puts in is run through a sort of an overkill hashing process.  It takes the passphrase and the SSID of your network and the SSID length, and it hashes - it concatenates all that, and it hashes it 4,096 times, over and over and over and over and over, into a 256-bit result.  So the key that is actually used by the various devices on the WiFi network ends up actually being a 256-bit key.  So the source of the key is the passphrase and the SSID and the SSID length.  So as we've discussed before, the attack on what's called a "preshared key," which is what this is, is trying them.  It's just a - it's a brute-force attack.  Anybody who has access to your network, that is, like receive access, as we know, is able to receive the SSID of your system if it's not turned off.  And if it is, then that's part of the hash anyway since other devices wouldn't know what it was.



So the only unknown in this hashing algorithm is the passphrase.  So the attack on this technology is just brute force.  You start with maybe all the words in the dictionary, and essentially put a word in the dictionary through this overkill hashing, this 4,096 hashes of this, to produce a trial 256-bit key, and then check to see whether that works on the network.  And if not - and actually you're able to capture payload from the network and see whether this key is able to decrypt the payload, which then tells you that it would work on the network.  So that's why this is a so-called "offline attack."  You're able to capture some traffic from the network, take it home with you, or to your Cray, and just pound on that data, trying every possible passphrase.



So 63 random printable characters is the most that the specification allows a user to put in.  Now, 63 random printable characters, assume that we had like a 7-bit character set, so we're using most of the printable ASCII.  Well, 63 times 120 - I'm sorry, 63 times 7, which is the number of bits in 128, actually, is 441.  So you're taking - if you used all 63 possible character length and hashed that down, you'd be hashing 441 bits down to 256.  So you're sort of starting with more entropy and reducing it to 256.  In theory, there may be other so-called "hash collisions," that is, there might be some simpler phrase that would also hash down to the same resulting 256 bits.  But, you know, it's a secure hashing algorithm.  Collisions are going to be minimized.  And so it's still going to require a brute-force attack.  The current wisdom is that 20 characters is, eh, right on the borderline of what would be feasible for a brute-force offline attack against WPA.  So you really don't want to use fewer than 20 because that begins to border on not secure enough.



LEO:  Now, remember, though, in order to crack your WPA somebody has to sit on your curb.  They have to be within radio distance of your base station.



STEVE:  No no no.  That's the point of this being a fully offline attack.



LEO:  Oh, they can just capture a bunch of the stream and then drive off and work on it.



STEVE:  Exactly.  And that's what I meant, that's what I meant when I said they could take it home to their Cray.



LEO:  Of course, you did say that.  I just wasn't paying attention.



STEVE:  And so, and just pound on it offline.  And/or do a parallel attack, or use a distributed network of PCs, I mean, or...



LEO:  Somebody would have to be pretty determined to do this.



STEVE:  Yes, I mean, exactly.  So, well, or you would be targeted, they would want to get onto your network specifically, as opposed to, for example, someone wandering down the street looking for open WiFi.  This is certainly a much higher level of attack than that.  And your typical home user is probably not going to be targeted by somebody who really wants to get onto their network.  However, a corporation certainly could be.



So Eddie was suggesting that he's used 24 characters.  That's probably good.  One of the things you do not want to do, and our answer sort of touches on this, is you do not want to leave the SSID default, nor do you want to leave it blank.  Because one sort of future-oriented attack on WPA will be precomputed hashes.  That is, if you knew, for example, you had a Netgear WiFi, and there was a default Netgear SSID, it would be possible to do a different kind of attack.  Rather than having to put the passphrase and the SSID and the SSID length into this function and hash it like crazy - and in fact that's the reason they've used 4,096 is they want to slow down this kind of attack by forcing 4,096 hashings of this in order for it to be computationally intensive in order to make a single guess.



So but the problem is, there are things called "rainbow tables," and I don't think we've ever really talked about rainbow tables.  They are essentially precomputed hashes.  So the reason that the SSID and the SSID length were added to this was specifically to prevent a precomputation attack where all of the, for example, words in the dictionary, or maybe starting with A, then Ab, then Ac, then Ad, then Ae and so forth, basically precompute all the possible hashes that result from common words, and then quickly apply those against offline packets in order to crack somebody's encryption.  So my point is that, if you leave the SSID default, then you're potentially opening yourself to a precomputation attack, if that starts happening.



LEO:  Okay.  So if I do a 20-character...



STEVE:  Eh, I would say 24.  What Eddie happened to settle on at 24 is probably safe.  I would say nothing less than 20 is safe.  And I have a - I found a nice page on the 'Net with a link to a discussion of this, if our listeners are interested and want to go into a little bit more detail than this, sort of without me interpreting what this page says.  It's pretty technical.  But there is a link in this Episode #128 show notes to a page that discusses the issue of this attack on Wireless Protected Access preshared keys.



LEO:  Okay, very cool.  Now, when you say "safe," that's a very relative term.  I mean, I use, I mean, I'll be honest.  I just use what normally, you know, what would be considered a normally kind of strong password, which is something I - but memorable.  It's probably only 10 characters.



STEVE:  I would say you absolutely want it not to be in a dictionary.  I mean, and so that's...



LEO:  It's got punctuation, it's mixed case and punctuation.  But it's memorable for me.  And but it's not 24 characters.



STEVE:  Yeah, and let's hope that no one desperately needs to get into your wireless network.



LEO:  And nobody does.



STEVE:  I don't think so.



LEO:  By the way, I met somebody at Macworld Expo, guy who does a podcast, Dan's Mathcast, who says he's used the math - he'll take a little clip of Security Now!, like that early part there where you were talking about powers, and he'll use that, and then use it as his mathcast to talk about that math issue.  So...



STEVE:  How cool.



LEO:  ...good work on the math there.  When he first said that, I thought, oh, no.  But he says, no, no, you guys are always good.  Don Sherman in Clawson, Michigan is looking for a shorter route:  Steve, he says, I'm a graduate student in engineering and a huge fan of the show.  I just finished listening to the most recent Listener Feedback episode.  It occurred to me that on several occasions I've heard you say you need three routers to safely employ WEP and WPA without allowing - both WEP and WPA without allowing any nefarious activity on the WEP side to compromise the WPA side of things.  Is there any reason why you need to use a router and not a switch to split the two networks?  If so, please let me know, as this is how I have my network set up.  I cannot use WPA with my TiVo boxes.



STEVE:  Okay.  Let's review briefly this idea of chaining routers.  The idea was that you could have your outside Internet connection go to Router #1, and that would be a wireless router running WPA or WEP.  And then you would chain it to a second router which was also wireless, running WPA or WEP.  Now, the problem is, if the inside router is the insecure one, then it is potentially able, that is, somebody who cracks WEP, and we know how easy that is now, remember it's less than a minute to do that now.  If someone cracks that, then due to the fact that it's possible to make upstream connections through a router, which of course is how the Internet works, we're all downstream of our routers, and we're able to make upstream connections through the router.  That allows somebody on the inside, that is, on the inner router, to connect to devices on that outer level router because upstream connections are permitted.  So that's why it's not safe to have an insecure network chained off of your secure network.



Now let's swap the routers around so that now the outer router, that is, the one connected to the Internet, let's make that one the WEP, the insecure WiFi router, and our WPA router where we have all of our crown jewels and our high-security WiFi due to using WPA.  That's the inner one.  Now the problem is that all of the precious, super secure network traffic goes out through the inner router to the outer router, which is the insecure one.  The problem is, as we've discussed before, in the face of ARP spoofing, which is well mature now and developed for Ethernet networks and for Ethernet WiFi, it is possible for - it would be possible for a wireless attacker to convince the inner router, the secure router, that its IP is the gateway, so that all of the precious Internet traffic on the inside would route through an attacker's machine on its way out to the Internet.  So there is a, if you assume that ARP spoofing could be present, then it is not secure to have the insecure router upstream of the secure one because ARP spoofing absolutely allows essentially man-in-the-middle traffic rerouting.



So it is not safe to chain an insecure and a secure router together in either order.  The only thing you can do that is safe is to have two routers that are joined by a third router.



LEO:  So you need the NAT.  You can't just use a switch.



STEVE:  Well, no, actually.  So what the outward-most router in a three-router configuration would be doing really is just giving each of the interior routers an IP.  So to answer Don's question, if his ISP has given him two IP addresses, then you absolutely could use a switch.



LEO:  I see.  You have to have two segments, basically.



STEVE:  Well, actually you have to have three segments.  You've got your insecure LAN, your secure LAN, and then a third little mini LAN that only has three devices on it.  It's got the switch, and then it's got the two routers.  And the reason you're safe from WEP there is that, I mean, the only real attack that's possible would be an ARP attack.  And you say, well, wait a minute, why can't I still spoof ARP in order to fool the outside interface of the super secure router?  The reason is ARP never crosses a router.  ARP is specifically used for local area networks.  No router will allow ARP to cross across from its LAN side to its WAN side.  So the only secure solution would be either to use three routers, or as Don has asked, if his ISP is giving him two IPs, then he could use a switch to connect those two routers.  



LEO:  Got it.



STEVE:  And be completely secure.



LEO:  Got it.  All right, good.  Jeremy in St. Petersburg, Florida, wishes he had more choices:  Hi, Steve.  I was a bit disappointed over having to pay $72 for my VeriSign credit card security key, due to $24 overnight shipping being the only option.  Hmm.  They could have just put it in an envelope.  But I've received my key, and I agree it is a really slick piece of technology.  I ran into one snag, though, that I hadn't heard mentioned on the podcast when you and Leo were discussing them.  The problem is with eBay and VeriSign's PIP site.  Both allow you to only have a single security key associated with your account.  This is unlike PayPal, which allows multiple keys.  Because of this, I can't leave my football at home in the office and have my credit card in my wallet.  I have to pick one of the IDs, and only one, to use with eBay and PIP/Seatbelt.



I wrote an email to VeriSign support and got a very nice reply from Gary Krall, the technical director of the PIP program.  He confirmed that VeriSign, like eBay, has no plans at this time to support multiple security keys.  VeriSign I can understand.  They have a higher, you know, high priority things on their plate.  But doesn't eBay own PayPal?  How can one site support more than one key, but not the other?  Anyway, this means I basically had to disable my football on eBay and PIP so I could use the cooler credit card key.  My football will still get me into PayPal, but that's it.  That actually was the experience I had, too.



STEVE:  Yup.  I just wanted to let your listeners hear Jeremy's pain because we've all had it, too.  I don't understand why eBay hasn't followed suit.  It is certainly the case, as we've discussed before, that the VeriSign VIP technology now supports up to five credentials registered to a single account.  And so the user of up to five credentials is free to use whichever one they want.  And when you submit the query, the authentication, to VeriSign's authentication system, it'll check the specified input against all five, up to five possibilities.  So, and PayPal does this.  But eBay and VeriSign themselves don't.  So I just wanted to make sure that our listeners knew that, just for the sake of making sure they understand that.



LEO:  Yeah, yeah.  But, you know, I keep the football for use on PayPal, which is frankly still where I use it the most.  And I just use the card, just as this guy does, on Seatbelt.  I don't use eBay that often, but that's fine.



STEVE:  Yeah, and after all, the football's only $5, so it's not like he was having to, you know, end up deciding to scrap his $72 cost credit card side.



LEO:  You think it's a security reason for that, or just an implementation issue?



STEVE:  I don't see any security flaw in having multiple credentials.  I mean, I just think eBay just doesn't care, hasn't gotten around to it.



LEO:  Moving right along, Marcio in London, UK, wonders whether - as opposed to, I don't know, London, Iowa - wonders whether IBM is spamming him:  Hi, Steve and Leo.  I have received a spam email, I know, nothing abnormal with that.  It was just another "replica watches" spam.  Obviously neither my email client nor my company's email server filtering policy seems to be finely tuned in, other wise that wouldn't have slipped through.  The curious bit, though, and the reason I'm writing, is the sender's address is kasey@ibm.com.  Could there be a trick, changing the sender's address?  Or is it the case that an IBM server or computer could be bot-infected?  Please let me know what your thoughts are.



STEVE:  Well, it's interesting.  I get sort of a little background flow of email like this, asking about strange spam sources.  So I wanted to...



LEO:  Well, people could get spam from TWiT.tv because I know that's used sometimes by spammers.



STEVE:  Oh, and GRC has been also.  Essentially what's going on, Marcio, is that the content of email, which contains the From and Subject and To and other headers, is completely separate from the - and that sort of inside the envelope - is completely separate from the protocol used by SMTP servers, that is, Simple Mail Transfer Protocol, to move that email payload from one machine to another.  So from random computer A to random computer B, which are email servers, a sort of an opaque content will go from one server to the other.  So there is the ability to trivially spoof the sender of the email just by putting anything they want to, and typically something credible.  I mean, Leo and I have both been targets because we're credible companies, and people might think, hey, email from GRC, how strange.



LEO:  Hey, but I've got to tell you, I think sometimes it's randomly chosen because I get questions on the radio show all the time from people saying, hey, what's going on, you know, I just got a bunch of bounced emails from a company saying I'm sending them spam.  What's happening?  Same thing.



STEVE:  Right.



LEO:  So I think sometimes they do it for credibility.  I mean, IBM.com clearly for credibility.  But sometimes it's just - they choose it from random from a mailing list.



STEVE:  Yup, that's probably the case, Leo.  So anyway, to answer your question, Marcio, I am sure that IBM machines and servers are not infected.  It's just it's so simple to spoof the source of email, that is, the sender.  Now, we've talked about this in the past.  If you dig down into the archives of Security Now!, we've talked about email headers and how they can be interpreted in order to determine the true source of email because that's not spoofable.  And so there is a way to determine what machine connected to your email server in order to send it a piece of email by following the headers back.  But it's not just a matter of looking at the From address.



LEO:  Well, and of course that's why there have been these various moves towards email authentication, which essentially is sender authentication.  And if that were to go through, if they were able to figure out a way to do that, it'd just reject email that doesn't have an authenticated sender, and pretty much all spam would go away.  But, you know, because the email system was never designed for that.



STEVE:  Right.  We can hope for that day.



LEO:  That's why three years ago Bill Gates said, oh, I think spam will be a thing of the past next year.  The problem - and because Microsoft had an authentication scheme.  Problem is, nobody's really been able to agree on what scheme to use.



STEVE:  Right.



LEO:  Thomas Bonham has a question for Mac-friendly Leo:  Hi, Steve and Leo.  I'd like to know if you know of any good encryption software for OS X, 10.5.  That's Leopard.  I'm unable to use FileVault because of the fact that I have HFS+ with case-enable on the computer.  It doesn't like that.  I'd really like to be able to encrypt the whole drive.  But for now I'd be happy just to have one folder encrypted all the time.  What I'm looking for right now is something like TrueCrypt for the Mac.  Any ideas would be great.



STEVE:  Leo?



LEO:  Hmm, that's a good question.



STEVE:  No kidding, there isn't something that's on the tip of your tongue that...



LEO:  Well, what surprises me is that TrueCrypt has not been ported for the Mac.



STEVE:  Right.



LEO:  But it hasn't.  That's a very good question.  I don't, I mean, you can use PGP, but that's a commercial - I guess there's a noncommercial free version.  I don't, you know, I don't know.  I'll have to do some research.  I don't know of anything, believe it or not.  Because most people use, if they're going to do the encryption, they use the FileVault, which is very similar to the system-level encryption on Windows.



STEVE:  So essentially the Mac does provide a built-in solution.



LEO:  Oh, yeah.



STEVE:  Which works for most people.  And so that's probably kept people from doing something redundant.



LEO:  I think that's possible, yeah.  I'm not sure - he says he's using HFS with case-enable.  That's interesting.  I didn't know that you couldn't use FileVault in that case.



STEVE:  And what's "case-enable"?



LEO:  Case-sensitive, I guess.



STEVE:  Oh, okay.



LEO:  But that's what I, I mean, that's what everybody uses.  I think, Thomas, you should investigate why you're not able to use FileVault.  Apparently there is - I'm looking.  Somebody has been looking at a port of TrueCrypt.  So I hope at some point - Bruce Schneier is saying, I'm reading his blog, he's saying, you know, I hope at some point there is a TrueCrypt for Mac.  And of course, remember, Mac is BSD UNIX.  So there are a lot of UNIX, you know, command line level encryptors you can use from the UNIX command line.  But that's going to take some cobbling.  It's not as easy to use as TrueCrypt.  Boy, I wish they would port it.  I don't know why they haven't.  Maybe there's some issue.  I don't know of anything.  And if anybody does, love to hear from you, and we'll mention it on a later episode.  But Thomas, all I can say is, the problem with FileVault, it's like BitLocker.  It encrypts your whole home directory.  So it isn't as flexible or as powerful or as useful as TrueCrypt.



STEVE:  Right.



LEO:  Matthew Reeves of Alpharetta, Georgia really wants to delete his files:  I'm a lawyer - a lawyer.  No, I'm a loyal Security Now! listener, and I'm so thankful it exists.  Well, thank you, Matthew.  I remember once hearing you and Leo speak of a secure file deletion utility.  I don't remember its name.  I went to search the transcripts, but I couldn't find a way to do so.  That's probably true.  So my question is, what is the name of the utility?  And my question is, can the Security Now! transcripts become searchable, if they aren't already and I missed it?



STEVE:  Okay.  To the last part, it is on my shortlist of things to do.  We've had a lot of requests for that.  It is possible in the meantime to get Google to do a limited search, since the transcripts are all being Googled.  And so by using the advanced search features you're able to restrict Google to a domain, and I think even a tree of files, in order to have it say, look, you know, find hits for these phrases right here.  So that can be done.  But I'm aiming soon to have, finally, a search facility that is GRC-wide up and running.  As for secure deletion, there are a gazillion various sorts of file shredders and things.  It turns out, though, that most people don't do it right.



LEO:  Oh, really.



STEVE:  Interestingly, yeah, interestingly enough, you may remember that, like I'm sure you will, Leo, in the old days, we were being told that NT was a C2-qualified OS.  It met some government standards for security.  One of the things that is required for that is that the operating system be very careful about re-use.  That is, for example, when memory is allocated to an application, Windows NT, 2000, XP, Vista, everything in the NT path or family will always zero the memory page.  In fact, one of Windows' background processes, when it's not doing anything else, is just rummaging around, filling memory that's not allocated to anything with zeroes.



LEO:  What?  That's really cool.



STEVE:  Yeah, it is really neat.  Now, similarly, disk space is zeroed, but it's not zeroed upon deletion.  It's zeroed upon allocation.



LEO:  Oh, that's interesting.



STEVE:  So what's interesting is, if you delete a file, and say that you then, you also deleted it out of your trash, well, it's been released, but we're all familiar with various utilities that are able to undelete files.  Similarly, anything that worked offline, like if you shut Windows down, it turns out that that file data is still available on the hard drive.  It's not until a program is being given sectors for its use that NT preemptively zeroes it.  So what's important here is that everything that isn't in the process of being reused is left the way it was.



So it turns out, though, that things are even trickier because, if you encrypt a file, what NT does is it, because of the way the file system works, sort of a journaling file system, we've also heard how NT - like for example the file system integrity can survive power failure or the plug being pulled out of the hard drive and other things - NT is careful, for example, not to remove a unencrypted file which you're in the process of encrypting until it has been successfully encrypted.  Once it is successfully encrypted, then NT unlinks the unencrypted version, but leaves it on the hard drive.  So you can have copies of unencrypted encrypted files...



LEO:  Not good.



STEVE:  Exactly, still lurking around.  The same is the case for compressed files.  It's compressed and encrypted, and there's one other class.  Oh, and even, well, the EFS system works in exactly this fashion.  So anyway, the point is that our good old friend Mark Russinovich has solved this problem.  Of course we know that Sysinternals was purchased by Microsoft, and so there are - his utilities, the Sysinternals utilities are now available and linked through Microsoft's site as opposed to his.  There is a program he has called SDelete, "S" as in "Secure."  It's just SDelete.  If you were to Google, you just put "SDelete Sysinternals," it'll take you, first link is Microsoft's page.  On our show notes page we've got a link to the Microsoft page discussing Secure Delete, SDelete utility.  And to the downloadable ZIP file.



It's just a - it's a small command-line utility that understands exactly how NT works.  And it uses the defragmentation API in order to find the actual physical pieces of a file which you're trying to securely delete, and it goes out and zaps them before freeing them back to Windows.  So it does it right.  Many so-called secure delete utilities do not do it correctly.  So, but we can trust Mark to have figured this out and done it right.  And it's got a couple other cool things.  If you were worried about, for example, now that you understand the things you deliberately encrypted or things you deleted may still be lurking around, you can give it - it's a command-line utility.  You can give it, I think it's a -Z option, and it will go out, and it will scrub all of the current free space on your file system.  So basically you could just run it now, and it would deal with any history of stuff that you were hoping was gone, but may not be gone.



LEO:  Interesting.  Mac has a secure-delete command in the file menu, but I wonder.  I bet you it's not erasing slack space.  And, I mean, but at least it would zero out the file, and I presume all copies of the file.  But slack space is a big issue.



STEVE:  Right.



LEO:  We may have mentioned this, as well.  When you want to erase the whole drive, for instance you're giving away the computer or you're giving away the drive, there's a free program, open source program called Darik's Boot and Nuke.



STEVE:  Yup, DBAN.



LEO:  DBAN, which makes a bootable floppy or CD-ROM.  And the reason you want a bootable floppy or CD-ROM is you don't want to be doing this from within Windows if you want to wipe the entire drive.  Mark's utility is for individual files.  But if you want to wipe the entire drive, DBAN, you just - it's very simple.  Google DBAN, and you make a bootable floppy or CD-ROM.  And then it says, you want to erase the whole thing?  Yes, please, yes, yes, yes.  And then you finally can zero it out.  I just was looking at the TrueCrypt page.  Interesting.  TrueCrypt 5, which is scheduled to be released this month, will include OS X support.



STEVE:  Yay.



LEO:  So it's going to be completely cross-platform, which is nice.  You could make, for instance, an encrypted USB drive or external drive in Windows and be able to read it on OS X.  Plus they're going to do a GUI version for Linux.  So that's a major improvement.  There hasn't been a release of TrueCrypt since May.  Obviously they're working on this TrueCrypt 5.  So watch for that.  Who knows, maybe by the time you hear this it'll be out.



STEVE:  Well, and Question #8 from Michael Daniels...



LEO:  Applies to that?



STEVE:  Yes.



LEO:  Well, we're not there yet.  We'll get there in a second.  Steven Barrett in Round Rock, Texas would rather switch than fight:  I know that it's really difficult to use another operating system that you're not brought up on.  But why not just use something other than Windows?  This probably sounds like another "Windows sucks," or "I'm a Mac fanboy that's irritated at everyone not using Macs," or "Linux is superior to everything because it's open source."  But honestly, why not?



STEVE:  Well, Leo...



LEO:  That's a question for you because you, despite knowing more than probably anybody what's wrong with Windows, at least security-wise, you stick with it.



STEVE:  Yeah.  I guess I thought this was interesting because I do - this is another question that comes up over and over and over is people say, gee, Steve, you know, you're spending all this time talking about how horrible Microsoft Windows is and all the security problems it has, blah blah blah.  Why not, I mean, why would you not have moved off of Windows?



LEO:  Right.  You can't.



STEVE:  I was going to say, my real answer is, this is where the problems are.



LEO:  You're not allowed to.



STEVE:  So this is where I am, exactly.



LEO:  I think we talked about this before.  You said, hey, if I weren't doing this, if I were retired, I probably wouldn't.  And I use Windows for the same reason.  Actually, I use Windows maybe more than that because, for instance, I use Windows for Adobe Audition, which is my editor, my audio editor and recorder of choice.  I have not found anything as good on the Mac.  And so I use Windows because I need a Windows app.



STEVE:  Well, that is exactly my real answer, aside from the fact that this is where I have to be, is virtually anything, I mean, okay, we were just talking about TrueCrypt, not yet on the Mac.  But it's been on Windows for a long time, I mean for years, because we talked about it a long time ago.  And so my position is - and I talk to people who are frustrated that the thing they want to do is not available on their non-Windows OS, but it is on Windows.



LEO:  Well, but it goes both ways.  There are many things you can do on the Mac that you can't do on Windows.



STEVE:  Dare I say SpinRite.



LEO:  Good example.  Perfect example.  But there are - and it's the same, I mean, there are things you can do on Linux you can't do, I mean, there's Rsync.  Windows does not have Rsync, which would be a really nice thing to have.  There's lots of things I can think of that aren't on any given platform.  But, you know, to address his issue, I personally think that people get over-attached to their operating system.  Remember, you may love your operating system, but it doesn't love you.  It's just a tool.



STEVE:  Well, and Leo, you know, I buy a lot of software.  And so in the same way that I'm now buying eBooks for my Kindle on Amazon, and I'm sort of locked in there, I mean, I've got a huge investment way beyond just the Windows OS in all the stuff that runs on Windows.



LEO:  Well, that's a good argument for open source.  The sooner you open to open source, the sooner you'll be free from those shackles, economic shackles.  You know, I use Windows, Mac, and Linux.  I probably use Mac more than Linux or Windows.  But it's more equal than most people probably think.  And I'm happy with all three.  Use the tool for the job you're using, you know, you're working on.



STEVE:  I think that's exactly right.  As we know, I'm a FreeBSD UNIX user for things where UNIX serving is the best solution.  And there are, you know, I tried to use Windows as a news server, a Usenet style, NNTP.  And it's just, oh, it's really bad.



LEO:  No, all my web serving is done from - we use Red Hat Enterprise Server.  I have two servers, dedicated servers.  Nobody else is using them, just me.  And they're both running RHE.  And I manage them.  They're not managed.  I manage them myself.  And absolutely, I mean, these servers are rock solid and have been for years.  And it's been, you know, once you tune them, once you figure out, you know, how to get everything just so, man, they just run, you know, tens of thousands of requests a day, day in, day out.



Michael Daniels of Dallas, Texas - Question #8 - wonders if TrueCrypt is truly cryptic:  Hi, Steve and Leo.  I'm a longtime listener of the show.  I've followed you guys since TechTV, when Steve would occasionally appear on The Screensavers as a guest.  Thanks for the podcast.  Keep up the good work.  I have recently started to keep my files mobile by carrying a 120-gig hard drive around with me.  However, after a short period of time I thought, this is stupid.  If I lose this drive, anyone can access my files.  I looked around, found TrueCrypt, an open source encryption utility.  I was wondering what you use, and if TrueCrypt is indeed any good.  I apologize if this question's been asked before, and I haven't made it through all the show archives yet.



You know, I just got a USB key from Corsair that came with TrueCrypt on it.  I was so pleased.



STEVE:  Yeah.  And the answer, Michael, is TrueCrypt is really nice.



LEO:  It's the best.



STEVE:  Yes.  We did an entire podcast on it, so I wanted to aim Michael and anybody else who didn't hear that back to the archives for our Episode on TrueCrypt [Episode #41] where we take a very close, an extensive look at TrueCrypt, the functions it supports, the way its crypto is done, I mean, the really clever little special things that TrueCrypt is that really make it our solution of choice.



LEO:  Yeah.  And boy, I'll tell you...



STEVE:  And soon to be on the Mac.



LEO:  When it's Mac, oh, man, I'll be happy.  And that's actually a very good use for TrueCrypt is an external hard drive, or any external device that you carry around with you.  This Corsair memory, you know, it's a USB key.  They have 16-gig, they have 32-gig, I mean, this is basically an external hard drive.  Absolutely you should be using TrueCrypt if you're putting private information on there.



STEVE:  Yup.  In fact, we're going to do an episode also shortly about IronKey, which we talked about briefly last week, which many people have asked about.  And the founder and chief architect of IronKey is going to join us...



LEO:  Oh, good.



STEVE:  ...to talk about his inspiration and to clarify some of the details of the technology.  But, I mean, it really is, it's a very, very nice-looking system.



LEO:  But I think, you know, given - you know, it's hard to learn all the ins and outs of TrueCrypt.  But once you figure it out, it's just as secure, right, I mean, it's just great.



STEVE:  Oh, it's spectacularly secure, yes.



LEO:  Don Hebert of Burbank, California wants more pixels:  Hi, Steve.  I noticed in a photo that you use three monitors.  So does Bill Gates.  Hooking up two monitors is easy, but how do you hook up three monitors?  And how do you use them?  Where was that photo?  I didn't see you in a photo.



STEVE:  There's a photo at the top of my page at GRC.com.  I think you just do GRC.com/steve or stevegibson, I don't remember which, or maybe either.  And there's a shot that was taken by a Newsweek photographer many years ago of me sort of grinning and leaning...



LEO:  Well, that was probably three different computers, then.



STEVE:  Well, no, it was exactly the same computer and monitors I'm sitting in front of now.  That's why I got a chuckle out of our other questioner, who said he's, you know, in three years he's gone through three machines.  I tend to hang onto mine for a long time.  I mean, they get kind of old and creaky.  I'm still using my Win2K box with three monitors.  And to answer Don's question, you simply plug in video adapters.  And at least in the case of Windows, it will see your video adapters, and you're able to arrange the monitors logically into one large screen and essentially just drag Windows back and forth among the various monitors.



LEO:  We used to talk about this a lot on The Screensavers when it was a little more difficult.



STEVE:  Right.



LEO:  I mean, there was a website that said which cards worked together and stuff.  But since XP it's been a lot - well, you're doing it on 2000.



STEVE:  Yeah.  And 2000 supports multiple monitors just fine.  To answer...



LEO:  It's best if you have three of the same cards, though, yes?



STEVE:  It really doesn't matter.



LEO:  Oh, okay.



STEVE:  It's a little confusing.  I should tell you, I do this a lot.  So I've got many machines with, like, a hodgepodge of screens on them.  It's a little confusing if the monitors are different sizes because then they don't really, like, stack next to each other well.  And there's, like, some weird ozone area, a rectangle that you can't get to sort of off to one side.  But...



LEO:  You want a rectangle.  You don't want some arbitrary [indiscernible] box.



STEVE:  Right.  And you can do strange things.  I mean, you can stack them vertically or horizontally.  If you had four you could put them into a square configuration.  And there is a cool little utility, UltraMon, that I like and that I've had running in my tray for many, many years which allows you to assign hotkeys to just make Windows jump to different monitors.  So, for example, I have Ctrl-1 moves whatever is the current window to the left in a sort of a circular fashion, or Ctrl-2 moves the current window to the right.  So it's easy for me to just quickly move a Window off to one side.



The way I use the monitors is I generally sort of have things in different positions.  I just like having more screen real estate.  I mean, I'm able to work with a laptop with only one screen.  But when I'm settled down into Mission Control here, I do have, like, reference windows.  For example, when I'm writing code, and I need to kind of keep an eye on the Windows API, which is so extensive that it's impossible to memorize it all, I'll have the API reference upon my left window so I'm able to just glance over at it.  And I don't want to cover up the editing window that I'm typing in in order to see the API reference and vice versa.  So there are places where you really do need more screen real estate.



LEO:  I have to say, I bought a 30-inch display for my Mac, and which is a single display; but, I mean, it's a lot of real estate.  And I'm actually thinking about getting a second one.  I mean, it's funny how your needs expand to fill the real estate you have.



STEVE:  Exactly.



LEO:  Right now I have a 30-inch and then a 24 - the Windows machine is on a 24-inch to the right of it.  And I use Synergy, so I can use one mouse and keyboard with the two computers and two displays.  And that works quite well.  Synergy's a really neat little program for Windows and Mac.  And I just slide the mouse over.  So in a way it's kind of like an extended desktop except it's two different operating systems.  That's kind of nice, yeah.  Yeah, I'm thinking.  You've got me thinking.  Maybe I need a 30, a second 30.  They're so hideously expensive, though.  You have - how big are the monitors in front of you?



STEVE:  I've got SGI monitors that I've owned for years.  They're 1600x1024.  And I've got my next machine set up already.  I'm going to be switching to DVI.  These are - they're, like, custom cards.  They were 3D Labs cards running on these SGI monitors.  And at the time they were available for a great price.  And I'm not gaming or anything on them, I'm just sitting here looking at text and editing and things most of the time.  So I don't need any ultra high performance.  But the machine I'll be moving to, I've referred to it before, it's that quad core Intel that I call Quadmire.  And it's got, okay, it'll be running Windows.  That'll be my move to XP.  And I've got beautiful 1600x1200 Dell monitors lined up for that one.  I just haven't had any time to make the switch.



LEO:  Those Dell monitors are really nice.



STEVE:  Oh, they really are.  I think I own maybe 15 of them.



LEO:  Yeah.  I have a few.  I have a few, yeah.  Let's see.  Peter Brischetto in Sydney, Australia wants more discussion of enterprise security:  Hi, Steve.  I was excited to read the title of the last Security Now! podcast, thinking you'd delve deep into the problem of corporate security and discuss it for hours and hours on end.  Well, we just got started, give us a break.  Alas, it wasn't to be.  I would like to share my experiences with you so that you could share it with your listeners.



At my previous employer, I was the network administrator for a software development firm with about 40 staff.  Every developer had a company-provided laptop that not only had XP on it, but also required them to run IIS, the Microsoft SQL database, Visual Studio, and other such applications.  Being laptops, they were often connected to third-party networks like client networks, hotels, even their own home networks.  To further complicate matters, while in the middle of a development cycle, many of the developers would refuse to install Microsoft's many updates - I don't blame them - updates, patches, service packs to any of their software as this had caused their development environment to break.  As you can imagine, I didn't have much confidence in the security of our network.



The solution we came up with worked great for me, the administrator, and also for the developers.  We implemented VMware on all developer laptops.  A VMware image was created for each client that the developers would then use on their laptop for the purpose of development and testing.  This allowed their native Windows XP install on their laptop to be kept fully patched without also having to run SQL, IIS, and other problematic software on the outer machine.  The VMware image was limited in its network connections, and regular snapshots were taken so if the image went bad it could be wiped and rolled back to the previous snapshot.  The added benefit to the developers is that when a new developer came onto a project, they could be up and running with the latest VMware image in minutes.



I've since left this company and now work as an IT consultant for small businesses.  This is more of a challenge, as I'm not only telling businesses what they can and can't do with their computers, but the experience and requirement level differs greatly from business to business.  I'd love to hear other network admins' experiences with their IT security and the problems they face.  Love the podcast, and of course SpinRite.



STEVE:  Well, I thought that was a very clever solution that Peter came up with.



LEO:  Yes.



STEVE:  We've of course talked about virtual machines and the isolation that they provide.  And there were a number of people who sort of expressed similar sentiments of really, really being captivated by the topic of enterprise - and the challenge of enterprise security.  So I wanted to have you share Peter's experience, but also to invite anyone who has their own stories like this - solutions, problems, dilemmas, that kind of stuff - to drop a line to us.  It's GRC.com/feedback is the page where people can submit things.  Make sure you put something in the subject line, like say "corporate security" or "enterprise security," that'll catch my eye.  And we'll try to give that some more time because I really think certainly it's an interesting different sort of set of problems, just due to the nature of network and uncontrollable users and telecommuters and all that.  So it's enough different from certainly the related topics that we typically discuss, I wanted to give it some additional time.



LEO:  Yeah, we've never not done enterprise, but we've never specifically done it.  I think everything we talk about is applicable really to a wide range of computing.  Obviously a lot of IT pros listen.



STEVE:  Exactly.



LEO:  And I hesitate to just say this, you know, we're going to focus only on enterprise, because that would leave a lot of the audience out, as well.



STEVE:  Exactly.  And certainly we're not going to do that.  But we just - we would never - well, I guess my point is that solutions like what Peter talked about...



LEO:  That was great.



STEVE:  ...have all kinds of applications.



LEO:  Yeah.  That's useful across the board.  We talk about  high-end computing.  I think if you were to say what it is, it's high-end computing, which is applicable in a variety of situations, including the enterprise.  TWiT has never done much enterprise stuff because I've just never been that interested in it.  I've always been end-user focused.  Higher, higher end user, and high enthusiastic focused.



STEVE:  And we know that's where I come from, too.



LEO:  Yeah, yeah.  And, you know, even though this - it looks like a business, and we have advertising and so forth, we really do it for fun, too.  We want to cover the topics we're the most interested in.  I'm sure there are many enterprise security podcasts out there you can listen to.  Of course, none of them have Steve.



Javier Gordo of Katy, Texas wants sticky windows.  Oh, yeah.  Steve, you mentioned some time in the past a small app that would make Windows' windows edges sticky, so that they'd lock to the edges of the screen and to each other.  I changed computers.  I can't find the name of the app.  I miss it, and I've got to have it back.  What's it called?



STEVE:  Well, I loved this because I totally understand that sentiment.  The program is called allSnap.  And we've got a link to it in our show notes for this Episode #128.  But it's also just www.allsnap.org is the site.  It's a tiny little tool.  I have it running on every single one of my  Windows machines.  And when I, I mean, I almost want to, like, bring it with me if I'm forced to touch anybody else's Windows machine.  I mean, I just, it's - I don't know, Leo.  We've joked about it in the past.  I used to sit there, literally spending time trying to get my window edges lined up with the edge of the screen, just because I didn't want any - I didn't want it to go too far, I didn't want to see any background coming through, I like everything sort of positioned right.  And allSnap just, well, makes it a snap.



And it's funny, when I was doing a little digging around I ran across another piece of freeware that appealed to somebody who was also an allSnap addict.  It's called Taskbar Shuffle.  And it's now running on my machine.  It's very simple also.  It simply allows you to shuffle, that is, reorder your taskbar button.  It's funny because I have some things that start up at the very beginning when I boot Windows.  So they're naturally over on the left side of my taskbar.  And I sort of get used to them being there, like my email client will be over there.  But when I shut my email client down, and then later - as I have, for example, during the podcast - and later start it up, well, now it comes up over on the right, where newer apps are.  And it sort of bugs me because I'm used to it being over there.  Well, with taskbar shuffle you just, literally, you just click on the button, drag it over where you want it, and you're able to put them in any order.  It's like, and I have to say, I wished I had that for many years.  Now I do.  So there's also a link to Taskbar Shuffle in the show notes.  And if you just put Taskbar Shuffle into Google, it'll take you right to it.



LEO:  Taskbar Shuffle.



STEVE:  Oh, and you can also, if you care, reorder the little icons in your tray.  You hold Ctrl down.  You can grab the icons and move them around.  I'm less concerned about their order than I am my main Windows taskbar icons.  But anyway, now everyone knows about, or knows again about  allSnap, which I love, and about this new little gizmo, Taskbar Shuffle.



LEO:  It's good stuff.  Leo in New Jersey - I like that name - wants to keep control of his machines:  Hi, Steve, my name is Leo.  Somebody just tuning in is very confused right now.  I'm 16 years old, and I'm the resident IT guy everybody goes to for advice.  My question is this:  I have a downstairs computer I use as a torrent box, mom, dad, houseguest computer.



STEVE:  Sort of a throwaway machine.



LEO:  Yeah, let Mom and Dad use the torrent box.  Would Windows SteadyState work for me?  Oh, SteadyState, that's what we were talking about the other day.  I have my admin account as my torrent area, my limited account for Mom and Dad - Leo, you know how to treat your parents.  If I wanted to make a SteadyState account for my parents and another one for my houseguests, would that work?  Will I still be able to keep my admin account?  So let's say I have to add software to the whole machine, or update AV definitions, not just my account, how do I do that?  When I install software in the admin account, does it then go to the SteadyState accounts?  Also AV scanning, do I need to scan with an AV if I'm using SteadyState?  What, what, how does it work?



STEVE:  Well, we've never really needed an inter-episode teaser...



LEO:  But that was it.



STEVE:  ...but that's what this is.  Because Windows SteadyState is the topic of next week's Security Now! podcast.



LEO:  Cool.



STEVE:  So if Leo can hang in there for one week, we're going to answer all of those questions and talk in detail about it.  I've been working with SteadyState now for - I've been going steady with it for about four weeks.  I am very impressed.  I'm going to be recommending its use in all sorts of environments.  It really solves a bunch of problems.  And it would be a perfect solution for Leo to essentially control what his mom and dad and his houseguests do with that computer when it's not under control of Torrent.



LEO:  So just quickly, do you want to just kind of thumbnail what SteadyState does?  I think we mentioned it last episode, but just so people know what we're talking about?



STEVE:  Yes.  It is a free facility that is now being offered by Microsoft.  It was known in a sort of an unpolished prior version as, like, Shared Access Toolkit for Windows, something, I don't remember the exact name, but it was like that.  It has been matured and packaged into a single, simple, easy download.  And essentially it has some characteristics of System Restore, where you're able, for example, as we know with System Restore, to back up if something bad happens to your machine.  But it is way more  bulletproof.  It allows you to really lock down a system.



Its typical use is - and again, it's sort of hailing from the Shared Access area - would be, for example, a Windows machine running XP.  It needs to be XP.  Vista has this technology in some flavor built into it.  So this is not something for Vista.  This is specifically for Windows XP.  Nor will it run on Windows 2000.  It needs the features of XP.  But if you ever had a machine that you need to, sort of by nature, expose to a hostile environment - like for example in an elementary school, where you've got a lab of machines that you want to allow students to use, or in a public library where, again, you want to make some machines available for doing Internet research, yet lord knows what the computer users are going to do to them - this is a way of constraining what they can do, and at the same time protecting the machine from them.



My particular focus was in a corporate environment, which is the reason I really got focused on this, is would it be possible to allow the selective preservation of things, like the contents of a user's My Documents directory, which is not the default configuration.  But I worked all that out, and that's what we'll be talking about, in addition to many other things, next week.



LEO:  Goody goody, I can't wait to find out.  Well, you'll want to tune in Episode 129.  Our next thrilling, gripping edition of Security Now! will be on January 31st.  And meanwhile, Steve, have a great week.  And we'll see you then.



STEVE:  Perfect.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#129

DATE:		January 31, 2008

TITLE:		Windows SteadyState

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-129.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo examine and discuss Microsoft's "Windows SteadyState," an extremely useful, free add-on for Windows XP that allows Windows systems to be "frozen" (in a steady state) to prevent users from making persistent changes to ANYTHING on the system.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 129 for January 31, 2008:  Windows SteadyState.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!.  Steve Gibson is here, the security guru from GRC.com.  That's where you'll find, of course, SpinRite, his great program for disk maintenance and recovery, but also all those free security programs he's written over the years.  And our podcast, GRC.com.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.  As a consequence of the fact that you are actually in Vancouver right now as our listeners are listening to this, we recorded this episode #129 immediately after #128.



LEO:  A week ago.



STEVE:  Exactly, a week ago.  Consequently, I have not had a chance to have a week's worth of what has happened in security happening between now and then.  So I do not have any news for security.  However, when we record next week's Security Now!, which is actually two weeks from time we're recording this one and one week from the time people are hearing this one, why, we'll catch up so that no one misses anything and we don't miss talking about anything that was significant.



LEO:  Well, with any luck, nothing bad happened, and we didn't miss anything.



STEVE:  Exactly.



LEO:  Although that's unlikely.  But...



STEVE:  We're going to talk, as we mentioned at the end of last week's episode, about Windows SteadyState.  And in a sort of a bizarre coincidence, I wanted to share a listener's experience with SteadyState who also shared with me his experience with SpinRite.  So I thought I'd start off by sharing with our listeners - I believe Jim's last name is pronounced Gaydusek.  Anyway, the subject of his SpinRite note was "SpinRite Is King."



LEO:  I like that.



STEVE:  He says, "Hello, Steve.  Let me first start off and say that SpinRite is a definite tool for any technician's toolbox.  It has helped me save a few systems.  One in particular, the hard drive that was all but lost.  It was a friend's neighbor's system, and they have all their financial data on it, as well as personal info.  They supposedly had tried everything, and even took it to some of the name brand stores, and everyone stated that the drive was toast.  As a last resort, they brought this machine in.  And since I have the software, I tried it on this system.



"The system ran for four days straight.  You would think it was a lost cause after the workday was over.  But the next day SpinRite had moved a little forward, so we waited.  After the fourth day it stated that it was ready.  SpinRite said it had found some corrupted sectors and possibly some unrecovered data, but had recovered others.  But as we rebooted the machine, it booted up without even showing any signs of an issue.  The system worked like it was new, and as far as I know to this day is still working.  And this was a year and a half ago."



LEO:  That's kind of neat.  People ask me that, well, you know, they call in on the radio show and they say, you know, something that obviously sounds to me like a drive is - something's gone wrong with a drive.  And they say, well, should I just throw it out?  Is it safe to format and reinstall Windows?  And the truth is, if you have SpinRite, you don't have to ask that question.  You just run SpinRite.



STEVE:  Right.  He concludes, saying, "Thank you for a truly remarkable product that has saved many heartaches, and I am sure headaches, as well.  This is one I suggest to everyone I talk to who wants to know how to protect their hard drives and keep them in top working order."  And he signs it, "Your loyal customer, Jim Gaydusek, Shelley School District..."



LEO:  Oh, neat.



STEVE:  ..."Senior Tech and Network Admin."



LEO:  See, that's really who needs SpinRite.  Anybody who has multiple systems that they have to maintain, then it's a no-brainer.



STEVE:  You certainly get a lot of bang for your buck that way.



LEO:  That's just a no-brainer.  All right.  Let's talk about SteadyState.  Now, how did this come up?  We talked about it a couple of weeks ago; right?



STEVE:  Yeah, I don't really remember.  Well, for one thing, I ended up...



LEO:  It was a question.



STEVE:  I ended up stumbling on it maybe a month ago because I was trying to configure a system for a friend who was in a corporate environment.  She's an entrepreneur, wanted to set up a small network.  However, in the past she had the experience of hiring employees who immediately, after sitting down at their machine, started changing them.  You know, they would install their QuickBooks app because they wanted to do their personal check register on their work machine.  Or they would install iTunes so that they could update their iPods.  I mean, just basically they took for granted the fact that this machine was just like their machine at home and had no more respect for it than their machine at home.  And before you knew it, it was infested with spyware and malware.  It wasn't working right.  Corporate apps wouldn't function any longer.  And so she said to me, what can I do to prevent this from happening?



So interestingly, Jim in Shelley, who we found at the end of that note is the school district senior tech and network admin, he wrote a note to me about Windows SteadyState because we had mentioned it before.  I thought it would be fun to kick off our discussion of this with Jim's experience.  He says, "Hello, Steve and Leo.  First of all, thank you from the tech community for creating a show such as Security Now!.  On your last show, #127, Steve talked about SteadyState from Microsoft.  And I wanted to let you know that we use it here in our libraries, and it has been a godsend.  Before that, we had Windows 98 systems in the library, and always, always had problems with students messing up the works by doing whatever they wanted.  It was a nightmare.  Always, every other day, we were in there working on systems and restoring them or ghosting them back to their original state or removing any and all printers except the one that is supposed to be installed on them.



"Then we upgraded the machines to XP in our high school.  I also had another system in my middle school library called Xtenda, which is a hardware facility that allows you to have up to four sets of I/O running off one machine.  I had the SteadyState predecessor on there as well, along with the Xtenda hardware and setup, and it works wonderfully.  So now that I have XP in our high school, I'm able to use the new Windows SteadyState.  It took some working to get it working properly on the system without enabling the hard drive locking feature, but it is working.  I had to do a registry hack to keep the wallpaper from changing, but it works like a charm.



"The only problem I have had with it is that at one point there was an issue with system updates because it would lock the user profiles and not allow anyone to log on.  But after a number of reboots the systems were all back online and updated.  No real info on that problem on Microsoft's help site, but people with the same problem indicated that it just seemed to clear itself up.  As for the systems, they all now run wonderfully.



"I would suggest, though, to have a good machine to run this software.  The machines this is running on are slow Celerons with only 512MB of RAM.  The problem we ran into is that when you enable the system to lock the hard drive, it essentially makes a copy of the entire hard drive to a sort of swap file.  Then if you reboot it puts that image back to its restored state.  If you shut down and reboot, it takes about five to eight minutes to come up to a log-in screen because it has to recreate that image.  In a school environment, that's a little long for our taste.  And that's why I do not have that feature enabled.  But it still has enough additional features to safely lock the system to ensure no changes can be made to it.



"So those are just my thoughts on SteadyState and how we use it here.  Thanks for listening."



LEO:  So it can be used two ways.  It can kind of be a policy editor, as well as a way of getting everything back to the original state.



STEVE:  Yes.  I don't know how many of our listeners have ever messed around in what's called Windows Group Policy, or with the group policy editor.  But there are a phenomenal number of settings which are accessible.  GP Edit is the name of the group policy editor.  If you just go down to your Run line under the Start menu and put gpedit.msc, it's not an EXE, it's an MSC file extension that will run the group policy editor, where you can then begin to browse around and see just a phenomenal number of things that are in there.



One of the problems with the group policy editor is that many of the functions interact with each other, and they're really not very well documented.  It's almost like you have more control than you want, and essentially more responsibility than you want or perhaps need.  So one of the things that Windows SteadyState has done is it's surfaced, I would argue, the most useful things for this particular application.



So let's back up a little bit and talk about what this Windows SteadyState is.  First of all, we have a link in our show notes for this Episode 129 to Microsoft's page.  If you just Google "Windows SteadyState," all one word for SteadyState, it'll take you immediately to Microsoft's page where they talk about this.  They have it under their shared computing sort of environment or discussion because that's really how they think of this thing.  And certainly that's one of the applications.  It's what our listener Leo from last week was asking.



LEO:  The 16 year old who had - he was the IT manager for his house.



STEVE:  Exactly.  And so he wanted to be able to create a guest computer, or at least use his downstairs machine, when it's not busily sucking down torrents over the Internet, he wanted to be able to allow his mom and dad to use it, but prevent them from messing it up in any fashion.  And the same goes with a guest logon.  So he was wondering if SteadyState would be appropriate for that.  Well, it's perfect for that.  It was essentially designed for that.  The idea is that there is a hard drive protection technology which is built in.



Now, it's not quite as onerous in my experience as Jim's letter indicates because it does not make an entire copy of your system partition and/or drive.  Instead you set aside a block of hard drive space.  And using a feature, basically it's file system filtering, this is able to capture any changes which are made to the system drive.  And essentially it caches the changes.  So, for example, when any application, installer, literally anything you do, I mean, this thing is global.  You cannot turn it off without restarting Windows.  So it's not something that just sort of easily comes and goes.  I mean, this is meant to be bulletproof.



And I discovered the hard way that it even protects the partition table, and that first track of the drive which we were talking about recently could be prone to preboot kernel rootkits.  I was using something else that did deliberately change that first track, very much in a kernel rootkit fashion.  And that'll be the subject of an upcoming podcast because it involves performing whole drive encryption.  And it turns out that SteadyState uninstalled this thing, even though I had SteadyState sort of in a mode where it was supposed to allow changes to be saved.  So, I mean...



LEO:  That's good behavior.  That's kind of what you wanted in that case; right?



STEVE:  Oh, exactly.  I mean, if you got a preboot partition table and, you know, sort of outside of the partition virus, this thing wipes it out.  It removes it.  It says, we're not letting you change it.  So the point is that, at the sector level, anything that attempts to write to the hard drive, that is, to the system partition, it gets instead written into this cache region.  And then any subsequent reads are first checked in the cache to see if the sector is there.  And if so, they're read back from there.  So essentially it sort of quarantines any writes to the hard drive.  And then any reads come from there if there's been a change.



So the beauty of this, instead of putting, like, a write lock on your hard drive - which Windows won't tolerate because it's constantly updating the registry, and there's all kinds of things going on with Windows, as we know, our hard drive light is flickering there even when we're not doing anything.  So instead of write-locking the hard drive, it basically sequesters any writes.  And when the administrator logs off, the administrator being a special user to Windows SteadyState, it will prompt you, saying do you want me to retain these changes or flush them?  A normal user, a non-administrative user, does not have access to that.  There's no choice that they're able to make.



But SteadyState recognizes that an administrator may, in fact, want to run Windows Update to update patches, or want to run an AV scan, and may want an antivirus program to be able to update itself.  So there are instances where, when you're logged on as administrator, you would like to flush those changes, which were cached, back into the real file system to allow them to become permanent.  And so SteadyState allows you to do that.



Now, as I've been talking about it, I've been careful to say that the system partition is protected.  Windows SteadyState specifically only protects the Windows drive, that is, the drive on which the system is running, it's where - typically it's your C drive, where you've got your Windows or WinNT directory.  I guess it's probably going to always be Windows under XP unless you upgraded an older Windows 2000 system with a WinNT directory into XP.  So it's where that directory lives.  And there is no way not to protect any part of that.  So again, I'm impressed from a technology and an integrity standpoint that Microsoft said, look, if we're going to protect the C drive, we're going to protect the C drive, period.



This does create a problem in the scenario I was interested in because I wanted an employee of a company to be able to make changes to their system that were benign.  For example, their My Documents directory, they wanted to be able to use Microsoft Office to write documents.  They want to be able to put things on their desktop.  They want to be able to do things of a data nature, but not, for example, have their installation of QuickBooks or iTunes or whatever junk they bring from home to permanently alter their system.



So it turns out that it is completely possible to create another drive, for example, a D drive - I like D because it's short for "data" - and to simply drag the user's profile, drag their My Documents directory over to D, as well as their desktop.  And then it's able to persist.  So it turns out it's also very simple to set up a system with - it does require repartitioning.  For example, if a hard drive was only dedicated to a C, you would have to chop off some space for user documents.  In this case I had an 80GB drive, and I just chopped it in half so there were two 40GB partitions, figuring that, you know, 40GB is plenty for your typical office worker who's storing documents.



LEO:  But you could have two drives, or multiple drives; right?



STEVE:  Oh, you absolutely could leave - yeah, it's a very good point.  You could leave C exactly as it is, install a second physical drive, and set that up, for example, to be D:.  And then Windows makes it very easy to move a user profile over to another drive.



LEO:  Will it protect the stuff on the D drive as well as on the C drive?



STEVE:  No, and that's the point.  There you don't...



LEO:  I guess you don't want it to because that's your documents.



STEVE:  Exactly.  So the user's desktop, they're able to put things on the desktop, they're able to create shortcuts and so forth.  Then, beyond this, SteadyState has a whole bunch of really nice options specifically targeted towards exactly this application, locking a system down and prohibiting and limiting what users are able to do.  Sometimes I find that the best way to get a feeling for the functions offered by software is just to cruise around through the menus or look at the options.  So for our listeners, I have taken screenshots of the configuration screens for Windows SteadyState and put them on this episode's show notes page.  So it's just the episode notes for this episode, 129, has a series of just simple static screenshots showing the various options and settings which are available.



And so on a per-user basis you're able to do many things.  For example, you could require a logoff after X minutes of use, or a logoff after X minutes of idleness, which, you know, you can imagine in a library mode.  You might say, hey, this computer could only be used for 30 minutes by one person.  So you could force a logoff after 30 minutes of use.  And that lands on a user, and their time is up.  It's time to let somebody else use the computer.



Similarly, there are, in much the way that IE gives you sort of a number of different profiles - highly secure, high-medium, medium, low security - SteadyState offers the same sort of features for Windows restrictions.  So it offers you various ways of restricting Windows.  For example, and this is one that I like, you can prevent right-clicking in the Start menu.  Right-clicking is the way, for example, in the Start menu you're able to drag things around or rename objects.  You can just simply, in these options, in these extensive options, just say no, I don't want to allow that.  Or I only want to allow the classic Start menu.  You can do things like remove the My Documents icon.  There are things you would do, for example in a library mode, that you would not do if you wanted a basically useful, friendly computer that just refused to get itself infected, refused to have permanent software installed.  But one of the nice things about this, in a corporate mode, is you could install, for example, you could say, look, to your employees, if you install QuickBooks, eh, we're not happy about that.  But it'll be gone in the morning.



LEO:  So this is, again, this is a combination of policy editor and a kind of restore function.  And this is where I'm unclear.  If I can't protect the user's profile - so I guess it's a policy that's keeping him from making any changes.  But it does save any changes that he's allowed to make.



STEVE:  Well, nothing gets saved on the C drive.



LEO:  Right, I understand that.



STEVE:  So, yeah.  So, I mean, and that's just a hard and fast rule which I really appreciate because, if they started  making exceptions to that, you could imagine people would find ways around it.  So if you move the profile to a different drive, then you are able to allow documents and user profile-ish things to change.  So, for example, you could allow the user to change the icons that IE was showing.



LEO:  I see, I see.



STEVE:  But there's a policy, one of the options down there in the details, for example, under Internet Explorer is prevent them from making changes to that.



LEO:  So if you're using this at a hotel, and you don't want any of the user's changes to be persistent, you just make everything on the C drive.



STEVE:  And that's - yes, exactly.



LEO:  And if you're using it at a school, where you want students to have their own individual profiles with their own individual documents, that's when you create that second partition or the second drive, because that's - and then, of course, policy is still effective, but they can presumably create their own stuff.



STEVE:  Exactly.  And I've been playing with this now for a couple weeks.  And, I mean, it's a little unnerving.  I just have my - I have my habits, you know, I right-click on the desktop, and up comes a little warning saying your administrator has prevented you from making any changes on the desktop.  It's like, whoa, okay, sorry.  But, you know, I'm glad because I checked - one of the little checkboxes was prevent people from changing screen resolution or basically messing with the machine in a way that you don't want them to.



LEO:  Right.



STEVE:  Anyway, it's a - I've been very impressed with it.  One of the simple little checkboxes is prevent write access to USB storage devices.



LEO:  Oh, fantastic.



STEVE:  And so just by checking that - it's funny because it caught me out, also.  I use, as we've talked about, Drive Snapshot.  And I was making snapshots of the C and D drive as I was going along.  And so I started getting an error.  It's like, wait a minute.  Oh, and I think I was - I'm sure I was logged in as administrator.  So even the admin user...



LEO:  Oh, interesting.



STEVE:  Because this was global, and it requires a restart of the computer.  So once again - so, yeah, I'm looking at the screen, it says "under computer restriction."  So this is whole computer restrictions.  And so when I realized that I had locked myself out of writing to an external USB drive, it's like, oh, shoot, I did that.  So I turned it off, but it said, you've got to reboot.  So again, these things are running deep in the system and are not easily circumventable.  I really - to me it looks like Microsoft has done a great job.



LEO:  Now, this is free.  And as far as I can tell from the website it's Windows XP only.



STEVE:  Yes.  It's XP only, first of all, because none of this technology existed back in Windows 2000.  So Win2K is too old to take advantage of this.  And there is language on the SteadyState pages saying that Vista incorporates enough of this that they didn't do this for Vista.  I'm guilty of not knowing Vista well enough to be definitive on what features Vista offers that are like this.  But with any luck, many of our listeners are still on XP.



LEO:  Well, this is a good reason to stay with XP, frankly.



STEVE:  Leo, this is a neat tool.  Yeah, I am very, very impressed with what this provides because it is simple to install.  In the default configuration, where users are going to be on the system drive, that is, user profiles will be there, for example, I'm sure this is the case with the way Jim has set it up in his school libraries.  You want kids to be able to use the machine, but it - I mean, he was talking about reghosting and reimaging these things in order to bring them back to sanity every morning.  Here, this thing, it will allow - it's plastic while you're using it.  You can do things.  Things all work.  But when you log off, everything you did disappears, and the system is returned to a steady state.



LEO:  Now, if you're listening, like me, and saying, well, why didn't I know about this, this is fairly new.  It only came out a few months ago.



STEVE:  Right.



LEO:  So it's not like it's been around for XP all along.  But I have to say, you know, I mean, here we are sitting with Vista.  If you put this on your home system, you know, your home network, with XP, you'd be more secure than Vista.



STEVE:  Microsoft doesn't suggest that this replaces antivirus software.



LEO:  But wait a minute, I mean, how could a virus infect you if you've got this running?



STEVE:  That's what I think, too.  I think that they're just hedging their bets.  They're not wanting to piss off the AV vendors, either.  They've go documented compatibility with a small number of antivirus software, where SteadyState recognizes the AV you're using and is able to permit some compatibility with it in order, for example, to allow patterns to be updated.  Users of specific AV software will have to take a look and see if it's automatic or not.  One of the issues that Jim talked about is mentioned in the FAQ document that goes along with this, and that's relative to Windows scheduled software updates.  SteadyState has the ability, for example, to run Windows Update at 3:00 a.m. if the machine is on and allow it to properly synchronize and receive Windows updates, which will then be made permanent.



LEO:  Even better.  So it's a kind of automatic Windows Update.  It's locked down.  By the way, I just sent you a link.  There is a beta for SteadyState 2.5 that is Vista compatible.  So they're clearly developing it for Vista.  It's just it took them five years to do it for XP, and they're only now getting around to doing it for Vista.  Now, this came out in November, so I have a feeling it's probably pretty stable.



STEVE:  I'm glad to know that because, again, there may have been features buried somewhere, lord only knows where, in Vista.  But one of the things I like about this is this is just turnkey.  It is easy to use.  Now, one thing I had...



LEO:  Who shouldn't use this?



STEVE:  It gets in your way a little bit.  Jim mentioned the problem of starting up the machine and how long it takes to boot.



LEO:  Yeah, eight minutes and all that, yeah.



STEVE:  Yeah.  In my experience there is a pause after you log on, where I've been asking myself, okay, what is it doing?  Well, it's not writing and reading the drive because I looked at the drive lights.  And the drive lights...



LEO:  Oh, interesting.  You'd think it would just be copying all the cached stuff back onto the C partition.



STEVE:  Yeah.  I'm not sure what's going on.  But there does seem to be a pause in the process.  And I thought, well, maybe it doesn't like other things that I've got set up.  So I stopped services, and I experimented with it.  It's when I stopped the SteadyState service that it did it then, booted right into the desktop.  With the SteadyState service running in the background, there was that delay.  But again, in my mind, no way was it eight minutes.  It was maybe 30 seconds.  And so it's like, okay, well, that...



LEO:  Well, he could have older, slower computers.  I mean, he may not...



STEVE:  Well, and in fact he did mention that those machines were slow Celeron machines with only 512MB of memory.



LEO:  There you go.



STEVE:  Now, one thing about SteadyState is it tends to be aggressive with the size it would like to have for its cache.  In the installation instructions it instructs you to defrag your drive.  So of course they're trying to cram all of your used space to the front of the drive, leaving a big chunk, a contiguous area of free space.  By default, it takes half of your remaining free space.  Well, that's ridiculous.  If you have a 120GB drive, and you've got a relatively new Windows system that maybe only has 12GB in use, you know, you don't want to lose half of that.



The good news is, you are able to tune the cache size down as small as you want.  I don't really know why it just grabs  half of the available space without limit, but that's what it does.  There's no reason not to tune the cache size down to maybe 3 or 4GB and control how much space it's got for its cache.  There is documentation that says, well, if users made lots of changes, they might get a dialogue saying they have to log off in order to allow this cache to be flushed.  So but my sense is, again, it's a little bit underdocumented at this point.  It's not clear to me why you'd run out of space unless you had, for example, 50GB of active space, and your cache was only a few gig, and you tried to change more than that many gig of storage.



LEO:  I would think the same size as your Windows, you know, your Windows partition, you know, it should be enough.



STEVE:  Yeah, exactly.  And so that's the assumption under which I've been operating.  And I have never had it tell me that I've run out of space.  And I've been pounding on it and using it.  And I'm really impressed, Leo.  This thing is very cool.



LEO:  I'm blown away.  I'm going to start recommending this.  It sounds like anybody who maintains a number of systems with users that are unruly, whether it's your teenage kids or your schoolchildren or your customers in an Internet caf, this is an absolute win.



STEVE:  And again, I cannot under- I mean, Microsoft is saying you still need to use AV.  And it's like, okay, well, I mean, you and I don't, Leo, anyway.  So, I mean, it's not like...



LEO:  It's belt and suspenders.  They're selling OneCare, and they don't want people to not buy OneCare probably.  I mean, there may be - it's possible for a virus to get around the SteadyState restrictions.  We don't know how secure they are.



STEVE:  That's a very good point.  And again, when software running in your machine is trying to protect you from other software running in your machine, we always know there's going to be a cat-and-mouse conflict there, you know, Spy vs. Spy sort of thing.  But this, I mean, I'm very, very impressed.  So I absolutely wanted to bring this to our listeners' attention because I'm sure, I mean, as people are  listening to this, they're thinking, oh, my god, that's exactly what I need for Aunt Sarah.



LEO:  I'm tempted to install it on the machines I use just to protect them so that I can't do anything dumb.  And then I can always get back to a known state.  You know, I mean, for instance, there's a Windows machine I use pretty much exclusively for recording and editing in Adobe Audition.  That's exactly what I'd like, that I could always get back to a known good state every morning.  Just reboot.



STEVE:  Well, and even in the case that the C drive will not change, all you have to do is either partition that into half, or use a second drive that's D.  There's no protection at all on anything other than C.  So that's something people have to understand, but it's also useful because it means you can have a data drive where you absolutely know SteadyState is not going to get in its way.  And so you're never going to have a problem with things you thought were safe not being safe.



LEO:  Well, and I've always kept a separate data drive for my Windows drive.  So it's just a natural way of operating for me.  So this is really neat.  Now, I do remember there's a commercial program that does something similar, and I just can't remember the name of it.  But I've had people tell me, you know, IT pros tell me about it, and that's what they've been using up to now.  But this is free.  It's from Microsoft.  Seems like it's a much better solution that GP Edit.



STEVE:  Well, yeah. And for example, here under general restrictions, prevent autoplay on CD, DVD, and USB drives.  It's just - you just click that on.  And now if some smart aleck, you know, thinks he's going to get around your restrictions by using a CD - oh.  There is in the FAQ a question of whether or not system would boot for a USB or a CD.  And so they specifically address the fact that, yes, if you boot something ahead of Windows, it will have your machine.  So in a lockdown mode you would want to also tighten down the BIOS.  You would want to remove anything but the hard drive from the boot order in the BIOS and, you know, maybe turn off the CD in the BIOS if that's available.  But here, you know, by just setting a checkmark, you disable autoplay.



LEO:  Well, that's great.  You can turn off that U3 thing.  I mean, if you're in a library, man, you want to turn off U3.



STEVE:  Yup.  I mean, here's prevent access to task manager.  Oh, there's also a complete screen that easily allows you to blacklist programs.  So you're able to say, for example, I do not want any of the following programs.  And so this lists all the programs that you've got installed, and you simply move - you either click "Block All," or you're able to move them one by one over into the blocked programs list, and they will no longer run.



LEO:  Good.



STEVE:  So, I mean, it makes it very simple to lock a system down.



LEO:  Steve's got some great screenshots, so you can see this before you install it, and all the different settings and so forth, at his website.  We'll put those show notes, the links in the show notes, and you'll have it at GRC.com/securitynow.  And let's add a link to that SteadyState beta for Vista because I know there's some Vista users probably would love to have this.  Although, to me, this is one more reason to stick with XP.  I mean, why not?



STEVE:  Yes.  They've done a great job with this.  And I will mention that, if people want to play with it to experiment with it, it uninstalls nicely and cleanly.



LEO:  Oh, that's good to know.  That's really good to know.  So you can always go back.  GRC.com, that's Steve's site.  That's where you'll find, of course, not only show notes, 16KB versions of the show, Elaine's written transcriptions so you can follow along, and even some great free programs for securing your system.  Not to mention SpinRite, my favorite disk recovery and maintenance utility, SpinRite.  It's from GRC.com.  Well, Steve, this is a find.



STEVE:  Yup.  I'm really, really glad we were able to turn out listeners on to it.



LEO:  Really cool.



STEVE:  And we'll be back next week with Episode 130, that'll of course be a Q&A episode.  Anyone who has questions or findings about SteadyState or any other comments or topics, please don't hesitate to go to GRC.com/feedback.  Send your notes and thoughts to me, and we'll cover what we can of them next week.



LEO:  And tell me what the name of that commercial program is that does the same thing.  It's just - same idea, you reboot the machine, it goes back to the pristine state.  I can't remember the name.  It's driving me crazy.  Steve, thank you so much.  Have a great week.  And we'll be back next week with another great Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#130

DATE:		February 7, 2008

TITLE:		Listener Feedback Q&A #34

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-130.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson and Leo Laporte, Episode 130 for February 7, 2008:  Listener Feedback #34.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, ladies and gentlemen, and I'm so glad to see Mr. Steve Gibson on the other side of the microphone.  Hello, Steve.



STEVE GIBSON:  Hey, Leo, great to be back with you once again.  Episode 130, 130.



LEO:  130, it's amazing.  Separated only by the state of California.  I'm in the north, you're in the south.  And so actually, if I were to see you across the microphone, it'd be very dim and tiny.



STEVE:  Yeah, well, you would have exceedingly good eyesight.  Actually, I think the curvature of the Earth would completely preclude that.



LEO:  I think you're right.  You're a scientist at heart, and you can't get away with any of this fantasy stuff with you.  No, I'm just finishing - not finishing.  I'm really in the middle of "Nights Dawn Trilogy."  Actually, you can't finish it.  It's the world's longest book.  The "Night's Dawn Trilogy," Peter Hamilton, really great.



STEVE:  Oh, are you loving it?



LEO:  Yeah, well, it took a little while to get into.  I couldn't - because there's so many storylines in it.



STEVE:  Yes.



LEO:  And they're very diverse storylines, you know.  So it took me a little  while to kind of start piecing it together.  But that's part of its charm because once you do - I don't know how many pages in I am because the Kindle only gives you paragraph markings.  But once you get a little far in on it - I'm three dots in, three or four dots in.  And...



STEVE:  Oh, and you probably have, like, 20 dots to go.



LEO:  Oh, it's a big book.



STEVE:  Yeah, yeah.  And it...



LEO:  Well, the Kindle always has the same number of dots.  Have you noticed that?



STEVE:  Yes, although the, I mean, it is a proportional...



LEO:  Right.



STEVE:  It is a proportional display, so...



LEO:  Right.  Hey, there's some cool Kindle hacks.  I know, I think you mentioned this the other day; but do you know about the one that, where you turn the radio on and then go to the Kindle browser, if you press Alt-1, it'll open up the Google Maps at your location?



STEVE:  No.



LEO:  Yes.  Yes.



STEVE:  Very cool.



LEO:  Because the cell - well, at your location.  It's the nearest cell site.



STEVE:  The only thing I really want is an onscreen clock.



LEO:  Okay.  That's one of the hacks.



STEVE:  Yay.



LEO:  I'll tell you - I'll look it up, and I'll tell you before - because I don't have it right in front of me.  But there is a simple keystroke that will put a clock on the screen at the bottom of the menu.



STEVE:  Oh, no kidding.



LEO:  Yeah.



STEVE:  So it's already built in there somewhere, it's just hidden.



LEO:  Exactly.  There are a - you know, the Kindle actually had a bunch of, a surprisingly large number of undocumented keystrokes.



STEVE:  Well, it's impossible to ever surprise you about anything going on in the industry.  But I had a note here to mention to you that Amazon is buying Audible.



LEO:  Yeah.  Yeah, that didn't surprise, I mean, that surprised me.  But, yeah, we've known about that for a little while.  And actually Audible is now a sponsor of this show, as well.  Happy to have them onboard.  They're on every show.



STEVE:  You mean Security Now!?



LEO:  Security Now!.



STEVE:  Oh, no kidding.



LEO:  They're on every show on the TWiT network.  They're a big - in fact, the day before the announcement, I got a very nice email saying how happy they were, how they looked forward to 2008 and a great relationship, and they were going to renew this through the rest of the year.  And then the next day Amazon bought them.  Now, I don't know if that's, you know, how that's going to affect anything.  So...



STEVE:  Right.



LEO:  But nevertheless, it was, you know, yeah, a little bit of a surprise.  So the guy you'd be interested in who hacked the Kindle - actually, I'd love to get Amazon as a sponsor.  Goodness knows, Kindle should be advertising on this show.



STEVE:  Have you see the count on my review on Amazon's site?



LEO:  How many?



STEVE:  It's, like, 11,000, I think.  It's way more than twice the #2 review, so.



LEO:  Well, you'd like this Kindle hack because the guy who did it, I'm still Googling around to try to find - oh, it's Igorsk.  The guy who did it, this is - he got the ROM code, disassembled it, and figured it out.



STEVE:  Oh, beautiful.  So pure reverse engineering.



LEO:  Yeah.  I mean, beautifully, beautifully done.  It's just really remarkable.  He starts by figuring out how to get root on it.  And then he is able to download the code, disassemble it, and that's how he finds all these undocumented keyboard shortcuts.  So let me find the time one.  There's Minesweeper in it, by the way.  Did you know that?



STEVE:  You know, I may have run across this article because I remember seeing...



LEO:  You talked about it, I think...



STEVE:  Yeah, I remember seeing a whole list of goodies.  But I did not - it didn't click with me that a clock was among them.  So maybe there's a newer list.



LEO:  So Alt - okay, there's a couple.  In the reader, at home, Alt-t shows the time.  Do you have your Kindle in front of you?



STEVE:  No, I don't have it in front of me.



LEO:  Okay, this is so very funny.  Well, I won't tell you what happens.  When you're reading, do an Alt-t.  Oh, I'm going to tell you.



STEVE:  Okay.



LEO:  It doesn't show the time digitally.  It spells it out.  It says, like, half-past six.  Because you're reading.  So I thought that was funny.  Alt-t, that's what you need to remember.



STEVE:  So the people who did this clearly had some fun.



LEO:  Igorsk.  Igorsk did it.  And...



STEVE:  No, no, I mean the Amazon guys.



LEO:  Oh, there's tons of stuff in there.  Oh, yeah.  And it wasn't at Amazon.  It was Lab126.  So if you go into settings and enter some numbers, you can see the Lab126 team members if you enter 126.  They clearly did.  There's a lot of stuff in there that is kind of not documented.  So anyway, I just thought I'd pass that along.



STEVE:  That's very cool.



LEO:  We have also Astaro back with us, so I'm going to do an Astaro commercial in a little bit.  But do you have, before we do that, do we have any addenda?  Oh, and we should tell people, this is a Q&A episode.



STEVE:  Yup, Q&A episode.  I've got all kinds of stuff.  I did want to mention that Yahoo! joins the ranks of being an OpenID authentication provider.



LEO:  Yes.  Isn't that great news?



STEVE:  Yup.  So they're now supporting OpenID, which I hope will do a lot to promote OpenID.  Unfortunately, they're only a single-factor authenticator.  So, you know, they're not competing with VeriSign's VIP.  And in fact it'd be very cool if they were to add that to VeriSign.  So if we've got Yahoo! members who would consider using Yahoo! as an OpenID provider, you might drop Yahoo! a little note through their support link and say, hey, how about adding VIP  authentication because it's going to be even more secure that way, as we all know.



LEO:  Of course we all know, if Microsoft buys them, then who knows.



STEVE:  Yeah, I was wondering about that, too, so.



LEO:  I mean, I'm actually a little disappoint- I hope that doesn't go through because I think - I like Yahoo!, and I like their range of services, and I like their support for things like open source and OpenID.  And of course all that would change if they were a Microsoft company.



STEVE:  Yeah, well, we've got, you know, hungry Ballmer is out scouting around, trying to get them, so...



LEO:  He's trying to beat Google, is what he's trying to do.



STEVE:  Let's hope not, yeah.



LEO:  Also I have a couple of addenda when you're done.



STEVE:  Yeah.



LEO:  Just to let you know.



STEVE:  Okay.  Well, I've got - I did want to mention that I'm loving Jungle Disk.  It just updated itself, or told me that there was one.  It's up to 1.50c, and he's been fixing little things here and there.  So, I mean, I'm just - I got my bill from Amazon for last month?  10 cents.



LEO:  I know.  I got 3 cents.



STEVE:  And I have a ton of stuff up there.  And, I mean, I just love it because I can - if there's something that I absolutely want to have universal access to, like I'll drop some - I just sent - I sent 120MB up there because I don't have my laptop with me.  But when I do next, I'll want to be able to yank that thing down from Amazon.  So it's just sort of, you know, it's data storage in the sky, and it's not very expensive.



LEO:  And Jungle Disk makes it look - it's WebDAV, right, so it makes it look like a mounted disk.



STEVE:  Yes.  Under XP and Vista, the WebDAV client is built in.  So you're able just to map it to a drive.  I'm still using Windows 2000.  I did find a - I found a product that allows, that essentially adds that feature to Windows 2000, although there is the ability right now just to browse to that sort of like a folder, where you don't have a drive mapping.  And I find that's just as convenient as having it as a drive letter.  It wouldn't be, however, if I needed to, like, automate things, like use my own backup solution rather than the one that's built into Jungle Disk in order to do that, so.



LEO:  Yeah.  Because looking for a drive letter is so much easier.  Every program can do that.



STEVE:  Well, I've got two really fun security event stories.  This one's just going to boggle people's minds.  It's funny, years ago, many, many years ago, I remember refusing to talk to my attorney on my analog cell phone at the time because I knew that it wasn't secure.  And that was probably my - and I remember him thinking, c'mon, Steve.  I said no, no, no, no, I'm in the car right now.  I'll call you back when I get to the office because this is a radio, and I'm not having a conversation with my attorney on an analog cell phone.  And so he's like, okay, fine, well, call me back.



LEO:  And you were right, by the way.  I've talked to many guys, many hackers who just kind of made a habit of listening into analog cell phone recording...



STEVE:  Oh, some, I mean, you could have some fascinating things that you would overhear.  And so it's like, radio, I mean, I know that listeners of Security Now! know how skeptical I've always been about radio.  Well, this story that just surfaced just really drives this home.  This was written, this was posted on DarkReading.com by Steve - I'm going to wreck his name.  But I'm not - I'm sorry, Steve, I'm trying not to.  It's Stasiukonis, something, Stasiukonis, something.  Anyway, he's a VP and founder of Secure Network Technologies.  They are a security penetration testing firm.  Okay, now, this is a true story.  And it's got a serious theme to it because there's one other area of wireless that is still - people are not thinking about it.



Anyway, he says, in offices all over the world, users are becoming increasingly enamored with those wireless, hands-free headsets that allow the speaker to move around the office while continuing a conversation on the phone.



LEO:  You're not talking cell phone headsets.  These are for land lines.



STEVE:  Exactly.  So instead of having the coiled cord where you're having to stretch that around, you replace it with a little base station and wireless headset.  And he says, have you ever wondered how secure those headsets are?  So have we.  Recently we had the chance to find out.  And what we discovered was downright scary.  If you don't know us, Secure Network Technologies is a penetration testing firm that focuses closely on the issues of physical security and social engineering.  We were recently hired - okay, so they were hired, so what I'm about to describe here is legal.  They were hired by a large organization to assess the company's network security and other potential vulnerabilities.  Always anxious to try new things, we asked to test wireless signals leaving their building, including wireless access points, radio frequencies, et cetera, and potential vulnerabilities in those hot little hands-free headsets.



To perform the work, we purchased a commercially available radio scanner.  These devices are available at any local electronics retailer at prices ranging from $80 to several thousand dollars.  We chose a scanner capable of monitoring frequencies from 900 to 928MHz and the 1.2GHz ranges, which is where many of the popular hands-free headsets operate.  We took a position across the street from the facility and started up the scanner.  Within seconds of turning on the device, we were able to listen to conversations that appeared to be coming from our client's employees.  Several of these conversations discussed the business in detail, as well as very sensitive topics.



After some careful listening, we determined that the conversations were indeed coming from our customer.  After confirming that the source of the conversations were on our client's premises, we made note of the specific frequencies that were used and locked in on them.  We could then record the conversations digitally using the scanner.  Within minutes of this discovery, we contacted our customer and explained the vulnerability.  We felt this issue could not wait for our final report.  To demonstrate the sensitivity of what we discovered, we used the conversations we recorded to social engineer our way into the facility.



LEO:  Oh, boy.



STEVE:  We gathered the names of people mentioned during conference calls, as well as other specifics about each person.  We then singled out people that were foreign to the location we planned to enter.  We singled out the names of people whom the callers had never met, people who had never been to the location, and people who were new to the organization.  Our plan was to assume an identity of an employee who had never been to the office we were testing.  Using that identity, we would enter the building, commandeer a place to sit and work, then see how long we could stay inside the building.  After zeroing in on a particular employee, we gathered as much intelligence on him as we could.  To prepare for the entry into the facility, we printed a business card with our assumed identity.  I put on my best suit...



LEO:  This guy likes his work way too much.



STEVE:  Oh.  I put on my best suit, he says, and then went to work.  When I entered the building, I was greeted by security.  I indicated I was an employee and was in town to work.  I handed the security guard a business card and was welcomed with a smile.  After escorting me to a cubicle, the guard showed me where the restroom was, where I could get a cup of coffee, and how to go about getting a building access card.  After settling into my new workspace, I plugged my laptop into the network, started my network scanning tool, and retreated to the cafeteria for lunch.  Upon my return I was presented with a card access key to the building.  The card was accompanied by a document outlining security policies regarding its usage.  Clearly the people who issued it never checked deeper into who I really was.



With access card in hand, I started exploring the building.  I had almost complete access.  In the few places where the card did not work, such as the server room and fitness center, I used additional social engineering tactics to gain access to those, as well.  By day two I was already accepted as an employee.  In the morning I greeted - I was greeted by my would-be coworkers and security folks.  I began to take some liberties such as booking conference rooms, asking for refreshments, and gaining permission to bring in a "vendor," unquote, actually Doug Shields, my partner here at Secure Network.  In all, I spent three days inside the building, gaining access to numerous types of information, resources, and technology.



LEO:  Oh, my goodness.



STEVE:  Our social engineering effort was just one exploit.  The real danger is the information that was being emitted across the street from the company through the wireless headsets.  This technology is convenient, but it is opening companies to potential calamity.  With the data we heard, we could have made a stock play, provided valuable information to a competitor, or gone to the press with scandalous data.  We also noted that when conversations ended, the headsets became bugging devices.  Even after calls were terminated we could hear headset-wearers breathing, as well as any other conversations that were going on in their offices.



LEO:  Oh, my goodness.



STEVE:  We were interested in this vulnerability, so we asked for permission from other clients to test it out at their locations, as well.  We ended up intercepting communications ranging from financial institutions, healthcare, and a variety of other professions and industries.  We heard conversations from administrators of computer networks, C-level - that is to say CEO, CIO and so forth - C-level executives, legal departments, and management teams.  What did we prove?  That many companies which fear security breaches and eavesdropping are actually bugging their own offices and spilling their private content over the open airwaves without their knowledge.



LEO:  Unbelievable.



STEVE:  The problem is not unlike the early days of wireless LANs and WiFi when the technology became popular before adequate security was developed.  What can you do about it?  The first step is to recognize the vulnerability.  These headsets generally operate at 900MHz and, as we learned, are not necessarily secured with encryption.  Find out who's using the technology and where.  Secondly, you should consider doing a scanning test of your own, as we did for our client.  It's worth 80 bucks to make sure your corporate secrets are not unintentionally leaking out of the building via wireless headsets.



LEO:  Now, just to make it clear, these wireless headsets aren't the same as, say, a cordless phone, or are they?



STEVE:  No.  These are add-ons to typical corporate phones.  I mean, I've got one around here somewhere.



LEO:  Oh, yeah, I have a Plantronics right here, I'm looking at it.



STEVE:  Yes, very much like that.  And they are simply trans- I mean, this is exactly like me refusing to talk to my attorney on an early analog cell phone.  I mean, arguably that was even worse because there you've got serious range.  But these things work across the street.  And, I mean, in this case this guy, simply by overhearing conversations, was able to function as an employee in a company where he wasn't employed.  The higher ups knew and gave him permission to do this.  But that permission was entirely optional.  I mean, anyone could do what this, you know, Steve and his partner, was it Doug or David, were able to do.



LEO:  That's just amazing.



STEVE:  So I just wanted, I mean, this report, I just read this, I thought, okay, we've got to talk about this.  I mean, just the idea that these little - they're basically handset extensions.  And, you know, people who use them are bugging themselves.



LEO:  Yeah, wow.



STEVE:  Okay.  Second amazing story of the week.



LEO:  Okay.



STEVE:  This is also frightening.  I mean, this is - what I'm about to read is horrifying and true.  It was posted by a blog at Symantec, describing an amazing trojan known as Silent Banker.  What's really fun about this, too, is that - I'm going to read the blog entry.  It touches on so many things that we have already talked about.  So, I mean, this is a little bit of a walk in the park for our listeners.  But the blog entry was titled "Banking in Silence."



Targeting over 400 banks, including my own, writes this blogger, this Symantec blogger, and having the ability to circumvent two-factor authentication, are just two of the features that push the Silent Banker trojan into the limelight.  The scale and sophistication of this emerging banking trojan is worrying, even for someone who sees banking trojans on a daily basis.  This trojan downloads a configuration file that contains the domain names of over 400 banks.  Not only are the usual large American banks targeted, but banks in many other countries are also targeted, including France, Spain, Ireland, the U.K., Finland, Turkey, and the list goes on.



The ability of this trojan to perform man-in-the-middle attacks on valid transactions is what is most worrying.  The trojan can intercept transactions that require two-factor authentication.  It can then silently change the user-entered destination bank account details to the attacker's account details instead.  Of course the trojan ensures that the user does not notice this change by presenting the user with the details they expect to see while all the time sending the bank the attacker's details instead.  Since the user doesn't notice anything wrong with the transaction, they will enter the second authentication password, in effect handing over their money to the attackers.  The trojan intercepts all of this traffic before it is encrypted.  So even if the transaction takes place over SSL, and of course we know we certainly hope it would, the attack is still valid.



Unfortunately, we were unable to reproduce exactly such a transaction in the lab.  However, through analysis of the trojan's code, it can be seen that this feature is available to the attackers.  The trojan does not use this attack vector for all banks, however.  It only uses this route when an easier route is not available.  If a transaction can occur at the targeted bank using just a username and password, then the trojan will take that information.  If a certificate is also required, the trojan can steal that, too.  If cookies are required, the trojan steals those, as well.  In fact, even if the attacker is missing a piece of information to conduct a transaction, extra HTML is added to the page to ask the user for that additional information.



And he shows two screenshots here.  I made a shortcut for this blog entry because it's really worth looking at for our listeners.  It's just SnipURL.com/sn130.  That's the episode number of Security Now!.  So anyone can put SnipURL.com/sn130, and they'll get this blog posting.



He goes on to say, when instructed, the trojan can also redirect users to an attacked-controlled server instead of the real bank in order to perform a classic man-in-the-middle attack.  Currently there's only one bank targeted in this way.  However, recent updates to the trojan - oh, and get this.  It gets constant updates using updated software.  He says...



LEO:  If it's working, why not?



STEVE:  Yes.  Recent updates to the trojan change the user's DNS settings, which we were talking about just recently a couple weeks ago, change the user's DNS settings to point to an attacker-controlled DNS server.  Using this technique, the trojan can start redirecting any site to an attacker's site at any time.  This feature could also mean that, if the trojan is removed, but the DNS settings are left unchanged, then the user will still be at risk.  See below for the attackers' DNS server addresses.



Add to all of the above the ability to steal FTP, POP, webmail, protected storage, and cached passwords, and then we start to see the capabilities of this trojan.  But it doesn't stop there.  Don't forget the porn.  The trojan also contains over 600 pornographic website URLs that can be shown to the Internet user so that the attacker can make money from the referrals.  Lastly, the trojan can also download updates, which it regularly does.  It can also upload other executables and can use the infected image as a proxy or as a web server on any chosen port.  In tests, the HTTP port used was 18102.  The multiple configuration files that the trojan downloads are updated several times per day, so it's more current than Windows is.



LEO:  More current than anything.



STEVE:  Yeah.



LEO:  More current than Norton Antivirus.



STEVE:  And currently the trojan is capable of injecting HTML into about 200 different URLs, meaning that, as a web page is being displayed by the user's browser - and this thing knows about both Internet Explorer and Firefox - as the web page is being displayed, the trojan is able to intercept that communication and insert its own modifications, its own HTML, into the page.  He says, the configuration files are compressed and encrypted.  However, after decrypting them we can see how the trojan works in detail.  And then he goes on into some additional details, which many of our listeners may find interesting.



Anyway, I mean, this is a beautiful posting because it gives you a sense for just how sophisticated trojan technology is becoming.  And, I mean, how much effort people are willing to go to for this kind of high-value attack.



LEO:  Well, it also introduced to me a new category.  I never heard the phrase "banking trojan."  But obviously these are trojans aimed at corrupting your Internet banking experience; right?



STEVE:  Exactly.  So you're right.  There is now a classification of trojans, a set of trojans, of which this is perhaps - and this guy, from everything he's seen - is the most sophisticated one of all.  And for, well, for one reason.  It's not like it's one trojan for one particular bank.  And so you're - how many - what's the chance that the infected user is going to...



LEO:  400 banks.



STEVE:  Yes.  And it's got specific scripting technology in order to deal with each one on a bank-by-bank basis.



LEO:  So just to understand, it would get on your computer as an end-user, and it would intercept information about your banking login, basically.



STEVE:  Correct.  Essentially you really don't want this trojan on your machine if you're someone who does online banking.



LEO:  And he mentions it's all over the world.  I mean, it's not just U.S. banks, it's banks all over the world.



STEVE:  Right.



LEO:  Wow.  So, something to be aware of.  You know, banks, I think, routinely cover up these kinds of losses.  But this is a loss to you.  This wouldn't be a loss to the bank, exactly.



STEVE:  Right.  Exactly.  You might very well go to check your balance and find that it has been zeroed.  Because this thing watched you log in once.  And, I mean, might right then have executed a funds transfer.  If not, it knows how to - it's able to send this back to headquarters, and then somebody else can log in as you, even if, as this thing, I mean, this thing is so comprehensive that whatever authentication data is necessary - it understands, for example, you know, grabbing cookie details.  So somebody could literally pretend to be you, even if you had static cookies on your machine to identify you.  And, for example, we've talked about how authentication strength is reduced in instances where you do have a cookie because you've already authenticated your machine to the bank once before.  And so it says, oh, well, you know, here's a cookie we recognize.  We'll only ask for the username and password and not, you know, which kitten the guy, you know, has chosen in the past.



LEO:  Right, right.  Hey, I had a couple of emails I wanted to just fill you in on.  One is from - actually I got it from a number of people.  But Rami was the first, he's a level designer at Ubisoft Montreal.  Deep Freeze was the name of the program I was trying to remember.  We were talking about Windows and Microsoft's capability of, what was the name of the Windows...



STEVE:  SteadyState.



LEO:  SteadyState.  So Deep Freeze is from Faronics.  And I've had a number of people recommend it to me in the past, does something very similar.  It kind of resets the machine on every reboot.



STEVE:  Is it free?



LEO:  No, it's not.  And Microsoft's is.  But Deep Freeze isn't hugely expensive.  It depends on how many seats you have and so forth.  It's 45 bucks just for the basic...



STEVE:  Oh, okay.



LEO:  So it's not hugely expensive.  But if you had hundreds of seats it would get more expensive.  And then I want to thank Randal Schwartz and many other folks who are fans of TrueCrypt.  The good news, you probably heard this also, there is now an OS X TrueCrypt.  Right when we started talking about it, I went to the TrueCrypt site, and it said we're working on a Mac beta.  TrueCrypt 5 is out and in fact works on OS X.  I've downloaded it.  In fact it is compatible across OS X, Windows, and Linux.  So you can have a TrueCrypt-encrypted file, folder, or disk, and you could read it on any of those three operating systems, which is...



STEVE:  Very cool.



LEO:  Yeah.



STEVE:  And in fact there was so much interest in this that our Q&A that we'll be getting to shortly talks about some things that are built in already to the Mac.



LEO:  Oh, yes, of course.  And now it's time.  Are you ready?



STEVE:  I'm ready, Leo.



LEO:  You feel good?  It's question time.  And we'll start off with Lin in Kalamazoo.  Lin has a lot to say:  Hello, Steve and Leo.  Longtime listener here, started off with you on show 01.  Should that have been show 00?  Yes, in true programmer's form I should have named it 00.  TWiT started with 00.  But I don't know why, I just - I wasn't thinking.  We started with show 01.



Love the show.  Frequently relisten to past episodes to keep your ideas and teaching fresh in my mind.  We do recommend that.  [Indiscernible] gain anything from that, but I think there's an advantage to that, you know?  Listen again and again.  I don't gain anything from it, Steve.  You know, it's just I like that idea.  I have to listen to it again.  I get something more every time.



I'm on the road about three hours a day, so I get a lot of Security Now!, and I love it.  Additionally, about six months ago I became a SpinRite customer.  I have 11 computers, 30 hard drives at home.  What?  Like most of your other listeners, I've saved several drives and many gigabytes of information with SpinRite.  I don't know how I lived without it.  Your last episode reminded me that I, too, had a few old broken dead drives in storage.  Remember we were talking about that, you know, somebody had resurrected a drive they hadn't used in, what, they had wrapped it up and hadn't used it in years.



STEVE:  Yeah.



LEO:  So it's kind of like cutting off your head and hoping that - and freezing it.  Someday they'll be able to resurrect you.  So I was able to revive them and get some cool data I'd missed over the years.  You know, I have to do that.  I have tons of drives.  Everybody does.  Just, you know, old 20MB drives, things like that.  It would work with any drive; right?



STEVE:  Sure, any IDE drive.  And, I mean, even pre-IDE if you still have the controller lying around.



LEO:  MFM, RLL, remember those?



STEVE:  Yup.



LEO:  Your last episode - oh, yeah, okay.  My longest drive recovery - oh, get this.  Now, our record is three months, I think; right?



STEVE:  I think so.



LEO:  He took 17 days.  That means his SpinRite was running for 17 days, but he's patient.  He'd heard about three months, I guess.  My SpinRite finally sorted everything out. I was able to get what I needed back from the drive.  One question, though, about SpinRite:  I have an expensive aviation Garmin GPS unit that's having a memory issue.  It has 512MB of RAM it treats as a drive.  I can't get DOS to see it as a drive.  Or I can get DOS to see it as a drive if I plug it in via USB.  Can I get SpinRite to work on it?  I'm a pilot, and I really depend on my GPS.  I'd love to save the two grand from buying another one.  Those are vital, you know, those GPSes.  Problem is USB; right?



STEVE:  Well, and I don't know exactly, he says he has a RAM issue.  I would advise him not to use SpinRite on that system because you really don't want to run SpinRite on non-volatile RAM.  All it will do is tend to bring it closer to its end of life.  So I never recommend running SpinRite on any kind of non-volatile solid-state storage.  We've talked about how ultimately all it does it move them further toward end of life.  So it's really not what you want to do.  I don't know enough about his system, what kind of an issue, as he puts it, he has.  I mean, if DOS will see it, SpinRite will run on it.



LEO:  It's a little USB drive, though.



STEVE:  Oh, yeah.  Absolutely.



LEO:  Oh, it will.



STEVE:  Yeah.



LEO:  I thought the USB interface hid drive essentials that you needed to see.



STEVE:  No, you can still read and write.  And SpinRite's able to back itself off and use as much of the available interface as possible, so...



LEO:  So you won't get the low-level stuff.



STEVE:  Correct, correct.  You don't have the ability to talk as intimately to the drive as when you plug it onto the motherboard directly.  But it still works, and...



LEO:  Oh, I didn't know that.  Oh, I didn't know that.  I thought we had to connect via IDE.  Oh, that's good to know.  That's good to know.  So worth at least trying.



STEVE:  So, yeah, I would, I mean...



LEO:  If it's really RAM.  If it's Flash, don't do it.



STEVE:  If it's Flash, don't do it.



LEO:  It has to be non-volatile, otherwise it'd be useless.



STEVE:  Yeah, see, I don't understand what data he's got there.  I would say pull it all off and just reformat it.  I would think maybe just reformatting it out to, you know, cure whatever problem he's got.



LEO:  There you go.  He has more.  He says, now onto my questions regarding enterprise and corporate security.  First, is Sprint's wireless data card safe?  I use a Verizon EVDO card, like the Sprint one.  He says:  Am I behind - so I'm curious about this answer, too.  Am I behind a NAT router?  Do I need a software firewall?  I've been running the Sprint card for about a year with no issues, but I was wondering what my exposure is.  It's a corporate laptop, sensitive data.  I thought we should know.  I haven't heard about this on Security Now! yet.  It fails the ShieldsUP All Stealth test.  It has service ports green except for port 22, which is closed.  So I failed ShieldsUP, but everything is blocked.  As far as - 22 is SSH; right?



STEVE:  Yeah.



LEO:  As far as a router, my traceroute hops seven times in the 68.*.*.* range before going to wired land network.  So there's seven hops within the Sprint network.  Is there anything wireless data card users should do to stay secure?  How do these differ from my home network protected by my NAT router?  Second, I've never - should we answer that first before we go on to spreadsheets?



STEVE:  Yeah, okay.  Now, I don't want to freak everyone out.



LEO:  Oh, boy.



STEVE:  But both...



LEO:  I'm freaked out already.



STEVE:  Both types of cellular technology, both GSM and CDMA, unfortunately use encryption that was - I mean, I can just hear our listeners getting ready for this - was designed by engineers and not by crypto people.



LEO:  Just like WEP.



STEVE:  In their defense, in defense of the cell technology, back when this was first done, it was much more expensive to have processing power than it is now.  At least in the case of GSM, it's based on a shift register, I think it's three different shift registers with multiple taps, which is one way of generating pseudorandom data.  They've tried, the people doing it tried to keep this as a trade secret, tried to keep it proprietary.  Bottom line is it's been cracked.



LEO:  Now, you understand first of all this isn't - this is CDMA.  And it's EVDO, it's EVDO.  It's Sprint.



STEVE:  Right.  Right.  Now, exactly.  Now, but CDMA has been cracked also.  So...



LEO:  And I don't know if EVDO really uses CDMA technology.  It's on those frequencies, but it might use something else.



STEVE:  Actually it does.  All EVDO is really doing is aggregating a bunch of channels together.  And essentially that's where you get all this extra bandwidth...



LEO:  Oh, interesting.



STEVE:  ...is it just pulls a bunch of cell channels together and uses them all in parallel in order to increase its speed.



LEO:  How interesting.



STEVE:  I don't know one way or another for sure whether there's an additional layer of encryption on top of the standard cell technology.  And when I - again, as I started saying, I don't want to freak out our listeners.  It's not like, you know, CDMA and GSM has been cracked to the degree, for example, that WiFi has been.  But there are papers on the 'Net that talk about how this stuff can be cracked.  So it's not like there's super-strong, industrial-grade, current state-of-the-art crypto.  The problem is, these technologies, these digital cellular technologies are so old, and now so widely deployed, that they can't be updated without obsoleting the entire network.  And they're, I mean, they're encrypted to the extent that you have to really, really, really want to crack them in order to get inside them.  But it is possible.  Has been done.



LEO:  I'm reading here that EVDO uses a 42-bit pseudo-noise sequence called a "long code" to scramble the transmissions.



STEVE:  Right.  I mean, and...



LEO:  That's not very long.



STEVE:  No, it's not.  And again, it's...



LEO:  And then it uses AES.



STEVE:  On top of it.



LEO:  Yeah.  Well, wait a minute.



STEVE:  Okay.



LEO:  Now, wait a minute.  The long code scrambles transmissions through the standardized cellular authentication and voice-encryption algorithm, which is probably the one that's broken, to generate a 128-bit sub-key called Shared Secret Data, SSD.  This key feeds into an AES algorithm to encrypt transmissions.



STEVE:  Well, that does sound pretty good. 



LEO:  If it's using AES with a 128-bit key generated by random, by pseudo-noise...



STEVE:  Yeah, it doesn't sound like it's using any kind of a public key technology.  And I don't know where the shared secret comes from.  It might be based on the phone number, or maybe it's established ahead of time?  Anyway, it is on my list of things to research deeply.  So I can, you know, we'll spend an hour here before too long talking in detail about cellular encryption technology because I know lots of people are a little anxious about it.



LEO:  Well, the thing that makes me anxious is maybe EVDO is secure, the data's secure.  But it sounds like voice transmissions over GSM and CDMA are not.



STEVE:  Right.  They would be relying on that initial level of obfuscation, which you really cannot consider as being encryption.



LEO:  Right.  You know, it's funny because, when we went from analog to digital cell phones, I remember, as we talked about earlier, analog cell phones, just like analog land lines, were completely, completely monitorable.  And I remember asking hackers; and they said, well, we don't know how, but probably you could hack into it.



STEVE:  Probably.



LEO:  Probably you could.  We just - and this was very early on.  He has another question.  This is a - you're right, he has a lot to say.  But Lin, we don't mind because you're a pilot, and you're going to fly us safe the next time we go up in the air.



I've never heard the question on Security Now! about Microsoft Excel security.  Okay.  I often time share Excel spreadsheets with people who I want to be able to use the spreadsheet, but not see my formulas or change anything.  As most folks know, if you use sheet protection and a complicated 64-bit password, it can be easily cracked in seconds with freeware out there.  Okay.  My question would be, is there any way to secure Excel so that it cannot be cracked, and you can keep formulas and data from being changed?  I did try to use Open Office's XML formatting with protection, but then of course Microsoft Windows customers or Office customers can't use them.  Steve and Leo, please help.



STEVE:  Yeah, this was an interesting question.  I mean, he obviously knows that the built-in password protection that's afforded to Excel, you know, there's lots of freeware around that'll crack that easily.  The only thing I could suggest -I don't quite understand what he's hoping to achieve.  He wants to allow people to view his spreadsheet but not change it.  So the thought that I had was to print it to a PDF file.  And then they've got the spreadsheet data, contents, charts, and all that stuff in a non-modifiable form, which is apparently what he wants them to see, but not be able to change.  So, you know, that was the one thought that I had.  Other than that, I mean, you could use external encryption to encrypt the file very strongly.  But then you'd have to give anyone the password in order to decrypt it if they wanted to display it.  So I don't think that really solves his problem.  The only thing I could think was just move it out of an Excel format into a printed form and, you know, share it that way.



LEO:  Yeah, depends how he wants people to use it.  If he wants them to be able to enter their own numbers, then I think you're out of luck.  I think you have to use whatever Microsoft does, and clearly Microsoft's not doing much.



STEVE:  Right.



LEO:  Chuck in Tennessee suffers from debris.  Hey, you wrote a little poem there.  How do you deal with all the preinstalled junk when you buy a new machine?  I've thought of just buying a new copy of Windows to go with every new machine - that gets expensive, have you purchased Windows off the shelf? - just to get as clean a slate as possible.  Is this obsessive?  Also, are there a range of running processes that you'd like Task Manager to be showing?



STEVE:  You know, this is a great question that comes up, you know, often.  And I was sort of talking about it the other day.  I was very impressed, frankly, with how clean the most recent two Dell systems that I've seen, a laptop and a desktop, they both had virtually nothing on them that I was unhappy with.  I also recently purchased some ThinkPads for my employees.  And unfortunately there was a bunch of junk there.  And I've seen other machines which, I mean, are just, well, oh my god, HP's current offering.



LEO:  Oh, it's the worst.



STEVE:  Oh, Leo.



LEO:  HP's the worst.  There's nobody worse.



STEVE:  Oh.  I mean, it's just, well, okay.  So I've taken exactly the position that Chuck has, which is the only way to deal with this is just to scrape off the machine and start over.  Now, I'm a paid MSDN developer, so I have the right to install, for example, XP...



LEO:  You pay them, they don't pay you.



STEVE:  Oh, yeah, I pay them $2,500...



LEO:  He pays a lot.



STEVE:  ...for this, $2,700 or something for a year.



LEO:  But you get a licensed copy of Windows that you can install on as many machines as you want.



STEVE:  Yeah, I don't know...



LEO:  So it's no big deal for you.



STEVE:  I can't give it away, of course.  But so that's not a problem for me.  My point is that, both with the recent ThinkPad and with the recent HP, even armed with all the drivers that I can find on their sites, I have been unable to install a clean build, a clean install of Windows and get rid of all the little yellow exclamation points under the Device Manager to make it happy again.  On a little HP Pavilion I couldn't - I was never able to get the CD/DVD-ROM working.  And I tried the same thing on my ThinkPad.  I spent two days trying to start from scratch, install Windows - of course I'm using Drive Snapshot all the time in order to make checkpoints.  And I should say, of course, that before I did anything I made a snapshot of the - I mean, before I even booted it the first time I made a snapshot of it so that if my attempt to install clean and build it up failed, then I could get back to the way it was when it first got taken out of the box.



What I ended up doing with the ThinkPad, on all four of them now, is simply removing stuff.  I don't like using Add/Remove Programs in order to remove the annoying stuff.  But there really was no choice.  And I always sort of feel like, well, there's going to be some debris left.  It's not really - is it really removed completely?  We've had no trouble with our ThinkPads where we just started with the way it came and then backed out of that back to leaving the things installed that are necessary.  And, I mean, in most recent cases I've been unsuccessful in, unfortunately, in installing a clean version of Windows and then getting all the various, you know, basically just the device drivers and additional stuff that I wanted to have there working.  So it's a mixed blessing.  I would just say don't buy HP, you know, buy Dell.



LEO:  There are a couple of things to say about that.  And Dell used to...



STEVE:  They've got get a clue about this, Leo.  It is so bad.



LEO:  Well, Dell used to.  And I think one of the reasons they don't, they have this program where they ask users what they want to change.  And they've done a number of things.  That's why they brought back XP, that's why they offer Linux, and it's why Dell, which has - I think they've done a very good job of removing the junk.  There is a program, actually there was a guy wrote it because he was so frustrated with his HP, called the PC Decrapifier.



STEVE:  Yes, I've heard of that, too.



LEO:  Yeah, it's PCdecrapifier.com.  It's free.  And it does other things.  I mean, it's one thing to uninstall stuff.  But it also does things like resets the home and search pages, eliminates unnecessary startup items, takes out things like Google and Yahoo! toolbar.  So there's a lot of stuff that I think is, you know, this is a choice.  The other thing is many manufacturers - well, maybe not many - some will still sell you a real Windows disk as opposed to a recovery disk.  The recovery disk, of course, recovers the crap.  But a real Windows disk, you know, with the hologram on it and all that, is just a Windows disk.  So if it comes with that, then you're golden.



STEVE:  I should mention, speaking of installing Windows, that I was poking around Microsoft's MSDN site just the other day.  And I noticed with glee that Service Pack 3 for Windows XP is now at release candidate 1.0 state.  And it's like, oh, please.  No more 95 or 98 updates and rebooting nine times for the updates' updates' updates' updates' updates' updates again.



LEO:  Well, not for a few months.  And then you'll have to do that again.



STEVE:  Yeah, it's true.



LEO:  And by the way, we should mention that Vista SP1 has now been released.  It's not - it won't be pushed out to you till March, probably.



STEVE:  Who cares?



LEO:  Some people care.  And we'll talk about it, Paul Thurrott and I will, I'm sure, talk about it Friday on Windows Weekly, as well as SP3 for XP.  Yeah, because now that's finally out, which is nice.  I mean, I don't know if it makes Vista better.  But anyway, it's out.  So thank you.  That was a good question.



STEVE:  He did also ask about Task Manager.  And there's no easy way to answer the question about running processes.  But...



LEO:  I can tell you a place to go.



STEVE:  I will say that every so often I will look at, for example, the processes running on GRC's Win2K box.  And I'm just jarred by how few there are.



LEO:  Compared to XP, yeah.



STEVE:  When I set it up, I went through, and I turned off all this nonsense, especially for a server that's just going to sit there, you know, it's not - doesn't need all kinds of wacky stuff running.  And that's, you know, sometimes I'll turn things off that then I later need, like I'll turn off the DHCP client because I'm not using dynamic IPs within my own network.  I'm in a 10. network, and I assign them all myself.  And then I'll take a machine somewhere, and it won't connect.  It's like, what the heck.  It's, oh, wait a minute, I turned off the DHCP.  But again, it's like I really do, I bolt these machines down and reduce the running processes just as a matter of best practices in security.  And it boots a lot faster, too.



LEO:  Black Viper, who did this most famously for XP and then went offline, yeah, is back.  He's back.  BlackViper.com.  And he does have all of the configuration recommendations and the services you could turn off, and at least explains what they do.



STEVE:  Isn't that so annoying, too, that Microsoft gives you this one little line.  It's like, you know, "Tracks changes to multiple files over the network."  It's like, okay, well, do I need that or not?



LEO:  Yeah, right.  And that's what Black Viper - Black Viper was a gamer.  But he, by trial and error, went through all these services to figure out what you could turn off and what you had to leave on.  So that's a good source of stuff you can turn off.  And then of course you can use Msconfig, but I recommend Autoruns, that's Mark Russinovich's program now from Microsoft, at Sysinternals.  Just Google "Autoruns" and "Microsoft," you'll find it.



A listener who didn't leave his name wonders about the dark side.  Maybe he wants to be anonymous:  Hi, Steve and Leo.  Thanks for such a great show.  I've learned a lot.  You guys have never really talked about cracks, pirated software, the whole WAREZ scene.  I knew a guy used to call it WA-REZ scene.  It surprises me how many people use serials and cracks without considering the security implications.  I don't pirate software at all, for lots of reasons.  Many people do.  Oh, boy, I'll tell you one thing, those WAREZ sites are a hotbed...



STEVE:  Oh, Leo.



LEO:  ...of security exploits.



STEVE:  It's true confession time.  Not long ago, maybe about two months ago, I was really annoyed with my copy of Eudora, which was in standard form several versions back because it had not been giving me a problem.  But I was - and, I mean, I love Eudora, I've been using it forever.  I actually own many more registrations because I used to have employees that were all registered Eudora users.  And so, I mean, and they wandered off and are no longer using Eudora.  And so I thought, okay, well - and I was having a problem because one of the cool things Eudora does is it stores all of the contents of a folder in a single text file, which is just nice.  The problem is, it tries to parse that file by just scanning the headers, and sometimes it gets messed up, especially if people are including what looks like email inside of email.  Then that really gives is heartburn.



So I thought, okay, I wonder if they've, like, fixed this with newer Eudora.  So I went to Eudora.com and immediately was greeted with we're sorry, we're no longer publishing Eudora.  Version 7.1 was the last one.  You can't have it.  I think the sponsored edition, which gives you ads in the UI, that you could still have.  And then they say, oh, but don't worry, it's going to be going open source, and it'll be coming out soon.  So I investigated that.  It turns out that that's really not true.  Instead the Mozilla people are putting a Eudora UI onto their email client, their communications client.



So it's like, okay, well, that's not what I want.  So I thought, okay, what am I going to do?  I mean, I own a whole ton of these licenses.  I can't get a 7.1.  I'd be happy to purchase it if I could, but they don't sell it anymore.  So into the WAREZ sites.  Knowing the danger of this, I used what I consider a sacrificial computer.  Because, as you said, Leo, it is beyond bad.  And I did manage to get this machine deeply, horribly infected, just by trying to poke around and see whether I could find something that would allow me to generate a key for a copy of Eudora that I was hoping would work, which again, I would have been glad to pay for, and in fact I've paid for it many, many more times than I'm using it now.  So I think, okay, morally I'm - ethically I'm in the clear.  But anyway, that's essentially how I feel about this is, again, you want to do what you feel is the right thing.  There are solutions out there.  But boy, as you said, Leo, they will, I mean, nothing will hose your system faster than poking around in those dark corners.



LEO:  Well, just think about it, I mean, if you run a WAREZ or a crack site - actually, no.  Let me put it the other way.  Let's say you're one of those people who wants to get exploits, trojan horses, viruses, spyware on other people's machines.  You bought one of those kits from the Russian website.  You just need a website to put all that malware on.  Now, what are you going to put together for a website?  Well, you're either going to do porn, or you're going to do cracks and WAREZ.  That's going to draw people in.  Or serial number sites.  And so of course that's where all of these exploits are sitting.  Now, we used, you know, occasionally on The Screensavers we would need - we would urgently need to run a program, and we would, I'm ashamed to admit it, figuring that, well, the company would want us to show the program on TV, we would go and get a serial number for that program.



STEVE:  Sure.



LEO:  But I haven't done that in years.  And I wouldn't dream of doing it, first of all because it's the wrong, you know, I want to buy my software.  But also because that's a sure way to get infected.  You know, I mean, do it, if you're going to do something like that, do it on a VMware version of Windows that you then erase.



STEVE:  Well, and that machine was seriously compromised.  It had, I mean, little command dialogue boxes were popping up, and then it was installing servers.  And, I mean, it was really - I thought, well, I'm sure glad I didn't just go browsing around these horrible places with my "A" machine, or it would be start-over time.



LEO:  No kidding.  Yikes.  Aaron Skinner in Omaha, Nebraska, he's considering going Steady:  So here's my scenario.  I am running Windows XP, Media Center Edition 2005.  I have a couple of roommates who also use my computer.  This computer is also used to play some online games.  By the way, games like Battlefield 2142 don't seem to run right unless you install and run from an administrator account.  Yeah.  And that's true.  I'd like to have a setup with my personal login, another login for my roommates and gaming.  I want my personal login to have full access to everything, and the roommate/gaming to reset after logoff - well, I think we know the answer to this - so no changes are saved, although this may cause issues with game save data.  In addition, I still want my Media Center to fully function, you know, record TV shows even if I'm not logged in, or I'm the only one who can do it.  I'm also using Avast, which is an antivirus home version, and want to be sure it gets automatic updates.  Basically, I want to limit the roommates from doing damage to my computer while leaving my computer and gaming experience unhindered - continuing to run as admin, I guess.  I'm interested if and how SteadyState can be used in my situation.  Oh, he heard the SteadyState actually.



STEVE:  Yeah, so he was wondering if it would apply to him.  The only problem that I can see is, first of all, Avast, as I recall, was not one of the few AV systems that SteadyState was aware of.  There were several, unfortunately, I mean, McAfee was one, and I don't remember now what they were.  But there were only a couple that SteadyState could deliberately interact with.  And it certainly does require deliberate interaction and operation in order to deliberately bypass this whole drive prophylactic, essentially, that SteadyState wraps your system partition in, your C drive.  So I don't think that SteadyState would work for Avast, as I recall, and that's a problem.



The other problem is that doing something like saving recorded TV shows, you do have this driver sitting there which is journaling changes to the system.  And, for example, when the admin, the god of that machine logs off, you get a dialogue that says do you want to retain the changes, do you want to flush the changes.  So then you decide what you want to do with what has happened while you as the administrator were logged on.  Non-admin users, that is to say, anyone who's not that main administrator account, doesn't have the choice, of course.  They would be like the user in the library that flushes their changes off the moment they log off.  But that does imply that this Windows journaling thing is going along and is on all the time.



So it feels to me like this is probably not the best solution in this case.  I would say setting up some sort of virtual machine for these other people to use would give them containment that makes more sense in this environment because I don't - SteadyState is certainly designed in a shared access mode, but doesn't - I think Aaron's application is pushing it a little too far, and I don't think he'd be happy with the way it works.



LEO:  Yeah.  Okay.  And I guess Deep Freeze would probably have exactly the same issues.  I mean, anything would that's going to try to maintain that state.



Amir Katz, listening to us from Kfar Saba, Israel - hello, Amir - needs just a little encryption.  Just a little tiny bit of encryption:  Hi, Steve.  You've dedicated a full Security Now! episode to TrueCrypt.  You've mentioned it a few times afterwards - and again today.  However, I find I don't need to encrypt a whole partition or even a whole folder, just a few files.  And AxCrypt is a simple and effective tool for just such tasks, especially if I don't need on-the-fly encryption.  It's open source, GPL license, also has a secure-delete feature, like SDelete, which we  mentioned a couple of episodes ago.  Can you comment on its security?  I find it extremely easy to use.  I'm a loyal Security Now! listener from Episode 1, and a proud SpinRite user.



STEVE:  Well, it's funny, I had to go back and check to see whether I had ever referred to AxCrypt in earlier episodes.  And I haven't.  Because it's what I use.



LEO:  You're kidding.  Oh, that's funny.



STEVE:  No.  Yeah.  I mean, I discovered it maybe a couple months ago when I was specifically looking around for a - oh, and it's also free, by the way.  It's voluntary support through PayPal and Amazon and a few other things.  It is a tremendous little program.  It is very lightweight.  It is different than - I answered a question like this maybe a few weeks ago.  And it was a different program, I'm trying to think of the name now, because it was for a slightly different application.  And I'm looking here, and I'm - oh, Omziff.  That was the encryption tool I recommended because, specifically because it made no modifications to the system it was run on.  It was a completely freestanding executable.  By comparison, AxCrypt does integrate itself into Windows, so it's more of an installation.  It's not quite as standalone.  And, for example, it adds right-click context menu support.  So, for example, you could right-click on a file and say "encrypt yourself" to the file.  So it's a little heavier duty.  But I like it very much.  And I've been very impressed with it and the way it operates.  And now I'm worried I'm going to get AxCrypt and Omziff confused.  But I think AxCrypt is the one which can make a self-decompressing EXE, which is also very cool.



LEO:  Oh, that's very handy because you can send it to somebody.



STEVE:  Yes.  And so - exactly.  So you turn it in, you turn a whatever, an archive of files, for example, into an EXE where, when you run it, it prompts you for the filename.  And it's all AES 256-bit, I mean, it's really, really good security.  And as he says, it's open source, GPL'd.  And you can even download the source from the AxCrypt site.  So I absolutely do recommend it.  It's a beautiful little program.  I like it a lot.



LEO:  Good.  Well, thank you, Amir.  Good suggestion.  Another anonymous listener has a question about IP space:   Hi, Steve.  I work at a large university which owns a Class B public IP range, for example 65.92.0.1 to 65.92.255.255 (that's not the range, but that's an example), consisting of 60,000-plus possible Internet addresses, if my math is right.  I've never been able to get info on how much this costs the university, although I know from my work in the private sector that a single IP can easily cost $5 a month.  I don't think you multiply by 60,000, but maybe I'm wrong.  Whether the IPs are subsidized or not, it seems like a huge waste of money - somebody must be paying somewhere - and an unnecessary exposure to script kiddies and hackers, when over 90 percent of our users would be equally served with a free private IP range.  In other words, having maybe one address for the whole university which you use DHCP to share out.  Do other universities do this?  Are they all subsidized?  And if so, are taxpayers picking up millions of dollars in billing for what seems to be nothing more than an increased risk?  I'd love to hear your thoughts on this, particularly if I'm totally wrong.



It's not just universities.  I mean, Internet service providers, lots of people buy big blocks.  A B class is big.



STEVE:  He's totally wrong.  IPs don't cost anything.  Unless you resell them.



LEO:  Unless you're reselling them, yeah.



STEVE:  Exactly.  So we've never talked about this, so I thought it was a really great question.  Back in the beginning we had 32 bits of IP space.  And it didn't used to be that networks could be divided sort of on arbitrary bit boundaries.  We have talked about this notion of Class A, Class B, and Class C networks.  A C class network having one byte of IP addressing, that is to say, 256 addresses, but you only get - you lose a couple from that network.  That's a Class C.  A Class B has two bytes of addressing, which is what this listener is talking about here, where then you're going to have 64K possible IP addresses within that network.  And then of course a Class A you have three bytes of addressing, so that's 24 bits of address space.



So what happened was that the original 32-bit address space was just sort of chopped up in big pieces.  There are some universities, and universities were of course part of the early adopters of the Internet, and so this guy works for a large university, they just got themselves a B class network.  So they've got, as he said, they have two bytes of addressing, with the first two bytes are fixed, which essentially is the address of their big B class network.  And he's very right that it may well be that the university does not need 65,536 or, you know, less a few, individual IP addresses.  But they've got them, and they're not going to let them go.



LEO:  So they were given them at the beginning.



STEVE:  Yes.



LEO:  As an EDU or whatever.



STEVE:  Yes.  And for example, you know, Level 3, I think, has all of 4-dot.  And BBN was one of the other early adopters.



LEO:  They invented the Internet.  They could probably have anything they wanted.



STEVE:  I think they've got, like, 1. or 2. something.  I mean...



LEO:  That would make sense.



STEVE:  And so essentially the idea is that all of these, the really main Tier 1 ISPs generally own a huge chunk of IP space.  I'm embarrassed to say that I at home have 64 IPs, of which I use one, because I'm behind a NAT router.



LEO:  And you get that because you bought server service or something; right?



STEVE:  No, no, no.  It's funky because this actually was due to my great relationship in the old days with Verio, where I did need some space, and I had two 32 IP blocks that were disjoint.  And so when I switched over, when Verio sold the T-1 business over to Cogent, they took Verio's engineers, who I knew really well.  And Andy, my old Verio engineer, said how many do you want?  And I said, well, Andy, I really don't need that many.  Oh, c'mon, take as many as you need.  And whereas now, for example, with Level 3, who is now hosting GRC's bandwidth, they were like, prove to us you need more than two.  I said, well, what do you mean?  No, prove you - so I had to literally fill out a sheet showing how and why.  And they called it the "IP Justification Form."



LEO:  Oh, my goodness.



STEVE:  I had to fill out a form because they're not wanting anyone to waste them because they're their precious resource, and nobody who ever gets any IPs...



LEO:  Ever gives them back.



STEVE:  ...ever, ever gives them back.



LEO:  Mine, dammit.



STEVE:  Exactly.



LEO:  Now I understand.  That's interesting.



STEVE:  It really is.  It's a weird sort of bizarre consequence of the early days of the internet, when people would say, okay, how many Class Bs do you need?  They'd just chop them up and, you know, because they weren't valuable then.  Now they're just - they're the most precious resource on the planet.



LEO:  Well, now, I figure we're done; right?  Everybody's got something, and there's nothing left.  I mean...



STEVE:  Do you know that there's still only about 60 percent of the IP space is in use?  40 percent is still just slack.  It's people like the university, hoarding the IP space because they don't want to give it back.  Even though they may not be using it, and somebody else could.  It's like, no  no no, this is ours.  This is our Class B.



LEO:  Well, it makes it easier for the record companies because they say, oh, there's 65.92, we know where that is.  That's U of A or whatever it is.



STEVE:  That's very true.  And of course after you've been doing networking long enough you just look...



LEO:  You start recognizing those, yeah.



STEVE:  Yes, you can just see the IPs and go, oh, this is Cox Cable, this is Comcast, this is Roadrunner, blah blah blah.  Oh, this is an AOL block.



LEO:  When you said 4., I said, well, that's Verizon.  So obviously Level 1 has given some to Verizon.



STEVE:  Exactly.



LEO:  Yeah.  [Brad] Beyenhof has Mac file security pretty well nailed:  I've been listening to Security Now! since Episode 1 - again, another great listener - from the actual time it was released, not by archive-diving.  I've been listening since day one, he says.  In the most recent listener feedback Episode 128 you had a question about encrypting files and folders on the Mac without using File Vault.  Oh, I got a number of people sending me this...



STEVE:  Oh, Leo, I mean, half of the email that I've received recently were Mac people who were proud - so I wanted to acknowledge everybody who wrote in.



LEO:  Thank you, everybody.



STEVE:  Yes.



LEO:  And actually, I mean, I should have mentioned it.  I've used this technique for years.  In Disk Utility you can create an encrypted disk image - it's a .dmg file - that requires a password to mount.  This obviously doesn't encrypt the whole home directory.  But if you want to keep a set of files or folders encrypted, it can do the trick.  You can even save the image's password in your account's encrypted Keychain, put the file in your login items so it automatically gets mounted whenever you log in.  You don't even have to enter a password.   Although you might not to do that if you want more security.  Another question mentioned erasing files securely on the Mac.  In addition to Secure Empty Trash, which according to Apple completely overwrites files with meaningless data - and I will vouch for that because it takes about 20 times longer to empty the trash when you use it - you can also securely clear all the free space in a hard drive.  Disk Utility to the rescue again.  Select the drive, go to the Erase tab - oh, that's right.  I have seen this setting.  Then you can erase free space with a seven-pass or 35-pass overwrite.  Finally, if you boot to the OS X installation disk, you can run Disk Utility from the menu bar and securely erase the whole hard drive with seven- or 35-pass secure deletion.  No DBAN needed.  So Apple obviously gives you a number of ways to get this done.



STEVE:  Yup, and Brad pretty much covered the bases.  Again, I wanted to acknowledge everybody who wrote in with various flavors and pieces of that.  I mean, from what he said, and being a person who doesn't want to install software I don't need, I love the idea that you can create essentially an encrypted partition, one of these DMG files, and put things in there knowing that, if you remove the password from it, it's really going to be safe.  Also remember that, if you delete files from there, you're not leaving them sitting there in the clear on your drive because Apple is encrypting them on the way to the drive, so they're always encrypted.  So you essentially have sort of the equivalent of Secure Delete for free.



LEO:  Right.  Yeah, this is really a good technique.  Also you can make a sparse encrypted image so it's small, but can expand to accommodate whatever files you put in it.  And when you mount it, it mounts like there's a drive there.  So it just shows up as another drive.  So it is actually a very good technique.



STEVE:  Nice.



LEO:  Steve Hendry of Kitchener, Ontario says:  "Steve missed an obvious solution (maybe)":  Hi, folks.  I've been an insatiable listener from the beginning - another #1 listener.  You're all #1s.  Steve's knowledge never ceases to amaze me.  I hope the show never stops.  One thing that surprised me, though, is his solution to the recurring question of how to provide both WEP and WPA access without risking compromise of the WPA side from the WEP access point.  Steve's repeatedly described what seems to be kind of a kludgey solution involving three routers.  Why doesn't he recommend using one of the free Linux firewall solutions - IPCop, Endian Firewall, Smoothwall - that allow separate networks to share an Internet connection without the untrusted network being able to see the trusted one.  Both of these forks of the original Smoothwall install into an old PC with multiple NICs - you do need two NICs, I guess you might need three in this case - and allow up to three isolated networks with each less trusted network being unable to see the more trusted network.  They are full-featured firewall routers in their own right, as well, and a great use for an old Pentium 2 or 3.  I might also add you could use Astaro Security Gateway for this.  That's Leo talking.  Endian is available as a hardware appliance as well as a free distribution for PCs.  Setting up one of these seems to be a lot more straightforward and elegant than rigging multiple routers together for the same purpose.  Am I missing something?  Keep up the good work.  Love the show.  Wouldn't be without SpinRite, either.



STEVE:  Well, he's absolutely right.  I don't think this was an obvious solution, but I'm certainly aware of it.  I guess the issue is for a high-end user, for somebody who has a PC, can install multiple NICs, wants to go into a Unix-based solution, absolutely this makes sense.  Except that then you still need your wireless radios.  So presumably you'd have a WPA router and a WEP router still.  So really I don't think you've solved any problems because...



LEO:  Well, and the router is doing essentially the same thing as the security gateway.  So you've used up a computer, I mean, the router's a 40-buck way to do this, I guess is what I'm saying.



STEVE:  Yes, exactly.  And so the reason I like what I'll call the "plastic consumer box" approach, just taking three routers and plugging them in in a Y connection is - that solves the problem.  And this replaces the Internet-facing router, which splits the connection to a WPA and a WEP router.  But you needed one anyway.  So I didn't mean to snub all of these really nice turnkey solutions, and of course Astaro is, as you mentioned, Leo, is one as well.  But you would still need two more routers, one for each of the WiFi formats.  So you haven't really made anything simpler, it seems to me, although you've got a lot more configuration power, although a lot more configuration responsibility, as well.



LEO:  It's very powerful.  You can do a lot more with that.  Yeah, I mean, and you still - and by the way, you still have the triangle.  I mean, the content is basically the same, it's just using a different appliance to do it.



STEVE:  Yes.



LEO:  Joe in Sacramento, California has some additional clarification about built-in Mac encryption and an enterprise security question:  On the last listener feedback show, Leo was asked if he knew of anything that would encrypt a folder on the Mac.  You can use Disk Utility to create a new disk image with a 25-bit AES password-encrypted encryption.  You specify the image size, like 2GB.  It creates a file of that size that's encrypted, which you can then open and write files to and close when you're done.  Best of all, it's part of OS X.  Well, and I should say the sparse image is probably more economical.  It grows to accommodate what you need.



STEVE:  Yeah, I love that.  I love that solution.



LEO:  Yeah.  That's what I use, encrypted sparse image DMGs.  And it's very useful.  I actually keep a bunch of notes in those things, with serial numbers and stuff.  And that's - and I keep it completely - I feel secure.



Another note about enterprise security, in my work they've implemented full disk encryption using Check Point, I think.  It slows things down.  We've had some computers crash because of corrupted encryption information, like a FAT table.  My question is, why not use Windows' built-in, enterprise-ready EFS?  Do you know why?  Have you tried it?



STEVE:  Well, it's interesting.  This follows on some work I've recently done, which I will be sharing with all of our users before long.  I found an incredibly nice, free, whole system encryption solution that does preboot encryption, where it alters the boot sector and points to some fixed file locations on the drive, and essentially does on-the-fly encryption/decryption for a system that doesn't have an encrypted hard drive.  And it works beautifully with Windows.  The reason I - and I explored using EFS.  This was for a specific application I was configuring about a month ago.  The problem with EFS is when you pull a file out, it stays encrypted.  And normally what you want is you want the hard drive to be encrypted, but not exports from the hard drive.  And so, specifically, I wanted a system to be safe.  But if I took, if I copied a file, for example, to USB, I wanted it decrypted in the process and to be transparent.  Whereas EFS actually uses file attributes, tags this as encrypted, and you get an encrypted copy that, you know, you can't use.  I mean, which maybe what you want is to keep exported files from being decrypted on the fly.  But that wasn't, in my case, the application I was looking for.



So this thing I found, rather than teasing our users I'll let everyone know, is called FREE CompuSec.  I researched it extensively and will be doing a show on it before long.  But if anyone wants to go poke around at it, that's the name of it.  And I have checked out the security of this thing, and it is - they really got it nailed.  It is nice.  And I even went, I mean, I've even benchmarked it because I wanted to find out what would be the overhead associated with doing software, on-the-fly, encryption/decryption of the whole drive, which is what this thing does.  Literally the entire physical hard drive, no matter how many partitions you divide it up into, no matter what you do, it starts at sector 0 and runs an encryption across the entire drive when you put it into that state.  And I don't have the numbers in front of me because I've got them written down for the show.  But it was like 9 percent overhead.  I mean, nothing.  It was not - you couldn't feel the difference at all.  It took maybe 326 minutes to do - no, not 326 minutes.  What I did was I benchmarked a highly frag- the defragmentation of a highly fragmented drive, both with and without this.  And the increase was surprisingly minimal to add this on-the-fly encryption/decryption.  So we'll be talking about that soon.



LEO:  Wow, neat.  Wow, very interesting.  I can't wait.  Our listener Glen in Denver, Colorado is in a hurry to login.  Regarding Windows SteadyState, he says:  My biggest interest, in addition to customizing what's retained and what is preserved, is how long the restoration process takes.  And we mentioned it does take a while.  I always hate long login times required by machines that start up oh-so-many processes at login time.  So this is the question of greatest concern.  Is the logon process a matter of seconds, more on the order of minutes, how long?



STEVE:  Yeah, in my experience - and I didn't explore whether this was a function of the size of the cache.  As I did mention in our SteadyState podcast, when you are going to install SteadyState, Windows asks you to defrag the drive, to bring as much unused space into one large, contiguous block.  Then SteadyState, and I don't quite get why, but it just takes half of that.  It's like, thank you very much.  You had 50GB free, now you've got 25.  And it's like, whoa.



LEO:  That's annoying right there, I've got to tell you.



STEVE:  Well, you can easily, there's a nice UI, you can easily bring that down to 1GB or something substantially more reasonable.  I don't know whether that speeds up the login process.  The reason I didn't research it extensively is it wasn't that bad.  I mean, the process definitely took longer, and it was more than seconds, but it was less than minutes.  So maybe 45 seconds?  Maybe, I mean, literally, about 45 seconds, I mean, enough so that - I'm the same way.  I'm Mr. Login Speedfreak.  And I was already saying that I don't run processes I don't need and so forth.  So when this thing kind of like came to a grinding halt, and I'm looking at a blank screen with a cursor, it was like, okay, hello.  But maybe it was 30 seconds.  I mean, it was enough so that I knew it, but it wasn't enough so that I'm not going to use it in the application where SteadyState is really what I needed.



LEO:  Yeah, okay.  But, now, he's talking about boot time.  Does that relate to boot time?



STEVE:  Well, yeah, because when you log on there's a, like...



LEO:  It has to load in that partition?



STEVE:  No, I don't know what it's doing.  It's definitely doing something.  I thought maybe some other services were hung, so I went in and I...



LEO:  So it is slow.  I mean, it's slow.



STEVE:  It does slow down your login.  There's no doubt about it.  It slows down your login.



LEO:  On the other of minutes?



STEVE:  No, like maybe 30 seconds.



LEO:  Okay, that's not bad.



STEVE:  Yeah.  Again, you know, Glen is really concerned about that.  So I wanted to say yes, it will.  And I wanted to also mention that people can try this.  I mean, it just - it does install nicely.  And it goes away nicely, too.  So it's not a big problem to give this a shot and see how you feel about it because it's easy to back yourself out of it.



LEO:  Get back out, okay.  Now, you were very patient, so you can hear Mark Livingstone's Quick Tip of the Week.  This is the award-winner.  Steve, he says, if people want to data-mine the Security Now! transcripts, Google can help.  You ready?  This is a really useful Google tip.  I use this all the time.  You type "site:" and then you can narrow its search down to a site.  So in this case, if you type "site:grc.com" and then the word "transcript," which will narrow it down to transcripts, and then whatever keywords you want, boom.



STEVE:  And I've got to tell you it works because this is - I used it earlier today when I was putting the questions together for this AxCrypt.



LEO:  Just to see if you'd ever mentioned the other one.



STEVE:  Yes.  And nothing came up.  And then I thought, uh, is this working?  So it's like, wait a minute, maybe I'm fooling myself.  So I put in, I don't know, VPN and went boom, and there was like, I mean, it's perfect, Leo.  It's like every article - every article.  Every one of our podcasts where I've mentioned VPN, thanks to Elaine transcribing them all, it's just bang.  And thanks to Google, you can see the use of the VPN in context.  I mean, it's like - and I have to say that I'm really pleased about this because I did mention last week or the week before that I was soon going to be adding full text search to GRC.



LEO:  Now you don't have to.



STEVE:  Change of plans.  I've decided that I just can't screw around with GRC when I've got CryptoLink that I'm so excited to get to.  You and I talked about it six months ago, and I've made very little headway on it.  So I decided, okay, we'll use this tip, site:grc.com space transcript space and then whatever keywords, you search Google, instantly people can find things in the podcast.  And that way I don't have to go spend another six months implementing my own native search.  Instead I can get to work on CryptoLink that I think a lot of our listeners will care more about anyway.  So that's the plan.



LEO:  That's excellent.  Well, I have to say, once Google finds its way into your page, they do a great job.  I use Google for searching my sites.  Why do your own search?  And I use WordPress and Drupal, and of course they have excellent searches.  But Google does such a good job.  I just use Google for it.  Done is right.  And many people, one of the things people complain about with podcasts, with netcasts, is they're audio or video, how do you find stuff?  You're so smart to have the transcripts.  I really should do that for all the shows because then it makes a netcast Google-searchable.



STEVE:  Right.



LEO:  I think it's a really, really good thing.



STEVE:  Okay, now, read this #12 carefully and slowly, Leo, because this is extremely cool.  It's the Amazing Idea of the Week Award.  But our listeners are going to have to pay attention to get this.



LEO:  All right.  Mike's corporation in Minneapolis wins the Amazing Idea of the Week Award:  I just thought I'd write in to tell you about the enterprise security solution we use.  I figured it was too esoteric to mention before.  But since you brought up the use of VMware in Peter's response a couple episodes ago, I thought I'd share.  In fact, our solution is just an inverted version of Peter's solution.  What was Peter's solution?



STEVE:  Peter's was they had everybody running in VMware.  Remember, he was the developer, and his company of developers were using VMware because they didn't want to have to constantly put Windows security patches in, which tended to break their build, their development build environment.  And so the idea was they would keep the external Windows patched up and current, but then they would use a virtual machine image.  And when they added somebody new to the project, they just give him an image, and he's instantly read to go.



LEO:  Perfect.  Perfect.  Okay, well, he does the opposite, sort of, upside down.  Here's what he suggests:



We run a virtual machine on each desktop.  But instead of running the applications in the virtual machine and managing network security on the native machine, as Peter does, we do the reverse.  We abdicate control of the real machine's network card to the virtual machine, so that the native Windows system doesn't use it and can't see it.  We then establish a virtual network connection between the native Windows system and the virtual machine, so that all the Windows network traffic is routed through the virtual machine.  Inside the virtual machine we run OpenBSD, which is a security-hardened version of BSD Unix.  This effectively puts every Windows system on the network behind its own Unix firewall.  This is actually brilliant.



STEVE:  It is so cool.



LEO:  I have some questions for you about implementation.  But I get the idea.  This way, even if a rogue system were to be plugged directly into our network - oh, so this is the advantage of doing it individually on each machine - there's a firewall between it and every other peer on the same Ethernet segment.  An OpenBSD firewall.  The main advantage with this inverted approach is that graphic-intensive apps running on the native Windows system have no performance penalty.  Except for, of course, the RAM that's used by the virtual machine.  But otherwise they have full...



STEVE:  Ah, but that's where the beauty of OpenBSD comes in.  He's about to talk about that.



LEO:  Oh.  We've also found some additional advantages using OpenBSD in the virtual machine instead of Windows.  First of all, no additional Windows licenses are required.  Because it's free, it's open source.  And here, listen to this.  The OpenBSD system can run in a virtual machine with a relatively small CPU and memory footprint, less than 32MB.  You know, it's funny.  I mean, that would be a lot a few years ago, but that's nothing on a 2GB or 3GB machine.  The network packet filtering is much more configurable than what's provided in stock Windows.  And I'll vouch for that.  BSD has a great firewall.  The network admins find that bulk configuration updates are much easier for Unix-based systems than for Windows-based systems.  The system can be completely locked down by the admins without any fuss.  Not even the most advanced Windows power users complain they're not allowed to reconfigure the OpenBSD.  Of course not.  They don't want to get in there.



STEVE:  Yeah.



LEO:  This is clever.  Now, but I have some implementation questions.



STEVE:  So essentially, just to clarify, it's exactly like a personal firewall, but you're using OpenBSD running on a Windows machine as your personal firewall.



LEO:  It's almost like you have a UTM for every desk, its own UTM, because - or however you're configuring that security.  Now, here's my question.  Okay.  So I'm running Windows natively.  I'm running all my apps natively.  How do I tell my desktop Windows to go through the virtual machine for its network access?



STEVE:  I have no idea.



LEO:  I mean, I like that idea, but that's what you need to do; right?   You have to tell the Windows system, oh, no, your network isn't coming from your hardware Ethernet card, it's coming from the virtual machine.



STEVE:  Exactly.  Somehow you've got to get the VM to publish a virtual network interface so that that's what the hosting Windows system can see.  I have no idea how you do that.  I mean, I don't know that you couldn't, I just never tried it before.



LEO:  Yeah, because normally when you use a VM you're bridging your network access through Windows.



STEVE:  Correct.



LEO:  The Windows which has hardware to the Ethernet, the NIC, has network access, and it bridges it over to the virtual machine.



STEVE:  Right.  He did mention in the original email, and I think - it looks like I maybe have cut that off - where he said he would tell us how to do it if I want.  That's right, he said he would tell anyone who wanted to know how to do it.  And I thought, well, that's not going to work well in a question.  But I think I need to write back to him and say, okay, give.  How exactly do you do this?



LEO:  Well, I think this would be a good topic for a show, is just let's talk about how to do this.



STEVE:  In detail, yeah.  And what I love, again, is like, there are some personal firewalls that are 32MB.  I mean, that take up a huge amount of RAM.  And the beauty of Unix is that it is so small.  I mean, it's running in people's routers.



LEO:  And this is, I mean, you can - hardened Unix distributions are widely distributed.  And I think OpenBSD is an extremely good choice, not only because it's hardened and it's secure, but also it's less likely to be known by many Windows-based hackers, or even Linux-based hackers.  It's something a little different.  But the other thing that worries me a little bit is you still have this hardware NIC and Windows, and they're sitting there right next to each other.  You've really got to kind of find a way to keep  Windows from looking at that NIC.



STEVE:  I would think, I mean, again, I don't know what they're doing.  But you can certainly unbind network interface cards from Windows.  I mean, there is - there's still this notion of binding of protocols and hardware.



LEO:  So maybe you can bind it directly to the virtual machine.



STEVE:  Exactly.  And you don't bind it to Windows.  So Windows just doesn't see it at all.  And then if the VM is able to publish a virtual adapter, then that's what you bind the Windows networking protocols to.  Anyway, I think this was so cool, very clever.  We're going to find out how to do it.  And I agree, Leo.  Well, the other thing, too, is that this could potentially, since it's now virtual machines are, I mean, not only are the virtual machine containers themselves free, especially if they've got OpenBSD in them, but we know, for example, that Windows Virtual Machine Server is free.  So this is potentially a 100 percent free solution.



LEO:  Yeah, or VMware.  You could use a VMware player and VMware appliance.



STEVE:  Exactly.



LEO:  Yeah.  I wonder what - well, that's the other thing.  I'd like to know what he's using.



STEVE:  We're going to find out.  We're going to find out.



LEO:  Is it VMware?  Is it Windows, Microsoft's Virtual Machine?  But do they still call it Virtual PC?  What do they call it?  I can't remember.



STEVE:  Virtual PC, last time I - yeah.



LEO:  Well, I'm looking at VMware's virtual appliance marketplace, and they do have OpenBSDs.  In fact, if you go there, you can look at their - they have a lot of free appliances, including a whole category of security appliances.  So, I mean, there's a ton of choices there, including Astaro, OpenBSD with VMware tools, NetBSD, Stockade, I mean, there's a ton of commercial - and these are all free.  Smoothwall...



STEVE:  It may well be that this evolved from someone using one of those and saying, hey, wait a minute, why can't we...



LEO:  Yeah, go the other way.



STEVE:  ...unbind Windows from the physical container, I mean, from the physical interface and bind it to a virtual interface.



LEO:  Yeah.  I wonder if anybody else has thought of this?  It's a very clever idea.



STEVE:  Yeah, I love it.



LEO:  Yeah.  Okay, yes, you do, you win, Mike.  I don't know who Mike's corporation in Minneapolis is, but...



STEVE:  No, he didn't say.



LEO:  He probably doesn't want anybody to know.



STEVE:  But I'm going to track him down.



LEO:  Wow, really great.  Hey, this is a long episode, but I think a really good one.  We thank our new sponsors, Audible.com; and we welcome back our old sponsors, Astaro.com.  Great to have you both on.  And some great questioners.  Thank you all for your questions.  If you'd like to ask Steve questions, you can do it right on his site, GRC.com/...



STEVE:  Feedback.



LEO:  Feedback.  I never can remember that.  Of course GRC is the place to go for SpinRite, Steve's bread and butter, his day job, that great hard drive maintenance and recovery utility that everybody ought to have.  If you've got a hard drive, you ought to have SpinRite.  You must know that by now.  You can also go there to get the 16KB versions of the show, for people who don't want to download a giant show, or want to store it somewhere compactly.  With 130 shows, it does add up.  You can get that from GRC.com/securitynow.  And also Elaine's transcripts.  And don't forget that search tool [site:grc.com transcript {keywords}] because that's cool.  You can just make that a search link that would automatically do that on your site.



STEVE:  Yeah, that would take five weeks.



LEO:  Just pretend you wrote it.



STEVE:  Because it'd have to be perfect.  No, no, no.



LEO:  Just pretend you wrote it.  And just, you know, oh, I think you could do that pretty easily.  But anyway, all right.  We'll let people do - that's an assignment for home.  Your homework assignment.  Hey, Steve, thank you for a wonderful episode, and we'll talk to you next week on Security Now!.



STEVE:  Talk to you then, Leo, thanks.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#131

DATE:		February 14, 2008

TITLE:		FREE CompuSec

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-131.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In this first of their two-part exploration of the world of whole-drive encryption, Steve and Leo begin by discussing the various options and alternatives, then focus upon one excellent, completely free, and comprehensive security solution known as "FREE CompuSec."



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 131 for February 14, 2008:  Free CompuSec.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!.  I know you've been waiting all week with bated breath and unprotected systems to hear what Steve Gibson has to say about security.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.



LEO:  Good to talk to you.  And today we have a new program we're going to talk about in just a little bit that will protect us all.  But before we get into that, do you have any updates that...



STEVE:  Well, it was a busy week in security news.  Of course this is the podcast after the second Tuesday of the month, that is, of February...



LEO:  The first Thursday after the second Tuesday.



STEVE:  The first Thursday after the second Tuesday.  Now, of course the first Tuesday of the month was the Presidential Primary Super Tuesday.  I'm inclined to call this last Tuesday the PC Industry, or I should say the Microsoft Super Tuesday.  They released 12 security updates.  Any of them are important.  I'm not going to go through them in painful detail because, you know, it gets sort of redundant at some point.  But Windows and Office and VBScript and Jscript and, I mean, it was a big - oh, and a big new IE update, as well, to catch IE up.  There were just a whole bunch of problems, many of them rated critical, meaning that it's a remote code execution exploit sort of thing.  So standard practice is just - I wanted just to remind our listeners that it's important, if they don't already have their machines updated, to recognize that we just crossed the second Tuesday of the month, and there was a whole bunch of stuff.



LEO:  Yeah, it's funny, it sometimes takes a couple of days.  I came in today, this morning, and my system said I rebooted last night after installing patches.  Because I have it set to, you know, automatically install, download and install any patches that come out, critical patches.  Which I think is probably the sensible thing to do.  Maybe not necessarily automatically install, but certainly to automatically download and notify you.



STEVE:  Yeah, that's what I do, too.  Of course Apple had - well, I don't mean to say "of course Apple had."  But Apple also had a substantial update.  In terms of hugeness, apparently it's about 180MB, or twice that if you've got an Intel-based platform.  I record our Skype sessions, I use a little Mac Mini that's PowerPC based.  And it had - I watched it - 180MB update to the OS.  And apparently...



LEO:  Oh, really.  Was it that big?



STEVE:  Yeah.  And apparently, oh, and there were a couple other little updates.  But this was a biggie.  And apparently Intel-based machines can be as large as 360MB.  So it takes a while.



LEO:  I don't think mine was that big.  It must be depending on what you've got installed and so forth.



STEVE:  That's probably the case.



LEO:  Although, you know, they break it up.  They say there's this, and there's that.  And mine did reboot two times, then wanted to install more and rebooted more.  So it was a - whatever went on, a lot of - some of it was cosmetic.  Some of it was not security.  We talked about this on MacBreak Weekly.  They fixed some cosmetic things in Leopard that people didn't like at all.



STEVE:  Interesting.  Well, also we talked last week or the week before, we mentioned an Adobe Acrobat problem that Acrobat had updated recently but hadn't really talked publicly about what was being fixed.  Well, that didn't stop the bad guys from figuring it out.  And the most recent Acrobat flaw is now being actively exploited to install a trojan called the ZoneBac Trojan, which disables AV, alters search results and banner ads, and is just another one of these bad things you don't want to get on your machine.  And it works by taking advantage of a flaw essentially in Acrobat that allows a bad PDF to install this trojan on your machine.  So if you - and my Acrobats recognized that there was a new version, and they've updated themselves.  So if users haven't launched Acrobat for a while, it's probably worth doing and having it check for updates because there's definitely something you want to get fixed before you go further.  Firefox had also an important update that for me, again, was automatic.  I had Firefox open for a while, I think it was maybe two days ago.  And it notified me that it needed to restart itself, having downloaded and fixed itself.  So it's like, okay, uh, go ahead.



LEO:  Now, of course beta 3 came out of Firefox 3.  But you're running 2.



STEVE:  I'm running 2.  I'm not, yeah, I'm not running in betaland yet.



LEO:  3 is actually, I hate to say it, but 3's more stable than 2 is.  But anyway.



STEVE:  Well, that's probably where everyone's attention has been.  They're all focused on 3.  It's like, that old version 2.  And there was a - over on the Windows platform, Skype has been having a series of problems involving various scripting exploits.  It was caused by the fact that Skype was invoking the Internet Explorer display control for some of its purposes.  So it's like having IE, unfortunately, hooked into an instant messaging system, which is really asking for trouble.  And so they were incrementally fixing them, one after the other, as they were occurring.  And then they finally figured out, that is, the Skype guys did, that this was dumb, that they ought to just do an architectural fix.  And the problem was that they were invoking this IE control under the local zone which had too liberal security.  And so now with this latest final update to Skype, they've architecturally improved it so that it's opening the IE control in the Internet zone that is inherently, by default, much more tightly bolted down.  So that hopefully will fix, well, basically it would have fixed all the problems they've been having.  And this way it's looking like it'll fix things that are coming up in the future.  So...



LEO:  It's a little worrisome, though, that a program can decide what zone to install itself into.



STEVE:  Yes.



LEO:  Because that means it could install itself, as it did, into a lower security zone.  If you're a bad guy installing malware on a system, you would do that.



STEVE:  Well, yeah.



LEO:  It shouldn't be able to choose.



STEVE:  It makes sense for software to be able to specify a zone more secure than the default.  But the default would be the local zone.  I mean, you'd expect, like, an application running on your system to be safe.  But then you're depending upon the thing you're installing to be safe.  And to suggest that Internet Explorer is safe, well, you know, few people would do that.  Also we talked a couple weeks ago about Yahoo's music jukebox ActiveX control that had some problems.  There's now malware actively exploiting that, installing backdoors on PCs.  No fix is available from Yahoo!.  So the only thing you can do, in fact, is to enable the so-called "kill bit" to prevent the ActiveX control from functioning, but of course that shuts down the music jukebox, which is not safe to use.  And in fact there have been so many ActiveX problems that finally the U.S. CERT agency, the U.S. Computer Emergency Readiness Team has just thrown up their hands and recommended that people disable all their ActiveX controls.



LEO:  Really.



STEVE:  Because, yes, because it turns out that there are new ActiveX controls which are being supported by Facebook and MySpace, the whole little new widget thing.  And so it's a typical case of non-security-aware people being in a big hurry to come out with new Facebook and MySpace widgets, which are operating on web pages.  And we've talked about ActiveX controls a lot in the past.  It was a really, really bad idea for Microsoft to allow IE to basically - it's like a DLL, it's actual code.  It's not even sandboxable in the way that JavaScript or VBScript are.  It's a DLL essentially that you are downloading and running in someone's machine.  And it's like, oh, isn't this nice, look at this new little widget that I have on my MySpace page.  But if it's not carefully written it's going to be, I mean, it's open to exploitation.  And so these ActiveX controls are causing all kinds of problems.  So one thing any IE user can do to disable ActiveX controls is set their browser's security level to high, that is, the highest available.  And the good news is, that tells ActiveX controls, no thank you.  Or...



LEO:  And if you don't use Internet Explorer, you don't have to worry about it at all.



STEVE:  I was just going to say, yes, exactly.  Or if you're using Firefox, and you were not using the ActiveX control extension that allows Firefox to invoke ActiveX controls, by default Firefox doesn't load and run ActiveX controls.  You'd be safe with Firefox.



LEO:  Yeah.  One way Yahoo! dealt with this is of course to go out of the music business entirely.  I don't know if this is related.  They killed their music business.  So the jukebox won't be around much longer anyway.



STEVE:  Well, that's going to be good news for a lot of people.



LEO:  But, you know, it's important to remember that a lot of these programs that use the Internet for content are really just ActiveX controls or versions of IE or using IE's engine.  And so they're just as vulnerable as IE is.



STEVE:  Yes, exactly.  Exactly.



LEO:  That's the easiest way to program it.  And on the Mac side, I have to say, the same thing happens.  WebKit, which is basically Safari, is used for a lot of Internet access in a lot of programs.  So when there's a WebKit vulnerability, just as when there's an IE vulnerability, it propagates to all these other programs.



Well, before we get on, I'm sure you have a SpinRite letter, and I'd love to...



STEVE:  Oh, I got a great one, actually.



LEO:  Let's do it now.  Then I'll talk about Astaro.



STEVE:  Okay.  Now, this individual who wrote to me has asked for anonymity because he doesn't want to get fired.



LEO:  Uh-oh.  That's always a good way to start.



STEVE:  The subject was, "Wow, SpinRite Really Works."  And he says, "Hey, Steve.  First, let me start off by saying that I listen to Security Now! every week and haven't missed a single episode.  Okay, now onto my story.  I am a Geek Squad agent at Best Buy, and as such I'm constantly seeing failed hard drives coming in.  It's sad because I know that many of them would be back to normal with just a few hours of SpinRite working its magic.  One customer named...."  Okay, now, I've changed the name here.  We'll call him John.  Although I had his real name in the original note.  "One customer named John came in with a look of desperation, as do most customers who come into the Geek Squad Precinct."



He says, "John stated that his five-year-old Dell laptop kept on bluescreening with the error message 'Unmountable boot disk.'  I immediately thought of SpinRite.  Best Buy, sadly, does not have a SpinRite enterprise license, or any license at all, for that matter.  So the 'agents are not allowed to use it.'"  He says, "I have emailed corporate about this, and they said they will see if the budget allows them to purchase one.  I explained the profit Best Buy will generate with all the backups customers come in for, but we turn away because their file system and drive are too corrupted."  He says, "I had two options.  I could send out his hard drive to Best Buy's service center for a fee of $1,712.32."



LEO:  What?



STEVE:  $1,712.32.  And he says in parens, "tax included."  He said, "Or I could tell him about SpinRite, surely risking my job, as this would be cutting revenue from Best Buy's bottom line.  But I couldn't let him spend the $1,700+ knowing SpinRite would probably would work for literally 25 times less.  So I did it.  I told him about SpinRite, where to get it, and how to use it.  Needless to say, you took a panicking radio personality and turned him into one happy man."



LEO:  Not me.



STEVE:  Not you.  He says, "Here is a quote from the email he sent me.  Quote, 'My computer had finished with SpinRite when I got home from work today.  Everything you said would happen, did.  My computer is now operational again.'"  He says - so this author says, "Thanks, Steve and the GRC team, for making an amazing product and making my job a lot easier.  I will continue recommending SpinRite for the rest of my life."  Then he says, "P.S.:  If you share this testimonial, please either change my name or blank it out.  I do not want to get fired."



LEO:  Yeah, because he was supposed to send it in for that $1,700 repair.  You're costing us money, kid.



STEVE:  Yeah, well, and it's funny, too, because an enterprise license is 10 copies of SpinRite.  So that's $890.  So it's less than half the cost of one of those $1,712.32 Geek Squad fixes.  So it's like, well, you know, they could certainly have an enterprise license with no problem.



LEO:  I might even know who that personality was.  But I'll ask you off the air.  I have my suspicions about just who that might be.  But it wasn't me.  Say that right now because I have a copy of SpinRite.  That's the first thing I try.  And it did work for me just, you remember, about a year ago it was that we lost a hard drive.  I'm still using it, by the way, so it did fix it.



Let me also mention a couple of things before we go much farther.  One is, oh, I forgot what it was.  It was really - it was a security thing, and I thought you would want to know this, and I forgot it.  Where is - oh, Service Pack 1, what am I thinking, of Vista.  Microsoft is moving that schedule up, and they've just announced that they're going to have it for MSDN users by the end of this week, on the 16th.  So we're getting very close to Service Pack 1 for Vista.  Which will be, I'm sure, an improvement.  It certainly will roll up all those patches into one big file.



STEVE:  So Vista has a whole bunch, as well?  I don't use Vista, so...



LEO:  Well, their service - yeah, I know, you're back in Windows 2000.  So for those of you in the 21st century, let me just...



STEVE:  No, but even XP, I mean, I'm...



LEO:  XP has Service Pack 3, yeah.



STEVE:  Yes, and I'm excited about that one.



LEO:  Paul and I talked about it quite a bit on Windows Weekly.  But so I'm going off of what he tells me.  But Service Pack 3 on XP is really just a rollup of all the patches to date.  But you need it because, of course, after you install Service Pack 2, you spend 10 hours rebooting and reinstalling the rest of the patches.  So...



STEVE:  So how is Service Pack 1 different on Vista?



LEO:  It changes some of the way Vista behaves.  And there's some question, some debate about whether it's faster or not.  A lot of people have been trying it, but it's not official code.  The official code will go out on MSDN this weekend.  They say sometime in March it will start getting pushed out to end-users.  But I don't know, you know, I only know what - Paul wrote a little bit of an FAQ, if you want to read more about it at the SuperSite for Windows, WinSuperSite.com.  And of course we'll talk about it tomorrow on Windows Weekly.



STEVE:  And I did hear that it was RTM, so...



LEO:  It is RTM.  And as I said, it's going to go out to tech and MSDN folks today or tomorrow.  By the end of this week, they said.



So we've talked about TrueCrypt at great length in the past.  Free, open source.



STEVE:  And actually a prior version.  The way I got into today's topic, today's topic is - I referred to it a week or two ago.  It's a very interesting and very impressive system that I found which is called FREE CompuSec.  The problem was I was doing some, have been doing some sort of just free consulting for a friend.  She's in the process of setting up a little office and some computers and a network.  And she's in the human resources field and is very security conscious, which I'm glad for.  I didn't have to do any preaching to her about the problems of security.  In fact, she was the motivation for my checking out and coming up to speed on Windows SteadyState because one of the problems she has had in previous entrepreneurial ventures is employees coming in and just installing their own crap on company computers, which is really a problem.  So SteadyState was the solution for preventing that kind of employee abuse of corporate resources.



But she has this - the other real concern is, since she's an HR company, and she reads the Wall Street Journal, and she hears all the horror stories about people getting laptops stolen or computers stolen, where hard drives have really confidential information on them.  So she said, you know, Steve, what do I do about protecting our workstations from someone breaking in and stealing them and discovering all of this potentially very confidential data on them?  Well, so that means, okay, it means one way or another we need to prevent the hard drive from being readable without authorization.



Now, we've talked about drive passwords in the past.  And, for example, my laptops have a fingerprint reader on them; and I use TPM, the Trusted Platform Module built into the motherboard that contains the code for essentially unlocking my hard drive.  I don't have the whole drive encrypted, but I'm using the drive password facility that's been available on little hard drives, especially laptop drives, for years now.  The idea being that only if I swipe my finger when I power up or restart the machine will the BIOS give the hard drive the password that it's been registered with to essentially enable the hard drive.  Without that, if someone got my machine and took the drive out of it, the only thing they can possibly do is low-level reformat the drive in order to get access to it.  That is, it would wipe it to zeroes in order to cause it to unlock.



Now, that's not secure against governmental agency-scale attack, that is, if I had a hard drive on my laptop and it was absolutely imperative that the data be recovered.  Because it's not actually encrypted on the magnetic surface, it would certainly be possible to go back to Hitachi or Seagate or wherever, and with enough inducement I'm sure they're able to unlock the drive.  So government subpoena sort of scale access is still possible.  But I'm not worried about that.  I'm worried about losing control of my drive and having it fall into bad guys' hands because certainly a drive password is sufficient to protect the information at that level.  And I don't really have anything super confidential on my system that, I mean, again, I don't want to lose control of it, but the drive password is just fine.



Now, the next level up is native hard drive encryption, which is, as we've also said in the past, beginning to be available.  It was an option that I just decided not to pursue when I purchased my most recent ThinkPads, is for an additional X amount of dollars it seemed like more than I needed to spend for that.  The drive itself uses the AES, the Rijndael cipher.  And so the BIOS, in a similar fashion to unlocking it, but the BIOS is actually giving it a passphrase, which the drive does not store on itself anywhere, but that passphrase is used to perform on-the-fly encryption and decryption.



So inside the drive, everything that I write to the drive runs through AES encryption on the way down to the magnetic surface, and runs back through it on the way out.  So there's no overhead in time at all.  That is, you get 100 percent performance that way.  And what's on the drive is always encrypted.  That is, the swap file, the hibernation file, all the contents, I mean, your deleted files, I mean everything.  And so without that, without giving the drive the passphrase that it's looking for, there's just - there's no way anybody - and again, not even under governmental-level subpoena strength, I mean, it is pseudorandom data on the drive which can only be decrypted by giving it the proper passphrase.



Now, as we know, brute-force attack is possible so you want a really good passphrase, something that couldn't be brute-forced.  But that's the only vulnerability that would be available would be asking the drive, here, take this as a passphrase, now give me the first sector, does this look like the boot sector or not.  And until you gave it the right passphrase, you wouldn't.  On the other hand, it would be reading this thing from the drive constantly, so you couldn't brute-force fast.  It would take a long time to brute-force a hard drive's magnetic media like that.  So either password-protecting the drive or native hard drive encryption are those first two options.



Now, in the case of the workstations that my friend had, she had no TPM on the - it was like the bottom-of-the-line Dell workstation.  Did not have any security built in.  There was not the ability in the BIOS to set a hard drive password.  So I couldn't even lock her drive if the drive had that option.  And certainly there was no native hard drive encryption.  So what I needed...



LEO:  You know what's funny, I just - I don't mean to interrupt, but I wanted to ask you about this.  There is hard drive locking built into the IDE spec; right?



STEVE:  Yes, it's been built into the ATAPI, the so-called ATAPI, which is...



LEO:  Try to get that acronym.  It's okay.



STEVE:  I'm blanking it.  ATAPI.



LEO:  It doesn't matter.  The reason that just came up is somebody mentioned that - called the TV show and said my hard drive's locked, you know, it's an old machine.  And I did some research and found out about this ATAPI locking.  But that's not encryption, is it?



STEVE:  It's ATA, which is - the ATA spec is the original spec, and PI is Packet Interface.  ATA Packet Interface.  I'm sorry, and I was so busy trying to remember the acronym I didn't hear what you said.



LEO:  So the question is, is this encryption, or is it just locking?  In other words, many machines will have it because it's such an old - it's part of the old ATAPI spec.  But does this...



STEVE:  Oh, yes.  Almost every drive anyone has been able to purchase for the last...



LEO:  You can do it, right, yeah.



STEVE:  ...10 years can be locked, but not encrypted.  Encrypted is only in the last six months or so.



LEO:  Does locking keep people off of it, though?  I mean, you can't get into it if it's locked; right?



STEVE:  Absolutely.  You cannot get into it if it's locked.  And the system is very mature.  And so if people have BIOSes where the BIOS gives you the ability to create a hard drive password - and now, see, this is something that's been available on laptops for a much longer period of time than it's been available on desktops.



LEO:  That's why I bring it up.



STEVE:  Right.  And so that's very good encryption.  It's all I - oh, I'm sorry.  It's very good protection.



LEO:  Protection, right.



STEVE:  It's not encryption.  It's very good protection because the hard drive will refuse to be a hard drive until the BIOS gives it the unlock password.  But because the data is not actually encrypted, under government subpoena I'm sure that Seagate or Hitachi or whomever could say, okay, we've removed the lock from the drive, grand jury.  Now you can - you're able to see what's there.  So here I was faced with the problem of...



LEO:  So she wouldn't use something like that.  That would be insufficient.



STEVE:  Well, she can't because it's not available in her BIOS.



LEO:  Ah.  It has to be supported in the BIOS as well as on the drive.  I get it.  You have to have an interface to it, for obvious reasons, yeah.



STEVE:  Well, yeah.  You have to have code which will use the ATAPI spec at power-up time to give the hard drive the unlocking password that it's looking for before you can even read sector one on the drive.  I mean, you can't get to the partition sector without that.  So I was faced with, okay, a desktop system like most of us have that doesn't offer you a hard drive password option.  And it was absolutely critical that, if the machine got stolen, the data would be protected.  So I dug around, and this was a couple months ago, and came up with this system, it's out of Singapore, called FREE CompuSec.  And if any of our listeners just put "free compusec" into Google, it's the first link that comes up.  And it's...



LEO:  Now, I'm confused because it's from CE-Infosys, yes?



STEVE:  Correct.



LEO:  That's a German company.



STEVE:  Yes.  In fact, they have three different offices around the globe.  So I don't know what the lineage of this is.  But I know that some of the stuff ends up coming out of Singapore; and you're right, CE-Infosys is German.



LEO:  Thank you.



STEVE:  So I have to say I am very impressed with the system.  I've looked at it very carefully.  I had to really understand it before I was going to trust it and stick it on these workstations.  Let me explain how this works.  It's called preboot authentication, and it's significant, not only for this, but also for the most recent version of TrueCrypt.  TrueCrypt 5.0 just came out of beta like a week and a half ago.  In fact, it was on February 5th it came out of beta.  They tweaked it a week later, just two days ago, in fact, on February 12th of 2008 they tweaked it and fixed a problem which was interesting to me because it's a problem that FREE CompuSec doesn't have because of the way they implemented their system.



But here's the idea.  We want to encrypt the entire drive.  And that's the only way to keep - if the BIOS won't support unlocking the drive, then we need to do something as the system starts to boot.  So the drive is not locked because the BIOS won't do that for us.  So it turns out that - and I mentioned this in passing recently.  The so-called boot sector, or the partition sector of a hard drive, is actually executable code.  The BIOS loads it into low memory and jumps to the front of it.  It actually runs the partition sector, which has just enough code - a sector on a hard drive is 512 bytes.  It has just enough code to interpret the table at the end of that sector, which is the so-called partition table.  It's got four entries in it.  And it'll read that table, which tells that code where to find the beginning of the bootable partition, which it then loads into memory and runs.  So it's because the partition table, that is, the partition sector is actually executable that a number of tricky things have been possible over time.  I believe we've talked about BootIt NG, which is one of my favorite, is my favorite multi-OS booting tool, where...



LEO:  I don't know if we have mentioned that.



STEVE:  It's actually OS independent.  It's not free, but it's very good, and it's not very inexpensive.  BootIt NG is - you install it on a hard drive.  And it installs itself in the first track of the drive.  Now, an interesting quirk of hard drive history is that partitions always start on an even track boundary.  So if you've got the partition sector on the first sector of the drive, which is where it is - literally it's on the very physical first sector, that's where every BIOS knows to find the partition sector.  Well, it's being there essentially ruins the rest of the track.  You can't have partition data on the rest of the track.



Once upon a time that was no big deal.  We had 17-sector MFM drives.  And so the 18th sector was the beginning of the partition.  Then we went to RLL, that had 26 sectors.  Now we've got drives that have many, many, many more physical sectors.  But for other historical reasons, the maximum number of sectors you can have on a track, logical sectors, is 63.  And you'd think, well, it ought to be 64 because that's a power of 2, except that sectors are numbered from 1, so there is no 0 with sector.  The first sector is number 1, then you go up to 63.  So my point is that you always have the first 63 sectors of a hard drive almost uncommitted because that first sector is the partition table, and the partition table sector.  And the beginning of the first partition will start on the second - I'm getting myself confused - the first sector of the second head of the drive.  So that is to say the second track of the drive.  So you've got almost 64 sectors.  You've got 63 sectors, each 512 bytes long.  So a little less than 32K bytes of space where clever people can tuck a program.



So, for example, BootIt NG creates a custom boot sector that displays a simple text menu on the screen, allowing you to choose which OS you want to boot.  And in fact I do remember, Leo, on The Screensavers many, many moons ago, some guy wanted to see how many bootable OSes they could have on one drive.  Do you remember that episode of The Screensavers?



LEO:  He had hundreds; right?  It was just crazy.



STEVE:  It was insane.



LEO:  I don't even know how he found that many operating systems.



STEVE:  So anyway, a custom bootloader will take advantage of the fact that a partition sector is actually executable code.  Another class of application that has used this fact, there were some - it used to be that BIOSes did not know how to handle the advent of really big drives.  And so when you would buy a copy, for example, of - buy a copy.  You'd buy a very big hard drive, like a big Maxtor drive.  They would come with a little CD or a little diskette that had a sort of a BIOS patching utility...



LEO:  Right, I remember that.



STEVE:  ...that would allow - it would allow an older machine to recognize a drive's full size.  Well, that worked in the same fashion.  It altered the partition sector to add some code that would essentially replace the BIOS's table that just didn't understand how to deal with drives of that size with a much bigger table.  So there were - and of course now all contemporary BIOSes are up to speed, and they know how to ask the drive how big it is, and so they sort of adapt themselves dynamically rather than having a fixed table of drive sizes.



Well, the final really interesting possibility here for what to do with the fact that a partition sector is executed code is preboot authentication.  That is, you could have an entire drive encrypted, except just the first track, just this chunk of data that is behind the partition sector.  That could be executable code which is enough to get the system booted, that is, it would prompt you, it would put up some sort of a screen and prompt you for a passphrase or a username and passphrase or whatever they want for your authenticating to the system.



That code would then proceed to read in the beginning of the bootable partition, decrypting it on the fly.  That is, it would read the physical sectors, decrypting those sectors as it loads them into memory.  And it would stay in control.  Essentially it would be - there's an old interrupt I know really well as the author of SpinRite called "Interrupt 13," which is the way the BIOS does its data reading and writing.  So Interrupt 13 and the BIOS code is what gets Windows going until Windows' own driver takes over, takes over control from the BIOS and runs from there.  So you could have this preboot authentication technology, which would - it would hook the Interrupt 13 BIOS, that is, it would - essentially it would intercept Interrupt 13 on the fly, performing on-the-fly decryption, until Windows took over.  And then a companion Windows driver would know how to continue decrypting the drive in order to allow Windows to run and the entire drive to appear decrypted to Windows because there would be a seamless handoff between the decryption that happens to get Windows going and then a new Windows driver that's provided by the same decryption system that would pick it up and continue.



And so what this allows is it allows the entire drive to be encrypted, I mean, really, really strong encryption.  It uses 256-bit AES Rijndael encryption.  No force on earth could cause this data to be decrypted unless you provided it with the authentication information at boot-up.  And once going, Windows just sees it as a regular drive.  It sees it as, you know, it has full access to it, and it's able to use it.  But if anything happened, for example the drive got stolen or the system got stolen, which was what I was concerned about preventing, there's no, absolutely no vulnerability of the data on the system.



LEO:  Can I be a turd in the punchbowl here?



STEVE:  Sure.



LEO:  It's not an open source encryption program, is it.



STEVE:  No, it's not.  It's free, but not open source.



LEO:  And here's why I raise that issue is, I mean, I don't know this company.  I don't know what backdoors there are.  It's not even a U.S. company, not that I would trust it more if it were a U.S. company.  But this is why I stick with things like TrueCrypt.  I don't know what's in there.  I don't know if there's a backdoor in there.



STEVE:  Well, that's a very good point.  More to my concern was that, as I was getting to know this system, I had some questions about specifically how things were done.  That is, you know, exactly how...



LEO:  Right.  You can't tell how they've implemented it because you can't see the source.



STEVE:  That's very true.  That's very true.  Now, I have to say this hasn't put me off of it at all.



LEO:  Yeah, because you're a closed source guy.



STEVE:  Well, because...



LEO:  You are using Windows.  I mean, I guess you're already in that environment.



STEVE:  Well, yeah.  I mean, there's certainly far more danger from the user of Windows and Internet Explorer than there is from this whole-drive encryption system.  Now, one of the things that I was concerned about was what is the overhead of doing this, because we've got a software driver that has essentially imposed itself between Windows and the hardware, that is, Windows and the drive.  And those drives are not super speedy, we know, anyway.  And it's not like it's software encryption/decryption that is sitting there between Windows and RAM or something, where there would be tremendous overhead.



So what I did was I made a drive - I used Drive Snapshot to create an image of the system.  And I actually had an image that I had made of the system from, I don't know, like a year before.  So needless to say there were many Windows updates, many security updates since that image.  So what I did was - and anyone who's ever used Windows Update knows that that just drags a hard drive horribly because you've got all of these files that are being replaced and old ones deleted and so forth.  So what this allowed me to do was this allowed me to create an environment where I was able to benchmark the performance of this FREE CompuSec whole-drive encryption before and after.



So I returned the system to an old image.  I then - oh, and I also set up Vopt.  Vopt is able to run from a command line.  And I found a command line timer program, it was part of a Windows Resource Kit called EndTimer, that allowed me to time the execution of Vopt running from a command line to defrag this very fragmented system.  So I went to the image.  I updated it with Windows Update to bring it current, which just fragmented it to pieces.  Then I timed the defrag operation without FREE CompuSec installed.  Then I restored the image, reupdated it so that it was again fragged in exactly the same fashion, this time with FREE CompuSec installed.  The defrag without any encryption took five minutes and 23 seconds in order to bring the drive back to a known defrag state.  Five minutes and 23 seconds.  With FREE CompuSec installed, it was five minutes and 54 seconds.



LEO:  That's not bad.



STEVE:  So it was really not bad.  It was less than 10 percent overhead.  It was 9.74 percent overhead, which is unnoticeable in any sort of regular usage scenario.  So, okay.  So that's just one of the things.  That is, this whole-drive encryption is just one of the things that FREE CompuSec does.  It also - and again, this is a - I have to say, I am very impressed with the system.  It creates log files for itself.  It installs itself carefully.  You're able to encrypt the whole drive from outside of Windows or from inside of Windows.  If you do it from inside, I mean, it's sort of freaky, but you can literally be encrypting it while you're using Windows because it's moving from the front of the drive uniformly forward.  It knows where it is, that is, how far it's gotten.  And that's just a simple sector number.  I'm now on sector number this.  Now I'm on sector number this.  And so the driver, the Windows driver is being informed in a synchronous fashion whether or not to decrypt based on whether it's accessing earlier on the drive that is already encrypted, so it needs to be decrypted on the fly and reencrypted before any writes, or whether we haven't gotten that far yet, in which case the data is still in the clear.  You're able even to shut down Windows and then restart it, and it will pick up where it left off and continue the encryption process.



So they have this whole-drive encryption as part of the FREE CompuSec suite.  Also CD encryption.  You can create encrypted CDs and DVDs which are burned with any of a number of keys that it will make.  And again, the result is a CD or a DVD that is just noise.  It is pseudorandom meaningless noise unless you have the matching key.  And this all uses AES 256-bit and Rijndael cipher.  It will also handle removable media encryption - diskettes, any removable drives or USB drives.  You're able to specify for any drives that the system has whether you want them to be encrypted or in the clear.  And so it will do on-the-fly encryption to and from reading and writing from those drives.  It will do individual file encryption using Diffie-Hellman public key crypto, so you're able - it'll create a pair of keys, a public and a private key, as we've discussed many times in the past, so that you're able to...



LEO:  Why would you have public/private key encryption for a drive?



STEVE:  Oh, no, for individual files.



LEO:  Oh, I see, for files.  So you could send somebody the file, or they could send you a file, better yet, yeah.



STEVE:  Exactly.  Yeah, you would be able to publicly post your public key, and then they would use this to encrypt a file that they send you, and you know that it was encrypted using that key, and you're the only one who's able to decrypt it.  They even have what they call SafeLan is on-the-fly LAN encryption that allows you to create folders and directories on a remote server which are fully encrypted over the LAN.  So any data that is being transacted through Windows filesharing to any file in a folder, with a nice, hierarchical, I think it's six or seven levels of key hierarchy, where you're able to specify, with a lot of granularity, who is able to access which files on the LAN.  So, for example, you could have multiple systems all sharing files on a common server, and have good control over who is able to access and essentially see which files that are being shared on the server.



And finally, secure VoIP is part of this.  Now, all of this is also available for Linux, except the VoIP is Windows only.  So if there were an application, for example, within your corporation, where for whatever reason you need point-to-point, absolutely secure audio link, audio conversation, voice over IP, this system has it through a system called ClosedTalk, which uses the same crypto technology, builds the whole infrastructure for a VoIP system where everything going over the link, again, is just pseudorandom noise, absolutely indecipherable unless you have the key.  And they've got all of the technology and a really nice presentation, I have to say.  I'm very impressed with this package.  Now, the only thing I know that competes with this is TrueCrypt 5, which is just out, as I said, updated two days ago.



It was interesting, one of the update notes for TrueCrypt mentioned that they had reduced the size of the decompressor, or of the preauthentication stuff, by 18K, which would solve a problem that apparently many people had been having since its release of TrueCrypt saying that it was out of space.  What that meant is that, remember we talked about how there are literally 62 sectors of space behind the partition sector, which is probably where TrueCrypt was storing its data.  The FREE CompuSec system works differently because I did, even though I've never been able to get a hold of these guys, their sector, their partition sector references areas on the main C drive and is able to load those.  And those are locked in place.



I'm very sure, although I haven't done an extensive analysis of TrueCrypt, we're going to address TrueCrypt 5 in an episode here within the next few weeks because I want to essentially wrap up the whole question of preboot authentication and whole-volume, whole-drive decryption.  TrueCrypt it looks to me like allows you to encrypt one partition, whereas FREE CompuSec encrypts the entire physical hard drive.  There is no provision for only encrypting one partition of the hard drive.  So it does the entire thing.  Which, you know, may or may not be a problem.



One thing that FREE CompuSec does that TrueCrypt does not do, and they make a point about this, so it must be something that's difficult to do, is support for hibernation.  FREE CompuSec will encrypt the hibernation file, which is a snapshot of the system RAM at the time the system was hibernated.  TrueCrypt cannot, and so it disables hibernation mode completely when you are using a TrueCrypt volume.



LEO:  Because it was a security vulnerability because that hibernate file would be unencrypted.



STEVE:  Yes, it is unencrypted; and it shows, you know, it's like a snapshot of RAM.  It'll have your various keys, it'll have the files that are open, everything you're doing at the time of hibernation.  Now, the problem is, I mean, I'm an avid user of hibernation.  I boot my laptops very rarely because hibernating is just, I mean, in the original days hibernation was kind of flaky.  Sometimes the system wouldn't come back from hibernation.  Your VGA screen wouldn't work again or whatever, or sometimes USB wasn't functioning right.  Well, that's all been worked out.  And Microsoft has put a lot of time into power state management in Windows.  So I come in and out of hibernation constantly with my laptop.



Again, I don't know how concerned I would be if my hibernation file were not encrypted.  But it's definitely something to be aware of, that it is something that TrueCrypt specifically does not do, and they disable hibernation if you encrypt your entire drive because they want to make sure you understand that this is no longer safe.  Whereas FREE CompuSec does manage to encrypt the drive.  So it is at least one difference between them.  So I just want to say that I'm, despite the fact that, as you say, Leo, it's not open source, I've spent a lot of time with this thing.  I'm very impressed with the technology.  And I wouldn't hesitate to use it, even though it's not entirely scrutinizable from an open source standpoint.



LEO:  I'm just a paranoid.  I just figure, oh, some government has created this.  Particularly the VoIP.  That's, you know, it's one thing, okay, so I encrypt my hard drive.  They don't want my hard drive, and who cares if they have a backdoor to my hard drive, whoever "they" is.  But VoIP might be the kind of thing, you know, if I were a government I'd encourage people to use our, quote, "encrypted voice over Internet" so I could snoop on them.  So that makes me nervous.



STEVE:  Sure.  I mean, it's definitely a possibility.



LEO:  Yeah.  Generally when it comes to encryption I like to stick to open source stuff just because at least it could be verified by - not by me, certainly.  Maybe by you, maybe by somebody who knows what they're doing.  But I just presume that it has been, and I don't even know who these guys - had you heard of this company, CE-Infosys, before?  I hadn't.



STEVE:  No.  Although I did pick up a pointer from one of our listeners who said they've got a very good reputation.



LEO:  Yeah.  They've been around for 27 years, it says on their website.  So, yeah.  If you're encrypting your company's laptops, you don't really care if some government has a backdoor to them.  That's not the issue.  The bad guys you're worried about.  It is CE-Infosys.com.  You know, I'm going to bring this up in a second.  There's a couple of interesting recent court cases about encrypted drives.



STEVE:  Yes, as a matter of fact I was going to talk about a Washington Post story.  But go ahead.



LEO:  So I guess this was a fella coming across the border into Canada from the U.S.



STEVE:  Yes, you and I have the same story.



LEO:  Yeah.  He had on his hard drive some pretty nasty titled files.  I mean, really, I wouldn't even want to say them out loud, they were so nasty.



STEVE:  No.  I was planning not even to mention the content that this guy had.  I mean, ugh.



LEO:  Doesn't sound good.  But it's just a filename.  They were encrypted.  He admitted that he downloads porn and occasionally comes across child porn, which he immediately deletes.  Canadian officials arrested him - or I guess it was U.S. officials, I think he was coming in from Canada - arrested him and prosecuted, saying you've got to give us the password.  You have to unencrypt this.  They couldn't do it themselves.  I don't know what he was using, but they couldn't unencrypt them without the password.  So he obviously was using strong encryption.  He refused.  A judge has ruled that he has the right to avoid self-incrimination.



STEVE:  Yes, exactly.  It was essentially the judge says that he has a Fifth Amendment right not to incriminate himself.



LEO:  Fascinating.  Very controversial.  I mean, let's say - let's not say - the child porn thing makes it kind of as a macguffin.  It makes it more controversial.  But let's say he had on there a file saying a plot to blow up the Pentagon.  So then it's, I mean, that's still pretty bad.  But you get the idea.  It doesn't - do police officials have the right to demand passwords?  Judge says no.  And in fact this isn't the first case.  In another case a few years ago a judge said it would be equivalent to demanding to look into somebody's mind.  You have a right to privacy.  So that's kind of interesting.  It means, at least in this country, it's not true in many other countries including England, but in this country the courts seem to protect your right to encrypt stuff and keep it encrypted.



STEVE:  Well, yeah.  And the reason I found this really interesting was that it does speak to the question that people have asked.  It's like, okay, well, if I really want to keep my private data private from everyone, and I have the technology to do it - and, I mean, this is the problem that the FBI and Justice Department face now is that they make the point that more and more people are using state-of-the-art encryption technology for their own privacy, and that it completely thwarts them because, I mean, there aren't backdoors to this kind of technology.  When it's implemented correctly, there is nothing they can do.  And so it's extremely frustrating for them because here they're got bad guys that are hiding evidence of their wrongdoing behind the technology, and using the technology.  And so we've argued, and we've talked about this several times, Leo, the morality and the ethics of this, we've argued that it's not the technology's fault that it's that good that it's a tool both for protecting free speech and privacy, but unfortunately there's a dark side.  It protects the bad guys who are able to use it.



LEO:  I was frankly stunned.  The court decision surprised me.  I would not have expected that.



STEVE:  Yeah.  It says on November 29, Judge Jerome J. Niedermeier ruled that compelling Sebastien Boucher, a 30-year-old drywall installer who lives in Vermont, to enter his password into - so compelling him to enter his password into his laptop would violate his Fifth Amendment right against self-incrimination.  The judge said, quote, "If Boucher does know the password, he would be faced with the forbidden trilemma of either incriminating himself, lying under oath, or finding himself in contempt of court."



LEO:  And so they had him in jail because he wouldn't give them the password.



STEVE:  Yeah.  And so the judge said he is protected by the U.S. Constitution against being forced to give up the password.



LEO:  Now, you know, I've spoken to the Secret Service and law enforcement officials, and I've asked them this question.  This was some years ago, and they said, you know, we usually just ask the guy, and they give it to us.  A lot of crooks don't make a big deal about not giving up the password.  They're intimidated or whatever, and they do give up the password as part of, you know, and I'm sure they get read the Miranda rights.  But as part of the interrogation this is something that they willingly give up.  Also, you know, that's one of the things about TrueCrypt is this - I don't know if CompuSec has it.  But TrueCrypt has this, quote, "plausible deniability" where you can't tell - the flaw in this Boucher's problem was that you could read the filename.  If he had used TrueCrypt, you wouldn't even know there was any data there.  Wouldn't look like a file at all.



STEVE:  Correct.  In TrueCrypt you're able to essentially use a space at the end of the container, the container file you create, to create an additional sort of hidden place.  And the way TrueCrypt builds its container, when you set up a TrueCrypt container it fills it all with pseudorandom data that looks just like...



LEO:  Noise.



STEVE:  ...pseudorandom data.  That's what it is.  So there's no way to forensically analyze a TrueCrypt container and determine what's in it or whether there's anything else in it.  So you're able to give up, for example, your external password and go, oh, look, here's what I've got in my TrueCrypt container.  Well, the fact is you could still have another one, but there's no way for them to know or ever prove that you actually had another one that unlocked this essentially sort of a hidden compartment inside the container.  So it's very clever.  And no, FREE CompuSec doesn't have anything like that because it doesn't work in file containers.  It encrypts the entire hard drive.



LEO:  And it would be immediately apparent that the drive is encrypted.  There's also, I don't know if it's TrueCrypt, I think it is TrueCrypt, there's some program that has this capability of having a pseudo key which you give the law enforcement people, and it unlocks something completely benign, and you're off the hook, and the stuff that you're really trying to hide - now, I'm not supporting all this because, I mean, I think about a terrorist.  But fortunately terrorists don't seem to be technologically very savvy.  But I think about a terrorist, how they could use this.  Look, it's a picture of Mickey Mouse.  And instead it's, you know, blueprints of the Rocky Mountain missile silos.  So I'm of mixed feelings about this, you know?



STEVE:  Well, the one thing I want to mention relative to hard drive encryption, that is, whole-drive encryption, and this applies to native hard drive encryption where it's being done in the drive's hardware, and also to FREE CompuSec or the whole-drive encryption offered by TrueCrypt that we'll be covering extensively once I've brought myself up to speed on it completely, is it completely solves the problem of discarding your hard drive.



LEO:  Oh, yes, that's right.



STEVE:  That is, you take one of these drives out, and you can just, I mean, you can hand it to anybody you want to.  There's nothing on the drive that is meaningful or forensically recoverable if you have encrypted the entire drive.  So you don't have the Darik's Boot and Nuke sort of problem, or the need to worry about having securely deleted things.  It is just pseudorandom data on the entire drive.  So you can sell it on eBay and not worry that anybody is going to be able to get anything else from it ever.



LEO:  It's amazing.  It's a very interesting philosophical discussion, I find.  All right.  We've got links to that program in our show notes, so you can find out more.  You can of course go to GRC.com.  That's where Steve not only puts his show notes, but also 16KB versions of this show.  So if you know somebody who doesn't have a lot of bandwidth but still wants to listen, they can listen to that lower quality version, and it's a much smaller file, it's one quarter the size.  You can also get transcripts there.  And I think a lot of times people find it very nice to be able to read along, even highlighting and underlining information that they want to keep track of.



Those are all available from Steve's site, GRC.com, not to mention all the free stuff he gives away there, great programs like Wizmo for configuring your system or ShieldsUP for testing your router, all at GRC.com.  And of course that's also the home of SpinRite, the finest, the best, the one-and-only hard drive maintenance and recovery utility, used for decades by geeks everywhere.  We need to come up with a slogan like that for you.  Saving the world one hard drive at a time.



STEVE:  I actually do have a slogan.



LEO:  Oh, what is it?



STEVE:  It works.



LEO:  Typical Steve.  Simple, to the point, no frills.  It works.  That's all you need to know.  Hey, Steve.  Great to talk to you.



STEVE:  Likewise, Leo.



LEO:  Have a great week.  We'll talk again next week on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#132

DATE:		February 21, 2008

TITLE:		Listener Feedback Q&A #35

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-132.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 132 for February 21, 2008:  Listener Feedback #35.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, everybody's favorite podcast about protecting yourself against the bad guys on the Internet.  Here he is, the good guy, Mr. Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.  You know, I think this is everyone's favorite podcast.



LEO:  Well, you're getting a lot of positive mail, is that why you say that?



STEVE:  Really, really, yeah, really do.  I just - for these Q&A episodes I get to read through the feedback that we receive.  And, you know, one of these days - I don't think I'll ever retire.  But I would love to do nothing more than be able to read all of the feedback.



LEO:  Just read your mail.



STEVE:  Every time I check it there's 600 pieces of email in the Security Now! folder.  It's like, oh, god, I can't, I just can't read and reply.  But I want everyone to know who writes how much I appreciate the feedback we do receive.  And I do try to, like, rush out little quick replies when there's something that I want to reply to, but I don't want to use it on the show.  So anyway, I do what I can, and I really do, really do encourage people and thank them for sending their feedback to GRC.com/feedback.



LEO:  Yes, indeed.  We thank you very much.  It's always nice to get so much positive feedback for the stuff we do.  So, and I extend that to the entire network.  Now, this is a Q&A episode.  And we're going to get to - we've got 12 questions; right?



STEVE:  And we do have two fun ones at the end.  I think we got the most clever hack and the great observation.



LEO:  Observation of the Week and the Hack of the Week.  Cool Hack of the Week.  That sounds good.  You want to go right into the questions, Steve?  Do you have addenda?



STEVE:  The good news is it has been a relatively quiet week in terms of security disasters.



LEO:  Good.



STEVE:  And we have a lot to cover, so I don't want to take too much time.  But I wanted to mention a couple things that have just sort of been sort of buzz that's in the air.  There is increasing thought about requiring encryption on different things, on corporate databases containing personal information.  In fact, there's - I remember seeing a blurb somewhere abroad, some country was considering requiring government laptops to all be encrypted.  So it's sort of just a general movement in a good direction.



LEO:  Well, they get lost and stolen so often, for crying out loud, they really out to be encrypting that secret stuff.



STEVE:  Yup.  And of course last week's show - and we've got a lot of questions about whole drive encryption because of last week's conversation about the FREE CompuSec product.  And next week's show we're going to do TrueCrypt v5.  We haven't talked about TrueCrypt since '06.  And of course, as many people know, TrueCrypt v5 adds whole drive encryption, so that's very topical.



Another nice bit of news, we had talked about the stories that ISPs were interfering with their customers' actions, whatever they were.  One of the large carriers was, for example, interrupting torrent downloads and things.  A couple of U.S. Representatives have introduced what they call their Internet Freedom Preservation Act, which is a formal Net Neutrality law, which would be a really good thing because essentially it means that the ISP can't mess around with the data.  They've got to treat it all the same.  Which is really good.



One other little bizarre bit of news that I ran across I thought our listeners would get a kick out of, and this sort of falls in the category of classic security and obscurity, you know, the old phrase is that you can't rely on obscurity for security.  It turns out that a German firm has built a computerized unshredder.  This thing is a conveyor belt that can scan up to 10,000 little itty-bitty bits of paper at once and reassembled shredded documents.



LEO:  Oh, my goodness, even the crosscut ones?



STEVE:  Yes, I mean, little, itty-bitty bits of paper.



LEO:  Oh, goodness.



STEVE:  And so I've got a crosscut shredder, and I'm diligently aware of issues of identity theft.  And so I don't throw things away that have any information about me on them.



LEO:  You shred them.



STEVE:  I just run them - I stick them in the little slot, and it crumbles around for a minute, and then it turns them into confetti.  Well, what a perfect example of nonsecurity, essentially.  It is obscuring the document by chopping it up in bits.  But clearly, with the right technology, you just dump this whole bin into some shaker that puts the bits out on a treadmill, and a computer scans it and reassembles them.



LEO:  Now, that's a fairly expensive operation.  I doubt it's going to be widespread.  But if there's enough money in identity theft, I guess somebody could set it up.



STEVE:  Yeah, well, these things all start being expensive, and then they get cheaper over time.  So I wouldn't - I'm not, obviously, I guess that means that after you shred, then you want to separate your documents or your confetti into 10 separate bins and drop them off at different locations or something.



LEO:  Oh, my goodness.  Or burn it.



STEVE:  Yeah.  And the other thing I wanted to mention, I've been sort of thinking about your comment, Leo, last week about the closed source nature of FREE CompuSec versus the open source nature of TrueCrypt.  And of course I certainly like the fact that TrueCrypt is open source.  But my sense was that maybe we came off a little too negative about the closedness of closed security solutions.  And what I wanted to comment, I guess, is that it would be a shame if someone didn't use something that was valuable to them for security because it wasn't open source.  And I wanted to observe that the vast majority of software we use is - well, Windows uses at least - is closed source.  I mean, Windows itself is closed source.  All of the firewall, the personal firewall products are closed source.  And we rely on them and trust them.



Now, I guess the point is that when something is closed source, you're relying on the reputation of the closer of the source, you know, the author of the product.  Whereas, in theory, when something is open source, you're able to examine and look at it.  Now, what most people of course do is expect that other people have looked at the open source and examined it.  But in the real world we've seen instances where everyone assumes somebody else is vetting the open source code, and no one ends up doing so.  Or that is to say that analyses have shown that open source code, in terms of inadvertent vulnerabilities, is not necessarily any more secure than closed source code.  So I just sort of wanted to say let's not discard closed source solutions just because they're closed source, recognizing that we are depending upon the reputation of the source of the code to have integrity and the best interests of its users at heart.



LEO:  And there's a little bit of a difference.  If you're using a firewall, you're not trying to protect against, say, government intrusion necessarily.  You're worried about hackers.  If you're using encryption, and the encryption was designed without your knowledge by the NSA and sold through CompuSec, that's a very different thing.



STEVE:  Yeah, although CompuSec, for example, is using AES standard Rijndael...



LEO:  What they say.  How do you know?



STEVE:  Right, true.



LEO:  So my point is that encryption, I never use a closed source encryption product.  And I think that - I think it's a little risky to use a closed source encryption product.  I mean, I'm going to use a closed source antivirus or a closed source firewall.  I don't think that's the same level of issues.  And you're right, you have to trust.  But on encryption I - there's enough good open source encryption stuff, I don't see a need to use closed source, I guess is my point.



STEVE:  Right.  Well, and I have to say, I am so impressed with TrueCrypt.



LEO:  TrueCrypt, yeah.



STEVE:  I've been, well, I mean, with the whole drive encryption of TrueCrypt.



LEO:  Well, and that's the issue, yeah.  If there were no whole drive encryption in TrueCrypt, or it weren't as good as FREE CompuSec, then I could see that.



STEVE:  Yes.  And we'll be talking about it in depth next week.  But I have to say we've had a lot of listeners from last week who did jump onto FREE CompuSec and are using it and liking it.  And some listening to the end of our show, where we talked about the fact that TrueCrypt had added this, have been working with TrueCrypt, and we'll be reading their postings right now.



LEO:  Yeah, I'm curious.  Yeah, I'll be very curious.  One other story, and I'm just going to leave this with you, and I'll send you a link to it.  Interesting article, and this is more in your other area of expertise, in ZDNet by a guy named Robin Harris who writes a storage blog called Persistence of Memory.  And he's talking about something called "latent disk errors," or actually "latent sector errors," LSE, and how larger drives, which you've always said seemed like a bad idea, larger drives are actually getting some serious data corruption due to LSE, and there's not much you can do about it.  Have you heard about this stuff?  It's very interesting.



STEVE:  No, I can't imagine what it is.  I mean, I'm sure when I read it I'll go, oh, yeah, okay.  But, you know...



LEO:  Oh, I'm sure you will.  This was a - it comes from a vendor, okay.  But he works at a network-attached storage vendor, Network Appliance.  And so they're studying the reliability of drives.  And they published something called an Analysis of Latent Sector Errors in Disk Drives.  Interesting study that says 8.5 - they make a distinction between consumer drives and business drives, which they call something kind of odd, like enterprise drives.  See, they call them "nearline" drives.  I'm not sure what the difference is between that and - I don't know.  A nearline drive is a consumer drive.  An enterprise drive is a high-end drive.  They say 8.5 percent of all the consumer drives developed LSE, including size, age, vendor problems, errors, these all make a difference.  And they say this is why desktop RAID or cheap RAID with cheap disks is a bad idea.  Anyway, I'm going to send you the link, and I'd love to get your impression on it.



STEVE:  Cool.  I will definitely read it, and we'll let our listeners know.  Speaking of disk errors, I had a funny little quick anecdote here.  This one caught my eye because the subject line was "Damn you, SpinRite!"  Eric Gerlach wrote, he says, "Hi, Steve.  I picked up a copy of SpinRite a while ago when I first started listening to Security Now!.  It's come in handy a few times since then, but never has it frustrated me as much as it did a few months ago."  And so I'm reading this, I'm thinking, uh, okay.  He says, "One of the computers at work, a point-of-sale terminal, got the dreaded unmountable boot volume error.  Given that it was needed desperately that night, I got out SpinRite and did a run.  A few hours later the drive was running like new again, and the night went by without a hitch."  So I'm still thinking, okay.  And he says, "I still had my suspicions about the drive, though," he says, "and as the computer was still under warranty, I decided to call Dell to get a replacement.  When I called them the next day, SpinRite had worked too well.  I could not convince the Dell representative..."



LEO:  There was a problem.



STEVE:  "...that the drive had failed in the first place," he says.



LEO:  This drive's fine.



STEVE:  "Then, after months of waiting, two days ago the drive failed again.  Once more, right before a busy night.  But this time we called Dell first and got the new drive sent.  Then we ran SpinRite, and all was well again.  Curse you, Steve, for making a product that works too well."  And he says, "Cheers, Eric."  And he says, "P.S.:  I know that using my personal copy of SpinRite for work was bad form.  But I've got a site license in my budget for next..."



LEO:  Oh, that's good.



STEVE:  So, absolutely.  And I'm happy to trade a use of SpinRite for a great success story any day.



LEO:  Well, now, be careful what you...



STEVE:  Okay.



LEO:  Buy the product, folks.  Buy the product.  And we should reiterate now, as more and more drives now, SSD drives are going out, Apple now is selling one with the MacBook Air, which is really expensive.  And I see other computers coming out with these solid-state drives that - you do not recommend SpinRite on solid-state drives.



STEVE:  Correct.  It is made for, I mean, intimately made for the technology of magnetic recordable media.  And so it doesn't make sense on a CD-ROM or a DVD or, I mean, it's about the magnetic domain.  That's where SpinRite's technology really does work.



LEO:  Right, right, right.  Okay.  Let me see.  Anything else?  Oh, I sent you the LSE thing.  I'll be really curious if SpinRite can work with those.  I think the problem with these latent sector errors is that even the system doesn't know about them.  They're just...



STEVE:  Well, I don't know what they are.  I mean, they've made up a term.  I mean, I've never heard the term.  So I would have heard it if it...



LEO:  Yeah, I think you would know about it.



STEVE:  If it was a common term.  So they made up something.  I'll find out what they're talking about, and I definitely will talk about it again.



LEO:  They're transient errors, basically.  But we've talked about that before where the ECC will fix an error.



STEVE:  Yeah.  I mean, the only kind of transient error I could see would be there is checking on the cable, that is, there is a CRC test that the drive performs on the transfer between the drive and the motherboard through the cable.  And that can be transient.  And CRC is not a super robust test.  So it's possible...



LEO:  ECC is, of course...



STEVE:  ECC is really robust. 



LEO:  This is what they say.  This error occurs when a particular disk sector cannot be read or written, or when there's an uncorrectable ECC error.  And of course at that point any data previously stored in a sector is lost.  But that's what SpinRite does is find those places...



STEVE:  And fixes them.



LEO:  ...and fixes them, if it can read it.  Now, if it can't read it, you are going to lose that data; right?



STEVE:  No, that's one of the cool things that SpinRite does, and this does bear on one of the questions we have today because people were wondering about what about SpinRite and encrypted hard drives.  SpinRite is able, and it's one of its best tricks, to perform a partial sector recovery.  So it's - and that's what this whole DynaStat thing is in SpinRite where it kicks in, if it's unable to, after trying all kinds of tricks, to get a perfect read, and it's able to accept as much of the sector as is available, which might mean you lose a few bytes.  But, for example, and that's in the middle of a directory, you could still get all of the rest of the branches off the directory and get a huge amount of data recovered.  So SpinRite's able to do partial sector reads which is, you know, really handy.



LEO:  That's good.  All right, good.  Well, I'm sending you this.  And maybe we can talk more about this.  It's an interesting subject.  But right now we have plenty of questions from you, our viewers.



Glenn Edward in Notting- or listeners, since you really can't see us.  Glenn Edward in Nottingham, Maryland is not, I repeat, not patch happy:  Dear Steve, I downloaded and tried to apply the latest Microsoft security patches of this month.  I have never before had so many failures of such patches.  No damage to my system, but at least three of the five patches failed to complete.  According to the logs, either some System\CurrentControlSet subdirectory wasn't present, or something (iis_www) wasn't of the proper value.  I wonder if this is because I have several Windows XP services turned off for improving security, or because I haven't applied all the patches since SP2, only the ones for correcting security flaws.  Are these latest patches expecting a certain state of Win XP that not everyone has?  Has Microsoft created them without accounting for more than one configuration of Win XP or Win XP Pro?  Should I worry these patches aren't in effect, if there isn't something present for them to patch?  I've already checked the Knowledge Base on these patches, and there's nothing mentioned about downloading something to alter or supplement the system before the patches are applied.  He gives the patch numbers.  I don't think we need to give those out.



STEVE:  No.  This is a really good question because it reflects a - well, it reflects my having given up.



LEO:  Okay.



STEVE:  I mean, the gurus in the PC world who are our listeners will probably relate to sort of the general annoyance that - and I'm sure you will, Leo - that was first met by Microsoft's automatic patching idea.  You know, the idea, it was just sort of a bend over and let Microsoft do to your computer whatever it wants to.  And those of us who liked to - who actually used to know what every file was on our hard drive said, no, you're not reaching into my machine and doing things.  So I well remember when I was sort of making a partial compromise.  It's like, well, I'm going to review these.  And, I mean, even now I don't use Express, I use Custom, that Custom option, just because I just kind of want to look over the list before it does it to me and make sure that I want all those things.  And for, like, for a while I was resisting Silverlight.  It's like, no, I do not want Microsoft's attempt to do their own Flash thing.  But every time, here, you want Silverlight.  Take Silverlight.  You need this.  And the same is true for many of these things.



I've got a friend of mine, a contemporary.  In fact, you've met him, Leo.  Bob is an old-world computer guy.  And we just talked about this a couple weeks ago.  He said - he was grumbling about something about Microsoft's patching.  And I said, "Really, Bob, you haven't given up yet?"  And he said, "What do you mean?"  I said, "Oh, I just let Microsoft do what it wants.  I just - it's easier."  And frankly, and this is what really bears on Glenn's point, is I do think that this system is becoming more brittle.  I've had some machines that are just always think they need a certain patch, and I try to let them have it, and they won't take it, and it just - it's always saying it needs this patch.  And I finally got annoyed with it.  It was one of my little laptops.  And so I did some research and found that there's a tool that you can get to sort of remove things that are stuck somehow in Windows Update.  And...



LEO:  Oh, that's good.  What's the name of that tool?  I'd like to get that.



STEVE:  I'll track it down because I still have it on that machine.



LEO:  I get this call a lot from people who say Windows Update failed.  And it's always a different place.  I think this guy is assuming that there's something particular about these patches.  It's not.  It's a general problem.  You're exactly right.  It's brittle.



STEVE:  Well, yes.  And, I mean, frankly, it's a daunting problem.  I mean, when you think about - I'm amazed, frankly, that it works as well as it does.  When you have all the interacting, overlapping, code replacement, I mean, I don't know how Microsoft manages this, what is fundamentally a disaster in progress.  But pretty much they do.  So my point is, as I said, I've given up.  I just say, look, Microsoft is clearly developing patches, assuming that the machine that it's patching is already patched current, or to some level.  And frankly, I can't wait for Service Pack 3, as we've talked about for XP, because it will resolve all of this phenomenal torrent of individual fixing of things which you have to do when you install a new machine and give it Service Pack 2 in order to get up to pre-Service Pack 3 level.  So my feeling is, I still go into Custom mode just to sort of survey what they're going to do to me this month.  But I think I'm better off just saying, okay, fine, go, and hope for the best.  Because that is the code base against which Microsoft is developing this.  And as we've agreed, "brittle" is probably the best word for it.



LEO:  Well, you know, it's funny because I'm on the frontlines of this doing the radio show.  I mean, I take callers every week who have problems.  And it used to be you could get a tool, you could fix it, you could clean it up, you could - and this is not just patches.  It's spyware and viruses and all of this stuff.  Increasingly this system is so complex, so brittle, that the only option most users have is to start over.  And when Glenn writes about how these three patches are blocked, it's not those three patches.  It's not exactly - it's something about your system.  And the problem is that Microsoft has to work in this hugely homogenous environment, I mean heterogeneous environment, where every system's unique, hardware and software.  Every system's unique.  So they can't - the only way to make it not unique is to start over.  Format the drive, put your system recovery disks or Windows on there, patch patch patch patch patch, right up to the current patch, and then re-add your software.  And I'm afraid that people are doing that more and more.



STEVE:  Yeah, well, they're giving up.



LEO:  You've got to, though.  What is your option?



STEVE:  That's exactly right.  Otherwise you're Don Quixote, tilting at windmills and just saying no no no, I'm going to - I want to understand everything that is going to happen.  It's like, oh, good luck with that.



LEO:  Geeks have a tendency in that direction.  They're, you know, they are Don Quixotes.  I mean, we are, that's what we want to do.  But in this case I think if you're going to use Windows...



STEVE:  You've got to bend over, bend over.



LEO:  Yeah.  Don in Ventura has a quick Kindle question:  Steve, in all of your talk about the Kindle I don't recall you addressing its suitability for reference and technical material, whether it's manuals, maybe the latest O'Reilly book.  Does it work well for that kind of book?  Is searching effective?  Could it replace MSDN?  Oh, that's an interesting idea.



STEVE:  Yes.  The reason I - I saw the question, and I liked it; but it also bore on something I had done recently.  I'm, first of all, I'm loving my Kindle.  It is my constant companion to Starbucks in the morning when I read the stuff that I subscribe to.



LEO:  It's great for news, isn't it?  Yeah.



STEVE:  Oh, it's fantastic for news.  And in fact there was a little kermuffle, is that the word?



LEO:  Kerfuffle.



STEVE:  Kerfuffle on MSNBC, which I watch every afternoon when I'm on my Stairclimber, that involved, god, I can't remember his name now, David...



LEO:  Gergen.



STEVE:  No.  He's one of their frequent guys.  No, it's the guy that Chris Matthews has on that does the...



LEO:  Shuster.



STEVE:  Dave Shuster.  He came on and apologized...



LEO:  Oh, the Shuster incident, yeah.



STEVE:  Yes.  Yes.  And for making a comment about Chelsea Clinton and how the Clinton campaign was using her.  And based on his apology, I was guessing what he had probably said.



LEO:  Right.



STEVE:  But anyway, so the point is, the next morning I saw a little blurb about it, and I thought, oh, I felt like I had, like, missed that news event because it was then several days before.  So I put "Shuster" into the Kindle's little search deal, and bang, there was every reference to Shuster and little snippets, I mean, it's exactly what you want.



LEO:  But, now, you didn't do a web search.  You did that...



STEVE:  It was just all the content in Kindle is indexed.  And so it indexes everything that comes in.  And so that's why I love - basically what's happening is every day - I subscribe to Salon and Slate and Wall Street Journal...



LEO:  So that's the key is you subscribe to all that stuff.



STEVE:  Yes.  And so that's all coming in.  It's building this news database which is indexed.  So anything that comes along that I think of that I want to know about, I'm able to do a search.  It's like having my own little off-the-web news search system.  I mean, it's really fantastic.



LEO:  I have to say, though, in direct response to Don, many of the reference and technical works you want are not available for the Kindle.  It's just what Amazon sells.  Now, you can convert it, if you've got it in electronic form, if you've got a PDF.  Have you tried emailing documents to yourself and...



STEVE:  Yeah.  I tried it initially to see if it would work and could work.  And it sort of does.  The free Mobipocket v4.2 converter, which you can get from Mobipocket, it will convert TXT and DOCs and PDFs and other things into the native Kindle PRC format.  And so that's really the way to do it, I think.  And then you've got control over it to a great degree.



LEO:  I found some of them were unreadable.  Sometimes a PDF wouldn't convert properly.



STEVE:  Well, and PDFs...



LEO:  But I didn't use Mobi, so...



STEVE:  Yeah, PDFs are not inherently a text-flowing format.  They're a page layout format.



LEO:  That's exactly what happened.  For instance, I had a bunch of documents that I had to review for a meeting, one of which was a letter.  They were all PDFs.  But apparently for some reason in the PDF that letter was turned into an image.  So it couldn't scale the fonts.  It was always going to look small.



STEVE:  Very good point.  And some PDFs are scanned, they're made from a scanned text.  And there you're just stuck.



LEO:  Right.  So it's not - it's less than ideal for reference, I think.  You know, you might look at safari.oreilly.com.  The Safari online thing is fantastic.  All the - it's not just O'Reilly.  It's Addison-Wesley, Sams, Prentice Hall, Que - my publisher - Peachpit, New Riders, IBM Press, Macromedia, Adobe Press.  They put all of their books online.  You pay a fee for this.  Searchable, bookmarkable.  If it's textbooks that you want as a reference, and you can get to a browser - and of course the browser in the Kindle's probably not good enough for this.  Safari is amazing.  It's a really neat thing.  But the Kindle's not ready.  I know why Don would like that.  What if you're working on cars, and you could get all the manuals that you needed in the Kindle?  Man, that'd be great.



STEVE:  Yeah.



LEO:  Be really nice.  Derek Rainwater, he says he's in the middle of somewhere in Texas.  I don't care where you are, even if you're in the middle of somewhere, expect a visit from Hillary and Barack any day now.  Your recent website changes certainly make it more user-friendly.  Nicely done.  He likes GRC.com.  He said he's in the midst of reading Simon Singh's "The Code Book" - that is a great book - which is so relevant to much of what you've discussed during the past few weeks.  I'm getting much more detailed background information than you've got time to cover on the podcast.  Well, of course, it's a big book.  I know Leo made a brief mention of it long ago.  You might want to recommend it to your listeners.  By the way, I'm one of the many who enjoy hearing you and Leo talk about the books you're reading, as well as the Kindle.  Thanks.



STEVE:  I did want to mention, he's one of many people who said, hey, Steve, I love what you've just done to the site.  What I've just done is...



LEO:  What did you do?



STEVE:  I finally made time to put the script-free pure CSS menuing up.



LEO:  Yay.



STEVE:  Yup.  I'm going to do one more change to lock it to the top of the page so that the page scrolls underneath is so you don't have to go all the way back to the top to get the menu.  I'm in the middle of doing that at the moment.  But I really appreciated people discovering it on their own and saying, hey, you've got a menu on your site.



LEO:  Yeah.  You needed this because it was always hard to figure out where stuff was.  This is great.



STEVE:  And people are discovering things they didn't know was there.  It's like, hey, I didn't know you had that.  How would you know?



LEO:  Right.  Look, under the freeware alone you've got one, two, three, four, five, six - you've got security, you've got utilities, you've got obsolete.  I mean, this is great.  I didn't notice it either.  Just shows you how often - I was at GRC the other day looking at show notes, and...



STEVE:  And you notice there's a search bar there, too.  I wasn't sure whether I had read that particular SpinRite story before because it was familiar to me, but I thought, I don't remember.  So I just put in one of the phrases in the story about the drive.  I put it in quotes.  And it said - it found it in two places, neither of which were Elaine's transcription of that.  So it's like, okay, I know I haven't read that before.  So we also have site-wide search, too.



LEO:  It's really great.  You did a nice job.  Very well done.  Thank you.  As for "The Code Book," really a good book.  There is another one that's a classic called "The Codebreakers."  Both of them are available on Amazon.  I'm just going to check to see if Audible has the Simon Singh book.  That's more accessible, I have to say.  He's a good writer, and it's not as technical.  "The Codebreakers" is a history of encryption that was actually - it was fairly old.  No, unfortunately it's not on the - but it's, like, really thick and heavy.  And if you're really into crypto, "The Codebreakers" is an amazing book, amazing book.  I'll find out who wrote that.



Bryan Key, Huntsville, Alabama, wonders about the value of obscurity.  I think you were talking about this a second ago, security through obscurity.  I'm a long-time listener, love the show.  My question is this:  You're always talking about how hard it is to crack encryption.  You say to break RSA would take X number of attempts, cracking an algorithm with 128-bit key would take Y number of attempts, and with a 256-bit key it takes Z number of attempts.  But would not a practical crack theoretically take all of these added together?



What I mean is this:  If the NSA, the spooks at Fort Meade, grabbed an encrypted piece of data - by the way, we have many listeners who work at the NSA, and just a tip of the hat to them.  And I'm not against the NSA, and I just - these are the guys who have the best crypto-breaking, we assume, the best crypto-breaking technology.  If the NSA grabbed an encrypted piece of data on the Internet and wanted to break it, would they not have to try - ah, there's the key word - try RSA with 32-bit key, RSA with 64-bit key, RSA with 128-bit key, Blowfish, and on and on and on.  Doesn't the fact that they don't know what was used to encrypt it add an even higher level of difficulty, astronomically higher?



I've never heard you mention this.  I thought if it were true it would be a good point to make.  That being said, I would not think that if one encryption method became the standard, then - or I would think that, if one encryption method became the standard, then not using it would actually make you even more secure.  In fact, it would be less secure, wouldn't it, if everybody used the same encryption.  Is that true?  Can you just look at a file and say, oh, I know how this was encrypted?



STEVE:  No, and that's, I mean, it's a good point, and Bryan's right.  I've never touched on that.  I mean, pseudorandom data which is just noise is truly that.  I mean, it is noise.  It is pseudorandom data.  There is no way for - and given that anything was properly encrypted, and all these different things we've been talking about are good crypto strength, the result of data coming out of, as we've said many times, out of a cryptographically strong cipher, is pseudorandom data.  It is just - it looks like static.  It has no meaning.  There's nothing in there.  So he makes a very good point.  And but it highlights sort of an issue of obscurity and security.  From my standpoint, and the standpoint of any formal cryptographer or crypto person, we assume that an attacker knows everything about where this came from.  And this is standard sort of crypto dogma is we assume, for example, that Rijndael, AES, well, it's open and published.  And that's a strength to it because it's allowed it to be really well understood and really well vetted.



By comparison, for example, our friends at the NSA have historically tried to keep their ciphers secret, you know, the old Clipper Chip algorithm was secret.  And it was a problem that they had because some things cannot be kept secret.  I keep talking about, for example, the problem with cell phone encryption is everyone's got a cell phone.  And when we've talked about DRM, the fundamental problem, for example, with a DVD player is that the consumer has to be able to decrypt it in order to watch it.  So the decryption stuff is there.  Well, someone is going to pry the lid off that chip and figure out what's going on, if just for curiosity's sake or because they want to.  So any kind of security that relies upon, fundamentally relies upon the bad guys not knowing something, other than the key, is important.



And so the point is it's true that all security relies on a secret being kept.  But you want to understand what secret you are relying on being kept and which you are not.  And so, for example, if data were captured off the 'Net, the example that Bryan gives, well, so this is an SSL link.  Well, someone capturing the data knows it's going to port 443 from a client to a server.  So they pretty much know it's SSL.  And certainly if they watched the whole conversation they would see the SSL session getting set up.  Even doing a man-in-the-middle attack they wouldn't be able to determine the key that is being shared for the encryption; but they would know, for example, a lot about that conversation being set up.  The beauty, for example, of SSL is that it is safe even in the presence of somebody with perfect knowledge about the protocol, the ciphers, and everything that's happening, and even still no one can crack it within, as far as we know, within a reasonable amount of time.  And we know, we understand really well why it's strong, why it's strong security even in the face of that perfect knowledge.



So having pseudorandom data, it's very true.  If it was just someone handed you, for example, a blob of ciphered data on a CD, and you knew nothing about it, well, okay, that's Bryan's point is you'd have a much harder time doing something with it than if you knew what cipher it was ciphered in.  On the other hand, any cipher worth its salt is going to give you a hard time anyway.



LEO:  Harder than impossible is still - is not much harder.



STEVE:  Exactly, exactly.  After it takes much longer than nine times the length of the life of the universe, it's like, okay, well, does it matter if it's nine or 10 times the life of the universe?



LEO:  Well, yeah.  When you send a PGP-encrypted email, it clearly says begin PGP block and end it.  I mean, you know it's PGP encrypted.  Doesn't help.



STEVE:  Right.



LEO:  That's the point.  So, yes, it is harder, but you know you don't need it to be harder.



STEVE:  It's already hard enough.



LEO:  Already hard enough.  An anonymous sender from Calgary, Canada, says:  Thank you for the site updates.  Wanted to let you know how much I appreciate seeing the PPP v3 pages up.  That's the Personal Paper Passwords.  Perfect Paper Passwords.



STEVE:  And I forgot to mention that last week.  I finished all that.  For a long time, for several weeks, ever since we talked about it they have been, I'm going to get to that.  So I invite our listeners back to GRC.com/ppp.  It ended up being very cool.  There's a form there where you can put in your own alphabet.  You get to put in your own key.  You can specify how long you want the passcodes to be.  And in fact it's funny, when I posted this I said, hey, try putting in as the alphabet greater than, hyphen, and less than, as those just three symbols.  And somebody wrote back in our newsgroup and says, wow, Steve, this is the first-ever cryptographically strong ASCII art generator.



LEO:  That's neat.  So it looks kind of cool, huh?



STEVE:  Yeah, it really is, it really came out nicely.  So it's done, and we've got people are, either have upgraded or are upgrading their third-party open source implementations.  So that stuff is around.  Anyway, I'm sorry to interrupt you, Leo.  Go on with your question.



LEO:  Ah, yes.  Well, no, you're not interrupting me, you're responding to that part.  Now here's another part.  It's also nice to see the new scripting-free, pure CSS menu system in use.  I've been coming to this site for the last couple of years and wondered what other educational materials and resources there might be hiding in an obscure link somewhere.  The new organization will help a lot.



You know, I have to apologize because I use CSS menus on my site, and I do use a little bit of JavaScript.  And it's to determine if you're using Internet Explorer because if you use IE then the CSS, one little CSS thing doesn't work, and you have to modify it.  I'm amazed, impressed that you got around it without JavaScript, though.  That's pretty good.



STEVE:  Well, I had to use some CSS hacks.  There are some things where the CSS parsers in the different browsers are known to interpret things a little differently.  So I've got some, for example, I'll have a CSS callout where I've deliberately put a backslash in the word because one browser won't understand it, whereas another one will.  So, I mean, sadly we're still not at a point where CSS is a standard implementation across the board, although mostly Microsoft was guilty in the early versions of IE.  And the later versions of IE, the most recent one is way better.



LEO:  Well, get ready.



STEVE:  Okay.



LEO:  Because it's getting way worse.  There's an article by the CEO of Opera.  And Opera is a wonderful browser company which has for some time now really tried hard to enforce web standards in the face of Microsoft's absolute indifference about it.



STEVE:  Oh, yeah.  IE5 and 6 were just horrible.



LEO:  Well, he's talking about now IE8 and what Microsoft's talking about doing in there.  And once again he's saying, you know, essentially what's happened is because Microsoft's so dominant, has eliminated competition, that they just set the standards, they do their own thing, and everybody has to follow along.  And IE8 is no better.  And this is my problem with those hacks is it's different every time a new version comes out.  You have to update your code because it'll detect IE6, it'll detect IE7, now you've got to detect IE8.  It's a lot of work to maintain CSS.  It's just terrible.



He also says, he goes on:  I might as well also thank you for teaching me so much through your site and podcasts.  A couple of years ago I could have appreciated the concept of Perfect Paper Passwords but would have had no confidence in being able to implement a working system.  All of your hard work and continued sharing is appreciated and highly valued.  OH, that's nice.  That's really nice.  And true.



Mike Cerminara of Moorestown, New Jersey poses some drive encryption puzzlers.  Put on your thinking cap for this one, Steve:  Hey, Steve, I have a simple but important question.  I've known about CompuSec for a while now - we talked about it last week - was put off by its closed source nature - as we were talking about just a minute ago.  I've been waiting for the new version of TrueCrypt, but using it on my laptop is a nonstarter because it doesn't support hibernation.  That is a big problem.



STEVE:  And the good news is, it's coming.



LEO:  Oh, good. 



STEVE:  Yep, the TrueCrypt guys understand that that's a limitation that is going to put some people off, and they're going to address it.



LEO:  So since it was discussed on Security Now!, and you seem pretty pleased with it, I figured I'd finally give CompuSec a shot.  There's only one problem.  What happens if I need to mount that drive on another system?  There's a number of - this is because CompuSec uses the BIOS, right, that's tied to the system.  There's a number of reasons I might need to do this, migrating to a larger drive or if Windows gets hosed and I need the rest of my data.  Is it possible to mount my CompuSec-encrypted drive on another system?  Shall I go on, or do you want to address this?



STEVE:  Okay.  If you were to move the CompuSec-encrypted drive to a different system, to a different motherboard, it would be okay because it's the process of booting it.  In the case of CompuSec, as with TrueCrypt, all of the data needed to decrypt the drive is on the drive itself.  So moving it to a different system would work.  But there's no way to mount the CompuSec drive.  That is, it needs to be booted in order for its boot-time code to function.  The only thing you could do would be to boot it one last time and then, as you're booting, you can hit F2 to get some boot options, one of which is decrypt the drive now.  And so that boot-time code can run through the entire drive to decrypt it.  Then of course you could do anything with it that you wanted to, stick it as a slave drive of another system, because he was talking about, like, moving to a larger hard drive, where you'd have to have it and a larger drive.



LEO:  Well, for recovery purposes, too.



STEVE:  Correct.



LEO:  And by the way, SpinRite would work on that drive because SpinRite doesn't care about the data, it's just looking at what's underlying it; right?



STEVE:  Yes, and we got a question about that coming up.



LEO:  Oh, good, okay.  Now he wants to know if TrueCrypt has that same problem.  Can TrueCrypt mount an encrypted system partition just like mounting any other TrueCrypt volume?  If TrueCrypt could handle this more gracefully I'd probably be more likely to choose TrueCrypt.  Does it do the same - it's the same thing, though; right?



STEVE:  I don't know for sure.  So that'll be one of the things, that is a question I will answer for sure for next week's episode, show, on TrueCrypt.  I will have an answer to whether you're about to mount a system partition.  I sort of think not.  But I will know for sure.



LEO:  Incidentally, "The Codebreakers," the book I was thinking about is by David Kahn.  I found it on Amazon, K-a-h-n.  And he updated it in '96.  So it's a little more up-to-date than it used to be.  They also have Bruce Schneier's "Applied Cryptography," which is, if you really want...



STEVE:  That's my bible.



LEO:  Yeah, if you really...



STEVE:  I mean, that's code.



LEO:  That's the real stuff.  Yeah, I'm talking about the layman's stuff.  But if you really want the bible of it, that's the one, yeah.



Sky Moreno in Yorba Linda, California, that's in Orange County, wonders about Amazon's S3 service going down.  It's gone down, it went down last week.  I forgot to mention that.  My name is Sky Moreno.  I appreciate all you guys do, and to support you I've purchased a copy of SpinRite and send TWiT a $10 a month donation.  Thank you, Sky.  That money is much appreciated.  Those donations are what keeps the day-to-day operation going.  I should explain that, because we have ads.  And I think some people, in fact I got an email from somebody saying, you know, I see you taking expensive vacations, I guess I'm not going to send you any more money.  Well, I have to explain how this all works.



STEVE:  You're kidding me.



LEO:  No.  I do have real jobs which pay well, a radio job and a TV job.



STEVE:  You've got a family.



LEO:  And I support them with those real jobs.  And frankly, I support TWiT with those real jobs, too.  It's not like - now that we're getting advertising it's a little bit better.  But essentially I donate my time to TWiT.  Thank goodness I have a real job.  And your donations go to the infrastructure, the things I have to pay every month - rent, Dane, servers, equipment.  That's where the - those donations.  And the monthly donations are great because then I know I have a certain budget every month because I know it's going to be consistent.  When we get ad revenues then, as Steve knows, TWiT takes a small operating fee, and then we split the rest with the participants.  So essentially all the ad revenue but a small part goes to the people who are doing the shows, as it should be, and that's why the ads are important to me because they pay people like Steve, who otherwise do this for free.  TWiT for the first two years really was a volunteer operation by me and the hosts, and is only now starting to get on its feet in terms of - and I still don't draw a salary, but that's all right.



STEVE:  Well, and you know, we also have toys to buy, Leo.  I mean...



LEO:  We've got to pay for this stuff.  This is...



STEVE:  Yeah, I dislike, for example, trying to get a promo copy of IronKey.  I don't...



LEO:  You just buy it.



STEVE:  I just buy it because I don't want to feel like I owe these people a positive review for giving me something, and I don't want to have to worry about sending it back.  So we have a serious toy budget around here, too.  So we know what all this stuff is.



LEO:  And I do the same thing.  I don't take loaners in general.  I actually do have a loaner, a rare loaner right now, the MacBook Air, but that's mostly because I didn't want to buy it.



STEVE:  And you know I'm not that impressed by it.



LEO:  It's pretty.  It's light.



STEVE:  Yeah, but it's not, I mean, compared to the MacBooks it's like, okay, so it's thinner.  Okay, well, thin is good, I guess.  I thought, eh, I mean, I didn't have to have one.



LEO:  No.  Me neither.  Me neither.  And so I could have bought one, but I just thought, you know, I actually didn't, and they called me up and said wouldn't you like a month loaner, and I said okay.  But normally, like you, I don't want to be beholden.  I want to be able to say this thing's crap.  You know?  I want to be able to say that.  And when they are - it's hard...



STEVE:  Yeah.  And I ran my car over it, and now I feel much better.



LEO:  You might say, oh, you can always say that, they understand.  And of course they do.  They never say, oh, you just gave us a - well, most of them don't say that, you gave us a bad review.  But there's a human thing that, when somebody's very nice, and they say, oh, please try our product, it's hard to say bad things about it.  So I don't - that's why I don't even get to know these people.  I don't want to know them.  I don't want to like them.



STEVE:  Exactly.



LEO:  Anyway, he says, I hope you and Leo keep up the great work.  I own a small network integration company down here  near Steve in Orange County.  After listening to the netcast on Jungle Disk, which both Steve and I use for backup, I immediately signed up and started sending all my family photos out to Amazon, 5,500 of them.  I was surprised about them going offline, wanted your comments on them going dark.  Should I and Jungle Disk users like you and Steve worry about this?



STEVE:  Well, this caused a great deal of controversy because Amazon had their much-ballyhooed...



LEO:  99.99 percent up time.



STEVE:  Yeah, and their so-called SLA, their Service Level Agreement is what it's called, and that's a jargon in the industry for 99 - I don't know, what is it, like five nines, 99.99999999?  Anyway, they're not supposed to go down.  And it's like, oh, we're spread around the country, and we've got fault tolerance and resilience and self-healing mumbo-jumbo.  And unfortunately, starting about 5:00 a.m. Pacific time, I think it was Friday, they were gone from the - their West Coast facility was down for as much as four hours, and then kind of came limping back online, and things were slow.



And there were a number of people whose businesses depended on Amazon S3.  That is, there were photo-sharing websites that use S3 as their back end.  There were greeting card companies and all kinds of things that were like, they were out of business while Amazon was down.  And there were several people that said, well, this cost me $5,000.  And I could have bought a couple servers for $5,000 and be doing this myself.  And so my reaction is, well, this maybe was a good lesson for people about how not to rely on S3 if you're worried about this.  I mean, first of all, it was extremely expensive in terms of Amazon's reputation.  This hurt them a lot.  Which to me means they're going to make sure this doesn't happen a lot.  There was, of course, a Blackberry outage not long ago, too.



LEO:  A couple, yeah.



STEVE:  And I was going to say, and not the first one, that had all the Blackberry people freaked out for a few hours because they couldn't - they weren't - they couldn't jack in directly into their neural system and get their email the moment it came in.  And so my feeling is, I'm not worried.  And like you and I do, we use it for backup.  So it is trickling out of my machines as needed.  And Jungle Disk is very robust in the face of my link coming up and down, Amazon coming up and down, my laptop coming up and down.  Basically, when it's got a connection and everything is working and happy, it sends what it can up to Amazon.  And so I'm not relying on S3 for being able to get access to mission-critical data.  And I would say, well, this is perhaps something that people want to consider when you use an outsourcing service.  I mean, imagine what would happen if the Internet went down.  We know all why it really can't because it's just so phenomenally redundant and was designed for the packets to be able to find a way around.  And ISPs, well, there are ISP outages, and of course there are attacks which cause problems.  But in general it stays up pretty much and is robust.  But when you rely on a service like this, well, you need to think about what happens when it's down.



LEO:  Yeah.  And I, you know, I think they're still going to be pretty reliable.  They say it wasn't their servers, it was their authentication got overloaded.  Too many people were using it.



STEVE:  Yeah, got to beef that up, then.



LEO:  Beef that up.  Jeffrey, Columbia, Maryland, wonders about whole drive encryption backup and imaging:  Steve, I encrypted my entire hard drive with TrueCrypt.  I do have a question that comes to mind now - now? - now since I'm using full-disk encryption.  Do I have to decrypt my entire drive before I make a backup image of the partition that has my OS on it?  I've tried using Acronis True Image on it after I encrypted it.  Acronis knew where the partition was but didn't recognize the file format of the partition.  Obviously, this is because it's encrypted, and it's just random data.  It would let me make an image still if I wanted to, which I did not.  Is this one of the downfalls of full disk encryption?  How do you make an image of it?  Yeah.



STEVE:  Yeah.  Really, really interesting.  A couple things.  First of all, there's a complete difference between, and we'll discuss this further next week, but I just did want to address the question.  I mean, I felt a little up in the air as I was reading through these questions that people had sent because I still want to talk about TrueCrypt.  I didn't want to hold these off until the Q&A after TrueCrypt because I figured, okay, we'll put this right in between FREE CompuSec and TrueCrypt so it sort of answers some questions that we'll be dealing with in more detail next week.  The real issue is whether you're doing an imaging inside of Windows, or your OS in the case of TrueCrypt, or outside.  So, and there is some impact.  For example, if you're using an external imager - as I assume Acronis must be.  Certainly I know that PowerQuest's Drive Image is.



LEO:  It's the same.  Yeah, it's just - it's software.



STEVE:  And sort of like an external ghosting of the partition.  But it runs, for example, it boots itself, or boots...



LEO:  No, it runs within Windows.



STEVE:  Okay, well, now, this is different, then.  If you use an external imager...



LEO:  I see what you're saying, like Ghost, which you have to boot to.



STEVE:  Ghost, exactly, or Drive Image from PowerQuest that was one I was using for years, years ago, before Symantec sucked them up and killed them.  There it's going to see, first of all, several things.  It's going to give you no compression.  And the imaging that gives you compression is very handy because the imagers often recognize a file system.  They know not to bother saving empty sectors.  And lord help us on a - if you've got a 500GB drive, hopefully you're not using all of that.  So it's a real saving for the imager not to be able to - not to have to image data that's not in the file system, and to be able to compress it.  Well, if you're running an external imager, and the drive is compressed, the entire drive just looks like an opaque blob of pseudorandom data.  Maybe the external imager won't work at all.  PowerQuest is pretty finicky.  And I'll bet it would not have worked at all.  It wouldn't have even offered to do just a snapshot of whatever this blob...



LEO:  It could do a bit copy, though; right?  I mean, it could go bit by bit, sector copy.



STEVE:  Well, an imager could.  But I don't think that PowerQuest Drive Image does because it complains if anything is wrong with the partition.  So it's really caring about it.  He says that this thing would have been able to make an image, so perhaps that's the case.  Now, I've already experimented with my favorite in-Windows imager, which is Drive Snapshot.  And because it's running in Windows, it's asking the device driver for the drive image data, which decrypts it on the way to it.  So what's interesting is, and this is an important thing for people to recognize, is in the case of Drive Snapshot you still get the compression benefit and the unused space not being stored benefit.  But you end up with a decrypted backup.  So your backup is decrypted because it was done by Windows on behalf of the program running in Windows.  So again, you would then want to maybe manually encrypt it or maybe run Drive Image into an encrypted file container in TrueCrypt that we'll be talking about next week.  That would give you a still-encrypted image.  So there are ways around this.  But it's definitely the case that imaging changes relative to whole drive encryption.



LEO:  Yeah.  Yeah, very interesting.  I actually hadn't even thought of that, so that's good to know.  He says should I make - unencrypt, make images, and reencrypt?  That sounds like the way to do it, then.



STEVE:  Well, it really depends upon what your tool is.



LEO:  Of course you don't have an encrypted image, yeah.



STEVE:  Yeah, it really depends upon what your tool is.  If you, for example, say that you had to use the old PowerQuest 

Drive Image that booted DOS and then ran outside.  Then you would have no choice but to decrypt your entire drive, leave Windows, image the drive - whoa.  And then again remember, the image is again nonencrypted.  So you've made a nonencrypted image.  Then you'd have to reencrypt the whole drive to get back in.  So it's like that seems like the wrong thing.



I think the solution would be to use something like - maybe Acronis will do it.  The question would be, does True Image, you know, how does it work?  I'm not familiar with it.  It's not the one I use.  I use Drive Snapshot.  And I know, because I've experimented with it already, that it works beautifully on a TrueCrypted volume, or for that matter on a FREE CompuSec-crypted volume.  But it's - and you get the compression benefit, it makes a smaller image, all things which I like.  Then you encrypt it, for example, using a TrueCrypt file container, in order to - or just do a standalone encryption of that file so it's safe and it's small.  And I think it's much nicer to have much smaller images than to just take a, I mean, literally a sector-by-sector copy of the physical entire drive.  That's big.



LEO:  Jeffrey of Columbia, Maryland, wonders about whole drive encryption backup and imaging.  Oh, we already did that one.



STEVE:  You're right, we did.



LEO:  Number nine.  Here we go.  Isaac, a proud SpinRite owner, I'm glad to say, in New Orleans, wonders:  Hey, Steve, I was just listening to Episode 131, last episode, hearing you explain FREE CompuSec's driver handoff procedure.  And I wondered, what happens if Windows doesn't work, and you need to run the Recovery Console to repair it?  Oh, that's a good question.  Does CompuSec's boot driver support the Windows boot disk repair procedure and third-party SCSI/SATA driver installation?  That's when you press that F6 thing and put a disk in.  If not, does that mean that the console will find no installed versions of Windows, since it's all just random noise on the drive?



STEVE:  Yeah, this is a great question.  And I should say, here we are at the Q&A between the FREE CompuSec episode last week and the TrueCrypt episode next week.  And I've got to say I'm very, very impressed with TrueCrypt.  I'm going to go into detail about how they compare and why I'm so impressed with TrueCrypt.  But essentially I was doing the FREE CompuSec whole drive encryption research prior to the release of TrueCrypt 5, and I didn't know when that would be happening.  So in my opinion, although the FREE CompuSec system has many other features way beyond, you know, we talked about, I mean, it'll basically encrypt and decrypt every channel in and out of your machine, you know, standalone drives, your network connection, just sort of everything.  It really locks down a system from an encryption standpoint.  Whereas TrueCrypt only deals with what we know is storage encryption/decryption on-the-fly stuff.



My point is, if that's all you need, I really think TrueCrypt is a superior solution, and I'll be explaining exactly why it's superior next week.  So I did want to entertain this question about FREE CompuSec since we had talked about it, of course, last week.  But in my opinion - well, for example, I've removed FREE CompuSec from that system.  It is now running whole drive encryption under TrueCrypt.



LEO:  Oh, wow.



STEVE:  So absolutely.



LEO:  You got a lot of listeners who started using CompuSec after last week going, what?  Wait a minute.  Hold on there.



STEVE:  There are many reasons why TrueCrypt that came along afterwards is superior, and I've switched over to it.  But to answer Isaac's question, if you had a problem, and Windows would not boot, there is an option.  You hit F2 as FREE CompuSec is booting.  That gives you an emergency decryption menu that would then allow it to sit there, unencrypt the drive, put it back to its original condition, and then whatever it is that Windows wants to do, if you need to do, you know, a Recovery Console or anything wacky, it's then decrypted so you can proceed with whatever you want to do.



LEO:  Interesting.  That's a good solution.



STEVE:  Yeah.  It's nice, and it's good that they have it.  But I'm not using it anymore.



LEO:  Well, whoa, okay.  But we'll find out more about that next week when we talk about TrueCrypt and the TrueCrypt 5 which has this whole disk encryption technique.  But in general, Isaac's absolutely right.  Because it is random code, you're not going to be able to do the recovery thing unless you decrypt first.



STEVE:  Yeah.  It'd be interesting to experiment with the Recovery Console.  I didn't because, you know, there is this handoff going on which is how both TrueCrypt and FREE CompuSec work.  That is, you're booting, running decryption code, which is - it's probably intercepting Interrupt 13, as I mentioned last week.  Interrupt 13 is the BIOS routine which pretty much all software starts using in order to get itself going.  And then as the OS boots there's a handoff between Interrupt 13, which is the BIOS's original technology for reading sectors from the disk, and the system's own protected-mode drive, which then takes over.  So...



LEO:  But that driver does not run in Windows.  That's a kind of a BIOS-level driver, effectively.



STEVE:  Well, there's two drivers.  There's the external FREE CompuSec/TrueCrypt code which has to intercept the BIOS in order to decrypt the contents on the fly.



LEO:  And where does that code - does that code live in the boot record?  I mean, where does that code live?



STEVE:  Well, now, that's very interesting because there's a question, in fact we're about to, oh, no, wait, where is the question?  We didn't have the question.  Oh, no, it's one of our last...



LEO:  Coming up.



STEVE:  It's one of our last two, 11 or 12, which was a really interesting interaction that this guy had in his application, whereas FREE CompuSec would work.  FREE CompuSec, because I looked at the first track of the drive, wondering if FREE CompuSec's code was there.  And it's not.  What they do is, their boot sector, that first sector of the drive that contains the partition table at the end of the boot sector, it references some physical sectors out on the disk in the Windows partition which are locked and prevented from moving.  After FREE CompuSec was installed - because I was doing this benchmarking of it, remember, that I determined that it had about a 9 percent performance overhead - I noticed that there was a bunch of regions of the drive that were now locked, that were resistant to any defragging because their physical positions were known to the boot sector.  So the FREE CompuSec code itself lives out in the Windows partition.  What's different about TrueCrypt is that TrueCrypt puts itself down in that first track.  And that can cause some problems.



LEO:  Oh.  That makes sense.  So they do have to load before Windows loads, obviously, or they wouldn't be able to load Windows.  So if your recovery occurs after they're loaded, then you'd be able to do the recovery stuff.



STEVE:  Except that the system...



LEO:  Recovery is booting from a CD, though, so you wouldn't be able to do it because a CD doesn't know to load the thing.



STEVE:  Well, and there's also the Recovery Console, or like the various safe-mode boots where you might be - you might not be loading a special driver as part of safe-mode boot.



LEO:  So it is loading as a Windows driver.  It's not loading pre-Windows.



STEVE:  Well, it's both.  It's both.  And that's the cool thing about this.  And this, actually, it's why it's hard to do.  It's why there isn't a lot of this being done now is that it's both.  You need decryption outside of Windows until Windows gets going, and then you need a preinstalled Windows driver that can take over and continue decrypting as Windows boots and from then on.  So there's an outside and an inside portion to all of these solutions.



LEO:  Got it.  So really the answer to his question is, well, depends.  Or better, it probably doesn't.



STEVE:  Well, the answer to his question was that there is a solution, which is if Windows was having trouble...



LEO:  Oh, yeah, I see, you use the boot console, encrypt console, right.



STEVE:  You hit F2 to get in and, like, do the emergency decryption is what FREE CompuSec calls it.



LEO:  Got it.



STEVE:  And of course TrueCrypt has a whole bunch of options that we'll be talking about next week.



LEO:  So you better listen.  Matthew Simmons in Raleigh, North Carolina wonders about confusing SpinRite:  Steve, I don't own a copy of SpinRite, nor do I have a drive encrypted with either FREE CompuSec or TrueCrypt.  But both are things I keep thinking about how I should do.  My question is, what happens between SpinRite and - oh, yeah, this is the one you were talking about we're going to answer, yeah - between SpinRite and whole drive encryption?   Presumably SpinRite can still determine the bad blocks, but can it recover the data if the drive is just filled with what looks like random noise?  And how can SpinRite tell what is real data and what is broken data?  Doesn't care, I presume.  Similarly, how resistant are TrueCrypt and FREE CompuSec to hard drive failures or partial failures through bad blocks?



STEVE:  Yes, this is a really good question.  Not necessarily the SpinRite portion, but the question of how resilient are TrueCrypt and FREE CompuSec to hard drive failures or partial failures through bad blocks, as he says.  First of all, SpinRite is able to operate on just a blank drive, one you just get open, take it out of its hermetically sealed, electrostatically proof plastic bag and stick it on SpinRite.  SpinRite doesn't care what you've got.  It'll just show you that you've got a blank drive.  If you've got a partition table with partitions, SpinRite will show those to you, and you're able to choose which ones you want to run it on, if you don't want to run it on the whole drive, or you can choose them all.



So we were talking earlier about the one cool thing in SpinRite is its Dynastat data recovery, that is, the ability to recover portions of sectors, that is, to recover all but the unreadable part, essentially.  Now, one of the features of whole drive encryption is that they encrypt on a sector level, that is, sector by sector.  So each sector is encrypted individually. But they use a technology similar to what we've talked about before, similar to the Cipher Block Chaining, CBC, mode, which means that all of the data that you're encrypting is dependent upon all of the data that you have already encrypted or decrypted.  Which means that that does create a subtle weakness in this technology.  That is to say, if there were some data early in the sector which was unreadable, then there is no way to decrypt the rest of it.  Or that is to say, in SpinRite's case, SpinRite would still do a partial data recovery.  But because the entire sector had been encrypted, you'd still lose all of the sector from that point on, rather than being able to recover the rest of it from that point on.



LEO:  Well, and this is the problem with encryption in general, and full disk encryption especially, is that a failure can be more catastrophic.



STEVE:  But again, I want to - I don't want to scare people off because, remember, it's limited to one sector.  And the fact is only SpinRite, of any utility in the world, can recover parts of sectors.  So, and this is why the people who are doing whole disk encryption are saying, oh, no, there's no difference because normally an unreadable sector is unreadable.  And so you've lost the sector.  So the fact that you've created in sort of internal encryption that makes the sector more brittle normally doesn't result in any, you know, in any loss because you've lost the whole sector anyway.  Only with SpinRite is that not true because it can perform, and does perform, partial sector recovery.  So it's like, well, okay.  So there's a slight loss, if you were a SpinRite user, and you could have been - a partial sector recovery would have given you some benefit.  Okay.  So you can't get that on that one sector if you are using whole drive encryption.  It's like, or any of the, I mean, all the encryption is working in small blocks like that.  So it's like, okay, so there's some subtle weakness.  But I would say it's not significant.



LEO:  The thing that's good to know is that these encryption, full disk encryption technologies work sector by sector.  So a loss of a sector isn't - doesn't mean you lose the whole thing.



STEVE:  Is only a sector.



LEO:  It's localized.



STEVE:  Yes.



LEO:  Is there a part of - are there any special sectors that, if you lose those, you're going to have more catastrophic data loss?



STEVE:  Yes.  But that's always been the case with a file system, except file systems that are extremely resilient for loss, like maintain redundant indexes and things.  The classic is, in the old FAT days, if you lost the first sector of the root directory, you were hosed.



LEO:  Right.  There's no recovering.



STEVE:  I mean, it was just - you had no way to get to anything else.  And of course the FAT was important, the File Allocation Table, which is why there were two copies of the FAT because - oh, it's funny, though, because DOS wrote two copies but never used a second copy.  It was just...



LEO:  Oh, I think sometimes in a catastrophic loss some - I remember I think Norton would recover that, from the second FAT.



STEVE:  Yes.  And there were certain - and SpinRite was very aware of the second copy of FAT.



LEO:  Oh, okay, good.



STEVE:  And would automatically fall back to that.  But DOS itself never read the second copy of the FAT.



LEO:  It was for utility purposes, not for...



STEVE:  Even though it maintained it, yes.



LEO:  Interesting.



STEVE:  And so it is important to note.  We had a question pop up in the Security Now! newsgroup in our Usenet forums last week after the FREE CompuSec discussion.  One guy wrote that his boss wished he had their laptops encrypted, but he was really afraid to do that because he believed encrypting the drive made a loss of any area much more, like it would spread throughout the drive, or they could lose the whole file system.  That is absolutely not the case.  So encryption is constrained to individual sectors.  And it's done with that boundary.  So it's really no more brittle than a nonencrypted drive.



LEO:  Except for this weird case where you're using SpinRite, and you could have recovered some of it.



STEVE:  Yes.



LEO:  But that's - yeah.  And now, ladies and gentlemen, the Tremendous Observation of the Week.  Dane, could you put a little echo behind that?  Just, you know, give it that - what it needs there?  Little echo?  Here we go.  This is from Steve Nicholas in the U.K.  Hi, Steve.  Having heard your recommendation of FREE CompuSec - see, I'm telling you, a lot of people heard that, and they say, ooh.



STEVE:  Yeah, I know.



LEO:  We gotta try that out.  I had a look at their website but found several postings in their forums regarding the fact that it doesn't, does not, create a recovery CD.  This prompted me to try TrueCrypt 5.0a - he'd already used TrueCrypt - and I encrypted my entire system disk with no problems.  However, after several days of smooth running, I opened Macromedia Dreamweaver for the first time since encrypting the disk.  Dreamweaver told me it needed activating, and I had to let it connect to Macromedia again and activate itself, which it did successfully.  Everything was fine until I rebooted my PC and then found the TrueCrypt bootloader froze after I entered my password.  Ooh, that's scary.



STEVE:  Yes, it is scary.



LEO:  He repaired it.  He repaired it using the TrueCrypt recovery CD.  It booted okay again.  I then opened Dreamweaver, and it again wanted to activate itself.  And after doing so, couldn't boot again.  So it looks to me like Dreamweaver has some copy protection built in that modifies the MBR or something and stops TrueCrypt's bootloader from working.  I bet you're right.  That's bad behavior on Macromedia's part.



STEVE:  It sure is.



LEO:  Actually we should say Adobe, which owns it now.  Restoring the bootloader must then overwrite this copy protection, and Dreamweaver - it's a loop - wants to be activated again, then the bootloader gets overwritten.  I have now unencrypted my disk as I need Dreamweaver for my work.  And I'm unsure whether to try FREE CompuSec as, if applications can overwrite the MBR or corrupt a bootloader, and FREE CompuSec doesn't create a recovery CD - thank goodness TrueCrypt does - I'd have to reformat my drive, and I've lost everything.  Just letting you know this complication as I'm sure it can't only be Dreamweaver that can cause this problem.  I'm sure others.  In fact, the chances are good - this is Leo now - that Adobe didn't make this technology, but licenses it, as most piracy measures are, from another company.  Which means other companies are probably using it.  So it's probably not just Dreamweaver.



STEVE:  Well, what's going on here, and the experience that Steve Nicholas reports makes it very clear, we've got two different systems that are fighting over territory.  There is, as I know from reading the TrueCrypt docs so far, TrueCrypt's code puts itself down in that first track.  And remember that last week I was explaining that the very first track, the 63 sectors, the first 63 sectors of the drive, the first one is this partition sector and partition table, which is actually executed code.  And then the 62 sectors which follow it are normally empty because by - not necessarily by design, but by practice, partitions always start on even track boundaries.



So it starts, so the first partition - since the first track has been ruined, essentially, by that one sector being taken, that partition table sector being taken - the first partition is forced to be bumped to the end of that first track to the beginning of the second track.  That leaves the rest of the first track free, which is where TrueCrypt lives.  FREE CompuSec does not live there.  So it would probably be the case that Steve could use FREE CompuSec if he wanted to.



On the other hand, FREE CompuSec doesn't have nearly the robustness of recovery from disaster, which is one of the reasons I like TrueCrypt so much.  I'll be talking about it next week.  TrueCrypt gives you no choice but to make a recovery CD.  You can't encrypt your drive until you prove to them that you have one.  In fact, it was bugging me so much I found an ISO loader so I could fake it out and say, yes, dammit, I made a CD.  Here, sniff this CD, and you can see for yourself.  Because I was, you know, doing all kinds of testing, and I was burning up CDs.  I said, okay, enough of this.



So anyway, I'll give people a pointer to that if they want to be experimenting with this.  But what this essentially means is that, as you said, Leo, Dreamweaver - and we talked about this in fact relative to boot sector viruses.  Remember that there are some root systems now, some rootkits which are essentially working just like whole drive encryption, inasmuch as they get control before the operating system do.  Well, they're able to install themselves because Windows is not protecting the first track of the hard drive, which is the way Dreamweaver is able to reach down outside of the partition and make some changes down there, which is where they're storing their DRM, their activation scheme, whatever.  They're just probably tweaking a few bytes.  The problem is that now TrueCrypt is living in those bytes.  So it's very good that TrueCrypt is being as picky as it is about forcing people to make boot CDs because people might go, oh, I'd really like to do that.  And it's like, oh, you really do want to do that.



LEO:  And I have to say this is probably bad behavior on Dreamweaver's part.



STEVE:  I really don't like it on Dreamweaver's part.  I agree.  I don't think that they ought to be going down and  mucking around with the hard drive because there's going to be all kinds of unintended side effects.  And in fact, what they ought to do at the minimum is to see if there's all zeroes in the area that they want to occupy.  And if somebody appears to be living there, then they do something else.  I don't know what.  But I guess my point is there are many - there are obviously many other ways to achieve the same effect because everybody else manages to achieve the same effect without mucking around with the first track of the drive.  I hope that this hurts them, and they get their hand slapped for doing this and come up with some alternative because they really ought to.



LEO:  Well, there you go.  And as I said, I bet you others are doing it.  It's probably not just Dreamweaver.  I understand, because what they want to do is write something where you can't see it, it's not part of the file system, so that you can't, you know, end around it.  But now everybody knows it's in the master boot record.  So I don't know, this is a dubious fix anyway, a dubious protection anyway.



Peter Burtis in North Conway, New Hampshire wins the Cool Hack of the Week Award.  Dear Steve, I thought you and your Security Now! listeners might get a kick out of this.  I'm a technology consultant out of New Hampshire.  I should probably read it more like:  I was very interested when you mentioned TrueCrypt now did boot drive encryption because that's exactly the solution one of my clients is looking for.  But I run Macs, whereas my client runs Windows.  Not wanting to experiment on my client's systems I thought, well, what the heck, I'll try it in VMware just for fun, knowing it should work in theory - ah, interesting - but also more than half expecting to brick my virtual PC because of the intricacies involved.  Long story short, nope, didn't brick the PC, it worked flawlessly.  The bootloader comes up on "power on," which is in quotes because of course you're already powered up, it's just mounting the virtual machine.



STEVE:  Starting up the VM, right.



LEO:  Yeah.  Asks for the password, and from then on in you'd never know you weren't running on a stock copy of Vista/VMware.  I wonder what they do if they have to write the master boot record.  I guess there's still a master boot record on that drive image.



STEVE:  Oh, absolutely.  It looks just like a hard drive with a boot sector.  You can do multi-bootloaders, everything you want to.  I mean, it really is identical.



LEO:  These guys are so clever.  In fact, that's what he says:  It's a testament to the great programmers at VMware and TrueCrypt that both of their applications work exactly the way you would hope they work, even under very unusual conditions.  I don't really have an application for this beyond goofing around, but I imagine some security-minded person out there might, so I thought I'd share.  An interesting bonus, you can inspect the virtual machine's drive file using a hex editor on the host system, which I've done.  And from what my layman's eyes can see, compared to a similar nonencrypted Vista VM, it is really, truly encrypted, just as advertised.  Random bits.  Thanks for such a great podcast.  You and Leo are a big part of why I am so successful at what I do.  Well, thank you, Peter.  P.S.:  SpinRite saved my bacon two weeks ago.  I won't bore you with the same old story - mother's lap- we can do this now, shorthand.  Mother's laptop, never backed up, power failure, worst possible nanosecond, BSOD on boot, SpinRite saves it.  So thanks for that, too.  I love that.  We need to have, like, a little checkbox.  Grandma's laptop, mother's laptop, wife's laptop, your laptop.



STEVE:  Never backed up, desperately needed the data that was on there, blah blah blah.



LEO:  Yeah, it's always - isn't it always the case that the drive fails on the day you need that drive most.



STEVE:  Right, right.



LEO:  Well, that's a great letter.  Thank you, Peter, for your kind words.  And that's a clever solution.  And actually not surprising.



STEVE:  Yeah, I thought that was very cool.  If someone wanted to play around with TrueCrypt but either didn't have a PC or for whatever reason didn't want to actually do it to their machine, they could see what it's all about by running it in a virtual context, and it works just fine there.



LEO:  Ta-da.



STEVE:  Next week is TrueCrypt v5.0.



LEO:  Hey, just out of curiosity, FREE CompuSec would do the same thing with VMware; right?



STEVE:  Yeah, absolutely.



LEO:  It should work with both.  All right, next week - I'm really excited about this - TrueCrypt 5 is out.  And not only does it add a lot of features, including full disk encryption, it's Mac compatible and cross-platform compatible.  So you can on a Mac read a TrueCrypt disk encrypted on a Windows machine.  I understand that at least to be the case.  But we'll find out.  You'll talk about it.



STEVE:  Yup.  And we're going to also talk in more detail about the traveler mode, which is so nice for it being able to encrypt, for example, a USB thumb drive.  And the reason we're going to talk about that is that again will straddle into the episode two weeks from then, when we're going to have the founder of IronKey as our special guest on our IronKey podcast.  So we'll do of course a Q&A in between.  But then the week after that we'll have the IronKey guy.  So we will have talked about using TrueCrypt for something similar to what IronKey does in hardware because their big claim to fame is true hardware encryption in the key itself and all kinds of neat, weird effects, like they deliberately pot this thing in solid epoxy so that if by mistake you do run over it in your car or your truck, it will - it's uncrushable because it's filled with solid epoxy.  And of course that also makes it a little more tricky for the bad guys to get to it.  So that'll be in several weeks.  But we will talk about the traveler mode of TrueCrypt specifically  next week because it's something that lots of people care about.  And in fact my - the little 4GB thumb I keep on my keychain is now TrueCrypted because it really works nicely.



LEO:  Excellent.  Well, folks, if you want to know more, or you want to see Steve's super-duper new CSS menus, go to GRC.com.  It makes it a lot easier to find all the things you're looking for, including in the Security Now! section show notes, transcriptions, even 16KB versions of every show, all 132 episodes, so that you can download them quickly on dialup.  Of course if you've got broadband you'll want the full quality version, the 64K version.  Do you offer the 64K version, as well?



STEVE:  Yup, also, yes.



LEO:  Both of us.  And then do you, you know, I never asked you this.  You do link through Podtrac on those, I hope.



STEVE:  Yes, we redirect to you so that they're being counted there.



LEO:  Because we don't want to miss a single one of you, the reason we do that redirect.  For those of you security minded, I probably should mention this, too, because there's security-minded folks saying, wait a minute, what's this site I'm going through here?  We redirect through Podtrac, which is our ad agency.  And it's a very simple redirect.  They just count how many people are downloading the show because that's how we sell it to advertisers.  So what happens, it's a simple redirect, goes through Podtrac.  They have a very sophisticated system.  In fact, they have a data - I didn't know this, Steve, but they have a database of IP addresses so that they can compare to make sure that you are a legitimate IP address.  They're not keeping track of you, but they want to make sure that you are a unique IP address coming from a real place.



STEVE:  Oh, to actually improve the quality.



LEO:  They validate you, yeah.



STEVE:  And improve the quality of their counting.



LEO:  Well, advertisers want that.  In fact, I think it's an advantage that we and the thousands of other podcasters who use Podtrac have is that the numbers you get from Podtrac are dead accurate.



STEVE:  And very conservative.



LEO:  Yeah.  Well, and advertisers like that, too, of course.  But they can never say, oh, you're inflating your numbers.  We know each and every one of those people is downloading the show.  And once, they're counted once and only once.  Anyway, long story short, that's why it goes through there.  GRC.com.  You can get those.  You can also - he's now got that menu for all his great utilities.



STEVE:  And site-wide search is there, too.



LEO:  Site-wide search.  Don't forget, of course, ShieldsUP, which is the great firewall tester.  And he's got a lot of other cool stuff.  And last, but certainly not least, that's the home of SpinRite.  And you've heard us talk about that several times today.  More than several times.  It is the hard drive recovery and maintenance utility.  It's just really a useful tool.  And I use it, and I know a lot of people do, and I'm very happy.  GRC.com.  Steve, out of time.  Tomorrow, or next week I should say, TrueCrypt.



STEVE:  TrueCrypt 5.0.



LEO:  5.0.  And we'll see you then.



STEVE:  Talk to you then, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#133

DATE:		February 28, 2008

TITLE:		TrueCrypt v5.0

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-133.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In this second half of our exploration of whole-drive encryption, Leo and I discuss the detailed operation of the new version 5.0 release of TrueCrypt, which offers whole-drive encryption for Windows.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 133 for February 28, 2008:  TrueCrypt 5.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



Time for Security Now! with Steve Gibson, the show wherein which we talk about securing yourself on the Internet, securing your computer, protecting your privacy.  Sometimes we talk about protecting your hard drives because that's Steve Gibson's day job.  He's the author of SpinRite, the man who coined the term "spyware."  And his site, GRC.com, is really a haven for people who are looking for security online.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.  This is the much-anticipated episode about TrueCrypt v5.



LEO:  Now, this just came out, what, in January; right?  I mean, it's pretty...



STEVE:  Oh, actually in fact I think it was February 5th was the day that it came out.



LEO:  Oh, yeah.  And in fact I remember because we were talking about TrueCrypt, and I was bemoaning the lack of a Mac version.



STEVE:  Right.



LEO:  And then I noticed on the web page it said we've got one coming.  And, like, two days later I got about a hundred emails.  People said it's here, it's here.



STEVE:  Yeah.  I am very, very impressed with everything I've seen.  I mean, we loved it when we first talked about it on this podcast back in 2006.  And that was a v4 dot something or other, I believe.  And, I mean, they had done so many things exactly right.  And this whole issue of whole-drive encryption, first of all, it's captured the attention and imagination of our own audience.  People who have laptops are thinking, wow, this makes sense.  And it's dicier, though, that is, to encrypt your entire system drive because if something goes wrong you're hosed.  I mean, it's game over.



And so you're going to love what I have done to test this.  I've even created bad sectors and watched how it handles unreadable and uncorrectable damage on the drive.  And bottom line is they've nailed this whole aspect.  I will use this without hesitation anywhere it would be useful to encrypt the entire system drive.  And of course it also provides, as we know from the past, many other features, one of which we're going to talk about because it segues perfectly into the podcast we're going to have in two weeks where we have the founder of IronKey on to talk about his hardware-encrypted USB thumb drive solution.  And we'll be able to compare that with this aspect of TrueCrypt.



LEO:  Let's see.  Anything else you want to deal with from last episode before we get onto TrueCrypt?



STEVE:  Our listeners don't realize until we tell them that this has been - that we're recording this the day after we recorded last week's podcast, which was a day before it was released on Thursday the 21st.



LEO:  Very confusing, I know.



STEVE:  Because you're, again, up in Vancouver, and I'll be joining you next month up there.



LEO:  Oh, good.



STEVE:  But this month you're on your own.  And so we're recording two in a row.  Thus there's been no opportunity for a week to pass with any new security problems or anything.  But as always, we will catch up and have two weeks' worth of what's been going on in the security world when we record our next podcast.



LEO:  Well, let's just knock on wood.  Maybe nothing bad will happen all week long.



STEVE:  It's been quiet so far.  I did want to share - I always look for something that hasn't been said before in these SpinRite testimonials that I receive from people.  And I got a kick out of this one.  It's from a listener of ours.  Well, I guess many of them are, of course.  Jeff Locke in Portsmouth, Virginia said, "Steve, I am most" - well, the subject was "SpinRite Saved Me," of course.  Said, "Steve, I am most happy to be writing to you to thank you for the wonderful product, SpinRite.  I'm a regular listener to Security Now! and very much enjoy your products and the show with Leo.  A week ago I found my computer completely frozen and could not get it to respond unless I completely cut the power.  Upon reboot, Windows reported an error on my data drive, which holds all my family photos, a wealth of software I've collected, and all the build files for several websites I manage," he says.



LEO:  Oh, boy.



STEVE:  "So Windows said it fixed the drive problem after a CHKDSK.  But the system frozen again an hour later, and the problem persisted.  So I unplugged my data drive, and the computer ran fine for three days straight.  After guessing that the data drive had a problem and was giving Windows a problem, I went straight to GRC.  SpinRite spent four hours on the drive, found and recovered what appeared to be a bad sector, and I was back in action.  Thanks so much for your work on this product.  I would also like to tell you that the SpinRite buying experience was the easiest I've ever been through.  The shopping cart you wrote was great.  And of course I had no concern about its security.  Love the show and SpinRite.  Jeff L., Portsmouth, Virginia."



LEO:  He raises a couple interesting questions there.  One is that a data disk can affect Windows.  You'd think it's completely separate.



STEVE:  Yeah, yeah.  I have seen Windows get, well, the Windows drivers, the disk drivers are down in the kernel.  So they're down where the real plumbing is going on.  And there are places in Windows where there actually is no multitasking.  That is, there isn't the ability for the kernel to be, whenever it wants to, be switching around between tasks.  And so deep kernel problems can lock up the entire system.



LEO:  That explains why sometimes Windows will just get stalled.



STEVE:  Yes, exactly.  Exactly.



LEO:  So you're saying if there's bad data on the data disk, it can lock up Windows because it stalled trying to read?



STEVE:  Exactly, it stalled trying to read or gets itself into, I mean, there are some funky modes that the driver can get into where what it's expecting, the way it's expecting the drive to perform and get back to it doesn't happen.  And it just gets itself tangled up.  I mean, probably the sort of thing, if you could induce the problem reliably, Microsoft could fix it.  But they don't see it often enough, and so it's just sort of like one of those, ah, well, you know, sort of like the blue screen of death, which unfortunately too many of us see too much of the time.



LEO:  Yeah.  Very interesting.  The second thing that came up for me was he used CHKDSK, and it wasn't enough.  What happened?  I mean, we do all have CHKDSK.  Doesn't that do kind of the same thing as SpinRite?  Boy, is that a loaded question.  A little softball for you, Mr. Gibson.  Here you go.  I lob it.



STEVE:  I remember when, I guess it was before DOS 6, maybe it was DOS 5, I'm not sure now which version.  But I had dinner with two Microsoft VPs back in the days when I was writing the TechTalk column for InfoWorld.  And it was the version of DOS where they introduced ScanDisk for the first time.  And this was Brad Silverberg, whom I really liked...



LEO:  Oh, yeah, I remember him, yeah.



STEVE:  ...and Brad Chase, who I had less affection for, but that's another story.  But Silverberg was just a super guy.  And they were self-conscious about the fact that they were about to introduce a disk-scanning thing into DOS because I had had SpinRite for many years.  And I remember over dinner them saying, now, Steve, you know, this isn't going to affect sales of SpinRite at all.  You know, so ScanDisk doesn't do anything like what SpinRite does.  And of course for the entire balance of my life I was trying to explain to customers why SpinRite was different than ScanDisk.



LEO:  Because we assume, hey, it's a disk checker.



STEVE:  It scans a disk, so isn't that the same thing?



LEO:  Same thing; right?



STEVE:  Uh, no.



LEO:  You're doing a much lower level.  You're working a lot harder.  And CHKDSK really is just looking for some very simple errors in the file system.  It's not even looking at sector reads; right?



STEVE:  Well, one way to put it might be that ScanDisk or CHKDSK are sort of - they want the drive to have a problem so that they have something to do.  SpinRite doesn't - when SpinRite's done, it doesn't want the drive to have a problem.  That is, SpinRite is about repairing things.  ScanDisk and CHKDSK are sort of about finding file system problems.  And so it's the reason, for example, you run them before doing something else.  You want to make sure the file system is okay.  And, you know, they basically say, oh, look, we found some lost clusters.  Well, we moved them over into a file, here you go.  But they're not about - they're much more about the higher level file system than the low level.  And if they run across a low-level problem, they don't do anything to fix it.  They just say, ow.  We can't finish.  We can't complete.



In fact, it's funny, when they added their own partition compression to DOS, which was - I'll never forget that version.  That was DOS 6, which caused me to kill SpinRite 3 just as I was getting ready to release it because it didn't support that natively.  And it's like, oh, no.  I mean, so I couldn't be releasing a new version of SpinRite, which I don't do very often, and not have it support the drive compression built into - that was then going to be built into DOS.  So that's why...



LEO:  Oh, I remember that, yeah.  This was DriveSpace.



STEVE:  DriveSpace, exactly.



LEO:  Oh, what a nightmare that was.



STEVE:  And one of the things that DriveSpace would not do is compress your drive if there was a single problem on it. And back then many people did have problems on their drives.  And so we actually sold a lot of copies of SpinRite because it would fix the drives, which would then allow DriveSpace to perform its compression operation.  And actually the same was true with the FAT32 converter.  Remember when FAT32 support first came out, and then you were able to convert your non-FAT32, your 32-bit FAT, into a 32-bit one, which everyone wanted because it had lots of, you know, better features, upper and lowercase text support and other things.  And again, if there was any problem on your drive, that would fail.  And so we sold copies of SpinRite to people who, you know, wanted to be able to convert to FAT32 but they couldn't without having SpinRite fix the problem.



LEO:  Now, watch this amazing segue.  You know the same problem they have with DriveSpace, if you have a little error with DriveSpace, the whole thing's messed up.  Seems like the same kind of problem you'd have with whole-drive encryption.  In fact, I think they're very - in a way they're very similar.  You're taking the drive and turning it into one big file in DriveSpace.  Does TrueCrypt do the same thing with whole-drive encryption, make a big encrypted blob?



STEVE:  No, no.



LEO:  Because that was a real flaw, I think, in DriveSpace.



STEVE:  Well, TrueCrypt runs in a number of different modes.  The way it ran prior to v5, where they added this notion of preboot authentication and the ability to have your system partition encrypted, that's what's new in 5.  So the various modes it can run is you can give it a file, so, for example, you could just have a file on your hard drive, on any hard drive or, for example, on a USB thumb drive, and TrueCrypt is able to mount that as a drive letter and, in the process, perform on-the-fly encryption/decryption of any data coming and going from that drive, which is actually just a file somewhere.  So it can do that itself.  So those are the three modes it's always been able to run in.



And then what was added, which really has brought it to a lot of people's attention, is they added the ability to encrypt the actual system drive, which you couldn't do before.  And the reason that's tricky - and this is what we've been talking about really for the last two weeks, first in the context of the FREE CompuSec program, and then we talked about it a lot during last week's Q&A.  And the idea is that if your system volume, your system partition, your C: drive, if it's completely encrypted, then Windows, the Windows files, the Windows code, the registry, I mean, everything you need in order to do anything is encrypted.  So you need something on the outside which will decrypt the Windows operating system files itself until they get going.  And then you need something on the inside, that is in Windows, which will seamlessly hand off that encryption task, so that when Windows takes over control from the external booting process, it also is able to transparently handle encryption and decryption of itself, essentially.  So it requires these two components.  And I've been extremely impressed with the way this was implemented.



When you install TrueCrypt - and it's still a very small, easily downloadable EXE, and as we've said now for the last couple weeks it is all open source, the source is available, so everything they've done is there, and the documentation documents what they've done.  So you don't have to go in and read all the code.  I mean, they lay out the format of the headers, which is the preamble before, for example, an encrypted partition.  It's like, this is how this data is.  And so they're not relying on obscurity at any level for the security of the system.  And they've really gone security happy with this thing.



So to give you a sense for how committed to the safety of this process they are - and this goes way beyond what FREE CompuSec did, and it's one of the reasons that I've completely switched over to TrueCrypt for this solution.  When you want to compress your system drive, you run TrueCrypt in Windows in that drive.  And you select Encrypt System Drive.  And I'm paraphrasing here, but it's easy to see from the UI.  That brings up a menu or a list of you want to encrypt - oh, is this drive a single boot or a multiboot?  And in my case I'm just booting just the standard OS.  I don't have anything else there.  It does support multiple OSes.  It supports of course Linux and Mac, although not, as I understand it, not yet in this full-drive encryption.  But you are able to essentially still boot unencrypted operating systems if you have - if you're using Windows multiboot loader.  They only support Windows multiboot loader.  Or there is a way that you're able to use the Linux multiboot.   I can't...



LEO:  LILO or GRUB or...



STEVE:  GRUB.  You're able to - and they give GRUB as an example.  You can't have GRUB on the boot sector.  But apparently it's possible to move GRUB to a partition.



LEO:  Yeah.  Both GRUB and LILO, in fact I think any bootloader in Linux can live on the boot partition, not on the master boot record.



STEVE:  Ah, and that's exactly it.



LEO:  If you took over the master boot record, this whole thing would fall apart.



STEVE:  Well, and in fact - okay.  So let me go back to this procedure because we'll see how safe they have made this.  So you say, okay, yes, I want to encrypt my system partition.  So the first thing you do is, as we've seen in prior versions of TrueCrypt, they start generating random stuff.  And they show you a little window of hex randomness and tell you to move your mouse around, you know, and the more erratic and randomly you move it, the better your randomness is going to be.  It's like, oh, okay.  I mean, this is, like, so overkill.  But it's typical of these guys.  I mean, they don't tell you that they're also taking all kinds of random stuff from your system, from the clock, from various serial numbers, from globally unique IDs, I mean, they're starting with something where, I mean, you could unplug your mouse and this thing would still be massively random.



LEO:  And this is designed because the pseudorandom number generators of computers, if you know where they begin generating numbers, you can predict what the next number will be.  So this way they use these seeds, these completely chaotic seeds, to seed it; right?



STEVE:  Well, yeah, except that, for example, in the case of a static pseudorandom number, that wouldn't matter.  What you're talking about was important, for example, for the keys being used dynamically for generating SSL connections.



LEO:  Right, right.



STEVE:  Where you could make some guesses about what the next key would be of the next SSL connection because Windows doesn't have a very good pool of entropy that it works from.



LEO:  So why do they go to all this trouble, then, I would ask.



STEVE:  Oh, it's just feel-good.  I just wanted...



LEO:  Extra, this is extra.



STEVE:  Yeah.  I wanted to bring this up because I don't want our users to sit here messing with their mouse for an hour, just sitting there scrubbing it and scrambling it and bouncing it on their desk and spinning it around by its tail, thinking that that's going to give them a better key.  I mean, literally, it's already really good.  It's not possible.  And that's one of the things I like about these guys is they've really, really concerned themselves about the security.  It's not possible to have TrueCrypt give you a bad key.  Before it even touches you it's already got a fantastically random key.  So, but okay, fine, I like that they've done this.  But I just want our users to know they don't have to sit here and worry about how long they need to scrub their mouse before...



LEO:  I've seen other things do that.  I thing PGP, some other programs do that when they're...



STEVE:  Yeah, it's...



LEO:  It's a feel-good measure.



STEVE:  Okay.  So now you generate all this pool of randomness, and from that it generates your master keys.  Then, unlike again FREE CompuSec, that has none of this, it builds for you an ISO file which you have to burn to a CD.  This is your recovery disk.  And at first I thought, yeah, yeah, yeah, yeah, this is just a scrap machine, I've been using it for the last couple months, and recently with FREE CompuSec, I've got images, I can reimage it, I don't care about it.  So I tried to say Next.  And it said, wait a minute, you didn't do it.  And it's like, whoa.  What?  It's like you have to make an ISO, you have to burn a CD or DVD and prove it to us.  And it's like, oh, come on.  So I have all these coasters lying around here now because for a while I was doing that.  Then I found something that would allow me to fake it out.  But these guys are really serious about protecting you from yourself.



LEO:  And you're saying that you did this because it was a test machine, you didn't care if you hosed it.  But you should make this disk if you're going to do this.



STEVE:  You don't have a choice.  You have to...



LEO:  They're right to require it.



STEVE:  Yes.  You have to really work to fake it out.  So...



LEO:  And don't.  Don't fake it out is what I'm saying.



STEVE:  So don't work to fake it out. 



LEO:  Yeah.



STEVE:  So you burn a little - and I have mini CDs, so they're small coasters that don't take - and it's a very small ISO, takes no time to do it.  Then you have to put it back in the drive if your CD-burning software spit the disk out as mine does, put it back in the drive, then hit Next and let TrueCrypt sniff the disk.  Oh, and the other thing it's doing is it is reverifying the image it made and that it's able to properly read.  So again, it's verifying that you got a good burn of your CD.  So it's useful for that, too.  So now it's made you make an emergency recovery CD.  And we'll talk about what that contains in a second.



Then it's like, okay, you've made your CD.  Now, hold on a second.  Now we've just put our bootloader on your hard drive.  Now we're going to - we're not doing any encryption yet.  We're going to make sure that it works.  So we're going to shut down and reboot.  See you in a minute.  And so it pops up a dialogue, you say yes, fine, shut down now.  So now you reboot, and you're taken to TrueCrypt's boot screen, where you have no choice but to enter your password.  Now, again, in trying to really push the limits here I said Escape.  Well, Escape bypasses its bootloader.  And since I had not encrypted Windows, Windows came up.  And TrueCrypt says no, good try.  You cheated.  Go back and try again.



LEO:  It really nannies you on this.



STEVE:  Oh, it does.



LEO:  This is funny.



STEVE:  We are not going to get faked out here.  We are not going to encrypt your system unless you prove to us you can enter the password.  And again, that's good.  So it's like, okay, fine, reboot.  So now I'm at TrueCrypt's screen again, and I type in my passphrase.  Oh, and mine is, it's like...



LEO:  You're going to tell us your passphrase?



STEVE:  No no no.  I was just trying to count the characters.  It's 18 characters long.  I was using my fingers to count right there.  Okay, that's not long enough for it.  So when I give this gnarly 18, I mean, it looks like the keyboard broke, right, and no one could ever duplicate this - no.  Passwords less than 20 characters long are not considered safe.  If you make us go forward, we will.  But we're going to grumble.  It's like, yes, I want to use my 18-character impossible-to-repeat passphrase.  And so but again it's like saying, you know, that may not be long enough.  Okay, it's long enough for me.  Besides, this whole thing is going to last about an hour before I scrub it off and do something else with it.  So I give it my passphrase.  Then it goes back into Windows and says, okay, so what we've proven now is, we've proven we've got a recovery CD.  We've proven that the bootloader we put on the first track of the hard drive successfully worked.  That is, you know, it was recorded, it worked, and you properly typed in the passphrase which, baby, you are really going to need from now on.  So it's like...



LEO:  Don't forget it.



STEVE:  ...now we will encrypt your hard drive.  Okay, finally.  So this thing does a beautiful job.  It brings up a dialogue.  It shows you what percentage with three decimal digits of accuracy.  It estimates how much time is remaining or how much it's spent, I don't remember.  But it shows you time passing in one way or the other.  And you're in Windows.  So you can use Windows.  Now, it is sluggish.  I  mean, it's got the hard drive saturated.  The drive light is on solid.  And while Windows is still functioning, I wouldn't go and try to do any 3D rendering or play a game or do anything that requires much of the system.  You could probably answer your email, but that's about it because, I mean, it is seriously working the system and just saturating the drive.  It runs on a slower, older machine with a 40GB Maxtor ATA.  It ran about two minutes per gig.  So that 40GB drive took 80 minutes to compress.



LEO:  Whoa, that's a long time.



STEVE:  On a newer machine with an SATA, a SATA drive, it was 1GB per minute.  And Leo, here we're going oh, how many gigs do you have?  This is billions of bytes.



LEO:  Oh, yeah, I understand, yeah.



STEVE:  So people are very cavalier about the size of their drives.  And of course they grumble about SpinRite.  Oh, it took, you know, two days.  It's like, yes, because we're moving an incredible amount of data.  So it's literally, it is reading, in the case of TrueCrypt, it is reading every sector.  It is in some block.  It is encrypting them all, then it's writing them back.  And it's making a note of where it is because remember, in order to do this on the fly while Windows is working, that encryption...



LEO:  Oh, that's amazing.  That's a good point.  Windows, you're still using Windows.



STEVE:  Yes.  And so imagine, here's your drive in front of you, this veil of encryption is being pushed from the front of the drive through the entire partition, encrypting files on the fly.  So at some point a chunk of the beginning of the drive is encrypted, the rest of it is not because we're moving along, taking...



LEO:  So you have to watch Windows, and when it asks for a sector, you have to unencrypt it and give it to us.



STEVE:  If it's a sector that you've already encrypted.



LEO:  If you've already done it.



STEVE:  And not if it's one you haven't gotten to.



LEO:  Now, does it do - is it file-aware when it's doing this whole-disk encryption?  Or is it really just going sector by sector?



STEVE:  No, no, it is sector by sector.  And again, you want that because...



LEO:  So it would have to, yeah, because it would just get slack space and so forth.



STEVE:  Exactly.  Deleted files and your...



LEO:  Swap file and all that stuff.  But if you didn't encrypt that it'd be a problem.  But I guess you could encrypt those things.  But if you're going to grow the file or whatever, you really want the whole thing encrypted.  But I could see now why it's taking a long time because it's even doing empty space.



STEVE:  Well, yes.  But conceptually, Leo, it's important that we understand conceptually, this is entirely different, I mean, this is entirely different from anything TrueCrypt has done before.  In the past there was this notion of turning a file into a drive and, you know, having a container file that contains a drive.  You know, this is every physical sector of the drive.  And of course the reason people would do this is they want maximum security from any, I mean, any possibility that any of their data on their drive can get loose.  So for laptop users this makes so much sense because unless you enter your passphrase, which is mixed with the master key, which essentially creates the master key to do this decryption, that entire drive looks like random noise.  It looks like static.  And one of the cool things is you never have to worry about wiping the drive to decommission it.  This is a wipe-in-progress, essentially as it moves through this.



So eventually this process finishes, and then you get your computer back.  It's no longer super busy any longer.  And it works exactly as it did before.  Now, if you then reboot, for example, and you come up to TrueCrypt's loader, you hit Escape, nothing happens.  You've said bypass the decrypting bootloader phase, and nothing happens.  I know, for example, that it's actually trying to boot Windows because at one point when I was messing around with how imaging, drive imaging affects this, I just restored a saved image of the whole system without changing that bootloader.  So it was still there.  And so it comes up and says, you know, what's your password?  Well, okay.  That's not going to work because I've just restored an unencrypted version of the Windows file system, the Windows drive, right on top of what was previously encrypted.  So I thought, huh.  Now what?  Well, I hit Escape, and Windows booted because it was no longer encrypted because I had restored an unencrypted drive sort of in place, right over what I had before.  So this thing, it holds your hand, it verifies what it's doing, it is incredibly safe.



So I decided, okay, I'm going to really stress this thing.  So I went into the NTFS file system.  Oh, and I restored - I think maybe I decrypted it first, or I had restored the image.  I think maybe I did that because it was a lot faster.  And I found early on the drive, about 18MB into the drive, I found a free cluster.  And it happened to be sector number 37299.  Sector 37299 was not in use by the file system.  So using some tools that I have that are proprietary tools of mine that I use for developing SpinRite, I damaged that sector.  I have the ability to create bad sectors.



LEO:  Not physical damage, but soft damage.



STEVE:  No.  Physical - well, I'm not bouncing the head.  But I can deliberately create a bad sector that ECC cannot recover, that the drive will refuse to read and refuse to relocate.  So nothing will fix it.  It is just sitting there and absolutely uncorrectable and unreadable, unwriteable, I mean, it's just dead.



LEO:  You'd better not let that tool get in the hands of...



STEVE:  No.  As I said, this is...



LEO:  That's a good tool.  I like that.



STEVE:  This is stuff I have that I use for SpinRite development and testing.  So I created an absolutely bad sector because I wanted to find out what would happen if I was encrypting this drive, and it hit a sector it could not read.  I mean, early in the process.  I didn't want to wait an hour for it to get to a sector toward the end.  So I fired up TrueCrypt.  I said, oh, I went through all the hoops again and, you know, burned the CD because I thought, well, maybe I'm going to really need this, depending upon how badly this hoses things, and started up the process.  Almost immediately it stopped.  And it said, you have a CRC - cyclic redundancy check - error on your drive.  You have a problem with your hardware.  This is not a TrueCrypt problem.  And it's funny because it said, don't call us.



LEO:  It's not our problem.



STEVE:  Don't send us anything.  Don't complain in the forums.  This is, you know, go call your computer vendor.  There's something wrong with your drive, your cabling, or your motherboard.  And we can't do anything.  Okay, but I'm thinking, well, yeah, but you just did 18MB of something which, you know is - because I'm defragging and putting all the Windows files at the front of the drive so that they boot faster.  So it's like, you know, Windows is in that first 18MB.  So now what?  So I'm thinking, well, but everything was still working.  So it's like, okay, let's reboot.  So I rebooted, and it asked me for my passphrase.  I put in my passphrase.  Windows came back up.  It's like...



LEO:  Because TrueCrypt hadn't done anything.



STEVE:  No, it had encrypted the first 18MB of the drive.  Well, I wasn't sure at that point, okay, because I got there pretty quickly.



LEO:  Right.



STEVE:  So then I went in - oh, and I got a dialogue box when I came back in.  And it said there was an encryption process interrupted.  Would you like to continue?  And it's like, oh, well, thank you very much, I would.  So I said yes.  And immediately, bang, you have a problem, you know, same message again.  So it knew where it failed, and it tried again, right on that sector.  And so I was unable to proceed.



LEO:  So if you have a bad sector like that, it will not do the drive encryption.



STEVE:  Well, yes, exactly.  It stops, and it will not proceed.  Now...



LEO:  Is that how it should do?  Shouldn't it just map that sector out or...



STEVE:  Well, no.  I don't mean to tell you that you need to buy SpinRite, but SpinRite would fix that for you.  But it would be nice, I guess, if it could say, do you want to proceed past this problem.  But these guys are being beyond careful.



LEO:  Yeah, well, that makes sense.  They don't want you to continue to do it if there'd be any problem down the road.  They just say, look, we're not going there.



STEVE:  Exactly.  I mean, I know exactly what the problem was because I manually created it on the drive.  But somebody else - okay.  So two different - there's two different courses of action now.  You cannot proceed.  So I thought, okay, let me choose the Permanently Decrypt Volume option in the menu.  So I did that, and it went zip.  I mean, it took, like, no time.  And it said, okay.  And it's like, oh, okay.  So then I rebooted Windows, and it asked me for my passphrase.  But I knew that it wasn't - the volume wasn't encrypted.  So I hit Escape, bypassing the decryption boot.  And Windows booted.  So everything was back to normal.  It had decrypted that first 18MB that I had assumed had been encrypted because, I mean, it did, it went zip and did something.



So then, okay, let's try this whole thing again.  So this time I did the same thing, got up to that 18MB point, sector 37299, bang, stops.  Okay.  This time I rebooted, and I hit Escape - no.  I hit something, I think it's maybe F2 for options.  There are some options when you're booting.  One of them was Decrypt This Partition.  So it's like, oh, okay, so it knows it's encrypted, or at least partially.  So it made me put in my passphrase again, of course, because you can't let anyone come along and just decrypt your partition, or what would be the whole point?  Then I was so pleased, I saw it go 18, 17, 16, 15, 14, 13, it counted down rapidly from 18MB, knowing how - now, this is outside of Windows.  So this is the bootloader portion was able all by itself to decrypt that only as much of Windows as had been encrypted before I hit this error.  I'm just - I'm completely impressed with the way this thing works.



LEO:  Wow.  So it sounds like they did everything right.



STEVE:  Okay, well, I got a killer one for you.  Now, remember that I was benchmarking FREE CompuSec?   And I thought, okay, we've got to find out what kind of overhead we have here.



LEO:  So just to recap, you get what, about, I think you said a 5 to 10 percent hit with FREE CompuSec?



STEVE:  It was 9 percent overhead.  Okay.  Well, I haven't computed the overhead here.



LEO:  Why not?



STEVE:  Because it's faster with encryption.



LEO:  Now, that's not right.



STEVE:  I am not kidding you.



LEO:  You have a divide-by-zero error here.



STEVE:  I don't know.  It's like, okay.  So I wrote a little batch file using that EndTimer tool and the Windows defrag and Vopt and Windows defrag.  I ran those three in sequence.  With no encryption, Windows defrag took 8 minutes and 35.765 seconds.  Vopt took 4 minutes and 31.046 seconds.  And then a final Windows defrag took 1 minute, 54.765 seconds.  Okay, so just look at the first number, 8 minutes and 35 seconds.  I did it; I did it again.  That is, I restored the image, ran the script again, and it was 9 minutes and 1 second.  So, you know, about 8 minutes and 45 seconds on average.  And the difference are just we're doing a lot of head-seeking.  And so where the disk's rotation happens to be is going to affect timing a little bit.



LEO:  Oh, yeah.  Okay, that makes sense, yeah.



STEVE:  Okay.  So it's like, okay.  So I'm seeing, like, 8.5 to 9 minutes to do the first defrag of a very well-fragged image.  And this is the image where I went from Service Pack 2 and applied those 95 patches and rebooted a whole bunch of times.  So, I mean, it mangled up the drive, so it was nicely fragged.  Okay, then I restored that image, the superfragged image.  And I encrypted it.  Then I ran the defragger in the encrypted system.  The first time it took 6 minutes and 13.531 seconds, down from 8.5 or 9.



LEO:  Down a lot.



STEVE:  Yes.



LEO:  I mean, that's a significant difference.



STEVE:  I know.  It makes Windows much faster.



LEO:  This can't be true.



STEVE:  I'm not - okay.  The second - and I thought, what, you know, I can't have a smaller number with encryption.  So I did the whole thing again - restored the image, reencrypted it, 6 minutes and 21.765 seconds.  So twice it was 8.35 and then 9.01 unencrypted.  Then with encryption it was 6 minutes, 31 seconds - I'm sorry, 6 minutes and 13 seconds, 6 minutes and 21 seconds.  Okay.  So then I'm thinking, what is going on?  So I went back to no encryption, final sanity check, back to the original, back up to 8 minutes and 21 seconds.



LEO:  So do you have a theory for why this is doing that?



STEVE:  Well, they say on their web page that they've got 100 percent pipelining of some sort.  Apparently once upon a time it was too slow, and boy did they fix it.



LEO:  So it sounds like they've kind of written new drive read routines.  They'd have to, I guess.



STEVE:  Well, they ought to send them to Microsoft because it runs...



LEO:  No kidding.  This is a typical open source [sound] take that, Microsoft.  That's so funny.



STEVE:  It runs faster under TrueCrypt than it does without.



LEO:  That's just amazing.  And great.  I love it.



STEVE:  So there's, like, so there's - overhead is not a problem.  That won't be causing anyone any headaches.



LEO:  Wow.  Now, this is something that they used to say about DriveSpace, too, was when you compressed it you would get a faster read because you could read the data in faster, which would...



STEVE:  That's not the case here though because this is changing - it's not changing the size at all, exactly, it's just doing an in-place symmetric cipher.  In fact, it uses AES - oh, that's another thing where overkill, you know, you're able to chain together multiple ciphers.  So you could do AES followed by Blowfish or Twofish or, you know, it's like, come on, folks, no one needs any more.



LEO:  There's severe paranoia going on here.  But, you know, the people who use TrueCrypt are very paranoid; right?



STEVE:  And again, I don't want to promote that in this case because AES 256-bit key is absolutely fine.  It's all anyone needs.  So maybe before we had that, when your option was like triple DES, they also had some 64-bit ciphers, that is, a cipher with a 64-bit block size.  And again, what I love about these guys is they're like, okay, that's no longer safe.  We will still support that on volumes that have been encrypted by older versions of TrueCrypt, and the person shows a 64-bit cipher.  But we will refuse - even though we have those ciphers inside of us, because we have to in order to be backward compatible - we're not going to build any volumes under any circumstances with a cipher that isn't at least 128 bits wide, has 128-bit block length.  So it's...



LEO:  Actually, that's great.



STEVE:  It is.  It really is.  So the other thing, to wrap up this issue of full drive encryption because then I want to cover the traveler mode briefly, the other thing I really like about this is for a person like me that is a tweaker and really wants a minimal environment, I wanted to see whether I needed TrueCrypt EXE and all of its, well, not that there's a lot of files.  But, like, do I need it running at startup?  Do I need it sitting there in my tray all the time?  Say that all I want is whole-drive encryption.  All I want - and this is like, you know, for an office computer, where the only thing you want is, when you boot it up, they have to type in their passphrase.  That way if someone steals the drive in the middle of the night they get nothing.  You know, that was what originally brought me in to looking at FREE CompuSec.



And the answer is you need nothing.  There's a TrueCrypt.sys drive which you of course have to have.  That's the key for being able to perform on-the-fly decryption.  But you can completely remove the rest of TrueCrypt, take it out of startup, not have it running.  You need none of that in order for your drive to be encrypted.  You can't - oh, and of course thanks to the bootloader having the ability to decrypt you, you could even take yourself back out without ever needing TrueCrypt again.  So a minimal configuration would use TrueCrypt to perform the encryption, and then you can take it out, not have it start up, not have it always there in the tray because you only need that for, like, mounting and unmounting other volumes and doing other things with TrueCrypt than doing whole-drive encryption.  I mean, it is just beautiful.



LEO:  That's neat.



STEVE:  I really, really, really like it.  Now, I should talk a little bit about the recovery CD.  The only thing you can do when you boot the hard drive is you're able to bypass it completely, or you're able to enter your passphrase.  If you enter your passphrase, you can go into Windows, that is, boot the encrypted partition, or you are able to say I want to remove encryption from this drive right now, sort of like a emergency decryption.  You can also, as I did, do it in Windows, where you're able to kind of use Windows at the same time, although the system is really busy.  But again, you're able to, from the bootloader, bring your system back to nonencrypted status.  Okay.  You can do more things with the recovery CD, which is one of the reasons they make you create this and don't give you any choice about it at all.  And let me find my notes here because there was a whole bunch of things.



LEO:  Have you found more things in your list?



STEVE:  Yes, and I'm glad I had a chance to browse through my notes here a little bit because there are a couple of really important things.



LEO:  It's a lot of stuff.



STEVE:  Well, there's a couple of really important things we haven't covered, either.  So remember one of our questioners in last week's Q&A told us about the collision he discovered between Dreamweaver, Macromedia's Dreamweaver's DRM or activation or whatever you want to call it, and the bootloader.  Well, were it not for that CD, he would have lost his entire system because, when he activated Dreamweaver, it overwrote something in the first track of the drive, which I guess we said last week is a bad thing for some software, some random application software to ever do, you know, step outside of the partition.  It's just a bad idea.  But it did.



Fortunately he had his rescue CD.  So if the bootloader becomes damaged in any way, the rescue CD is able to restore the original bootloader code to repair that first track.  If the passphrase, if you were typing in your passphrase correctly, but the system said it's wrong, that would be caused by something having messed up the master key and some other critical management data for the decryption.  So again, the CD is able to restore that if anything mangles it.  Or if the bootloader area were to become infected by malware, such as, for example, the track zero rootkits we've been talking about.  The point is, it would be running at boot time.  And you certainly wouldn't want to have a rootkit.  You'd be forced to boot from the hard drive in order to get decryption, yet in the process you'd be allowing the rootkit to run.



So the CD can itself provide the booting code, staying completely off of track zero.  And the CD will hook interrupt 13, load itself, get Windows going.  So you're able to still boot Windows with full use, not touching track zero at all.  And finally, if Windows is, for example, itself damaged and refuses to start, then you could either use, as we said, the boot code in track zero, or also the CD has a copy of that, and it's able to independently permanently encrypt the drive.  And finally, if when you first install TrueCrypt, whatever you originally had on track zero, it gets largely overwritten by all this TrueCrypt code.  A copy of that is on the CD.  So you're able to restore the original track zero to its original condition.  And TrueCrypt is essentially completely removed then from the low area of the drive.



LEO:  Another reason to make that CD.



STEVE:  Oh, yeah.  Well, you have no choice.  And again, encrypting one's whole drive is a scary thing.  But these guys have nailed it.  I mean, they have made it so safe and so bulletproof against anything that might happen.



Now, one thing we talked about, I think in both of the last two episodes, I want to remind people of is that at this point in time the one thing that is not encrypted is the hibernation file.  And we know that it's possible for a whole system encryption to do that because that's the one thing that FREE CompuSec does do at the moment, and they're proud of it.  So it must be that it's kind of tricky.  You can imagine how it could be because it must be that the hibernation file, since it's not being encrypted, it's either not able to be decrypted at boot time, or it's not able to be encrypted when it's being written.



Essentially the hibernation file is a copy of your RAM and various hardware registers and the dynamic state of the system.  And so it's just copied, however much RAM you have is essentially copied to this hibernation file.  And it's after Windows is in, like, most of Windows is shut down so that everything is static, yet Windows isn't quite gone.  And so its last gasp is to write this file to the drive, and the reverse process.  But top of their list of, that is, the TrueCrypt guys understand this is a problem.  It's the first thing they list as the next thing that they're going to be working on.



So this would not be a problem in any system that isn't typically using hibernation.  For example, the desktop application that I have, like the corporate desktop, where you just want to make sure that, if someone spirits the system away in the night, you're not losing any corporate secrets, those systems typically don't use hibernation.  They're just shut down.  And what TrueCrypt does, again, in its super, make sure there's no way you can hurt yourself mode, is it completely disables hibernation if you do the full system encryption.  Hibernation is just no longer available to you as an option.  And so they protect you that way.



Also it's worth noting that there is nowhere, not even on your emergency rescue CD, is there any password recovery.  And, I mean, that's really what you want because password recovery is dangerous.  If the CD, for example, had the ability to forgive you for forgetting your passphrase, then that would be a huge security vulnerability.  But it won't remember it for you.  So whatever it is you choose, it is entirely incumbent upon you never to forget it.



LEO:  Do they put anywhere on the website, don't call us if you forget your password?  We don't know it, and we never...



STEVE:  And now the last two things are interesting, sort of edge cases of whole-system encryption.  And that is the wear leveling, which exists now in the higher end solid state media, and hard drive sector sparing.  We've talked about before many times about how if a hard drive sector starts becoming marginal, so that the hard drive is seeing that it has to apply more on-the-fly error correction than it's comfortable with, then it will read the sector and correct it one last time, then swap it out of use, essentially stop using that physical sector and use a good sector in its place.  The problem is, whatever data was in that sector at the time is still there.  So although you can't access it through the normal API, there are manufacturer-level means for doing so.  That is, that sector, you really cannot get to it from the outside.  But it's physically there on the drive.  And remember, it's only 512 bytes, but over time they tend to accumulate.



So the point is that if you then TrueCrypt your drive, you are TrueCrypting all the sectors currently in use, none which were once in use.  Those are gone.  They're not available.  But they have whatever data they had in them at the time.  And wear leveling on a solid state drive is similar.  As we know, the technology, the actual chemistry, tends to wear out in a given spot.  And so high-performance, good solid state drives, even if you're trying to rewrite the same spot, for example, well, you would never want to run Windows swap file on one of these.  I remember telling our listeners that Mark Thompson, my buddy at AnalogX did, and burned out a drive in a couple hours by doing so.



But the point is, in wear leveling, even though you think you're writing to the same spot, you can actually be writing to a physically different location, which means that, again, whatever was in the previous location has not been overwritten.  And these solid state drives also have extra sectors just for the possibility that one becomes damaged.  So similarly, you could encrypt your thumb drive, and TrueCrypt, in rewriting, it would read what it thinks is a physical sector and encrypt it and write it back.  But it might be writing it back to a different location, meaning that the original contents of that sector didn't get overwritten by the encrypted data as normally is the case on a hard drive.



So both of these say, I mean, these are, again, they're edge cases.  They're probably really not a huge concern.  But to their credit, again, the TrueCrypt site addresses this - actually it addresses wear leveling.  I don't think I saw it talk about sector sparing, but I understand that that's a problem.  So if someone was really concerned, the solution is get a new device, get a brand new solid-state drive, a brand new thumb drive or a brand new hard drive, and the first thing you do is encrypt it.  That is, you put it under TrueCrypt management.



LEO:  Interesting.



STEVE:  And if you do that, it will never be the case that unencrypted data is ever written to that, ever.



LEO:  And you might have some data integrity protection because of this wear leveling.



STEVE:  Sure.



LEO:  I think it would it kind of help you with that.



STEVE:  Well, wear leveling is certainly a good thing.  And it does extend the life of our little thumb drives.



LEO:  Especially for flash drives, yeah.



STEVE:  Yeah.  And then that's exactly what we're talking about.



LEO:  So encrypt to improve your flash drive life, among other things.  That's interesting.



STEVE:  Well, the wear leveling is something that happens continuously in the background, where it's always trying to sort of even out the amount of exposure...



LEO:  Oh, the drive does that automatically.



STEVE:  Exactly.



LEO:  Oh, I'm sorry.  I thought TrueCrypt was doing that.  It's just aware of it.  I get it, I get it.



STEVE:  Yeah, it's just underneath.  Well, actually it's not aware of it.  And it's not aware of it, and it can't do anything about it because it's happening at a level underneath - it's literally at the hardware level this remapping is going on, typically in large blocks, just to kind of keep things evenly written to across the entire surface of the drive.  But it does mean that you don't really know when you've encrypted something that you wrote back over the old stuff.  Not that you can read.  I mean, when you read what you wrote, you get back what you wrote.  But technically, electronically, there's still that data there.  It's not accessible from the outside.  But it could be accessible by, you know, NSA sorts of people, I mean, people who really, really know this stuff and want to see what was there.  So if you were really concerned, you just wanted to start fresh, TrueCrypt something before you ever start using it, and you never have to worry that anything of yours was ever there before.



LEO:  It's a beautiful thing.



STEVE:  And finally, this traveler mode is just spectacular.  It allows you essentially to carry TrueCrypt EXE and the TrueCrypt SYS.  And there is support for 64-bit version, or 64-bit OS.  It allows you to carry them on the media that is encrypted.  So, for example, you could create a traveler disk from a USB thumb drive.  And there's a nice little wizard that walks you through the process of doing so.  And you end up with an autorun INF file such that, when you plug this in to any computer, it runs TrueCrypt EXE that's on the unencrypted portion of this thumb drive.  And that has to be unencrypted so it's able to run it before it starts doing the encryption, the on-the-fly encryption.  Then it prompts you for the password that contains the data on the rest of the drive.  You enter that, and then it creates - you will already have a drive letter for sort of the outside container.  Then it creates another drive letter for what's encrypted and protected on the inside.  So you get a second drive letter, and that's your inner sanctum contents.



Now, it's worth noting that you have to have admin privileges because it needs to load the TrueCrypt.sys device drive, and non-admins are unable to load device drivers.  So what I've done is, rather than - I have, like, a 4GB thumb drive.  But I don't really have that much super secret stuff.  I have a lot of random freeware and utilities that I don't care about having them encrypted.  But I also, for example, have my master WiFi keys and other things that I really do care about.  So because you're creating a file that lives on this thumb drive, you can make it any size you want.  And the advantage of that, for example, is that you do not need admin privileges to read all the unencrypted area, only to get to your super secret inner sanctum, which is actually what I call the file, innersanctum.tc, on the thumb.



So the point is, I would say, if that makes sense to people, you know, if you had, like, a 4GB thumb drive, maybe make it half a gig.  512MB is the inner sanctum, and the other three and a half is just there, open and in the free, so that you can still get to most of the data without ever needing admin privileges.  And if you ever need to get to your really protected TrueCrypted stuff, then for that you would need admin privileges because you're not sure what control you're going to have over the computer that you might want to be plugging this into.



LEO:  Right.  Very cool.  And it's free from TrueCrypt.org.



STEVE:  It's all free.  And, Leo, it's open source.



LEO:  Thank you.  Another victory.



STEVE:  I know what that means to you.



LEO:  For the open source community.  No, it's really - but it shows you that, you know, sometimes people say, oh, how could you, how could open source write good software?  How could it compete with commercial software?  I don't think there's any question it can.



STEVE:  This is better than anything I've seen commercially, Leo.  I mean, it is a fantastic - I can recommend this without hesitation.  The only caveat I would have is it's very new.  It's February 5th.  It's a few weeks ago.  It already went from 5.0 to 5.0a.  And in doing so they made their bootloader - they reduced the size of their bootloader so that it was less greedy about how much space it needed on track zero.  And that allowed it to accommodate other things that might also want to share track zero with it.  So I would say maybe give it a few months, depending on how cautious people are feeling.  I mean, it's hard to imagine that with all the testing it's had, I mean, if you look at the download counts on their site, this thing is being heavily downloaded.



LEO:  I'm not surprised, yeah.



STEVE:  Lots of people have jumped on it.  I have never had a single bad experience with this.  And I love the idea that I can create a minimal system where TrueCrypt is almost not even present, where you only see it when you have to type in your passphrase, and it's not running in your tray, it's not running in the system, it's just a device driver that is allowing, advantaging the encryption of the whole thing.  And it's faster than before you installed it.



LEO:  And that's the amazing thing.  You know what is also good for your system?  SpinRite, all the free utilities, ShieldsUP, all the stuff Steve does at GRC.com, including 16KB versions of this show, transcripts, show notes, it's all there.  And now, thanks to the new menuing system, easy to find.  GRC.com.  And we come back every Thursday to bring you more security news.  Next week your questions and Steve's answers, so make sure you go to the feedback form there at GRC.com and submit your questions for our next episode.



STEVE:  It's GRC.com/feedback.  And I will be checking in before we do the Q&A that listeners will hear next week.  It's actually going to be two weeks for us in real time.  So people will have a week to listen to this, play with maybe TrueCrypt, and let me know what they think.  And we'll be sharing it in our next episode.



LEO:  Good.  Thank you, Steve.



STEVE:  My pleasure, Leo.  Great to talk to you.



LEO:  See you next time on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#134

DATE:		March 6, 2008

TITLE:		Listener Feedback Q&A #36

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-134.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 134 for March 6, 2008:  Listener Feedback #36.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.  



It's time for Security Now!.  And it feels like more than a week since we've done the show, and actually it is because Steve and I prerecorded our last episode.  I was about to go up to Canada.  And now we have a lot of catching up to do.  Hello, Steve Gibson.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.



LEO:  Security guru extraordinaire.



STEVE:  Well, it was a busy, busy, busy week and a half, I guess it's been.  It's funny, you know, this is a Q&A episode.  And I literally had a difficult time sorting through all of the feedback that we've received from listeners because of something major that happened that bears directly on the recent topics of whole-drive encryption.  You know, bizarrely enough, some guys at Princeton did some research where they really - this is an issue that's been known for a long time but never really received any focus.  They did some quantification of a weird phenomenon with dynamic RAM where they learned and showed exactly how long data will persist in dynamic RAM after it's been turned off.  The presumption was, you know, milliseconds.  It turns out, well, no, it's more like seconds.  And these guys did a ton of work to demonstrate how, for example, whole-drive encryption keys could be recovered from RAM before it had had a chance to decay far enough.  And, I mean, they've done some really clever things that I'm going to talk about in, I mean, extensively.  We're going to give it a whole episode of its own.  And there are other things that have all sort of happened all at the same time because it turns out that Firewire represents a vulnerability, and then USB dongles could be used to recapture RAM that hasn't been zeroed from, for example, after a cold boot.  So...



LEO:  We were all excited about the fact that we'd found this great full-disk encryption, and it all fell apart two days after we recorded the show.



STEVE:  Well, now, just - okay.  Because I want to give this whole treatment, we're not going to be able to get to it for a couple weeks because next week we've got the founder of IronKey is going to be our guest on the show to talk about IronKey and their hardware encryption stuff.  We've got today's Q&A, and we have a Q&A after that.  So it won't be till the episode after that...



LEO:  So we won't address this at all?



STEVE:  Well, there's just no need to.  I mean, I want to give it - there's so much to talk about, I don't want to give it partial treatment.  But what I did want to say was, for anyone who's worried, the bottom line is, if you wait 10 seconds, you're fine.  That is...



LEO:  So shut down and wait 10 seconds.



STEVE:  Exactly.



LEO:  Before you walk off.



STEVE:  Well, maybe 20 to be really safe.  Now, I mean, the fact is, it would be very difficult for someone to probably grab your laptop away from you and employ some sort of a hijack of the RAM without you knowing it.  So my point is, the length of time we're talking about data staying in RAM, it was believed to be insignificant.  It turns out, well, it can be significant, especially if you spray it with Freon, which can then actually cause the RAM to - the data in the RAM to last a lot longer.  Anyway, I wanted to let all of our listeners know that I was well aware of this.  Please...



LEO:  We know.  Stop emailing.



STEVE:  Please, when I updated my Security Now! mailbag, there were 745 pieces of mail.  Most of them were about this.  So...



LEO:  First of all, we welcome people letting us know about this stuff.  And really the fault is mine.  I'm going to take full responsibility because we had to prerecord that show because of my monthly trip to Vancouver.  And so as a result we did a show on TrueCrypt full-drive encryption several days after that news came out.  And people thought, oh, well, they obviously hadn't paid attention.  So it's just because we had to prerecord it.  And that's not going to happen again.  I've rearranged my schedule.  I'm not going to be making those trips to Vancouver.  So I will be able to make sure that we do this stuff the day, or the day before, usually, we air it.  So it's not going to be out of date.  So that'll help.



STEVE:  Yep, that'll be neat.  Also I wanted to mention that many people have subscribed to the ChangeDetection service.  I've got a button on the Security Now! page, and there's one at the bottom of GRC's home page.  And something like 8,000 people have subscribed over the years.  And every time I make a change to Security Now!'s page, I deliberately send out an update.  And the same thing is true with our web page.  Well, the ChangeDetection people upgraded their system and broke the ability for me to say to their bot, do not look at this page except where I tell you to because all of GRC's pages have stuff that's changing on them, like download counts and page, you know, how many days since the page was last updated.  And so I've deliberately over time constrained the ChangeDetection bot so that it only launches when I tell it it's okay to send the following message.



Well, they broke that.  And so for, I don't know, for weeks people, like these 8,500 people were all getting mail saying, oh, this page has changed, this page has changed, when it hadn't.  So I wanted to let everyone know, I wanted to apologize for that.  It's out of my control because there was no way I had of telling their bot not to do the pages.  And it was impossible to get a hold of them.  I had to track them down by their DNS registration and then sent email that had a long response cycle.  Finally I got somebody.  And then it wasn't until I showed him a snapshot of all the mail they were sending out.  Because I was getting a response from their bot saying, hey, we just notified 8,500 people of the change in your page.  It's like, argh.  So they finally fixed it.



Also our feedback form broke.  Normally when you submit feedback, and you say, okay, here's my note to Steve about Security Now!, and you press the button to send it, it says thank you for your feedback, it's been sent to Steve.  End of story.  Well, what happened was, when I made some sitewide changes to add the GRC menuing that we talked about last time, I broke inadvertently that page.  So people were concerned that maybe their feedback hadn't been received, so they would hit the back button and send it again, hit the back button and send it again.  So I got lots of copies of everyone's feedback.  The moment I saw that that problem was happening I fixed it.  And so that's fixed also.



LEO:  Sounds like it was a perfect storm of a week.



STEVE:  It was quite crazy.  Also I did want to mention that the script-free menuing is up on the site.  And we've got a search feature, sitewide search, courtesy of Google.  And also if you get a search that is too wide, there's a link at the top that allows you to narrow it down to just Security Now!.  So there's some nice Security Now!-oriented search that will allow people to find past episodes based on the transcripts that Elaine is doing.



LEO:  Yeah.  Great.  That's very handy.



STEVE:  And then my last note is that there were three critical security vulnerabilities in the Opera browser that were recently addressed.  My copy doesn't notice and look for updates by itself.  I had to tell it to look for updates.  I caught the little security blurb go by.  So I just wanted Opera users to know that they do want to do a little manual check for updates because there were a couple important changes that were made.  So they'll want to update Opera.



LEO:  Okay.  Very good.  Steve, anything else before I read you - we've got so many questions for you.



STEVE:  I did have one little bit of errata that I wanted to share.  We got a report from one of our listeners, Brian Dent, who reported that he was really glad that TrueCrypt made him produce an emergency rescue CD.



LEO:  Oh, yeah.



STEVE:  It turns out that another Adobe utility - I don't know what it is with Adobe and track 0.  But it turns out that he's learned that their acrotray.exe utility, which is some sort of something that lives down in the tray of Windows, is also writing into track 0 and wiped out TrueCrypt.  He rebooted, and he typed in his password.  Nothing happened.  And he said he saw his life pass before his eyes.  Then he realized, wait a minute, I've got that CD.  So he booted from the CD.  It was able to, of course, restore that track and the boot track, and he was able to get back into Windows.  And again, by juggling back and forth a little bit, he figured out what it was that was causing the problem.  And so this is two different things now from Adobe relative to, I guess to Macromedia.  Or I think Macromedia was the other one.  And so it's something DRMish that Adobe is doing is really causing problems.  And he did do some browsing around and confirmed that lots of other people are having the same problem with Adobe's software and its collision with the TrueCrypt bootloader.



LEO:  Oh, that's too bad.



STEVE:  So I just wanted to make sure our listeners knew.



LEO:  That's too bad.  That's too bad.



STEVE:  Eh, they'll have to fix it.  I mean, nobody else is doing DRM that way.  They certainly don't need to do it that way.  Someone just said, oh, this'll be clever.  And unfortunately that's an area that really needs to be reserved for non-OS or pre-OS things, and not used by software running in the OS.



LEO:  But that is why they do it there, because then you can't - it's harder for you to hack it, basically.



STEVE:  Well, it's really not.  Now that you know it's there, I would imagine you could just copy it to another drive and say, oh, look, you know, it's probably easy to fool after it's been exposed like this.  I think they were thinking, oh, this'll be off the radar.



LEO:  Yeah, nobody'll see it there, yeah.



STEVE:  Exactly.  It's off the radar.  Now it's really right in the middle of your radar because it's keeping your system from booting.



LEO:  Yeah.  Do you have any SpinRite tales to tell?



STEVE:  I have one little short notice.  It's something that we haven't really focused on before.  It turns out that most people who write testimonials do so because, first of all, they're Security Now! listeners, and they run across some serious problem with their system.  This is actually not from a Security Now! listener.  I don't have his real name.  His handle is Mgomgo.  So, you know, yeah.  Anyway, so he says, "I haven't used SpinRite very often (every couple of years or so).  But one of my important USB drives got really goofy on me last night.  None of the usual fixes worked, not even the XP repair utility on the install CD.  So I finally remembered SpinRite.  And in three hours a completely unreachable USB drive was restored to happiness.  Just thought you would appreciate a positive feedback note."



LEO:  Always.



STEVE:  So here's someone who doesn't know we get positive feedback notes pretty much all the time from our Security Now! listeners.



LEO:  Now, don't say that.  We welcome them.  It's always good to get them.



STEVE:  Absolutely.  Someone wrote the other day, well, I know you must get tired of these.  And I'm thinking, no, no, no, no, I never get tired of hearing news of SpinRite saving somebody.  I love that.



LEO:  Yeah.  Well, that's very nice.  And of course if you want to get a copy of SpinRite it's easy enough.  You just go to Steve's site, GRC.com.  It is really the best hard drive maintenance and often recovery utility.  Not always.  Depends on what's wrong with the hard drive.  If it's a file system error it's not going to fix that.  But if it's a hard drive error it will.  More than anything else I know.  Are you ready for Q&A?



STEVE:  Let's plow in, Leo.



LEO:  Mr. G.  This is from Keion, I guess.  Age 19, he's at Monroe College in the Bronx.  He writes:  Steve, I'm majoring in information technology.  I'm a new lis- no, he doesn't talk like that.  I'm a new listener to the Security Now! podcast.  Welcome, Keion.  Must say it's very interesting.  You made me encrypt my - you made me.  You made me encrypt my whole hard disk with TrueCrypt.  But one important question.  Even though a user may have encrypted his or her hard disk with TrueCrypt, can't the password still be retrieved if the user uses rainbow tables or the LOphtCrack live CD?  Thank you.  Now, explain what these are.



STEVE:  Yep.  We've never talked about rainbow tables.  It's even funny, the heritage of the name "rainbow tables."  It comes from one of the early very popular DRM anti-piracy dongles that was from a company called Rainbow.  And rainbow tables - so anyway, that's the name that these tables got.  They are nothing however, other than precomputation hash tables.  That is to say, the idea being that you could take all kinds of common dictionary-based words.



We've talked about how hashing works, how hashing is a one-way function.  And oftentimes, for example, a passphrase will be hashed in order to turn it into a fixed-length blob which, for example, might be used as a key for symmetric encryption or for some other purpose.  And so the idea being is hashing takes time.  It takes time to put something from a dictionary through the hashing algorithm in order to get the hashed output.  So since many different programs, for example, might use in the old days, for example, an MD5 hash, you could precompute the hashes, and that's what rainbow tables are.  Rainbow tables are all kinds of phrases and dictionary words and combinations of words that have painfully, in terms of compute time, been hashed once.



But rather than redoing all that work when you want to crack somebody's password, if you knew, for example, that the password was going to be run through an MD5 based on the OS, for example it might be a version of Linux or UNIX where they use an MD5 hash for the person's passwords, instead you would - somebody, some, like, bunch of people would do all of this work finding out, determining the MD5 hashes for a huge number of common phrases and passwords, and they'd save them.  So the result is these rainbow tables.  And then it's much faster to simply run through the table trying all of those at very high speed.  You no longer need to do the hashing of each of these things because they've already been hashed.  So essentially they are prehashing a large number of possible common passwords and phrases.  Well, so that's what rainbow tables are.



To answer his question, it's certainly the case that precomputation attacks like this are possible.  But they only work if you're starting off with a bad password.  So if you've got, you know, if you've used Scott, for example, as your passphrase, well, that's very bad because it's going to be in a dictionary.  It's going to likely be in a precomputation table.  And so, sure, it would certainly be possible for a system if you had a very, very weak passphrase and somebody specifically modeled the TrueCrypt technique going from your passphrase through the building of the decryption key for your drive.  Then, yes, potentially it would be better to do that than it would be to manually put in every possible phrase.



So again, the takeaway is you absolutely want to have a nonguessable passphrase, which is not going to be in a dictionary.  You know, something that looks really random.  Come up with some algorithm for typing on the keyboard, skewing the letters, scrambling things, add in some noise characters, you know, all the things we've talked about in the very, very early episodes of Security Now! for how to get good passwords.  If you use good passwords, then you're not going to be subject to any kind of a precomputation hash attack because yours won't be in that table of possible hashes.



LEO:  Right, right.  So as far as LOphtCrack, that's just a brute-force crack; right?



STEVE:  Exactly.



LEO:  And so same issue.



STEVE:  Exactly.  Same issue, the idea being that you don't want whatever - you don't want your passphrase to be in anybody else's dictionary or crack library in any way.



LEO:  But if it's a totally random password, the likelihood - with enough characters - the likelihood of them getting it by a brute force shrinks to nothing.



STEVE:  Well, yeah, exactly, because they're inherently going to try more likely passphrases, and yours just won't be among them.



LEO:  Yeah.  There you go, Keion.  Thanks for writing, and welcome to the show.  We hope you listen from now on to every episode.  Benton Greene of Austin, Texas wonders about data recovery on encrypted drives:  Hi, Steve.  I was listening to Security Now! 132 and heard you talking about how SpinRite doesn't care if a drive is encrypted or not since it only looks at the bits and whether or not it can read them.  It's trying to make sense of them or its file structure.  That got me thinking.  I remember you talking about how SpinRite will read the data off a bad sector, write it to a good sector.  But if the drive is encrypted, everything on the drive is pseudorandom noise.  So how does SpinRite know not to write over any pseudorandom noise it might find on a good sector?



STEVE:  This was a great point because it highlights some confusion about the way drives handle bad sectors, and also how it is that data recovery can still function even on an encrypted drive.  I mean, you know, if a lot of people are going to be encrypting their laptops, and for example they were able to successfully use SpinRite in the past to get them out of a jam, they'd like to know that SpinRite or appropriate data recovery technology could still be used.



So back in the old days of the FAT file system and when I first wrote SpinRite, it was aware of the file system structure and operation.  And it had to be because SpinRite needed to manually spare out sectors and move clusters around as it was moving valuable data out of regions that it had found to be defective.  So in those days drives were not dealing with their own defective sectors.  They were relying on the operating system and the file system to mark clusters bad, saying this is a region where it is not safe to save data.



When drives became intelligent, that all changed.  Drives then became responsible for the data stored in their own sectors and responsible for relocating those sectors themselves.  So what SpinRite developed into was technology which would work with the drive to show the drive that it had a problem.  That relieves SpinRite of the responsibility of understanding the file system and made SpinRite file system independent, which is the way it's able to work on Macs or TiVos or unformatted drives even, just anything.  Or drives that have been completely encrypted.  So again, SpinRite doesn't need to understand what is there.  It's able to show the drive, hey, I've got a sector that I've managed to recover the data from.  Give me somewhere safe to put it.  And the drive will then perform that relocation underneath, sort of underneath the level where the operating system and SpinRite interact with the drive.



Essentially sectors are all numbered.  They're numbered zero through some really big number with lots of digits.  And that's how many gigabytes of data you've got.  And so literally sector number 32627, for example, will go bad.  Well, what happens is, the drive takes that physical sector that was 32627 and makes it inaccessible.  And it takes a spare sector that it has and numbers it, literally gives it the same number, 32627.  And then SpinRite puts the data back from the recovered sector that it's been holding in RAM into this new sector which has the same number but is a physically different sector.  So essentially the operating system doesn't know anything happened, yet the data was recovered from a bad sector, put into a good sector, and that sector's number is the same.  So the operating system accesses it just like it was the bad sector, although now it's good.



LEO:  Interesting.  Interesting.  So really the file system keeps track of this stuff, not SpinRite.



STEVE:  Well, SpinRite doesn't.  And the file system no longer needs to because the drive keeps track.



LEO:  Oh, the drive, I see, at the lower level, yeah.



STEVE:  Exactly.  Underneath all this the drive says...



LEO:  But there is a file system, isn't there?  I mean, even when you're encrypted there has to, I mean, doesn't - there has to be a file system to know where the file is.



STEVE:  Sure.  But that's on the other side of the encryption/decryption.



LEO:  That's encrypted.  So that's garbage data, as well.



STEVE:  Exactly.



LEO:  Invisible, yeah.



STEVE:  So all the drive - the drive doesn't care what you store in its sectors.  And now neither does SpinRite.  So SpinRite works with the drive.  Neither SpinRite nor the drive care about the specific data you're storing because working together they're able to make sure that whatever it is you store is stored correctly, regardless of what it is.  Whether it's pseudorandom noise or normal, nonencrypted file system data.



LEO:  That's actually quite clever.



STEVE:  It's very cool.



LEO:  So does it do that even on unencrypted drives?  I guess it would.



STEVE:  Yep, it does them on all drives.



LEO:  That's how drives work.



STEVE:  Yep.



LEO:  It's good to have Steve around because he understands how drives work in ways that I think most people do not.  I mean, you have to to work - to do SpinRite.



STEVE:  To write it, yeah.



LEO:  Ryan listening in Florida was thinking about latent unencrypted data.  I don't know what it means, but I like the phrase.  Steve, after hearing your review and your concerns with full-drive encryption I've been wondering something.  You mentioned before that even if a hard drive is zeroed out, depending on how many times a sector is written to, it will still contain bits from previous data.  Please forgive me if I misunderstood what you were saying.  But if this were the case, couldn't the original unencrypted data still be read from a drive even if the drive was fully encrypted?  Would the best possible scenario be DBANing the drive - that's that program we recommend, Darik's Boot and Nuke - for a clean install of the system, then immediately encrypt the drive before any sensitive data is put on the drive?  That's a very good point.  Just want to confirm my suspicions and inform your listeners of potential security risks involved even when using full-drive encryption.



STEVE:  We sort of touched on this during our discussion of full-drive encryption, but it's a very good point, as you mentioned, Leo.  And I wanted to sort of highlight it.  And that is that we've talked about secure deletion of data from drives, that is to say that if you simply write zeroes over a data sector, when you read that data back, you are certainly going to get zeroes.  I mean, that's how drives work.  They're going to give you back what you last wrote.  But in fact when you write zeroes, it's an additive process. That is, you're adding magnetic flux reversals on top of the ones that were there before.  You're doing it strongly, that is, you are suppressing the prior ones.  But you're not completely eliminating all of their influence.  So there is a sort of a latent image of the data that was stored before, underneath what you've just written.



Now, it's very weak.  And it's weak enough that it won't confuse the drive when the drive reads that data back.  It'll read back zeroes if that's what you wrote.  But if you had very sensitive equipment - and this definitely exists, such sensitive equipment exists - and that equipment, for example, read back that you had zeroes, and then it said, okay, I know that he's written zeroes, so I'm going to subtract the zeroes out of the actual magnetic flux data that's there.  What that would do is that would have the effect of subtracting out what had most recently been written, leaving behind what was there before.  So it's literally a way of, like, peeling a layer of history off of the hard drive, allowing you to get to what was there before.  Which means if you simply ran one encryption pass over your drive, you are writing - you're turning every sector of unencrypted data into pseudorandom noise, as we know, and writing it right back on top.  But that latent unencrypted data is still there.



So it's exactly like we were talking about the problem of securely erasing a drive.  In order to securely erase a drive, the best way to securely erase a drive is to record multiple passes of really, truly random data.  Well, we know how virtually impossible, not completely impossible, but really hard it is for computers to create truly random data.  So really good pseudorandom data is good enough.  The point is, you want to - there are, for example, there are secure erasure programs which write well-known patterns on the drive.  Well, that's not what you want because if the well-known pattern is written, then somebody who's trying to peel these layers off to get back into the history of what was written, they know what those well-known patterns are.  They know what to successively subtract from the existing data in order to peel back each layer.



So what you really want, the optimal erasure is just several erasures, several overwrites with pseudorandom data.  That way they don't know what they're peeling off layer by layer because it was just pseudorandom.  So, and the state-of-the-art secure erasing utilities do typically now have a pseudorandom options.  And a few passes of that is absolutely all you need.  But we did also mention, and here would be like the ultimate solution, and that is, get a brand new drive that has none of your data on it.  TrueCrypt it first, then do all your work.  That is to say, you have to have Windows on it.  So you would take a brand new drive, you would install Windows, then before doing anything to it, before customizing it, putting any data on it at all, give it full-drive encryption.  That way everything you ever store of yours is always encrypted by full-drive encryption, and it never exists on the drive in unencrypted form.



LEO:  So let me just ask you, this is actually a topic that goes beyond whole-drive encryption, but the issue of fully securely erasing a drive.  And let me ask you a couple of questions.  If you - obviously the chance of recovering it if you do it a few passes is going to get tougher and tougher.



STEVE:  Yes.  Essentially what happens is you are pushing the signal into the noise.  There's a signal, and there's noise, the so-called signal-to-noise ratio.  So every time you're writing on top of it you're obscuring the signal, pushing it into the noise.  And at some point, after a couple passes, there's just no way that anybody, no matter how sensitive their equipment is, is going to be able to find a signal that is several writes into history.  At that point the actual physics of the signal being recovered from the drive will prevent you from finding the signal amid the noise.



LEO:  Right.  Now, practically speaking, who has machinery that even can read it if it's overwritten once?



STEVE:  Oh, we're not talking some guy in his garage.  We're at the NSA sort of level.



LEO:  But you are sure such a thing exists?



STEVE:  Oh, absolutely.  It absolutely does.



LEO:  Okay.



STEVE:  Yes.  Yes.  I mean, it sounds like science fiction.  But nobody would have believed a couple weeks ago that you could turn a computer off and capture its RAM half an hour later if you quickly froze the memory chip.  So, yes, I mean, this kind of stuff, it absolutely does exist.



LEO:  How many passes do you think you need to do to make it impractical to do this?



STEVE:  With pseudorandom data, three or four would absolutely be enough.



LEO:  Not ones and zeroes, but pseudorandom data.



STEVE:  Yes.  You absolutely need a pattern that is not known by the people who are trying to recover it.



LEO:  Ah.  If they know it's a one they can subtract that one.



STEVE:  They can subtract that one, exactly.



LEO:  Oh, interesting.  So you need to cover it - one pass with pseudorandom data, would that be enough?



STEVE:  Eh, it's enough for me.  I mean, maybe two.



LEO:  It'd be pretty hard to do, I mean, one pass even, since you don't know what's been written over there, it'd be pretty hard to reconstruct that, I would think.



STEVE:  Correct.  Well, okay.  Think about it this way.  If you did two passes, you always know what was last written.  Because that's, I mean, that's screaming at you, one, zero, one one, zero zero.



LEO:  Oh, because the file system tells it, that's right, of course.



STEVE:  Yeah, I mean, that's the data the sector has.



LEO:  That's retrievable, right, right, right.  Two passes is what you need, then.



STEVE:  Yes.  And, I mean, there are people that have, like, do 30.  It's like, okay, well, how much time do you have?  You could throw the drive away and go to Fry's in the time, I mean, in fact, you could earn enough money to buy a new drive in the time it would take to do that 30 times.  So...



LEO:  What I am surprised is to see the number of supposed drive shredders that do ones and zeroes.  That seems to be the most common.



STEVE:  Yes.  It is a misnomer that writing known patterns is useful.  It's absolutely not what you want to write.   You want to write noise.  Because no one then will know what it is they're trying to subtract after a couple layers.



LEO:  Now, I'm looking at Apple's secure erase options.  They have zero-out data, which writes zeroes over the data once.  Not good enough.



STEVE:  Not good enough.



LEO:  They do have a seven-pass erase using DOD 5220-22M.  It erases the information and writes over the data seven times.  Doesn't say what it writes it with.  But it's going to take seven times longer.  And then there is a 35-pass array.



STEVE:  I know.



LEO:  I don't know why it would include that.  It doesn't specify random.  But I'm figuring, if you're going to write, you might as well write random if you understand what you're doing.



STEVE:  Right.



LEO:  Which I didn't, but now I do.  Thanks to you, as usual, we've learned something today.  Matt, tuning in from Melbourne, Australia, has connectivity troubles.  I'm sorry, Matt.  I have a Netgear wireless router WPN824 RangeMax that I'm now using with a hardwired Ethernet connection on my PC.  That's a terrible accent, I apologize.   Also with a wireless connection to our other home PC.  My whole LAN was wireless until I got fed up with having to reboot/repair the connection due to signal loss, or what I thought was signal loss.  I installed the Ethernet connection - it's amazing, all the questioners actually sound like me, don't they.  I installed the Ethernet connection to my PC and left the other PC to continue using the wireless connection on the router.  However, even now with a direct wired link to my router my connection is having the same continuous issues.  I get these kinds of questions on the radio show all the time.  I'm so glad you're getting them.  What can I do?  Since I download approximately 50GB a month - what's he doing?



STEVE:  Uh-huh.  I think his ISP has got his number, too.



LEO:  I think so.  I need a reliable connection that won't keep dropping out, et cetera.  Is it dropping out, or may I have a setting wrong somewhere?  Also, how can I give my connection to the router priority over the wireless connection without interrupting performance for either one?



STEVE:  Okay.  There are a couple things going on.  First of all, if Matt is downloading from Melbourne 50GB a month...



LEO:  That's a lot.



STEVE:  ...it may very well be that his appetite for downloads has come to the attention of his ISP.  We do know that ISPs are now doing so-called "bandwidth throttling," not being 'Net neutral, and have the ability to interrupt connections.  So we know that's going on.  We don't know that that's what's happening for Matt.  He's having this problem over his non-wireless connection, that is, over his physical, electrically wired Ethernet connection.



Now, I have seen that some switches and routers are more finicky about the quality of the cable that is being used.  And most people are now running at 100MG, if not a gig, between their equipment.  The equipment on each end has to be a gig, so you have to have a gig Ethernet adapter.  But, for example, most laptops, new laptops now have it because it's like, oh, yeah, well, why not?  This is a phenomenal amount of signal to squeeze over a cable that's wandering around the living room and looping around the dining room table a few times and going lord knows, probably runs behind the toaster on the kitchen sink.  I mean, it's amazing this works at all.  So I would absolutely pay attention to the quality of the cable and the connections.



The Ethernet connection, the RJ45 connector was beautifully designed with gold contacts.  It was designed so that, as you plug it in, it's creating a wiping contact in order to continually sort of self-clean and get any oxide off of the wires that may be there.  But I know that I've solved problems sometimes just by jiggling it in and out a little bit to sort of rewipe the contacts.   So that's worth doing.  Now, many people also have problems with wireless disconnections.  And it turns out...



LEO:  That's very common.



STEVE:  Yes.  It turns out, believe it or not, that this is by design, and it's Microsoft's fault.



LEO:  Oh, great.  Just empirically I have this experience because whenever we do Skype with people on wireless I ask them to go wired because of dropouts.



STEVE:  Yes.



LEO:  Usually brief, but nevertheless apparent.



STEVE:  Well, and believe it or not, even deliberate.  What happens is, Microsoft came up with this wonderful technology in XP called Wireless Zero Configuration.  And what it literally does is it deliberately disconnects you periodically in order to see if it can find a better access point for you to be connected to.  Now...



LEO:  I call that promiscuous.



STEVE:  Who knows what they were thinking.  The common wisdom is that they were thinking, well, people are just web surfing.  And so you click a link, and you get some stuff, and then you read the page, and you click a link.  So they really won't even notice if we just disconnect them...



LEO:  And it's true, you don't.



STEVE:  ...as long as we reconnect them quickly enough.



LEO:  Yes, it's true.



STEVE:  The problem is that many people are not in that model anymore.  Many people, like you were just saying, Leo, create static connections for instant messaging or Skype or remotely connecting across a VPN to some other system.  I mean, the model for many people, especially as ubiquitous as WiFi has become, no longer tolerates brief disconnections.  So I made, in response to this, the first update to Wizmo in six years.



LEO:  Oh, that's great.



STEVE:  Wizmo has a new command called wanlock.  So you say "wizmo wanlock."  And following the Wizmo model of creating a shortcut, basically it allows you to put a little shortcut on your desktop or down in your quick launch tray where, after you've got a connection that you like, you just click that, and it stops the Wireless Zero Configuration service.  It turns out that just stopping the service stops this from happening, and you no longer lose your wireless connection.



LEO:  I do recommend people just disable that service because there's no real reason for it.



STEVE:  Well, as long as you don't need it in order to get your connection going initially.  So I also have wanopen, which does the reverse of wanlock.  And so that just starts the service up again, in case somebody needed it.  Now, normally the service is set for autostart, so it'll automatically start when you boot.  So the idea would be, you boot up and get connected.  Then you can just do the little Wizmo wanlock.  Or, I mean, you don't have to do that.  If you don't want to use Wizmo, just stop the Wireless Zero Configuration service.  You could also open a DOS prompt and type "net stop wzcsvc" and hit enter.  That'll do the same thing.  But that's all I did.  Wanlock just stops the Wireless Zero Configuration service.  And I think you'll find, given that you've got a strong enough signal, that these dropouts go away.



LEO:  Didn't we also talk about a fix that Microsoft pushed but never told - actually didn't push, released but never pushed, never told anybody about, that improves Wireless Zero Config or fixes these problems?



STEVE:  I know that we did.  And I don't know...



LEO:  Fixes this problem.



STEVE:  I'm not sure now what it was that it was doing.  The problem is, some people who are network-savvy believe they're making things better - or, that is, more secure - by turning off their access point's SSID broadcast.



LEO:  Yeah, right.



STEVE:  That's another problem is it's better to have that on.  For one thing, it provides you no security.  Remember...



LEO:  It's in every packet.



STEVE:  Yes.



LEO:  It's actually transmitted.  So...



STEVE:  Yes.  It's got to be - it's in the packet.  Anybody sniffing anyway can see what your network's SSID is.  The only thing...



LEO:  And it slows things down considerably because your system's going who are you, what are you doing here?



STEVE:  Yup, it ends up being a bad thing for WiFi performance.  So I have a friend who, sort of tongue in cheek, he changed it to something like NORAD Central Command or something.  And he actually lives not far from a major military base.  And so you could imagine people who, like, networks - networks within range comes up.  And it says NORAD Central Command.  It's like, ooh, crap, I'd better not touch that one.



LEO:  Or more likely, let's attack.  Let's get in that one.



STEVE:  Oh, he uses a WPA key from GRC, so believe me, they're not going to figure that one out.



LEO:  Yeah, I get calls all the time about connectivity issues.  And wireless especially is a constant dropout.  Why he would get a wired dropout, I think you're hitting the nail on the head.  If he's downloading 50GB a month, his ISP is kind of nudging him a little bit.



STEVE:  I think they're doing a little throttling, yeah.



LEO:  Do you really need all that bandwidth?  He's probably doing BitTorrent, and they probably are throttling those.  Deric Merino in San Diego, California needs his file to be touched.  Touch me.  Hi, guys.  Before going into my issue let me say I'm looking through the documentation, and I haven't found anything to help me yet.  Good, we like it when you read the manual first.  He says:  I've been using TrueCrypt for some time and recently started using Jungle Disk.  Which we both love.  Steve and I use that.  I just love it.  I'm running into a situation where Jungle Disk is not backing up TrueCrypt archives and would like to run my scenario by you.  Let me explain.



I have a TrueCrypt archive - actually I have a few, but let's just use one for example - created Jan. 1, 2008, given a size of 200MG.  So the initial timestamp says 01/01/08.  The file size will not change as I add/delete files because of the way TrueCrypt chunks HDD space.  It's always a 200MB file.



STEVE:  Right, it's a container file.



LEO:  Yes, container.  I've configured my Jungle Disk auto backup to run periodically, grabbing some specific folders as well as this specific archive file.  Jungle Disk pulls them all up to S3, no problem.  Now, let's say that today, February 25 - in this case March 6 - I add or delete or modify some file in the archive through TrueCrypt.  When I'm done, I unmount all the TrueCrypt dives, then manually kick off the backup process.  Jungle Disk does not see that the archive file has changed.  Therefore it doesn't reupload it to S3.  Looking at the archive through Windows Explorer I see the initial timestamp hasn't changed from 01/01/08.  To me this is strange.  Shouldn't the timestamp or at least the hash of the archive change when I modify the internal content?  If it does not change, I'm not sure how to get Jungle Disk to reupload.  Any thoughts?  I don't think it's using date.  It's probably using a CRC or something that...



STEVE:  Well, that would take a long time to compute.



LEO:  Oh, would it.  Oh, okay.



STEVE:  Yeah.  My guess would be, for example, that at first that Jungle Disk first looks at the date, assuming that that's going to change if the file is written to.  And then maybe then it does some sort of a hash, or it has some logic for deciding whether the date reflects an actual change.  I sort of smiled because this sounds to me like the TrueCrypt guys doing their job, which I think they do very well, of further obscuring what's going on.



LEO:  Nothing's changed here.  Go somewhere else.



STEVE:  Exactly.  I'll bet that they are deliberately keeping the timestamp constant, just to say, oh, yeah, you've not accessed this strange file.  We don't know what this is.  It was created back at the beginning of the year, and no one's done anything with it since.  I just think that's very cool, and I would bet that's what they're doing.  However, that has a problem which Deric has discovered, and that is that Jungle Disk, or for that matter any other backup tool which is based on - which is using timestamps on files to determine whether they've changed, would not see a change.  Which is why I mentioned at the top that his file needs to be touched.



Many old computer guys may be aware of the "touch" command, which is probably originally a UNIX command, which allows you to essentially manually change a file's time and date to the current one.  It was used by developers a lot because there's a process known as "make," that uses a make file, which sort of automatically compiles changes and sort of builds - it's used for rebuilding programs.  Sometimes you have a need for telling something in your system, very much like this, to take a look at this file, it needs some attention of some sort, needs to be recompiled or something, where that process may not be automatic.  So you would have a touch command.  You would touch the file to set its time and date to the current one.



It turns out that the UNIX utilities have been recompiled and ported over to Windows.  And on today's show notes for this show, Episode 134, I've got a link to a set of open source versions of many of the standard UNIX commands, among which is touch.  It's very small.  I've got one of them on my machine which I use for various purposes.  So anyway, I wanted to aim Deric at that link where he could find the touch program to manually tweak his TrueCrypt archives so that Jungle Disk would then see them.  And it looks, I mean, this is a manual process.  But he's already unmounting his archives and manually launching Jungle Disk.  So I would imagine that adding one little command to a batch file, if that's what he's using for unmounting them, would be trivial.  And then this would work for him.



LEO:  There's another possibility, and I'll run it by you.  Jungle Disk's backup by default does not back up in-use files.  Would it be seen as in use if TrueCrypt had that file open and was saving stuff to it?



STEVE:  No, because in the scenario that Deric mentioned he is unmounting those.



LEO:  Oh, okay.



STEVE:  And that would be closing them.



LEO:  There is a switch in Jungle Disk that you could say backup, locked, or in use, or files that are in use by other applications.  So that might be worth a try.  But, yeah, if he's unmounting it, I guess it wouldn't be seen as in use.  The other thing is there are other programs like rsync that do in fact do a checksum.  I don't know what Jungle Disk is doing for its backup, how it's determining it.  If it's just looking at the date, yeah, that's obviously what's confusing it.  But rsync does a rolling checksum.  I mean, it actually looks at if the file's been changed.  And that will work with Jungle Disk, as well.  Moving on, another question.



STEVE:  And for what it's worth I think rsync is part of that package also that I mentioned.



LEO:  Oh, yeah, rsync is a universal UNIX program.  Just it's odd that Jungle Disk would only look at the file date.  That's not a great way to do that.  I guess it's faster, though, isn't it, yeah.  Andrew Dalton, lurking somewhere in Connecticut, was wondering:  Steve, a question came up amongst my coworkers.  I thought you'd be the guy that ultimately could answer the question.  We are thinking of using an eraser utility to securely delete sensitive files, overwriting them seven times.  A question came up on what kind of threat or vulnerability - we're circling back.



STEVE:  Yeah, we sort of are.



LEO:  What kind of threat or vulnerability does that protect against?  Does an attacker need physical possession of the drive to retrieve files that were deleted by conventional methods?  Or could an attacker retrieve these files by hacking in over a network, if they could get past the firewall and the security measures?  They'd need physical access, wouldn't they?



STEVE:  Yeah.  This was interesting because it puts a nice little bit of frosting on the discussion we were just having.  In order to read the data underneath what's been written before, you need, I mean, serious, serious, technology.  Maybe you could use the drive's normal heads with a high-precision analog-to-digital converter to digitize to a much greater degree and with much greater accuracy than the drive normally did, the analog signal that the drive's heads retrieve.  But it may very well be necessary to take the drive apart and give the platter extra special care and extra kinds of equipment.



So the answer is, to do anything like this, to get underneath the data that has been overwritten on a drive, I mean, it is way beyond anything you could do at the API, that is, the electrical interface to the drive.  That's always, by definition, going to just give you what was most recently written to the sector, which of course is the drive's whole point.  It never wants you to see what was there before because something was written on top of it, and that's the data that you want to get back when you read it.  So no way could you do it with anything other than really fancy equipment, replacing probably the little motherboard of the drive, or maybe even needing to take the drive physically apart and have access to the platters themselves.  So by no means could it be done remotely or from outside the computer.



LEO:  Let's just say it.  Only the NSA could do this.



STEVE:  Right.  It's not something to worry about.



LEO:  If anybody can, it would be the NSA.  And they would have to come to your house, take your computer, take it back to Fort Meade - it's not going to happen.



STEVE:  Well, but this is the kind of stuff that was done, for example, after 9/11, if terrorists' hard drives and laptops were found.



LEO:  It was, you're right, yeah.



STEVE:  I mean, believe me, they were going to find out what was written there.



LEO:  Yeah.  You know, I wonder, I mean, how sophisticated are terrorists?  Are they smart enough to use encryption?



STEVE:  Unfortunately they're all using it now.



LEO:  Rob Pontes of Toronto, Ontario, in Canada, of course, worries that maybe Steve wasn't paying attention.  Steve, pay attention.



STEVE:  I'm trying.



LEO:  You need another quinti venti latte.



STEVE:  You've got my attention, Leo.



LEO:  Hi, Steve.  I listened to your podcast on TrueCrypt 5 and was confused by your finding that system performance was increased.  You mentioned that you were restoring your system from an image, though.  So my question is this:  Wouldn't the act of restoring a drive not place the data more closely together than the initially imaged drive?  In other words, optimize it?  Defragment it?  Could that account for the performance increase?



STEVE:  I was paying attention.  And that certainly did occur to me.  So I verified that the imaging tool I was using, which was Drive Snapshot, I verified that a restored snapshot was restoring the individual sectors in their highly fragmented, lots of holes and spaces left on the drive, position, which in fact it was.  So Rob is completely correct.  If I did, for example, a file-by-file backup and then did a file-by-file restore, it would just put them all right back in the file system, packing them one after the other, and I would lose the fragmentation that I had deliberately created by giving Windows all those security updates on an old version of Windows specifically for the purpose of fragmenting the drive pieces.  So I did make sure that this was going on.



I should mention that this was by no means a super extensive, thorough benchmark.  I just did it quickly because, when I was using the FREE CompuSec utility, I did see a 9 percent overhead of just doing this defrag operation.  And as we know, for whatever reason I got a negative percent overhead with TrueCrypt.  I have to imagine that it was some caching and buffering they're doing that happened to favor the fact that I was doing sort of random reads and writes to the drive.  The good news is, though, it is not slowing systems down appreciably.  That much we know.  But I wouldn't want to sell my little quickie benchmark of just seeing how long it takes to defrag a drive as being extensive, real-world performance.  That was just something to give me an idea whether this thing was going to be slow.  And it sure is not.



LEO:  Well, for one thing, it's much heavier disk access than most programs would ever do.  But that's what you wanted to find out is how it impacts...



STEVE:  Exactly, exactly.



LEO:  Clement listening in Melbourne, Australia - another Melbournite - found scripts on GRC.  No.  For shame.  Mr. Anti-Script?  Hi, Steve.  I'm a long-time listener of Security Now!.  I used the Firefox no-script plug-in to disable scripting while browsing the 'Net.  I noticed as I am surfing your 'Net that three to four scripts are currently forbidden from GRC.com and GRCtech.com.  I'm curious about this.  I thought your website was script-free.  Could it be some malware hijacking your site?  What's the matter, mate?



STEVE:  Not to worry, Clement.  I have to say, though, I've slipped a little bit into the dark side.



LEO:  Oh, Steve.



STEVE:  It was a consequence of adding that Google search technology to the site.



LEO:  That's a JavaScript piece.



STEVE:  Well, it is JavaScript, and it uses JavaScript in order to return the results.  However, while I was over there in Google Land, they sort of said, hey, you know, if you like search, how about our web analytics technology?  And Mark Thompson, my buddy at AnalogX, had been raving about...



LEO:  I use it.  I love it, yeah.



STEVE:  Yes, the amazing amount of information that a webmaster is able to obtain about where people are coming from, what searches they're using, what search tools they're using, how long people are staying, how many people apparently go there and immediately leave, blah blah blah blah blah.  So I thought, well, let me just sort of try this.  And to do web analytics requires that you put this little, actually two little JavaScript instances at the bottom of each of your pages.  So that's what's going on.



I don't think I'm going to keep it because I can live without it.  And I do still sort of feel like this is kind of icky, especially to be, like, exactly as Clement has seen, to be throwing up warnings because he's using no-script all the time.  I don't like that.  And here I went to all the trouble of doing an absolutely 100 percent script-free CSS-based menuing system.  So, yeah, I think that's just temporary.  I'm going to give it a few more - maybe another week or two.  And, I mean, I looked at it today, I look at it every couple of days and go, okay, that's interesting.  But it's like, I don't really care.  So it'll be leaving soon.



LEO:  You know, it just really underscores how difficult it is to use a script-free web.



STEVE:  Yes, Leo, we're losing the battle.



LEO:  Both for users and for webmasters.  I use Google Analytics.  And while I don't have the same fear of scripts that you do - well, they're just everywhere.  I mean, you're probably one site in literally a million that doesn't use them.  So everybody does.  And, yeah, if you don't like them, no-script is a really good Firefox plug-in that just alerts you and will disable scripts whenever you say I don't trust this site.  On the other hand, you're probably going to enable them in most cases.  Certainly if you use TWiT.tv there's scripts for the Flash, there's scripts for analytics, there's all sorts of scripts on there, all benign.



Now, there is a larger issue with Google Analytics, which I think is worth addressing, which is you're sending Google information about every single person who visits your site, including the things that any log keeps track of, like IP address, browser used and so forth.  I'm not sure we want to share that information with Google.  And certainly we're not telling our users we're doing that.



STEVE:  Good point.



LEO:  So that's - I think that's an even larger issue.  And I use Google Analytics because it's free.  It's really excellent analytics.  They bought Urchin.  If you are willing to spend money, you can host it locally.  And there are certainly many stats packages you can host locally that don't, in fact, put any JavaScript on the page, they just analyze the log.  And that's probably, you know, you won't get heat maps and things like that.  For that you need JavaScript.  So I...



STEVE:  And they've got some just...



LEO:  Oh, it's great.



STEVE:  Oh, have you seen that deal where you can do the overlay, where you...



LEO:  Yeah, that's the heat map, yeah.



STEVE:  You hover your mouse over your own links on your own page, and it shows you - oh, my goodness.



LEO:  You can see where people click, where they linger, what they're looking at.  And that's really useful for understanding how people use your site, what they like, what they don't like, what they never use.  But that requires JavaScript because something has to follow their mouse around.  And that's the problem.  That you cannot get out of the logs.  You can only get what page they're on and for how long.  You know, the referrers, things like that.



STEVE:  And I don't even have logging on most of the time.



LEO:  Your server is not logging?



STEVE:  No.



LEO:  Really.



STEVE:  No.



LEO:  See, that's good.  I think that's great.  I mean, that really is, you know, 99 - again, you're one in a million.  Almost everybody, I mean, if you just run Apache out of the box or IIS out of the box, it logs every visitor.  That's just normal.  I mean, I don't pay attention to the log.  But if there's a problem you can go back and say, well, what was going on?



STEVE:  Yep, in fact on our privacy page I mention that I do not have logging because I feel it's part of what I want, the privacy I want GRC's visitors to have, and that if during like weird times I may turn it on for forensic purposes briefly to find out if something's wrong or what's going on.  But in general - and then I delete them afterwards.  But in general, I mean, I don't have logging on right now.  I never do.



LEO:  Excellent.  You're a rare man, Mr. Steve Gibson.  But we knew that for a long time.  Colman Burke in San Francisco reminds us of the Heise Security Offline Update:  Almost 10 episodes back, #124, your Fantastic Tip of the Week went to someone who clued you in to the Heise stuff, which I tried and found to be a godsend.  Since that episode, though, you and Leo have several times referred to the pain of doing a Windows reinstall, in particular the repeated patching and rebooting that entails.  Have you forgotten about Heise or found some reason not to use after praising it so highly?  I've done a couple of XP reinstalls on various machines since learning about Heise and found it avoided the headaches you guys continue to grouse about, except for one trivial Windows update for the most recent patches that Heise didn't include.  In my defense, I haven't done a reinstall since we've talked about it.  But I definitely had forgotten about it.  I probably wouldn't use it just because I forgot.



STEVE:  And Leo, I think mostly we just enjoy grousing about the 90-plus patches that XP now needs, even after Service Pack 2, and wondering where Service Pack 3 is.  I did want to affirm for everyone that it is a really good system.  What happens for me is, I'm not installing XP often enough, and normally I'm never really planning to do it, that it's worth going through all the trouble.  Also, I've got so many machines around here, I'm never doing it on, like, my main machine.  So I don't mind really if it just sits over there and sucks things down and grinds along and does whatever it's going to do and does reboots and things.  So for somebody who is in the XP reinstall business, oh my goodness, this thing really makes sense.



And again I'll remind people, you can find it just by Googling the phrase "offline-update."  If you Google "offline-update," the first few links that come up, definitely the first link at the moment, will be the page that will take you to these guys.  And, I mean, it is absolutely terrific.  And I wanted to bring this up again to say that I've had a bunch of positive feedback from people who we turned onto this 10 episodes ago and who are saying, oh, this thing really works.  I mean, they've looked at the scripts, the way it builds these ISOs, and they've been very, very impressed with it.  So I wanted to remind people about it.  It will be less critical once SP3 comes out for Windows XP.  Speaking of which, Leo, I just saw something today earlier about Microsoft getting ready to end XP.



LEO:  Well, they have said for a long time that June 30th they would stop selling it.



STEVE:  Oh, okay.



LEO:  And there's been quite a bit of protesting about that.  I don't know what the latest is.  I'll have to look real quickly and see.  But they've been planning on phasing that out.  And they don't - they want you to buy Vista.  And you know, to be honest, it makes sense to buy Vista.  It's just - if it's on a new machine it makes sense.  I guess...



STEVE:  It doesn't make sense yet, Leo.  It needs another three or four years.  They just broke it with Service Pack 1.  Just the Service Pack 1 broke a whole bunch of things.  It's like, oh, this is really not ready yet.



LEO:  Well, you know, I try to stay away from Windows whenever I can.  And frankly, that's one of the reasons.  It's old, and it's showing its age.



STEVE:  You know that I run Skype on my little Mac.  And I turn it on once a week to talk with you.  And I was doing it today, and I was sort of browsing.  I thought, oh, I haven't updated Skype for a while, so I checked, and oh, I was way behind, so I updated Skype.  And I just sort of felt peaceful.  Like oh, this is just sort of peaceful to use a Mac.  You're not, like, holding onto the edge of your desk thinking, oh, what could happen.



LEO:  Oh, my God.  Windows 2000 was like that.  It was a peaceful operating system.



STEVE:  I'm looking at Windows 2000 right now, Leo.



LEO:  It just works and works and works.  I think really, if I could say anything to Microsoft, I would say just keep something like - probably Windows 2000 would be the best choice.  Just keep that around.  Offer it for 100 bucks, 50 bucks.  Just say we'll keep it up to date, we'll keep it patched, it's not going to be high priority, you're not going to see any new features.  But just for people who want a solid, non-changing, and secure operating system, we'd like to just give you that.  Kind of Windows Light or something, or Windows Business or something.  I don't know why they don't do that.



STEVE:  Well, because, as you say, ultimately - okay.  In fairness to them, Windows has got so many problems that keeping it current is a full-time job.  I mean, you know, somebody...



LEO:  You would say, look, this isn't going to run anything past 2000.  It's for those of you who are still running all your old software and are not planning to upgrade.  But the problem is they no longer ship patches.



STEVE:  Well, exactly.  And unfortunately it still needs them because they've got so much legacy code that they're still finding problems in that they would have to - and again, in fairness to Microsoft, having that many versions all in different states, I mean, I don't know how they do it as it is.  I mean, it is such a huge task that they have.  But it's a problem that they brought on themselves, of course, by needing all those patches.



LEO:  It's difficult.  That's why I think in the long run for a lot of users a UNIX system is probably a very good idea.  But it's not good for novice users.  But then is Windows good for novice users anymore?  I don't know.



STEVE:  Well, and Mac, I guess Apple really took some heat for this most recent Mac OS upgrade.  A lot of people thinking I don't know what I paid my money for.



LEO:  As with I guess anybody, they're moving away from simplicity.  And the idea of a - that's what I'm saying is we need a simple kind of no-frills operating system for people who just want to surf, get email.  And the Mac has got, you know, as always happens with age, it accretes more and more features, more bells and whistles, and that means more bugs.  And the only reason Windows is worse right now is because it's older.  OS X in 10 years is going to be the same creaky machine Windows is and will need to - at some point you have to cut it off and say we're going to start completely from scratch.  Let's see, Martin in Calgary, Alberta, Canada needs the magic password.



STEVE:  Oh, you're not going to believe this one, Leo.



LEO:  What is the one - what's Pee-wee's magic password?  He says:  Hi, Steve.  I recently bought a new Toshiba laptop.  It came with a 200GB Toshiba hard drive.  During last weekend my kids played with the laptop, created a system and a hard drive password using the BIOS.  They can't remember it.  In order to reset the BIOS password, I knew how to do it, so I removed the battery from the motherboard and put it back.  Bingo.  Well, that's good he can get his BIOS.  However, the hard drive password, still there.  In order to use the new laptop I pulled the 20GB hard drive from my fried Xbox 360, put it into the laptop.  The partitions were a little weird, but it worked.  Now, how can I reset the password on the hard drive?  There's no jumper or nothin'.  He's got one of those new hardware encryption drives; right?



STEVE:  Well, no.  He probably - it may just be...



LEO:  Or used that IDE lock?



STEVE:  Yeah.  I mean, the ATAPI spec has had a password facility which many laptops BIOSes know about.  This is the so-called hard drive password.  It's not encrypted, it's just locked.  And here's the bad news.  There's no way to unlock it.  There is no...



LEO:  Really?



STEVE:  No.  There's no jumper.  Now, the only thing you could do is if you had, literally, a subpoena, or you were the NSA or government clearance or something, Toshiba certainly has the ability at the factory to remove the password because it's just a password that the drive has on it that you would need somehow to remove.  The problem is, the spec, the ATA password management spec does have a way to remove the password from the drive.  The only way it will agree to do so is if it first wipes the drive.  So you are able to force the removal of the password at the cost of all the drive's data.  Which really makes sense.  I mean, that's a secure solution.  So it doesn't - you're not just having to throw the drive out the window and say, well, my kids put a password on the drive that they no longer - you've got to keep your kids away from the BIOS, I think, in your laptop in the future.  But so you are able to prevent completely scrapping the drive.  But you'd have to have a utility - perhaps Toshiba makes it, I'm not even aware of one that's wandering around - that gives you the option of doing this, of removing the password at the cost of wiping the drive.  But all drives will unlock themselves under command after they have successfully wiped their entire contents clean.  But there is no jumper.



LEO:  At least you can use your computer again.  And he says he just bought it, so maybe he doesn't have a lot of data on it.



STEVE:  That sounds likely.  Although I don't know where I would tell him to go get such a utility.  I mean, I could write one, but I never have.  It must be out there somewhere.



LEO:  What if it were one of those new hardware-encrypted drives?  Would there be any recourse?



STEVE:  No, because the drive would not have the password.  But I'm sure you could do the same thing.  There is the same facility of saying unlock the drive, just wipe yourself first.



LEO:  Rene Knigge - which sounds like a Peter Sellers name - is at NATO HQ in the Netherlands, so I'm not going to make fun of him anymore, has solved the unshredding problem:  I heard you guys mention the deal with shredders and scanners plus computers being able to put Humpty-Dumpty back together again.  We talked about the fact that there are machines that will reassemble crosscut-shredded documents automatically.  At NATO HQ here in the Netherlands our papers get shredded, as well.  But in the same machine, water is added - oh, what a good idea.



STEVE:  Isn't that neat?



LEO:  Creating, yeah, an irreversible and definitely unscannable pulp.  Just add water, you should be good.  And then you can make papier-mch animals afterwards.



STEVE:  So I just loved that.  It's like, okay, the shredder machines have been upgraded to compensate for this problem.  They now have a water reservoir.  And so you shred the paper, and it turns it into pulp.



LEO:  Wow.



STEVE:  Like this big goo pile at the bottom of the...



LEO:  Magical.  That's very cool.  All right.  You ready for the last question?



STEVE:  Or the segue question.



LEO:  Brian W. in Montreal:  Computer World Magazine just published a lengthy article reviewing several "secure" USB drives from major vendors.  Most of what they said has already been covered better on your podcast.  But some of the security features and hoops these drives use are pretty funny in a sad sort of way, like this nugget:  "Kingston refused to say what encryption mode the device runs in, citing that it was proprietary information."  <Sigh.>  In the end, they came to the same conclusion as you and recommended IronKey, although they failed to point out you could do better than almost all of these devices just by using any old USB key and a free copy of TrueCrypt.



STEVE:  Right.  It's funny, I took my car in for its, like, major service last week.  And I literally have, I have a little 4GB - I actually think it is Kingston.  Kingston has a cool little super-mini USB gizmo.  It's got a little weird sort of slider on the outside.  And immediately I thought, well, this isn't going to last long.  And the detents wore down in about four days because of course I couldn't keep from sliding it back and forth.



LEO:  You keep sliding it, don't you.  I knew it.  I have the same one on my keychain.  It just gets...



STEVE:  Yeah, I know, it's just too fun to play with, you know?  Anyway, so, and then the little slider cracked in half, and it's gone, leaving just a sort of a little exposed USB UI electrical interface on the front.  But it doesn't matter, wasn't being hidden very well anyway by that thing.  But the point is that I had to leave my keys with the service folks to have the car for the day.  And I thought, wow, I mean, now I'm really glad that there is nothing on this in the clear.  There is TrueCrypt.exe and TrueCrypt.sys and a file, can't remember what I called it, blob, I think, dot ct.  And so there was no danger from turning my keys with this little USB dongle over to the techs.  Because, you know, you have to think what a tasty thing for anyone to see is like a USB dongle on someone's keychain.  It's like, wow, I can just plug it into my little laptop here and see if he's got any good files I need.  So, you know, you definitely want that encrypted.



LEO:  Absolutely, yeah.



STEVE:  And next week we will have the founder of IronKey as our guest to talk about his hardware's encryption solution and what makes it, he thinks, the best there is.



LEO:  Well, that'll be fun.  We'll talk about IronKey and how it works and why it's a good idea, or not, on Security Now!.  Steve, everybody knows that the place to go for great free software is GRC.com, including your new, updated Wizmo with a special turn off zero wireless config feature.



STEVE:  Yep, the new wanlock command.



LEO:  Wanlock.  You're good at naming stuff.  Wanlock.  You could have worked in advertising.  SpinRite, wanlock, Wizmo.



STEVE:  DCOMbobulator.



LEO:  DCOMbobulator, Shoot the Messenger, Unplug n' Pray, they're all there for free.  And of course SpinRite, which is the world's greatest must-have disk maintenance and recovery utility, GRC.com.  We also put 16KB versions of the show there.  Steve gets transcripts made, which is really handy for people who want to follow along as they listen or want to share the information with others because we've heard you do that, as well.  GRC.com.  Now with the new script-free menuing system.  Google Analytics included without charge.



STEVE:  I'm in the process of nailing down some loose ends from some research that I had done, actually it was the summer of '06.  The menuing system was one.  There's another new feature coming to GRC shortly which is going to be a blockbuster.  I'm very excited about it, and it's going to be right up the alley of our Security Now! listeners.  So we will certainly be doing an episode about some major revelations that have been uncovered as a consequence of this research.  And it'll be a new, basically a new feature, not unlike ShieldsUP!, which will greet people who come to GRC.  So we'll be talking about it within a few weeks.



LEO:  Excellent.  Thank you, Steve Gibson.



STEVE:  Talk to you soon, Leo.



LEO:  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#135

DATE:		March 13, 2008

TITLE:		IronKey

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		David Jevans, CEO of IronKey

SOURCE FILE:	http://media.GRC.com/sn/SN-135.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I spend 45 terrific minutes speaking with David Jevans, IronKey's CEO and founder, about the inner workings and features of their truly unique security-hardened cryptographic hardware USB storage device.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 135 for March 13, 2008:  IronKey.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, 135 episodes strong, and a good one ahead today.  Hello, Steve Gibson.



STEVE GIBSON:  Hey, Leo.  Great to talk to you again.



LEO:  We are going to be talking in just a little bit with the folks from IronKey.



STEVE:  In fact, that's the title of this episode, IronKey.



LEO:  Old IronKey.  And Raymond Burr need not apply.  So this is a - we've talked about it peripherally, but I know you wanted to get the guy who invented it on the show.  This is a USB key that has special built-in encryption and special hardware protection to keep your data private.  And it's very interesting.



STEVE:  And we learned that it's more than we thought it was.



LEO:  Yeah, that's kind of neat.  So that's coming up.  Do you have any addenda or news?



STEVE:  Oh, yes, I do.  You bet.  First of all, it was a relatively quiet week over in Microsoft Land.  However, after our podcast went public last week on Friday, Sun released updates to their so-called JDK and JRE, their Java technology, which had some serious vulnerabilities that anyone using the JDK or the JRE really need to take a look at.  They had both privilege elevation and buffer overflow vulnerabilities.  And, for example, reading from their announcement, they said, for example - this is one of many -"A vulnerability in the Java runtime environment may allow JavaScript code that is downloaded by a browser to make connections to network services on the system that the browser runs on through Java APIs.  This may allow files that are accessible through these network services, or vulnerabilities that exist on these network services, which are not otherwise normally accessible, to be accessed or exploited."



So the whole idea, of course, was to create a sandboxed environment and keep Java stuff within its own environment.  Well, this says that there is leakage from that, and that an attack vector is the user's browser with JavaScript.  So the vulnerability, of course, is you go to some website, and they're able essentially to bypass your router and firewall and get a connection to your internal network.  So that's not good.



LEO:  Microsoft did have a patch for Mac users.  Macintosh Office 2004 had a serious vulnerability that allows an attacker to overwrite the contents of computer memory with malicious code.  So if you use Microsoft Office, it's not an auto update.  You've got to run the Office updater.



STEVE:  Oh, and in fact there were, you're right, there were also some updates to the regular Windows-side Office suite, as well.  So there were some Office updates across the board, but not mainstream Windows OS.



LEO:  You can add, and I think it's a good idea to do that, if you use Office you can add Office updates to your overall Windows Update.  I can't remember how to do that.  But I think if you go to WindowsUpdate.com you can figure that out.



STEVE:  What you do is you actually switch from Windows Update to Microsoft Update.



LEO:  Ah, okay.



STEVE:  And Microsoft Update is sort of this omnibus now that does SQL stuff and Office and Windows.  And so it's absolutely what you want to do in order to keep basically the whole Microsoft suite current.



LEO:  Good.  Also issues in Office 2008, mostly bug issues, stability.  So that's for Mac, as well.  Worth updating if you have Office on the Mac.



STEVE:  Okay, there were a couple TrueCrypt things, as well.  We talked - one of our Q&A questions last week, and you and I actually talked about this after or as part of our Q&A, remember the guy that wanted automatic update of his TrueCrypt volume, but the TrueCrypt timestamp was being maintained at its original creation date, not showing that it had been updated.  So Jungle Disk was not seeing a change, and the Jungle Disk backup was not triggering.  I got a nice note from the creator of Jungle Disk saying, hey, Steve, several of your listeners contacted us to ask about that.  So he said, I wanted to let you know that there's a timestamp option offered in TrueCrypt.  It's "/m ts" for - obviously for timestamp.  And what that does is that tells TrueCrypt not to fudge the modification time, but to leave it real.  In which case Jungle Disk then does pick up on the change and will do the backup.  Also last week we had a question about random hashing and rainbow tables, you'll remember.  And someone posted over on the GRC forums that because TrueCrypt was using salt in their hash, there was no problem with rainbow tables.



LEO:  But I always put salt in my hash.



STEVE:  I figured you did.  You seem like the kind of guy who would want to salt his hash.



LEO:  So by salting your hash, the rainbow tables can't be - you can't make a standard rainbow table.



STEVE:  Exactly.  And, for example, that's something that WPA also does as part of its cipher suite.  And it makes sense, the idea being that part of the randomness, the entropy that you're creating when you're creating the volume, is to create a chunk of entropy which is so-called "salt," which is mixed in with the data that you're hashing so that essentially you end up with custom hash results that are not like anybody else's hash results.  So unlike rainbow tables, for example, where there'd be a rainbow table for MD5, the generic MD5 hash, all you have to do to completely destroy those is add a little bit of salt.  So that's what TrueCrypt is doing to maintain itself.  And then the big news.



LEO:  And then.



STEVE:  We are now at TrueCrypt v5.1, which has added hibernation file support.



LEO:  Wow, that was fast.



STEVE:  It did not take these guys long.



LEO:  See, open source ain't so bad.  There's some advantage to open source.



STEVE:  So we now - the one real thing that concerned people was that the hibernation file would be a nonencrypted snapshot of RAM.  Now it is encrypted.  And they've even solved the annoying Adobe/Macromedia problem.  They shrunk the size of the bootloader, and they're now able to put two copies of it on the first track of the hard drive.  If one of the copies is damaged by something like Macromedia or Adobe, I think it was some PDF component that we learned about last week, well, if one of them gets damaged, the other one is automatically used.  So you don't end up being crippled by doing that.  And they reimplemented AES in my favorite programming language.



LEO:  What's that?



STEVE:  Assembly language.  They took it from C to Assembler, and it now runs between 30 and 90 percent faster than it did before.



LEO:  Wow.  I guess, you know, people still can benefit from optimizing in Assembly.  You used to do that all the time, especially I/O.  You'd optimize those little things than ran - the loops and stuff that ran a lot in Assembler.  And then it got kind of to the point where these processors were so fast you could do everything in C or whatever high-level language you use.  But, you know, in something like encryption there is a lot of processor activity, isn't there.



STEVE:  Well, Leo, that's my favorite language.  It's all I write in, so...



LEO:  I know, I know.



STEVE:  And then there was one little weird blurb I just want to sort of bring to our listeners' attention.  And that is that CNN covered a story of they met with three Chinese hackers in their 20s who have claimed to have hacked many of the world's most secure and sensitive sites, including downloading information from the Pentagon after hacking into the Pentagon's network.  They claim that they have been paid by the Chinese government to do this. 



LEO:  Wow.



STEVE:  The Chinese government, of course, denies that and says that's ridiculous, we've never paid anyone to do this kind of work.  Okay, couple that with the fact that the FBI released the news recently that they've participated in over 400 seizures of counterfeit Cisco networking equipment totaling more than $76 million, which has been filtering into the United States from China.  So this is counterfeit, for example Cisco routers, not made by Cisco, coming into the U.S. from China.



LEO:  And you can bet they have backdoors.



STEVE:  Well, that's exactly the problem.  In 2004 some counterfeit Cisco switches ended up in one of the Navy's secure facilities.  So, I mean, I use Cisco routers.  I know how sophisticated they are.  They call it IOS is the OS that runs in these routers.  There could be anything in those routers, and there would be no one way to know that there weren't backdoors in these routers.  So, I mean, it becomes a little frightening.



LEO:  No kidding.  Wow.  No kidding.  So make sure you're getting a real Cisco router.  I have to believe that the Chinese government - that's cyber warfare.  And you have to believe our government's doing the same kind of thing to other hostile, potentially hostile governments.



STEVE:  It's sad and freaky, but I think you're probably right, Leo.



LEO:  Well, and in a way it's not because at least, you know, I mean, it's a kind of warfare that people don't necessarily die from.  And it's certainly where it's going to happen.  It's more like an economic warfare.  It's not a good thing, but it's certainly - I would expect it to be going on.



STEVE:  And I guess that's where the world is headed.



LEO:  Yeah.  Yeah.



STEVE:  Speaking of which, SpinRite fixed a WiFi problem the other day.



LEO:  All right, I like that.  How could it possibly - I'll bite.  How could it possibly do that?



STEVE:  We got a fun email on March 9th from Steve - I'm afraid to pronounce his last name - Diyorio.  I think that's it, Steve Diyorio.  And for Elaine's benefit I'll spell it, D-i-y-o-r-i-o.  Anyway, so his subject was "SpinRite Fixes Weird Wireless Problem."  And he said, "Hi, Steve.  Just wanted to drop you a note to say thanks and thought this might be an interesting one to mention on a future episode of Security Now!."  Yeah.



He says, "I have Ubuntu Linux installed on an HP laptop and have been extremely happy with it for quite some number of years now.  I've noticed that my system has been booting and running a bit slower lately (a feature of Windows that I thought I'd left far behind)."  He said, "And more recently my wireless suddenly refused to connect.  I tried everything within my knowledge to get the wireless working and spent countless hours scratching my head, trying to figure this mysterious problem out.  In light of the slowness, I figured I would run SpinRite at level 4 to do some maintenance on the whole hard drive.  Lo and behold, after fixing some errors on my drive, my wireless is working again.  Thanks for a wonderful product.  I will share my experience with everyone I meet."  And we've shared his experience with everyone who listens to this podcast.



LEO:  Why would a - I guess was there a flaw maybe in the file or...



STEVE:  Well, just, I mean, this is a bizarre circumstance where there were problems on his drive in a sector of something to do with his wireless networking.  And SpinRite fixed the sector that was erroneous and brought his wireless back online.



LEO:  You know, one thing I do notice, and I get a lot of calls from people who say everything's slowed down, slowed down, what's going on?  And of course naturally you say spyware or viruses or, you know.  But one thing is, if a drive is flaky, the operating system can spend an inordinate amount of time trying to read it.  It may eventually read it and continue on, but that can really slow a system down, can't it?



STEVE:  Well, in fact, yes.  One of my very good friends from many, many moons ago was experimenting with some servers.  He listened to Security Now!.  And he asked for a copy of SpinRite to sort of see what was going on with hard drives.  He learned that the vibration of the fans in the server chasses were enough to throw the hard drive heads off track.  So that even though everything was working, the system was running much more slowly because the drives were having to go around and around and retry their reads in order to get the data off the drive.  And the problem is, of course, the track densities are so high now in order to get these multi-hundred gigs of data in such a small space, that a little bit of vibration will end up coupling into the drive.  And so it turned out that just by taking the drives out of the, like, off the server chassis and suspending them, suddenly the servers ran much faster.



LEO:  Now, how would he use SpinRite to find that out?



STEVE:  Well, he was able just to perform more experiments with it and watch SpinRite run in sort of a uniform fashion.  And I think he told me he pushed down on the drive, coupling it mechanically more tightly to the server, and he saw it slow down.



LEO:  So Dynastat, if Dynastat is running you can kind of get an idea of the reliability or performance of the drive.



STEVE:  Sure.



LEO:  Yeah.  Oh, that's a clever diagnostic.  I think as computers get more complex we're going to have to see more and more of these kinds of people who are really good at this kind of deduction because they're such complex systems, and there's so many interactions.  You can't just say, oh, well, it's got to be that anymore.  You really have to, I don't know what, try stuff, I guess.



STEVE:  Well, and you know, when we talk about network security, cyber terrorism, you know, the notion, I mean, these three Chinese hackers said that no website is safe.  They have to know what the software is that the website's running.  Then they dig into their bag of tricks, and they know where vulnerabilities are.  And the problem is, as this stuff gets incredibly complicated, it becomes more like an analog domain than a digital domain because it gets soft.  It's just not as hard.  It's not a yes or no, this packet can or cannot go.  It's like, well, wait a minute, we'll use this protocol and come in through some network that this has an affiliation with and hop around a few times and get in.



LEO:  I kind of hate it when there are errors on my server, and the server announces what it is, its exact version number, what software is running - this is Apache 127, and you've got a problem with the Perl module CPAN_43.  It's like saying to the hacker, this is what we're running.



STEVE:  Oh, you mean like it actually spits it up on the web page.



LEO:  Yeah, Apache does that.  Kind of bugs me.  I mean, I guess with Nmap or Nessus or something you could figure out what server's running anyway.  But I don't know, it seems like they should be a little more quiet just for security reasons.



STEVE:  Yeah.  The less you say, the better.



LEO:  I learned that from stealth mode at ShieldsUP!, GRC.com.  And we're going to talk a little bit about Audible, and then we're going to get to our guest.  We're going to talk with Dave about IronKey.  He's the CEO of IronKey and then really kind of an amazing amalgam of security technologies all built into one USB key.  I think you're going to be interested I this.  So introduce our guest here.



STEVE:  Well, this is David Jevans, who is the founder and CEO of IronKey Corporation, who we're going to spend a nice chunk of time with, talking about IronKey, what it is, how the technology works, and all the things that it is way beyond just being a secure USB flash drive.



LEO:  Very cool.



STEVE:  So, yeah, David, I wanted to get directly from the creator's brain what the genesis was, the motivation for IronKey.  And I guess really, I mean, it competes with software-based encryption solutions.  So I wanted to get a real good sense for our listeners, who've been very interested in IronKey, and in fact we're interviewing you and talking to you and doing a whole show on it because of demand from our listeners.  What has IronKey got that no other solutions do?



DAVID JEVANS:  Well, I appreciate the chance to speak with you guys.  And you've thrown quite a lot of good questions out, so let me try to take that stuff one by one.  I think the first thing you asked was around how we came up with the idea and what we were trying to accomplish.  And I'll be quite honest with you.  What we started out with is certainly not what we ended up with.  And I think that's probably true of most businesses out there.  I've been in the security business now for over 10 years.  And one of the things that I do is I run a nonprofit organization called the Anti-Phishing Working Group.



LEO:  You run that?  That is a great group.



DAVID:  Yeah, thanks.



LEO:  I've referred people to that site many, many times, especially because of your archive of phishing emails.  For people who don't believe in phishing or say, oh, I would never be fooled by that, they go to those archives, they look so real that it's very convincing.



DAVID:  Yeah.  I mean, it's a group effort.  We now have over 2,000 member companies and government agencies and law enforcement groups that work with us.



LEO:  How did that come about?  Was this your idea, or...



DAVID:  It was.  In 2003 I was working at a company called Tumbleweed which makes antispam and email encryption.  And, you know, I started seeing that strange spam that looked like it was coming from PayPal, and it wasn't; or looked like it was coming from Citibank, and it clearly wasn't.  And I looked into it, and we decided to publish a little report because we saw quite a big spike of it at the end of 2003, just before Christmas there was a huge spike.  And we got a lot of interest.  We had quite a number of banks and major ITs come together, and we started the Working Group.  And to be honest, I thought back then phishing would have been solved by probably mid-2004.



LEO:  Why hasn't it been?  Because first of all, I can see why - I'm sorry.  I don't mean to hijack this, Steve.  But I think it's an important subject.  We'll get to IronKey in a second.  I can see why end-users, consumers are fooled by them because if I get an email that looks like it's from PayPal, smells like it's from PayPal, and it says they're going to cancel my account unless I click this link, I click the link and it goes to a web page that looks like PayPal, I could see how you'd be fooled by that.  But in every case that link has to go to a bad website.  You would think that those sites would get shut down so fast that it would just not work very well.



DAVID:  Well, I'll tell you, back in 2004 there were no shut down companies, and nobody admitted there was a problem.  People didn't understand it.  There was no email authentication protocols.  It wasn't on the radar of anybody.  And I think that's one of the things that we've been successful with is building a lot of awareness.  One of the things that we have done, though, is we've tracked the bad guys and how they've changed and how they've grown and how they've become more and more professional about stealing data, stealing credentials, stealing passwords.  I mean, they have gotten so effective.  So to your point about takedowns, now there are takedown companies and people know how to get sites taken off the Internet.  So what the bad guys do is they go and abuse CMS.  They implement something called "fast flux" where they basically change the server every 10 seconds where it's being hosted.



LEO:  Oh, wow.



DAVID:  Right.  So everything you do, the bad guys who are making hundreds of millions of dollars a year off this cyber crime, they move a whole 'nother step ahead in distributed systems technology, massive botnet armies to get around spam filters, I mean, it's a continuing evolution against well-funded bad guys.



LEO:  Well, thank you for the Anti-Phishing Working Group.  It's AntiPhishing.org, phishing with a "ph."  And obviously it still needs to be there, which is sad to say.



DAVID:  Yeah.



LEO:  So that was the inspiration.



DAVID:  Well, yeah.  So one of the things that I get out of that, you know, it's a nonprofit group, but one of the real values I have out of it is I get to see what the bad guys are doing probably in advance of most other people because I know a lot of the security researchers.  I work with the financial institutions.  And so you get to see the trends and the sophistication.  And it became clear to me that to really start protecting the infrastructure and to protect people's privacy and their passwords and really the stability of the financial system, you need some pieces of hardware.  You can't just do everything in software.  So you need either hardware to protect against keyloggers or hardware to encrypt data or hardware to do strong authentication on the Internet so that, if they steal your password, it doesn't matter, they still can't get in.  And that the person you're logging into, they know who you are, and it's really you.



And so that was really the genesis of the whole IronKey project was, you know, we see where it's going.  Let's put something together that can be used by millions of people because it's easy to use, it's not expensive, and it does something that they know how to use, and that we can build it as a platform to help protect against more and more of these threats.  So, you know, the first thing was, hey, there are lots and lots of flash drives out there, in fact well over a hundred million of these sold every year.  Why don't we make a really great one with hardware encryption, no software needs to be installed, make it cross-platform, but add some magic in there which is authentication so it can be used to do a lot more than just a regular flash drive.



LEO:  So why flash drives, though?  Do you think that they're particularly vulnerable?



DAVID:  Well, so there's two aspects to it, I think.  The first one is that, if you look at an enterprise context, people use flash drives all the time to back data up.  They go on sales calls.  They're going from hospitals to clinics. They're brokers moving all around the country.  There's lots of different use cases for why people use them.  And as you know, people lose them.  They get stolen.  The laptop gets stolen.  And, you know, there's just increasing regulations about making sure everything's locked down.



LEO:  Right.



STEVE:  And of course we're also more and more seeing the requirements at various levels to make sure that anything that can be stolen is encrypted.



DAVID:  Absolutely.  And, you know, we can get into why hardware encryption is the right answer versus software encryption in a minute.  But that was clearly one market requirement right there was make these things really easy to use, and you can't mess it up.  Anything you write on it is for sure secure.



STEVE:  One question I saw was that you talk about being able to do a secure backup.  And so I'm wondering whether that works by pulling the encrypted data off of the flash, not going through the decryption on the way out. 



DAVID:  It actually does not work that way, although that is a very good idea on how to do it.  The reason it does not work that way is because the encryption keys on the IronKey devices are not exportable.



STEVE:  Good. 



DAVID:  You can't pull them off.  Right.  Which means that malware can't copy them.  A malicious user can't steal them.  You can't have a - they're not vulnerable to cold boot attacks that we've seen out of Princeton, some research in the last two weeks on that about hacking software encryption.  So if I can't pull the encryption key off the device, but the data is sitting on your computer encrypted with it, if I lose my IronKey, and I go buy a new one that's got an encryption key, how do I decrypt the data?



STEVE:  Right.  So you have to run it back through the cipher chip in order to decrypt it and then reencrypt it with something that's outside of the chip. 



DAVID:  That's correct.  You have to generate another AES key that is a strong AES key, a random AES key, generated by the hardware random number generator.  You encrypt the data with that, and then you further encrypt the AES key with several rounds of a hash based off of your password.  And you have to store that with the encrypted data.  It is how all basic software encryption has to work.



STEVE:  So the cipher chip is a little bit like the TPM technology that we have discussed at length in that you are limited in what you're able to ask it to tell you.  And for example, it internally generates these ciphers, I mean the keys, which are used by the IronKey.  And so you could tell it to do encryption and decryption, but there's no facility for you to say give me the key that you have inside. 



DAVID:  That is correct.  And you can't have the hardware allow that and then pretend like I won't expose that API.



STEVE:  Right. 



DAVID:  Because I know from everything I see in security, if it exists, people will try to hack it.  And they will find a backdoor if it exists.  You cannot have any backdoors because they will get found. 



STEVE:  And I guess the other thing that I found intriguing, certainly you make the point that you're going to prevent brute-force attacks by counting down the number of incorrect attempts to access the key through a password.  And there's language in various places on the site and in the help files about this thing self-destructing. 



DAVID:  Right.  So let's talk about the brute-force prevention first.  If I find a hard drive, a flash drive, a computer, and it's been encrypted with a software encryption package, you know, there are freeware ones and there are ones that you can buy, effectively the key is stored somehow with the data and then encrypted with some derivation of your password, or the key itself is in fact a derivation of your password.  Which means if I want to break an encrypted drive, I don't go try and break AES encryption because, I mean, I've done the calculations.  Even with 100 million computers I can get it down to, you know, a couple hundred thousand years maybe.  It's not practical.  What you do is you guess passwords.  You can build a machine for $10 million that will guess 40,000 billion passwords a second. 



LEO:  Really? 



DAVID:  Yeah, you can crack strong, you know, you can crack things with 10-character passwords in three hours.



LEO:  Wow. 



DAVID:  Absolutely.  And in fact with some of the NVIDIA supercomputers it's probably less than $10 million now.



LEO:  Wow.  How many a second?  How many a second? 



DAVID:  You can guess 40,000 billion passwords a second for about 10 million bucks.



LEO:  40,000 - that's 40 trillion. 



DAVID:  Yeah.  So that's the way to attack software encryption is password...



LEO:  How can you get it even to respond that fast?  I guess you have to... 



DAVID:  Well, you just do this all in parallel.  You just build a chip with a hundred cores on it, and you put a hundred chips per board.  And then you could - and, you know, each chip costs maybe five, 10 bucks.  And then you just put 10,000 boards in a computer room.



STEVE:  And then you stick it next to Niagara Falls for power and cooling. 



DAVID:  Well, yeah, I mean...



LEO:  But that's why you said the NSA has to do something like this, Steve.  It's just prohibitively expensive for the Russian mafia to do it.  But the NSA... 



DAVID:  Right, or you set up an online service and offer...



LEO:  Yeah, that's right.  Hey, it's the new SETI@home.  Brute-force cracking at home. 



DAVID:  Yeah.  So the point of it is that the key - the way to crack it is through cracking passwords.  And to be quite honest you can crack most passwords much faster than that because most people don't use a strong, random, 10-digit password.  And so there's commercial password-cracking tools available on the Internet that also work with hardware.  And in fact you can get forensic - you can buy computer systems that are multiprocessor purely for cracking passwords.  So that's the way to do it.  So the defense is you have to have  hardware-implemented, brute-force prevention.  And the keys have to be managed in hardware and not exportable.  And so what we do on the IronKey is the Cryptochip itself manages the password count and the password verification so that when you try to log into it, it will check itself, is this the right password.  And a decrementive counter which is stored on-chip in nonvolatile protected memory under layers of metal with differential power attack protection and things of that nature.  So you cannot go and replay it.  You can't put wires on it to turn it off.  You can't recopy NAND Flash.  You basically have 10 tries, and that's it.  So that effectively makes it uncrackable by password guessing means.



STEVE:  And when you say "and that's it," what happens after a failed attempt to guess number 10?



DAVID:  So on, of course, on try number nine you're warned extensively, this is the end, your last chance.  We mean it for sure seriously.  You're about to get a shiny nice little doorstop if you do this.  But if you enter incorrectly 10 times, you're an attacker and you enter in 10 times, basically what happens is the Cryptochip is disabled, the encryption keys are killed, and then we do our Flash Trash where we basically, as a further step, we erase at a hardware level, at a very low level in the NAND Flash, we erase all of the encrypted data, including all the wear leveling and any ID data for the AES encryption.  So it's a much lower level, higher speed way to erase all data than you could ever possibly do with software.



STEVE:  Very nice.



DAVID:  Yeah.  All encryption keys, by the way, on the device are also further encrypted.  So if somebody did find some way to strip it down and get an electron microscope in there and somehow defeat the anti-tamper and the layers of metal, you still have to go break AES.  So we believe it's got multiple levels of protection.



STEVE:  The one thing that you're not doing that occurred to me, because I've seen reference, and you've mentioned it, to keystroke logging protection, is that this is the same password every time. 



DAVID:  Yeah.  So we're looking at a couple of different things on the keystroke side of things.  So what you have to do is you have to look at the threat model about what you're actually defending against.  So the first one is I've studied many, many keyloggers; and as part of some research we did for the Department of Homeland Security we analyzed over 60,000 pieces of malware and different loggers.  Most of the keyloggers, modern high-end ones, also do screenshot logging.  Because they're designed to defeat virtual keyboards.  So if you take a look at the good keyloggers out there, they will actually take a click of - they will take a small screenshot, oftentimes, of the screen around where the cursor is, or a full black-and-white image, so they can see if you're clicking on a virtual keyboard.  So if that's an issue, you know, you can't just solve that by a virtual keyboard.  But that is one thing that we're looking at.



You could do complicated things like the password's different every time.  People have suggested you hold a button, and every third character is your password, or you do a challenge/response and say what's the third letter of your password.  And, you know, you could do all that.  But it's a usability nightmare.  And is it really worth investing a lot of time in writing the software to do that, versus looking at other things, for example, physical external entry of your password.



STEVE:  Right. 



DAVID:  So we're looking more down those lines.  The keylogger thing you can - and here's the other point, is if it's a generic keylogger, okay, well, it's on your computer, its getting at your flash drive is probably the least of your worries because this thing's on your computer getting your key logs, all your Internet stuff and all that kind of thing.  So, and also, if it really wanted to attack you, it's going to copy the - it's custom targeted, and it's going to copy the data off your computer anyway once you unlock the device.  So there is certainly a threat, but you have to kind of look at it and go, okay, what is the real threat, what are they going after, and are there other ways to mitigate it that are not quite so obvious.



LEO:  So what this is really designed to do is, if you lose the USB key, or somebody takes it from you, not somebody who has access to your system. 



DAVID:  Yeah.  If somebody has access to your system, they can install malware on your computer, I mean, you're dead.



STEVE:  Right, right.  One thing that surprised me, as I was establishing the password for my key, I got - you know how you have the little red and green tag that shows whether your password is okay, it turned green for me after I'd entered four characters.  Or five, maybe.  But, I mean, I was surprised what a short password it would allow me to use for the IronKey itself.  And I thought, well, maybe that's because of this 10 strikes and you're out, guessing doesn't really work approach. 



DAVID:  Right.  So there are two answers to it.  Well, I guess there's probably three.  But one is usability.  So we wanted to make a product that a lot of people could use.  So if you put it at eight characters with three upper and two lower, lots of people are not going to remember that, or they're going to write it down someplace, which is not that secure if you write it down, especially if you write it on the back of your flash drive or in your wallet.



The other one is, you're quite right, because there's brute-force password-guessing prevention, it's not the same as a software attack where on software I can guess thousands or hundreds of thousands or millions of passwords in a second.  With the IronKey you've got 10 tries.  So you've actually restricted your attack surface down to be five or four or 10, whatever characters you choose, but there's only 10 tries.  There's not a thousand or a million.  So you can effectively use shorter passwords, and your odds of being attacked are actually lower.  Now, I do recommend longer passwords.  But I personally, my personal recommendation, it's not a corporate one, but a personal recommendation is use a passphrase that's easy to remember, like "The quick brown fox jumped over my IronKey" or something.  Because, you know, you don't have to have weird numbers and letters and upper and lowercase because, again, you've only got 10 tries to guess.  Now...



LEO:  That's kind of a nice - that's kind of nice.  You're right, that is totally a usability issue.  And this issue is raised by Bill Gates, who said passwords don't work because people can't remember them.  Either they use a password they can remember, in which case it's no good, or they can't remember them and they put them on a sticky on their screen, and then that's no good either.  But this was his argument for smartcards.



STEVE:  And the point David is making is that the only way you can really do this and make it secure is if the counter is on the hardware because any time, I mean, you could certainly have a counter in software, but all you have to do is have some other software that resets it back, and again you're vulnerable to brute-force attacks.



LEO:  Now, once something like that is on hardware, though, it's still software, it's just it's written to firmware.  Can't it be modified with a jump or something like that? 



DAVID:  No, well, you'd have - so now, well, that brings up the question of can someone load malicious code.



LEO:  Right.



STEVE:  Right. 



DAVID:  So the firmware that does the counter is not modifiable when it comes out of the factory.  So it's actually not upgradeable.  It's actually a metal layer in the factor.  So that firmware itself is not - it's actually part of the silicon.



LEO:  Right.



STEVE:  So you're never going to change your mind and wish that it was 20 tries instead of 10.  That part is...



[Talking simultaneously]



STEVE:  Exactly, it's physically locked at 10. 



DAVID:  Well, actually the logic which implements the counter is locked.  The counter can actually be changed in our enterprise version, which is just coming out in the next couple of weeks.  And that can be changed once you've logged in.  And you have to submit the existing password.  And you can then change the password try count based on policy.  So an enterprise could say, you know what, I want the try count to be three, not 10.



STEVE:  Right. 



DAVID:  And I want to enforce a nine-character password with three upper and two lower and a number.



LEO:  That's excellent. 



STEVE:  Nice.



DAVID:  And so we've put that in because there's environments where you want a homogeneous password policy across all devices.  The other thing, just one point I wanted to bring up about the firmware, is we do have the ability for parts of the engine, which implement other kinds of logic, to be upgraded.  And that brings out the question of malicious firmware, can someone put malware onto the device itself.  And we prevent that by digitally signing all firmware updates with a hardware signing module that's securely managed.  And those firmware updates, when they're loaded onto the device, are then verified by hardware with a 2048-bit RSA signature.  So if you try to load malicious firmware, it will not load onto that device.



STEVE:  Nice.  And it's only you guys who have the matching public key at the other end that allows you to securely sign the firmware after verifying that it's what you want to load onto the keys. 



DAVID:  Right.  The public key is actually burned into the silicon and can't be tampered with.  And then the private keys are stored in an HSM that's accessed by two [indiscernible] with two different smartcards.  So you can't get rogue firmware.



STEVE:  Very nice.  We should talk a little bit about the additional services that you guys offer that go along with the key.  I mean, we've in the past covered multifactor authentication a lot.  Is there any provision for the key being sort of a general purpose hardware token for other authentication? 



DAVID:  Absolutely there is.  And that really gets back to why we decided to do a USB device in the first place.  So yes, there's this issue of USB storage, and there's these cool things that are coming along, like portable applications and people putting virtual machines on IronKeys.  But the other thing that we really were cognizant of is that strong authentication, I believe, is an imperative.  I frankly believe that passwords are not enough for most applications.  And that will continue to be proven true over the next 10 years.  And one way to do strong authentication is to have it on a USB token that can be inserted into any computer, that can be removed from that computer, that requires a strong password to get into.  And that's what is also part of the IronKey.



So if you just want to use it as a flash drive, that's great.  You can do that.  It's the world's most secure flash drive, and hopefully people like it a lot.  But there's more to it.  These devices are full crypto engines.  They have full capabilities to do RSA encryption.  They can do SHA-256 hashing.  They have a variety of different crypto algorithms on them implemented in hardware.  They have strong encryption keys on the devices for private and public key operation.  And that allows us to do a lot of really cool things that are actually really easy and seamless to the user, but add a ton of security for two-factor.



STEVE:  And is any of this API published? 



DAVID:  So.  There is a PKCS#11 API that actually is available with every device.  And that is how we make the onboard Firefox talk to the crypto hardware now.  So you could actually taken open applications like Thunderbird or anything else that uses PKCD#11, which is an open API, and you could actually use crypto ops for your own application.



STEVE:  And I did notice that you had the DLL there as part of the files as you were loading.



DAVID:  Exactly.  The other thing that we've done is we are now in a sort of limited beta of a more broad software developer kit.  So that you can actually, as a developer, access more functions and do things like load your own software on the device so that you can create your own custom application container or what have you, using the IronKey devices.



STEVE:  Very nice.



DAVID:  We will be announcing some interesting partnerships in the next couple of weeks around other forms of two-factor authentication that are on the device because it really is designed as a general purpose authentication device to support not just PKI-based authentication, and to support multiple different credentials on the device at the same time.



STEVE:  So there's some provision, then, for user storage, either in the IronKey or protected by the cipher chip.



DAVID:  That's correct.  There are areas where applications can have private encrypted storage areas with their own AES keys and their own access control, yeah.



STEVE:  Very nice.  And we should talk about the other services, like the safe web surfing and privacy and TOR and so forth.



DAVID:  Okay.  One of the cool things about having strong authentication on the device is we can offer real neat web services, and we hope that third parties will over time develop them, as well.  And so you know it's really that device.  So one of the things that's very simple that we offer, it's completely optional for users, is self-service password recovery.  So if you're using a strong password, and you're the forgetful type, you have the option when you fire up the device to register with our online service, and we will store your device password for you on our service.  And if you forget it because let's say you, I don't know, go out and change your password after a couple of beers and forget the next day what you changed it to, or you don't use it very often or what have you, you're a busy doctor and you only use it once every week or two, you can actually come back to the online service, answer a couple of secret question challenges, we send you an email to also confirm your identity, and then we will actually present you with your password so you can unlock your device.  Completely optional, but it leverages the strong authentication of the device so that we know it's not somebody else trying to spoof you and get your password.



STEVE:  I was just going to say, I wanted to make sure that our listeners picked up on the fact that it is only possible to do this if the IronKey in question is physically mounted on the computer at that time.



DAVID:  Yes.  You have to have the IronKey.  We do the challenge response.  You have to log into the device.  You have to answer secret questions.  You have to have possession of the email accounts, as well.  And again, completely optional.  And we're looking at stronger authentication, as well, like potentially we could ask things where you ping the mobile phone for an authentication code.



LEO:  I like that.  I always like that.  So it really is interesting.  So once you have this hardware encryption capability or this hardware random number generator capability, it really is a useful - it's more than just a USB key.



DAVID:  Yeah.  Really it has the potential to become a way to manage your identity, to manage your passwords, and also over time we believe to carry applications around.  So speaking of passwords...



STEVE:  Go ahead.



DAVID:  One of the applications that you have on the device, if you choose to use it, is a password manager which, you know, there's lots of password managers.  You can download freeware, and hopefully you don't download one that's actually malware.  But there are some good real ones out there, as well.  Just check the reputation of what you're downloading.  But, you know, it's a password manager for your Internet passwords.  Couple of things that are different about it, though, are, one, the passwords are not stored in a data file on the USB key that could be copied.  They are stored inside of the USB key in protected memory area, so they're not on the file system.  And, two, we offer the ability to do an online encrypted backup of your password database in case you lose your IronKey.  If you get another IronKey, and you reauthenticate and prove your identity, you can get back and you can recover your password database.  So it starts to be the beginnings of ways to manage identities and passwords beyond just storing a file.



LEO:  Could you use it as, like, the football dongle, Steve, that we've talked about, the PayPal dongle?  I guess you could put software on there that would do the same thing; right?



STEVE:  It's a good question.  We've talked about, David, the SecurID and VeriSign's six-digit LCD one-time password system where you prove that you're in physical possession of the device by pressing a button, and it gives you a sequential six characters that you then enter in, and the server at the other end knows the key in your device and so is able to confirm that you must be in possession of it.



DAVID:  Yeah.  I've got a keychain full of those.



LEO:  Would it be possible to use an IronKey for that kind of thing at some point?



DAVID:  So I hate to do this, but I have to use this moment as a teaser to invite people to come to our booth at the RSA show in San Francisco the second week of April.  We are making no announcements here today.  But yes, this is a general purpose authentication device.



LEO:  That's what I like.  Eliminate all those dongles, yeah.



STEVE:  It's also worth noting, too, that when you use the IronKey, for example, on a foreign machine, and this differentiates, it's one of the thing I noticed, it differentiates it from, for example, TrueCrypt that we've talked about, you do not need admin privileges in order to run the client-side software in order to access the key, which, you know, can really be a good thing.



DAVID:  I cannot tell you how difficult that was to do, by the way.  That was so hard to make that work without installing drivers and software.  Because we're not just, you know, copying files.  We're doing cryptographic operations, control operations.  There's a whole bunch of information going between the device and the control panel software.  To make that work without installing drivers on XP, in non-admin mode, was unbelievable amounts of work.  So difficult to do.



STEVE:  Well, I really think it's worthwhile because, again, on a system you don't control, you may not have admin privileges.  But you do need access to your data.



LEO:  How about Vista?  Were you able to do it on Vista, too?



DAVID:  It works fine on Vista.  We are right now in beta testing of Windows 2000 SP3.



LEO:  You'll like that, Steve.  Steve's the last man still using Windows 2000.



DAVID:  We launched a beta of Linux support this week.



LEO:  Great.



DAVID:  So we'll be doing...



STEVE:  And a Mac, too.



DAVID:  We have basic Mac.  It's not as much as we want.  But once you initialize it on Windows or Linux, you can then unlock it, at least, as a flash drive on Mac.  But we will be adding more fully featured Mac support.  If anybody's a super hot Mac programmer, we're hiring.



LEO:  Yeah, yeah.  Well, that's - and so the capability to do that driver thing, is that a requirement for all the functionality of the IronKey?  I think you said that you don't have to have that for everything.



DAVID:  Which capability?



LEO:  The driver support.



DAVID:  Well, the driverless support is needed because you have to enter your password into the device, and we have to be able to securely communicate that to the device.  And that goes over, obviously, not a data connection over USB.



LEO:  So that's the piece that has to be installed onto XP or...



DAVID:  No, we don't have to install anything.



LEO:  Oh, you don't.



DAVID:  No, it's completely driverless.  That's the magic.



LEO:  I see what you're saying.



DAVID:  Right.  That was, I mean, that was probably six or seven months of work, seven days a week, 15 hours a day by super, super smart people.  It's nonintegral.  And that connection, by the way, is fully encrypted.  The control connection between the software and the device, not for data, but for all the control connections, passwords, crypto, APIs and all that is a fully encrypted CLS-like stream.



LEO:  So do you use the mass storage class driver?



DAVID:  Yeah.



LEO:  You don't sound happy about it.  But that's how you'd see it as a hard drive.  Is that sufficient for you to communicate all this other stuff, too?  Or do you have to do something else?



DAVID:  The theory is no.  The reality is yes.  Magic hand-waving happens here.



LEO:  Interesting.



STEVE:  And then obviously you must also be protecting the machine's client software from any kind of tampering and messing around because it has to be trusted in order to establish the TLS dialogue with the IronKey itself.



DAVID:  Right.  So we do as much as we can.  All that software is locked on a virtual CD-ROM that's digitally signed.  But at the end of the day, to be quite honest, you cannot trust the host computer ever.  You just have to assume the host computer is not trustworthy, and you have to do your best.  But, you know, doing your best includes, yeah, making sure you can't tamper with the software, you're doing PKI operations between the software and the device to establish CLS-like connections, things of that nature.



LEO:  Well, let's assume worst-case scenario somebody's got a host computer that's just, you know, completely owned.  Obviously that means they can see any data before it's copied to the IronKey.  But does it soften the IronKey afterwards?  I mean, when you unplug it?  Now, the IronKey is still secure, yes?



DAVID:  That's correct.  Yeah, and that's because we're doing things like, for example, software updates and firmware updates all have to be digitally signed and are verified in hardware.  So being able to put low-level malware on the device is not really feasible.  I think some of this thing, I mean, we also control the autorun, so malware should not be able to automatically run off it if it's copied onto the device.  I think there's more that can be done, for example putting AV and antispyware scans when you unlock the device.  So we're looking at a bunch of different options in that area.



LEO:  Are you using U3?  How are you - what are you doing the - how are you doing the autorun?



DAVID:  We're not.  U3 was really a sort of a proprietary thing that actually has been sold off to Microsoft.  It ended up in my view being kind of a shareware distribution thing.  I mean, if you look at what was the killer app for it, I never quite figured that out.



LEO:  But it sounds like you're doing something similar because you're mounting a locked CD-ROM image and so forth.



STEVE:  Yeah.  Essentially the IronKey has several profiles.  One is that, when you initially insert it into the machine, it looks like a CD-ROM. David was saying that they have also taken great pains to protect that from being altered in any way.  And then the CD-ROM starts up, and it invokes the client, which then mounts another device which is your encrypted drive.



DAVID:  That's right.  So it comes up with two devices, one a CD-ROM, runs the software.  Then we have to deal with drive mapping issues because you might be in an enterprise environment where you've gone and mapped a F: drive to some network drive, which you're not supposed to do, but people do all the time.  And so you have to then negotiate where you're going to mount that new secure volume.  And that comes up as a removable media.  And once you're authenticated to the device, we mount the media on there.  So there's your, you know, 4GB of writeable storage.  That also protects against certain attacks, for example cloning an offline attacks.  So imagine you've got a software-encrypted flash drive, you could copy the contents off of it and then go and farm it out to a botnet of 10,000 computers and for free go and attack it.  Or just run common attack tools on your laptop.  And the IronKey you can't do that because we don't mount until you've actually successfully logged into the device.



LEO:  Very interesting.  I love the challenge that you faced and the work that you put into solving all these.  It's really great.



STEVE:  And then also you guys have what you call a Secure Sessions service.



DAVID:  That's right.  We basically have, and I think you mentioned it, it's based on TOR technology.  We're big fans of the TOR project.  But basically one of the problems with that system, which is effectively a - it creates encrypted tunnels out to the Internet so that people can't easily spy on your traffic.  But there are a certain number of problems with the experimental, what they call the "experimental network" out there, which is that it's slow.  And you don't know who's actually running the endpoint, so oftentimes you get malicious people running endpoints, injecting malware, injecting code, injecting trackers, redirecting DNS or what have you.



So what we did is we built a private network based on that technology where we establish an encrypted surfing connection from your computer out to our servers.  It's a three-layer encryption model, so we can't actually track your activities and record it because it goes through multiple hops at different datacenters.  We also run the DNS for you.  So you're protected against pharming attacks if let's say you're on a WiFi network and someone's running malicious DNS on there, trying to route you to their server instead of when you typed in PayPal.  They could take you to somewhere else.  So we protect against that by running the DNS queries through our network, as well.  So you're getting privacy.  You're getting accurate DNS information, as well.



STEVE:  It's tremendous.



LEO:  Yeah.  I had no idea.  I thought it was just a USB key with, like, a cool, brushed-metal finish.  I, you know...



DAVID:  The other thing we built into that was an anonymous subscription protocol.  So we can, you know, you're not just going to get everybody piling onto that network.  But again, it's an anonymous cryptographic protocol that was validated by a number of different cryptographers.  So, you know, we know you're allowed to be on it, but we don't know who you are.



LEO:  Wow.  So you're not doing your own TOR thing.  You're still a gateway to TOR.



STEVE:  No, no, no, it's their own network.



LEO:  It's your own TOR.



STEVE:  Yes.



LEO:  Oh, wow.



DAVID:  Yeah.  And then...



LEO:  And you control the exit nodes, so you're really...



DAVID:  We control the - yeah.  So we can control security on the exit nodes.  We know where they are.  And we control the DNS out of them and things like that.  So you can provide a lot of different services on top of that.



LEO:  Wow.  Really neat.  I'm going to have to buy one of these, Steve.



STEVE:  I have three of them now.



LEO:  I know.  Did you break one?  Did you actually see if it self-destructed?



STEVE:  No, no, no.  I don't want to lose it.  It's just too cool.  And we ought to also mention, and the IronKey site talks about this, is that it's deliberately potted solid with an epoxy compound.  So it is extremely hard to get into.  But it's also - it means that if you run over it or back over it with your car or something, it's also uncrushable.  So it's really strong physically, as well.



DAVID:  And a degree of waterproofness as well.  So if you leave it in your pants, and it goes through the wash or what have you, if you dry out the connector, it will work again.  All of the electronic components are sealed.  And it does make it highly tamper resistant.  Meaning, you know, you'd have to get into the device and grind through it and get at the chips.  And your chances of getting at them without destroying them are much more difficult than with any other regular USB-type device.



LEO:  And all this for $79.



DAVID:  Right.



LEO:  Really you could charge twice as much.  That's really amazing.  What's the next...



DAVID:  It's actually a good deal.  I mean...



LEO:  It is a good deal, yeah.



DAVID:  They're not cheap to make, and there's a lot of technology in it.  And there's a lot of thought into it, too.



LEO:  What is the largest capacity?



DAVID:  We're currently shipping 4GB devices.  But we hope to have 8GB devices out by the end of the month.



LEO:  And how much is a 4GB?



DAVID:  $149.



LEO:  See, that's very reasonable, I think.



STEVE:  And Amazon has it for $138 at the moment.



DAVID:  Grrr.  The other thing about these things is one of the reasons that they cost a little bit more than a regular device, other than all the magic we've been talking about tonight, is that these devices use a type of flash memory called SLC Flash.  And most of the really cheap ones you can get use something called MLC.  And MLC is really designed, like, for an iPod or something, where you copy your files on it, and you almost never, ever write them again.  It's almost, you know, it's slow, and it's not very reliable.   Whereas SLC memory is designed for applications like an IronKey, where you're putting critical files on it, you want them to last a long time, and you may be running applications where you're doing a lot of write cycles.  So it's very much faster than MLC memory.  But it also lasts up to 20 times longer.  So you can get 100,000 write cycles out of them.



STEVE:  And I also heard you talking about wear leveling.  So it looks like you did not short the actual technology over on the physical storage side, as well.  I mean, you did everything you need to to make it not only secure, but really reliable.



DAVID:  Right.  So we put - there's hardware wear leveling in it, so that as you write, as data is written to it, it's randomly mapped around to reduce hotspots in the memory to make it last a lot longer.  There's error correction in the NAND Flash, as well.  So there's full error correction on the chip.  So if there's any kind of glitches in the memory we actually detect it and will go move the block and rewrite it correctly.  And then the other thing we do, which actually turns out to be difficult, is implementing AES encryption correctly for large blocks is actually very difficult.  It's called CBC-mode encryption.  And you actually have to store data inside of the NAND Flash away from where your real data is to make sure that the crypto stuff's not actually replayable if you write the same block.  And that's actually really hard to do.



STEVE:  Yeah, cipher block chaining we've talked about on the show, so our listeners know what that is.  But you're right, I hadn't thought about the difficulty of doing that in hardware.



DAVID:  Right, where are you going to go store the initialization vectors?  You've got extra metadata about every block of data.  Every 512 block of data's got extra metadata that's got to be stored somewhere.  And so thinking about where that's going to be mapped is actually a real challenge.



STEVE:  I've always wondered about wear leveling.  What's the mapping page size that is typically used?



DAVID:  There's different page sizes.  And actually I'm not a flash engineer, so that I'm not sure I can accurately answer that.  But 1024-byte pages.  There's small maps, there's large maps, there's sectors, there's...



STEVE:  Right.



DAVID:  Now I'm talking beyond my area of expertise.



LEO:  But it sounds good to me.



DAVID:  [Indiscernible].



STEVE:  Well, I'm very impressed.



LEO:  Yeah.  It's really great to talk to you, Dave.  Thank you so much for taking the time to join us.  I'm not kidding, it sounds like something I want to run out and buy.



DAVID:  IronKey.com.



LEO:  There you go.  We'll give you the plug.



DAVID:  Thanks.  Thanks, guys.  I really appreciate the interview.



LEO:  Sure.



STEVE:  Can you make them smaller?  I wish it were smaller.  That's the only complaint.



LEO:  No, it's cool.  Brushed metal.  It looks like kind of a cool retro cigarette lighter almost.



DAVID:  Yeah.  And we put a lot of work into the physical case.  So let's talk about smaller.  Yes, they can be made smaller.  That is, with everything there are compromises.  So the first one is, it's the thickness that it is, 9mm, because you need to accommodate varying chip heights.  It's a double-sided board.  The way we get a lot of the speed is we're writing parallel channels at the same time.  We actually have two memory chips in there, not one.  Now, if we had one memory chip, it would run half as fast, but we could make it probably 12 or 14mm shorter.  So we could actually make it quite a bit shorter.  But you're going to sacrifice speed because you're taking away one channel of memory.



LEO:  So you've interleaving, you're interleaving the writes?



DAVID:  Yeah.



LEO:  Wow, that's neat.



DAVID:  Yeah, yeah.  There's a whole high-speed DMA engine in there that's parallel.



LEO:  Is that common in a USB key, or is that something you guys...



DAVID:  In high-end ones.



STEVE:  It's the way they get the writing performance up is they're writing in parallel to many chips because each chip has a maximum bandwidth.



LEO:  Yeah, even among USB 2.0 keys there's a dramatic difference in writing.



DAVID: Oh, yeah.  Well, the difference is the single versus dual and the MLC versus SLC.  Your main speed comes from MLC versus SLC.  So you can get an MLC device with a single chip, it'll write 4 Mbps, maybe 3.  And we can write up to 18 to 20 Mbps because it's much faster, more expensive memory, and because it's dual channel.



LEO:  Is the read faster, as well?



DAVID:  Yeah, it's like 30 Mbps or more on the bigger ones.



LEO:  These are faster than the hard drives of a few years ago.  That's what blows me away.  I can't believe it.  That's just great.  Very cool.



STEVE:  And it's got a nice blinky light, too.



LEO:  Ah, well...



DAVID:  It's got a little blinky light.  And it actually - the colors actually mean things.  There's firmware verification at the beginning which is when it changes different colors, lets you know if the correct firmware is in there or not, all of these nondocumented features.  And actually when they're dead there's a little blinky-light session, too, that lets you know they've actually cleanly erased.  And for certain applications where you need to know it's safe to leave it dead, that's helpful.



STEVE:  Oh, that's interesting.  I may have to kill mine, or one of mine, after all, just to watch that other light blink.



DAVID:  Different firmware versions may or may not have it, so I can't guarantee how - I don't know how old yours are.  But that's one of the newer features, the ability on the light to signal that the device is safe to be left.



STEVE:  That's very nice.



DAVID:  That it's completely killed itself, yeah.



LEO:  And now, finally, the unannounced feature that will be unannounced at RSA, will that be an upgrade, or will it require a new IronKey?



DAVID:  So there's been some discussion about that.



LEO:  If you were to add some features...



DAVID:  [Indiscernible].  So we design these devices to be completely field upgradeable to where you can actually download software and firmware updates from us.  So we don't want to require new hardware for that, and we want to make these types of upgrades downloadable.  I will tell you guys that the challenge has been the constant battle between people demanding new features and people wanting these upgrades, and also QA of the upgrades.



LEO:  Well, you also want to lock down the firmware; right?  You don't want to make it too easily upgraded.



DAVID:  Oh, no, yeah, trust me, the firmware is pretty locked down.  But the question, the challenge is that we need to do it, you know, if we make that upgrade happen, and you have a device with a certain version of firmware, but not a different other one, and then you did this thing to it and stored this data here or there, it's going to be so different across the user base that the testing matrix that we have to do is extremely difficult.  And so we're actually kind of working through that right now over the next month or so, you know, getting the process down where we can actually release updates a little more frequently, maybe smaller updates more frequently.  So that's our hope this year is really to get into more of a regular pattern.  And some people would say, well, gee, I can get an update to Firefox every three months or what have you.  And yes, it's true, but that's one piece of software.



STEVE:  And also, for example, in the case of Microsoft, people are getting updates every month whether they want them or not because there are serious security problems that Microsoft is continually fixing.  And it would obviously defeat the whole point if the IronKey were not really, really, really well designed from a security standpoint.



DAVID:  Yeah.  I mean, we're in a lot better position than Microsoft given that we control the hardware.  And we came in it with digitally signed hardware and firmware and software.  So you're right, we're in a much cleaner position.  But then, you know, to their credit they've had 25 years to develop their software update process.  And they can now do it about once every month.  Ours is, you know, we don't quite have 25 years of history under our belts.  And I think the other one is we don't want to do so many updates.



STEVE:  Right.



DAVID:  And we're updating firmware as well as software.  So it's actually far more challenging than might actually appear on the surface.



LEO:  Yeah.  Good, well, we'll look forward to see what we can do new with our IronKeys.



STEVE:  In about a month.



DAVID:  Yup.



LEO:  Dave, it's really been great talking to you.  And now I'm sold.  I tell you, you make an excellent representative.



DAVID:  Thanks a lot.



LEO:  Which is good because it's your company.  So that's good.



DAVID:  Yeah.



LEO:  Yeah.  Dave is the CEO at IronKey, also has a blog you can read on the IronKey site if you want to know more about the IronKey and its uses and so forth.  That's IronKey.com.  And your blog is blog.IronKey.com.  Dave Jevans, thanks so much for joining us.  We really appreciate it.



STEVE:  Thanks, David.



DAVID:  Thanks, I really enjoyed it.



LEO:  Wow.  Okay.  You're a cagey fellow, Steve Gibson.  Because you said, oh, we're going to talk about IronKey.  I didn't realize it was - did all that stuff.  That's really neat.



STEVE:  Well, what I learned during this also, which for me obviously as a developer and with my Perfect Paper Passwords and all that, is that it's a multifactor authentication dongle that is having an open API on its way.  So that becomes very interesting in addition to everything else it can do.



LEO:  Security is very interesting.  I love it.  Well, what's interesting is, unlike a lot of programming, although I guess all programming now has to be security aware, you have an adversary.  So it's a more kind of challenging form of programming where it's, I mean, it's really an intellectual challenge to think this through.



STEVE:  Oh, Leo, yeah, it's like everything - for example, when I was writing our eCommerce system, there's, I mean, everything I did, everything I thought about was Spy vs. Spy.  It was like everything I was doing was, okay, now - or even when I did the Perfect Paper Passwords system, in order to create secure roaming for myself and Greg and Sue, was okay, now, wait a minute, what if, what if, what if.  And so you're constantly challenging yourself with what could someone do to get around this.



LEO:  Man.  I guess all programming nowadays, if it's on the web, is going to have to be aware of that.  Anything...



STEVE:  Oh, and Leo, that is the huge vulnerability.  Every single newsletter that I get from SANS, for example, they talk about the phenomenal number of insecure web apps that have known vulnerabilities in them because people are just rushing these things onto the 'Net.  And security is the last thing they think about rather than the first thing they think about.  Which it really needs to be.  And certainly it's the only thing these guys thought about.



LEO:  Clearly.  Well, this was a fun episode.  I'm just...



STEVE:  I want to just inject one thing.  I just got a big kick out the fact, listening to Dave, who's steeped in security and security technology, all the things he talked about we've covered on Security Now!.



LEO:  Yeah, I know.  You know, it was neat. It was like we've been building up to it.  You could listen to this, if you'd listened to all the previous ones, and understand what he's talking about.



STEVE:  Yeah, I mean, the acronyms, TOR and cipher block chaining and public key and private key and symmetric crypto and, I mean, just it was everything we've done here.  It was just really neat.



LEO:  And it's what impresses me about it is it answers all those questions that you would have.  And it has capabilities that just blow me away.  But I think running their own TOR servers, wow.  I mean, these guys obviously are into this stuff, and they share your sensibilities about the whole thing.



STEVE:  Yup.



LEO:  All right, Steve.  We're going to wrap up.  Next week it's a Q&A segment.



STEVE:  Yes, yes, yes, yes, yes.



LEO:  People should go to...



STEVE:  And then the week after we've got our RAM hacking episode.



LEO:  Oh, we're going to talk about the Freon freezing thing?



STEVE:  The freezing RAM and Firewire backdoors and USB boot dongles for sucking RAM contents out and all kinds of cool stuff.



LEO:  Oh, great.  So we know we've been getting a lot of email about that.  We'll talk about that.  Next week we'll answer many of your questions.  And of course you can go to Security Now!'s website - well, Steve's website - GRC.com to submit a question, to ask a question.  You can also go there to get 16KB versions of this show, the really small ones for people who have dialup.  You can also get transcripts.  A lot of people like to read along, highlight as they go.  All of that at GRC.com/securitynow.  And that's where you can find all of Steve's great freebies, including the new updated Wizmo that automatically turns off that wireless 0 config.  That's a very useful...



STEVE:  The new wanlock command.



LEO:  Wanlock.  Now with wanlock.  I love it.  It's Wizmo, Now With Wanlock.  You can also, of course, get SpinRite there, which is Steve's bread and butter and a great program, a must-have program that is the ultimate file and disk recovery utility.  It's a maintenance utility for your hard drive.  If you've got a spinning disk, you need SpinRite.  GRC.com for that, too.  Steve, we'll see you next week.



STEVE:  Right-o, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#136

DATE:		March 20, 2008

TITLE:		Listener Feedback Q&A #37

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-136.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 136 for March 20, 2008:  Listener Feedback #37.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!.  We're going to talk about security for the next hour or so with Steve Gibson, the man who coined the phrase "spyware."  He is a security wizard.  He's written so many great security programs; taken Microsoft to task for security flaws, chiefly raw sockets in their operating system.  And every week we talk about the latest in security.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you once again.



LEO:  Yeah.  We're going to do a Q&A segment.



STEVE:  It's only been 136 weeks we've been doing this.



LEO:  136.  Well, you know, you're tied with TWiT now.



STEVE:  Cool.



LEO:  So TWiT just has to take a week off, and you pull ahead.



STEVE:  Okay.



LEO:  We're at Episode - I think we just did 136 of This Week in Tech.



STEVE:  Well, you're going to be taking a trip, I think, out of the country here.



LEO:  Oh, you might pull ahead, you're right.  I'm going to Australia.  You're going to pull ahead when I go to Australia because you, unlike those TWiTs, you like to record ahead and make sure that we don't miss a week.



STEVE:  We will not.  And I'm going to say, as I'm reading the feedback that we get from our listeners, which I really so much appreciate, so many of them talk about like this is - I don't want to say it's the high point of their week.  I'm sure they have lives outside...



LEO:  I would hope so.



STEVE:  ...outside of Security Now! and podcasting.  But at least within their podcasting domain they write and talk about how they look forward to Security Now! every week and wondering what's going to happen.  So I loved one, one I read yesterday when I was preparing the Q&A for today.  The guy said, you know, the problem I have with Security Now! - I'm thinking, okay, what's coming?



LEO:  Yeah?



STEVE:  He says, most of the podcasts I listen to are sort of, you know, in the background, jab jab jab jabbing.  He says, and then sometimes something that they say will catch my interest, and I'll back up a little bit and then listen.  He says, I can't have Security Now! running in the background.



LEO:  Oh, good.



STEVE:  Because he says, sometimes I have to listen to it multiple times to get everything that, you know, all of the content.  It's like, well, okay, yeah, good.



LEO:  That's okay with us.  That's what the transcripts are for, too, of course.



STEVE:  Right.



LEO:  They help a lot.



STEVE:  You can read along.



LEO:  Yeah.  Well, Q&A time is coming up, #37.  But before we do that, anything you'd like to recap or cover from the last few weeks?



STEVE:  Two quickies.  First of all, Greg, my tech support guy, asked me to mention on the podcast that GRC has not been infected by viruses or trojans.



LEO:  Well, that's good to know.



STEVE:  Isn't that good to know.  Just a little public relations mention.  Apparently Avast, the AV scanner, has been warning people for the last week that GRC is infected with trojans and spyware.  I don't know if this is the Google Analytics stuff that we talked about or what the cause is.  But they fixed it.  So I wanted to let anybody who's been worried that we got taken over or something, I wanted them to know that an update of their Avast viral signatures no longer reports, misreports a false positive that GRC has been compromised.



LEO:  I think a lot of antiviruses now probably check a website or keep an eye on a website since that seems to be the number one vector for attacks nowadays.



STEVE:  It absolutely is.  And it certainly makes sense for them to do that.  It'd be nice if they weren't false-positiving.



LEO:  Yeah, I mean, you know, it's funny because that's happened for years in applications.  We've never had to deal with it as web people.  But now I guess, yeah, maybe it's seeing the JavaScript for analytics.



STEVE:  Well, and in order to try to be preemptive, increasingly these AV tools are having to be heuristic.  They're having to apply sort of basically sort of rules of thumb instead of finding a specific pattern.  And unfortunately, well, and in fact some of the tools, some of the freeware that I've created has caused false positives because I've had to do things deliberately that were sort of like the insecure thing I was trying to fix or deal with.  And so there was code that I had that was deliberately doing the same thing.  Like a perfect example is that the Windows Metafile problem, we were causing some false positives because I was doing Windows Metafile stuff to test for the vulnerability which other malware could take advantage of.  And so it's sort of the nature of the...



LEO:  Well, that's why they often say don't run multiple antiviruses because of course sometimes the signatures from one will seem to be a virus to the other.



STEVE:  Exactly.  Perfect example.  And the second thing I have under the subject of "I love our listeners."



LEO:  We do.



STEVE:  A listener named Mark Odell sent feedback that I just, I mean, just cracked me up.  His subject was, "This sounds like something" - it says, "It sounds like you could use one of these."  And so he quotes me saying on Episode 134, which is two weeks ago, where I'm talking about going to get my car serviced, and I have a little tiny cute little 4GB thumb drive on my keychain.  And I was talking about how it's a good thing I felt comfortable that I've got it TrueCrypted because I was handing my keys over.  And I was just imagining, in general keys are a problem.  You don't want to give them to your valet if you can avoid it because your car registration is in the glove compartment, they could figure out where you live.  If they wanted to duplicate your key, it's a way in.  And so I was thinking, but still, just how tantalizing a little thumb drive would be for someone.  Anyway, so he...



LEO:  That's a whole new thing nobody's probably thought about.  But if you have a thumb drive or a dongle on your keychain, there's a security problem with handing it over.



STEVE:  Oh, absolutely.



LEO:  I never thought about that.  Very good point.  I have my SanDisk on there.



STEVE:  So, yeah, exactly.  So he quotes me saying this.  And then - and this is what I love - he gives me a link to a Google search for the query "detachable key ring."



LEO:  By the way, that's the new snotty reply email.  You just attach a Google search to the response.  Hey, I got an idea for you, look this up.



STEVE:  What a concept.  Whoever heard of such a thing.  A detachable key ring where I could have two parts, and I could just remove my - actually it would be handy not to have my keys dangling from my laptop when I plug this thing into my computer, too.



LEO:  Good point.



STEVE:  So that's not a bad idea.



LEO:  I want to Google that myself.  I need that, too.



STEVE:  Lord knows how many hits you get.  I didn't even click the link.  But I did get a big kick out of that.



LEO:  That's a very funny response.  That's great.



STEVE:  So I appreciate that, Mark, and I just wanted to let you know.



LEO:  Good.  Very good.  Anything else before we get to our...



STEVE:  Well, I do have a SpinRite story that was so well written, and pretty funny, actually.  This is from an owner, Westcott Hyde.  Okay.  He says, "Hey, Steve and Leo, sorry this is long, but you have to read this!  First, thanks.  I just had to let you know I finally caught up to you.  That is, it took six months and a day, and I have finally heard all the Security Now! episodes, some of them six or seven times, including last week's IronKey.  Whew, I did it.  Where is my Security Now! degree?"



LEO:  Yeah, you need a button or something.  "I Survived Security Now!."



STEVE:  He says, "Now for SpinRite, a quick tale.  I heard you mention a record for SpinRite being a three-month recovery.  But the record's anecdote was missing [SN-102].  Here is mine, since I have a similar record.  An IT buddy came to me, asking if I knew anything about recovering hard drives.  I had already purchased a copy of SpinRite sometime before this request, which meant I knew a little more than he did, I suppose, but not much.  I had purchased it using the 'just in case I need it' rationale."



LEO:  Fair enough.



STEVE:  "And to support the Gibson team."



LEO:  Thank you.



STEVE:  "Well, I hesitated accepting this mission knowing that this is a breach of etiquette, since SpinRite was purchased for me, by me.  But I acquiesced and told him I would help him out if he could convince his company in the meantime to buy a copy of SpinRite in the spirit of good intentions, not knowing it would take so long to achieve results.  Read on.



"Long and short of it, this drive had extremely valuable CRM, customer relations data, that was running on a platform that was running on VMware, and the files were buried in VMware's structure.  Not an easy prospect.  No backup snapshot, or other backup of any kind, for that matter.  SpinRite gave the Red Screen Of Death warning notice that the drive was about to imminently fail and to recover data before running SpinRite."



That's actually something that SpinRite does.  It does an initial check of the SMART subsystem.  And if SMART is already saying, oh, you know, this is about to die, SpinRite will bring up a red screen and say, okay, now, look.  We'll go with this for you.  But the drive is already saying it's about belly-up.  So maybe you should pull off whatever you can before going for hopefully complete recovery with SpinRite because SpinRite has been known to kill a drive.  If it's already right on the edge, SpinRite just in doing its data recovery, just regular reads and writes to the drive, can push it over the line.



LEO:  Just the activity.



STEVE:  And SpinRite is constantly checking the SMART data and will stop if the drive says, oh, wait a minute, I don't know how much more time I've got here.  So anyway, but apparently, due to the fact that this was in a system buried in a file system buried in a VMware image that was virtually unrecoverable, there's nothing they could do, and they had to have this data.  So he says:



"Well, the drive, even though it was surge protected until the cows came home, was a victim of a lightning strike near the building, or so I was told."



LEO:  Wow.



STEVE:  Struck by lightning.  "So I figured, what the heck, it is beyond the RSOD anyway.  Let's see what we can get.  I only needed the precious CRM data.  So a couple of days go  by with SpinRite running.  I check.  No, it won't boot, and no file structure can yet be seen on another Linux Fedora box by simply mounting the original Fedora Core 6 drive.   SpinRite keeps going and going and going like the Energizer bunny, with 'unrecovered red sector' after 'unrecovered red sector' error.  The first six weeks go by.  Now...."



LEO:  I can't believe he just leaves it running.  This is what cracks me up.



STEVE:  "Now I could see the file structure, but could still not get any data.  SpinRite wasn't done, however.  I was just impatient to get the data.  Three months later the drive is still spinning.  It is simply hopeless, I thought.  But there was no failure of the actuator or the drive spindle.  It never overheated, and SpinRite was still cranking away.  By this time I had learned to tune out the drone of the drive spinning in the background as just something my subconscious learned to accept, and not as a reminder to me that valuable data was actively being recovered.  I really thought that the software (which I had never had the occasion to use before) was just hype.



"Hah.  After multiple intermittent weekly checks, three-plus months into the process, I gave it one last whirl to see if I could perhaps retrieve some data.  (SpinRite still hadn't completed, but I needed to give my power bill a break.  Enough was enough.)  Avast, not SpinRite hype, but reality.  Bingo.  The entire file structure not only finally appeared, but a fraction of the files were now fully accessible.  The CRM data was there and valid.  It was quickly backed up, pressed and plattered on a CD-ROM and on other more reliable retrievable media.  Lightning plus good drive gone bad plus SpinRite plus time equals a good deed done for the year.  What a cool project.  Thanks."



Then he says, "The IT guy who solicited me has since left the company, a folly of the timeframe, I suppose.  But please know that I give SpinRite a sales pitch even when talking about things like Kool-Aid or Starbucks, to try to make up for the grief I carry knowing I used it on someone else's drive.  However, I know it has resulted in an extra couple of sales for you just telling the story, and to my other IT friends.  Again, thanks for SpinRite.  Thanks for my Gibson degree in security.  And thanks for your dedication to producing the show."



LEO:  That's pretty amazing.  So how long did it run?



STEVE:  Three-plus months, he says.  It sounds like about maybe three to four months.



LEO:  So it's okay to stop it periodically and see what it's done and then continue it on?



STEVE:  Oh, absolutely, yeah.  You stop it, it gives you a percentage completion accurate to four degrees or four decimal digits' worth, so that you're able to resume at that point.  It used to be in the old days we would write what I call the little fingerprint file on the root of the drive.  But since we're now able to run on unknown drives in unknown file systems, and since I'm unwilling to write in that first unused track of the drive - we know what happens when you do that, you mess up the...



LEO:  No, you shouldn't write to the drive at all.



STEVE:  No, we do no writing to the drive at all.  But so I give you a where we were accurate to four decimal points so that you're able to go back and resume SpinRite from that point.  So, yeah, so you can stop it and see if it gets better.  I don't know if you know that Dvorak is currently running SpinRite.



LEO:  No, I didn't know that.



STEVE:  We got a whole bunch of information from people saying that he was complaining in some venue of his about the family's main machine had gone down.  And when I finally got myself back into email - remember that I crashed my Windows 2000 box last Thursday.  So it was over the weekend, I think it was Sunday that I finally got email up and going again, and I found John had tried to contact me through every channel known.  People...



LEO:  He didn't go through me.  I could have reached you right away.



STEVE:  Anyway, so he said, hey, can you hook me up with a copy of SpinRite?  I want to see if my family's main gaming machine can be brought back to life.  I said yeah, of course.  So it'll be interesting to see what kind of success he finds.



LEO:  Yeah.  It just depends.  I have a RAID array, in fact we're recording on it right now, that when I boot up, it says errors found in the second disk in the array.  It still seems to work.  So I ran SpinRite on it, and there was nothing wrong with it according to SpinRite.  So I don't know what that means at this point.  And it's still working.  So of course I record three different versions of the show, so it's not like we're running a great risk.  But I think probably I should rebuild the array, I think.



STEVE:  Sounds like maybe there's - oftentimes some technology in the RAID controllers, where they'll go through and do some sort of scrub of the array, typically at the expense of your data.  It's not a nondestructive process, which SpinRite is.  But still it's probably something that is worth - or Leo, just get rid of the drive.  Swap...



LEO:  They're cheap enough, huh.  I probably could, yeah.  Okay.  I have 12 fantastic questions for you.  Are you ready?



STEVE:  From our fantastic listeners.



LEO:  Absolutely.  Starting with Postdiction in Chicago.  He's losing his memory.  Uh-oh.  Hi, Steve and Leo, love the show, try to listen every week.  Recently an older laptop, a P3850 with 384MB of RAM - oh, that is older - had some memory die, and now I'm down to 128MB of RAM.  He says he was running XP on the machine.  I don't even know how he did it with 384.  But of course it runs too slowly now with 128.  He says:  I tried dual booting with Windows 2000.  Windows 2000 runs great.  I was wondering if Steve could briefly go through how he sets up and locks down Windows 2000 on his laptop so I could feel secure taking this machine into the wild.  That's kind of a problem because it's no longer being supported by Microsoft; right, Steve?



STEVE:  Well, yes.  First I wanted to clarify that all my laptops, being newer, are now using XP.  And I'm comfortable...



LEO:  Newer, not new.  Are you running Vista anywhere yet?



STEVE:  No.  No.



LEO:  Of course not.



STEVE:  I think I've got it in some VM somewhere.  It's like - oh, no, I do have it on one machine.  It's like I installed it, it's like, oh, okay.  You know, and if I ever - I ought to, like, check my software on it.  And I guess at some point I'll need to be doing screenshots for the website.  It's like, okay, this is what this thing looks like because people are - are we over 50 percent adoption?  What percentage of...



LEO:  They sold 100 million copies - I'm sorry, 150 million copies last year, in 2007.  But that's only half of all of new machines sold.  So...



STEVE:  And you can't give them back.  So...



LEO:  I think it's well less than half.  But I actually haven't seen statistics.  That's a good question.  But we  haven't gone all the way there.  Now, what's your primary OS?  Is it still Windows 2000, or is it XP now?



STEVE:  No, no, it's XP now.  In fact, as I mentioned, I did something dumb last week on Thursday.  I killed my Windows 2000 server workstation that I've been using probably for about a decade.  I was having problems with the IIS web server in it, which I use for testing all my stuff before I put it up on the public server.  And I uninstalled it and reinstalled it, under Microsoft's online advice, and it just brought the house down.  It was just, oh, goodness.  Now, I didn't lose any data.  Everything's backed up.  I've got my registry and all that.  And I've been, you know, I've talked about my quad core monster machine that I've been sort of wanting to get set up, but who wants to take the time?  There's always something more important I have to do.



So anyway, this finally - that was the straw that broke the camel's back.  And now I'm sitting in front of a barely configured new Windows XP system that I'm excited about.  I mean, I'm sure a couple weeks from now, once I've got everything back in and my development environment set up and tuned and customized, I'll be really happy.  I did, I mean, I'm taking it slowly because I want to really nail, you know, just like bolt this thing down in terms of just how it's running.  For example, I've got every unnecessary process stopped so that when it boots it uses 131MB of RAM.  So which is very lightweight for Windows XP.  So most times you'll see, like, maybe 3, 400MB in use.  This is 131.  So...



LEO:  That's kind of impressive.



STEVE:  So anyway, I wanted to respond to this listener, Postdiction, to mention that I'm not using 2K on a laptop, so I'm using XP.  What makes me comfortable with XP is its built-in firewall.  Win2K does not have one.  And that is the one thing you absolutely want to add to any machine, a portable machine that you're going to take around and plug into things.  You absolutely can't have it exposed without some sort of inbound blocking capability.  From my standpoint, outbound blocking that allows you to manage individual apps, that's much less important.  What's critical is inbound blocking.



Now, one thing you could do would be to take one of these little tiny mini travel routers and always run the Win2K machine behind the little travel router, which is going to get - as we know, routers make really good hardware firewalls.  So that would provide you with good protection.  But that's probably unnecessary.  I would say just choose any well-regarded current personal firewall, put it in there, and make sure it's running.  And that's really the only thing you have to do to protect yourself when you're out roaming around is just make sure you're not allowing unsolicited incoming traffic.



LEO:  How do you address the issue of no patches?



STEVE:  Oh, you mean like in the future?



LEO:  Well, they're not patching Windows 2000; right?



STEVE:  Oh, no, they have been.  I've been getting updates till last Thursday.



LEO:  I thought they stopped.



STEVE:  No, I think they had to extend it.  Or I think maybe it's not - maybe it's what, is it security, or I guess I should know this.



LEO:  Security only, I'm sure.



STEVE:  I haven't worried about it because I've been getting patches constantly.  Every time I do Windows Update it says, oh, here's some new stuff for you.  So it's like, okay, fine.



LEO:  So as long as it's being patched.  Now, when they do end-of-life it - I could have sworn they'd done that already.  But when they stop patching it, then is it too dangerous to use?



STEVE:  One of the things that happens is you begin - the target of opportunity begins maturing and moving.  I've got people running on Windows 98 ME that have never, I mean, these are not computer-savvy people.  They only need to do email and browse the web.  They've never gotten infected because all of the new exploits are against the new technology.  They're against XP and Vista.  Nothing, I mean, it's sort of like your genetics are no longer compatible.  So nothing infects Windows 98 anymore.  No one's doing things to infect that old funky platform.  So it's become safe.  It's sort of like a Mac or Linux.  It's just no longer a big target, even though it is technically Windows.



LEO:  I'm looking at the Microsoft site.  They say they will continue to offer security updates through the life of Windows 2000, which means through 2010.  So I think they do a 10-year life cycle on all their OSes.  Okay, so you've got another year or two.



STEVE:  It's going to be really interesting to see what happens with XP because apparently they've had to agree to extend XP's life or something or other.



LEO:  Well, here's the deal.  They were going to...



STEVE:  It just won't die.



LEO:  Yeah, they were going to stop selling it at the beginning of the year.  And so many protests that they now say June 30 they'll stop selling it.  But support goes on for a while.



STEVE:  Okay.



LEO:  You know, typically they say what they call mainstream support for five years, extended support for five years after that.  And then security updates go on for the entire 10-year...



STEVE:  And if they would just make it right, they wouldn't have - this wouldn't be such a problem.



LEO:  Well, yeah, but there's always going to be holes; right?  I mean, even if it's perfect...



STEVE:  Well, and notice also, Leo, I mean, the fact that we're having this discussion demonstrates that the reality of an unsupported OS moves people forward.  Microsoft is desperate to get everyone over to Vista.  I mean, I don't blame them.  It's a pain to, like, be supporting three OSes - 2000, XP, and Vista in all the different flavors.  They don't want to be doing that.  So they really, I mean, not only economically, but just in terms of the burden for them, they really want people to get off of Windows 2000, at least get up to XP.



LEO:  There's still people running NT4 out there, and it isn't getting patched.



STEVE:  Yeah, and it works.



LEO:  It works, and I understand why those people don't want to upgrade.  They say, look, it's doing what it needs to do.  But it's not being patched, so I don't, you know - and if I'm a hacker, I figure, hey, what better machine than a machine that is completely neglected to the point that it's still running NT4.



STEVE:  Well, yeah.  Now, okay.  If, for example - I would guess that those NT4 boxes are servers.  They're NT4 servers.  I don't imagine anyone's walking around with NT on a laptop.



LEO:  Oh, no, I'm sure they aren't, yeah.



STEVE:  And so in a server environment it's - there were some horrible problems with NT's IIS in the beginning, all kinds of URL exploits.  So I imagine that those have been nailed down.  And now it's probably bulletproof unless they add something to it that causes a problem.  But again, it's stable and bulletproof.  At some point it's like, hey, if it's not broke, don't fix it.



LEO:  After 10 years you'd figure everything that's got to be found is found. 



STEVE:  Yeah.



LEO:  TJ Schroemer in Houston, Texas wants to know a little bit more about the security of web forms.  He says:  When I type HTTPS: for, let's say, Discover or DiscoverCard.com, it always ends up back to HTTP:, no "S."  The web desk tells me when I click the login button it changes to a secure connection and then transfers my login information safely.  Is that right, or are they blowing smoke up my cautious risk management?  Is my login information safe if it's loaded into an unsecured page?  Is it supposedly changed to secure when I press login?  I think we talked about this once before, as a matter of fact, because I was concerned, too.



STEVE:  Right.  We have talked about it.  And it does come up from time to time, so I just sort of wanted to revisit the question.  First of all, I would blame the web designers for the fact that this is causing confusion.



LEO:  A lot of pages do this.



STEVE:  Yes.  The idea is that the way a web form works is, because the web was originally designed as a query system, that is, you had a web browser which browsed, and you had servers which served.  The browsers were not supposed to be sending data back in the other direction.  It was supposed to be - it was like sort of a passive, document-reading model.  So in order to sort of shoehorn information flow in the other direction, they created a kludge which is they took this query-based model where the site is asking for things, and they added the information you want to send back to the query.  So you're essentially - what it is you're asking is actually what you're sending.  The data that you're sending is part of your question.  And the way it's formatted, the server goes, oh, look at this wacky question.  Oh, wait a minute.  Here's the question part.  And then tacked on the end is all this other stuff which is technically not part of the question, it's a submission to the server.



So what that means is that a connection is being made to the server which is first secured - remember, that's how SSL, Secure Sockets Layer, works.  That is the HTTPS, the "S" stands for SSL or for Secure.  It creates the connection, establishes through some handshaking, which is well designed, an absolutely secure tunnel using an ephemeral key that will not be used for longer than that connection.  So it's very secure.  And then over that connection goes the query that contains the form data.  So it is safe, is what that means.  The troublesome thing is that there's no way without viewing the page source and finding the button and finding the URL that is this query, for the typical user, the armchair surfer who's been listening to Security Now!, to figure out whether this button is going to send the data over a secure connection.  And I don't know if you've looked, Leo, but it used to be feasible to do a view source of typical web pages.  Now they are so gunked up with junk, I mean, it's really hard to figure out what's going on by viewing the source of a page.



LEO:  Well, there really is a flaw here.  None of this was intended to be human readable.  Nobody, Tim Berners-Lee didn't expect you would be seeing HTTP://.  What's too bad is that the browsers which do have this supposedly human-readable lock-and-key thing aren't able to tell either.



STEVE:  Right.  Now, I started off by saying that I really blame the web designer.  A properly designed site where you are submitting data, the page with the form would come up secure.  Even though it doesn't need to be.  I mean, the point is...



LEO:  Just do it a little earlier, just to reassure people.



STEVE:  Yes, exactly.  Switch to an SSL connection on that page, so then you get the happy little green coloration, if you've got extended certification and IE7 or a browser that supports that, to give everybody a nice warm fuzzy feeling that says, oh, good, look, this is all secure.  Now, the good news is, I know that IE, and frankly I'm not sure of other browsers, but I wouldn't be surprised - you probably do know, Leo.  IE has an option that allows you to tell IE whether you're allowing it to submit unsecured form data.  So IE can be set to alert you when you press the button if that's not - if it would not be a secure connection at the time of sending.  Because the other thing that could happen is, if this page were really poorly designed, you could have a secure form display, but the button that submits the data could be insecure.  And you wouldn't know that, either.



LEO:  I think all browsers have that.  Unfortunately what happens is the first time you submit information that's not encrypted, you get a little warning box saying you're doing that, and then a checkbox that says it's an opt-in checkbox.  It says, if you'd like me to warn you about this in future, check this box.  But the default behavior is not to.



STEVE:  Ugh.



LEO:  So I would go, and you can do this I know in Firefox certainly, you can go into the security settings and, under the warnings messages, make sure you check the box that says "Warn me when I submit information that's not encrypted."  Now, you're going to see that all the time.  That's the problem.  You're going to see it in a lot of pages where you're submitting form information.  But at least you'll have a warning if you're trying to do something on a page where you've giving something you'd want to protect.



STEVE:  Right.



LEO:  I think that's why they default to off, is you would see this all the time.



STEVE:  Right.



LEO:  Anytime you submit a form.  Because most of the time it is insecure and doesn't need to be secure.  It's only when you're logging in it's not.



STEVE:  Just not very well designed, all of this stuff.



LEO:  You know, this was all designed before security was an issue.  And we're still stuck with a lot of this legacy.  Jeffrey in Columbia, Maryland is weighing TrueCrypt versus IronKey.  I think we've confused everybody by talking about three, actually, really good technologies:  CompuSec, TrueCrypt, and then IronKey, almost in a row.  Steve, after Episode 135 I've been fighting with myself over what I should use now.  TrueCrypt and a USB key, or IronKey?  To me, as an everyday computer user who's security minded, they both suffer from the same problem.  They're both worthless in a sense if your client computer's already been compromised.  We did talk about that.



And is TrueCrypt really that much "less secure" because it's software based, and someone can attempt brute-force password crack on it?  Please correct me if I'm wrong, but can't you also use TrueCrypt's keyfiles as part of your key ring material to make up for this?  To my way of thinking, you still can't beat TrueCrypt.  It's free.  Personally I don't want to trust another company as far as their servers and such for the storing of my password, regardless of how secure they claim to be or how much they say they can be trusted as being on your side and in your best interest.  That's the point I always make about open source versus closed source.  In my opinion, this is one of those Trust No One situations you talk about.



Finally, regardless of the situation, it would take a state-sponsored enemy to even attempt - like the NSA - to even attempt to break either of these items to begin with.  So what really is the scare in the end to the everyday user?  Just curious.  Look forward to your thoughts.



These are great.  This is the kind of thing actually I'd like to ask you, Steve.  I think Jeffrey's right on there.



STEVE:  Okay.  If price is not an object, and if IronKey were as tiny and cute as the little Kingston 4GB thumb drive I have on my keychain, I would use IronKey.  I think.  But it's huge.  I mean, I'm not having that monster thing on my key chain.  Many users asked about IronKey.  We completely covered it last week.  I'm really glad we had Dave on.  I think it was a tremendous - and actually I got a lot of nice feedback compliments about how much they liked the idea of us having guest people on, and Dave in particular, which I thought was neat.  I agree, it was really fun to have him.  But I'm using TrueCrypt on my little 4GB dongle, which my car mechanics are free to do anything with that they want.  I mean, that's my choice.



So I guess it's - is it the case that TrueCrypt is safe enough?  Absolutely.  I mean, do you need a hardware encryption on the device?  No.  In fact, even USB dongles can be used as third-party, I mean as multifactor authentication.  So you could do two-factor authentication.  So, I mean, there are ways to do this without the IronKey solution.  I think for the really high-end, extreme secure, maybe corporate user or something, maybe IronKey makes sense.  But I've got to say TrueCrypt is what I use.



Now, the one interesting danger about TrueCrypt which IronKey doesn't have is that you can pull - a bad guy, say that my, you know, the car mechanic, I turned my keys over to him, and I didn't have the little key release gizmo that has been suggested, he could copy the encrypted partition, that is just a file, from my system to his, and give me back my keys and my car, and away I drive.  Well, now he's got my encrypted file forever.  He can have it as long as he wants.  There's no way that TrueCrypt prevents him from copying it off.  There was the comment made about keyfiles, that is, Jeffrey mentioned that with TrueCrypt you're able to use a file in addition to your passphrase.  But again, copy the entire, the contents of the entire 4GB, and you'll have whatever keyfiles it might have been using, too.



So, you know, it makes me a little uncomfortable that he could have this encrypted blob on his machine to do with whatever he wants.  Certainly IronKey absolutely prevents that.  You're not able to get past it in order to get to your data without authenticating yourself.  TrueCrypt does allow you to pull the data off and then use state-sponsored enemies to attack it.  But again, TrueCrypt is, I think, just every bit as safe as anyone needs.



LEO:  Okay.  Excellent answer.



STEVE:  And it is free.



LEO:  Yeah, it has that advantage.



STEVE:  And you can put it on cute little thumb drives.



LEO:  Which I do.



STEVE:  And the thumb drives cost, you know, 20 bucks instead of...



LEO:  I have a Corsair.  I buy Corsair 16GB drives because we still use sneakernet here in the office, and it's great for transferring files to Dane so he can edit them.  And it comes with TrueCrypt on it, TrueCrypt 4, but at least it comes with TrueCrypt on it.  I think that's kind of a neat thing that Corsair is doing.  They're just kind of bundling it along, just to - I guess in some way just letting people know you could do this.



Tyler, playing with coLinux, which I'm not familiar with, somewhere in Arizona, writes:  Steve, I've found something relatively new I think might pique the interest of a low-level hacker like you, especially considering your interest in virtualization.  You mentioned earlier about running Linux BSD in a VM under Windows to act as a firewall.  I've tried all the VM emulators on the market, and I've always been disappointed.  They all feel heavy in one way or another, either performance or size, impact on the host system.  I've just always felt like technology had a long way to go yet.



Then along comes Cooperative Linus, or coLinux for short.  This isn't a better VM implementation, just a whole new approach.  With coLinux, both kernels run in ring zero.  The two kernels are modified via driver to run as coroutines of each other.  Neither is absolutely in charge.  In the interest of sanity, the Linux kernel only sees hardware through a virtualization layer.  Otherwise if you put in a USB key, which OS would take it.  But other than that, the systems run as normal.  It's called virtualization because that's what it's most similar to, but nothing is actually being virtualized.  Both OSes are running on bare metal.  This creates a significant advantage.  There's literally no perceptible overhead.



It doesn't use any processor time or memory that's not directly accounted for by some application on the guest system.  Not only does the guest OS run at 100 percent normal speed, there's no additional cost to the host system, either.  There's no VM engine, so all the memory and CPU cost of the guest OS is accounted for by the guest's applications.  With Fedora under coLinux running in the background, I could still even play high-end games with no slowdown whatsoever.  Try that with VMware.  CoLinux can even be run as a Windows service, making it easier to use as a personal Linux firewall.



The downside - oh, well, I knew there would be one - is security and stability.  Oh, well, great, okay.  There's no separation between the two operating systems, so a kernel-level exploit under Linux could jump the gap and compromise Windows.  Similarly, a kernel panic under Linux might cause a blue screen under Windows.  Also coLinux is very much still in development.  The whole architecture is still being built and rebuilt as they work toward an optimal solution.  However, it already beats the pants off everything else out there.  I've finally found a VM environment I can literally live with as part of my day-to-day computer usage is concerned.  I highly recommend you have a look at it.



STEVE:  Well, this is a very, very interesting approach.  I wanted to mention it because I feel the same way that Tyler does about sort of like the persistent use of a VM.  As we've talked about, you need to commit a chunk of your host system memory to a VM.  That's the thing that gets used up first.  It's one reason even to have a swap file, even if you've got, for example, 3 or 4GB of memory, a swap file will allow multiple VMs to swap out to disk because VMs are very memory hungry and resource intensive.



What the coLinux guys have done I think is really interesting.  It's the reason I wanted to bring this to the attention of our listeners is, despite the fact that you lose some of this notion of isolation, increasingly our listeners are using multiple OSes.  That is, they may be Windows people, but they want to play with Linux; or they're Linux people who want to have Windows around, but not in the way.  Essentially, this allows the Linux kernel to run as a device driver, as a service, essentially, in Windows, and not be in the way.  It's able to give and take memory to and from Windows as it needs it so that if you run a Linux app, the Linux app runs in Windows memory rather than in, like, a separate sequestered VMware or virtual machine of some kind memory.



So, I mean, it's really practical from the standpoint of wouldn't it be nice to be able to have Linux around if your main platform was Windows, but you wanted to have access to Linux stuff.  So it's an interesting approach.  If you just put coLinux - c-o-l-i-n-u-x - into Google, it'll take you right to their site.  And it is new.  It took about a month for them to bring it up the first time.  So it's an interesting sort of lightweight approach to two OSes running side by side in the same box.  And I'll absolutely bet that our listeners will find some use for it.



LEO:  It's an, yeah, it's a really interesting idea.  But you wouldn't do it for security, which is why a lot of people are doing this.



STEVE:  Yeah, well, I would say it's one of the - maybe it's half the reason people are doing it.  I mean, security is one thing.  But often there are times where you just want to have a different OS around, for any of a number of reasons.



LEO:  Well, actually that's true.  When I run VMware or Parallels on my Mac, it's just so I can run Windows.  It's not so I can be secure, obviously.



STEVE:  Exactly.



LEO:  Tim Bousky, listening from Singapore, was wondering about relocated sectors:  Hi, Steve.  In Episode 134 you briefly described how modern hard drives will automatically relocate sectors that are deemed bad while retaining the original sector number.  If that occurs with any frequency, won't it tend to erode the benefit of utilities like Perfect Disk and other defrag utilities, since sequentially numbered sectors won't necessarily be located sequentially on the hard drive?  Love the podcast.  Happy SpinRite user, devoted Security Now! listener, Tim.



STEVE:  Well, Tim is technically correct.  Although the relocation strategies of drives differ.  One of the interesting things many drives will do is they'll have pools of spares scattered around the drive, like some of them have them at the end of every cylinder of the drive, although cylinders now have sort of lost their meaning because drives are regarded as a linear array of sectors as opposed to cylinder-headed sector, the old 3D approach of accessing a given sector, sort of by its coordinates physically on the disk.  But what drives will do is they will slide sectors down so that if a given bad sector is found somewhere, what happens is, given that its data can be recovered, which is what the drive requires - of course using SpinRite gives you much more power over that process.  But given that the sector can be recovered, it will be - essentially at the end of this run of sectors, however long it is, whether it's a track or a cylinder or some arbitrary span, at the end of a run of sectors is the empty sector pool.  The drive literally slides all the sectors down by one, reducing the size of the pool by one, and essentially keeping them linear, but skipping over the bad one.



So if you imagine like a hundred sectors, and the tenth one is bad, well, what happens is those - I'm trying to get my math right - the 89 sectors following the tenth one, they're slid down, all of them are slid down by one, thus encroaching into the spare buffer at the end of that run, and essentially keeping them all linear.  So the drive's performance is impacted only marginally in that it has to just sort of ignore one sector.  And then it keeps on going in a linear fashion.  So it's very cool.



LEO:  I think this is the part where people rewind a couple of times to understand.  Okay.  Sure, I'll let you do that, folks.  And we'll stay here until you come back.  Number six, Shawn White in Osaka, Japan doesn't want to write too often.  It's okay, Shawn, really.  Dear Steve, during last week's interview with IronKey's Dave - great episode by the way - he briefly touched on the types of flash memory.  He talked - he did.  It was, I thought, very interesting.  I'd never heard this, SLC and MLC.  Talking about keeping data safe when using portable applications, say for instance the PortableApps.com suite, where our users - our university - uses Firefox, OpenOffice, Audacity, GIMP, NVU, have you any idea how you would estimate the number of write cycles that a flash drive would be subjected to?  As we move more and more towards portable computing or cloud computing, will MLC really be enough?  Should we be in SLC?  Thanks for much for the greatest source of tech info on the 'Net.



So I gather where Shawn's going to school in Osaka they're using a thumb drive and just moving around from computer to computer with all of their stuff on it - OpenOffice and Firefox and all of their programs that they use.  And he wants to understand how the number of write cycles will impact that and whether SLC is better or MLC is better than - or SLC is better than MLC for that.



STEVE:  Let's do a little bit of de-acronymizing here.



LEO:  Yes, please, yeah.



STEVE:  SLC stands for Single Level Cell.  MLC stands for Multi Level Cell.  And MLC technology was developed, that is, multilevel cell technology was developed to increase the density of data that can be stored in this flash ROM or RAM or PROM or e, you know, lord knows what you want to call it.  But what's very cool about multilevel cell, that is, MLC, is it stores two bits per cell.  The way it does it is by storing essentially four voltage levels in the cell.  You have all off.  Then you have one quarter, two quarters - well, I mean, sorry.  All off, one third, two thirds, and three thirds.  So you literally - we're all used to thinking in terms of binary.  But these are, what is that, the quaternary technology, where they realized, wait a minute, we've got enough resolution in our ability to write and read that we don't have to just store ones and zeroes.  We can actually store a zero, a one, two, or three.  And that gives you two bits of data.



So that MCL stands for multilevel cell.  There are a couple problems with MLC, which our listener apparently understands because he was sort of talking about SLC versus MLC.  First of all, MLC has about a factor of 10 fewer write cycles that it's able to handle.  It can do 10,000 writes before it begins to have problems.  Whereas SLC, single level cell technology, can do 100,000.  And that's primarily just due to the fact that you're only storing a zero or a one.  And so as the cell's ability to store degrades, it's easier to tell the zeroes and the ones because they're, like, absolute; whereas with multilevel technology you're storing a zero, one, two, or three.   That is, four different voltage levels, essentially, or charge levels, in each cell.  And so as that begins to degrade, you could start having problems.  So the multilevel cells have about one-tenth the write cycles.  They do have a higher error rate.  Although all of these technologies use ECC, Error Correction Code, in order to essentially ignore and deal with those kinds of bit errors.



Now, all of this, any high-end memory, as Dave was talking about, and IronKey is one of these, will use what's called "wear leveling."  Because of the sensitivity to the number of write cycles, when you are writing to a given area, there's a sort of a mapping layer that is between you and the actual physical ROM.  So that when you're writing to it, you're actually writing to a different zone of the memory, even if logically you're writing to the same spot.  For example, in a hard drive, when you write to a given sector you're actually writing to that sector, except in the case we talked about before where there may have been some sparing going on, where a sector was swapped out.  But in the general case you're physically writing, given that all other things are okay, to the same location over and over and over and over and over.



Not so with our solid-stage memory, our non-volatile, solid-state flash memory.  In that case, with wear leveling, they're deliberately sort of spreading the writes out across the physical surface.  The bottom line is, if you have an SLC technology that's good for 100,000 writes, and you imagine, I mean, you're literally able to calculate how much you're writing compared to how large the memory is and how long it would take for you to write the entire thing 100,000 times.  So if you take a 4GB memory, which is high quality, so that it's got wear leveling built in, and you multiply that 4GB by 100,000 - so let's see, by 1,000, 4GB becomes 4TB.  And by 100, so that becomes 400TB.  That is to say, you can write 400TB of data into that 4GB memory before you reach a wear-leveled 100,000 writes per region.  So then compute how much data you're writing.  I mean, the fact is, I mean, it makes people a little jittery to think, you know, wait a minute, I could burn this out, I could wear this out?  Well, yes.  But when you really do the math, it'll take 400TB of data written to it before you reach that point.  So most use is far, far less than that.



LEO:  Certainly on a thumb drive.  Although when you start talking about SSD hard drives, then you start maybe coming up against that.



STEVE:  Oh, and yes, you don't want to, for example, have very little main memory and use SSD as your swap file, as we found out from, you know, in the early experiments that Mark Thompson did, you know, those can get burned out pretty quickly.



LEO:  Yeah, yeah.  So that's a great question, Shawn.  I'm glad you asked that.  Jim Phelan is also backing up his TrueCrypt volumes.  He's doing it with Jungle Disk, and we talked about the issue with timestamping a couple of episodes ago.  Steve, thanks for the errata tip about the TrueCrypt switch, a little switch in the program that forces the software to update the timestamp on a TrueCrypt container.  I was also having trouble getting Jungle Disk to back up my encrypted files.  After hearing your tip on Security Now!, I checked my TrueCrypt preferences and found there is a way to set this option in the TrueCrypt GUI.  Go to Settings, Preferences; uncheck the box that says "Preserve timestamps on all file containers."  It gives you a warning about losing plausible deniability.  Okay, because, you know, they could say, hey, you've been updating this.  But once you do that and restart TrueCrypt, every time you dismount a TrueCrypt volume it updates the timestamp on the encrypted container.  Thanks for the best podcast going.  Good tip, Jim.



STEVE:  Yes, Jim and many other listeners mentioned that this option was in the GUI.  So I wanted to make sure our listeners know.  We talked about a command line option that you could add to the end of the TrueCrypt EXE invocation.  Certainly for the typical user going in and unchecking "Preserve timestamps on all file containers" is a lot easier to do.  Now, one reason you might not want to do that is you might not want to make that change globally, in which case using the command line switch would allow you to do it on a container-by-container basis as you are telling TrueCrypt to mount a certain container and dismount it.  But I did like the option.



And I just loved, again, I was guessing from hearing that the timestamp was not being updated that those TrueCrypt guys were again doing the right thing.  They were wanting to preserve the date stamp at its creation, its original creation date, specifically for the purpose of plausible deniability.  So I love the fact that, when you uncheck that, it warns you that, oh, okay, we'll update timestamps as you wish.  But then someone might say, hey, wait a minute, this has today's date.  You've been in there today.



LEO:  Yup, very interesting.  Good tip.



STEVE:  TrueCrypt rocks.



LEO:  Yeah, they're just - they think about everything.  They're true paranoids.  David O., lurking about in the Bay Area of California, feels that stating "Only the NSA can do it" understates the scope of the threat.  And I take responsibility for that.  I'm the one, I think, who said that.  Hi, Steve and Leo.  Love the show.  What was - our previous questioner said something, "state-sponsored organizations"?



STEVE:  Right, right.



LEO:  That might be a better way to say it.  I'm writing to ask that you consider amending something that you have said on more than one occasion.  When discussing the topic of writing several passes of pseudorandom noise as a means of obscuring previously written data on disk media, Leo has been understandably skeptical about the true real-world feasibility of such sci-fi data recovery, stating something along the lines of, "I mean, c'mon, only the NSA has the sort of technology that would be necessary to read disks at this level; right?"  So I wanted you guys and my fellow listeners to know it ain't so.



There are commercial services available that offer this level of data recovery - okay, I'm going to be very skeptical here, but I'll keep reading - of truly erased and overwritten disks.  I used to work in tech support for a large computer company, and representatives from a data recovery service came in and talked to us once to explain that disks that were erased or overwritten could have their data recovered by them for forensic purposes.  It's not cheap or easy, but it's an available service, and anyone can employ them for the price.  They discussed the details of how it's done, much in the way you explained using trace levels of residual magnetic charge.



So because there are commercial services available, it means that the scope of risk is not just the NSA at the national security level, but is expanded to the scope of, let's say, private investigators, with angry ex-wife, husband, partner, et cetera; mistrust between bosses and employers; well-heeled snoops and so on.  I'm not suggesting that folks should be paranoid or overwrite their data seven times with pseudorandom noise every time they empty the trash.  That might be a bit over the top.  But I think it would be unjust to your listeners to understate the scope of the risk in a security-related concern on a podcast such as Security Now!.  If somebody really wants your data and is motivated, a simple erase or even a zero-all is truly not secure enough.  And I agree with that.  I wasn't saying that a simple erase was secure enough, or a single pass was secure enough.  I understand that.  I question these so-called "commercial enterprises."



STEVE:  Well, and we do all agree that 36 passes is...



LEO:  That's too much.  Two or three would be more than enough.



STEVE:  I really think that's the case, yes.



LEO:  I'd like to know who these commercial services are.  You know, I'm talking not based on my own experience, but on the testimony of people I trust in this area, arena, like Simson Garfinkel, who did this study and is a very bright guy, who said, ah, one pass is plenty.



Tim O'Malley of Beach Park, Illinois, wants to remain virus-free.  But pass as many times as you feel necessary.  Hi, Steve and Leo, says Tim.  The question stems from podcast 129 where Steve makes the comment at the end of the show, and not for the first time, that neither Steve or Leo use antivirus.  Now, I know you're not denouncing antivirus or suggesting that people shouldn't employ AV.  Before I go any further, I don't work for an antivirus vendor.  Still, it begs the question, how do you set up your machines so that you feel safe enough not to have to use antivirus software?  I've been listening for a while now and can speculate as to how you have it set up so not to run, but I would rather hear it directly from you.  Thanks again, guys.  Keep up the great work.  Tim.



STEVE:  Well, Leo, I would say it's a combination of the way we have our machines set up, and more probably than anything else, our behavior.



LEO:  Yeah, it's all about behavior.



STEVE:  It really is.  We know I'm a little stricter than you are.  Well, I'm much stricter than you are...



LEO:  A lot stricter.



STEVE:  ...about scripting.  I just don't like scripting.  I'm going to - well, and so I surf with scripting disabled, which normally sort of catches me out a little bit.  I go, wait a minute, why is this not working?  Oh, that's right, I need to trust this website.  Then I add it to my trusted zones in IE, and scripting is back on the way I have my zones configured, and I'm able then to do what I want.  But so that, I really like that.



But the second thing is I never, ever, once ever in my life used Outlook Express or Outlook for email because Microsoft has had so many horrible problems with IE's web browsing experience, and Outlook and Outlook Express use the web browsing control in the window.  So any problems that you have with IE and scripting, your email automatically inherits.  Which is just the dumbest thing I've ever heard of.  I mean, who ever thought that scripting was useful for email?  But it's been turned on from the beginning, and we've had all kinds of viral problems as a result of that.  Now, that's getting better.  But those are things that hurt other people.



I've always been using Eudora, and one of the things, one of the options you can check is do not use Windows viewer in Eudora.  So I turn that off, and then I use just a generic text display rather than essentially IE, you know, Windows viewer for my Eudora.  And so, yes, when I look at email, I'm not seeing what looks like a web page.  I've looked at other people's email, and I've thought, wow, look what I'm missing.  On the other hand, I get all the text.  Email is for text.  So that's really my two things are be careful about email, and in my case I turn scripting off.



But as you said, Leo, or agreed with me, largely it's about behavior.  I will not click a link that I get through email.  I mean, I just - I am really, really, really reticent.  I have a hex viewer that I use, and I'll look at an attachment in the hex viewer to see if it looks like what it appears to be, if I'm inclined to believe that I've received something.  But, I mean, I'm really anxious about attachments in email.  I don't treat them casually at all.  So it's just a matter of really being careful.



LEO:  I just don't surf the Internet with a Windows machine.



STEVE:  Ah.



LEO:  I use Windows all the time.  I need to.  I'm using it right now to record the show, to edit the show.  I just don't go on the 'Net with that machine.  That helps me.  Now, on the Mac, obviously I still have to worry about those kinds of things, and I'm very careful.  The good news is that almost everything I run up against is written for Windows.  So all the email attachments and everything are all written for Windows.  I think it's probably a good idea to have an antivirus in your toolkit to at least scan from time to time, just to make sure that you haven't made any mistakes.



STEVE:  Certainly if your system seems to have gone a little funky, then it's like, uh, maybe I ought to, I mean, I've found myself scanning, grab the current copy of AVG if I think something's wrong.  And normally it's just the fact that the thing's 10 years old is the problem.



LEO:  Here's a good one.  This will give you a little chill.  Sony Daswani submits a succinct request with the subject "to learn password of any ID" and asks, "Please give us how we can learn password cracking."  Obviously a devoted listener.



STEVE:  I just loved it.



LEO:  How can we learn password cracking, Steve Gibson?



STEVE:  That's not why we're here, Sonu.



LEO:  He's Sonu.



STEVE:  You've got the wrong podcast.



LEO:  You've got the wrong show.  We've talked about it, I mean, peripherally, things like brute-force attacks.



STEVE:  Well, no, we absolutely talk about what it is that bad guys do to crack your password.  You have to...



LEO:  Those tables, those, you know...



STEVE:  Rainbow tables.  And brute force, and dictionary attacks, I mean, we've talked about this a lot.  But we're not in the business of teaching how it's done.  We're in the business of explaining the technology used.  And then from that we derive the best defenses against password cracking.  The good news is, for Sonu, there are plenty of sites on the internet, and probably even some podcasts, which will help him to learn password cracking.  But not this one.



LEO:  Well, I think if you're following what we're saying closely, you're getting everything you need to know.  It's just a step between what we describe and the implementation.



STEVE:  Right.



LEO:  What we don't do is give you scripts.  We don't teach script kiddies.  But I think if you're an intelligent person you could listen to what we're talking about and say, oh, okay, I need this, this, and this, and pretty much figure it out.



STEVE:  Well, yes.  For example, you can imagine in the case of, for example, WiFi, which we've covered extensively, all the things we've talked about, somebody who was wearing a gray hat could use - for example we've talked about how SSID, turning SSID off doesn't help, how using MAC address filtering doesn't help, I mean, we've talked about all the things that you should not do.  Well, anybody who's not listening to this podcast or hasn't somehow brought themselves up to speed with state-of-the-art security, they're going to fall victim to these things.  And, I mean, I still read today as I'm surfing around, oh, yeah, turn off your SSID beacon.  Oh, just use MAC address filtering, that's secure.  Okay, good luck with that.  Our listeners know better.



LEO:  They know better.  David in the United Kingdom is wondering about radio.  Steve, I heard you talk about the security of wireless keyboards a few weeks ago, or the insecurity, I should have said.  That got my attention.  I have a Logitech wireless keyboard, but I do not access Internet banking through it because of the uncertainty of its security.  I'm thinking of getting a new iMac soon and would like the convenience of using their Bluetooth keyboard.  However, I'm worried about its wirelessness.  My flatmate got malware on his phone last year through Bluetooth.  Is it possible that a Bluetooth keyboard could get compromised?  For instance, could you get a keylogger in the keyboard?  That would be a bad thing.



STEVE:  Well, okay.  We're going to do a podcast here before long on Bluetooth security.



LEO:  Oh, good.  Because there seems to be a big debate over how secure it is.



STEVE:  Yes.  We're going to cover it as carefully and extensively as we cover all of the fundamental technology stuff.  It may be one of those episodes that people have to listen to a few times.  Certainly they should not be operating heavy equipment at the time that they're listening to our Bluetooth, you know, how Bluetooth security works episode.  For now, let me say that the one thing you absolutely want to do - and Leo, we discovered this when you and I were up talking about Bluetooth on The Lab with Leo a couple months ago - was you want to turn off discoverability.  Discoverability is something that really should just switch itself off.  I mean, if this were designed correctly, you would make a device discoverable for 60 seconds, and they would all snap back to nondiscoverable, because you really only need discoverability during the so-called "pairing" of two Bluetooth devices.



But what was interesting was we were up in Vancouver recording The Lab with Leo, and we turned on a Bluetooth sniffer and looked at how many Bluetooth devices just there in the studio.  And it was, like, 20.  It turned out everybody there, the cameraman and the producers, I mean, everybody had their Bluetooth devices, they just left it in discoverable.  That's the vulnerability in Bluetooth.  So make sure your devices are not left that way.  Unfortunately, people turn that on.  And then they're like, yay, I got connected, and they go off and do their next thing and forget to turn that off.



LEO:  Somebody asked me on the radio show if Bluetooth encryption had been cracked.  And it uses AES, so I think it's probably pretty good.



STEVE:  We'll be talking.



LEO:  I think that's going to be a great subject.  Stay tuned for that, David.  Let's see, Mr. G., one more question.  Are you ready?



STEVE:  Yup.



LEO:  I can't believe how fast this went.  David Miles of Westminster, Colorado is having second thoughts...



STEVE:  You're just having too much fun this time, Leo.



LEO:  I am.  It went fast.  I mean, it always goes fast, but this week it went really fast.  Hi, Steve, I've been using OpenDNS for over a year - as have I, so I'm very curious about your answer to this question - and over the past few weeks began noticing that Google has been painfully slow.  I haven't noticed that.  Then Google started accusing me of having a virus even from my Ubuntu and Fedora systems.  Actually I do get that from time to time, but I don't think it's OpenDNS.  But what it says is, Google gives you a little popup that says you're behaving as a spyware or virus program would, and then gives you a CAPTCHA saying please identify yourself as a human.  I went through a day of getting that a lot.  And now it's stopped completely.\



He says, I finally got tired of the OpenDNS "Yikes server not responding" on every other access and returned to the Comcast name server.  Suddenly Google is back to normal, no more bogus virus warnings.  It seems that OpenDNS is up to some evil.  They're apparently harvesting info from queries for unknown purposes.  The Wikipedia article on OpenDNS has additional info.  Since I first heard about OpenDNS from Security Now!, I thought you might want to take a look at this.  Have you looked into this?



STEVE:  Well, I wanted to say a couple things.  First of all, I was interested in your experience because I knew that you were an OpenDNS user.



LEO:  On everything.  I use it at home, and I use it here.  I don't think that the Google warning is related to OpenDNS.  I think that that is something Google has a problem with from time to time.  It's happened to me, and it's happened to others with and without OpenDNS.



STEVE:  Right.



LEO:  So I don't know, I mean, I can't trace it back to OpenDNS.  I really can't.



STEVE:  Yeah, I run my own DNS server here on UNIX, and it's a server that goes out and resolves all my queries.  So I'm not using an ISP's DNS servers.  I wanted to mention, though, I mean, conceptually I love the idea of a third-party good-guy DNS service.  We know how dependent everything that we do is on DNS.  That is, you know, whenever you're looking up a website, unless it's explicitly supplied through an IP address, which is, you know, it can be done, but it's uncommon, DNS is involved in translating that human readable address, like Amazon.com, TWiT.tv, GRC.com, whatever, into its IP.  Well, that gives that translator an opportunity to intercede and say, wait a minute, these are bad guys, what do you want to do about this?  Or as DNS does, for example, to correct spelling mistakes.  If you go to, like, SourceForge.og instead of org, it says, oh, we know what he means, and it fixes it for you.



So there's a tremendous opportunity for DNS to be essentially a filter in a very benign and non-intrusive way.  And because DNS is often sort of the poor stepchild of ISPs, they'll, like, have a DNS server that's 30 years old, it's been there forever, that is an underpowered machine because once upon a time DNS didn't require much power, doesn't have much RAM, you know, my point is that an ISP's DNS server can often be very slow.  And if an ISP's DNS server is slow, it will bottleneck all of their users' access because their users' access has to go through that.  So it can be the case.  It looks like David Miles has an ISP with a good-performing, fast DNS server.  But it can be the case that using a third-party DNS can be substantially faster.  And the experience is wow, you know, the Internet is faster is how people describe it.



LEO:  I actually don't use OpenDNS for speed because both my Internet service providers, one of them is Comcast, are just as fast as OpenDNS.  So I don't use it for that reason.  I use it, it's got phishing filters, which is great.  If you sign up for a free account, you can also use it as an adult site filter, has actually very good filtering, and it's done - since I put the OpenDNS server's info into the router at home, it's done throughout my house.  So unless I enter custom DNS information in my computer, which I do.  But the kids, you know, they haven't figured out that the router's doing the DNS.  And so it's getting blocked at the router, and it's really a very effective filtering solution that costs nothing.  Also they have DynDNS for people who have a moving IP address, that's very handy.  I don't, you know, I've talked to these guys.  I can't say 100 percent they're benign.  But I have a pretty strong feeling that they're benign.  I have a very good feeling about them.



Yes, one of the things they do, and this is how they support themselves, if you enter a 404, instead of getting the Internet Explorer 404 message or a nonexistent web page message from your browser, you get a nonexistent web page message from OpenDNS.  It looks like a Google search page.  It has ads down the side just as Google does.  And it has, which I find very useful, corrections, suggested corrections.  And frankly, I use that all the time.  And when I mistype something, if it can't do the obvious fix like the og to org, it'll give you that page.  That gives them some revenue because this is a free service.  I don't have a problem with that.



So I've been recommending OpenDNS.  It's a very easy thing to implement.  You could either just change the DNS settings on your computer, or do as I do, do it on the router and then blank the settings in the computer.  And from then on you'll be using it instead of your ISP's.  I think it's a good service.  And I don't see, I haven't seen any evidence that it's tied to the Google, those Google warnings.  That's something that goes wrong with Google every once in a while.  Have you ever seen that?



STEVE:  No, actually I haven't.  It's interesting that you say that it believes you're acting like some sort of malware and wants you to prove that you're human.



LEO:  Yeah.  I have an image on my blog of it coming up.  And it could be, you know, maybe it is because of something happening with OpenDNS.  Maybe - I don't see why it would because once the DNS is resolved, Google doesn't know that I've done a different, used a different DNS server.



STEVE:  Right.



LEO:  How would that impact that?  You know, it's just as you - they've made too many requests in too short a time.  Maybe I just use Google a little more than I oughta.  I don't know.  Or maybe, I don't know, maybe that's a sign I have some spyware on my system.  Maybe I should be using that antivirus.  I don't know.  I'll check it.



STEVE:  Yeah.  I guess my hope is that Google has been changing their behavior as they've grown huge.  I guess you know that their purchase of DoubleClick has now been approved.  It was approved by the EU, which was the only thing really holding them back.  And so they're going to be acquiring DoubleClick, that is of course one of the infamous trackers of...



LEO:  I'm so upset about that, yeah.



STEVE:  I know.  And so I think OpenDNS is still a relatively small group.  I think they've got, like, about a dozen guys.  And I hope they don't, like, start leveraging their success into needing to generate more money and becoming more commercial because that would be a shame.



LEO:  I'll read the warning.  It says "We're sorry, but we can't process your request right now.  A computer virus or spyware application is sending us automated requests, and it appears that your computer network or network has been infected.  We'll restore your access as quickly as possible.  Try again soon.  You might want to run a virus check or spyware remover."  I've never gotten that one.  Mine...



STEVE:  Interesting.  So this is Google saying you're asking us too many things, essentially.



LEO:  Yeah.



STEVE:  Wow.  Interesting.  I've never seen that.



LEO:  Yeah.  So that's actually one I've not gotten.  I've gotten the one that just says, you know, you're acting like spyware.  So I don't know, it's a very interesting question I'd like to know more about.  If our listeners know more, that would be a good subject for us to talk about in a later show, too.



STEVE:  Yeah, yeah.



LEO:  Steve, we're out of time.  I want to encourage everybody to go to your website.  We're not really out of time, we have as much time as we want.  We're out of questions.



STEVE:  We filled up their RAM.  Their RAM runneth over.



LEO:  My RAM is full.  I need a nap.



STEVE:  Next week we're going to have fun.  We're going to address this issue of RAM hacking.  All this wacky, spray Freon on your memory chips and put them in your refrigerator and recover some of the drive and all that kind of wacky stuff.



LEO:  That's a very, very good topic.  That'll be fun.  Of course in the meantime you can go to GRC.com, that's Steve's site.  Now, GRC, Gibson Research Corporation, of course is the home of SpinRite.  And if you need SpinRite, you should get it there.  And do get it because it's the greatest.  It's the disk recovery and maintenance utility of all time.  You know, just having it here to run just gives me such great peace of mind.  I also suggest you go there for 16KB versions of the file.  So if you want to listen to this on a bandwidth-challenged system, that's a good way to do it, save yourself some bandwidth.  Doesn't sound too bad.  We also have transcripts, so you can read along as you listen, and show notes, too.  That's all at GRC.com.  Steve, we'll see you next week.



STEVE:  Did you run SpinRite at level 4 on that RAID drive, or just 2?



LEO:  I think 2.  Should I run 4?



STEVE:  Yeah, you should.  That's probably why something is going on.  2 just does a - it's a read-only pass.  If any sector causes trouble, then it drops into level 4 and massages the sector to figure out what's going on.  But it's possible that you could have just run it - also maybe the drive was less hot than it is normally when it's been in there, like you shut the machine down, you recabled it, you ran SpinRite on it, that would have given the drive a chance to cool off.  And so it might be something thermal also.  But give it a shot on level 4.



LEO:  It's a weird, you know, unfortunately it's such a useless error.  It just says there was an error on the BIOS bootup message.  And then everything was fine.  So I don't know.  I will, I'll do a level 4.



STEVE:  On your way out the door to - where is it you're going?



LEO:  Australia?



STEVE:  Australia, yeah.  Just fire up SpinRite.  It'll be done by the time you get back.



LEO:  It won't take that - see, now, people are going to think SpinRite takes long.  It does, you know, it takes, you know, you do it overnight at worst case.



STEVE:  Generally like three hours for 80GB, I read someone's mail earlier.  So three hours for 80GB.



LEO:  Okay.  Thank you, Steve.  We'll see you next week on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#137

DATE:		March 27, 2008

TITLE:		RAM Hijacks

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-137.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo plow into the detailed operation of static and dynamic RAM memory to give some perspective to the recent Princeton research that demonstrated that dynamic RAM (DRAM) does not instantly "forget" everything when power is removed.  They examine the specific consequences of various forms of physical access to system memory.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 137 for March 27, 2008:  RAM Hijacks.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now! with Steve Gibson, everybody's favorite security guru at GRC.com.  You're a guru.



STEVE GIBSON:  I guess I am.  I'm a year older guru now.



LEO:  That's fantastic.  Congratulations and happy birthday.



STEVE:  Yeah.  Well, you know, I am not a big birthday person, but it's sort of nice to note that I've survived another one and got - I think I'm about halfway done, so...



LEO:  That would be good.  That would be good.



STEVE:  Yeah.



LEO:  You're halfway there?



STEVE:  My grandfather lived to 103.  I'd like to beat him.



LEO:  You're kidding.



STEVE:  Like to beat him by one year, so...



LEO:  103.



STEVE:  Yeah.



LEO:  So you have good genes.  And you're wiry and thin, which bodes well.  You don't drink, you don't - well, you drink a little wine, but that's good for you.



STEVE:  Cabernet is good for you.  And I work out 64 minutes a day on the stair climber.  I had my annual physical the other day, and the doctor said, well, if all my patients took as good care of themselves as you do of yourself, Steve, he said, I wouldn't have a job.



LEO:  That's fantastic.



STEVE:  And I told him we'll be doing this in 20 years.



LEO:  That's so great.  Well, congratulations.  Happy birthday.



STEVE:  Thanks.



LEO:  Let's see.  Today we're going to talk about something  that is a very, very hot topic, something that actually we missed a little bit because we did that TrueCrypt drive encryption story a little early, we taped it early, and then the news broke that you could in fact crack drive encryption with some very arcane techniques.



STEVE:  Well, arcane, and I'm not sure whether this is a hot story or a cold story because a lot of it involves spraying Freon on RAM chips in order to extend the length that they - or, well, to slow down their rate of decay.  We're going to talk about all of that and also about the various means of accessing RAM and what it means.  These guys at Princeton just did a fantastic job, so it's going to be really fun to catch everybody up on on what's been going on with that.



LEO:  All right.  Let's get some errata and addenda and all...



STEVE:  Well, actually, yeah.  We don't really have any errata, but we have a very important security issue which has just come up.  It is an exploit which is being actively exploited that's been acknowledged by Microsoft.  It involves a flaw in their Jet Database which is part of the Office Suite and especially comes along with Word.  What's happened is, okay, first of all, the vulnerability affects Windows 2000, XP, and Server 2003 SP1.  This vulnerability does not affect any computers running the SP2 of Windows Server 2003 or Vista because they run a different edition of the Jet Database.



It turns out that the MDB extension is the file on the database file.  There's an exploit which was found in the wild, it was zero day, no one knew about it, at least it has never been acknowledged publicly in any forum.  And most systems will not run anything with a .mdb.  So the way this exploit functions is that users receive an email message with two attachments.  One is a Word doc, and then the other is a file with the extension changed.  And when you open the Word doc, the Word doc causes the database file to be executed, which makes the exploit occur.  And so what's happening is this is a targeted attack.  For example, it's been used in industrial espionage and attacks on government systems where, rather than just spraying spam, people who are using this are deliberately sending email to specific recipients, hoping that they will open this attached Word doc and get themselves infected.  So there's no fix for this.  It is being exploited.  There's really nothing anyone can do at the moment, unfortunately.



LEO:  Well, except not open email attachments.



STEVE:  Exactly, except follow the standard guidelines and just do not open email attachments.  There is a scenario also where both files arrive in a ZIP file instead of being separate attachments.  So but either way, basically the exploit functions the same way.  The Word doc causes the database file to be executed, which wouldn't otherwise be executable.  That makes the exploit happen.



So I expect - Microsoft's advisory acknowledges this.  They know it's in the wild.  They're trying to figure out what all the possible exploit vectors are to make sure they nail it down.  And they're saying they will either deal with it in the second Tuesday of April - hopefully it would be April - or they may do an - this may be bad enough and serious enough that they will do an out-of-cycle patch.  We're going to be unable to advise people next week and the week after because we're having to record those episodes early.  So there may be news of this in a week or two.  If we're not able to talk about it, that's why, because we're already had to record our podcasts.  So I just wanted to give people a heads-up about this.



And also, I mean, I've been noticing Windows Update has been very busy lately.  There was an update to an Excel patch which was patched on March 11.  But there was what they call a "regression error."  They broke something else in Excel when they made the patch.  So they had to patch the patch.  And that came out a few days later.  There is now vulnerability code, exploit code for some of these problems that were patched.  Remember we had the big Office Suite patch earlier this month.  So there is now released and in the wild vulnerability code which generally means we're going to see a lot more attempts of that.  So again, the standard guideline is make sure that Windows is staying patched, at least for the patches that we have right now.



LEO:  I was doing a search for Jet vulnerabilities and there's a lot of them since going back years.  This is kind of a continual problem.  There was one last year.  There was one in 2004.  I'm having a hard time finding the one we're talking about.  Oh, here it is.  Security Advisory 950627.  I'll put a link...



STEVE:  That's exactly the one, yes.



LEO:  I'll put a link in the show notes.  You know, people often yell at me because I say don't open attachments.  And they say, well, come on, not all attachments.  And then I say, well, I guess technically it's don't open executable attachments.  The problem is, people can't tell what's executable.  And this is a really good example.  Here you are getting a doc file and an mdb database, neither of which are executable technically.



STEVE:  Well, exactly.  And in fact it used to be that the file extensions would be changed in order to fool the filtering software.  And Microsoft added technology to open files by content rather than by extension in order to solve that problem.  Here we have a problem, though, that Word is able to run scripts, and documents are able to contain scripted executable code, which is just like a web page.



LEO:  So this is, I mean, you know, don't open attachments.  Really it's very straightforward.  I wish there were another way.  People say, well, how am I supposed to do business if I can't send attachments?



STEVE:  Well, and to give us a little more strength, when I was researching the details of this I ran across an interesting sort of summary from the Security Focus site.  And quoting from their site, it says - they wrote, "Flaws in Microsoft's Office productivity applications have become standard weapons for fraudsters conducting targeted attacks aimed at high-level managers and executives.  While 10 or fewer high-severity flaws were reported in the five major component applications of Microsoft Office each year from 2002 through 2006, at least 26 high-severity flaws were reported in Office applications last year, according to data from the National Vulnerability Database.  And earlier this month, as we know, Microsoft patched dozens of flaws in Office applications."



LEO:  Yeah.



STEVE:  So we're seeing an increase in the rate at which these problems are surfacing in Office.



LEO:  That's interesting because for a while it looked like the vector had shifted from email attachments to web-based vulnerabilities, web-based exploits.  Guess that's not the case.



STEVE:  Well, the Office exploits are slightly more targeted, as this said.  They're not spraying them out to everybody because the likelihood of finding victims is smaller, and they would rather not have their actions discovered as quickly.  They'd like to keep these exploits a secret.  I mean, this Jet Database exploit that we're talking about here, the longer it stays unpatched, the better for the bad guys.  So they're not wanting to spray it all over the place.



And the one last little bit of news I wanted to mention on the security front was you may have heard, Leo, you and I hadn't talked about it, about there was a bunch of furor, I guess it was late last week, about - first it was Barack Obama's passport file that had been breached on three occasions in January, February, and earlier this month, in March.  And then they found out that both Hillary Clinton's and John McCain's passport files, all three of them had been opened by contractors working for the State Department.  The cool thing is that it was State Department monitoring software, security monitoring software that caught these breaches.  So...



LEO:  Too bad they caught them and couldn't block them.



STEVE:  Well, actually they caught them and notified people, who then didn't talk about the fact that they had been caught.



LEO:  But it might have been better, instead of having the monitoring software, have some sort of security on there.



STEVE:  Yeah.  Well, now the problem, of course, is that this was an unauthorized access.



LEO:  Well, they shouldn't allow unauthorized access.



STEVE:  Well, but no, I mean, it was something that these employees by virtue of their job had to have access to.  They had to be able to do it.  But they shouldn't have looked there.  In fact I'm reading stories in the security space like this all the time.  Police officers or law enforcement people are poking around in databases, in files, in other people's lives that they're curious about.  And they have the authorization to access the database.  But it is a violation of privacy rights for them to be using their curiosity to direct their searches.  And so that's the problem is these employees, by virtue of their job, had the access.  But they abused their access in order to satisfy, apparently satisfy their curiosity.



LEO:  Well, at least they had a monitoring system.  They didn't have one before, so that's...



STEVE:  Well, and that's my point is that - and it's a rare thing still in this day and age for companies to have monitoring software.  Normally companies just rely on policy enforcement and don't have that backed up by something verifying that the policy is being followed.  So, yes, this was a good thing.



And then I have one quick little short fun SpinRite story that was different.  I always look for, try to find things that are different.  The subject was "SpinRite Rules."  And this was - looks like Ravi Keecheril.  I hope I'm pronouncing his name right.  He says, "Hello, Steve.  SpinRite rules.  I have a MIT TV box made up entirely" - I love this - "of discarded hard drives."



LEO:  Oh, wow.



STEVE:  "In my company, whenever a hard drive fails, it immediately goes to the dark storage room on its way to the hard drive graveyard.  I've mentioned SpinRite many times to them, but they're more comfortable taking a new drive from inventory.  There's always several new drives in stock, usually bigger than the last one that just failed, of course.  So I asked them, can I have the old ones?  And my boss said sure.  So periodically I go into the storage room, take the old drives home.  Of the seven drives I've taken so far, six have been completely resurrected by SpinRite and are working happily ever after."



LEO:  See, that's an interesting point, that a lot of times what looks like a failed drive isn't a failed drive, it's just an error on the medium that can be either repaired or blocked, and the drive is fine.



STEVE:  Sure.



LEO:  That's a large percentage of them, I mean, that's a huge number.



STEVE:  Exactly.



LEO:  Do you think that holds true across the board?



STEVE:  Well, given SpinRite's proven track record, its ability to recover drives which have died in one way or another, I mean, it really does seem to be the case.



LEO:  Very interesting.  All right.  Shall we talk about these exploits, these very interesting - Ed Felten is a brilliant security researcher at Princeton.  He's always pushing the envelope.



STEVE:  Yep, in fact his name is very familiar to me because I see him being cited and quoted all over the place.



LEO:  Oh, yeah.  I think he was first known in the copy protection wars.  He's done some really interesting research there.



STEVE:  Over in DRM stuff.



LEO:  In DRM, yeah.  He got in trouble for, and I think bowed out of - oh, he's done analysis at Diebold, the voting machines?  He's really an interesting guy, interesting researcher.



STEVE:  Yes, and in fact I just saw an article about that.  Somebody wanted him to analyze - he and Princeton were going to analyze another voting machine issue where there had been some concern raised.  They were all set up to do it, and they got threatened with a lawsuit, saying that it was a viol- by the company who had the apparently defective voting machines, preventing them from analyzing what was wrong.  It's an example where our DMCA really does us no real service.



LEO:  Yeah.  He did a really good paper on the digital music initiative challenge.  He bowed out of it because he couldn't publish his results.  But he cracked it in a few weeks.  I mean, it was like - these guys are bright.  So what's the latest?



STEVE:  Well, what they did was - and many of our listeners literally flooded us with reports of this when the news first broke.  The great concern was that - there was a little bit of hype, what I consider hype.  And I think maybe our listeners, once they have all the facts in front of them, will agree.  Because the email that I was getting made it clear that people who were writing to us at GRC.com/feedback, using the web form that I have there, they were clearly given to believe that whole drive encryption had been cracked, it had been broken, it was a serious problem.  That's in fact not the case, although what this group did was extremely cool.  Essentially what they discovered was that the contents of RAM stays available for longer than was believed.



Now, historically people have understood that RAM could have sort of a latent image, essentially, that there was - that data stored in RAM, until it was expressly and explicitly cleared, would linger for some length of time.  But no one in the literature that had been surveyed ever really sat down and figured out, okay, how long is long?  Is this seconds?  Is this minutes?  Is this hours?  No one thought it was days.  But people sort of - there was sort of this general concern floating around that oh, you know, memory doesn't - it isn't, like, immediately lost, even when power is removed.



Now, let's back up a little bit and talk about technology because that's always the underpinning behind what we talk about that I really enjoy and I know our listeners do.  There's two types of memory, essentially.  That is to say, volatile memory.  We've talked a lot about Flash RAM and how that works.  Volatile memory is either static or dynamic, which are the two terms to broadly differentiate memory.  The original memory that was created for early computers was static memory.  And what that means is not that it survives power being turned off, but that it does not need to be continually refreshed.  Refresh of memory - and people may have heard, like, RAM refresh terms if they've been in the business for a while - is something that dynamic memory needs, and I'll explain why in a second.  But static memory doesn't need it.



Now, the way static memory works is kind of cool.  If you think of a piece of digital logic called an inverter, we've talked a lot about binary data.  An inverter turns a zero that it receives on its input into a one.  And conversely, it turns a one that it receives on its input into a zero.  In other words, just whatever you feed it, it sends out the other bit, the reverse.  Give it a zero, you get a one; give it a one, you get a zero.  So imagine a very simple circuit where you connect the output of the first inverter to the input of the second, and the output of the second back to the input of the first.  So you've got two inverters sort of in series.  They're each connected to the other in a loop.  Well, that's a stable, logically, that's a stable configuration.  If say that the first inverter has a zero coming into its input, so it puts out a one, which goes into the second inverter, which because it's getting a one puts out a zero, which is connected back to the first one, giving it that zero that we started with.  So that thing can sit there forever, essentially.  As long as power is up, those inverters are going to just maintain their state.



Now, imagine that we briefly imposed an external influence on this.  We forcibly yanked the input of the first inverter, which is a zero and has been sitting there, we yank it briefly up to a one.  We just force it up to a one.  Well, it puts out a zero then, which goes into the second inverter, which now puts out a one.  So that one that we briefly yanked up is now again stable.  Well, this is another thing, a common term people have heard of called a "flip-flop."  Essentially it's called a "bistable multivibrator," also known as a "flip-flop," and it's the basis of static RAM.  So to turn that into a chunk of memory, basically you just have a ton of these little inverters, these little inverter pairs, all connected to each other, connected back to back like that.  And you provide an ability for reading out the state of any of these little flip-flops and also for forcing them into, like, change from their otherwise stable condition over to the condition that you want to store.  So that's how static memory works.



The problem with it, which our semiconductor industry ran into after a while, was that every single cell, that is, every single bit, essentially these two inverters, this flip-flop or this bistable multivibrator, it takes a lot of space in terms of silicon to create the inverters with the transistors and resistors and the addressing logic and things that you need in order to force it into either state, in order to read its status out, and just for its own little bit cell takes up a bunch of real estate.  What that means is that as you try to increase the density, and of course that's what we're always doing in the computer industry is trying to store more data in a smaller space, you start having your chips getting too big, or you're just not able to put as many bits on a practical size chunk of silicon as you would like to.



So scientists, these brilliant engineers that come up with all this stuff, thought okay, how can we make this simpler?  How can we somehow reduce the size that's required to store a bit?  Well, they came up with something very clever, which is dynamic RAM.  What dynamic RAM is is essentially a capacitor, that is, that's all there is, with a little bit of logic around it.  But just a capacitor.  A capacitor is a component in electronics which is able to essentially electrostatically store a charge.  You put a charge on the capacitor by pulling electrons off of one of the plates or pushing them on.  And as long as you leave it alone, it doesn't change.  So it's a very simple way of maintaining memory.  And there's a bit.



Now, the problem is, as you make capacitors very, very small - and again, density is our goal, we want to cram as many of these little microminiature capacitors onto a chunk of silicon as possible.  As we make them very, very small, their capacitance, that is, their capacity for storing electrons, diminishes.  And leakage effects begin to creep in, just sort of thermal effects, you know, electrons tend to wander off the reservation.  And so the capacitor won't be able to keep its charge indefinitely.  And again, as is always the case, we're trying to make these capacitors as absolutely small as possible.



So we start running into tradeoffs.  What the engineers figured out was that they could make the capacitors incredibly small to get a whole bunch of them on a chunk of silicon, but they couldn't do that and have them keep their charge, for example, indefinitely.  So they came up with this notion of refreshing.  And the idea is that all of the capacitors, all of the memory bits in a chunk of dynamic RAM are continuously being scanned.  That is, what's happening is you write something into memory which either charges or discharges the capacitor.  If it's charged, it immediately begins discharging back down to its so-called "ground state."  It starts to just self-discharge due to electron migration.  So as long as you come back and read that before it discharges too far, you can see whether you had originally stored a one or a zero there.  And as it's draining, as long as you come back and read it in time, you can go, oh, well, this is only 50 percent full.  But that means it must have once been 100 percent.  So you refresh the data in the memory, essentially recharging all the little capacitors that have been trying to discharge since you last swung by.  That's how dynamic memory works.



So now, if you imagine suddenly cutting the power to this, you have stopped refreshing, but you've got this whole grid of little capacitors which are, at their own speed, and based on variations in the specific physics of the material and temperature, they are all beginning to discharge as soon as you stop refreshing.  So the guys who did this research, they said, okay, what happens if at normal operating temperature we cut the power, count to three, and then turn the power back on again?  You know, what percentage of these capacitors will decay, and what can we do about that?



So the research they did showed that very much as a function of temperature that dynamic memory would hold its data for - oh, well, okay, first let's talk about normal operating temperature.  Normal operating temperature, which is pretty hot actually inside a laptop or inside a computer, we're blowing air on all this stuff to try to keep it from melting down, but still it's very hot.  What they discovered is there's a great variation in decay rate based on the technology being used.  The newer RAM, being even more dense, meaning the capacitors are even smaller, tend to decay to, like, maybe 10 percent will decay in as short as one or two seconds.  So you have, like, 10 percent loss of information in one or two seconds without refreshing, that is to say, without power on the DRAM.  And again, at normal operating temperatures, they found a couple older dynamic RAM chips that, oh, maybe you could get as much as 10 seconds before you lost - oh, I'm sorry, the charts that I was looking at, we're talking about 50 percent loss of information in one or two seconds or 10 seconds.  So in 10 seconds, even, I mean, the best these guys found was at normal operating temperature half of the capacitors had discharged to their ground state within a maximum of 10 seconds.



Now, we talked about how the reason these capacitors are discharging is electron migration through the dielectric, the insulation of which is what makes the capacitors possible.  Well, naturally, as we know from physics and chemistry, temperature has a substantial effect on the rate of all these kinds of processes.  So what the researchers did was they said, okay, let's - what could we do to extend this time for some sort of - whatever purposes.  We want to see how much time can we get.  So they just took those little spray can of air bottles, and it turns out when you turn them upside down and spray them the Freon comes out, and it cools these things down way far.  They were cooling them down to, I think, -50 degrees C.  And there, not surprisingly, by freezing the DRAM, they were essentially able to dramatically slow all of the physical processes going on in the DRAM which would otherwise be facilitating the capacitance discharge.  And they were able to come back an hour later, that is, have this little DRAM chip out of a computer, sitting on a desk, spraying it with Freon to keep it cold, and then an hour later plug it into a computer and read out the majority of its data by freezing it down.  And in fact they also dunked it in liquid something, hydrogen, nitrogen...



LEO:  Probably nitrogen.



STEVE:  I'm not sure what it was.



LEO:  They had to do that pretty quickly because you only have a second or two if you want to save everything; right?



STEVE:  Oh, yeah.  Well, and the other thing is, Leo, I mean, they sprayed this while the machine was on.  I mean, so...



LEO:  Right, well, you want to cool it down before you remove power; right?



STEVE:  Exactly.  So...



LEO:  Then maybe you have some time, you could dunk it and get even more time out of it.



STEVE:  Okay.  So, okay.  So now we have a good foundation for understanding what they did.  They were using Freon to slow down the loss of data from dynamic RAM.  We understand how dynamic RAM works and why you get this, you know, bit errors.  What they did that I think was the coolest was they said, okay, we're going to, after some number of seconds, we're going to as quickly as we can take a snapshot of what we've been able to maintain in the presence of known bit errors of RAM.  Now the question is, how can we use that data?  What can we find in there?



And one of the things they did, and their paper that you and I both have links to, you on your show notes for this episode and me over on mine, what they did was they said, okay, let's go after encryption keys.  Let's look at BitLocker and TrueCrypt and major whole drive encryption, which is because it's exciting and it's fun.  You know, what can we do?  Well, okay, take for example a strong 256-bit key.  And let's talk about AES because we've covered Rijndael, the AES standard, at length recently in talking about exactly how that works.  So we take a key of a certain length.  Well, we know that as you start changing bits in that, I mean, you change one bit, and you've got something that doesn't work at all.  So given some percentage of bit drift caused by the dynamic RAM being disconnected from its refreshing for some length of time, you would think, okay, you're screwed immediately.  I mean, this key changes at all, and it's useless.



But remember that in the details of the way AES works there's something called "key expansion," which we talked about.  The idea is that, for example, in Rijndael and in virtually all other symmetric ciphers there are some number of rounds, that is that essentially a round is a reversible bit scrambling, meaning that it maps any set of bits that you're inputting that you're going to encipher or encrypt.  It maps them into exactly one other pattern in a way that is reversible.  That's the whole point, of course, is being able to decrypt what you encrypt.  But that mapping itself, doing it once is not secure.  So the ciphers work by iterating through this, doing that some number of times.  Well, every one of those rounds requires some data from the key.  And, for example, in the case of AES, we take the key, and there is a chunk of entropy, a big table of data, which is part of the AES spec, which has been chosen.  And all AES implementations use the same big chunk of entropy.  The key is mixed in a cryptographically secure fashion.  And data is taken from that table.  That generates the data which is, for example, XORed with the output from each of the rounds every time through.



The point is that the key, the original Rijndael key is expanded through this key schedule or key setup, as it's called, to create this chunk of data which is then used, each piece of it, for each round of the cipher.  What the guys realized was that data is like error correction code.  It's like ECC that we've talked about on a hard disk, meaning that the key is expanded to something much bigger and inherently has much more redundancy in it.  The individual bits in the key have no redundancy.  But when you use them to expand this into the key schedule, you've got a tremendous amount of redundancy.  It could be used like error correcting code.  And they worked out all the details to reverse engineer the exact key from the key expansion and the key, under the assumption that there were unknown random bit errors.  And they did the math, and it works.



So it's extremely cool.  Essentially they said, okay, we're going to experiment with decay rates and dynamic RAM.  We're going to figure out what kinds of levels of bit errors we can expect.  We're going to experiment using temperature, using cold, to slow down the decay rate.  And then we're, in the presence of known errors, we're going to see whether we're able to reconstruct a key knowing that Rijndael was used here or whatever it is.  Well, in fact BitLocker uses Rijndael also, but in a different way.  And they also do the same thing with DES.  It turns out that DES's key schedule is extremely straightforward.  So it was very simple for them, even in the presence of a high degree of bit loss, of bit decay, to reconstruct an original DES key, and even Triple DES.



So essentially that's what these guys did.  It was promoted, of course, as look, we're able to take a chunk of DRAM which was briefly without power or without refresh or, for example, went through a cold boot, which is what they often did was they simply hit the reset button, so the RAM was not being refreshed for some length of time.  And then the system came back up.  And then so there was some level of loss.  And so they were able to say, we're able to come back after a brief period of time, again, like maximum of a few seconds at normal operating temperature, or if the situation permits it, if we're able to cool the DRAM down, I mean, and really cool it down, we can go as much as hours or days and then bring the RAM back to life, capture its data, and even though we know we've got errors, we are able to, by taking advantage of what we know about the way symmetric ciphers work, and they did also some work with public key crypto as well because again the idea is that while you are using the cipher, that key is expanded.



So that key expansion, all that extra redundancy, is there in memory because it needs to be used dynamically.  You just, in terms of performance, you cannot afford to expand the key on the fly every time you want to, for example, read or write a sector to and from the disk.  That overhead would just be really prohibitive.  So it's done once.  And the point is if you capture the system, if you're able to get a snapshot of memory, even in the presence of errors, they've demonstrated that it's possible to reconstruct the keys of virtually all of the whole drive encryption products that they attempted.  So it was very cool.



LEO:  Well, it's very impressive, too, and they really do good work.  So but I also gather from what you say that this is not something that's going to be easy for a hacker to do to you.



STEVE:  Well, okay.  Now, there's some other things we have to cover when we're talking about RAM hijacks.  But I wanted to first discuss...



LEO:  How it's done, first, yeah.



STEVE:  Well, exactly.  Well, this particular type of RAM hijack, which is, you know, the very intrusive, get your hands on the DRAM, I mean, you would hardly allow anyone to grab your laptop and turn it over and spray Freon on the memory, if they were able to even find the memory in your laptop.  I mean, it would be obvious to you that this was going on.



LEO:  Yeah, no kidding.



STEVE:  So I'm not sure...



LEO:  And then let's just also, I want to emphasize this as well, they have to get your laptop while you're logged on.  Once you're logged off the key is gone; right?



STEVE:  Yes.  In the case of - we know that it's the case with the Mac because they did some work with a Mac.  When you log off, your keys are scrubbed.  I'm happy that this came to the attention of TrueCrypt...



LEO:  TrueCrypt will fix this; right.



STEVE:  I was just going to say, yes.  I mean, I'm really happy that this came to the attention of the industry at a period of time when TrueCrypt is under active development and has moved into v5.0.  Because, I mean, Leo, you could imagine, if I got a lot of email, can you imagine the amount of email that the poor TrueCrypt guys got when this thing surfaced?  So anything that the TrueCrypt guys can do to minimize the danger - and essentially what it means is it means when you're not actively needing to have access to the encrypted resource, whatever it is, TrueCrypt or BitLocker or the Apple drive encryption technology, it wants to actively scrub these keys from memory.  You can either write nonsense over it or zeroes, I mean, there isn't the issue that we've discussed several times with hard drives where you're actually able to find what was stored there before.  As you can imagine with these little capacitors, I mean, they're doing all they can just to hold onto the charge they've got.  There isn't any notion of what was there before, although there has been some study that showed that memory also has a bit of burn-in features in the same way, remember, that you know that screensavers were originally created to, quote, "save the screen" because if an image was sitting on a screensaver for a long period of time, the phosphors were aging, well, because there's a physical process there.



Well, as we've just been saying, RAM, dynamic RAM has a physical process going on.  And there has been some studies that showed that, if the same data was always being stored in the same place, that it might actually be possible to come along and take advantage of long-term physical changes in the memory.  So, which is sort of interesting.  It's like, well, that's really interesting.  I mean, it would take a lot of research, and it would mean that memory would literally have to be burned in the same location.  In modern operating systems that's probably unlikely because there's a whole layer of paging which occurs which associates physical memory with its logical addressing.  And it probably means that just normal data is going to be moving around in physical memory and not in the same place all the time.  But it's something for really security-conscious designers and developers to keep in mind.



LEO:  Yeah, yeah, yeah.



STEVE:  Okay.  So the other interesting things which are sort of fallouts from this, there are a couple.  For example, you could take a USB dongle which is bootable and create a very small boot OS which takes a snapshot of memory.  And you want it to be a small footprint in the OS because of course the OS is going to have to run in the same memory that you're trying to take a snapshot of.  So you don't want to do too much.  But, for example, these researchers did experiments using PXE, which is Intel's specification for network booting, saying okay, let's reboot a system and use the network boot ROM that is on the motherboard's BIOS to essentially install a very small footprint OS, just enough to do essentially a remote RAM suck through the network interface.  So that was one thing that they did.  You could also do the same thing with a small USB dongle that is able to boot and use it to snapshot the system memory.



And then the one other really interesting aspect of RAM hijacking which has actually been floating around for years is Firewire.  It turns out that Firewire, as part of the spec, it's OHCI, the Open Host Controller Interface.  And it turns out that the open host may be a little more open than these people intended.  It turns out that the Firewire spec supports direct memory access.  It really is a bus.  It is a bus just like the bus that you plug cards into, through the 1394, the Firewire controller.  And so it is possible for someone to create a Firewire gizmo which would, when plugged into a laptop's Firewire port, it would declare itself as needing accessing to direct memory, that is, Direct Memory Access, DMA.  And it can then suck out the system's RAM through the Firewire port.



LEO:  Wow.  So if you had such a device, like a USB key, it would actually do the same thing reading the RAM as you have to do with all this freezing activity.



STEVE:  Exactly.  Well, and in fact you may have some loss depending upon what the USB key does.  I mean, certainly when we - we've talked about autostart and how much a concern it is that when you plug a USB key in, the OS will automatically run things.  It always has made our listeners uncomfortable, and deservedly so, that an OS is configured by default, that is, modern OSes, where you plug the USB key in, and it has the chance to run code.  I mean, that's the convenience, for example, of using traveler mode on a TrueCrypted drive is you plug it in, it is running the TrueCrypt driver automatically when you do that.  Well, there's nothing to say it can't be running a RAM-sucking little executable that just simply copies all of the system RAM out to the thumb drive, I mean, literally to...



LEO:  That's amazing.



STEVE:  Yes, to hijack your system.  Nothing prevents that.  Now, it's worth noting, though, that there are other vulnerabilities, for example, in typical laptops.  For example, many laptops have a PCMCIA card or an ExpressCard.  Those are the system bus.  So, similarly, nothing prevents you, I mean, it is access to the system's bus.  If you plug something in there, that device is on the bus, which gives it access to the system's memory.  And for that matter, laptop docking connectors.  You know, they're all different based on laptop make and model.  But they're also the laptop's bus.  So I sort of wanted to create a little more perspective on this whole issue and say, you know, physical access to our systems is almost never secure.  That's the case.  If you're going to allow someone to spray Freon on your dynamic RAM...



LEO:  What're you going to do?



STEVE:  ...and then take it with them, okay, that's not very secure.  You can hope that they lose more bits than they plan to.  But I guess the point is it's certainly of academic interest that data can be slowed down without power from loss in dynamic memory, and that clever algorithms can be used to reconstruct a low amount of bit loss in order to reconstruct someone's keys.  But if you turn your laptop off and you count to 10, your data is gone.  And it's certainly the case that now that this has gotten all the attention it has, and I'm glad it has, if there were any vulnerabilities, or if, for example, in the case of the TrueCrypt guys whose intentions are very clear, if there's anything they can do to minimize the window of exposure, they will.  For example, you know, make it incredibly fast and easy to dismount TrueCrypt, a TrueCrypt volume, and wipe the key.  And so that would require that you reauthenticate.  But people who want that security may want to, for example, when you hibernate or when you suspend your system.  It's certainly possible for the TrueCrypt drivers to see that that's gone on and then deliberately unmount as they're able to and then require you to reauthenticate in order to regain access to your now unmounted partitions.



LEO:  I mean, I understand what you're saying when you say if somebody's got physical access to your system you're in trouble.  But I guess the point of these full disk encryption systems is to protect them in that eventuality because otherwise you don't really need full disk encryption.  I mean, if somebody doesn't have physical access to your system, what are you worried about?



STEVE:  Okay.  Right.  My feeling, though, is that the proper way to think about this is, if someone - if you lost your laptop, if you left it in the airport, or someone swung by and sneaked away with it in an area where it was unsecure, you absolutely want to make sure that, when the laptop is not in use, it cannot be put back into use without requiring full-strength reauthentication of its user.  So it may be the case that, for example, just putting it into standby, as we know a laptop on standby is having its dynamic RAM refreshed.  That's what standby is.  It's the reason it's using a little bit of battery power.  Unlike hibernation, where the whole contents of RAM is copied to the hard drive, and then the system is shut down, it is powered off, and you can pull the battery out of it for as long as you want to.  That hibernating image exists then on the hard drive.



LEO:  Now, you didn't address the issue of the hibernating image, did you?  I mean, can you do the same kinds of tricks to that to get the key out of it?



STEVE:  No.  We know that the hibernating image is encrypted.  I don't know whether a decrypted hibernating image requires reauthentication.  That would be something that we would want to check on.  But, I mean, I would bet it does.  I would bet that the keys are wiped, then the image is encrypted and written to the drive so that when it comes back you need to reauthenticate coming out of hibernation.  I'd bet anything that that's the way it's got to be.



LEO:  Well, until we find that out, though, the most prudent thing would be to shut it down.



STEVE:  Certainly powering off your machine and then not handing it to a stranger...



LEO:  Immediately...



STEVE:  ...immediately...



LEO:  What would be a prudent amount of time?



STEVE:  And especially a stranger who's holding a can of Freon.



LEO:  Would a minute be enough?



STEVE:  Oh, 10 seconds, Leo, I mean, really...



LEO:  It's pretty quick.



STEVE:  And anything even more recent is down at a second or two.  I mean, they managed to find some old, less dynamic, dynamic RAM, less dense, where they were able to get, like, 10 seconds kind of.  But, I mean, really...



LEO:  Okay.  So to be prudent, if you're using full disk encryption, and you shut your system down, and you hold onto it for 10 seconds, you're safe.



STEVE:  Yeah.  Then give it to anybody you want.



LEO:  Then it's a gift.  Well, no.  More to the point, then if you leave it in a taxi or it gets stolen you don't have to freak out because none of these techniques work unless the system is logged in.



STEVE:  Yeah, in fact I would argue that it's probably the case that with TrueCrypt you are more safe because given that TrueCrypt wipes the keys and encrypts the RAM to the drive, then you're getting explicit wiping of the mount of TrueCrypt.  So the moment the hibernation is finished, it's safe.  You no longer have that 10-second wait.  If you powered down leaving the system mounted, then you powered down with the keys in service, in use, then you've got to wait a few seconds.  I mean, most people are going to turn the machine off, then they're going to be wrapping up their cables and putting it into its laptop case and putting things away.  I would say turn the machine, turn your laptop off first.  And then when you're busy doing everything else to get it stowed, it's completely forgotten everything it ever knew.



LEO:  Right.  So it's not sensationalistic, I mean, but in fact it's a valuable research project to let people know that this vulnerability even exists is saying something.  I'm particularly interested in the USB key vulnerability.  That's amazing.



STEVE:  Leo, it is a perfect episode for Security Now!.  That's about what it is.  I mean, it's really intriguing academically.  But it isn't going to affect anyone's life because memory - DRAM doesn't forget what it knows instantly, but it does very quickly.



LEO:  Fast enough.



STEVE:  Yes, very quickly.



LEO:  Okay.  Very good.  I'm glad.  I think there was a lot of concern, in all seriousness.  There was a lot of - people were worried.  And so nothing to worry about.



STEVE:  Well, or at least we...



LEO:  We know what to do.



STEVE:  Yes, yes.  I was going to say the threat is now understood.  And I'm glad the TrueCrypt guys know.  I'm glad the BitLocker folks know.  And apparently there was some work that Microsoft did in awareness of this for the design of BitLocker.  The researchers made the point, though, that there is - I think they call it Basic Mode with BitLocker where it works with the TPM module that we've talked about on the motherboard, the Trusted Platform Module.  So I guess saying "TPM module" is redundant.  I got two modules in there.  It works with the TPM.  The problem is, in the basic mode the TPM by default provides BitLocker with the keys on the fly without requiring authentication.  So...



LEO:  Then you've got a problem anyway.  You turn on your machine, and hello.



STEVE:  Yeah, I mean, exactly.  So anyone could take it and turn on and get what you want.  So don't - I'm sure any of our security-conscious users understand that requiring authentication, while it's a bit of a headache, I mean, it's protecting you from exactly that.



LEO:  Right.  I never mind logging in.  I know that I'm...



STEVE:  It feels good.



LEO:  Yeah.  It's safe, unless you - so I'm glad we did this.  I want to reiterate that the problem was that we did the TrueCrypt episode ahead of time.  And so I think the day before the TrueCrypt episode came out, but a week after we recorded it, this whole storm broke.  So I'm glad we could, it took us a little time, but we could get around to it and talk a little bit about it.  And as you can see, it was nothing to freak out about, nothing to worry about.



STEVE:  Well, and again, it did raise a lot of people's concern.  I don't want to say nothing to worry about.  I just want to say, well, probably, and...



LEO:  Something good to know about, though.



STEVE:  Absolutely.  It makes a perfect episode of Security Now!.



LEO:  Well, as always.  You are now going to pull ahead of This Week in Tech because I'm going to Australia.  And so we'll - by the way, don't worry, there's a Security Now! episode next week and the week after.  We're going to pretape.  But not of TWiT, not of MacBreak Weekly.  You're now pulling ahead.  The only show that is ahead of you now - there are two shows.  One's The Tech Guy, but just because it started in 2004, and it does two a week.  And you can't - you'll never beat the Daily Giz Wiz because he does five shows a week.



STEVE:  That's cheating, Leo, Giz Wiz.  I mean, could you not have numbered them, like, 1.1, 1.2, 1.3?



LEO:  If we did that, you'd be winning.



STEVE:  Okay.



LEO:  So next week Episode 138.  TWiT is in the dust.  Security Now! will be back next Thursday with the great Steve Gibson.  And don't forget Steve's site, GRC.com.  That's where you can go to get SpinRite, of course, the world's best, the world's only, really, true disk recovery and maintenance utility.  It's a must have for recovering those hard drives that the boss is putting in the dark closet.



STEVE:  I hope Boss is wiping the contents of those drives.  I was thinking about...



LEO:  Employee is I'm sure.



STEVE:  Yes, yes.



LEO:  If he's a good employee, he wouldn't dream of...



STEVE:  Yeah, he's filling it with MIT TV video.



LEO:  Isn't that funny, he's got every episode of "CSI" on there.  You know, I'm sure the boss is not wiping them.  You know he's not.



STEVE:  Well, especially when the drive dies.  It's a little hard to wipe a dead drive.



LEO:  Yeah, how are they going to wipe it, yeah.  So Security Now!, then wipe it.



STEVE:  SpinRite.



LEO:  SpinRite.  Security Now!, then SpinRite, then wipe it.



STEVE:  There you go, there you go.  Then you're really covered.



LEO:  When you go to GRC.com you also find many great tools like Steve's fun - and these are all free - Wizmo, which now has that, what do you call it, LAN Wipe, LAN...



STEVE:  Lanlock.



LEO:  Lanlock feature.



STEVE:  I'm sorry, wanlock.



LEO:  Wanlock, to turn off zero config, which is really handy.  It does a lot of other stuff, too, fun stuff.  And then all his great security utilities.  It's all GRC.com, including 16KB versions of this show for the bandwidth impaired, and full transcripts so you can read along as you listen.  I know many of you like to do that, as well.  Steve, next week what do we do?  It's I guess Q&A time, yeah?



STEVE:  We have a Q&A time and an interesting little bit of news.  Someone has created a paper enigma machine.  We've talked about...



LEO:  Oh, cool.



STEVE:  ...the German Enigma machine.  There's a paper enigma machine.  You can download a PDF and make one.  So we'll be talking about it at the top of the show, then do our Q&A.



LEO:  Oh, that's so cool.  And if you don't know what an Enigma machine is, you're going to find out.



STEVE:  Yup.



LEO:  All right.  Well, that will be next week on Security Now!.  We hope to see you then.  Until then, Leo Laporte and Steve Gibson.  Stay safe.  We'll see you next time.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#138

DATE:		April 3, 2008

TITLE:		Listener Feedback Q&A #38

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-138.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 138 for April 3, 2008:  Listener Feedback #38.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, everybody's favorite security podcast.  Is mine, anyway, because it stars the great, the one, the only Steve Gibson, the man who discovered spyware.  What?  What are you laughing at?



STEVE GIBSON:  It's definitely my favorite security podcast.



LEO:  Yeah, well, it's my only security podcast.  That's why I'd have to like it.  But I would anyway.  Steve is an expert at making stuff intelligible.  But, and I'm proud of this, we never dumb it down.  And that's one of the reasons we have written transcripts and, you know...



STEVE:  No, and in fact I'm a real believer that if something is - if someone understands something and is able to communicate it, it really does not need to be made simple.  I mean, I think last week we talked about static and dynamic RAM.  And I would imagine that everybody listening kind of enjoyed understanding, if they didn't already know, what is static about static RAM and what is dynamic about dynamic RAM and how that stuff works.  And there's no need to dumb it down if it's explained correctly.



LEO:  I've made my living assuming people are intelligent.  And I prefer to do it that way.  A lot of broadcasting doesn't assume it.  It assumes the worst.  I like to assume the best.  And, you know, it's self-selecting.  I mean, if you listen to this show you're obviously a smart person.  And but that's fine.  I'm really happy just talking to people who get it and want to get it and care enough to figure it out.  And I know this is a challenge.  It is certainly the most challenging show we do on the network.  But that's part of the fun of it.  Your brain grows when you listen.



We are going to talk today, actually we're going to do listener feedback.  We're going to answer your questions, so it means we'll talk about at least a dozen different topics, which will be a lot of fun.  So do you want to talk about the Paper Enigma Machine first?  Because this is so cool.



STEVE:  Yeah, just very quick, Leo.  I just thought it would - I ran across it.  Bruce Schneier was blogging about it this week.  And I thought, oh, that's kind of interesting.  So I followed the link, and it's to a really interesting, simple, zero-cost implementation of sort of a reduced-capability but still functional Enigma machine, the Enigma cipher machine used by Germany during World War II.



LEO:  The story of Enigma is really a significant story.



STEVE:  Right.  And so it's - this is just something that you can - they have a PDF you can download which you then print onto card stock.  And using scissors and glue and cut some slots and make some strips, you're able to really get a sense for how it works.



LEO:  So I remember it was - was it Alan Turing who broke the Enigma machine?



STEVE:  Yes, Turing working at, I think it was...



LEO:  Bletchley, yeah.



STEVE:  Bletchley.  There's always an L in there, I'm not sure where it goes.  Bletchley Labs, yes.



LEO:  Yeah, in Britain.  And this was, I mean, the Germans were able to use Enigma to really harass British shipping with their submarines.  Once it was cracked, it may have been one of the keys to winning World War II.  It was significant, significant.  And people never thought they'd crack it.  It's so cool that you can make one.  It was - they were beautiful.  They were wooden boxes with gears and cogs and a typewriter on it, I mean, it was really quite a clever, interesting device.



STEVE:  Well, so what people can do is, you and I have links to it on our respective show notes.  You can also just simply Google "paper enigma machine."  The first link there takes you right to this page.  It's also worth noting that there's a link in about the middle of the top of that page to an Enigma simulator.  It's a software simulator that runs under Windows or under Wine under Linux, which is a complete emulation of a whole bunch of different Enigma machines.  It was beautifully put together.  So if anyone is sort of curious about this and wants to play with it, either just print out paper and get a real, intuitive sense, I mean, a real understanding of how that works.



LEO:  Yeah, and I notice it's math classes that do it.  And I think that that's really one of the neat things, to bring both math and history to life.  I just think it's a really neat solution.  So, yeah, very cool.  So today Q&A, yes?



STEVE:  Q&A, yes.  I don't have any errata nor security information since we're recording this on the heels of last week's episode because as people are listening to this you're in Australia taking pictures of things.



LEO:  I'm in Tasmania, mate.  I'm taking pictures of the Tasmanian devil and the Tasmanian tiger.



STEVE:  In my eternal search for new and different SpinRite data recovery stories, I had something wacky that I thought I would share with our listeners.  Steve Hall wrote with a subject, "Thanks to SpinRite, my daughter can read better."



LEO:  What?



STEVE:  He says, "Hi, Steve.  I just wanted to say thank you for making such a fine program.  Recently my father gave me a hand-me-down computer since he was replacing it.  The reason he was replacing it is due to the fact that during an act of Windows-induced frustration" - okay, I kid you not - "during an act of Windows-induced frustration he decided to give the computer some flying lessons."



LEO:  Oh, I can believe that.



STEVE:  "From the second floor to the first floor..."



LEO:  Oh, no, he threw it out the window?  Or downstairs.



STEVE:  I guess he - I think downstairs because there's a reference here to his Pergo flooring.



LEO:  Oh, man.



STEVE:  "From the second floor to the first floor of his house.  Well, after a new motherboard and some replacement sections of his Pergo floor, I had it up and running in no time, keeping the old original hard drive."  Which, okay, I don't think I would ever use a machine whose hard drive had gone down a story.  But he says, "I kept the Windows XP that was running on it and gave the computer to my four-year-old daughter to run her Hooked on Phonics game.  She loves it and uses it daily.  Until it stopped booting up."  Not surprisingly, I mean, the drive probably had loose bits floating around inside.



LEO:  Oh, can you imagine what happened to the drive, yeah.  I mean, that's the worst thing you can do to a drive, right, is impact.



STEVE:  Oh, yes, yes, yes.  You're literally - you're bouncing the heads on the surface.  Now, it's way worse if it's spinning.  So presumably Dad unplugged the computer during his fit of pique with it, or his peak of pique, the peak of his pique, and before throwing it downstairs.  So the platter - the heads would have pulled off the platters to go into the center near the spindle where as the platters vibrate there's less vibration in the center where the drive is anchored.  Normally that's what heads do.  They used to get pulled off of the platters completely and parked away from the disk.  But now they just slide into the center where they're safe.  And they generally - there's, like, an electromechanical mechanism.  A little hook comes out that locks...



LEO:  Oh, I had no idea.  They park it.



STEVE:  Yeah, they park in the center.  And the reason they go into the center, not only do you have much less motion if the disks are vibrating because they're anchored in the center, but also it helps with the stiction problem.  When the motor starts up, naturally the heads, which are resting on the surface, they can be a little sticky.  And so you'd like to have them in the center where they have less mechanical advantage in preventing the disk from spinning than if they were resting out on the outer edge, where they have a very strong mechanical advantage to keep the disk from spinning.  So all of that goes on.  Anyway, so...



LEO:  I had no idea.  And it goes on in milliseconds; right?



STEVE:  Yes.  Oh, yeah.  The moment you power down, the heads are snapped into the center and rest there until you power back up again.  And he says - so he says, "Suddenly it no longer booted up" - it's like, yeah, no kidding - "but instead displayed a message that it could no longer locate some key Windows files."  Like I said, those Windows files were off on the edge of the drive somewhere.  He says, "I also know that the drivers for the very old Netgear wireless card are nearly impossible to locate now.  Being a loyal Security Now! listener, I was pretty sure SpinRite would fix it."  Okay, he's a faithful Security Now!...



LEO:  Wow, that's great.



STEVE:  ...listener.  "So I decided to bite the bullet and purchase me a copy.  After 12 hours of clunking away and many recovered sectors, SpinRite recovered the computer..."



LEO:  What?



STEVE:  "...and it once again boots up."



LEO:  The computer that went down two stories, it recovered.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  He says, "I certainly am a satisfied customer and will always recommend SpinRite to many happy daughters everywhere."



LEO:  Now, here's the question.  Do you recommend this?



STEVE:  No.



LEO:  See, he's an honest guy.  I love this about you.  There are a lot of people'd say, oh, yes, absolutely, no matter what, SpinRite.  But once a drive has gone down the stairs, probably not worth trying to recover it.



STEVE:  No, I mean, that kind of physical damage is, I mean, I'm glad that SpinRite was able to recover.



LEO:  Get your data off it now.



STEVE:  I've seen pictures of literally barbecued hard drives that survived fires that our listeners tell us SpinRite was able to get the drive back up again enough that they were able to copy data off it.  I mean, it looked like it had been in a charcoal, bottom of a charcoal pit.  But...



LEO:  But a new drive is cheap.  Copy the data off.  Don't trust that drive now.



STEVE:  Yeah.  Yeah.  But, I mean, he's been able to keep it going, so what the hell.



LEO:  I'm impressed.  I am impressed.  All right.  Let's see, shall we get to our questions?



STEVE:  You betcha.



LEO:  We'll start with number one.  We've got 12 good 'uns.  Fred Zanegood in Orlando, Florida, he wants a free audible podcast.  Well, I don't blame you.  Actually there are free - if you go to Audible.com, this is not an ad for Audible, I just want to mention they do have free stuff.  In fact, they do a lot of pro bono stuff, things like debates, speeches, state of the union, that kind of thing.  I haven't seen a lot this year.  I wonder if they stopped doing that.  But they always have in the past done a lot of pro bono.  So there are a lot of free things on Audible.com.  But, he says, just thought you'd like to know that the AudiblePodcast.com/securitynow URL - which we use all the time - doesn't work, he says.  Huh?  I thought it may have been an OpenDNS problem, but after putting it on my whitelist it still doesn't work.  Have you guys tried it or heard of others experiencing similar problems with the URL?  I'm using Firefox.  Love the show. Love SpinRite.  Thanks, Leo.  Thanks, Steve.  Well, it worked for me.  Does it work for you, Steve?



STEVE:  Works for me perfectly.  First thing I did was put it in.  I did notice, however, that it immediately jumps around a little bit.  There's...



LEO:  Well, don't say the other URL.  Here's what's going on.  They don't want people to go to the other URL.  It does redirect.  But the point is they're counting how many people go to Security Now!.



STEVE:  And that's a good thing.  But it may be the redirection that is causing Fred the problem.  You mention...



LEO:  Well, let me tell Fred, first of all, that it doesn't matter.  While we'd like it to be counted, they don't pay us by number of acquisitions or anything.  So, I mean, it's not like we'll get less money.  But we do, you know, we just want to - they want to know, and we want them to know, how many people come to them from each different show, that's all.



STEVE:  Exactly.  So what happens is, it is doing a redirect, meaning when he puts that in, there's actually a website at AudiblePodcast.com which sees that he's trying to reference the page securitynow.  It gives the browser back a new URL, called a redirect, which the browser then follows, all things being equal.  However, there have been some shenanigans played in the past with redirection of a security nature, and there's sort of a - it sort of generally makes people feel, I mean, really security-conscious people feel a little uncomfortable.  It's like, wait a minute.  I put this URL in because I trust it.  I don't want to be bounced somewhere else.  And in fact we've talked about some sort of shady goings-on with redirection where for example links at PayPal are actually DoubleClick links which take you to DoubleClick and then redirect you back to PayPal.



LEO:  Well, this all goes through Audible, I should tell you, it's not...



STEVE:  Yes, exactly, there's nothing shady going on there.  But as a consequence of the fact that redirection of URLs has been abused in the past, and the fact that Fred mentions he's using Firefox, which tends to be a security-conscious browser, and that Firefox has all kinds of add-ons, it may just be his security.



LEO:  Ah, blocking it.



STEVE:  Exactly.  He may have redirects disabled.  He may be using an add-on.  He mentioned whitelisting it.  I don't know if he was talking about whitelisting through OpenDNS because - and he says, "I thought it may have been an OpenDNS problem, but after putting it on my whitelist it still doesn't work."  So that sounds like maybe something whitelisting externally.  He may have to tell his browser that AudiblePodcast.com is an okay website and to allow redirections from it to the Audible URL that actually...



LEO:  Yeah.  You end up at Audible.com/podcasts, I think, something like that.



STEVE:  Right.



LEO:  But, yeah, okay.  I use redirects for the podcast URLs because - and the reason I use a redirect is because I may host the - so a podcast is an RSS feed.  And I sometimes have in the past moved the RSS feed to different servers for various reasons, mostly because I want to be able to do that should a server go down or be over-expanded or whatever.  So if you go to, for instance, the nominal URL for Security Now!, which is leo.am/podcasts/securitynow, it'll redirect you to an XML file.  And the reason for the redirect is, again, so that I can - I have one URL that's always guaranteed good, and I can move you around, if I need to, to different locations for that XML file.



STEVE:  And I do, too.



LEO:  So I should not do that?



STEVE:  Well, no, I do the same thing, for example, on the 64KB versions of Security Now!.  We have a URL that looks like GRC.  But when the user's browser fetches it, it redirects to you guys.



LEO:  Right, and then which gets it from AOL.



STEVE:  Exactly.



LEO:  So it's redirect redirect.  And in fact that's how we count podcast downloads, we direct through Podtrac.com and then to the server, whether it's AOL or CacheFly that provides the bandwidth for the show.



STEVE:  Well, and interestingly, I was thinking about this question this morning.  I also, when I was originally setting up GRC way back in the old dark days, the way our DNS was set up was with a wildcard in front of GRC.com.  So anything dot GRC.com took you to the IP of GRC.com.  So you could use www.GRC.com, just GRC.com, or literally anything.  I mean, you could just make up something dot GRC.com.  Which, you know, I thought, oh, isn't that cool.  Well, I don't know how or why, but we, over the years, we accumulated so much, I mean, an unbelievable amount of debris dot GRC.com.  And Google was, like, finding it.  And if I Googled GRC.com I would see all this random, like, machine names dot GRC.com.  So finally I got - I said, okay, this is ridiculous.  So I have a redirect now, or I did for years, where anything dot GRC.com redirected you to www.GRC.com.  And I think finally, after several years of, like, training the world not to use anything but the real names, I then shut off the wildcard.  But so I've had - I make great use of redirects, as well.  I mean, again, they  never go anywhere spooky or suspicious.  But they are very handy.  I wish they hadn't been abused.  But like everything else that's kind of cool and can be used for gray purposes, they were.



LEO:  They're not going to go away.  I mean, there's just a lot of reasons why you would have a redirect.  And it's just, you know, it's just unfortunate, I guess.



STEVE:  It can cause problems, which is of course what caused Fred to write to us saying, hey, why can't I get to AudiblePodcast.com/securitynow?



LEO:  Well, and I appreciate your trying, Fred.  And it's okay if you just go to Audible.com.  It's fine.  We don't have to count every single person.



STEVE:  Well, I imagine Fred would like to know if his security settings in Firefox are causing redirects to break.



LEO:  Or Norton Internet Security, McAfee, there are a lot of security programs doing that.



STEVE:  Anybody that is doing a filtering on his browser stuff.



LEO:  Yeah, a lot of security programs do a proxy.  And you go through them to get to the 'Net.  And at that point who knows what's going on.



Rene van Belzen in the Netherlands is worried his drives may be getting too much sleep:  I have a Mac, and recently bought a shareware utility called TinkerTool System - I use it, it's excellent, this is Leo saying that - developed by Marcel Bresink.  In the Hard Drives tab of the System Setup there's a warning message:  "Switching off the hard disks of desktop computers too often may reduce lifetime."  All right.  I'm trying to be green and save energy when I can, but I don't want to kill my hard drives prematurely, either.  So what, Steve, in your expert opinion, is an appropriate period of inactivity to put my hard drives to sleep?  How soon should they go to sleep?  And this is true on Windows, too, you have that slider.  15 minutes?  An hour?  Never?  What's the best for hard drive longevity?



STEVE:  I'll tell you, I never sleep mine.  My feeling is that, I mean, I know in the old days it was when you powered up systems that hard drives failed.  They were working the prior evening, everything was fine.  You said okay, you know, I'm done.  You turn off your computer, you come back in the morning, it won't boot.



LEO:  Well, that's true of everything.  That's true of light bulbs.  They always blow out when you turn them on.



STEVE:  And that's exactly why, is that - well, in the case of light bulbs, there's an interesting phenomenon with them.  And that is that the resistance of the filament is lower when it's cold than when it's hot.  So there's an inrush current that is the reason light bulbs blow out when you turn them on, is they get more power than they're supposed to have during that first instant when the filament is really cold.  There used to be an oscillator, in fact, I think it might have been a Wien bridge oscillator, I can't remember if that was the one, that actually used a light bulb to regulate the oscillator because of this weird characteristic that, as more current went through, the resistance went up, which limited the current.  So it was, I mean, a cold light bulb is sort of a regulator all by itself as a consequence of that.  But so anyway...



LEO:  So it isn't the same for hard drives.  But it is more stressful when the hard drive's spinning up.



STEVE:  Well, the other thing that goes on, given that you are changing - he's just talking about spinning down his hard drives.  But turning the whole computer off, of course, causes it to cool down to room temperature, which may get low at night.  Then when you turn it on you're heating it back up.  So now you've got big thermal swings from hot to cold and hot to cold.  I mean, I never turn my machines off, and I never spin my drives down.  I'm sort of self-conscious about it.  I've had drives last a long time just by leaving them going.



LEO:  I'm changing all my settings right now.



STEVE:  I think they're happier that way.



LEO:  They don't heat up, they don't cool down, they don't expand and contract.  They're consistent.  And, you know, you may not save power by switching them off and on because of all the extra power used to spin up.



STEVE:  Well, yeah, I mean, it is a function of what your duty cycle is of using a computer.  If you're somebody who gets on for an hour in the evening to check email, do a little web surfing, and then you're sleeping at night and you're gone at work during the day, it's like I don't want to tell anybody to leave their machine on 24 hours a day if they're going to use it one hour a day.  For me, I'm sleeping - the only time I'm not in front of my computer, Leo, is when I'm sleeping or at Starbucks.  Otherwise I'm here.



LEO:  And because he goes to Starbucks so often, he doesn't sleep much.



STEVE:  Exactly.  Exactly.  There's that caffeine effect.



LEO:  But that's a good point.  For power reasons it would be a good idea.  In fact, I've seen statistics that said that if businesses turned off their computers at night when people went home, it would power hundreds of thousands of homes.  I mean, it's a significant - when you think of millions of machines in use, it's a significant power saving.



STEVE:  It really is.  And so what I tell people who are not massive computer users like you and I, who are literally using our computer when our eyes are open, I say, look, if you're going to use your computer again this day, probably better to leave it on.   If you are done for the day, at whatever point you're done, shut it down.  I mean, I don't.  But my power bill demonstrates that.



LEO:  I leave them - I guess I leave them on, come to think of it, I do leave them on.  But I have had the drives being powered down.  And you know what, I'm going to now turn that off on all the systems.  You've got to balance greenness with the length of the drive.  The other point, I guess, to  make is that systems last a long time nowadays.  We're not killing off our drives.



STEVE:  True, and hard drives are cheap.  And SpinRite fixes them when they die, so what the heck.



LEO:  Buy a copy of SpinRite, and then you can turn them off and on.  Scott Hemmeter in nearby Orange, California is curious about IronKey's private TOR network offering:  Hi, Steve.  During the IronKey episode - what was that, that was 136?  135, I think - your guest explained how it could be used as a TOR network.  If I recall from way back in Security Now! - when we did a whole thing on The Onion Router, TOR - you said that traditional TOR is anonymous but not secure.  Did I understand correctly that the IronKey TOR network is both anonymous and secure?  If so, could this be used as a VPN?  I'm currently using HotSpotVPN as a VPN service.  That's $10.88 a month.  And HotSpotVPN slows my connection considerably.  I'm looking for an alternative.  Could IronKey be that solution?  If it can, boy, it would certainly justify the cost of the IronKey.  Is it secure and anonymous?



STEVE:  Well, let's review a little bit about TOR.  TOR is a system that was designed for anonymity.  And TOR is an acronym that stands for The Onion Router.  And if anyone really wants to know everything there is to know about TOR,  we did an episode which I really liked because we explained, I think, very clearly and carefully what this onion model is, what is the onion, and how it's possible for people's traffic to be routed or bounced from one onion router to the next with the design deliberately created so that no intermediate onion router knows anything about the traffic other than which router it got it from and which router it's going to give it to.  The payload itself is encrypted.  It cannot decrypt it.



It's not until it gets to the final onion router, after so many hops, however many you want to configure, that only the last router peels the final layer off of the onion, as it's called, gets inside there the crypto keys which no prior router is able to access, then decrypts the traffic and puts it out on the 'Net.  So the goal is that no one monitoring that router is able to determine who generated the traffic.  However, they are able, if they were monitoring that router, that final onion router where your traffic finally is emerging onto the Internet, if somebody were monitoring that router they would see your traffic.  They would not be able to backtrack it one hop to the next in order to determine your identity.  But at that point it's no longer encrypted.



Now, that's, however, exactly the same with any of these HotSpot services.  HotSpot is a VPN, which Scott was talking about, where his traffic is encrypted from wherever he is to the HotSpot network.  And at that point it is decrypted.  It's taken out of the VPN SSL tunnel and, similarly, put onto the Internet in its natural form, in its unencrypted-by-the-VPN form.  You might still be using an SSL connection, for example, to a remote website, in which case your end-to-end connection to a website is encrypted.  So, for example, if you're using Gmail, we talked about this before, using https://mail.google.com, then all of your access to Gmail is maintained through an SSL channel.



Now, subsequent to our talking about The Onion Router network, there was some news about malicious TOR nodes, meaning that bad people were - or people of varying badness, maybe even state-run agencies, were creating TOR nodes and monitoring the traffic.  Which is really not what you expect or want from a TOR node.  You would like it to be run by a white hat, by somebody who is pro-anonymity who's offering a TOR node because they believe in the concept of supporting the anonymous use of the Internet.



So this is what IronKey is providing.  IronKey has a private TOR network which they completely control.  So unlike the public normal TOR network, which uses volunteer donated TOR nodes that no one is really vouching for, the IronKey guys have said, look, we like the idea, we're going to run our own TOR network, and we will allow IronKey users access to our TOR network.  So the TOR client creates an encrypted, a securely encrypted SSL connection to the first TOR server.  So very much like HotSpotVPN, your traffic is encrypted.  Then it bounces around IronKey's own TOR servers to obscure the path that the traffic has taken, and then emerges from IronKey's final TOR node out onto the Internet.



So it is secure.  The problem is, it tends to be lower performance.  I can't vouch for the performance of IronKey's private TOR network.  But I do know that TOR in general is a dramatic tradeoff between anonymity and performance.  That is, you know, using TOR is a very sluggish process where you're trading performance for anonymity because your data is bouncing around among these servers.  So the only thing I could suggest would be to give it a try, if you have an IronKey.  It is absolutely secure, but it may not be giving you more performance than a regular HotSpotVPN service or something similar.



LEO:  And the security is somewhat compromised by the fact that it's all through one company.  I mean the anonymity.  The advantage of TOR is it's a certain - it's whatever it is, 20 different, completely unconnected people hosting this.  So it wouldn't take one subpoena to catch it.



STEVE:  That's a very good point.



LEO:  So in some ways this really isn't a true TOR network because all they have to do is go to IronKey and say, who is it?  And they say, well, okay, it's him.



STEVE:  That's a very good point.



LEO:  So, okay.  That answers the question.  I need not go any further.  Bryan Moore in Carlsbad, California - are there caves in Carlsbad?  Carlsbad Caverns?



STEVE:  Yup.



LEO:  That's what I thought.



STEVE:  Probably bats in the cave, too.



LEO:  Actually as this airs I will be in Tasmania, where they have bats the size of foxes.



STEVE:  That's a big bat.



LEO:  Scary.  They have scary animals there.  There's an ant that can jump two or three meters.  And its bite is as bad as a bee sting.  I don't know, maybe I'll stay home.



STEVE:  And I think they have really, like, serious tarantulas, as well.



LEO:  Oh, yeah.  Big, bad spiders.  They have snakes, lots of 'em, many poisonous.  Bryan Moore in Carlsbad, California, where the caves are, doesn't want to create Flash Trash:  Dear Steve - this is a long question.  I'm going to be reading.  Let me get a drink.  Okay.  I listen to every Security Now! and love and recommend your show, but I will not buy an IronKey unless they make a variation of the product.  He wants them to use a slowed-down password failure punishment method, not a shiny doorstop Flash Trash destruction.  Let's explain.



STEVE:  Please do.



LEO:  Please do.  A few users might prefer Flash Trash, but many of us don't want e-waste or a shiny doorstop when someone else might try to sneak a peek at our data.  He's talking about the fact that, if you try to break open the IronKey, it destroys itself; right?



STEVE:  Actually he's talking about the fact that if you...



LEO:  Oh, if you fail the password.



STEVE:  Yes, yes..



LEO:  So how many times did he say it's - 10 times or something?  But you could change that.  But 10 failed password attempts and you've got nothing.  You've got a doorstop.  He says:  A few users might prefer this, but many of us don't want this.  It seems far more highly probably for most of us than for someone to guess our password in a million tries.  In other words, that you would not guess it in 10 tries.  The possibility created by Flash Trash, where the USB key permanently self-destructs, requires that I maintain an accessible copy of my data in a secondary, possibly less secure backup.  This weakens the whole concept.  He points out Kingston also does this.  Anyone doubting the truth of the severe warnings displayed might use up the counter.  And then I wouldn't know until I needed to use it myself.  Oh, he's got a point.  Somebody tries to break in, tries it eight times and then says, oh, never mind.  Now you've only got two chances.  Even if they stop at "we really mean it" and I have one count to go, I might have two IronKeys, and I myself might need more than one try, or else I wipe out my own data, but only because of someone else's surreptitious attack and IronKey's mistaken use of permanent counters.  So you get 10 tries lifetime.  Is that right?



STEVE:  Oh, no, no.  It's 10 tries, and then if you successfully authenticate within 10 tries, that resets the counter to zero for your next authentication.



LEO:  He says what he'd prefer is time sequencing.  So after two or three failed guesses, the UI replies more slowly.  I've seen this happen with other programs.  After several more it goes into "Sorry, no more tries until power cycled," so you have to reset the machine, or even "ignore/stealth mode," where even a correct password does nothing until power is cycled.  True, the attacker now has unlimited time, but we can easily characterize the risk profile.  After three guesses we could require five seconds between guesses.  After five or 10 guesses the attacker must physically remove and reapply power or even have a nonconventionally controlled USB host.  The rate slows down to one guess every 10 seconds.  An internal capacitor could provide means to detect a repeated attack within 30 seconds.  And since there are only 31,536,000 seconds in a year, this would - I thought it was 325- anyway.  This would reduce the maximum attack frequency to about one million per year.  And even a very weak five-character all-upper-case password has 11 million possibilities.  The knowledgeable user simply unplugs the device, plugs it back in, and gets two or three more fast guesses before it slows down again.  Isn't that better for most of us than these consequences?  Thanks for having David on the show.  Perhaps their team, if not their competition, has already considered these improvements.



So just to summarize, he doesn't like it because you only get 10 tries.  And if an attacker tries eight of them or nine of them, then walks away, you may actually fry your own key.



STEVE:  Yeah, I thought this was an interesting question.



LEO:  Good point.



STEVE:  Yeah.  The point worth noting is that his attack model is different from what many other users may feel.  I could see users who have an IronKey, I mean, absolutely seriously don't want their data to fall into the wrong hands under any circumstances.  And so their model is, if I lose control of it, and someone tries to break in, and it's really not me, we're assuming we're not going to get it back when the guy is pissed off after trying eight times and didn't push it over the edge with two more tries which triggered the self-destruct.  So here we've sort of created a synthetic situation where somebody is trying to crack it, brings it very close to the point of its self-destruct, and then sneaks it back under our control.



LEO:  Never mind.



STEVE:  Uh-huh.  And then, you know, we kick it over the line.  So, I mean, I don't know.  I thought it was worthy of discussion, and it's a sort of an interesting issue.  I know that because I have so many different passwords, there are systems that I use, for example, well, I mean, many OSes adopt this slowed-down log-on approach where, if you miss the first couple, then you have to sit there and wait for 10 or 15 seconds.  And it's like, it's annoying when I'm trying to remember which one of my many passwords I used.  But it's sure better than having the hard disk wipe itself.



So it's like, I can also appreciate this notion of slowing it down.  I do think, however, that the typical model is I have lost my IronKey, I absolutely don't want anyone to have access to it.  Remember that I talked, I think it was last week, maybe it was the week before, I talked about the sort of the annoyance of a non-IronKey solution, which I myself use, my little 4GB little tiny Kingston RAM that I like so much, my little thumb drive, where I use TrueCrypt.  It's sort of uncomfortable that somebody who can't provide the password can still have my data in encrypted form.  That is, it's an almost 4GB file that is just pseudorandom data.  It's like, okay, well, they can't do anything with it.  But it's like, eh, but they could still copy it and have it and keep it and then be poking away at it.  And I have to say yes, but they really, really, really can't do anything with it.  I mean, that's the whole point.  And the strength of TrueCrypt is it is really, really good encryption.  But it's still annoying that they could have the file.  And IronKey prevents them from ever getting the file, the raw data off of it under any circumstances, right up to and including killing itself.



LEO:  Now, I should point out that you shouldn't only have one copy of your data on your IronKey anyway.



STEVE:  Correct, and that was the point he was making, a point that David, the founder of IronKey, made is that they provide a backup service.  I don't think I would use them, but I would certainly want to keep all of that critical data, I mean, basically everything I'm doing with my key, for example, my own case is I'm using it, as you mentioned earlier, sort of as a sneakernet.  I'm using it to shuttle stuff back and forth.  This morning, in fact, I was working on some outlining stuff on my laptop, and I copied it to my key to bring it back home.  I mean, I brought the laptop, too, but then I wanted to transfer it to my main machine.  And it was just easier.  Sometimes I'm doing that with Amazon's S3 and Jungle Disk, or sometimes I use my key.  So I've always got another copy of anything on my key.



LEO:  Right.  I think that anytime you have one copy of anything, you're going to lose it somehow.  And the point of all this encryption is not that it's your only copy, and this is a special, highly secure storage, but if you carry this key around and you lose it, that you're protected.  That's the real point.



STEVE:  Exactly.



LEO:  I am the kind of person, though, I have to say, who would forget his password, enter it 10 times.  I almost have to call my bank every time I want to enter the bank site because I've tried three times and the bank locks me out.  Every time.  So there you go.



A listener named Steve in Florida - good name - wants details.  Steve, says Steve, in describing your newly built Windows XP system you said, "For example, I've got every unnecessary process stopped so that when it boots it uses 131MB of RAM."  So which are unnecessary?  I've used BlackViper.com's list of services and disabled about 20, then found I might need one or two.  It's a pretty good site, but I'm sure we'd like to know your list of what we can disable safely for a given setup.  That's what Black Viper does.  You have gaming, standalone, home wireless network with fax/scanner, wireless laptop, desktop hardwired to router, and also acting as print server for a freestanding printer, et cetera.  Fewer unneeded services equals good.  So what do you think?  Do you have a list?



STEVE:  I use BlackViper.com.



LEO:  There you go.



STEVE:  BlackViper.com.



LEO:  He's the guy.



STEVE:  Yup.  When I was doing this I poked around.  I think I first learned of Black Viper when I was up with you, Leo, in Vancouver a few months back.  And I thought, oh, that sounds interesting.  And I'm very impressed with his work.  I looked at some other sites.  I also merged it with all of my own experience, although I don't have as much experience with XP as I do with Windows 2K and NT and earlier Windows.  But I found Black Viper's advice to be exactly correct.  I don't think I've - basically I used it as confirmation.  But there's some weird services that it's like, what the heck does this do?  And so it's useful to use somebody who's experimented with it, who's certainly had lots of feedback.  And this guy is known for his service-disabling site.  So certainly people are writing back to him and giving him feedback.  So BlackViper.com is what I use.  And it's terrific.



LEO:  It was gone for a while.  I was very glad when he came back.  He does it for Vista, too.



Matt in Virginia asks:  How secure is SSL VPN?  Steve, I have a question about VPN security, which I've researched extensively online.  And of course we've talked a lot about it on the show some episodes back.  He says:  You're my only hope.  Does an SSL VPN such as that offered by WiTopia or HotSpotVPN - or, I might add, Astaro - protect non-browser activities?  In other words, when I check my email through a desktop client, not webmail, with an SSL VPN enabled, will my login info be sent through the VPN tunnel and therefore be secure?  Will the contents of the email be downloaded to the client securely?  I've found that IPSec and LLTP are generally not options because their ports are often blocked by hotspots.  So what do you say?  Thanks for your help.



STEVE:  Yeah.  I mean, a VPN is secure, absolutely secure, so long as all of your traffic goes through it.  I'm a little uncomfortable about the way OpenVPN works because it uses a routing table and sort of dynamic changes to the routing table in order to hopefully route all of your traffic through the OpenVPN interface.  But it's finicky configuration-wise, and it makes me a little bit nervous.  It sort of seems...



LEO:  OpenVPN is not the only one that can do SSL VPN.



STEVE:  That's totally true.  And so any well-designed SSL VPN should route all of your traffic through the VPN.



LEO:  What is SSL VPN?



STEVE:  Well, okay.  We've talked a lot about HTTPS, you know, the protocol used for a browser to connect to a remote server.  SSL stands for Secure Sockets Layer.  It was originally designed by the Netscape folks when they wanted to add cryptographically strong secure connections between browsers and servers for the purpose, for example, of allowing people to transmit their credit card information to a web server through their web connection.  It has evolved through several versions.  SSL is now at v3.0.  And it's also sort of morphed into TLS, which is Transport Layer Security, which is sort of the formal official name now, although it still goes by SSL because that's how it was born.  And essentially it is a secure, certificate-based, strongly authenticated, strongly encrypting, point-to-point connection that can be trusted as long as it's all set up correctly.



LEO:  So when we talk about SSL VPN, we're merely saying that the VPN technology is - you can use different security technologies like IPSec or LPTP.  You're using SSL instead of IPSec.



STEVE:  Exactly.



LEO:  So it secures the whole thing.  It's not that it's the SSL for your browser, it's an encrypted tunnel using SSL for all traffic.



STEVE:  For all of your Internet connection traffic, yes, yes.  Whereas, for example, HTTP, which your browser uses, even though you may have a secure connection from your browser to a remote server, if you have no other VPN or security, when you do email it's not going through an SSL connection unless you've got email configured for secure connections, which you can also typically do.  So, and SSL VPNs are often more robust in mobile environments, exactly as Matt says, because, for example, IPSec and LLTP, as we discussed very early on in Security Now!, they use well-known ports that are not, for example, port 80 or port 443, which browsers use, or other ports.  They use well-known ports as part of their protocol, which many people who don't want VPNs to be used can block.  As he says, they're generally blocked at hotspots.



LEO:  Right, right.  You can't block SSL because then people wouldn't be able to go buy stuff on Amazon.



STEVE:  Exactly.



LEO:  Yeah.  Kyle Hasegawa in Tokyo, Japan - nice to have you, Kyle, listening to the show - is wondering about quantum crypto cracking.  It just sounds good.  Dear Steve and Leo, thanks for the great show.  You always mention the astronomical times it would take to break strong encryption using even the largest clusters of the fastest silicon transistor-based CPUs.  But what happens when government agencies begin to use quantum computing?  Will the trusty TrueCrypt be worthless against protecting ourselves against oppressive state agencies?  This is a question actually I've asked quantum computing experts.  And some of them, in fact, use that as an example, that yes, it would be easy to break.  It's a little early days, though.



STEVE:  Yeah.  Well, not only is it early days, and quantum computing still doesn't exist yet, and we're not even close to it existing yet, but currently 128-bit keys, symmetric keys, 128-bit symmetric keys, are considered incredibly strong.  I mean, here I am talking about astronomicals again.  But 64-bit keys are no longer considered safe.  But remember that every bit we have doubles the complexity of the key.  So when we add another 64 bits to the 64 bits we had before, I mean, 64-bit keys were considered strong for a long time.  I mean, they're still strong.  That's still a lot of bits.  But when you double that to 128, unless we're using 256-bit AES, where we've doubled that to 256 bits, I  mean, and these numbers are huge.  So, yes, if and when quantum computing actually happens, it's going to be way faster than silicon.  But I still don't think that we're going to have a problem with either 128-bit or 256-bit encryption.  This is, I mean, really, really astronomical.



LEO:  Well, but that's, I guess, the point of quantum computing is that you go from bits, from on and off binary bits, you go to three-state, four-state or, you know, systems which have that same astronomical geometrical factoring.  So these computers, if - you're right, it's pretty theoretical.  There are companies who claim they've built simple quantum computers.  But if this were to happen you'd have that same kind of, you know, geometric jump in computing power, as well.



STEVE:  Okay.  But geometric and astronomical, I don't know.



LEO:  Okay.  Yeah, I can understand where the question comes from because this is an example that quantum computing proponents use.



STEVE:  We'll have lots of notice.  We'll let our users know with plenty of time when they need to go to 512-bit encryption.



LEO:  Well, but if you're paranoid about the government, those are the first people who are going to use such a thing if it works.  And you may - they may not warn you.  I don't think the NSA is going to say, uh, guys, we've got quantum computing now.  You might want to double the strength of your keys.



STEVE:  Just want to let you know.



LEO:  Just want to give you a little heads up.  Chip Mason - I like the name - from Raleigh, North Carolina wants to revisit the good old PC vs. Mac security question:  Steve, I'm a longtime Windows user.  And while I've used Macs over the years, generally Windows is what I end up using due to legacy software and, you know, the amount of money I've spent on software.  I've recently listened to six hours of Security Now!, including episodes discussing nasty banking trojans and other issues.  And that got me thinking, maybe I should just switch to Mac and be done with it.  But my concern is Mac doesn't have these issues primarily because it doesn't have the market share to attract hackers.  I feel that Mac will get its trojans and viruses sooner or later.  But is that so?  Is there something inherently more secure about Mac with its BSD UNIX Mach kernel under the covers?  Actually it's really BSD UNIX and Mach kernel under the covers.  I know UNIX protects root and limits permissions very well.  But does this really mean viruses and trojans won't ever be a problem on Macintosh?  I'm guessing it would be my luck to invest, heavily, I might add, as Macs are pricey - they're not that much more pricey, I think really it's more getting new software that's the investment - and then find the same issues showing up on a Mac that I want to escape on PCs.  In other words, is it safe to move to Mac, or is it just going to - are the problems going to chase you?



STEVE:  And there's the question.



LEO:  It's a good question.



STEVE:  I know, Leo, that I turn my little Mac on an hour or two early every time we're going to be recording in order to give it the chance to update itself.  This morning I had a 50MB OS update and a 39MB Safari update.  That was 80-plus patches to the Apple OS and 13 patches for Safari.  I'm seeing, for whatever reason, a lot more of this security updating happening on my Macs than I have in years past.  My sense is that Apple is staying ahead of the curve, that is, that again, probably because it's a less large target than Windows and Microsoft, I think that the actual incidence of exploits of these vulnerabilities is still substantially lower than is the case for Windows.  But I don't think there's anything inherently different from the Mac in terms of some fundamentally more security than over on Windows.  And it's worth noting that there were, like, 40 problems that were patched at the end of last year in addition to the 80 that just got patched.  And I looked at a breakdown of them.  Half of the vulnerabilities repaired by Apple are in open source applications.  And Apache had 10 advisories.  The AV had nine.  MIT's technology had four, and PHP had 10.  And so the other half were found in Apple's own applications or components, with that first half being in open source.



So, I mean, we know it is difficult to write really, really exploit-proof software.  And I think Apple is in the same boat as Windows, and applications are in the same boat that the OSes are.  And that is, people are - the ante is being upped.  There's increasing value behind cracking into software.  And it's the eternal cat-and-mouse game.



LEO:  I will say that, I mean, we still have yet to see any big exploits on the Mac side, for whatever reason.



STEVE:  And I think that the Mac, and I've said this before on our podcast, I think the Mac does benefit from the horrible history that Windows and Microsoft had.  I mean, Microsoft now finally has a clue.  It took them a long time, an amazingly long time, to have a firewall running in Windows by default.  The second they did that, the second Service Pack 2 came out for XP, everything changed.  Well, the Mac learned that lesson with much less pain than Microsoft did.  So it will probably always have a better reputation than Windows.  And it's going to take a long time for Windows to shed the reputation it probably doesn't deserve now as much as it has it because Microsoft getting serious about security, we see that as an event in the not-too-distant past rather than it always having been the case.



LEO:  I'll also say that Microsoft suffers because it's an old operating system, and Microsoft has always attempted to preserve compatibility with legacy hardware and software.  To the degree that you do that, you compromise your ability to make a truly secure operating system.  Apple, probably because it had less market share, has been very quick to abandon legacy hardware owners and legacy programs.  They've done it before.  They recently did it with the move to Intel.  And by that - you know, it's a new operating system.  So by their willingness to do that I think they're also saying we're willing to take the hit and be more secure.  So, you know, I understand why Microsoft doesn't do that.  But maybe if they, well, look what happened with Vista 64, you know?



STEVE:  Well, and a perfect example, too, is we've talked about Vista when we were covering the security in Vista.  One of the things that we ended up making very clear was that Vista has a ton of fundamentally sound new security technologies which they have had to deliberately neuter for the sake of backward compatibility, exactly as you were saying, Leo.



LEO:  Yeah, yeah.  That's the tough one.  I think ultimately it comes down to that.  Certainly Apple is less of a target because there's fewer machines installed.  Hackers know Windows.  They know how to attack Windows.  And there's more profit in attacking Windows.  But I think they also benefit because they're willing to perhaps be a little less secure.



STEVE:  And the fact is, you know, there was a comment about how Macs are pricey.  Of course, that again, that's history.  That's really not true today.  So it is the case that hackers hack the machines they own.  They don't hack machines they don't own.  Traditionally people were receiving Windows machines for Christmas.  They have them at school.  Hacks had Windows.  Now the hackers have Macs.  And so we're beginning to see more Mac hacks.



LEO:  Right.  I don't think you're going to see a massive change in market share for Apple, however.  I mean, yes, market share's going up.  But you're not going to see - Apple's never going to be more than 10, maybe 20 percent at best.  Not for years.



STEVE:  Which is good for the Mac people.



LEO:  Yeah.  I mean...



STEVE:  It is.



LEO:  You're not going to be the dominant operating system.  It's just not going to happen.



John Hurst in New York City has a question about IronKey.  He says:  The rep from the company - well, that was our guest a couple of episodes ago - said they planned a number of improvements for the near future.  Will the buyers of the current IronKey device be able to update, or will they need to buy a new IronKey?  Well, I asked him that because I was wondering.  And he said they'd be updatable.



STEVE:  Yup, I wanted to make that very clear.  The question had been asked a number of times.  And so I finally said, okay, let's make sure everybody knows.  First of all, of course, this was not a rep.  This was the founder and CEO and chief techno bottle washer guy.  I mean, absolutely the guy.



LEO:  We don't talk to reps.  Ever.



STEVE:  And we did make it very clear.  We said, if we buy the keys now, will all this cool next-generation stuff be retrofittable?  And David said yes, absolutely.



LEO:  Yeah.  Which was really encouraging.  Justin Gerard, lurking somewhere in the USA, wondered about Firefox preaching:  Hey, Steve and Leo.  On Windows Weekly I heard about how Firefox was gobbling up - oh, I'm sorry.  Did I say "preaching"?  I misread it.  There's a "C" in there.  You know, it's interesting, you take out the "C," it is "preaching."  He said "pre-caching."  On Windows Weekly I heard about how Firefox was gobbling up tons of memory by using pre-caching.  And that is in v2, by the way, not in v3.  So I was wondering, if Firefox pre-cached a link with an exploit in it - oh, this is interesting - could it exploit the machine even though I didn't click the link?  So pre-caching is you go to a website, and it loads, starts to load all those other sites that are on that website before you click them.  He wonders if, by very virtue of the fact that they're loading those pages, could the exploit be triggered.  Keep up the great podcast.  I hope to be like you someday.  Aw.  Justin Gerard.  Oh, he's Gamer's Edge.  That's actually a great podcast.



STEVE:  Well, I'm glad to hear that because he's also the neat, I think he was either 12 or 13, who had the Best Buy computer guys, the Geek Squad guy came out and I think ran a copy of SpinRite that he didn't own.



LEO:  Oh, yeah, yeah, yeah.



STEVE:  And it was funny, too, because I used GRC's sitewide search.  I put Justin Gerard's name in and, wink, there were the - I got three hits on his name, thanks to Elaine's transcribing it.  So I was able to remind myself that, yeah, that's who I thought it was.



LEO:  Yeah, Justin's a great guy.  Great kid.  Who will undoubtedly succeed us and do better.



STEVE:  Well, and to answer his question, it's a really great question because, exactly as you said, what Firefox is doing is it's going and sort of going out and pulling in content that are referred to by the pages that you are - by the page that you are viewing.  The good news is, though, that it's not until the page is displayed that, for example, JavaScript is invoked, that active scripting comes into play, that the images of the page are run through the image rendering.  And it's the image rendering that can cause malicious JPGs or PNGs or whatever to get exploited.  So it's almost certainly the case that the pre-caching would not expose people to exploits from linked pages that you did not click on.  But it's a really great point.



LEO:  Yeah.  So it doesn't get exploited until you click on it.  Doesn't get - it doesn't run.



STEVE:  And I was curious, Leo, because I did not listen to that episode of Windows Weekly.  Apparently it's, what, filling up its cache with pages you never visit?



LEO:  Yeah.  So people had noted in the past that Firefox 2 takes a huge memory footprint.  And it's because it's loading these pages.  And I think that's bad 'Net behavior, frankly.  I think you're using bandwidth you shouldn't ought to be using.  It does speed up browsing, of course, and there have been programs that have done this in the past.  For years people had programs that would do this.  And I believe it is behavior that they have stopped in Firefox 3, which makes it more reliable, reduces the memory footprint.  And you know what, I have to say, everybody has broadband now.  It's not that much faster.



Hudson Seiler of Janesville, Wisconsin has a cautionary data recovery message for our listeners:  Steve, he says, I recently bought a dead and broken Xbox 360 hard drive.  I took the drive out of its proprietary Microsoft mounting mechanism - I guess once you do that you've got a standard SATA drive - and utilized SpinRite on it.  SpinRite not only allowed the drive to boot, but to my astonishment - whoops - it completely recovered the data of the previous owner.  I of course immediately deleted it, reformatted the drive, and it works great.  Thanks, Steve.  However, listeners of Security Now! should grasp the imminent security risk of having your gamer tag stolen - oh, that's a good point - because it contains your debit or credit card information.  Also, for security, store your gamer tag on a 360 memory unit.  That way if somebody does get your drive, at least they can't get your credit or email information.  SpinRite rocks.  Boy, I didn't even think of that.  But that's true, your gamer tag is on there, and password.



STEVE:  Yup.  So I thought that was a great thing for Hudson to mention.



LEO:  Thank you, Hudson, for reminding me.  You know, when you send your Xbox 360 - and Microsoft says detach the drive, do not send us the drive.  But if you were to sell the drive, that would be - or your Xbox, that would be an issue.



Now, our final question, it's really a statement, from Chris Noble of Wellington, New Zealand.  He brings us our Cool Firefox Add-On Tip of the Week.  Hi, Steve.  Just finished listening to your latest Q&A episode in which you discussed the problem of not knowing the URL with which a form is being submitted, or to which a form is being submitted, for instance is it secure or not.  But there is a Firefox extension, he says, just for you, called FormFox.  Have you checked it out, Steve?



STEVE:  No, I haven't.  But I posted the link because the way he describes it I thought, hey, this is very cool.



LEO:  I'm going there right now.  Let's see, will it install?  Yes, it will install in my beta version of Firefox.  "Do you know where your form information is going?  This extension displays the form action, the site to which the information you've entered is being sent."  In any place where you can enter data from search boxes to order forms, just mouse over the form and it will say where it's going, including the HTTP or the HTTPS.  So you'll know immediately if you're going to a secure server or not.  That's cool.



STEVE:  I think that's very, very cool.  I mean, I could easily wish that browsers just did this by default, is that you mouse-over the button and a pop-up tool tip gives you the URL, and maybe color-coded, green if it's HTTPS and red if it's not, just as some additional quick verification that it'll be a secure access when you press the button.  I thought that was a really nice little add-on for Firefox, and I wanted to let our listeners know.



LEO:  It'd also be useful if they were routing it through somewhere like, say, DoubleClick.



STEVE:  Exactly.



LEO:  He says:  I've used this, and it works a treat.  The form's destination URL is revealed in a little text pop-up when you mouse-over the button.  A very nice solution for security-conscious Firefox users without having to dig through the source code.  Thanks for the podcast.  Keep up the great work.  Thank you, Chris Noble.  We love tips as well as questions.  How do people submit or ask their questions?



STEVE:  They go to GRC.com/feedback.  And there is a web page form that they can put their question in.  Telling me who they are is optional, although we like to have that so we can, for example - that Chris is named Noble, Chris Noble in Wellington, New Zealand.  He volunteered that information.  And so that is fun to share with our listeners.  So I appreciate him sharing that with us.



LEO:  Very cool.  GRC.com is a great place to go, too, for your security software.  There's all sorts of little utilities, really fun stuff.  And of course the world's famous ShieldsUP!.  People go there to test their router, first thing they do when they set up a new router, go to ShieldsUP! at GRC.com.  And while you're there don't forget SpinRite, the world's best, the finest, the must-have hard drive recovery and maintenance utility.  GRC.com.  We also have 16KB versions of the show there for quick download.  Elaine has the transcripts up there so you can read along.  It's just a really great place to go.  By the way, when they do the transcripts of these Q&A sessions, Elaine just puts the entire question in its entirety, so you can just read it exactly as it is.



STEVE:  Yup, she asked me for the text so that she can spell everyone's name right.  And then I realized, hey, you know, the text is there, use the text and save on typing.



LEO:  Yeah, don't use Leo's fumfering around, just put the whole text right in there.  Steve, we're done with this episode.  That's great.  Next episode, next week, I'm still going to be in Australia, so we're going to pretape.  What do you want to talk about next week?



STEVE:  Well, there's been a lot of controversy about - and we've talked about this several times - about the issue of so-called "Network Neutrality."  And a lot of Internet engineering is going into looking at what the real problem is with essentially users essentially colliding with each other.  I want to talk about, not the politics because that's for the politicians, as always, but the technology of congestion and how congestion is handled and how it can be changed to change this.  This isn't directly obviously a security issue, but it's something that affects everyone.



LEO:  Well, it kind of is, kind of is.



STEVE:  Well, and it turns out, I mean, our listeners, as you were saying either this time or before, we have smart people.  And I think that if people understand some of sort of the key concepts behind congestion, because it turns out that, for example - I'll tease people a little bit this week.  Once you've got a network in place, the cost of using it is the same whether you don't use it or you use it all until congestion occurs.  It's when congestion occurs that is when you max out.  That's when you start having a cost associated with overusing it.  And it turns out that TCP does not do very well in congestion.  And there are other things like multiple connections tend to abuse the way routers handle congestion.  So I want to talk about all of that and sort of set some context for sort of some engineering and sort of a theoretical context for the impact of people using YouTube so much and downloading TV shows over the Internet and, like, what's happening as the model of how people use the 'Net is evolving from a technology standpoint.



LEO:  You know, I often say that there's two kinds of 'Net neutrality.  There's one thing if a company is trying to be anti-competitive and filter out any Skype calls so that they can charge you for their Voice Over Internet.  But there's also a legitimate need of a company to stop bandwidth hogs.  If there's four or five guys using BitTorrent to download the entire library of movies out there, it impacts your ability to get decent bandwidth and decent speeds, and their ability to make a living selling Internet access.  So I think it isn't unreasonable for companies to try to control some of this bandwidth and how it's used.



STEVE:  Yeah, I completely agree.  And in fact an old model of a network is the phone system.  And we know that the phone system is unable to handle everyone talking at once.  During emergencies, when people all try to get on the phone, nobody gets a dial tone because the system is unable to actually service the number of subscribers it has.  Similarly, no ISP is able to provide all the bandwidth simultaneously that they're selling to people because they use a model for how much bandwidth people are actually going to use.  That model is being skewed.  And as you said, Leo, when there are some hogs who are sucking out a disproportionate amount of bandwidth, and I guess I have to use the term "hog" provisionally because users can argue, hey, wait a minute, my ISP said that I have unlimited bandwidth, so I want to use it.  I want to get as much as I can.  Anyway, it turns out that the way the Internet's technology fails in the case of overuse is currently not optimal because it was never designed for what has happened.  And that's what we're going to talk about next week.



LEO:  Yeah, yeah, yeah.  I mean, some of it's they're cheap and they don't want to buy more bandwidth or have more connections.  But there's some legitimate need to control, as well.  All right, good.  That's a good subject.  We will be back next Thursday on April 10 with a great...



STEVE:  Never missing a week.



LEO:  Never missing a week.  Rapidly pulling away from TWiT because we miss weeks all the time.  In fact, I should mention that you've probably noticed that a number of podcasts are not arriving.  It's because - except for Security Now!.  It's because I am in Australia, and we're not recording This Week in Tech, Net@Night, MacBreak Weekly.  So we're taking a couple of weeks off.  I'm thinking of it as a spring break minus the over-consumption of alcohol.  So enjoy your spring break.  Catch up on the podcasts you've missed.  There are still podcasts coming out.  And we'll get - in fact, I'm going to be doing some, I think - you might check my blog, Leoville.com.  I should have pictures, blog entries, and even some audio available if I do put out podcasts or audio from the trip to Australia.  I'm going with some brilliant photographers, you know, this is our new Lightroom Adventure, and some of the greatest people out there.  So you can check, if you subscribe to the Radio Leo podcast, that'll get automatically pushed to you.  That's Leo.am/podcasts/leo.  That's the Radio Leo podcast.



Do you know about the Radio Leo podcast?  Some people don't, and I should mention there is one feed - you could subscribe to the individual shows like TWiT, Security Now!, and MacBreak Weekly.  But I made one feed - somebody asked me, well, I'd like a feed with everything that you do on it.  So there's one feed, Radio Leo, that has all of the shows that I appear on.  And there's also a feed of everything that TWiT puts out.  And that you can subscribe to.  That's the TWiT feed.  Actually the Radio Leo feed is, as I said, Leo.am/podcasts/leo.  The TWiT feed is through the TWiT.tv site.  It's actually Drupal does an RSS feed automatically of everything we put out.  And I think - let me just check to see exactly what the URL is for that.  It's http://twit.tv/ - let me just see what it is.  I think it's /node.  I want to get this right so I don't - let's see, show info.  Let me see if I can find the actual feed, dagnab it.  It's hidden here somewhere.  TWiT.tv/node/feed.  And that will be - what that is is an RSS feed with everything that comes out on TWiT.  Everything.  Not just stuff I'm on.  So there's Radio Leo if you want just the stuff I'm on.  If you want every podcast - and that's a good way to make sure you get everything that we put out, including blog posts and everything.  It's TWiT.tv/node/feed.



All right, enough of that silliness.  We'll be back next week with another episode because Steve refuses to miss even one episode.  I hope you'll join us.  We'll see you next time on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#139

DATE:		April 10, 2008

TITLE:		Net Congestion

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-139.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss an aspect of the "cost" of using the Internet - a packetized global network which (only) offers "best effort" packet delivery service.  Since "capacity" is the cost, not per-packet usage, the cost is the same whether the network is used or not.  But once it becomes "overused" the economics change since "congestion" results in a sudden loss of network performance.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 139 for April 10, 2008:  Network Congestion.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



Time for Security Now!, the podcast that helps you stay safe online, with our security guru, Mr. Steve Gibson of GRC.com and SpinRite fame.  Hi, Steve.



STEVE GIBSON:  Yo, Leo, it's great to be back with you.  We're approaching Episode 140.  This is 139, so...



LEO:  And TWiT is stalled in the water because I'm in Australia.  And so you...



STEVE:  Oh, darn.



LEO:  Oh, darn.  Pulling ahead now.



STEVE:  Yup.



LEO:  Well, good.  I'm glad we could do that.  Now, last week we promised we'd talk a little bit about, I guess, Net Neutrality and...



STEVE:  Well, it's sort - maybe, I mean, that's the only common jargon that I know of to refer to this.  But it's sort of really not that.  As I understand the Net Neutrality argument, you know, I don't have any real interest in the politics.  I'm Mr. Technology and Security more than filtering out or giving preferential bandwidth to one party or another.  But I know that the topic has come up.  We've talked about how some ISPs are, like, dropping people's connections.  They're, like, doing sort of nefarious, behind-the-scenes - and initially not admitting to doing so - sending spoofed packets at the connection endpoints of people, for example, who are using BitTorrent or downloading massive blobs of data, to sort or curtail them from doing that.  So I started doing some analysis and ran across much more that was going on, like in the IETF, in the Internet Engineering Task Force, about basically they're working on dealing with this huge transformation which has come about only really in the last few years as we've moved from using the Internet primarily for email and web browsing, and now for massive content delivery.  So I want to talk about it.



LEO:  And, you know, when they say "Net Neutrality," I think the biggest issues of Net Neutrality are the political issues involved, where an ISP, let's say Comcast, might block Skype traffic, not to protect its network, but for anticompetitive reasons, to protect their Voice Over Internet product.  We're not going to talk about that today.



STEVE:  No, and in fact one of the things I saw, maybe an even more annoying example, is this idea that an ISP could give preferential treatment to YouTube as a content supplier to their customers, versus some other content supplier that is not paying a premium to, like, get premium traffic treatment.  And that's what really has people upset is because, I mean, really then it really does bias this notion of all the content being treated equally.  And I think that underlies this issue of Net Neutrality.  What we're going to talk about today of course is not the politics.  I want to really discuss something we've never talked about before, which is what happens when you try to push too much data through a narrow pipe.  How do the fundamental Internet systems, routers and protocols deal with that?  Because it turns out it has a real, I mean, that's ultimately what's causing the problem is there isn't enough bandwidth.  So people are scrambling around trying to figure out, uh-oh, how do we react to that?



LEO:  Well, good.  That's good.  So we're going to talk about it from an engineering point of view in particular.



STEVE:  Right.



LEO:  Before we - we don't have - we are prerecording this before I go to Australia.  So I don't imagine you have any addenda from the three shows we've already recorded this week.



STEVE:  Well, I don't have, unfortunately, any security updates because for the last two weeks we're prerecorded.  And so we've been blind to whatever might have happened, and we're now into the beginning of August - I'm sorry, August - the beginning of April.



LEO:  In your dreams.



STEVE:  We'll be catching up next week with any important security news that has occurred since.  I had one interesting note that I found, actually this was email forwarded through Sue, my operations gal.  Someone named Dan Linder wrote.  It was something that I thought was really just kind of cute.  He said, on Episode 136 you mentioned some listener feedback pointing you to a Google search for detachable key ring.  Remember this was some guy who was sort of being just a little bit of a smart aleck and saying, hey, Gibson, you know, rather than having to TrueCrypt your thumb drive on your key chain, have you ever heard of a detachable key ring?  Anyway, so Dan, being a little bit of a punster, says, if you end up splitting your keys up like this, doesn't this become a physical implementation of your public key and private key?



LEO:  There you go.  It's true.  It's true.  That's very funny.



STEVE:  So I thought that was great.  I wanted to give him some credit for that.  And I did have - a question came up when I was running through all of our mailbag from last week in Q&A, a question that a number of our listeners have asked, so I wanted to share it and an answer.  And as it happens, this was bundled with his SpinRite story.  So I thought I'd incorporate that.  This is just - he identifies himself as Dave.  Oh, no, he says his last name in his Gmail, David Crisman.  And the subject was "A SpinRite story and a question."



He says, "Hey, Steve, I wanted to write in to thank you for all the work you've done with both Security Now! and SpinRite.  I've been listening from the start.  And in addition to being very interesting, many of the topics you've covered have greatly helped my understanding in the classes I've taken for my computer science degree, particularly the series you did early on about basic network technologies" - well, he's going to like today's episode, then, too - "as well as the discussions on various types of encryption.  I just had one question for you.  But first I thought I'd share the story of my personal experience with SpinRite.



"Last year, given my part-time job for the campus IT department, I came to be known as the guy to go to in my building when someone was having trouble with their computer.  So I wasn't too surprised when one evening someone came to my room asking for help with his girlfriend's machine.  I followed him down the hall, and a bunch of their friends were gathered around the room.  They explained that the computer was bluescreening on boot, and the girl who owned it was in tears because she was afraid that she had lost all the things she'd been working on for her classes.  I played around with it for a few minutes, but it didn't take long for me to realize that SpinRite could almost definitely do the job.  I told them I'd be back in a few minutes.  Unfortunately, being on the budget of a college student, I didn't yet own a copy.  After quickly checking to make sure I could afford it, I hopped onto GRC.com.  In less than 15 minutes I had purchased my copy of SpinRite, burned it onto a CD, and popped the disk into the drive of the offending machine."



LEO:  It's a small - what is it, 70K?  It's a very small download.



STEVE:  Yeah, it pissed me off when it went above 64 because it used to be...



LEO:  64K, folks, not 64MB.



STEVE:  It used to be a COM file.  Remember the old DOS COM, you know...



LEO:  They had to be under 64K?



STEVE:  Exactly, because they fit into a single segment of memory that you were able to address with 16 bits.  So it was 16-bit code that fit into 64K.  And it was a major revamp when it's like, oh, I can't...



LEO:  It's an EXE, oh.



STEVE:  I had to switch to an EXE and have multiple segments.  It's like, okay, fine.



LEO:  Boy, that's a long time ago.  Wow.



STEVE:  So he says, "It ran for about two hours.  Then all of us gathered around the desk to see what would happen when I turned it on.  Of course, it booted up, good as new, and all..."



LEO:  I bet he got a kiss for that.



STEVE:  I would hope, "...and all the files were recovered.  She greatly appreciated the help, and many of the people there asked about this great program I had used.  I pointed them all in your direction.  So hopefully you sold a few more copies as a result."  Or if not then, then perhaps when any of them have a problem.  So he says, "So thanks a lot, Steve, for creating such a great, compact product, along with a quick and easy system for acquiring it.  I know that my story isn't nearly as impressive as many of the others you've gotten.  No files worth millions of dollars, and it didn't run for months to do its job.  But I just thought I'd share it with you to express my appreciation."  Well, you know, his story was as great as any that we've received.  So thank you for sharing that, David.



He says, "Anyway, here's my question.  Do you have any advice or book or article recommendations for a newly graduated programmer entering the workforce, like me, to prevent the code that I write from becoming the cause of the next major PR nightmare security vulnerability?"  He says, "I realize that it's a bit of a broad question, and there may not be much I can do if I end up on a team where my work is only a tiny part of the overall project.  But I'd just be interested to hear your thoughts.  Again, Steve and Leo, keep up the great work, and thanks."



LEO:  Well, don't use strcpy.  There's number one.  Right?



STEVE:  Yeah, exactly.  Many people have asked, sort of at the similar stage in their career to where Dave is.



LEO:  It's got to be scary.



STEVE:  Oh, I'm not surprised we've scared people.  I mean, I'm scared when, literally, I mean truly, it's something that everyone who's writing code that's going to be exposed to the 'Net - and almost by definition these days, any code you write is Internet exposed.  It's got some Internet-facing surface.  The only thing I could suggest, I don't have any specific books, but I do know just sort of from general browsing that this topic has now been around enough and has been getting enough attention that there are a bunch of books that have been written about writing secure software, or security issues.  So I would just say go to Amazon and put "secure programming techniques" or something into Amazon, and I'll bet you will find a whole bunch of really interesting and essentially topical books that address the same sorts of things we're talking about all the time.



LEO:  I saw a good one the other day.  I think they sent me a copy of it, and I just can't remember the name of it.  Yeah, there absolutely are a number of these books.  And I think that this is - now that this is such a high priority, there's got to be more and more thinking about this, more and more than just use "strncpy" instead of "strcpy."  But yeah, I think you're right, go online and look because there's going to be a ton of stuff out there.



STEVE:  Yeah.  I think, I mean, I don't have any specific recommendations, I mean, I'm programming in Assembly language, so I'm not working with any higher level libraries.  I'm being extremely careful.  And that's the number one thing, I think, is just be thinking about this.  We've talked about how - the general role of programming, especially in a corporate environment or a team environment, where typically you're being pressed to be done.  Software always takes longer than we expect, so there's deadline pressure.  People are saying, is it done yet, is it done yet?  Please check your code in so we can do a build and we can start testing, blah blah blah.  I mean, all of that works against taking care.  I mean, it works against caution.  The focus is getting it done, making it work, rather than, okay, yeah, it works, but what if someone wants it not to?



And that's really the strange thing about software which I think for many people, for many programmers who really love programming, it's the thing they enjoy is that there's a mindset you get which is a belief that it's correct.  And it takes a debugger to rub your face around in the fact that you're wrong, that it's not correct.  And sometimes you can be staring at your own code, and it looks perfect until you step through it with a debugger that says, look, dummy, this is a zero.  And it's like, oh, you know what I mean, and you have to be shown so clearly where there's a problem.  And my point is that security is an even more subtle kind of bug because it's something you're just not used to seeing.  We're not expecting it.  And it makes writing really bulletproof code really difficult.  You'd have to look at your own code skeptically and really keep in mind what the challenges are from a security standpoint.



LEO:  It's one of the reasons modern programming languages have built-in testing in a lot of them, so that as you write a module, you test a module.  And it's just kind of an automatic process.  Anyway, good subject.  And boy, I have to say, if I were a kid in college studying this stuff, that would be probably job one.  You don't want to be that person that is the one in the headlines.  Shall we get to the topic at hand, network congestion?



STEVE:  Yeah.  I touched on it at the end of our episode last week, sort of teasing this episode a little bit.  So, okay.  Here's the issue, essentially.  When you think about a network infrastructure which is in place, meaning we've got the last mile connections by cable modem or DSL.  Then those all at some level get aggregated to what ISPs call their "aggregation router," which aggregates many of their clients' traffic into a single connection.  So then there will be an interface that has much larger bandwidth, so it's able to carry many of the tributary bandwidth feeds and aggregate it into a larger one.  And that'll then go typically to an even bigger router that is aggregating the traffic from many of the aggregation routers.  And so it sort of is a classic tree structure with many branches per node feeding together into a larger and larger chunk, which ultimately then gets routed to the ISP's peering partners.



And we've talked about peering in the past.  Some of our listeners, as many listeners write, they've been listening since Episode 1.  They'll remember when my T1 provider, Cogent, got into an argument with Level 3.  And GRC's networking technology, all of our servers and things are now being hosted in a Level 3 facility, in a Level 3 datacenter.  And I was unable, over the T1s that served me personally, I was suddenly one morning unable to reach my servers because Cogent and Level 3 that had this peering agreement got into a dispute, and Level 3 stopped peering with Cogent, meaning that literally there were chunks of the Internet that I as a Cogent subscriber could not get to because they were over on Level 3 side, and Level 3 said we're not going to permit Cogent traffic into our borders any longer.  So that lasted, I guess, a few days, and they settled their contract dispute.  But it was sort of an interesting wakeup call of sort of the infrastructure that we all take for granted.



Well, okay.  So now there's all this equipment in place.  There's bandwidth and pipes and routers and all that.  Now, when you think about data, data sort of being ephemeral, there isn't a difference in infrastructure cost as a function of how much that infrastructure is being used.  It's all in place.  If no one's using it, it costs just as much as if all the links are saturated because the bandwidth has to be there in order to carry the maximum traffic that the bandwidth allows.  The hardware has to be there in case it's needed to be used.  But not running it at 100 percent doesn't cost less than running it 100 percent.  So my point is that there is a fixed cost for the whole capability.  And until you start overusing it, there is no increased cost as you approach that saturation point.



For example, these, I mean, even at the higher level, these peering agreements are agreements between, for example in the case I was just citing, Level 3 and Cogent, where they don't charge each other for traffic transit.  They figure, hey, we're getting a reciprocal benefit.  We're getting a benefit that is balanced in our agreement.  So we're each benefiting equally.  We're just going to agree to carry each other's traffic.  And that's the way at these Tier 1 providers that they operate.  So it's only down at the retail level where you're negotiating with your provider about what kind of maximum bandwidth you're going to have and what you're going to pay for that.



Well, as I was researching sort of this general area of network neutrality, trying to sort of get a sense for what was going on, what I discovered was that there is a huge amount of work which is happening in academia and among the gurus that design our protocols that ultimately bubble up into new protocol support in hardware, like in Internet routers and in our own PCs that are Internet hosts, able to connect to the Internet.  There's a huge amount of work being done which we're currently unaware of, that is, very little of it surfaces.  And it's being driven by the recognition that we are really seeing a dramatic transformation in the way the Internet is being used.  I think it's pretty clear now that the Internet is not a fad.



LEO:  We can say that, yeah.



STEVE:  For a long people were, oh, that's just a fad, that's not going to happen.  I think Bill Gates was for a while thinking, oh, you know, that's just not going to happen.  He was doing MSN, it was going to be his - Microsoft was going to compete with CompuServe in the dialup modem pool to see who can have more dialup modems.  And then of course Netscape happened and caught Microsoft off guard.  And I think it's, as you say, it's pretty much established that the Internet is not a fad.



LEO:  Even Bill Gates agrees now.



STEVE:  I'm sure he does.  So what's happened is it's gone from sort of a messaging medium and a bursting medium, in other words, for example, when you're downloading a web page, you grab the page.  As our listeners know, the browser looks at the page, which calls out its need for additional resources, images of all kinds and maybe assets from other sites, and then the browser turns around and gets those.  So there's sort of an event of loading the page, and then it comes in, and we stare at it for a while and decide where we want to go from there.



So this transformation is in many different stages.  For example, you and I, Leo, right now are communicating through a VoIP application, Skype, that we use over the Internet, and able to achieve, since it's being recorded at your end, the people listening to the podcast are listening to me at the other end of an Internet connection.  And so now there's a persistent connection.  We are very sensitive to the amount of bandwidth that we have.  We are very sensitive to the percentage of dropped packets that we have and to packet delay, which is known as "jitter," in the arrival time of the packets because, if jitter were too great, bandwidth were too low, too much packet loss was occurring, my voice wouldn't sound nearly as good as it does.



LEO:  And we've heard that, actually.



STEVE:  Exactly.  I mean, it happens.



LEO:  You'll hear that on the shows from time to time.



STEVE:  Exactly.  Similarly, I was asking my sister a couple months ago, I guess I was up in Northern California during Christmas.  And I was sort of saying - so I have a niece and nephew who are in high school and college.  And I said, Nan, what TV do they watch?  And my sister said, oh, TV?  They don't watch TV.



LEO:  Oh, that's great.



STEVE:  They watch everything - no no.  They watch everything on their laptops.



LEO:  Yes, yeah.  Same with my kids, yeah.



STEVE:  And I guess that's the new model is you're using BitTorrent to download shows, or you're just hanging out in YouTube.  And we've talked about how there are companies that are deliberately blocking their employees' access to YouTube during the day after doing studies showing how large a productivity drain YouTube is because people are just wanting to sit there and click on these amazing videos which are popping up all the time.  So essentially what's happened is the newer content applications have put a huge drain, a huge load on the existing infrastructure.  Now, ISPs are happy to charge what they can for this additional bandwidth.  I mean, it used to be that a modem, you could actually use the original Internet over a modem.  The pages came in a little slowly, but they loaded, and they weren't nearly as big as they are now.  You certainly didn't have all this Flash and animation stuff jumping around, burning up bandwidth on every single page.  So there was much less bandwidth demand.  But certainly email was entirely practical over a modem.



Well, nowadays you can't take advantage of any of this next-generation technology without having substantially more bandwidth.  And of course people are noticing that they're having to pay for that.  Well, so we sort of laid the foundation that as long as the network is not overused, that is, it does not become congested, there isn't any problem with using it all the way up to its limit.  What happens, though, when we go beyond that, when we push beyond that?  The whole Internet, the genius of the design of the Internet is the fact that the designers realized you could have a workable system which simply operated on a best effort delivery principle.  That is to say, my computer puts a packet of data onto the Internet.  And so everything is packetized.  It puts a packet of data on the Internet that's got a destination IP.  And that goes to my router that probably translates the IP from my public IP to my - I mean from my private IP to my public IP, and then puts that out on my ISP's wire that goes to the closest router, which picks it up and sends it on.



And we've talked about how routing works, how at every one of these hops routers have routing tables and multiple interfaces, and all these routers are richly connected in a large network to each other so that there isn't just one route.  There's an optimal route, but you may have backup routes and alternative means for getting the data from one point to another, which provides a great deal of resilience to the whole network.  So individual packets are coming into routers' interfaces, and then the router examines the packet and then sends it out another interface.



Well, we also talked about how routers aggregate inherently.  Routers have lots of interfaces and are accepting packets on any of them and routing them out of any.  Well, it's possible for a router at any stage in this process to be receiving too much incoming bandwidth for it to send the totality of the incoming bandwidth - for it to fit out the bandwidth that it's trying to get out of.  So it's because you've got multiple interfaces, you might have just an overabundance of packets that are arriving through different incoming interfaces that coincidentally at this point in time, you know, a busy time in the evening or lunchtime, for example, the router just gets overloaded.  Just because of the fact that it's got multiple connections, it might be that the sum of the bandwidth of the packets that are trying to all go out of one particular interface won't fit.



Well, the first thing, the first solution is there are buffers.  So all routers have buffers on their interfaces so that the packets are put on the front end of the buffer, and then the buffer empties out of the interface.  Well, that helps little bits of burstiness.  That is, you would certainly want some buffer so that if, like, three packets all arrived on different interfaces at the same time, bound for a fourth one, they wouldn't all just instantly collide.  They'd be able to line up in the order that they were received and get their way out.  But you could still, over a larger, slightly larger period of time, you could have a situation where the persistent bandwidth that is being demanded on the outgoing interface is just not sufficient to carry all the packets that are arriving.



So the router, all Internet routers have the right to simply discard packets.  They just drop them.  And there are various strategies that have been devised for looking at the packets that are already in the buffer and trying to drop packets that are part of recognized flows, as they're called, a flow being a connection between one source IP and one destination IP.  So there are various strategies the router uses.  But ultimately a router whose outbound buffer is full has no choice but to discard a packet.  Well, and this is why we call it "best effort delivery."  Because essentially some host computer somewhere has been putting packets onto the Internet and trusting that they're going to get to their destination.



Well, we've talked about how TCP is a reliable delivery protocol.  What that means is that one way or another the TCP protocol will accept responsibility for getting all the packets through that the sending computer wants to.  They may be a little delayed.  They may be slowed down.  But TCP, the TCP protocol is responsible for getting that message through.  What happens is that when the packets finally arrive at their endpoint IP, at their final destination, the receiving TCP/IP protocol sends back acknowledgments.  And what it does is it looks at all the packets that it has received so far.  And the bytes in the TCP packets are numbered sequentially in order to solve the problem of packets arriving out of order, which can also happen on the Internet.



We talked about how there are different routes that packets could take.  And routers will sometimes send packets that are bound normally for a congested link, they may send it out an alternative route which could be faster, which meant that a packet arriving later at a given router ends up arriving sooner at its final destination.  So packets have sequence numbers that they carry that allow the final recipient to put them back into order.  Once it's done that, it looks at the highest numbered byte that it has received so far and periodically sends back an acknowledgment to the sender saying, I've received every single packet you've ever sent me in this connection up until this packet carrying this byte number.  So basically that acknowledgment says everything up until now I've received.



So what this simple solution does is it means that if somewhere along the way, anywhere between the sender and the recipient, a router is overloaded and unable to deliver a packet, it'll simply drop it.  All routers have permission.  And when you think about it, they have no choice.  I mean, they've only got a finite amount of buffer space.  So they end up just saying, fine, there's no way I can store one more packet in this buffer.  Everybody's trying to get out of this one popular interface right now.  I have no choice but to just say, sorry.  And so it drops it.  The router has no obligation to notify anybody.



And this is, again, part of the brilliance of the designers because they recognized that relying on routers that were congested to send some sort of help, I'm buried underwater message, well, that would just increase the congestion, even though it might be in a different direction.  I mean, it's essentially the goal is to minimize congestion.  So generating packets that are warning of congestion doesn't make a lot of sense.  So routers simply discard packets whenever they need to.  What happens on the sending end is the sender is receiving these acknowledgments from the far end which is saying I've received everything up until here.  Oh, now I've received everything up until here.



Well, what happens is, if acknowledgments don't come in in a timely fashion, the sender, using some timeouts which are cleverly designed to be adaptive and to just do the right thing in the vast majority of cases, the sender says, okay, there must have been a loss at some point because remember that the recipient might have received packets after the one that was lost because the sender could be sending packets ahead of the receipt of acknowledgment.  In fact, that is the way TCP operates.  In order for it to operate efficiently, it has permission to send packets ahead, assuming that the acknowledgments will be delayed.  So when an acknowledgment that it's expecting doesn't arrive, it starts resending - it backs up and starts resending packets from the point of its last acknowledgment, assuming that nothing since then has been received by the recipient.



Well, the other thing it does, because it assumes if a packet was dropped it was due to congestion at some part along the way, the other thing it does is it drops its speed in half.



LEO:  Ah, boy.  And therein lies a tale.



STEVE:  Well, exactly.  What happens is, so it drops its speed in half in response to what it assumes is congestion, and then over time slowly ramps it back up again.  So all TCP connections do this.  This is the way TCP works.  So everybody on the Internet is slowly increasing their transmission speed until they start seeing packets dropped, which they sense because the far end has stopped acknowledging the continual flow, the receipt of a continual flow of packets.  So as soon as they lose an acknowledgment, they cut their speed in half and start speeding up again.  Then cut in half and start speeding up again, and cut in half and start speeding up again, and cut in half and start speeding up.  So it's sort of the waveform is a sawtooth because it's slowly increasing, then drops in half, slowly increasing and drops in half.



What this does is it is generally - what it means is, the TCP is seeking the optimal transmission rate for the prevailing conditions from endpoint to endpoint so that any point among all these routers, any number of routers, a completely nondeterministic path, we don't have any idea what path the packets are taking to get there, we just drop them on the 'Net and cross our fingers.  And when we get an acknowledgment back we know that, oh, everything that I've sent up until this point has been received.



So what this means is it means a couple things.  It means that all TCP connections are treated individually.  So my connection from my browser to a remote server is treated in exactly the same way as somebody else's connection.  Because routers drop packets randomly, they basically just say, well, I would love to hold onto this packet, but my outgoing buffer is full on this interface.  I have nowhere to put it.  I've got to drop it.  So they drop them randomly.  What that means is that just statistically all of the packet flows that are moving through a router, for example towards a destination server, they're going to generally get equal treatment because the router doesn't love any one flow more than another.  It would happily route all the packets it was receiving if it could.  But, gee, there's just not enough bandwidth on the link that the incoming packets are all trying to use, so it's got to throw some away.



Well, a number of things have resulted as a consequence of this sort of equal treatment of flows.  What it means is that all of the connections that are trying to use a given pinch point, a given congested interface, because of the random dropping of their packets, all of the connections share equally in the available bandwidth at that point.  But that means that if somebody were to open more than one connection through the same two points, they would get a larger share of that total congested bandwidth.  Thus parallel file downloaders, which open multiple connections - I actually downloaded an updated copy of Corel Draw the other day.  And I was sort of curious.  It was downloading, and I'd been doing all this research, so I fired up netstat in a DOS box.  And sure enough, there were four established connections between my computer and Corel's server.  And it was using Corel's own file downloading system.  So what this meant was that if there was no congestion anywhere, these parallel connections don't really help because...



LEO:  Oh, that's interesting.



STEVE:  ...because I'm not getting any more bandwidth.  I'm not - it's their server...



LEO:  Well, it doesn't help in your case because your bandwidth probably exceeds any server you're going to.



STEVE:  Well, I guess my point is that...



LEO:  Oh, actually that's when it should help, when you have more bandwidth than they do.



STEVE:  Well, one connection, because it's what TCP is doing, where TCP is ramping up, trying to - running as fast as it possibly can, it would be, for example, if I were using a cable modem, it would be my cable modem's upstream bandwidth, or rather downstream bandwidth as I'm downloading it.  That would be the limiting factor.  So Corel's server would end up finding my maximum bandwidth point because the router trying to squeeze packets to me over my cable modem connection, it would have to stop dropping them - it would have to start dropping packets coming from Corel when Corel's TCP endpoint was sending them too fast.  So it would be slowing Corel down.  But one TCP connection would end up maximizing our connectivity so long as there is no competition at a congestion point.



LEO:  Well, but maybe it's designed to get around downloading sites that have a limit per connection.  I think a number of sites will do that.  They'll say no connection may have more than 500 kilobits.  So by opening multiple connections you could be getting around that.



STEVE:  Yes.  You would certainly be doing that.



LEO:  And I think that's the intent.



STEVE:  Well, and the other thing happening is, exactly as we were saying, given that routers that are congested themselves as opposed to the transmitting site - well, okay.  A perfect example is any sort of peer-to-peer program where you've got clients which are sending as fast as they can and recipients that are receiving as fast as they can.  There's no throttling going on there.  Everyone is trying to move these large movie files and TV program files or music files, whatever they are, they're trying to move them around as fast as they can.  So in the event of multiple connections going through a single congestion point, and that might well be your own - a router very close to you, your own ISP router.  So, for example, I'm using a parallel downloader, and my neighbor that's on the same network segment as me is just using his browser.   Well, because I've got all these  multiple connections open, if the congestion point is my ISP's router, which it probably is in that situation, then I'm getting an unfair share - well, I'm getting, I don't know, I guess fairness is a value judgment.  But I am getting a larger proportion of the bandwidth through the router because all of my connections are being treated individually rather than in any kind of aggregate.  And so all of mine are sharing with the total number of connections that are running through the router because packets are just being dropped at random, and TCP protocol that is running across this is having to do the best job it can of maximizing its rate of flow.



LEO:  Okay.



STEVE:  Okay.  So what this means is, this means that there is no cost to the network until we start having congestion, and that it is congestion at routers which begins to create some cost as we are trying to push the network beyond its capacity.  And so the position that is being taken by the guys that are designing these next-level protocols, they're recognizing that people who are opening lots of connections and who have them open for a long period of time, in this model of thinking about the use of the Internet, they're recognizing that it's almost as if you were to count the number of dropped packets that result from someone's use of the 'Net.  Not your own dropped packets.  But your use is causing congestion, which is causing everybody else to have packet loss.  And it's not just instantaneous loss, it's the sum of lost packets over time.



And so they're looking at ways to create some means for accountability.  And, I mean, it's a hard problem because there's no way for routers that are just sort of these autonomous packet-moving boxes, there's no way for routers to know anything about their users, the ultimate sources and destinations.  There's no way for them to maintain any kind of history.  And an individual end-user, for example, who's using a peer-to-peer filesharing system, they've got connections branching out from them in all kinds of different directions, going to different people, meaning that they're going over different routing paths.  So the only solution that people have come up with is some sort of system which looks at the current use and the history of use of individual users and begins to hold people accountable for their aggregate use of bandwidth over time.



And one interesting thing is that people have noted that, for example, say that my ISP's routers are super congested because there's a whole bunch of people using the system who are downloading large files for a long period of time.  Now I come along, and I want to look at a web page.  Well, it's aggravating to me if it takes a long time for me to bring the page up and to download the page's images because my ISP is so busy.  And the ISP is so busy because you've got all these other customers of the ISP downloading huge files over the course of many hours during this window of time.  And I just want to look at a web page.  The point is that I'm suffering because I want to bring up a page.  But my bandwidth requirement for the page is the same if it takes me a minute to finally get the page loaded or if I can bring the page up much faster because largely I'm going to now sit there and look at the page and then decide what I want to do next.



So there's this notion of looking at end-users' usage of bandwidth over some period of time and changing the priority of their packet-handling dynamically so that a user like myself, that isn't downloading big files, but just wants snappy use of the Internet to do a little Wikipedia research or to go find something on Google, looks at a few pages, it would be nice if I could click the links and have the pages snap up quickly.  And I'm going to be using the same amount of bandwidth, but the profile of use is different.  That is, I'd like the amount of bandwidth that I'm using to come in in three seconds rather than 30 seconds because that means that my experience is much better.



And there's one other aspect of this that affects this conversation, and that is, as packets are buffered more, their delay increases because then you have packet delay caused by buffers which are full, and that begins to affect realtime services like Voice over IP.  So again we want to minimize congestion.  We want to hopefully not overflow buffers.  But what's even better is if we can keep the buffers from becoming too deep because that way we're getting timely transmission of packets across the Internet and not having lots of jitter in addition to lots of lost packets.



LEO:  Well, it's all very exciting if it works.



STEVE:  Well, and the problem is, if you think the surface politics of this are hairy, you wouldn't believe the fighting that is going on in the technical committees because there are people who talk about flow rates.  And then there are people that talk about fair use.  And there people saying, well, wait a minute, what do we mean by "fair"?  And what is it that people are buying?  And end-users don't want variable pricing.  They want fixed pricing.  They want to be able to say, look, I want to know what it's going to cost me per month, and I want to know what I'm going to get in return.  Because of course lots of users are wondering whether they're really obtaining the bandwidth that they're purchasing.



And it's clear that ISPs - essentially we're going to have to have an evolution, one way or another, into a different sort of model where there is some sort of accountability so that ISPs are able to prevent their networks from being overused, at the same time allow them to be fully used.  Because certainly from an economic standpoint a fully used network benefits everybody.  The ISP's costs are the same if it's fully used or half used.  The end-users are happier if they're part of an efficient network which is being fully used because that means that, again from a theoretical economic standpoint, their cost is minimized because the ISP is not having to charge them for a network which is not fully used.



So what's going to end up happening is a change in the ISP's customer-facing contracts and relationship where what you're buying is a best effort delivery and availability, where people who are moving huge files may have their moving of huge files take longer, but there'll be a protocol in place so that people who are paying the same fixed price but not moving huge amounts of bandwidth over time will find that the network is always extremely sappy and responsive because this notion of congestion of the network from point to point will have been worked out so that the users of huge payload large bandwidth will end up having themselves throttled so that the network ends up getting used, but not overused.



LEO:  Is it possible to do some sort of just-in-time solution for bandwidth?  I mean, I know that streaming providers have this kind of setup where, when you need it, the bandwidth can kick in, and you don't pay for it until you need it.  Why don't ISPs do something like that?



STEVE:  Well, at some level that's going on.  For example, my relationship with Level 3.  I've got what's called a 95-5 billing.  I actually have a 100MB connection between the Level 3 aggregation router and my equipment.  I'm paying for 15MB, what they call "15MB commit."  I'm burstable up to 100MB.  So, for example, when I'm transferring a file from your server to mine, Leo, when I'm grabbing the Security Now! podcast, it's 25MB that I see, and it's a short burst, I've got the file.  It's like, hey, that's really cool.  I'm not sitting around watching the little bar, the meter bar slowly crawl along.  I'm able to go get the next one.  So it's a little bit of a burst.  But I'm paying Level 3 at the rate as if I were using 15MB 24/7, although frankly GRC's usage is more like 3 or 4.  But 15 is the minimum that Level 3 will sell because they're not wanting to have lots of relationships with small guys.  They're wanting to keep their contracts at a higher level.  There are Level 3 resellers who, again, I could have gone with a reseller and been able to purchase a much smaller chunk of bandwidth.  But I just didn't want a middleman in between me and Level 3.  And I've been glad for that.



LEO:  Yeah.  I'm trying to think what we have.  I think our TWiT servers are 100MB, yeah, 100MB uplink speed.  But I don't know what that means in terms of day to day.  They pace it figuring you're not going to use it all the time.  I mean, that's what's always happened.  It happened with modem pools.  You'd have five users per modem, figuring they're not all going to use it at the same time.



STEVE:  Well, and that's the classic example.  Remember, and I think I mentioned this last week, we know of our phone system that if everyone goes off-hook at the same time, the system collapses.   It's designed for typical use.  But no way does it have the switching capacity to allow all of its subscribers to be talking at the same time.  You just don't et a dial tone when you go off-hook.



LEO:  So you would overbill, but you just don't want to overbill too much.



STEVE:  Exactly.



LEO:  I imagine there's quite a bit of theory in how much you overbilled and how, you know, I mean, and I guess that's the point is a lot of that theory's out the window now that we're doing so much more online.



STEVE:  Right.  And the real problem is, none of the technology we have today solves this problem.



LEO:  Even fiber?



STEVE:  No no, I mean the...



LEO:  Switching technology.



STEVE:  Well, the hardware and the protocol.  We've got, I mean, I'm now running XP.  And...



LEO:  Aren't you modern.



STEVE:  Oh, baby.  And with the state-of-the-art TCP/IP stack.  And there is no technology in here today in our machines to begin to deal with this next-generation problem of how people who want to use a little bit of bandwidth but would like it to be snappy, how we coexist with people who are saying, hey, I bought a cable modem, and I have a $49 a month contract that says...



LEO:  Unlimited, baby.



STEVE:  Unlimited baby, and it's a megabit.  I want to use it all.



LEO:  We just bought a T1 from Covad for $379 a month.  It's only 1.5MB up and down.  But I presume that the reason you're paying all that extra money is because, first of all, you have a lot of upstream, but also it's kind of guaranteed.  It's low latency; right?



STEVE:  Oh, actually I'm glad you've done that, yes.  You've bought a full T1, which is 1.54MB, symmetric, both ways.  And assuming that Covad is a good supplier, and they are good, their infrastructure will allow you to move all of that 1.54MB 24 hours a day.  Well, in fact, T1s used to be voice links.  They carried 24 64KB voice channels on a single T1.  And many people used them for a long time.  Corporations wouldn't have 24 pairs of copper coming in, they'd have one T1, and then they would have a multiplexer that would turn that into individual voice channels inside their corporate facility.



LEO:  I'm just buying it on faith, although I have to say 379 bucks is a lot cheaper than they used to be.  They used to be 1,500 bucks.



STEVE:  Oh, I had a pair when they were 1,500 bucks.  And I'm glad now that I'm at Level 3 and paying less than that for my whole lash up.  So, yes.  Certainly prices have come down.  The problem is that what's happened in the last couple of years with this explosion in bandwidth, it has caught, well, essentially it's caught our protocols and our hardware off guard.  And unfortunately we've seen some first reactions from ISPs saying, well, we're just going to kick these connections which are using too much bandwidth.  And the reason they're doing it, Leo, is they don't have any other technology.  They would love to somehow throttle these flows if they had the capability to do it.  But there isn't the technology in the system I've described, there isn't the technology to do that.  So what they end up doing is spoofing packets and just shutting down users, which really upsets the people who are saying, wait a minute, I'm paying...



LEO:  I bought this.



STEVE:  Yeah, you said $49.95 and unlimited bandwidth.  Well, I'm trying to use my unlimited bandwidth, and you're saying no, we're going to send out dummy packets in order to shut your links down.



LEO:  Yeah, the specific technology that Comcast uses is called Sandvine, which is a Canadian company.  I think most ISPs use this Sandvine thing.  And that's exactly what it does.  It just turns off the peers.  It sends a message saying, yeah, we're done, you're done, we don't have anything more to offer.  Just cuts them off.  And I guess I understand that.  Aren't there - I guess you've just explained why there aren't - systems like Squid and so forth that would allow you to kind of throttle stuff down?



STEVE:  Yes.  Certainly there are approaches where you could put some technology near the end-user.  You need to put it, essentially, at the other end of the connection because if you go any...



LEO:  Don't want to throttle everybody, yeah.



STEVE:  Well, but more than that, you want to see all of that end-user's traffic. 



LEO:  Right.



STEVE:  If you put it too far away or, like, at your border, it'd be much more difficult in order to - you'd have to aggregate all of the traffic information from a single user into one point in order to know what they were doing.  But it's certainly the case that, for example, if you could aggregate all of the traffic that an individual user was transiting, then you could drop packets simulating router congestion before that congestion occurred and essentially throttle that user's traffic in a way that's not causing your network trouble and is not just simply dropping the connection and causing that problem.  But that's expensive technology.  And the ISPs are trying to avoid deploying it.  It's easy for them just to see the connection and have a router or a firewall or a traffic filter pattern match and go, oh, let's send this packet out, that'll take care of the problem.  And sure enough, that traffic is gone now.



LEO:  I have a good friend who runs a local ISP, Sonic.net here, which is very good.  He's been past-president of the California Independent ISPs Association, really smart guy.  We should get him on sometime and talk about what they do as an independent ISP.  He's very forward-thinking and I'm sure is very, I mean, you've got to be a little sympathetic if you understand this for companies like Comcast that are trying to ensure that the majority of users get what they expect, which is as you said, that snappy occasional service.



STEVE:  Right.



LEO:  And it's a difficult thing.  I wish they'd spend a little more - maybe if they spent a little more on infrastructure they wouldn't have to be so draconian in shutting people down.  I don't know.



STEVE:  Well, and I guess also I think that the stigma of peer-to-peer systems, the fact that people are downloading television shows and movies, I mean, it doesn't help the effort any that the ISP is able to say, well, this is copyright violating traffic anyway.  It's like, well, yes, but Net Neutrality says...



LEO:  It's not necessarily, though.  That's the point.



STEVE:  That's very true.  I mean, for example, someone downloading who wants to download all past 138 of our podcasts.



LEO:  That's legal.



STEVE:  They have every right to do so.  Just click a bunch of links, baby, and start sucking that down, 100 percent legal.  Yet it's going to use up a lot of bandwidth.



LEO:  A lot of Linux is distributed over BitTorrent.



STEVE:  Right.



LEO:  You can't make the assumption that it's an illegal - I hope they're not doing it for that reason.  Although remember, companies - unfortunately these are big media companies as well as Internet service providers, so they do in fact have a dog in that hunt.  They have some interest in shutting you down.  That's what we talked about at the very beginning.  Some of this may be political.  Some of it may be anticompetitive.  Only some of it is technical.



STEVE:  Right.  Well, and the fact is, as I mentioned, I think it was two weeks ago when I turned on my Mac, we were talking about security problems, I downloaded a 50MB blob OS X replacement and a 39MB blob new Safari.



LEO:  Right.  That's a lot of bandwidth.



STEVE:  Yeah, two big chunks of code.  But it's not because I'm doing anything wrong, it's because Apple wants to send me a new copy of the OS.  Every week or two.



LEO:  Hey, Microsoft just pushed out SP1 for Vista.  That means there are 150 million people downloading 150MB each.  Do the math.  There's a lot of traffic.  That's a lot.  And pretty much all at the same time.



STEVE:  And important because, if they don't get that, they've got security nightmares.



LEO:  That's right.  That's right.  So one last question before we wrap this up.  I find this fascinating because we're all dealing with it.  I mean, there's times I'll get online, and it's slow, and it's a beast.  And I don't know if I'm mad at my neighbor who's downloading all the versions of the "Terminator" movie, or if it's just that there's too many of us.  How does something like all that dark fiber that's supposed to be out there, how would that help?  Wouldn't that make bandwidth kind of free and plentiful?



STEVE:  Well, okay, a couple things.  There's a dark fiber which is linking Internet, essentially Internet backbone, which was overbuilt during the whole dotcom boom.  And then there's the notion of FIOS, where fiber will be coming to the so-called last mile, yeah, I mean into people's houses.  And the idea of end-users being fiber connected, I mean, it just makes my eyes cross.  I mean, in terms of the impact on the Internet backbone and infrastructure.  I'm sure as - our listeners have been around since pre-Internet likely, many of them.  And I remember that there is a change of behavior when your own last-mile bandwidth changes.  That is, I was using, as you were, Leo, for a long time a modem in order to connect to the 'Net.  And then when I got my T1s, or certainly when most people switched from a modem to a broadband connection, to either DSL, high-speed DSL or cable modem, it's like, whoa, just think of all the stuff I can get now.  I mean, so there...



LEO:  You do, you start downloading stuff.



STEVE:  You know what I mean?  Yes.  There is behavior elasticity in the type of connection you have and how feasible it is for you to do certain things on the 'Net.  And so what that means to me is that people who have fiber are going to be much more inclined to grab big chunks of stuff because now they can so much more easily.  I don't know.  I mean, we need some solution to this problem of the individual users getting a disproportionate use of limited resources is what it really comes down to.  So either you make the resources unlimited, or you come up with a means for explaining to people that, look, you can download movies, but your traffic, which we're now going to be able to recognize as such, is going to have a lower priority on our system than everybody else that just wants their web pages to come up snappy.  And we're not there yet, but ultimately that's what it's going to take.



LEO:  Well, I'm very interested to see how this T1 changes our experience as Skype users.  I've been - you have a T1 obviously you're using.  You always sound the best of all of the Skype participants here.  I have been using a shared DSL, I mean, it's business-class DSL, and it's 384 up.  But it's sharing it with my Internet access and everything.  And every once in a while it will degrade as my email client starts to download stuff.  Be very interesting.  I'm going to dedicate that T1 ultimately to streaming video.  But next time we do the show, next week I will have a T1 in here.  And we will see if it sounds any better.  I think we're at max anyway, aren't we?  I don't think it's going to sound any better.



STEVE:  It probably won't.  But I would imagine, well, first of all, DSL is going to give you a good connection so long as it's being fed with sufficient bandwidth and lack of congestion at the other end.  I would guess that having a T1 connection, you're just at a higher class of service.



LEO:  I'm high-class, yeah.



STEVE:  You're higher class, Leo.  You're going into a bigger router that is probably serving T1s.



LEO:  It's an Edgemark router for T1s, yeah.



STEVE:  So it's going to have enough upstream bandwidth to deal with all the T1s' total aggregate bandwidth, which means you're not going to have any problems there.  And then I would imagine it'll be a short hop, so to speak, till you're on the Internet backbone and over to me.  It'll be interesting to see, you know, right now - I remember when we've done packet traces, my traffic goes right up to San Francisco and then over to you.  It's funny, due to the Cogent/Level 3 connection, my traffic goes up to San Francisco and then back down to Southern California.



LEO:  No.  Well, I have DSLExtreme, and they are a Southern California company.  I don't know if they're peering with Cogent in L.A. or what's going on there, but...



STEVE:  Yeah.  It'll be interesting to see.  But you are switching over to Covad, that is a different outfit.  And I imagine we'll have just absolutely pristine connections.



LEO:  Won't that be nice.



STEVE:  And you'll be able to do other stuff at the same time.



LEO:  Well, I'll have a different connection for that, exactly.



STEVE:  Exactly, and so it won't interfere with our audio connection.



LEO:  I shut down everything so I don't interfere with it.  But I still surf.  I'm still looking at the web, and I'm still taking notes and so forth.  And so there is some usage.  You know, for people who use Skype, just to fill you in, Steve and I run the diagnostics as we go.  And you've never seen more than six, under the bandwidth monitor, 6,250 for the audio out; right?



STEVE:  Right.  That's as high as it will go.  It'll use 6,250.



LEO:  6,250 bits per second, is that what that is, or kilobit?  I don't even know what it is.



STEVE:  I would think that's probably 6,250 bits per second.  So, no, bits per second.  So 6.25KB.



LEO:  Which isn't that much, really.



STEVE:  No, because it's doing compression, and it's doing a good job.



LEO:  We also look at jitter, which is 20 right now, as low as I've ever seen it.  Roundtrip time is 30 milliseconds.  So this is probably as good as you're going to get on a Skype connection.



STEVE:  It's as good as it goes.



LEO:  Yeah, yeah.



STEVE:  I mean, Leo, you couldn't ask for better connection, better sound.



LEO:  It's pretty amazing.



STEVE:  It's way better than a telephone, yeah.



LEO:  It's pretty amazing, yeah.  Steve, always a pleasure to talk to you.  This has been very interesting.  And it's, I think, very important to understand how this works.  You know, sometimes when we talk about streaming Internet radio or streaming video - as we're about to do, that's really why I bought the T1 is for streaming video - I have to explain to broadcasters, it's a very different model, just as you were talking about.  It's virtually free as a broadcaster.  Once you put up the tower and the transmitter, doesn't matter how many people listen.  A million people costs you no more than 100,000.  But it's the exact opposite business model for data.  That's data, is the more people listen, the more data costs.  But as you point out, the cost doesn't get great until it's congested.



STEVE:  Exactly.  If you've got the network there, the routers don't care whether they're limping along doing a few packets, or whether they're saturated.  And neither do your network links.  All of those, it's capacity.  And once you've established it, whether you're using it fully or not, the cost is the same until you start overflowing.  Then you're essentially pushing cost back onto your customers because they're not getting what they're paying for.



LEO:  Right.  It's a hybrid model because it's like the broadcast model until it breaks down, and then it becomes more like a magazine model or some other pay-per-download model.



STEVE:  Right.



LEO:  Great to talk to you.  Thank you so much for your time, Steve.  I'm in Australia as this airs, but I will be back next week.  We will be on the T1.  They say they're going to install it on April 14th, so...



STEVE:  Cool, cool.



LEO:  We should - it'll be very interesting to hear if it sounds any better at all.  I bet it doesn't.



STEVE:  I think it'll just sound - it'll be consistently better.  We won't have any of those little occasional blurches and dropouts and things.  And we'll be doing our 39th Q&A for Episode 140, which our listeners will hear one week from now.  And we'll be going from there.



LEO:  Visit Steve's site, GRC.com.  He's got 16KB versions of this for those of you suffering from congestion, or just dialup.  He also has transcripts, so you can read along as you listen.  I think that's often very helpful on this show.  There's a lot of information packed in there.  And notes, other great programs, software like ShieldsUP!, Shoot The Messenger, DCOMbobulator, Unplug n' Pray, Wizmo, and of course the most famous, SpinRite, the ultimate disk maintenance and recovery utility, a must-have for anybody.  If you've got disk drives, you need SpinRite.  GRC.com.



STEVE:  It's probably worth mentioning, too, that listeners can send their feedback and questions...



LEO:  Oh, yeah, for next week.



STEVE:  ...and thoughts and even show suggestions to me at GRC.com/feedback.  And also one of the other benefits of the transcripts that Elaine does every episode is, once Google has found them, which it tends to find pretty quickly because the site's indexed by Google, you can then search all of the textual transcripts for keywords in order to find the podcasts that are topical or you remember us talking about something but can't remember which one it was.  So we've got sitewide search also in the GRC menu now.



LEO:  Very cool.  I love that.  All right, Steve.  Thanks a lot.  Have a great week.  I'll see you next week when I'm back from Australia for Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#140

DATE:		April 17, 2008

TITLE:		Listener Feedback Q&A #39

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-140.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 140 for April 17, 2008:  Listener Feedback #39.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, the podcast that talks about online security, privacy, hard drives, eBooks, and occasionally coffee.  Actually you're not as bad - Steve Gibson, ladies and gentlemen.  You're not as bad as Paul Thurrott.



STEVE GIBSON:  Oh, is he a major - that's right, I have heard Paul talking about coffee.



LEO:  Yeah, Windows Weekly has become in some respects the coffee show.  But you have - now, you still - the last time we talked about coffee was some time ago.  You had installed the plumbed espresso machine, which all gaze on in wonder.



STEVE:  Yeah, I've switched back over to Starbucks mode.  I get up now every morning at 4:40 a.m., believe it or not.  And I'm the first person into Starbucks.  It opens at 5:00.  And I read an hour and a half with my Kindle what's been going on for the last day.  So do about an hour and a half, about 90 minutes of news updating while I sip on my first quad Americana.



LEO:  Quad.  Only a quad?



STEVE:  Yeah, because, you know...



LEO:  What happened to the quintis?



STEVE:  I do quinti ventis, or quinti venti lattes.  But, yeah.  And when I'm traveling I'll do lattes.  I don't know why, but that's sort of my habit.  But normally just Americanas, mostly because I don't want to be drinking all that milk.  I don't need all that milk.  And then I take my second one - oh, and I prepay for two refills.  So then I take my second one to go.  At about 6:30 I pull out and then start the day.  And then about three hours later that's gone, so I go back.  And it's just sort of nice to get out of the house and stretch my legs and breathe some air and remember what the sun looks like.  And so then I get my third - my second refill, my third coffee, and that's my final one for the day.  And that's all we're going to talk about coffee.  I'll turn it back over to Paul.



LEO:  Back over to the coffee show.



STEVE:  Turn it back over to Paul.



LEO:  Wow, yeah.  But it's a good point.  It is kind of nice when you work at home all the time to have somewhere to go once in a while just to - I do the same thing for lunch.  I could eat lunch in, but I like to stretch.



STEVE:  Just to remember that there are still people outside.  I mean, there's still people wandering around.  And actually I had some lattes last week because I did a little bit of traveling.  We haven't mentioned this on the show, but next week's podcast will be my coverage of last week's really, really interesting RSA Conference 2008, as they called it, which is of course the industry's big, the preeminent major security conference.  I was contacted by them, and they said, hey, Steve, we noticed you're not registered.  How about if we give you full access to the conference and press credentials?  And I said, well, that'll be great.  So while you were in Australia taking pictures, I was in San Francisco looking at the street people and...



LEO:  And learning about security.



STEVE:  Yeah, exactly.  I'm not a city person.  I like my suburbs.



LEO:  I'm thinking - was it at Moscone, RSA?



STEVE:  It was at Moscone.  And I mean, there were some things, some memorable things.  I met the guy who misspelled the "referer" header.



LEO:  Oh, with one "r."



STEVE:  With one "r."  Remember you and I talked about that once a long time ago.



LEO:  Drives me crazy.



STEVE:  And I think my favorite little takeaway slogan, we've all heard how people say "Information wants to be free"?  Information wants to be free.  Well, at RSA they added another clause to that.  "Information wants to be free, and code wants to be wrong."



LEO:  Yes.  Isn't it true.



STEVE:  I love that.  Code wants to be wrong.  That's every bit as true as information wanting to be free.  And of course this whole show is about code's success in being wrong.



LEO:  We should rename the show to "When Code Attacks."



STEVE:  Yes, but when doesn't it?  As a matter of fact, that's a perfect segue into my first errata.  But I've got a bunch.



LEO:  Well, go ahead.



STEVE:  Okay.



LEO:  Go to it, and I'll do - we'll save the Audible for a little later.



STEVE:  Okay.  We had a big black Tuesday, the Microsoft 2nd Tuesday of April, where there were eight security updates, every one of them critical.  And probably the most notable - and I should say that there's much proof-of-concept code that's been released, and there is exploit code in the wild.  The most significant one is our old friend the Windows Metafile.  And I did a little research looking back, and pretty much every year - remember of course the classic Windows Metafile was the one that you and I, mostly me, made so controversial back at the beginning of '06, little over two years ago, where it was clear to me looking at the nature of what was wrong that this was just something that had been left behind but was originally put in on purpose.  Well, then a year later, around this time in '07, there was another major metafile problem.



And here we are in '08 with a serious one.  This affects both 32-bit and 64-bit OSes, Windows 2000 SP4, all supported releases of XP, Server 2003, all versions of Vista, and Server 2008.  I mean, it just - it's every OS that Microsoft has.  And quoting from Microsoft's own details, they said, "A remote code execution vulnerability exists in the way that GDI" - which is the Graphics Device Interface - "handles integer calculations."  So there's an integer vulnerability of some sort.  It says, "The vulnerability could allow remote code execution if a user opens a specially crafted EMF or WMF" - that's Enhanced Metafile or Windows Metafile - "image.  An attacker who successfully exploited this vulnerability could take complete control of an affected system."  Well, it would be affected then.  "An attacker could then install programs; view, change, or delete data; or create new accounts."  And then they say in a separate section, "In a web-based attack scenario, an attacker could host a website that contains a web page that is used to exploit this vulnerability.  In addition, compromised websites and websites that accept or host user-provided content or advertisements could contain specially crafted content that could exploit this vulnerability.  In all cases, however, an attacker would have no way to force users to visit these websites."  Okay, big deal.  "Instead, an attacker would have to persuade users to visit the website, typically by getting them to click a link in an email message or Instant Messenger message that takes users to the attacker's website."



So this is the new model of exploit that we're seeing are these web-based attacks that take advantage of the inherent vulnerability of web browsers, which is inherent just because, first of all, they're so complex.  And of course scripting is a big problem.  This isn't, in this case, a scripting-oriented problem.  This is a problem - actually it's a heap overflow vulnerability in EMF and WMF files.  And then there's another different stack overflow in Enhanced Metafiles.  So it's just like, oh, goodness.  Basically it means anything that can cause Windows to display a picture - and, I mean, that's opening your email with preview mode active or doing anything that shows one of these specially crafted images.  And you notice that Microsoft is now - they've enhanced their jargon here to talk about "or advertisements."  Because we have seen instances where ad content, ad imagery was not sufficiently vetted, or in some cases there's no vetting at all, where an ad server was hosting infected advertising images, without intending to of course, on a huge number of sites.



LEO:  It happened on MySpace.  It was a terrible thing.



STEVE:  Yeah.  So anyway.  So if for some reason it is not possible for people to patch, there is a registry tweak that can be put in to just disable metafile processing.  That's probably not a big deal because frankly, you know, metafiles are there.  They've been there from the beginning of Windows.  But they're not typical images in email or web pages.  As we know, web pages are JPGs, GIFs, and PNG files, typically.  So you could successfully disable Windows Metafiles.  And maybe that's what the corporate guys are going to do, use a script to push out a change to disable metafile processing.



LEO:  Because they don't really like to update all the time.



STEVE:  Well, exactly.  I mean, we've seen cases where updates cause more problems than they cure.  An update causes an absolute problem, whereas the vulnerability is a potential problem.  But I'm sure that our listeners are staying on top of this.  This was the standard Windows patch.  All of my Windows machines were showing a list of these problems that needed to be fixed.  Actually when I got back from San Francisco they were all waiting for me.  So anyway, it's just another typical black Tuesday.  This one, well, I guess we've had a couple non-event patch Tuesdays this year so far.  But this is a big one, so I just wanted to give our listeners a heads up and say don't miss this one.



LEO:  Boy, I tell you, I'm surprised that that's still happening with the Windows Metafile.  Aren't you?



STEVE:  Well, and across all the OSes, Leo.  Which says they're sharing code.  Maybe this is, like, 32-bit code that runs in a 64-bit context under the 64-bit OSes.  Or it was a problem that existed even in source that survived compilation into a 64-bit target environment.  I mean, it's amazing to me.  But it's like, whoops.  I mean, this stuff is really complex.  And as we know, our new slogan is "Code wants to be wrong."



LEO:  Apparently it does.  Apparently it does.



STEVE:  I noticed when I was doing a little browsing around, I thought I would mention a little preemptively - or maybe it won't be by the time this is heard in two days - we're about to cross the four million Perfect Passwords delivery on GRC's Perfect Passwords page.  It's about 3,600 a day are being generated.  That's actually sets of passwords, so there's actually more than that many.  I think it's, what, three different variations twice.



LEO:  I thought your page was more a demo of the fact that it could be done, not the place to get...



STEVE:  Oh, no.  People use it as a source of entropy.  They go there, I mean, and of course we've read in our Q&A, hey Steve, I'm using one of your Perfect Passwords to protect my WiFi.  I don't blame you for not being able to type those in, and then they give us their tips for how they manage to type them in.



LEO:  Oh, you're not talking about the Perfect Paper Passwords, you're talking about the Passwords page.



STEVE:  Correct. 



LEO:  That's my confusion.  When you put "perfect" in there, now I'm confused.  Okay.



STEVE:  Right.  It's not the Perfect Paper Passwords, and you're right, that's just a demo.



LEO:  The 64-byte crazy web key.



STEVE:  Yeah.  I use them myself whenever I just need something.  I'll just go get one there because it's safe and guaranteed to be unique, blah blah blah.



LEO:  Boy, no wonder.  That's a lot of passwords.



STEVE:  Four million, yeah.  And I just wanted to see...



LEO:  Did you see, by the way, the entropy problem that - was it the Maryland State Lottery was having?



STEVE:  No, interesting.



LEO:  They were using a random number generator.  Let me make sure that this is correct.



STEVE:  Ooh, but it was a bad random number generator?



LEO:  It was.  And they got a - it was one of those power - the short ones, like the numbers game?  And they got 7077, 7707, 7007.



STEVE:  Ooh.



LEO:  It was kind of a problem.  Kind of a little bit of a problem.  I have to - let me not libel the Maryland State Lottery.  I'll try to find out which lottery it was.  But there was a state lottery random number generator that didn't work so well.



STEVE:  I did want to give our listeners a little bit of heads-up on my early experience with my monster quad core workstation.  I wanted to say that the quad core seems to be a total waste as a personal workstation.  If you're going to- unless you would be using that machine for media compression.  It is just a killer solution for media compression.  Oh, my god, Leo, is it fast.  It's just unbelievably good.  I mean, it...



LEO:  Well, because you're using a tool, whatever it is that you're using to do the compression, that is multithreaded.



STEVE:  Well, yes, it's multithreaded, and it's multicore.  I mean, it recognizes what you've got, and it really uses it.



LEO:  But you won't see any benefit - that's the real issue is I think a lot of programs aren't multicore aware.  They're not SMP aware.  So you won't see any benefit.



STEVE:  Well, and that's just it.  I'm looking at this thinking - and I wanted to give our listeners a heads-up.  My feeling is, if I knew now what I knew - if I knew then what I know now I would have gone with a state-of-the-art, top-of-the-line, single-core, maybe dual, but go for the 3.something gig rather than slowing down in order to get four cores.  Because I rarely see more than one ever in use.  It just doesn't happen in a personal workstation environment.



LEO:  Well, having had much experience with this, I can tell you it really depends on how you use your computer.  If you don't have many - it works very well if you have multiple programs running simultaneously.  And your OS is smart.  You're using Windows.  If the OS is smart enough, it will divide those tasks up.  So I have many - I use a quad-core processor also, dual Xeons.  And I run a CPU, as I'm sure you are, a CPU monitor.  So I see when the cores are used.  And you're right, if you're just, you know, if you're using one or two programs at a time, and they're not multithreaded, you're not going to see much benefit.  But if you're using a multithreaded program, or you're using - your OS is smart enough to divide tasks among separate programs, then you'll see a benefit.



STEVE:  Well, but I guess, I mean, most Windows programs, and I'm sure Mac is the same way, they sit there in their idle loop waiting for input.



LEO:  Right.



STEVE:  And so I guess in my own personal use - I'm reading email, I'm writing code, I'm in an editor, I'm browsing the web, I mean, I'm not - there's nothing I'm doing where programs are, like, really busy all the time doing things behind the scenes.  The only thing I can really think of would be image compression, would be big media file compression.  And there you just sort of want to go away and not try to use your system at the same time.



LEO:  I have a few programs that will use all four processors pretty heavily.  So it really, it does, it's totally dependent on your usage.  But occasionally I will peg them.  Right now they're not.  They're all sitting there.  I've got Skype running, I've got a browser running, I've got email running.  Nothing's happening.  Two percent, all across the board.



STEVE:  Well, I did have a nice little note from Matt Ludlum in Weybridge, London, who made a comment from our prior Q&A where there was a - we mentioned a Firefox add-in which if you - it allowed you to hover over the Submit buttons of forms, and it would pop up a little window showing you the URL.  And he mentioned something that I had not noticed before, and that is that IE7 has that functionality built in.  I went back and looked at IE6.  I've now got VMware installed on this workstation, so I can run multiple versions of Windows, each with their own version of IE.



LEO:  There, by the way, would be a good multicore use.



STEVE:  Yes, and actually it is.  I did notice that when those were doing something, VMware was good about borrowing some more of the system resources.  Of course, there what I really wish is that I could put more than 4GB in a 32-bit machine.  Because, boy, RAM is so cheap now, and VM as we know, virtual machines just burn memory because they all like to have their own.  Anyway, Matt's point was very well taken.  IE7 you're able to hover over Submit buttons.  And down where it normally shows you the linked text when you're hovering over normal links, it also now does it for Submit buttons, which I thought was very nice.  Yeah, so you're able to check the security state before you click.



And then finally Elaine, our illustrious transcriber, she sent me a note shortly after that last round of many podcasts you and I recorded before you were taken off to Australia, and she said - and I have a little note here that I left to myself so I wouldn't forget to mention it.  I said, "Elaine reports," quote, "the Carlsbad Caverns are in New Mexico."



LEO:  Yeah.



STEVE:  And I was saying that I was thinking they were in Carlsbad, California, and we said something to that effect a couple podcasts ago.



LEO:  I wasn't listening, or I would have mentioned that.



STEVE:  So she said, "Carlsbad, California is the home of the expensive spas, not creepy bats."



LEO:  Right.



STEVE:  And she said, "I have a feeling you may hear from some of your less geographically challenged listeners on this."  And I wrote back and said, "Yeah, I don't get out much."



LEO:  Too many people.



STEVE:  Yeah.  Wrong Carlsbad.



LEO:  Carlsbad, New Mexico.  What'd she say, New Mexico?



STEVE:  Carlsbad, New Mexico.



LEO:  You know, we went in caverns - a cavern, the Marakoopa Caves, in Tasmania, that were quite awesome.  I have a few pictures of that.  Quite amazing.



STEVE:  Cool.



LEO:  Caves are fun.  But to the bat cave, Robin.  Actually, before we do that - we do have listener feedback.  This is Episode 39 of our listener feedback.



STEVE:  And Episode 140...



LEO:  I was wondering when you'd mention that, yeah.



STEVE:  Ah, baby.



LEO:  You've passed TWiT.



STEVE:  Yeah, passed TWiT, and we've got 10 to go till we're at the magic 150, which is a nice round number.  Well, I have an interesting note that I wanted to share because it sort of describes an interesting journey that somebody had with TrueCrypt and Macs and PCs and SpinRite.  This is Jonathan Schmidt, from Ohio, who writes, he says, "SpinRite saved my Vista Mac."  And he says, "Hi, Steve.  I've listened to you on Security Now! since the beginning, and I really appreciate all you do for the Internet community.  You, too, Leo.  In fact, because I love your podcast and the others at the TWiT network, I signed up for the automatic PayPal payments..."



LEO:  Thank you.



STEVE:  "...and send $5 a month.  I know it's not much" - well, I think that's pretty good, actually.



LEO:  No, it's more than I even ask, so thank you, yeah.



STEVE:  Yeah.  He says, "I know it's not much, but I hope it helps."  It certainly does.



LEO:  It does, yeah.



STEVE:  "In support of you and your efforts, I also purchased a copy of SpinRite, which is the reason for this email.  In the recent episodes of Security Now! concerning whole-drive encryption, I got the itch to try it out.  I downloaded the latest version of TrueCrypt, 5.1a, to try on my MacBook Pro running Vista via Boot Camp."  So that's the dual-boot mode.  He says, "Incidentally, 5.1a's bootloader now supports Intel Macs."  So that's cool.  He says, "I first ran into a problem when trying to encrypt my Vista partition.  Apparently TrueCrypt doesn't like the partition table set up by OS X and Boot Camp.  It said that there was not enough room available on the drive to install itself.  So I did some digging and found out that you can actually install Vista directly on a Mac without OS X.  All you have to do is boot from the Vista install disk and remove all partitions, and then install Vista just like any other Intel machine, no hacking required."



LEO:  Right.



STEVE:  "I proceeded to go through the Vista install just like any other Intel-based machine."



LEO:  There's only one problem, which is you don't have the OS X drivers, but we'll address that.



STEVE:  Ah, right.  He says, "I proceeded to go through the Vista install just like any other Intel-based machine.  After the clean install I ran TrueCrypt 5.1a and started the whole drive encryption with three-pass wipe to be safe."  Wow.  And he says, "Voila, everything started working.  TrueCrypt began encrypting the whole drive.  Unfortunately, when it got to about 78 percent of the way through, TrueCrypt gave me a CRC error, indicating that it was a problem with my drive.  Although I tried several times to continue, TrueCrypt gave me the error every time.  I thought, crap.  I went through all this work only to have a drive error.  Now what do I do?  Then I thought of SpinRite.  Of course, SpinRite doesn't run on a Mac.  {Hint, hint.)"



He says, "So I pulled out the drive and stuck it in my regular Intel desktop.  I ran my copy of SpinRite overnight at Level 4.  Sure enough, this morning when I came down, SpinRite reported that it found and fixed an unrecoverable error.  I popped the drive back into my MacBook Pro and powered it up, and TrueCrypt prompted me to pick up where it left off.  I did so, and it did not give me an error this time.  It is continuing to encrypt the rest of the drive as I type.  Pretty amazing.  SpinRite saved my Vista Mac.  I always knew that SpinRite would come in handy someday.  Thanks so much, and keep up the great work at GRC and Security Now!.  Sincerely, Jonathan Schmidt."



LEO:  Excellent.



STEVE:  And, let's see, there was one thing I noted.  Oh, when he said that TrueCrypt didn't like something about the partition, I'll bet I know what that is.  I'll bet that when the Mac was repartitioning the drive and set up a boot sector on the Vista partition, I'll bet that it didn't zero out the rest of the track, and that when TrueCrypt, being as careful as it is, looked at that first track of the Vista partition, it saw debris there, whatever happened to be there before.  But it just assumed that it was something horrible like Macromedia junk.  Or it saw that apparently...



LEO:  The copy protection that Macromedia uses, right.



STEVE:  Exactly.  I mean, it probably saw there was something there.  Normally that track is all zeroes.  And so I'm sure the TrueCrypt guys take a look at that and make sure that it's zeroes before they install themselves.  And they probably saw that it wasn't and said, ooh, you know, whatever's there, we don't want to hurt it, and we can't go in here.  So that may very well have been what caused the problem for him.



LEO:  Yeah, it's very careful about these things, which is as it should be.



STEVE:  Absolutely, yup.



LEO:  And it sounds like he was installing, instead of running Mac at all, he was installing, I mean, I'm not sure, maybe I misunderstood him, but...



STEVE:  I think he wiped Mac OS X off the machine completely.



LEO:  You do want to use Boot Camp.  And the main reason that this procedure, I wouldn't recommend this procedure, is that one of the things Boot Camp does is make a CD with Vista drivers for the Macintosh hardware.  Otherwise you don't have drivers, specific drivers for the hardware.  So do at least do that, create that CD.  Then you can wipe it.



STEVE:  Right.  And then you use that to install the Mac drivers for the hardware.



LEO:  Right.  So what normally happens with Boot Camp is it does the partitioning, then you install Windows.  But before it does that it makes a CD of drivers.  After you install Windows, you put the CD in, you install the Mac hardware-specific drivers.  So if you don't use Boot Camp at all, you won't get that disk, I guess is what I'm saying.  But you don't have to use Boot Camp, of course not.  I don't know why you'd buy a Mac to run Vista only, but you can, if that's what you choose.  Shall we get to the questions?  We have a lot.



STEVE:  Yup, let's do it.



LEO:  Let's do it.  Let's read those questions.  What did I do with them?  I put them away.



STEVE:  That's your announcer voice.



LEO:  Let's go to the questions.  As soon as Leo finds the questions.  I have about 80 windows open at the same time here.  You know, I think I've put them away.



STEVE:  No wonder you have quad core.



LEO:  You see, now you know why I need it.



STEVE:  Actually I sort of shut things down and keep the system from getting...



LEO:  Well, I do.  What I really don't want it to be doing is running Internet processes.  There it is.  But I do have other processes running because that's one of the reasons you might want a quad core is for the headroom.  I guess that's what I would say is it's all about headroom.  So that when you need additional cores - like I'm seeing right now as I look at my graph that there have been a few spikes during this.  But I don't have to worry because I know that Skype running in its own process there, in its own processor, is not going to run out of juice.  So it's about headroom.  For me, anyway.  And you're right.  And I have several quad core machines.  And it may be that Windows doesn't do as good a job of dividing tasks up.  I don't know.



STEVE:  Yeah.  I just, again, I'm happy saying to our listeners, you know, maybe just go with a fast dual core or a single-core hyperthreaded processor, and go for more speed.  I think for typical users, unless you're into media compression, or literally having things really doing number crunching at the same time, I think it was a waste of money.



LEO:  Really.



STEVE:  Yeah.



LEO:  Well, see, the interesting thing is that basically you're not getting a choice these days because Intel has decided that everything's going to be at least dual core.



STEVE:  Right, and in which case you've got multiple cores, and that's a good thing.  But for me, given what I understand now, I don't think I'd do it again.  I think I'm seeing these are underutilized.  And I'd rather have more speed and fewer cores.



LEO:  Well, I don't even know if you get that choice anymore.  But...



STEVE:  Right.



LEO:  Okay.  Message to Intel.  You might want to look at an AMD chip.  Chris Clark from Western Australia's Perth - I didn't make it to Perth.  Apparently nobody makes it to Perth because it's in Western Australia, far away from the rest of the continent, whatever you call that.  It's not a continent.  It's a big island.  Let's his fingers do the walking:  Hi, Steve and Leo.  I've been wondering what you'd think of a technique I've used for a long time to create passwords that are easy to use despite their apparent complexity.  He says he uses muscle memory.  I create a simple geometric pattern that moves my fingers around the keyboard in a way that makes the output look like complete gibberish.  The pattern is simple; the resulting password is not.



Basic example, start at the bottom left-most key of the U.S. QWERTY keyboard, hit the first four keys - bottom left-most key.  So that'd be zxcv.  Move up a row and so on, be asdf, then qwer.  And then he adds 1234.  After a little practice the keystrokes become second nature, can be tapped out in a second or two.  That's true.  That would be easy.  Even though it's a nice long password.  As an added bonus, since you're memorizing the pattern, not the text, your eyes and brain never really learn the password.  I don't know why that's a bonus.  Only your fingers know the secret.  Obviously my own finger-dance is a lot crazier.  Oh, good, because I was going to say that one is probably one of the first things a hacker would guess.  It's a lot crazier than the example that I gave just now.  But you can see how even the simplest example could produce a longish password that looks pretty random.  Maybe "looks" is the operative word there.  Even if strictly speaking it's not random at all, would a password like this stand up to a sophisticated brute-force attack?



STEVE:  Well, it was an interesting question.  My concern is that it sort of sounds like this methodology results in using a single password a lot.  And we know that it's generally a bad idea to use one password as, like, your password, and reuse it wherever you go.  We understand it's much more secure to somehow have a system that generates different passwords for different uses.  So I wanted to throw the question in because there's some interesting ideas here.  For example, if you had an algorithm that was more sophisticated, for example, like the first letter of the website is your starting key on the keyboard, and then you do something.  You go up if you can; otherwise you go down.  You go right if you can; otherwise you go left.  But, I mean, you could imagine an algorithm where starting at any given location on the keyboard you could do something consistent that would generate a password which is very unlikely to be found in any kind of a brute force.



First of all, when he talks about a sophisticated brute-force attack, you'd first be exhausting your dictionary, and then combinations of words, it's very unlikely that an attacker would start attacking the physical location of keys on a keyboard.  And frankly, there's so many possible algorithms.  Of course in a typical keyboard you've also got diagonals, not just up and down.  You've got up left, up right, down left, down right.  I could see coming up with an algorithm that could, given any starting place, could consistently generate an interesting password.  So there's something to it.



LEO:  I'd be careful about some of the more obvious combinations, though.  I think that probably brute-force attacks include things, look for things like ASDF and go, oh, keyboard...



STEVE:  Oh, yeah, and doing QWERTY, you want to stay away from that one because it's probably in the dictionary.



LEO:  It wouldn't be so difficult, frankly, to write a brute-force attacker that includes some of the more obvious keyboard algorithms.  I'd be careful about that.



STEVE:  Yup, absolutely right.



LEO:  Someone who asked us not to use his name from Tennessee wrote he strongly disagrees with advice about old operating systems:  Steve, I usually agree with what you have to say, but I thought your advice about old operating systems on Episode 136 was way off base.  In many cases the vulnerabilities that are found in newer operating systems exist in the old ones.  Not always, of course.  For example, wasn't the animated cursor exploit one that went way back?  And some of the most recent networking holes went way back into old operating systems.  Well, we just talked about WMF, which goes way back.



STEVE:  But not that far.



LEO:  Not that far.  And some of the most recent network - oh, yeah.  I'm aware of at least one incident involving an employer in my area where systems were compromised and information stolen.  The hack involved older operating systems, past end of life, that were on a network.  Employees received malware in an email that infected their systems.  The malware then went through a series of known exploits for unpatched and past-end-of-life operating systems.  I'd argue that the only safe way is to run a system with an OS past end of life is, A, to ensure it's never connected to an Internet-connected computer, air gapped - that's a good word, I like that, air gapped - or that it is behind a well-configured external firewall that only permits absolutely necessary and well-monitored traffic through the outdated system.  That makes sense.  I'd agree with him.



STEVE:  Yeah, and I have to, I mean, I still like the idea of using 9x-era machines, 98 2nd Edition, for their relative invulnerability.  They have, for example - none of the exploits in today's or this month's Patch Tuesday affects those older machines, for example.



LEO:  Well, you wouldn't expect new patches for the older machines.  They don't even patch them anymore.



STEVE:  No, no, but I mean none of the vulnerabilities exist in the old - none of this month's vulnerabilities affect 9x-class OSes.



LEO:  We know that for a fact?



STEVE:  Yeah.



LEO:  Or just that they didn't patch them?



STEVE:  No no no, they're not vulnerable back there to that specific one.  Just like the Windows Metafile.



LEO:  I guess his point is that you can't always say that they don't.  They may not patch them doesn't mean that they're not vulnerable.



STEVE:  That's very true.  And so I don't...



LEO:  That's the problem is that they don't patch them.



STEVE:  Yup, it's past end of life.  And so I just - I thought his opinion deserved being aired.



LEO:  I'm kind of on his side.  Windows 9x, you're just - I think he's right.  If it's going to be in any way connected to a network machine, you're vulnerable, even if it's not on the 'Net itself.



STEVE:  Right.



LEO:  I mean, you would agree with that; right?  Certainly there are - he's cited a case where there are exploits that look for, particularly for older machines.  I think a lot - I'm willing to be that a lot of the reason things like Sasser are still on the 'Net is because there's a bunch of dusty old Windows 95 or 98 machines running in closets at enterprises that don't bother to look at them ever because they still work, they do what they were supposed to do, so they don't patch them, and they don't fix them, they don't keep an eye on them.  And they're out there chugging out viruses all the time.  I think that's, I mean, that's why Sasser is still around.



Eric, listening from Sanford, North Carolina, wants greater security and less service.  Oh.  Steve and Leo, first, thank you for providing a valuable service to computer users everywhere.  I'm an avid listener who never misses an episode.  And thanks for making me look smart to my friends and family while helping them with their computer problems.  Secondly, you and your feedback listeners have mentioned turning off unnecessary services and processes in Windows 2000 and XP.  Could you do an episode or a feedback question detailing how to slim down Windows and slam some vulnerability doors shut?  My identity, my processor, and my limited RAM thank you in advance.  I do what you recommend.  I keep up to date with Microsoft OS patches, use the Komodo firewall, run spyware and antivirus weekly, use a NAT router at home.  I do my best not to contract a CTD - I like that, Computer Transmitted Disease - by traveling to only a few favorite sites.  Wow, this poor guy.  But I do take a Sunday drive on the 'Net occasionally.  Good.  Third-party ad banners are a cause for concern, for one.  Thanks.  And that's just what we talked about with this WMF vulnerability.



STEVE:  Yeah.  I wanted to respond to a couple of points that Eric made.  First of all, I do think that's a great subject for a show topic.  And I've got it on my...



LEO:  Turning off services, yeah.



STEVE:  Yeah, well, essentially, doing the research to see specifically which things can clearly and safely be turned off.  I mean, I know we were talking about the Black Viper site, which gives a lot of advice, just the other day.  In fact, it was when I was setting up some of these machines in a VMware environment.  I noticed that in XP the wireless zero config service is there and running.  And it just bugs me because, I mean, this is a workstation with no WiFi.  And Windows could know that I don't have any wireless stuff.



LEO:  You mean it actually starts up even though there's no wireless adapter?



STEVE:  Yes, it's there and running, just like oh, you know, we're going to...



LEO:  That's crazy.



STEVE:  ...give you zero config.  Well, zero config is right because I've got nothing to configure.



LEO:  Zero WiFi.



STEVE:  Oh, my god.  And so in my case, for example, I use static IPs, but there's the DHCP client just sitting there running, waiting to give me an automatic IP.  It's like, well, don't need that, either.  And so there are just so many services that end up running.  And when I'm done trimming them down, I've just got this short little list.  And in this case of this XP that I set up, I just was doing it yesterday, I was running in 66MB of RAM.  And it boots instantly.  And it's just such a small footprint.  And especially, for example, in a VM environment where you want to minimize the RAM impact of running a virtual machine.  It really makes sense to pare down the RAM footprint of your virtual machines because it leaves more RAM for everybody else, for the external systems.  So that's one point.



The other is I've been big in the past on turning off services for security vulnerability reasons.  So, for example, Unplug n' Pray turns off the SSDP enumerator.  Shoot The Messenger turns off the Messenger process, which most people don't need.  DCOMbobulator shuts down the DCOM service.  And so those were things that were done in a pre-Service Pack 2 of XP mode.  Specifically, they were things that really made sense when you were not behind a firewall.  The world really did change with Service Pack 2.  And I wanted to bring up that point, that having these services back behind a firewall is far less dangerous than it used to be.  So that's one point.



On the other hand, the more things you've got running, the more opportunities there are for local exploits.  We always, you know, we hear about privilege elevation attacks, where you're running in a non-privileged account, but some malware gets in.  And you're thinking, oh, well, I'm safer because I'm a non-admin user.  But there are privilege elevation attacks, typically that use some sort of kernel exploit in order to get advanced privileges from a non-privileged account.  And that's typically done by leveraging some services that are running, which a non-privileged account is not able to start.  So they have to be there first, and then a non-privileged account is able to take them over.  So again, it's another good reason, even if you're behind a firewall and a NAT router, why having less services, having fewer less services - having fewer services...



LEO:  Yes.



STEVE:  ...really does make sense.  So I think it's a great topic for an episode, and we're going to go there.



LEO:  And as far as I know, I mean, I think Black Viper's done a really good job.  You've recommended them in the past, I mean, that's a great place to go.  I don't know if you can much improve on it, frankly.  He's, it looks like, done trial-and-error on every single service, one by one.



Curtis Wyatt writes from Las Cruces, New Mexico.  Hello, Steve.  Oh, this is a good one for me.  I'm considering online bill paying.  I've been using this for years.  What do you think of this?  Is it safe?  Are there any drawbacks to giving my electric, gas, and cell phone company bank information over to these guys?  What do you think?



STEVE:  Well, I think it's the typical tradeoff between security and convenience.  Now, in a non-online mode, you're mailing your check to these people.  So they've got your banking information.  I mean, they've got your bank account number, and they know who you are, they're matching it up with your account and so forth.



LEO:  But only the particular person you're paying the bill to.



STEVE:  Oh, exactly.  Exactly.  But...



LEO:  So you're adding one additional person who knows this information, that's this third-party bill payer.



STEVE:  Okay.  And so I guess my point is that any time you're aggregating information in a database, and your data is there with a whole bunch of other people's, there's a single point of vulnerability, which is what has all the bad guys salivating.  When we were talking earlier about this month's new metafile exploit, one of the things that I heard a lot about last week at RSA is the increased prevalence of targeted attacks where specific executives or employees of companies that the bad guys want to get into, they'll send email that is about their organization or about their company or about their job because the email that is focused on that company is able to have a much greater penetration rate if it knows who it's going to instead of just random blanketed spam going out everywhere, talking about somebody in Jakarta who's got money that he needs to transfer into the U.S. if you'll give them a hand.  And so this kind of attack is the sort of thing which is now causing financial institutions a great headache.  And again, so I would say relative to online bill paying, it's like, well, it's a tremendous convenience.  And you probably trade off a little bit of security for it.  But lots of people do it.



LEO:  And you could make a case that you trade less security since you aren't using, well, okay, actually here's the dirty little secret of it.  You may be using the mail after all.  Because a lot of companies don't accept electronic funds transfers from the bill pay service.  In many cases what the bill pay service does is print a check, put it in an envelope, and mail it.  So I guess in that case you're not saving any security.  I guess the ones that are using electronic funds transfer, by not using the mail you might be getting some security; right?  I mean, mailing a check does expose you.



STEVE:  Well, now, I assumed that he was talking about setting up an account with the individual organizations, as opposed to...



LEO:  Well, that would be safe.  Well, I use a central clearinghouse.  I use Intuit's Paytrust, and have for years.  It was originally PayMyBills.  Paytrust bought them, then Intuit bought Paytrust.  So there's a flaw right there.  God knows how many different companies, at least three, have owned my information.  There's also the potential risk, I've heard it said, this may be completely apocryphal, but that some data entry is done by prisoners.  And who knows if the bill pay services use that or not.  But I suspect that some of them do.



STEVE:  When they're not making license plates.



LEO:  Right.  So there is some data entry, quite a bit of data entry involved.  I mean, no machine can look at a bill, figure out where it goes, and make sure the amounts are correct and everything.  Some human's reviewing that, and you trust that human.  So, I mean, I think there are some real security issues involved.



STEVE:  Well, and my concern, any time I hear someone talking about my bank account information, as I understand it, if electronic funds transfer is used to suck money out of my account, it's gone.  I mean, there's no indemnification against fraudulent transfers out of a bank account.



LEO:  That can't be true.



STEVE:  I don't know.  Because I know that I've talked to the FBI when we were - I had some conversations with some of my local friends years and years ago when I was setting up my eCommerce system, just sort of asking them, so, you know, what do you - what's to watch for?  And they had some, I mean, some real stories about people who innocently got involved with eCommerce, had their merchant accounts set up incorrectly so that there wasn't a limit on the amount that could be transferred, and they lost their entire balance, and there is no recourse.  It was gone.



LEO:  No, no, that is old information.  They did change the laws on EFTs.  And so there is a limit and indemnification.  The law was changed a few years ago.



STEVE:  Oh, good.



LEO:  However, I'm not saying that that protects you.  You should probably check with your bank and see what their policy is.  But certainly on - this was an issue with using an ATM card instead of using a credit card, was originally when you used an - until a few years ago, when you used an ATM card you didn't have the same protections.



STEVE:  A debit card, right.



LEO:  A debit card.  So as a result you could, in fact, if you lost your debit card information, really be drained.  But that's - but there was a law passed to change that.  Now, I would check with your bank about EFT and what kind of indemnification you have.  So you're right.  Now, maybe it is then a little bit safer to do what I do, which is use a single third party, because they handle the transaction.  So only they know my bank account information.  And then they pass along - of course if you're sending somebody a check, they've got the bank account information.



STEVE:  Exactly.



LEO:  That's kind of the weak link in all of this is that so many merchants don't accept the kind of - it would be nice, the whole idea of online bill pay would be this kind of everything's done electronically, but it isn't in many cases.  Your bank may offer this.  Intuit, I trust Intuit, and certainly their privacy policy says - it's very clear.  Their privacy, we do not sell or rent your personal information to anyone.  We do not share your personal information with anyone outside of Intuit.



STEVE:  We'll just sell the whole company to somebody else when it's no longer something that we want.



LEO:  Right, it's been - this is the third owner now of all of my personal information.  However, having said that, I have been doing it for over a decade and have never had a problem.  But you're right, I mean, what we cover on this show is theoretical problems, not - we cover what could go wrong.



STEVE:  Well, yes.  We're heavy on the technology.  I should mention that while you were gone in Australia, Leo, I lost my credit card.  That is, I lost access to it.  By that I mean it escaped on the Internet.  I got a call from a robot.



LEO:  Really.



STEVE:  Yes.  It's the third time this has happened to me.  I use it extensively all over the 'Net.  And I got a call from a robot that said, "Please hold for a security consultant."  And I got a gal on the phone who said, "Were you buying anything in France last night when you were probably asleep?"  I said no.  And she said, well, the first charge was for a dollar.  And then there was a charge for 1,500 and some dollars for some sort of sports boutique, whatever that is, in France.  And I said no, that's not me.  And then there was a third try.  All three were caught and blocked by their automated security since I had no past of any kind of transactions like that.  And I said, okay, cancel the card.  So we canceled that number and issued a new one.  And...



LEO:  Happened to me, too.  I bought something from an Argentinean company.  And shortly thereafter I got a $7,000 charge.  But that's the good thing is the credit card companies call you.



STEVE:  Yes, exactly.  And anything fraudulent they will take off your bill.  And as it happens, I did go over my statement, and nothing got past them.  Apparently that little $1 charge was their test charge to see whether the number and credit card information, which they had clearly received from someone, was valid.  And it was.



LEO:  So do check your statements.  But, you know, the banks use interesting - actually this would be a great subject for a podcast at some point.  They use business intelligence software to - remember, there's billions of transactions every day.  How do they find out what's a weird transaction?  They use software to monitor your kind of patterns.  And anything out of the ordinary this software flags.  And this is a very effective software.  It seems to catch most of this stuff.



STEVE:  Well, and in fact in one case it's a little too effective.  I've never been able to purchase gas with this credit card.



LEO:  Sorry.



STEVE:  No, it shuts it down every time I use it to fill my tank.  Then I'll be at a restaurant, and they'll say, really sorry, Steve, but this card is - I was like, what.  Anyway, so I'll call them.  It happened, like, three or four times in a row.  And finally I said to the person, look, every time I buy gas with this card you guys shut it down.  They said, well, that's because, unfortunately, that's what the bad guys do.  They buy gas with a credit card because there's no attendant present.  They're next to their car.  They can make a fast getaway if the card is declined.  And so it's a simple way for them, in relative safety, to check to see if the card is good and they can get away with it.



LEO:  Oh, that's interesting.



STEVE:  And so consequently, I mean, I have another card that isn't so particular, which is the card I deliberately pull out when I want to buy gas because it stays alive afterwards; whereas this other card - and it's these people who caught this stuff happening in France, it's like I'm glad for that.  I'm glad they, I mean, I'm willing to make the tradeoff.  I won't buy gas if they'll shut down any fraudulent purchases because their software is so particular.



LEO:  Well, it should be.  But that's a little weird.  I haven't had that trouble.  Although when I tried to use an ATM card in Canada at one point it said no.  I called the bank.  And all you do is you call the bank and you say, you know, I am in Canada.  And they said, okay, good, we were just, you know, we were a little nervous.  And from then after I never had trouble using my ATM card in Canada because they know, oh, he goes to Canada every few months.



STEVE:  Yeah, you had your Canada bit set.



LEO:  Right.  So I'm glad they do that.  Let's see.  Where am I?  John, listening from an undisclosed location, wishes he had a Wayback Machine.  Well, who doesn't?  Hi, Steve.  I really, really like the Security Now! podcasts, so I ended up subscribing to Security Now!.  By the way, that's free.  I hate that word "subscribe."  That's what Apple uses on iTunes.  And I think it confuses people because, first of all, you're in the iTunes store, and then you press a button that says "Subscribe."  It sounds like you're going to be charged something.  All our shows are free.  If you want to donate, that's fine, that's completely optional.  You go to TWiT.tv, and you can press the Donation button.  It certainly does help, especially now that we're starting to add this video.  They're spending a lot of money on things like lights.



But he says, I ended up subscribing - for free, I add - to Security Now! and have downloaded all the Security Now! podcasts that iTunes has to offer.  Well, that won't be many because we only put 20 up at a time because we don't want that feed to get so long.



STEVE:  Ah.  Thus his need for the Wayback Machine.



LEO:  I would like to get the rest of the earlier episodes so I have all of them, but I saw on your website information that stated, "You may download and listen to selected episodes or subscribe to the ongoing series as an RSS podcast."  I've already subscribed on iTunes.  Does that mean I cannot download the episodes?  See, this drives me crazy because it really is this impression that in some way you're limited.  There's no limit.  I wanted to ask, don't want to violate your policy.  No, look.  They're free.  Get as many as you want.  The easiest way to get them all is to go to TWiT.tv/sn, if you want to go directly, and that's the Security Now! page.  TWiT.tv/sn.  You know, I realize, Steve, that a lot of people don't even know that TWiT.tv exists, that there's a website.



STEVE:  Really.  Oh, because they found us through iTunes, and...



LEO:  Right.



STEVE:  Right, right, right.



LEO:  And so they don't see the donation stuff.  People are constantly surprised.  Oh, you accept donations?  Yes.  Oh, you can get all the files?  Yes.  You just go to TWiT.tv/sn, and you can go one by one through every - every episode's on there.  In fact, I'll tell you a little shortcut.  If you go to TWiT.tv/sn1, you'll get the first episode; sn2, you'll get the second episode; sn3.  Unless we make a mistake, sometimes we forget to do that, and if we have, please let us know.  But all 140 episodes are available there.  Now, how do you download them all at once?  There isn't a way to subscribe.  The reason is you don't want a podcast feed that has 140 shows in it.  It would be too large, and it would cost us a lot of money because we pay the bandwidth for the downloads of the feed information.



STEVE:  Good point, and people might just be downloading them when they really aren't going to listen to them all or don't really need...



LEO:  But they do, they do.  I mean, that's the way iTunes and everything else works is it downloads the feed.  Like every hour it checks the feed.  So if your feed size - our feed sizes are already pretty big because we put 20 episodes, that's about 50K.  It would be a MB or more if you included all 140 episodes.  That means every hour everybody who subscribes would download a megabyte file.  Do the math.  I can't afford it.  We used to do that.



STEVE:  Oh, I was going to say, I think your math is wrong.  But you're not talking about the content, you're talking about...



LEO:  Just the feed.



STEVE:  The RSS, the XML definition file.



LEO:  Just the feed, exactly.  So we keep the feed to 20 episodes of any, of all of our shows, the most recent 20 episodes.  That's 20 weeks, goes back five months.  But if you want to go back farther, then you have - I don't know of an easy way to do this.  Somebody maybe want to write a script, they can, to download all the episodes.  That's actually not a bad idea.  I can probably put something like that out that would just do it all.  But not through iTunes because iTunes is dumb, dumb.  I guess you know what I could do is create - no, I don't want to do that because people will subscribe to it, and then I'll get hit by it.  Really it's very expensive.  Bandwidth is not cheap.  The good news is, of course, thank goodness, AOL pays for the bandwidth for the show.  But they do not supply the feeds.  And even the feed itself can add up.  So go to Security Now!'s page on TWiT.tv.  I imagine, Steve, you have every episode at GRC.com, too.



STEVE:  I have them all there, GRC.com/securitynow.



LEO:  So you can go there, as well, doesn't matter.  Same to me.  Now that Steve, you go through - you do the Podtrac link; right?



STEVE:  Yup.



LEO:  So that's the main thing is that we get counted - actually it doesn't even matter.  For any episode that's older than a month we don't get paid anyway.  So forget that.  We only get, you know, we get paid by our advertisers.  Actually Astaro just pays us a flat fee.  Audible pays for the number of downloads.  And but they only count the first month's worth, which is kind of annoying since many people like our good friend John like to listen to old episodes.  You want me to read this next name?  Hkan Lindqvist.



STEVE:  That's very good.  I don't know how to pronounce it.



LEO:  Hkan Lindqvist - I don't know what that first name is, I don't know what that is - in Sweden deeply gets the point of HTTPS security.  I would just like to emphasize - by the way, we love it, we have many listeners in Sweden, in Scandinavia in general.  We love that.  And Australia, I found out we have tons of listeners in Australia.



STEVE:  We have a ton, yes.  In fact, a bunch of them are here in our questions, as a matter of fact.



LEO:  That's one of the things that's most fun about podcasting, or netcasting as I always call it, is its international scope.  I would just like to emphasize something regarding banks, et cetera, that have their login form on a plain HTTP page and a statement that says "Your login information will be submitted securely" or something to that regard, and maybe even redirect people back to that insecure page if they attempt to switch that page to HTTPS manually.  Ooh, that's annoying.  It is actually not just a lack of fuzzy warm feelings for the visitor, but a catastrophe waiting to happen from a security perspective. Even if a form is submitted over HTTPS, it really does show that their security department doesn't understand HTTPS at all, which makes it worrisome that they have an online presence at all.  Wait a minute.  No, I think he's going a little far here.



First of all, any phisher that makes a look-alike page will have no trouble emulating the login form.  Of course not, they just copy and paste the source.  How hard is it to write "Your login information will be submitted securely"?  What kind of security measure is that?  What it should say is something like "Never ever enter your login information unless your browser shows the padlock, and ideally verify the certificate chain."  Actually he's got a good point.  That's a very good...



STEVE:  Yeah, he really does.



LEO:  I mean, everybody does this.  I'm not sure why they have the insecure page that goes to a secure page.  But he says encryption's only half the point of HTTPS.  HTTPS is designed not only to encrypt data, but actually show who you are communicating with so far as the trusted root authority knows, which at least much more than the web surfer can know.  So if you have the actual form on an HTTPS page, it not only gives the user a warm and fuzzy feeling, it's actually the only way for the user to be able to check who they're communicating with.  The browser only can show that after establishing the connection, HTTPS connection.  If your bank misuses security technology that badly, it may be worth switching banks.  Except they all do.  Even Amazon does that.  He's got a very good point, though.



STEVE:  Yeah.



LEO:  It's more than just security, it's certification.



STEVE:  It's authentication.  Yes, you are, I mean, as we've talked about, we have root authorities who go to some length of trouble.  And one of the things we're going to talk about next week, I attended a really interesting discussion last week at the RSA conference about these EV, the extended validation certificates.  And I've got a much better sense today for why it makes sense.  I was surprised that only 5,000 of them have been purchased.  There's only 5,000 merchants who are using them.  GRC may become 5,001, although they are expensive, and it annoys - that still annoys me.  But I can understand, given what they do, that they are, they're earning more money than they are with the regular certificates, that's for sure.  But the point is that HTTPS does provide you with authentication of the identity of the far end.  And we've talked often about right-clicking on the page, looking under the page properties and view the certificate and look at the chain of trust back to who trusted the site you're at...



LEO:  Why wouldn't you do that all the time?  Is it because it's costly in some way?



STEVE:  I'm sorry?



LEO:  Why wouldn't you, I mean, for instance, now, Amazon, I slandered them a little bit.  When I get to the login page it is an HTTPS page.  But as I'm shopping, it's an HTTP page.  Why isn't it always HTTPS?



STEVE:  That's a very good point.  I think it ought to be.  Once upon a time, I mean, and we're at 15 years ago where we had 8MHz PCs, you could argue that it was too expensive to establish the HTTPS, that is, the SSL or TLS, which are sort of the same thing, handshake.  There is that cryptographic setup process which is a little expensive.  But that's just gone away now.  Servers are so powerful, individual end-user machines are so powerful, and we went from HTTP 1.0 to HTTP 1.1.  One of the changes is the notion of persistent connections, where a browser, instead of initiating lots of little short-lived connections, it will leave the connection up between the browser and the server as you move from page to page.  So that helps in many ways, one being that you're not needing to create individual secure connections.  So that dramatically lowers the burden.  I've been giving serious thought to just switching all of GRC over to secure connections.  There just isn't a reason not to.  I think once upon a time Google was not indexing secure pages, and that's long since changed.  So they're just - I don't see any reason not to leave it secure.



LEO:  Yeah.  So, I mean, yeah.  Let's do that, folks.



STEVE:  And so you have persistent authentication, and...



LEO:  Then you'd know, yeah.



STEVE:  And you're actually snoop-proof, the entire dialogue is snoop-proof.  You know, and as it is now, I enforce SSL connections on sensitive pages.  The Security Now! entry page is that way.  The Perfect Passwords, of course, is shielded that way, and these Perfect Paper Passwords when it's displaying its stuff.  So it just makes sense to leave it secure the entire time.  I don't think there would be a downside to it.



LEO:  Yeah.  That's, well, okay.



STEVE:  Anyway, I really liked...



LEO:  Good for you.



STEVE:  ...liked his observation that it was - it's about authentication.  And banks that don't put you on a secure page for filling in the data don't allow you to verify their identity.  Now, that's one of the things that we'll talk about next week that the EV certificate changes, is it's in the user interface, is that you can see the name of the site's certificate up in the browser's UI, which over time I think people are going to really get, I mean, basically it's like having to right-click on the page, do properties, check the certificate, and see who the certificate owner is.  It does all that work for you and just sticks it up there in the user interface.  I think it's a great idea.



LEO:  I have to say, I'm looking at my bank page, which as I remember at least at one time didn't do this.  Bank of America does do it.  You're HTTPS from the moment you're there.  So that's...



STEVE:  Good.  They got a clue.



LEO:  They got a clue.  And I don't want to slander anybody.  So Amazon does do that when you log in, but not while you're shopping.  And that would be a nice - why not just do it all the time?



STEVE:  Well, and a perfect example is Google Mail.  We've talked about this.  If you go into http://mail.google.com, it takes you through security in order to log in, and then drops you back out to nonsecure pages.  If you go in as https://mail.google.com, then you'll be secure and you'll stay secure.  But they ought to always - since you had to go secure anyway to log in, it demonstrates that your client has the ability to establish an SSL connection.  So why not just leave it up?  I mean, why not take them into that mode?



LEO:  Right.  In fact I'm noticing now Bank of America has now added - oh, this is great.  This is something recently.  They've added this second layer, actually I guess it's third-layer authentication.  You now have to use, or you can, you don't have to, have them send a code to a cell phone each time so that it's like having a dongle, a football.  I like that.



STEVE:  It's another factor.



LEO:  I like that.  Added that third factor, that's great.  Don't mind the inconvenience.  It's nice to know that I'm the only one who can get on this system.



Moving along, Jim Busser of Vancouver, British Columbia, Canada wants to remind us of one thing:  Hey, Steve.  Really enjoy your and Leo's show.  To supplement your answer as to whether you, and by extension anyone, should prefer to use TrueCrypt versus IronKey for protecting USB drives, a particular advantage of IronKey is its lack of need for administrative rights.  Where a user must frequently access portable files from a PC over which they have no admin rights, as in many government and corporation institutions, and also the included secure surfing service from untrusted access points, really should not be overlooked.  Oh, that is - I didn't realize.  So in order to use TrueCrypt you have to be an admin, even to unlock.



STEVE:  Yes, because it needs to install - you either need to be an admin, or that system needs to have the TrueCrypt driver preinstalled by an admin.  But it does this drive mapping where it creates a virtual drive, and that requires kernel-level access in order to instantiate a drive.  So, I mean, and it's why I thought this was a really good point that I wanted to remind users of.  I gave a presentation at our local North Orange County Computer Club two weeks ago.  I loved it, it was their 32nd anniversary, but that's 1000000.  So they said, well, in binary that's a big round number.  So we need cake.  And we need Gibson to come talk to us.  And so I gave a presentation on TrueCrypt and whole-drive encryption and about the things that we've been talking about.  And actually one of the ex-managers of the club came up and said, hey, Steve, I want to make sure, I'm needing to often in my environment - she was in a school administrative environment - often needing to use my USB drive on machines that are locked down with non-admin rights.  And so that says I cannot use TrueCrypt.  I said, unfortunately that is the case.



LEO:  Excellent point.  Excellent point.



STEVE:  Yes.  And so IronKey does not suffer from that limitation.  And so I think that's a very good point.



LEO:  Yeah.  Dan Menear in Northglenn, Colorado needs some DNS clarification.  Steve, you stated you run your own OpenDNS server.  If the goal is to protect you from being a victim of DNS poisoning, how do you get propagated DNS information?  Excuse my ignorance on this subject, but I do not see how this would protect you.  Thanks.



STEVE:  Well, if I said OpenDNS, then I misspoke.  I just...



LEO:  Because you run your own DNS server.



STEVE:  Yes.  And so what I run, the server I run is called a "resolver."  That's the technical name for what ISPs' DNS servers are, meaning that the ISP clients, that is, regular end-users, they've got their Windows set up to ask their ISP DNS server to resolve DNS names.  So the client, the Windows or Mac or Linux machine, whatever, it sends the DNS query to the ISP.  And then that server does what's called a "recursive lookup" because DNS is a hierarchy starting with the root and then dotcom and then - or dotorg, dotnet, dotcom and other top-level domains - going to the second level and third level and so forth.  Anyway, so what I run is I run the same thing that the ISP runs.  I have a little FreeBSD box which is running BIND, v9 of BIND, which is sort of the industry-standard DNS server.  And so it does - it is my resolver, meaning that it has a list of all the root name servers, and so...



LEO:  So it goes right up to the top of the tree if it can't find it.



STEVE:  Exactly.  So basically - and I gave it lots of memory, and it caches.  And so it is a full resolving DNS server.  So all of the machines in my network ask that machine to handle their DNS.  And exactly as you say, Leo, it'll go to the root, and then it'll find the COM servers, and then it'll ask for the, like, for example, Amazon.com, and then if it needs to, www.amazon.com.  And it will itself obtain the IP address.  So my point is...



LEO:  So the root servers would have to be poisoned for this to be a problem.



STEVE:  Well, what it's avoiding is it's avoiding trusting the ISP because an ISP, being an ISP, they're a big target.  If their server were compromised, all of their customers, for example, if someone managed to get a bad IP for Amazon or Microsoft or eBay or something, then you would think you were at Amazon, and in your browser it would say www.amazon.com.  And they would just sort of not switch you into secure mode.  They just, you know, unless you were really paying attention, you might not notice that you were submitting your log-in information not on a secure page.  And so it's easy to spoof browsers by poisoning DNS.  And so I'm not that concerned about it, it's not the reason I'm running my own DNS.  Actually I'm running my own because I don't have an ISP.  I'm buying T1 service from a bulk provider, and so I have to do my own DNS.  But that's the story.



LEO:  Right.  Makes a lot of sense.  And the only thing I would say is that, if you do that, it's incumbent on you to make sure that you keep BIND patched and keep your BSD patched.  BIND has had problems in the past.



STEVE:  BIND has had a ton of problems in the past.



LEO:  Right.  So you can't just turn it on and forget it if you're going to run your own DNS server.



STEVE:  The other minor downside, and this doesn't seem to be any problem for me, but one of the advantages of an ISP's caching resolver is that if I turn my machines on in the morning, not that I ever turn them off, but I use a machine that doesn't already have Amazon.com, the IP cached locally, it's almost certain that my ISP does because one of their other customers will have asked for it within the window of the DNS expiration.  So that server immediately returns the IP that it already looked up for somebody else to me, which is a performance advantage.  Whereas if I'm running my own resolver, as I am, well, it's got to go and do that work because there's nobody here but me.



LEO:  And the other thing I would wonder is, certainly the folks who run the root servers would prefer that people don't do this, right, because for that very reason it could actually really increase the traffic on their servers.



STEVE:  It would increase the load somewhat.  Although they've got long TTLs, Time To Live, on their records.  So generally you've got a list of all the com, net, and org servers, and there's a ton of those.  So you're really not going back to the root that often except when you need to update that master list of the top-level domains.



LEO:  Well, how long is the TTL?  How long is the Time To Live?  When you say long, you mean a day or two, right, or...



STEVE:  Oh, yeah, a day or two, yeah.



LEO:  So at least every few days you have to download that entire list.



STEVE:  Yup.



LEO:  I mean, that's...



STEVE:  It's just like a big RSS feed.



LEO:  Right, it's not insignificant.  So I would imagine - obviously they don't prevent you from doing this.  Anybody can set up a DNS server.  But I would imagine they would probably prefer it if people stuck with the established ones rather than setting up their own.



Eric Larsen, listening from Denmark, wants guessing stopped.  Well, good for him.  Hi, Steve.  I just installed the new version of TrueCrypt and have starting using the whole-drive encryption feature with pre-boot authenticated.  TrueCrypt recommends using a password of at least 20 characters.  That can be a bit difficult to remember.  In a recent show you talked about IronKey and how it only allows 10 tries, thereby preventing any brute-force attacks.  I like that since even a four-character password's pretty secure in a situation like that.  Wouldn't it make sense to perhaps, say, limit to 50 tries with a pre-boot authenticate in TrueCrypt?  No one having tried 50 wrong passwords is going to get it right away, or going to get it right anyway, and no brute-force cracker will run more than second before having used up the 50 tries.  A second, a millisecond.  I'm sure the people at TrueCrypt have thought about this.  What do you think is the reason for not putting in a limit to the number of wrong guesses?  Thanks, from a guy who looks forward to every Thursday.  Thank you, Eric.



STEVE:  Well, the reason is they can't.  And this is a point that David made that I thought was really worth revisiting, and that is that the reason IronKey is able to enforce 10 tries is you have no access to the hardware counter in the IronKey.  But in a TrueCrypt environment there's the whole PC.  So you could take a snapshot of it, use up your 50 wrong passwords.  It would have a counter somewhere that's inherently exposed unless somehow you could use the TPM, for example, on the chip, and the TPM isn't really set up to be used as a secure counter.  But the point is that any kind of counter is going to be on the hard drive or in RAM or in a combination of those or in the registry or somewhere, where you fundamentally have access to it.  So you get to 59 and just reset it to zero and try - I mean, sorry, 49, reset it to zero, and try another 49, reset it to zero, try another 49.  There's just no way, unless you've got a secure counter, that you could enforce a password retry limit.  It works in a client-server mode because you as a client cannot reach into the server and reset the server's counter.  But when you're sitting here in front of a machine you're trying to log into, you don't have a client-server model, you're right there at the TrueCrypt server where you could reset that counter.  And it's all open source.  So whatever they're trying to do, everyone's going to be able to know what it is.



LEO:  Right.  So they can't.



STEVE:  You can't even obfuscate the counter.  Right.  It is absolutely there in the clear.



LEO:  There's an advantage to having hardware and closed source.



STEVE:  I don't think I just heard that correctly.  Did you say that, Leo?



LEO:  I did say it.  But that's a very - that's a good point.  That's an advantage.  Scott Edwards in Newcastle, Australia, has a nice reminder:  Hi, Steve and Leo.  I was recently trying to explain encryption decryption to my workmate.  I was telling him how difficult, impractical, impossible it was to crack strong encryption.  To do this for the first time I used the show notes to find the billion billion billion billion scenario - it's a number with 1,296 billion billion billion billion digits - just to make the point that strong encryption is strong.  So I just thought I'd a drop a line and let you know the show notes are great.  It was very easy to find the info I needed to make the point.  I look forward to the show every week.  Keep up the good work.  Happy SpinRite user.  PS:  What are you up to when you come to Oz?  Thank you, Scott.  I was there for a two-week photo expedition.  It was so much fun.



STEVE:  Oh, I just wanted to remind our listeners that thanks to Elaine's weekly transcriptions and the fact that we now have sitewide search available on every GRC page, if you go to www, or actually that's optional, GRC.com/securitynow, in the upper right-hand corner is a search box.  I imagine that Scott put "billion billion billion" into the search box, sort of remembering that he'd heard something like that.  And he pressed the button, and bang, he was immediately taken to the episode, which he could then listen to or re-read in order to get exactly what that was.  And then of course after it finds the right episode you can easily use the Find in your browser to find the billion billion billion where it exists in the transcript.  So that's there for everybody, for every one of the 139 previous episodes, and shortly for this #140.



LEO:  It's a really nice feature.  Thank you for - actually Steve pays for that out of his own pocket.  That's nice of you to do that.  And if you want to see what I was up to in Australia, and I'm sorry I didn't get to anywhere besides the state of Tasmania because I was there as the guest of Mikkel Aaland, and he's writing his new Lightroom Adventure book.  20 photographers and I, the amateur, went down there to take pictures of Tasmania for two weeks.  And they will be part of a book called "The Adobe Lightroom Adventure II," which should be out in a few months.  I don't know if I'll have a picture in the book.  I mean, there were so many really good photographers.  But you can see my pictures.  You can in fact see the whole story on my website, Leoville.com.  If you go to the blog, I put up about - every other day I would put up a post with lots of pictures in it.  And then you can see what I consider to be my best pictures in the photos section of the blog.  You go to SmugMug, you can see the Lightroom Adventure Tasmania folder.  Flickr also has some pictures, although there are more on SmugMug.  I only put what I considered to be the best pictures on Flickr.  SmugMug has everything.  Not everything.  I took 3,600 pictures.  It only has about 80 of them, 80 of the most best pictures.



STEVE:  Wow.



LEO:  It was fun.  Oh, it was a great time.  And what a great place.  And I apologize to Scott and everyone in Australia that I didn't get to meet.  But we just - that was it, it was Tasmania, two weeks in Tasmania, which was not nearly enough.  But I'll go.  I'll be back.  Australia's a great place.  Boy, it's wonder- have you ever been down there, Steve?



STEVE:  Never have yet, no.



LEO:  Great country.  Really, people are so friendly.  And it's a beautiful, beautiful country, at least the part I saw was.



James Manger, also in Australia, from Melbourne, makes a very good point about wandering thumb drives.  Hi, Steve.  Leaving your thumb drive on your keychain with a mechanic - we were talking about this, the two-part keychain.



STEVE:  Right.



LEO:  Because you have a thumb drive on your keychain, and you always have to take it off.  Might not allow them to read your private files directly, given that they're protected with TrueCrypt and a long crypto-strength password, but they could do even worse.  They could put malware on the thumb drive.  Huh?  Did you ever think of that?  Huh huh huh?



STEVE:  Yeah.



LEO:  Malware could automatically infect the computer you subsequently plug the thumb drive into.  Perhaps your computers are mostly safe from this if you've deliberately switched off autorun, although I'm not sure if that's sufficient.  For U3 it might even require more.  I think you mentioned a small TrueCrypt EXE that could go on the thumb drive so you could access your data from a computer where TrueCrypt was not installed.  What happens if the mechanic has replaced this EXE, for instance, on the thumb drive with malware of the same name?  Whenever you deliberately run this EXE, you'll infect your computer.  The malware might even behave like the real TrueCrypt EXE, prompting you for your password.  At that point the malware can read your protected data and probably find a way to send it to the attacker.  The problem is, you protected the confidentiality of your data, but not the integrity of the disk.



STEVE:  And he's right.  I mean, the more we look at TrueCrypt versus IronKey, the more I wish IronKey was small and cute and could innocuously sit on my keychain the way this gorgeous little Kingston microdrive does.  This little 4GB Kingston that I use is just, I mean, it's just wonderful to have it there.  And unfortunately the IronKey is crushproof and filled with epoxy and industrial strength and metal and all that, but I just can't have it on my keychain.



But I'll tell you, I mean, once again, there's an advantage of IronKey is that it is hardware encryption.  Nothing is exposed, there's no drive there until you log in, and then it does the deciphering.  Whereas, exactly as James says here, even my little thumb drive, it's got that TrueCrypt EXE has to be accessible because without that, it's that that mounts the device driver that prompts me for my password and so forth.  So there really is that vulnerability.  I mean, he's exactly right.  I'm going to have to come up with some solution to that problem.



LEO:  Hmm.  Yeah.



STEVE:  I think I could probably password-protect the TrueCrypt EXE, and that might work, although you couldn't show that it's absolutely - well, maybe.  I don't know.



LEO:  Do an MD5 hash.



STEVE:  I'll think about that.



LEO:  Do a hash on it, you could probably...



STEVE:  Yeah, but then you're not going to.  I mean, it needs to be something that you have to do every time.  If I were to password-encrypt it so it's a self-extracting EXE, then I would instantly detect if it were replaced.  There would be no way to - well, but then again, by the time you run something to find out that it's not what you expect it is, the damage is done.



LEO:  Too late, it's been run.



STEVE:  Yeah, there's no good solution to that one.



LEO:  There's always a risk, I think, when you give somebody the hardware.  When they have access to the hardware, that's risky.  That's why the IronKey goes to such great lengths with the epoxy and so forth.



STEVE:  And I have to say again, David, I think, and the IronKey folks, they solved that problem.  I mean, I was sort of thinking, oh, boy, this is overkill.  But the more I think about it, it's like this is what you have to do if you want to have a secure thumb drive that you can hand to someone and say, here, I don't care what you do with this, you can't get me.



LEO:  Yeah.  Meanwhile, our Shocking but True Jolt of the Week, anonymous, nearby in Irvine.



STEVE:  Now, he actually had his name in his message to me, in his email, and I thought, no, no, I'm not going to use his name for this one.



LEO:  Really.



STEVE:  Listen to what he says.



LEO:  Steve, man, you have no idea how right-on you are about any digital resource left in, on, or around your car when you leave it for service.  I have provided IT support for a dealership group local to you in Irvine, VW and Honda, you probably know them.  You're probably aware that almost all auto technicians have PCs and laptops in their service bays.  Well, when a vehicle is brought to their service bay, the first thing they do is inspect the vehicle for CDs and iPods to rip and import music.  After that, any USB drive, portable hard drive, laptop is tapped into to see if there are any files that might be useful.  Probably looking for porn.  Then the items are placed back in the vehicle, and the owner never knows their music, personal files, and applications have been copied.  Oh my goodness.



STEVE:  Yeah.



LEO:  The service technicians I've observed have amassed a huge library of music and applications that never seem to stop growing.  They supplied their own network attached storage to share their booty without - they put it in their own NAS server.  This is like organized crime - without tapping into the company IT resources.  Be aware, anything you leave in your car can and will be accessed by tinkering fingers.  Holy cow, Steve.



STEVE:  Isn't that horrifying?



LEO:  Holy cow.  Well, I was always told not to leave your keychain anywhere, have a valet key and put stuff in the trunk, and then take your keys because of course they could copy the keys, they've got your registration, they know where you live.  I mean, I've always worried about that.  But who knew they were doing this?



STEVE:  Yeah, as you say, it's almost like it's organized.



LEO:  It's organized crime.



STEVE:  They've got their network attached storage in order to have storage space.  And anything you leave behind they - well, you can imagine just them sitting there ripping your CD collection because lots of people have a bunch of CDs in their car.  So they empty out your CD changer, stick one disk in after the other to suck all your music out, and then put it all back.  And if people have ever wondered if, wait a minute, I thought that was disk number four, how did it become number six, well, now we know how the CDs move around magically.  They weren't put back in the same place.



LEO:  Wow, that's really quite amazing.  Holy comoly.  Holy comoly. That is the shocking admission of the week.  And I see why you took his name out now.  And I bet you're going to be even more careful when you - of course people always leave CDs in their car.  I mean, I wouldn't leave a laptop in my car.  That seems kind of kooky.  But now I won't leave my IronKey in there, either.



STEVE:  IronKey is safe, Leo.  You just want to make sure you get it back.



LEO:  Somebody, we had a couple of impromptu, informal meetings...



STEVE:  Oh, I guess actually the IronKey, if they guessed wrong 10 times, it would shut down.



LEO:  They could break your IronKey.  You're right, you don't want to leave it in there.



STEVE:  Because they'd absolutely plug it in and do some guessing.



LEO:  Well, let's try some passwords.  Geez, Louise.  There were a number of people at the - we had these meet-ups in Australia.  And a guy, it was so cute, I think it was Ivars came up, said look at this, and he has his IronKey on his keychain.



STEVE:  Oh, neat.  And actually I saw the IronKey guys also.  And their reaction was, they said, boy, this podcast has legs.



LEO:  Tell them to buy some ads.



STEVE:  I guess wherever they were going they were saying, hey, yeah, I heard Steve and Leo...



LEO:  IronKey, right on.  He also had a PayPal football on his keychain.  So this guy is a serious - I think it was Ivars.  It was a serious listener.  If it's not Ivars, I apologize to whoever it was.  Hey, we're done.  We're not out of time because we could go on and on.  But we are done.



STEVE:  With Episode 140.



LEO:  Yeah, you're proud now, you've passed TWiT.



STEVE:  Baby.



LEO:  Happy now.  Are you happy now?  So next week we're going to cover the RSA Conference which happened in San Francisco.  It is the security conference of the year.  It's the big one.



STEVE:  And code wants to be wrong.



LEO:  Which should be the title of this podcast.  Leo wants to be wrong, too.  Steve, thanks so much.  Remember, go to GRC.com, folks.  That's the place to get your 16KB versions of this for the data challenged, download challenged.



STEVE:  And I will remind people that all the questions they heard Leo read just now, they came to me via GRC.com/feedback.



LEO:  Good point.



STEVE:  So that's where you go, GRC.com/feedback.  There's a web form there where I get no spam.  And so submit your question, and it'll get to me.



LEO:  Yes, yes.  And you can also search for any previous episode at that spot.  Find many great programs, too, to help you, including the Perfect Passwords generator GRC.com/passwords, Perfect Paper Passwords, Wizmo, Shoot The Messenger, DCOMbobulator, and the famous, the world-famous ShieldsUP!, it's all there.  And did I forget?  I did.  SpinRite, my favorite, the one and only, the best hard drive maintenance and recovery utility.  GRC.com.  Steve, we'll talk again next week.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#141

DATE:		April 24, 2008

TITLE:		RSA Conference 2008

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-141.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss recent security news; then Steve describes the week he spent at the 2008 annual RSA security conference, including his chance but welcome discovery of one very cool new multifactor authentication solution.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 141 for April 24, 2008:  The RSA Conference.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, wherein which we attack the attackers, we hack the hackers, we crack the crackers, we talk about what's going on in the world of security with Steve Gibson.  He's the guy who created - coined the term, he didn't create it, he coined the term "spyware."  Others created the spyware.  He just found it.  He also did create the first antispyware program, which he's long ago handed off to others.  But he certainly was, as usual, kind of the Paul Revere of security.  The hackers are coming, the hackers are coming.  Hello, Mr. Gibson.



STEVE GIBSON:  Oh, Leo, great to be with you for our 141st episode.



LEO:  Oh, go ahead and rub it in.



STEVE:  Wow.



LEO:  You love that because TWiT's only at 140.  He loves that.



STEVE:  Yeah, I need a bigger - I need a bigger lead.  So...



LEO:  Oh, you'll get one, don't worry.



STEVE:  Boy, it took two, it took - oh, that's right, we started a lot later than TWiT did.  I was going to say it took, you know, two and half...



LEO:  Well, TWiT's three years old.  Yeah probably did take, like, a couple years.



STEVE:  Yeah.



LEO:  But, yeah, but that's a good point is that TWiT had a year on you.



STEVE:  Exactly.  So we've been catching up quickly.  So watch out.



LEO:  Oh, man.



STEVE:  We can just shoot by, Leo.



LEO:  Oh, man.  So we're going to talk today about your visit to San Francisco and the RSA conference.



STEVE:  Oh, there was just so, well, I've got a ton of things to share with people.  And it was a really, really interesting, worthwhile trip.  And I got a lot of good feelings.  I mean, largely, I've got to say that if people listen to this podcast, they pretty much have a grip on everything going on.  I mean, the whole show was identity and authentication.  I mean, basically you could just rename it the Identity and Authentication Show because, I mean, that's what everyone is all freaked out about.



LEO:  Well, that's funny because that's what we've been talking about for the last few...



STEVE:  I know, I mean, it's like - I had sort of the same feeling that I had when we had Dave Jevans on from IronKey.  It's where, you know, he was talking about all these things, and they're all things that we had discussed in prior weeks of Security Now!.  So I was thinking, wow, isn't that cool that, I mean, we've covered all that.  And similarly, I mean, there was nothing at the show that we haven't covered in one form or another.  I mean, it was really nice.  It's like, okay, if people are listening to this, they really are up to speed.  Which is not to say that I wouldn't highly recommend this RSA security conference for any of our listeners who are, like, in the security business.  I mean, it's not something I would expect random end-users to need to go to.



LEO:  Well, I think a lot of end-users are very interested in this stuff.  Oh, they wouldn't go, you're right, they wouldn't go to RSA.



STEVE:  Well, but on the other hand, I mean, if you had a high-end end-listener who was really into security, it wasn't - overall it has sort of a corporate aim.  I mean, it's aimed more at corporate solutions, enterprise, securing your networks, authenticating your 100,000 employees, that sort of thing.  But the individual breakout tracks where you go and listen to, like, small, either individuals or small groups of two or three talk about specific topics, and I'm going to talk about a couple of those during this show that I found were really interesting, I mean, they're interesting to anybody.  So, I mean, certainly our listenership.  And anyway, it was really fun.



LEO:  Yeah.  Yeah.  I mean, I read one - an interview with one showgoer who said, "I didn't understand what one product on the show floor was meant to do."  So it also is probably fairly technical.



STEVE:  Yeah.  I will say, like I said, it was - what I found walking around was it was largely everybody doing the same thing.  I mean, there were - everybody had tokens.  Everybody had press-the-button-and-get-authenticated stuff.  I mean, so there was, like, literally you just, as you walked by the booths, it was "the industry's strongest authentication solution."  Okay, somehow everyone had that.



LEO:  Yeah.  So there's a little hype, as well.  And, well, we certainly know that security, I mean, hype and security go together.



STEVE:  And you'd stand there looking at the booth, and which was a problem, you know, I had press credentials, so they were all like, oh, come closer, come - it's like no, no, no, don't scan me.  Because, you know, the badges were all RFID-enabled.  And so, you know, you could get scanned and suddenly you'd be getting phone calls.  Actually I got one this morning that was sort of annoying.  It's like, I don't need anybody to sell me on this stuff.  I understand it.  But standing at the booth, you could not determine from any of the background of the booth what their thing was.  It was, again, it was world-class-strength identity verification for your enterprise.  It's like, okay, well, but that's what the people on either side of you are saying, too.  So it was - and it was huge.  I mean...



LEO:  Oh, really.



STEVE:  On the last day of - the last day of the show I just dedicated to dealing with all the exhibit space.  The prior three days were all just going from one of these interview track breakout sessions to another, where I found really interesting things.  And what was really bizarre is it was in the morning of that last day, in a really bizarre way, I found the one coolest new authentication gizmo of the show.  It was - there was this woman just standing at the top of the escalator, looking kind of forlorn.  And it turns out she's the inventor, the founder, and the CEO of this company in Sweden that has come up with something that is so cool that I can't wait to tell our listeners about it.  And but she had a deal to be in one of the vendors' booths.  So she comes over from Sweden with a whole bunch of these things, and this invention, and they reneged on their agreement.  So, like, nothing had happened for her.  And so here she was on the last day, just looking for some way to get her message out.  And I walked by with my press badge, and she sort of thought, oh, maybe this would work.  Well, let me tell you, I hope it's going to work because...



LEO:  Oh, good.  Oh, good.



STEVE:  ...this - she really deserves - and this - anyway, it is so cool and clever.  I just love clever and new.  And this is a multifactor authentication solution that we've never talked about, and nobody else has it.



LEO:  Good.  So let's talk about RSA.  Unless you have some - do you have some errata or anything you'd like to talk...



STEVE:  Oh, I've got a ton of security stuff that happened in the last week.  And of course a fun, interesting, sort of different SpinRite anecdote.  I got a letter - we received, GRC received a letter from Dan Stoddard just last week.  And he said:  "GRC, I know you get a lot of these letters of appreciation, but I must tell you how pleased I am with SpinRite.  Earlier this week a friend's laptop crashed.  It would display the Windows boot-up logo briefly, then bluescreen.  He called the laptop manufacturer and was told there was no way to recover his data.  Frustrated, he asked me to take a look at it.  I first tried running the Windows repair utility from the installation CD.  No luck.  Next I booted a laptop from a BartPE CD-ROM, but was not able to access the drive at all.  Finally, I removed the hard drive from the laptop, connected it up to my PC with a hard drive-to-USB adapter.  This, too, failed.  Normally at this point I would have told my friend the hard drive was dead, with no chance of recovering his files.  But I've been listening to the Security Now! netcast for the past several months and have heard Steve read letters from SpinRite users" - just like him - "SpinRite users who have successfully recovered data from crashed hard drives.  So I purchased a copy of SpinRite from the GRC website and within a few minutes downloaded it and had created a bootable SpinRite CD-ROM.  I have to admit I was somewhat skeptical at first.  But as SpinRite went to work, I could see raw data from the hard drive flashing across the screen.  I then realized the hard drive still contained my friend's data, and SpinRite was finding it.  After a couple of hours the process was complete.  I rebooted the laptop, and to my immense relief it booted up Windows normally with all his files intact.  Needless to say, I am now a SpinRite believer.  Thanks, Steve, for a great utility."



LEO:  Excellent.



STEVE:  So just love those stories.  Any listeners who have SpinRite success stories, please don't let the fact that I get a lot of them deter you from sending me yours because every one I just - it's just so neat to have someone write...



LEO:  That's - Steve's reward is not the financial reward, it's the emails he gets.  He loves it, just loves it.



STEVE:  I just love it that it works.



LEO:  Yeah, yeah.



STEVE:  Okay.  So in the last couple weeks a bunch of stuff has happened.  First of all, probably maybe most important, there's a huge problem has been found in the ClamAV system.



LEO:  Oh, dear.  That's not good.



STEVE:  It's open source, as you know, very popular open source antivirus.  The problem is that because it's open source, the bad guys have the same access to it as the good guys have.  So there are proof-of-concept exploits out such that, if you've got ClamAV filtering your email for malware, viruses, spam, whatever, you can send somebody using the current release of ClamAV a deliberate malformed piece of email.  The email scanner has a buffer overflow in it.



LEO:  Oh, interesting.



STEVE:  Which means that - and, for example, ClamAV is often run on email servers, where it'll be, like, scanning all the mail coming into a corporate facility, to the corporate server.  So spam - and as far as we know it's not in the wild yet.  Updates are available.  So I wanted to make sure that anyone who thinks maybe even their corporation, if they think their corporation IT guys are using ClamAV, make sure they have updated to the latest because - and it's not the signatures they need to update.  That's probably happening all the time.  It's the code itself has a problem such that just it receiving spam can take over the server.



LEO:  That's wild.  That is wild.



STEVE:  Yeah.  So anyway, so...



LEO:  So people would - spammers would send out this message to everybody, hoping that they're going to snag somebody who's running the ClamAV...



STEVE:  Exactly.  Anybody who has not updated, who's running the pre-most recent update, would be vulnerable.  And their own AV, I mean, when you think about it, the last place you want a buffer overrun or a similar sort of exploit is in your AV, which you've added to make your system more secure.  In the process you've made it much more vulnerable.



LEO:  And by the way, it's not just ClamAV.  I've heard these kinds of similar buffer overruns with...



STEVE:  Yes.  I don't mean to be picking...



LEO:  Almost all antiviruses seem to have this problem, or have had this problem at one point or another.



STEVE:  Well, remember my favorite quote from the RSA show is "Information wants to be free, and code wants to be wrong."



LEO:  The other thing you should pay attention to is that ClamAV is used as the engine for many other third-party solutions, so you might want to check and see what the AV engine is in your solution and update as needed.



STEVE:  Also the very original instant messaging program, ICQ - remember that in the old days, Leo, when it had like a little flower petal logo?  I think I was like - I was user, like, 4444 or something.



LEO:  Really, wow.



STEVE:  I wanted to find out what it was and got onboard very early.  And it's really not for me.



LEO:  Onboard and offboard, I'm sure.



STEVE:  Yes.  But there's an important vulnerability that was found in ICQ.  It's got a weird exploit.  It's in the status display portion that shows, like, somebody remote that is in your friends list is online or offline.  Well, it turns out if their machine were to send you a malicious status report on them, that could take over your machine.  So it's got the potential for creating a flash worm that would go through the ICQ system, basically getting into someone's machine and then sending out a malformed status to everybody they're connected to, which would then jump into all of those machines, and then all of them would do the same.  So you could imagine like a flash worm that would just flash through the ICQ network and take over the whole thing.  So you have - I don't know whether ICQ updates itself automatically.  You definitely want to make sure, if you're an ICQ user, that you fix that because you don't want to be part of that flash when that happens.  That would be bad.



The other big news is all the browsers have had updates since we last talked.  Firefox is now at 2.0.0.14.  I had been using 13 for a while, so it's now 14.  And that fixed some important updates.  Safari, both Windows and Mac versions, are now at 3.1.1, and there were some important things fixed in them.  And Opera is now - just went from 9.26 to 9.27.  And I'm going to say I'm liking Opera a lot, Leo.  It's got a whole bunch of features that you only discover, like, after you've had it for a while.  Like I right-clicked on a page, and on the menu was the option of blocking, selectively blocking content, where like you could then click on things on the page that you wanted it to block, like ads and things, and it would automatically add those domains to a block list.  And it's like, wow.  And it's got a built-in download manager and - anyway, I mean, it's just a whole ton of features that I just, as I use it more and more, I'm doing a bunch of work with a bunch of browsers on a topic that we'll be talking about here in maybe another month, it's taking longer than I expected, but then everything I do does, but it's going to end up being very comprehensive.



So I've been using Opera and Firefox and Safari.  And Opera's got some neat features.  Firefox v3 is in beta and is looking nice and stable.  I loaded the Windows version of Safari just because there is one.  I didn't install it on my machine, it's in a VM.  And I have to say, I mean, it looks identical to the Mac Safari except you can grab any edge of the window and drag it, which is so nice, just like Windows.  It's like, I don't know why the Mac just refuses to do that.  It's just - it's a constant annoyance to me, as you know.



Also, Windows XP Service Pack 3 is almost ready.  Microsoft has said they will make it available through Windows Update on April 29th.  So, what, I guess that's going to be next Tuesday, which will be wonderful for those of us who set up Windows XP from time to time.  I mean, I have it, for example, running in my VMs that I'm running these various browsers on.  And it's like, oh my goodness, thank God that you can clone VMs so you don't have to re-upgrade every version of XP that you install.  But going to Service Pack 3 will save us about a 100-plus patches.  So that will be very nice.



LEO:  Hallelujah.  It's not a - unlike Service Pack 1 for Vista, it doesn't change the functionality in any way.  It's just a rollup of patches.



STEVE:  Is that the case?  I meant to look to see.  I'm trying to remember whether I read that there was some change.  I might be thinking instead of Service Pack 1...



LEO:  Service Pack 1 for Vista does change a lot of stuff.  I don't - you know what, I'll ask Paul Thurrott.



STEVE:  I kind of think maybe it does a little something.  I can't really remember.



LEO:  Okay, good.  That's good.  I'll find out.  Listen to Windows Weekly tomorrow.



STEVE:  There you go.



LEO:  Paul will know.



STEVE:  And the last little bit of news is not really, like, security trauma, except that, well, it is for the Hotmail people.  It turns out that there's a botnet now that has a 10 to 15 percent success rate of cutting through Hotmail's CAPTCHA protection.



LEO:  Wow.



STEVE:  And of course we've talked about CAPTCHA a lot because it's a cool technology.  The idea is - "Are You Human," I think, was the name of our podcast that we talked all about CAPTCHA.  And of course the problem is a botnet has hundreds, thousands, tens of thousands of machines in it.  And botnets are now being used as a preferred spam generator because it makes it impossible to blacklist the sender's IP because you've got 10,000 of them, instead of it, like, coming from one server.  So what the botnets do is they would love to be able to create a Hotmail account so that, rather than sending email just from their own IP, they create a Hotmail account and then use the browser interface to put their mail into Hotmail because there are obviously, who knows, hundreds of thousands of legitimate Hotmail accounts, and that means that you cannot blacklist by Hotmail.com, you've got to do more.



But the point is that even having as low as a 10 to 15 percent success rate, that would annoy a user, but the bot doesn't care.  It just, you know, essentially that means that it's going to try eight times and it's going to get through between eight and nine, every eight and nine times it's going to be able to create a new account and use it until Hotmail decides that it's evil and shuts it down.  And also researchers in the U.K. have published a paper describing their automated approach for breaking Hotmail's CAPTCHA that has a 60 percent success rate.



LEO:  Wow.



STEVE:  So more than half the time they're able to crack Hotmail's CAPTCHA.  So I think the Hotmail guys are - Microsoft, of course, owns Hotmail now.  They're going to have to go back to the drawing board and come up with a better CAPTCHA solution because it's just - it's not doing the job anymore.



LEO:  I mean, come on.   A lot of spam comes from Hotmail and Gmail and all of these created mails, whether they're using automated break-in tools or not.  I presume that's what you mean when you're saying 60 percent success rate.  They're talking about some sort of computer program that can figure out what the CAPTCHA is.



STEVE:  Yup.  Which of course is what CAPTCHAs are supposed to prevent.



LEO:  Right, right.



STEVE:  They're not doing that very well.



LEO:  Those bots, they're everywhere.  Spam is such a problem.  It's just not getting any better.  It's just getting worse and worse and worse.



STEVE:  Well, and when it's not, I mean, it used to be original spam was just annoying commercial stuff, home mortgages and various organ enlargements and...



LEO:  Right.  Now it's, yeah.



STEVE:  And now it's malicious.  It's take over your computer when you click the link by mistake, or in some cases not even having to take any action at all.  So, I mean, it's real malware that is being sprayed, you know, instead of just annoying advertisements.



LEO:  Yeah, yeah.  So there we go.  That's the news.



STEVE:  That's the news.



LEO:  That's the news across the nation.



STEVE:  Okay.  So RSA, of course, we've talked about RSA a lot.  RSA Corporation had the early, well, was the patent holder, thanks to its founders.  RS&A stand for Rivest, Shamir, and Adleman, who did the original public key work and have a whole bunch of patents which have since expired because that was more than 17 years ago, the life of patents.  So that stuff is all out in the public domain now.  But they're a big, strong security company that offers all kinds of great features.  And they produce an annual show in San Francisco, the RSA security conference.  Although the formal name is RSA Conference 2008.  It was a fantastic show.  I mean, it was really well put together.  I'm just very impressed with the job they do.  Now, I'm tempted to end the podcast now.



LEO:  What?



STEVE:  After telling our listeners they have got to go see the keynotes.



LEO:  Are they online?  They're all online?



STEVE:  Yes.  Now, I created a short URL just for everybody listening because the big one is long and nasty.  We will have links on your show notes and on GRC's to the page of the keynotes, which I cannot recommend highly enough.  Now, not all of them were fantastic, so I'm going to recommend some, and I'll put those on my page also, and Dane can get them from my page, Leo, so that you have them.  So it's snipurl.com/rsa2008. 



LEO:  Oh, that was easy.



STEVE:  Yup, snipurl.com - why don't you type it in right now just to verify that...



LEO:  I got it.



STEVE:  Okay.  Snipurl.com/rsa2008.  That will take you to their page where we can find all the keynotes.  You can - they're available in Windows Media format or in Flash.



LEO:  It also says "View Interactive Webcast."  What does that mean?  You can view the video, or you can view an interactive webcast.



STEVE:  Okay, well, that's, okay, that's what I was about to say was it's that thing that comes up in Flash.  Click on one of those, and it'll come up.



LEO:  Yeah, I'm watching it right now, the opening ceremony.  So it's got a whole interface.  You've got the video, you've got the slides - I guess these are the slides from the...



STEVE:  That were shown during the presentation.



LEO:  Oh, that's cool.  So you can actually watch their - oh, this is a nice way to do it.



STEVE:  Oh, it's beautiful, Leo.  And over down in the lower left you can see the four days.  And when you click on one of those, it shows you the keynotes.  Okay.  So the title of this year's show was - it was all about Alan Turing, whom we've talked about of course, the famous cryptographer mathematician who did the Turing test, the Turing machine, who cracked the Enigma cipher using his math and technology.  And so "Turing Lives" was sort of their whole theme, which was sort of laced through the whole show.  So the opening ceremony is worth watching, the first half, where they talk about Turing.  So it was just sort of interesting.  And of course we've talked about him extensively.  The second half is the dance number.



LEO:  What?  There's a security dance number?



STEVE:  Oh, goodness.  They took the whole - the old, remember the "Brick House"...



LEO:  Yeah, "She's a brick...," the Commodores, yeah.



STEVE:  Yeah, the Commodores, right.  And they relyriced it into "It's a Botnet."



LEO:  Oh, geez.



STEVE:  Oh, it's so bad.  Oh, goodness.



LEO:  Why, why, why?  Why would they do that?



STEVE:  So I want to make sure everyone knows I am not suggesting that they listen to the second half of the opening ceremonies.



LEO:  But now you know they will.



STEVE:  Well, yeah.  You can get a taste for it, but believe me, it doesn't get any better once it starts.  It was just...



LEO:  Let me just play it.



[Music]



LEO:  I'm going to make them listen to it.



[Music]



LEO:  Oh, that's just ridiculous, and they've got a whole group of people up there.  Were you there for that?



STEVE:  Oh, yeah.  Oh, yeah.  She's a botnet.



LEO:  Were you groaning?



STEVE:  And they had the - and because it was sort of hard to hear, they had subtitles for the whole thing going on.  I was like, oh, goodness.  So, yeah, that kicked off the show.  And I thought, well, okay.  We'll see how this goes.



LEO:  What did the security pros in the audience - how were they reacting to that?  Were they enjoying it?  Were they digging it?  Were they getting down?



STEVE:  It was, you know, I mean, it was light-hearted and spirited and fun.  And it was like, okay, is this what I paid for?  The good news is that's not what you paid for.  There was tons, tons of really high-quality content.  Okay.  So John Thompson of Symantec, I absolutely recommend his keynote.  He brings out their guy who's in charge of malicious software.  And unfortunately they try to do a little bit of canned humor that just doesn't work in this setting.  But I know that our listeners will be fascinated by their statistics.  And it was his comment, I couldn't remember who said it, but I watched it again, actually I ran through several of these again because, you know, in order to prepare my recommendations.  And it was Symantec that has the numbers that showed there is more malicious software now that users are encountering than good.  And so it was in that presentation where their numbers that they have, this worldwide, this global network which is monitoring malware and viruses and spyware and everything.  And so end-users are now coming in contact with more bad software than good software.  And it was this year, apparently, that that tipped, that scale tipped over to that side.  So John Thompson's Symantec presentation I really recommend.



Now, my - okay, I've got two favorites.  The panel discussion at the end of the first day, April 8, which was Tuesday, was the cryptographers panel.  And we've talked about Whit Diffie and Dick Hellman of the Diffie-Hellman key exchange, and of course Ron Rivest was one of the founders of RSA.  I actually knew Diffie and Hellman back in the early '70s, when I was at Stanford University's AI lab during the summers, I got a job there in the summers.  They were, I mean, these guys were there doing their early Stanford crypto stuff.  So it was fun to see them again, and I chatted with them.  Their panel is great.  And Whit Diffie is this wonderful, white-bearded, long hair, I mean, he's exactly what you want in your cryptographer.  He was just tremendous and very funny, had lots of little quips and things.  Again, I think our listeners will really find it interesting.  Just, I mean, here are the guys that founded the crypto industry, you know, talking to you for 45 minutes about things that they think are important and what's going on.



And one of the things, I don't remember, I think it might have been Rivest, one of his points was, I thought it was interesting, he said humans do a bad job of judging low probability events.  That is to say - it might have been Hellman now I think of it.  Anyway, our listeners can listen to the keynote.  But the point was things that tend to happen very seldom, we make the mistake of confusing that with never.



LEO:  Right.



STEVE:  And, I mean, to our detriment.  I mean, so you might argue that something like the chance of terrorists commandeering commercial airliners and doing evil with them, you know, what's the chance of that?  Well, it's not zero, and we found out on September 11th.  And so...



LEO:  Well, I'll give you another example.  People forget that New York City is actually very earthquake prone.  It's just there hasn't been an earthquake there in a couple of hundred years.  So people figure, aw, never gonna happen.  But, and if it does, it's not going to be a pretty sight.



STEVE:  And that's a great example, Leo, is that, yes, I mean, it's interesting because, I mean, how people are just bad with statistics.  There's something, whatever it is, the way our brain is wired, and actually the way our brain is wired was my other very favorite keynote because a friend of ours...



LEO:  Oh, Jeff Hawkins, yeah.



STEVE:  Yup, on Wednesday.  But anyway, so it turns out that the way we're wired, we just don't do well with statistics.  Something about us, about humans, we just don't...



LEO:  It's not intuitive.



STEVE:  We don't get statistics.  And one critically bad way not to get it is to confuse low probability with zero probability.  Anyway, so again, that cryptographers panel discussion on April 8, Tuesday, is absolutely worth watching.  And then my other favorite was Jeff Hawkins, whom we've talked about, in fact; "On Intelligence" is the book he wrote recently, and that was one of our Audible recommendations at some point.  And this of course is the book that talks about the work he's done.  Jeff, to remind our listeners, is the founder of Palm and Handspring and Numenta, which is his company which is working on software to model, essentially to solve problems in the way that the human brain does by modeling the exact neurological functioning of the brain.  He's got this technology called HTM, Hierarchical Temporal Memory, where he - basically they are building in software exactly what, I mean, they're exactly modeling in software the way the brain is neurologically wired.  And so they're doing it much more closely than the old neural networks did, where you just sort of basically had a bunch of goo, you know, neurons wired up in software, and you threw things at it, and they sort of learned.  Here, because they're modeling the brain closely, they're getting, well, much higher quality results.



The cool thing about his keynote is first you get to see him, and he's kind of a neat guy, and he's odd and neat.  But he also has really good results that he shows.  You've got diagrams of his stuff, he shows pictures, he shows, for example, he gives examples of the kind of photos - they're doing photograph recognition is the way they're developing their technology now.  And all the technology is downloadable from Numenta.  So you can get this and play with it yourself.  And he shows some phenomenal results where they were training one of their models on image recognition, showing them pictures of boats and cats and dogs and animals and all kinds of random stuff, and then showing the kinds of things that this technology of theirs can then correctly recognize where, I mean, even I'm looking at it going, well, okay, that's a boat, but how the hell could it possibly know that?  I mean, it's really impressive.  So here, I mean, for free, our listeners can watch this keynote and see this for 45 minutes.  And I absolutely highly recommend it.



Craig Mundie from Microsoft, also back on Tuesday, had a really interesting discussion with their - Christopher Leach is their chief information security officer.  And so they're talking about perfect identity versus perfect privacy, security versus privacy.  Their theme is "End to End Trust."  And so basically here's Microsoft talking, I mean, the guys at the top talking about where Microsoft is and what they're working on and what they're thinking.  And I highly recommend that, as well.



LEO:  Very interesting stuff, yeah.



STEVE:  And if anyone's curious to see Michael Chertoff, he was added late to the program, that is, a few days I think it was, maybe about a week before.  He's, of course, Secretary Michael Chertoff, the head of our Department of Homeland Security for the U.S.  And so he spends about 45 minutes talking about their stuff and what's important and what's going on.  So, I mean, just really, really great, great information.  Which is why I said I'm tempted to just end the podcast now.



LEO:  But before you do, you might - I would like to, I mean, yes, we can all go and look at those videos.  And we can, you know, it's not - I'm thrilled that they did that.  I think that if more conferences did that, yeah, maybe there'd be lower attendance.  I'm sure that's what they're worried about.  But boy, they'd sure get the word out.  And I bet you people would look at that and say, boy, I want to be there next time.  I don't want to miss that.



STEVE:  Yes.  And again, I want to say that I will work to give our listeners some notice before next year's conference in case there are people who look at this stuff and think, wow, I really want to be part of that, or I want to attend.  I mean, there was pretty much on the exhibit space was 100 percent enterprise-targeted content.  But the individual breakout sessions, I think there were 14 different tracks.  And so at every hour there were 14 things going on.  And, I mean, I needed five of me in order to see them all.



LEO:  Well, good, so you can watch them online.  I think that's really great.



STEVE:  Well, no, those you cannot.



LEO:  Oh, you can't, ah.



STEVE:  No.  Only the keynotes.



LEO:  I wish they'd put those online, too.



STEVE:  Well, they were all being recorded.  But the access is restricted.  So only people who had access to them at the show are able to download them.  But you are able to - so, for example, I could get them and listen to the ones that I missed.



LEO:  Yes, I get it.



STEVE:  But I guess my point is that, I mean, there was so much good stuff happening all in parallel that I was having a hard time, hour by hour, scheduling myself, choosing this over that, which one do I really want to see more.  So one that I stumbled on on Wednesday, it was - it had, like, a strange name.  It was Securing the Internet with Strong Authentication or something like that.  And I thought, okay, well, that's good, I definitely want to know what that's about.  Turns out it was all about something we had talked about before, which is EVCerts, Extended Validation Certificates.  And I was really pleased to see that the panel is as upset as I am about the proliferation of certificate authorities.



Our old-time listeners will remember how I was ranting - perhaps a little more than necessary, but still - over discovering recently when I went and looked at IE's list of qualified certificate authorities, that this list had just exploded since I had looked at it many years ago.  I think once upon a time there was maybe 11 certificate authorities, meaning that there were 11 organizations that were able to sign SSL certificates.  Well, the list has just gone insane.  And my argument was, the problem is, from a security standpoint, even though everyone ought to have the right to create a - to become a certificate authority, from a security standpoint just, I mean, common sense tells you that the more of those there are, the greater the chance of a mistake.  And mistakes have been made.  The famous one, of course, was a bad - somebody malicious got a Microsoft certificate.  And so it was like, oops, that was revoked, and everyone's recovered from that.  But, I mean, there have been...



LEO:  That's important to remember, though, the certificate doesn't guarantee safety.  It just means it's revocable if it turns out somebody's misbehaving.



STEVE:  Well, okay.



LEO:  It guarantees identity.



STEVE:  Well, what has happened is the standards have been lowered over time.  So that, for example, and I was curious about that, I went over to Go Daddy just thinking, okay, well, you know, these guys are sort of, you know, the budget domain name guys, and they offer certificates.  Well, they literally say here's a - I don't remember what the numbers were.  But it's like, $49 or $39 or something for an SSL certificate that just verifies your domain.  So what they're doing is they're doing domain validation only, nothing else.  So now all an SSL certificate really means is that you're connected to the domain that you think you're connected to, but it says nothing about who owns that domain.



LEO:  Hmm, interesting.



STEVE:  And so, I mean, I'm paying - what am I paying?  I'm paying $500 a year, although I think I buy three years at a time to get, I mean, because it bugs me, but I buy VeriSign certificates.  GRC is 100 percent VeriSign.  And so for three years it's $1,295.  But I have to go through some hoops.  I mean, they check out my D&B.  We do some faxing.  Sue, my office manager, gets a phone call.  I mean, so...



LEO:  Good, good.



STEVE:  ...there is some - well, but the problem is, there's nothing to say that I have a VeriSign certificate or a Go Daddy.  I mean, both gives you the same SSL connection. And Go Daddy's $39 certificate, or it's $29.95 or something, I mean, that gives you the lock on your browser window even though it doesn't mean nearly as much as...



LEO:  So that is interesting.  Somebody must have said to Go - somebody, some master certificate authority must have said to Go Daddy it's okay to do this; right?



STEVE:  No, Go Daddy is a CA.



LEO:  They are.



STEVE:  Yes.



LEO:  Well, who gave them the right to be a CA?



STEVE:  Well, look through the CA list, Leo.  I won't...



LEO:  I know, the Hong Kong Post Office, I know.  So who is it that awards this ability?



STEVE:  Well, it's - okay.  Each browser manufacturer has - it's the browser that contains the master list of CAs.  So Fox - FoxPro.  Firefox.  Firefox brings one.  Opera has theirs.  Safari has theirs.  IE has theirs.  However, they pretty much all have to have the same ones that everybody has because anybody who's issuing SSL certificates to websites, their browser has to be able to get a secure connection to that website, or it puts their browser at a competitive disadvantage to...



LEO:  And of course Go Daddy's huge, so they've probably got to do it.  But shouldn't there be some standard for what a certificate authority requires?



STEVE:  Well, and thus - thank you, Leo.  We've walked right into what EV certificates are.  First of all, they are a lot more expensive.  They are double the price, in the case of VeriSign.  Now, once again, Go Daddy does offer much less expensive, actually half price.  For example, a one-year VeriSign EV certificate is $995, a thousand dollars.  Two years is $1,790.  So you get a discount, as typical with domain names or anything like this.  Go Daddy's one-year EVCert is half that price, it's $500.  Actually, it's $499.99.  And their two-year cert is $800.



LEO:  Okay.  So they're half price.



STEVE:  So they're half price.



LEO:  Do they do the same thing?  Is the EV certification required?



STEVE:  Yes, yes.  There is a formal document that specifies what every certificate authority has to do in order to be able to issue EVCerts.  And any certificate authority that short-circuits that process, that doesn't go through the level of validation required, is at risk of having their CA, their ability to set the EV bit, essentially, I mean, this is just one bit in a standard x.509 SSL certificate.  All it is is a bit.  But they will have that revoked if they start issuing these things cavalierly.



LEO:  Okay.  All right.



STEVE:  So, now, get this.  Apparently whatever it is you're put through to get one - and frankly I'm so sold on this, much as I hate the idea of having to pay the price, I'm going to.  So I'll know what it takes at some point.  But apparently it can take up to three months to qualify.  You have to, I mean, I don't know if it's a DNA test and you send them blood or - but, I mean, my eyes glazed over.  And I'm thinking, god, I hope I will be able to get one of these.



LEO:  Yeah, no kidding.



STEVE:  Because, I mean, they verify that the people, the identities of the people who control the domain, who control the server, I mean, there's all this stuff we go through.  So it's not just a domain name.  It is, I mean, they're really validating the company, the corporate entity, the ownership, the management, the structure, the executives, I mean, it is seriously rigorous.  Now, to give you some sense of the relative number of these, first of all, for a long time IE - IE7 was the first Microsoft browser that supported extended validation.  And so there wasn't a big pull for it.  So at this point today the number I heard quoted was that 5,000 EVCerts have been issued.



LEO:  Now, in IE7, if I go to an EV certified site, does it look different?  Is there some way...



STEVE:  Oh, that's what's so wonderful about it.  It's why I have to have it.  Yes, Leo.  Go to - you can go to PayPal, or you can go to VeriSign.  So, for example, https://www.verisign.com.  That'll give you a secure connection.  And under IE7 and Firefox 3 and Opera 9.5 - which is not out yet, but that's in beta.  So EVCert at the browser level is spreading beyond IE.  And you'll see that the bar turns green.  And on the right-hand side it identifies the company, the corporate entity behind it because that's what the EV certificate is, it's what you paid for.  I mean, and the reason they're getting twice the money is, first of all, they can.  But, I mean, they are really doing some serious work in order to, I mean, I guess at each end.  I'm doing work and they're doing work in order for me to prove to VeriSign that I am who I am.  So but the point is, how many times have we said, okay, right-click on the page, go to page properties, click on certificates, get the certificate, look at the chain...



LEO:  You don't have to do that anymore.



STEVE:  Exactly.



LEO:  Now, I have seen studies that say that consumers have no idea between, I mean, they'll look at the green bar, go oh, that's pretty.



STEVE:  That's today, Leo.  I mean, this is...



LEO:  You've got to raise awareness here.



STEVE:  Well, what's happened is the SSL certificates are now so easy and cheap to afford if all you're doing is protecting your domain name, that phishing sites are buying them from Go Daddy.



LEO:  Why not, yeah.



STEVE:  Exactly.  Because, oh, look, there's a lock on my browser.  This must be secure.



LEO:  It must be my bank.



STEVE:  Right.



LEO:  Despite the fact it says Hacker.com.



STEVE:  Exactly.  So, I mean, we know that consumers are freaked out about online commerce, about online banking, about online purchasing, about online everything having to do with their credentials and their money.  And so this is new, but this is going to happen.  I mean, I've known about EVCerts.  We've talked about it before.  I wasn't sold until I really thought about it.  And frankly, it was this presentation.  The guy in charge of security from Mozilla was one of the guys on the panel.  One of the other guys was the guy I mentioned who was at CERN who misspelled "referer" in the original HTTP specification that only has one "R" in the middle instead of two, the way he spelled it.  And so, I mean, these are serious good guys who are talking about, you know, this is why we've had to do this is that SSL certificates got to the point where they meant nothing because there weren't these standards in place.  I mean, it was like, you're supposed to do this stuff.  Well, that just got weakened over time.  So we absolutely want to hope, need to hope that the same will not happen with this.  But, I mean, everyone understands the mistake that was made.  And so EVCerts, I'm convinced - I'm thinking in fact of switching GRC over 100 percent to SSL, that is, just make all of our connections SSL, since it's just a warm fuzzy thing.  And I like the idea of, I mean, especially GRC being all about security, of us just having unsniffable connections 100 percent of the time.



LEO:  You know who's not?  Amazon.com.



STEVE:  Yeah, I know.  And I thought eBay would be, too.  But they're not.  And PayPal, but PayPal is.  So, but Leo, only a thousand EVCerts have been sold yet.  So it's, well, I forgot to say, as opposed to 850,000 generic SSL certificates.



LEO:  Now I'm using all my different browsers to see who's supporting it, which sites are doing it, which sites are not doing it.  And then we've got to get the word out to consumers that this exists.



STEVE:  Well, what'll happen is, they'll begin to sense it.  You'll begin to see...



LEO:  The green does jump out at you.  It really does.



STEVE:  Yes.  The green bar, and I love the fact that they - oh, in IE7, if you left-click on the name of the company, it pops up in a window that says VeriSign has verified that this is this company.  So, I mean, they're pushing it to the next level, saying okay, we're going to give you a certificate that we're really going to stand behind, "we" VeriSign, for example.  So we're going to do the work to make you prove that you're who you - that you are who you are, that this is a corporate entity in good standing that owns this certificate, such that when you click on this, we're going to be making that warranty to the end-user.



LEO:  Right, right.



STEVE:  Anyway, it's going to end up being very important.



LEO:  Yeah, no kidding.  So it's too bad, of all the major browsers, Apple Safari is the only that isn't currently supporting it.  Firefox 3, as you said, Opera 9, and IE7 all do.



STEVE:  And I don't know why Safari hasn't.  Well, again, there is a bit of a chicken and egg.  I'm sure you remember back in the beginning of the web, people were sure it wasn't going to take off.  Because they said, well, but why are people going to have websites when there's no users, and why are there going to be users if there are no websites?  Well, that problem solved itself, obviously.  So the same thing is going to happen here.  This is an important good thing that is going to, I think, go a long way to strengthen regular end-user consumer.  And so what'll happen is, people won't use Safari when they want the EV certification if they have a browser that lets them know.  And so Safari will have to do it.  And other high-end websites that are suddenly not green when an increasing number of sites are green, well, the ones that aren't are going to have to belly up to the bar also.



LEO:  Right.



STEVE:  So there will be pressure on...



LEO:  Oh, you bet, you bet.



STEVE:  There'll be pressure on Safari to join the other browsers.  There'll be pressure on non-EV sites to join the EV parade.  And before long it'll just be - there will still be $29.95...



LEO:  Yeah, and I'm going to, you know, somebody like me is going to do that.  I'm not - there's no - well, if I ever - I don't - I'm not in SSL at all.  But I'm not doing eCommerce, so there's no, I mean, I'm not going to spend $2,000 for a cert.



STEVE:  It does hurt.



LEO:  Yeah.



STEVE:  It does hurt.  Just for some bits.  Thank you for this little pile of bits.



LEO:  Well, I understand why they charge that much.  If they're doing that much validation, if they're actually calling you and doing all that stuff, that's expensive.  I can understand that.  I don't know if it's that...



STEVE:  Yeah, and similarly you can understand why Go Daddy says, hey, $29.95 you can have a cert.  We're not saying anything other than, gee, it's www.mysiteoftheday.com.  That's all we're going to do.  But if you want a padlock, you can have one.  And what that does...



LEO:  Well, it gives you SSL, though, too.



STEVE:  Exactly.  It gives you SSL, which is a good thing.  And it no longer costs a lot.



LEO:  Right.  And that's, I mean, for that alone I think it's worthwhile, you know, just to encrypt your transaction with websites.  If everybody did this, we wouldn't have to worry about VPNs and all this stuff because you'd always be encrypted as you surfed.



STEVE:  Right.  And email clients are now supporting SSL connections, so that would allow, I mean, it makes it very simple to keep things encrypted.



LEO:  Yeah.



STEVE:  And it's no longer a big, huge expense to do so.



LEO:  Now, let me just - we've talked about some of the things you saw at RSA.  And I think that - it sounds like it was a great conference.  But just overall, what's your sense of it?  Are we winning the battle against bad guys?



STEVE:  No.  The overall sense I got from listening to the keynotes, from attending all of the, well, many of the individual tracks as I was able to, and as I said, I wish there were five of me, there was this sense of sort of doom and gloom.  It was like, you know, it's like we're losing.  The problem is, as we've talked about before, the 'Net was designed for sharing.  It was not designed for securing.  It was designed to be open and sharing.  You put up web pages, and everyone can look at it.  I mean, and so here we are trying to come along later and fix the fundamental lack of security.



And similarly, I mean, one of my other favorite quotes, and I don't remember, I think this might have been from the Symantec keynote, was something that really stuck with me.  They were saying, "Do not protect the network, protect the information."  And I thought that was an interesting distinction because the sense I got was that our much-reviled DRM, which has up to now been used by commercial publishers to lock and control what's done with their content, I could almost foresee a day when DRM is sort of ubiquitous and is as useful and used by end-users as it is by commercial publishers.  The idea being that I've talked, for example, about the files on my little key ring and how I'm using TrueCrypt in order to protect them.  But the problem is you need to have admin rights, and that's why the IronKey solution has some compelling advantages because you don't need to be an admin in order to be able to unlock your IronKey.



But imagine if all files had DRM?  I mean, everything the computer produced.  If that was a fundamental part of even a text file, it was everything was in some kind of securable wrapper so that that just becomes ubiquitous, I mean, we are so far away from there today that I can't even think about how we get there.  And we don't want to think about how we get there.  But, I mean, it's just like, doesn't that make sense?  And then you don't have network perimeters, you don't have this problem of, oh, crap, somebody got in and now what can they do because you just open your door and say come on in.  All of our files are individually protected using some amazing new alien technology that we don't have yet.



LEO:  Well, encryption.



STEVE:  Some, yeah, I mean, but it's - yeah, something.



LEO:  You know, sometimes I think that these proclamations might be self-serving.  But it seems like it would be easier to protect the data than to protect the network.  Much easier.



STEVE:  Whoo, I think it's much harder, actually.



LEO:  Oh, really.



STEVE:  Oh, yeah.  I mean...



LEO:  Well, then, why not just protect the network?



STEVE:  Because that doesn't do the job.  We're trying to protect the network, and we're failing.  And so the idea being - well, and...



LEO:  I guess that's what I mean by it's easier to protect the data than - if you can't do it, then it's not that easy.



STEVE:  And, for example, here I am in my fortress of solitude, as you frequently - or fortress of security or something.  And, I mean, I'm behind a ton of protection.  So that's neat.  But when I walk out of the house I've got my files on my thumb drive on my key ring.  Now I'm outside of my network.  And so now that's not protected.  And so I just, I mean, the kernel of the content - I'm not saying, I mean, Symantec's not selling it.  They don't have it, either.  But I just - I sort of got this interesting, it's like protect the information, meaning that this notion of ownership and authentication and rights, the idea of digital rights being useful to end-users and part of our experience, part of our use of information so that, I mean, again, we are so far away from having that, it just makes your eyes cross.  Because we're talking about a whole 'nother infrastructure, and everyone having public and private keys and/or whatever, I mean, I don't even know how we would do this.  But it's like, wow, that's the answer.  I mean, it's impossible, but that's the answer, is that fundamentally when we create files, the files protect themselves.  And somehow they know who's supposed to be able to open them to get the information out of them.  It's just an interesting idea.



LEO:  Seems like we could do both, attempt to protect the network and protect the data.



STEVE:  It's just, well, no one's - yes.  And I was just being facetious when I said that everyone's going to take their firewalls off and just say, oh, come on in because...



LEO:  Let's do both.



STEVE:  ...why not.



LEO:  What the heck.



STEVE:  But I have to say - and again, speaking of being self-serving, we're at the RSA Conference 2008.  So it's all about solutions for security.



LEO:  Right, right.



STEVE:  So, yes, okay, we're trying to promote security.  But there was this sense of a cloud.



LEO:  I agree.  I feel it, too.  I mean...



STEVE:  Well, and end-users feel it.  Like this is all becoming too hard to use, and security, and multifactors, and I need all these things, and I'm afraid to do stuff online...



LEO:  And ultimately it fails.  You can't really be safe.



STEVE:  I don't think I mentioned that I've had to cancel my most used online credit card.



LEO:  Oh, boy.



STEVE:  Three weeks ago it got out of some site that I use, as careful as I am, as I try to use PayPal and Google - what's Google thing?



LEO:  Google Pay.



STEVE:  Google Checkout.



LEO:  Google Checkout.



STEVE:  Google Checkout, yeah.  I mean, I try to use those to minimize how many different websites I give my credit card information to.  But there's lots of sites that don't take PayPal and don't take Google.  I mean, my own, for example.  And so somehow I got a call from a robot on the phone saying, "Please hold for security."



LEO:  Yeah, no, we did talk about this last week, yeah.



STEVE:  Oh, okay.  And so it's like, okay, well, so, there again.  I mean, again, my card was protected by the company that blocked those.  It was sharp enough to block them.  But that's an example of what happens to some consumers.  I mean, so this kind of secured information gets loose.



LEO:  And we look at spam, and that's completely out of control.  And as you said, now it's a security hazard as much as anything else.  I mean, it just doesn't feel like we're gaining on these guys.  It feels like they're gaining on us.  And it's really frustrating because they're jerks.



STEVE:  And I think at this point it would be fair to say that the bad guys are winning.



LEO:  Ugh, you know, I mean, excuse me, I mean, obviously this is - everybody knows this.  But just, you know, you're taking something really incredible, really powerful, really useful, and just trashing it for no real good reason, just so you can make a little extra money.  I mean, it just frustrates the heck out of me.



STEVE:  Yeah.  I have to say, Leo, my sense is we're going to win.  I think, I mean, we've got a long way to go because we, the good guys, we started out nowhere, with technology that was operating systems where security wasn't - network security wasn't an issue because there was no network.  They were standalone computers that got stuck onto the 'Net.  And of course we all know the story of Windows and how long it took to get a firewall in Windows that was on by default.  I mean, it took until Service Pack 2 of XP, the current service pack of XP.  Not even an old service pack of XP.  So it's taken a long, long time.



But there will be - certainly there will always be problems.  But I think we're going to get authentication, we're going to get - well, for example, when everybody has SSL certificates because they're no longer expensive, and exactly as you said, then sniffing all goes away because no longer will your email username and password be going through an access point in the clear because the first thing you'll do is set up an SSL connection and encrypt the tunnel.  And, I mean, so there will still be problems.  But incrementally we're going to win this, I think, long term.  I don't know if you and I will still be around...



LEO:  Oh, that long term.



STEVE:  Oh, yeah, yeah.



LEO:  Oh, we're a ways off.



STEVE:  Oh, yeah, yeah.  It's not happening soon.  It's difficult to see how we get there.  And due to the need for standards, and this has to be done in a standards way, it's going to be baby steps.  It's like the EVCerts.  EVCerts is a perfect example of a good step forward which ultimately - again, it's chicken and egg.  Ultimately commercial websites will have to prove that they are who they say they are, and they'll be able to advertise that in the bars of web browsers.  I mean, it's - the other thing that was so clear to me, and I'm sure this is not news to our listeners, but the web browser is our window to the world.  I mean, it is the application now, especially with Web 2.0 and 3.0.  It's the way you do things.



LEO:  We're going to talk a little bit about your Swedish lady and her amazing authentication system.



STEVE:  Oh, the one cool, I mean, the coolest thing I saw at  RSA Conference 2000.



LEO:  And she was just skulking in a corner because she'd been denied her booth.



STEVE:  Oh.



LEO:  That's frustrating.



STEVE:  And she was cute, too.  But, you know.



LEO:  Oh, now the truth comes out.



STEVE:  Swedish.



LEO:  Swedish.  Smart.



STEVE:  Stina Ehrensvrd, I think is how I would pronounce - no, Ehrensvrd, E-h-r-e-n-s-v-a-r-d.



LEO:  I just hope you got her phone number, that's all I can say.  He's not saying anything.  So let's talk about your Swede.



STEVE:  Yes, okay.  Go open your browser, Leo, www.Yubico.com.



LEO:  Yubico.com.



STEVE:  Yubico.com.



LEO:  Follow along in the home version.  Oh, there she is.  She's the CEO, and she's very attractive.



STEVE:  Yes, and, okay.



LEO:  Not that we're focusing on that.



STEVE:  No, no, no.



LEO:  This is an authentication system.



STEVE:  Look at the little picture of that thing.



LEO:  It's a key, it looks like, a USB...



STEVE:  Oh, yes, it is, Leo, get a load of this.  It is a USB tiny thing which is a USB keyboard.



LEO:  What?



STEVE:  With a one-time password system.  So you know how you can have USB keyboards instead of, like, USB thumb drives or...



LEO:  Oh, it shows up as a keyboard, I get it, I get what you're saying.  The driver is using the HID driver.



STEVE:  Exactly.  So it is a USB keyboard.  And...



LEO:  Wait, I don't see any keys on it.



STEVE:  No, and that's just it.  Okay.  See the little circle?



LEO:  Yeah.



STEVE:  That glows green.  And it is a touch button.



LEO:  Okay.



STEVE:  So when you - okay.  So for people who aren't seeing it, let me describe it to people.  It is a tiny little wafer.  As our listeners know, I'm very sensitive to the size of the junk on my key ring.  I just can't have, much as I love the IronKey, I have a tiny little Kingston 4GB thumb drive because I actually can have it on my key ring, and it doesn't bother me.  So Stina was standing there at the top of the escalator, heading down toward the...



LEO:  Did she invent this?



STEVE:  Yes.



LEO:  How cool.  Stina Ehrensvrd.  We should give her credit.  Wow.



STEVE:  She's the CEO, the founder, and the inventor.



LEO:  She is so cool.



STEVE:  Isn't it?  It's just a perfect solution, Leo.  I mean...



LEO:  Well, tell us how it works.  Tell us how it works.



STEVE:  Okay.  So she sort of stops me, kind of, as I was getting ready to go down to the convention floor, and said are you with the press.  And I had my press credentials, which the RSA folks were kind enough to provide me.  And I said yeah.  And she said, well, I have something that I want to - can I talk to you for a minute?  And I said of course.  And so she holds this little thing, which is just, I mean, it's wafer thin.  I know that you and I have seen, like, USB thumb drives which are just like a little plastic wafer, that is all they are is like the four little contact fingers with a little - and that's what this is.  So it is, I mean, it weighs nothing.  It's got no extraneous fluff on it.  And she says this is a one-time password authentication.  And I'm like, yeah, I know, the floor is full of those.  And then she says it's a keyboard.  And I said, what?  She says, it looks like a keyboard.  And it's like, oh my god.  And I then...



LEO:  You got it right away?  Wow.



STEVE:  Well, yeah.



LEO:  Okay, you better help us because we're a little slower than you.



STEVE:  I live in this space.  So, and I said, that is so cool.  And then she sort of apologized because here she was pulling random people off to the side to show them this.  And she explained to me that she had a deal and they reneged because she was supposed to be in one of the major corporation booths, but they decided no.  And I think it's because they didn't have anything nearly as cool as this thing.  So, okay.  So the idea is, first of all, no battery.  Unlimited shelf life.  It lives forever.  Unlike many of the other, I mean, all of the other things have a battery.  Now, it does mean that you need to plug it in to use it.



LEO:  It gets power from the USB port.



STEVE:  Yes, it's powered from the USB port, which has 5-volt power...



LEO:  Wait a minute, I'm starting to see this now.  So it actually types in your passwords.



STEVE:  That's exactly what it does.  Which means it can be wacky and long.  So the idea is...



LEO:  Oh, now I get it.



STEVE:  Leo, it's so cool.  Yes.



LEO:  Okay.  So tell me what's going on inside.  What is it doing?



STEVE:  Okay.  What's going on in side is there's a nonvolatile counter that increments once for each power-up event.  So every time you plug it in there's a nonvolatile counter that increments by one.



LEO:  So just like the VeriSign key, except you don't have to press the button.  As soon as you plug it in, you're generating a new password.



STEVE:  Well, okay.  So then there's a second counter that starts at zero when it's powered up and counts once for each code.  And they use 128-bit AES to encrypt this.  So basically this is a one-time password system.  So, and you can - I've got to get some more of these so you can see it because I plugged mine in.  And they've got a bunch of demo stuff where you can, like, see it happen.  And the little ring sort of glows green.  And I was, like, pushing on it.  And I said, well, it doesn't go in.  She says, oh, no, it's just a touch surface.



LEO:  Ah, okay.



STEVE:  So you just put your finger on it and wait.  It takes about a second.  And she built a delay in so that it wouldn't misfire.  And then it spits out this long string of gibberish.  And we are very familiar, our listeners are familiar with long strings of gibberish because that's what this show is all about.  And I don't mean verbal.  So, and of course every time you do it, it generates a different long string of gibberish, which it's turned into ASCII, and it's typed by this thing pretending to be a keyboard.



LEO:  So if I, instead of using my PayPal dongle, I would use this.  When I get to the PayPal login, I type my password, then it says, okay, give me the dongle number.  I would plug in my Yubico key.  It would automatically type it in for me after I press that button, I guess.



STEVE:  Yes.  Now, what's very cool, there are a couple things that I really like about this that, much as I have  liked, when we talk about VeriSign, and we know that I think their credit cards are cool, you know, their one-time password system and the footballs and the dongles and all that, it does bug me that their business model requires major corporations to buy tons of these and then use VeriSign as the back end.  That is, so VeriSign servers are performing the authentication.  I've looked at, as we've said, I've vetted the API, I've looked at the protocol, it's 100 percent private.  They're doing nothing, they're asking for no information they don't need.  Basically they're saying what's your dongle number, what does the dongle tell you, yes, that's good.  I mean, that's all they're doing.



But it means that, for example, as we know, my next product is going to be a really cool, next-generation VPN solution.  Well, I can't use VeriSign because I'm not a big guy.  I'm not Bank of America or PayPal or eBay or one of these huge companies.  But I could use this because they offer a low-level SDK in C and Java, meaning open source, with all the code.  So I could build the authentication into the VPN client itself so that when you're out on the road roaming around, you could use a YubiKey.  Oh, and by the way, these are $4, depending upon quantity.



LEO:  Wow.



STEVE:  So they have backend servers if you want to use them.



LEO:  They have a web API.  They have a web service.



STEVE:  Yes.  And they are fully OpenID compliant.  So you can use this as your OpenID authentication.



LEO:  Oh, I'm liking it more and more.



STEVE:  And they have a PAM module, so you can use it for logging into Linux and Macs and anything that has PAM. They support - they have web clients in Java, C-Sharp, .NET, Python, PHP, and Ruby.  So pretty much any website would be able to use this.  It's just - it is a cool solution.  Now, one way it differs from, for example, the VeriSign credit card and football is you could use those, for example, at a web kiosk to authenticate.  That is, you could use those where you had no access to USB, that is, where you can't get to a machine's USB.  But, for example, in a corporate environment where you want to have a corporate VPN, and you've got roaming laptop users, well, this is a really nice third-factor, multifactor authentication solution.  And I just, the cleverness of it being a keyboard, a USB keyboard that all operating systems support - Macs know about USB keyboards, Windows, Linux, I mean, it's a universal standard.



LEO:  That saves me from typing in some crazy, goofy password, too.



STEVE:  Oh, and these things, I mean, I've looked at it, at what it's typing in.  And it's just, you know, it looks like...



LEO:  Are they long, long, long?



STEVE:  Yeah, it looks like one of GRC's nutso Perfect Passwords, just gobbledygook, although it's all ASCII so that it doesn't have a problem getting through the web, and it doesn't need to be URL-escaped and all that.  So, yeah, it is a - it's not something you would ever want to type in. Every time you touch the button it generates the next one.  So it is a super-secure, one-time password system in the form of a super-tiny little USB thing that really could go on your keychain and be authentication.  And since they're providing OpenID and back-end, anybody who wants to use this could, like, get these and use them for authentication.



LEO:  You know what I like, let's say we wanted to do subscription-only access to, say, the video that we stream of this.  We could - you send us the subscription fee, we send you one of these.  And without that you can't get on.  We don't have to worry, we wouldn't have to worry about piracy or even, well, I guess DRM we would have to worry about because it's content.  But, I mean, that's pretty cool.  At four bucks a pop that's very affordable.



STEVE:  Now, again, I wanted to say, in a show that was all pretty much stuff that we've talked about, and everyone saying this is the world's most amazing security identity authentication stuff, I mean, here was one thing new.  And I just - I loved - I felt, of course, sorry for her story, that she would have been in a booth but she got removed.  It's like, okay, well, sorry about that.  Anyway, this thing is just - it is way, way cool.  And I wanted to bring it to our listeners' attention.  I mean, if we've got people who are, like, potential users, who are running websites, who have a need for some sort of authentication where, like - and what, again, I like about it is that you're not setting up a huge account with someone else.  You can do all the authentication yourself in your own server or in your own utility or whatever.  Just it's way cool.



LEO:  Now, by the way, Yubico.com.  And if you go there, she has on the front page somebody named Steve Osborrn saying "The coolest authentication hardware device ever."  I think she means you, Steve.  You might want to call her and say, uh, it's Gibson.  Of course we've probably butchered Stina's  name, too, Ehrensvrd.



STEVE:  Well, and I'm sure that's not me because...



LEO:  I think it is you.  There's no security researcher I know of named Steve Osborrn.  I just Googled it.  There's nobody there.  I think it's you.



STEVE:  Let's click on references.



LEO:  It's not mentioned.  It's not mentioned.  I think she threw that in, and she figured everybody's going to know who Steve Osborrn is.  I think it's you.



STEVE:  Maybe it was a language gap, yeah.  I mean, because she had, I mean, she was speaking English much better than I speak Swedish.



LEO:  Oh, yeah, all the Swedes speak English very well.



STEVE:  Well, if this is me, you have my permission to change Osborrn into Gibson because...



LEO:  It does sound like what you would say.  In fact, I think you say that.



STEVE:  You know, it's funny because I read that this morning when I was getting the URL.  And I thought, oh, isn't that nice, I wonder who he is.  Maybe that's me.



LEO:  It's you.  I'm pretty sure.  I don't see a Steve Osborrn in these other references.  I'm pretty sure it's you.  But I could be wrong.  If there's a Steve Osborrn listening, I apologize.  But he can't be that well known because he doesn't show up in Google.  And you do, by the way, if you type in Steve Gibson.  If you do, you'll get sent to GRC.com.  That's Steve's website.  That's where he sells SpinRite, of course, the world's finest, best, the only, really, hard drive maintenance and recovery utility that's worth talking about.  He also gives away a lot of great free stuff.  Oh, highly recommend visiting just the freebies on GRC.com, like ShieldsUP!, which you can use to test your firewall, Shoot The Messenger, DCOMbobulator, LeakTest, UnPlug n' Pray.  I love Wizmo.  You might want to take a look at the newest Wizmo plug-in, which turns off zero config.  I had a woman call the radio show Sunday, and she said my wireless keeps dropping its connections, it keeps dropping its connections.  And I went, oh, I know what that is.



STEVE:  And speaking of which, Leo, my tech guy, Greg, has had a constant problem with that.  And in his case, the wireless zero config, turning it off did not solve the problem.



LEO:  Ah, okay.



STEVE:  He did a lot of Googling.  It's been bugging him for months.  It was his laptop's modem.



LEO:  Oh, wow.



STEVE:  It was the modem drivers.  He disabled them, and the problem disappeared.



LEO:  That's why computer issues are so tough.  Because it's a million things.  It's such a complex system.  Well, Wizmo's fun even if lanlock, or wanlock I should say, doesn't do it for you.  It's certainly worth having.  And that's also where you'll go to get 16KB versions of the show, for those of you who are bandwidth-challenged.  We also have complete show transcriptions there, thanks to Elaine.  And we'll have show notes, and there's a lot of links.



STEVE:  Yes, we're going to be link-happy for this week's episode.  I'll get that page to you and Dane right away, Leo.



LEO:  Excellent.  Steve, I thank you so much.  Great talking to you.  And I, you know, I think this sounds like the RSA conference was worth your trip up to San Francisco.  Sounds like it was fascinating.



STEVE:  It was fantastic, and I'm really glad that this show is able to bring it to our listeners.



LEO:  Yeah.  We will see you all next week on Security Now!.  Thanks for joining us.  Take care, Steve.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#142

DATE:		May 1, 2008

TITLE:		Listener Feedback Q&A #40

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-142.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 142 for May 1st, 2008:  Listener Feedback #40.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, and we're going to talk about technology and security and protecting yourself online with Mr. Steve Gibson.  He is the man who discovered spyware, coined the term, wrote the first antispyware program.  He's been writing free security utilities ever since, including ShieldsUP! and Shoot The Messenger, DCOMbobulator, all at GRC.com.  He's also the guy behind SpinRite, which is the ultimate disk recovery and maintenance utility.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.



LEO:  It's May, it's May.



STEVE:  Nice to be back with you again.



LEO:  The lusty month of May.



STEVE:  We have, yeah, May Day today.



LEO:  Yeah.  Now, this is - Mayday is, of course, in French it means "help me."



STEVE:  Do the kids in elementary school still, like, get crepe paper streamers and do the Maypole dance and...



LEO:  Funny you should say that.  We talked about that this morning on the Giz Wiz.  I remember that from school.



STEVE:  Yeah.  Unfortunately I do, too.



LEO:  And they'd go over, under, over, under, so they'd braid.



STEVE:  Exactly.  And you end up with this, yeah, exactly, like a streamer braided pole that's really cool.



LEO:  Called the Maypole.  But yeah, I don't - I doubt anybody does that anymore.



STEVE:  Okay.



LEO:  We're antiquarians.  So we've got a Q&A for you today, some great listener questions.  We love it that you submit your questions.  It gives - what's nice about it is it's still Security Now! in the sense that we still - Steve still talks about security.  But it's stuff in response to your concerns and interests.



STEVE:  Yeah, the way I think of it is things that are, as you said, interactive and responsive, but also topics that really don't necessarily need their entire show.  But we can do it in a piece of a show, so it makes sense.  And we've got some fun things at the end of this, as well, as I always try to find some neat, wacky things.



LEO:  Oh, let me see.  I'm going to jump ahead.



STEVE:  There's even a bonus 13th one.  It's very short.  I called it the "Quip of the Week."  I just got a kick out of it.



LEO:  Quip of the Week, okay.  Good, good, good.  And some sobering truth and terrific observations and questions and answers.  Steve Gibson, do we have any errata or anything you want to cover?



STEVE:  Oh, we got tons.



LEO:  Oh, boy.   And security news, too, I'm sure.



STEVE:  Well, that's in there, too.  Yeah, I sort of call it all sort of like pre-Q&A stuff.



LEO:  Right, right.



STEVE:  Many listeners have been writing in to - GRC.com/feedback is the page on the GRC site for Security Now! listeners to send me their thoughts and ideas and questions and show ideas and so forth.  Many have been asking about a new gizmo called the Yoggie Pico, Y-o-g-g-i-e P-i-c-o, as in very, very tiny.  It's a USB system, I mean a full Linux PC running a small Intel chip in a USB dongle.



LEO:  Cool.



STEVE:  And it purports to be a security system.  So you plug it in, it installs a low-level NDIS driver, which is down deep in the kernel, that allows it to intercept all incoming and outgoing traffic.  Essentially it puts a Linux system in a USB dongle inline to your network connection.  So I just wanted to acknowledge all the requests from people about, gee, Steve, what do you think about that?  I mean, the idea sounds great.  I've noted it, and we will give it a show after I've had a chance to thoroughly scope it out and see how it works and if I see any problems with it.



LEO:  I mean, that's a neat idea.  I don't know about security-wise, but just the idea that you could run that Linux on a USB key is very cool.



STEVE:  Definitely neat idea.  Also out in the world, unfortunately, as many as half a million IIS, that is, Microsoft's web server-based sites - you've probably heard this, Leo, already - have been hacked.



LEO:  Including - this is the punch line - the Department of Homeland Security.



STEVE:  Yes, yes, and the U.N., and U.K. government.  The attack on Barack Obama's site was different than that.  They used some cross-site scripting to make some changes to Barack's campaign site.



LEO:  You clicked a link, and it'd send you to Hillary's page.  But this one is a SQL injection; right?



STEVE:  Yes.  This is, yeah, and we've talked about that before.  It's an SQL injection.  It uses - it's really not Microsoft's fault.  It is the fault of the web coders for not sanitizing the input.  It's Web 2.0 fundamentally is more interactive.  That's the whole idea, the notion of, like, posting comments to blogs and all of the Facebook/MySpace stuff where users are able to supply content.  But the problem is this content is typically being stored in an SQL, a.k.a. sequel, database.  And that's just sort of like the default database.  That's not what I use, but that's what everybody else uses.



And so what happens is because - and as we discussed in our SQL injection attack episode, if anyone's curious they can certainly go back and relisten to it, or maybe listen to it for the first time.  The idea is SQL is a language, so it's possible to inject language commands and essentially install malicious content on a website.  In this case they're installing JavaScript, which then is downloaded into innocent users' browsers, as JavaScript is.  But in this case it's not JavaScript the website provider wants you to run, it's JavaScript that's been injected remotely into the website.  So then it's downloaded into the innocent user's browser, runs.  That installs malware and takes them to a Chinese server, that is, an IP address in China, which then attempts to use known Windows vulnerabilities to further compromise their system.



So it's just bad all the way around.  And the only thing you can do is disable JavaScript, or selectively enable JavaScript.  I know lots of people have followed the discussion, we've talked about the NoScript add-on for Firefox.  And of course, although it's not as easy to use, it's possible to configure Internet Explorer so that it's not scripted by default, and then you selectively enable scripting on those sites where you trust them and/or they need to have scripting in order to be functional.



So, I mean, one of the things we're seeing, and I heard a lot about this of course at the RSA conference earlier this month, is we're seeing a huge move toward web-based attacks because this is so-called "low-hanging fruit."  I mean, there are so many vulnerable websites, so many web apps are being written without an eye toward security, that just creates, I mean, it's like a public server sitting there where anyone who knows the tricks is able to install their malware remotely.  And then anyone visiting that site gets infected.  So it's like it's the next big problem.  And of course we've been talking about this kind of thing more from a theoretical standpoint, like this was going to be a big problem.  Well, it's arrived to the point where hundreds of thousands of websites are now infected with this junk.  So...



LEO:  Something to point out, of course, is that even if they're infected doesn't mean the payload happens.  In fact, the guys who did the research said, you know, a lot of cases nothing happens when you go to these sites.  Also the servers that they point to are currently down, whether because it's so successful or more likely because they've been shut down.  And that's the problem from the hackers' point of view is these exploits are only good for a brief period of time.  Once they're discovered, the SQL injection still works and the code's still on the site; but it doesn't do anything because the sites that it points to are down.



STEVE:  Right, exactly.



LEO:  So I think it's right now not a problem.  I also, by the way, I just saw - because we've talked back and forth about disabling JavaScript.  Just saw a study of the hundred top sites.  80 percent of them use JavaScript.  It's almost universal.



STEVE:  Yup, and it's going to be more so.  I mean, it does power the next generation of the web.  So, I mean, and it's a mixed blessing unfortunately because, as we've said many times, you're downloading some web server's code into your browser and running it locally.



LEO:  The nice thing about your technique is you can selectively enable it.  So once you trust a site, you enable it.  The problem is the SQL injection attacks often infect trusted sites.  So you could trust a site today...



STEVE:  Yeah, very good, that's a very good point.



LEO:  You would trust the Department of Homeland Security, one would think.  But in fact it has the exploit on it.



STEVE:  Although I guess by disabling scripting by default and then selectively enabling it, if nothing else you are dramatically lowering your attack window.  That is, in general, I will follow links in news reports, and you end up wandering off of your well-trodden path all the time when you're out poking around the 'Net.  It's just sort of the nature of it.  I mean, it's why it's so cool is all that stuff is out there.  So unfortunately it's not always safe.



LEO:  One would hope that at a site like DHS, in fact they said this, you know, now that we know that that bug exists, we've fixed it.  So one would hope that they would become more secure.  So a trusted site would be somewhat safer.  One would hope.



STEVE:  Yeah.  An old problem has resurfaced.  There have been problems with Intel Centrino drivers.  Centrino is Intel's laptop WiFi platform.  An old, well-known privilege elevation problem has turned into, it's evolved into a remote code execution problem.  I bring it up because I just want to make sure that our listeners who are using the Centrino - it's the 2200BG is the affected device driver.  There's, like, four different varieties.  There's 3459 or something, and a couple others.  I checked one of my laptops, and that's the one that I had.  I had the 4559 or something.  But it's the 2200BG has a known problem.



The reason this is a concern is that it is - the way this works is you - first of all, there's no way to block it.  No firewall will prevent this from being a problem because it's an exploit, well, it's a vulnerability in the kernel driver, in the actual WiFi driver which is underneath every other sort of security defense the user can have.  So the way an attack would work is that some wiseguy who thought it was fun to do this would have a laptop at Starbucks, for example, and anyone whose laptop had not been patched to the current version of this driver could have malware installed even if they're not, like, hooked up to Starbucks' wireless.  You don't need to be even connected to the network, just the idea, I mean, just having your wireless adapter live allows it to receive these malicious frames down at the low level and get code installed.



So the only show notes I had for this week are a bunch of links for this problem to Intel's site.  There is one that allows you to run a little app of theirs that identifies the device driver type and version.  You need to have at least version 10.5 of this 2200BG wireless device driver.  If you know how to poke around in Windows and bring up the driver information for your WiFi, you can just do that.  I did that on my laptop.  That's how I know what model and version I had.  In my case it was at version 11.something or other on a different wireless device driver.



So I just wanted to mention it to our listeners.  It's not a huge big deal.  But nobody would like to be somewhere in public and get code installed on their machine.  And this is sort of a problem because these device drivers not being mainstream Microsoft problems may be old.  It may not be that anything has updated them for some time.  So users who have this Centrino 2200BG should make sure they're at version 10.5 or later.  And I've got links on this episode's show notes, notes-142, that you can find at GRC.  And I imagine that, Leo, Dane will probably copy those also over to your page.  So that's a good thing.



Bruce Schneier, the well-known cryptographer that we've talked about and mentioned many times - and I'm annoyed that I didn't get a chance to say hi to him at the show.  He was on one of the tracks, but he was on a different one than I was.  And so I missed being able to shake his hand and hang out with him and say hi.  But I loved something that he wrote.  He blogged about the conference.  And what he wrote so much echoed sort of what I said last week about some of these booths.  He said - I'm just going to quote one paragraph in his blog.  He said, "The booths are filled with broad product claims, meaningless security platitudes, and unintelligible marketing literature.  You could walk into a booth, listen to a five-minute sales pitch by a marketing type, and still not know what the company does.  Even seasoned security professionals are confused."



LEO:  I saw that.  I thought that was great.



STEVE:  Yeah, that was exactly the sense I had.  That's why I said they all sort of seemed to be the same because they were all saying oh, fantastic new security solution for authentication identity.  And then you go to the next booth.



LEO:  Fantastic new security...



STEVE:  Exactly.



LEO:  Yeah, yeah.



STEVE:  Also, after last week's episode, our intrepid transcriptionist Elaine shot me a little note.  Remember we were talking about sci-fi and "Andromeda Strain," I think.  I don't remember now what the context was.  But she said hey, Steve, this coming weekend...



LEO:  Oh, we were talking about Michael Crichton, a book...



STEVE:  Oh, that's right, Michael Crichton books and how good "Andromeda Strain" was, where we weren't that impressed with some of the more recent ones.  She said that this coming Memorial Day Weekend, so about three weeks from now, A&E cable channel are airing a new miniseries of a remade "Andromeda Strain" that was done by Ridley Scott.



LEO:  Oh, I want to see that.



STEVE:  Oh, baby, the guy who gave us the first "Alien" movie.  Anyway, there's a trailer around.  I tracked it down and saw it.  It's funny because I thought, oh, wow, I wonder if my newsgroups know about that, because I created - we have a grc.scifi newsgroup at GRC just because I love sci-fi so much.  And it turns out many of the people who hang out on our news server do also.  Way back weeks ago there was a thread all about this.  So it's like they already knew about this.  I've got to keep more current with my own sci-fi newsgroup.  Because I would absolutely not want to miss this.  It will be on DVD.  It's being released in June, I think, on DVD.  But oh, Leo, the trailer, oh.  I mean, it looks like it's everything you could want in a contemporary remade version.  Because the original one was, what, back in '75, I think.  I mean, so it was - it's dated even though it's a really good story.  Well, now we've got state-of-the-art special effects and cool, I mean, just like way much better.  So I wanted to let all of our sci-fi-interested listeners know that we've got a new version of "Andromeda Strain" on the way.



LEO:  That will be worth seeing.



STEVE:  A little miniseries.  And I did have one really cool, neat, fun bit of SpinRite feedback.  This one was titled "Skeptic Is Finally a Believer."  A listener, Ralph Montgomery, wrote.  He said, "Steve, I've been an avid fan for years, both of your excellent program SpinRite, and now in the podcasts of Security Now!.  Working in the information technology field for the past 21 years, I have used SpinRite on everything from MFM and RLL drives to today's EIDE/SATA drives with great success.  With these successes I took every opportunity to evangelize the product to friends and coworkers everywhere.  One particular coworker has listened to my praise for years with, 'Yeah, yeah, sure it works.'  I eventually convinced him to purchase his own copy of SpinRite a few months ago, which he used sparingly to check new drives after purchase.



"This past weekend, however, a friend of his referred a young lady to him with a nonbooting laptop, a laptop this recent college graduate had taken to all her professors and several other friends with no success.  She had a recent job's data which she had not backed up yet (she's a web designer) that she desperately needed for her client.  My skeptic coworker tried everything he could think of to get the system to boot, even removing the drive and attaching it to an external USB cable, and still could not access the drive and data.  Finally he pulled his copy of SpinRite bootable CD-ROM, booted the system, and watched it work for about 15 minutes on the first couple of sectors, recovering data, then scream through the rest of the drive finding nothing else wrong.  After completing the SpinRite cycle he powered the laptop off, restarted without the CD-ROM, and voila, a booting laptop with all the data intact.  A quick transfer to a new laptop, and his friend was very happy.  And you now have a convert."



LEO:  Wow, that's great.



STEVE:  And then he says, "Great job (but I knew that already <g>)."  So thank you for sharing that, Ralph.  I really appreciate it.



LEO:  What a nice story, yeah.  That's really cool.  Shall we launch right into our questions?  Are you ready?  You feel good?



STEVE:  Oh, I'm ready to go.  I feel good.



LEO:  Face the music?  Start with Jon in Adamstown, PA.  He wonders if Vista's User Access Control, UAC, is worth anything.  Hi, Steve.  I think it's User Account Control, I'm sorry.  I always call it User Access Control.  Slashdot recently carried an article describing how simple it was to bypass Windows Vista's much-annoying User Account Control (UAC) system.  The authors of a utility were annoyed by UAC, so they easily coded around it.  If this is true, is there really any security benefit?  They claim there isn't.  Can you let me know what you think of this?  Certainly I think it's good if UAC prompts before install; but if what the author says is true, it seems pointless to prompt on startup.  So I guess they're saying not a utility merely to disable it, but a utility that lets you go right around it.



STEVE:  Yeah.  This actually came up, or came to my attention, I guess, I don't know, a few days ago when Slashdot first had the article.  A bunch of people said hey, you know, what's the story?  Is UAC worthless?  And it's like, has it been circumvented?  It's like oh, no, now what?  So I went off and did the research, figured out what was going on.  And the good news is this is nothing.  So I wanted anyone else who had seen this on Slashdot, because it got a lot of coverage, to know that this is sort of a bogus report.



The deal is there was some sort of a utility which required admin privileges at startup.  Well, when you try to run a utility that requires admin privileges, UAC gets in your face and says do you want this to allow it to happen.  The problem is - and this is some sort of like a reboot utility that allows you to do multibooting or something, I didn't even really look too closely at what it does, because they wanted it to run in the startup group.  So if you put it in startup, every time you boot it's going to run, and so it's always going to prompt for UAC permissions.  So they decided that was an annoyance.  So they recoded it so it no longer does that.  And that's what was upsetting people.



Well, okay.  What they recoded it to do is they split it into two parts.  There's a service which you have to be an admin and do UAC to install.  And then there's the client that talks to the service.  Well, this is the way Windows works.  And so this is not - this didn't circumvent UAC or get it out of the way or mean that it's worthless because in order to install this privileged service you have to use UAC to get permission to install it.  Now, it's true you're not having to give permission every single time you use it.  But, I mean, you couldn't use Windows if you had to give Windows permission every single time any service did anything.  So this is just the way Windows works.  You install something that you're giving privilege to, like a firewall, for example.  And then afterwards it's god because it's down in the kernel doing whatever it wants to.  So you're trusting it from then on and not having to deal with it every single time it runs.  So this is just UAC the way it was meant to be used, not a circumvention of anything.



LEO:  Got it.  So don't get your hopes up, hackers.  Jesse in Honolulu, Hawaii wants to know more about the YubiKey.  This was that thing we talked about the Swedish lady from RSA; right?



STEVE:  Yup.



LEO:  Aloha, Steve and Leo.  When I heard the story of Stina and the YubiKey, I immediately went online to do my homework because the thought of a $4 authentication token was too good to pass up.  Well, I read a little more; I'm not as excited.  YubiKey's ordering page has two products available:  a single key you have to agree to use for evaluation purposes only, and the "pilot box" which comes with 50 keys.  A small business would never go through that many keys, but it doesn't look like Yubico offers any smaller packages.  It even costs 4 euros more per key when you buy them in bulk.  More.  My other concern with YubiKey is how they're locked into Yubico's web service.  Sure you can purchase the low-level C or Java SDK, but for how much?  I took a look at the open source APIs.  They all seem to rely on the subscription-only YubiKey web service.  The YubiKeys only come with a one-year subscription, according to the site.  Am I missing something obvious?  YubiKey does sound like a good alternative to SecurIDs, but not the holy grail.  Do you know otherwise?  And by the way, thanks for Security Now!.



STEVE:  Well, okay.  First of all, there's been a lot of interest in the YubiKey surfaced by our users.  I wrote to Stina, and we set up a little - we've got a little dialogue going.  She reported, I mean, she was really happy with my mention of it last week.  More than 50 users and companies who listened to Security Now! have contacted them via email.



LEO:  Wow.  Wow.



STEVE:  So it's been very good for her.  And many people also in the Security Now! newsgroup at GRC - I do have a Security Now! newsgroup in addition to a sci-fi newsgroup at GRC.  And they had a bunch of really good questions because it's sort of unclear from the website exactly how this works.  So I said to her, gee, you know, a lot of really good questions are being asked.  I don't have the answers.  I'd like to find out.  So she has sent me one of the patents that they've applied for, an in-depth security analysis, an independent security analysis of how this thing all works.  I'm going to figure it out and probably do an episode to explain what this is and how it works because it's got a lot of interesting characteristics.



So I sort of wanted to acknowledge Jesse's frustration.  And the sense is that this is still just beginning to happen.  Stina said - I asked her, like, for all the developer documentation.  She said, well, we're still working on getting the server documentation done and putting it all together.  So this is a relatively new thing.  Ultimately I'm hoping that it'll be available in a way that makes sense affordably.  And I don't have any firm pricing on things like the subscription where you use the back-end service and all that.  I certainly like the idea of being independent of that, in which case there's no one-year expiration on the key.



LEO:  Well, and yes, you're dependent on it.  Besides the fact that you have to subscribe to that, if their server went down, you're kind of out of luck.



STEVE:  Well, it's funny because I got a notice from VeriSign the other day to, like, major accounts, saying that for four hours their VIP system was going to be done for, I mean, like, major maintenance and cleaning out and upgrading and all that.  The problem is, imagine if you were dependent on that for authenticating something in mission critical, I mean, during those four hours you need to do something that requires authentication.  I mean, that's really...



LEO:  You can't even...



[Talking simultaneously]



STEVE:  No, that's not okay.  So, I mean, it is the case that, well, and I know for example that Hamachi users similarly - Hamachi had to be in the loop.  Anytime the Hamachi servers were down, the whole Hamachi - you could maintain your existing Hamachi connections, but you couldn't initiate any during that window.  And it caused people huge pain because they were in love with Hamachi, and suddenly nothing worked that they needed to have work.  So these sorts of things, I mean, it's one of the reasons for my own, you know, I've talked about CryptoLink, the VPN that I will be working on as soon as I get the current project finished, that it's going to have a full, not only TNO, meaning Trust No One, but RNO, Rely on No One.  So that it'll do its job without needing any sort of a third party because it's just - you can't have that with reliability.



LEO:  Right, right.  Yeah.  Of course you running your own server could be unreliable.  But at least it's your own damn fault.



STEVE:  Well, yes.  And if in fact you're trying to connect to your own server, if it's down, well, you can't connect to it anyway.



LEO:  Right.  Well, that's a good point.  Now, would that be a security flaw, to have your authentication running on the same server as the thing you're authenticating?



STEVE:  No.



LEO:  No.  Just thought it might.  Nick Bauer in Newmarket, New Hampshire wonders about Killing Bits:  Hi, Steve.  I noticed this patch to Windows come down the pipe last Update Tuesday, and I wondered what it is.  Sounds like it might be a DEP for ActiveX.  Are ActiveX controls now a lot safer?  This guy must be a cowboy.  He's very terse.  So what's this patch to Windows come down the pipes last Update Tuesday?



STEVE:  I saw that, too, and I was wondering what it was because they were talking about a kill bits...



LEO:  Oh, that's what it's called, kill bits?



STEVE:  ...update.  It's called kill bits.  This is a feature which, you know, thank goodness it's in Windows.  As we know, Internet Explorer is able to load ActiveX controls.  That's, for example, what Flash is.  Flash is an ActiveX control that is able to embed itself into Internet Explorer web pages.  And, you know, there are some utilities - I actually have one sitting here on my taskbar, I'm looking at it - which is able to disable Flash on the fly because sometimes Flash is a little more Flash than you want, when you're just trying to look at a web page and little bunnies are jumping all over the place or whatever it's doing.  These things do everything they can to get your attention, when in fact it's like, okay, fine, can I just look at the content please.



Anyway, what this thing does is this manipulates Flash's kill bit.  Every ActiveX control has a kill bit which the user can flip.  And what it does is it denies IE permission to load that ActiveX control.  And in the past, and this is like a couple years ago I'm remembering from Security Now! episodes, there have been really, really bad exploits where Microsoft had no patch.  And so our advice was, and we gave people links and...



LEO:  Oh, yeah...



STEVE:  ...go into the registry...



LEO:  Kill bit, yeah, I remember that.



STEVE:  ...here's the key, and set the kill bit because that way it'll turn it off until Microsoft gets it patched, then maybe you want to turn it back on, if for any reason you need the hairy eyeball ActiveX control.  I mean, some of these things are not anything anybody wants.  And so it's like - and in fact you can even turn them off without your system having them.  You can turn them off preemptively.  Then if it comes in or installs or reinstalls, the kill bit stays set, and IE is unable to run this thing.  So what happened is that a third party asked Microsoft to please set the kill bit for them.



LEO:  Oh, interesting.



STEVE:  And that was Yahoo!.  The Yahoo!, shoot, I had it in my head just a second ago, now it's gone.  The Yahoo! something or other.



LEO:  Messenger?



STEVE:  No, it wasn't Messenger, is was - can't remember now.  It was something we talked about actually in the last couple weeks.  It was a known exploit in a Yahoo! ActiveX control.  The problem is they don't have the facility to notify and download updates on the fly.  So this is a widely exploited problem, and they asked Microsoft please set our kill bit for this thing for us.



LEO:  Can you believe that.



STEVE:  So that's what that was.  It's not an improvement in ActiveX controls, however much we wish there could be such a thing.  It's just it's Microsoft doing Yahoo! a favor.



LEO:  Maybe - I wonder if that's part of their courtship.  It's a little test.



STEVE:  Yeah, we'll see how that works out.



LEO:  Yes, dear.  Will you turn on the kill bit for me, dear?  Yes, dear.



STEVE:  The Hatfields and McCoys at the moment.



LEO:  Yeah, well, they're not getting along too well together.  But they did the kill bit, which was nice of them.



STEVE:  Yes.



LEO:  All right.   Amir Katz in Kfar Saba, Israel, figured out how to grab all the SN episodes.  Actually somebody Twittered me a shell one-liner for it.  But I'll see what Amir came up with.  In Episode 140 you looked for different ways to enable your listeners to download many, or all, SN episodes.  You did not have a good solution, in my opinion.  There's a very simple way.  Since GRC.com/securitynow page has all episodes, you could use Firefox with the Download Them All extension - oh, yeah, that'll work - and download all links of certain types, including the - using the DTA filters.  It doesn't have a predefined filter for PDF files, so I created one.  And then with a few clicks you start a download of all PDF files from the page.  Of course we don't want the PDFs, we want the MP3s.  But if you want the PDFs you could do that.  Regards, long-time SN listener and proud owner of SpinRite.  Thank you, Amir.



STEVE:  So I just wanted to pass that tip on.



LEO:  You could also use CURL and a little regular expression parsing and create a one-liner that would download any of the TWiT podcasts because we use kind of a regular format for the names for this very reason.  So Security Now! is always SN-0 - well, not necessarily zero, could be number number number.  Could be in this case 142.  But I don't know what's going to happen when we get to a thousand episodes.  We'll have to add a zero.  The whole thing's going to break down.  But right now you could write a little - you know, it's funny, I'll put this in the show notes because somebody Twittered it.  It's short enough that they were able to send it in 140 characters to me using CURL, a little probably SED or something like that to parse it out, maybe AWK, I don't know, to create this kind of repeating - and which is a little shell script and would get them all.  For any of them.  All you have to do is provide the base URL, and you can get them all.  It's kind of clever.



STEVE:  It's funny, you were talking about what happens when we go to 999.  I'm reminded that I think it's in 2032 or 2036 or something, the 32-bit seconds counter in the NTP, the Network Time Protocol, wraps to zero.



LEO:  Really.



STEVE:  Yes.  And that's going to be a problem.  We survived Y2K, but...



LEO:  When's that going to be?



STEVE:  It's like in 2032, I think, it's 2030 something.  And I've sort of kept my eye on that, it's like oh, goodness.



LEO:  Well, you know what's interesting, UNIX runs out in 2038 because UNIX uses - the start date is 1970.



STEVE:  Well, that's what I'm talking about, Leo.  That's the date.



LEO:  Oh, you're talking about the UNIX.  But NTP - oh, because NTP is running UNIX.



STEVE:  It's 32 bits of seconds.  32 bits of seconds starting on January 1st, 1970...



LEO:  Oh, okay, yeah.  It's not just NTP, dude, it's everything.



STEVE:  That's what I'm saying, I think it's bad.



LEO:  It's not just the time servers, it's everything.  Yeah, because, well, I mean, I presume by then somebody will have had a 64-bit UNIX.  I don't know.



STEVE:  Yeah, we'll see how that goes.



LEO:  They'll have to rewrite it, I guess, because a lot of, I mean, wow.



STEVE:  I don't know how we're going to contact each other.



LEO:  2038, will we still be around?  I think we'll be up in heaven looking down.



STEVE:  I hope so.  But wait a minute.  2038?  30 years from now I'm going to be kicking.  I'm going to be going strong.



LEO:  You probably will.  I'll be looking down on you saying, "It's Steve's problem now."



STEVE:  And we will have dealt with the 999 podcast number by that time, too.



LEO:  Yeah, that's another question.  Okay, so that means we have another 860 to go.



[Muttering]



LEO:  If we're still doing this in 860 shows...



STEVE:  If we still have any listeners left...



LEO:  Oh, my goodness.  That's more than 10 years.  So, good, all right.  My plan is to do this for 10 years.



STEVE:  Okay.



LEO:  That's probably what I was thinking.  Although, you know, with TWiT I gave it four zeroes.  I thought TWiT would last longer, I guess.  Not so.  Joe Rodricks, listening in Massachusetts, has been clicking on a keyboard.



STEVE:  I think it's the Giz Wiz you need to give about nine...



LEO:  I know, that one needs more.  It only has 999.  You're right, it's going to run out next year or the year after.



Steve and Leo, I came across a new log-in method I thought I'd share.  Oh, another one.  This one's from an ING Direct account which I opened.  Well, the Dutch do it right.  Let's see what they've come up with.  When you log on, it first asks for your ID.  Then it prompts for two security questions.  Then it asks for a PIN.  It's this PIN that's interesting.  Your PIN is a 40 - I'm sorry, it's a 4 to 10-character numeric password.  However, you never type it.  On the log-in screen there's an image of a keypad which you click your PIN based on its numbers, or you can type your PIN's code.  The keypad has a layout just like a telephone, three rows of three numbers, the zero's on its own row at the bottom.  On each number there's a single letter.  The letter assigned to each number changes with each log-in attempt.  Oh, that's clever.  It's probably a Flash or something, too.  So if my PIN is 12345, I would look at each number and type the corresponding letters, which may be QOSPX for this log-in, then next log-in could be SLCUG, and on and on and on, each time you log in a different set of numbers.  Or letters.  I think this is an awesome idea, just totally fool a keystroke logger.  I won't access my ING Direct account very often, perhaps just weekly, so I don't find the security questions that bothersome considering the extra layer of authentication they provide.  I may not have explained this well, but I think it's worth creating an ING account just to see.  It seems to be a pretty simple solution that would fool all but the most sophisticated keystroke loggers.  Love the show, keep up the good work.  What do you think?



STEVE:  Well, I think it's a really interesting and neat idea.  Essentially what he's described is he's got a fixed PIN which is not changing.  And what it's presenting him with is a translation table which changes every time.  So on the screen is a translation table.  And he looks up his PIN by number, but he types on the keyboard the letters, the alphanumeric, I mean the alphabetic letters corresponding to the numbers.  And so they change every time.  And so it's clever.  The problem is, and there was a discussion of this at RSA a couple weeks ago, is that keystroke loggers really are absolutely doing screen captures now.  And so...



LEO:  So they would see the keys.  But it's a one-time deal; right?



STEVE:  Exactly.  The problem is it's reversible.  They would capture the screen and see the mapping table.  And then, knowing what was typed in alphabetically, looking at the mapping table, they'd go backwards through it and get the numbers out.  And the numbers are what never changes.  And at that point they would be able to log in...



LEO:  They'd know.  They only need to get it once, in other words.  Of course.



STEVE:  Exactly.  Exactly. So it's a nice idea.  But, I mean, unfortunately - I mean, it would take a sophisticated keystroke logger.  But unfortunately, sophisticated keystroke logger is now an oxymoron because...



LEO:  They all are.



STEVE:  They really are getting very sophisticated.



LEO:  It's actually the opposite of an oxymoron.  I don't know what that is, though.  A noxy...



STEVE:  OxyContin.



LEO:  Noxymoron.  Ryan Benz in nearby Irvine - hey Steve, he says, he's waving as he drives by - wonders about cell phone authentication.  Hi, Steve and Leo.  In the last episode of Security Now! you mentioned that Bank of America now allows its online banking users to add an additional factor of security for their log-in process through the use of a one-time code sent via cell phone text messages.  I've been using that.  I love that.  I love that.  It seems as though this mode of security is becoming more and more prevalent, but I'm curious about the security of sending cell phone text messages.  I remember Steve saying he doesn't discuss sensitive issues with his attorney on his cell phone.  Are cell phone text messages any more trusted and secure?  Is it possible for others to sniff this traffic?  Thanks for the great podcast.  Listener since numero uno.



STEVE:  Well, it is a great authentication solution.  I should clarify that when I was talking about not discussing sensitive issues with my attorney on the cell phone I was specifically referring to the old original era of analog cell phones because they were literally just open analog radios, and any police scanner or radio scanner could pick them up and listen.  You could listen to typically one side of the conversation, and some of them were quite fascinating.  And I decided I didn't want to be part of adding to the fascination of anyone listening to me talking to my attorney.  So today's cell phones are digital.  And on my list of things we will get to is a discussion of the cryptography used, and unfortunately its relative lack of strength, meaning that both systems, both CDMA and GPS - GPS?  GPM.  GPRS.



LEO:  I don't know where you're going.  GSM, is that what you're trying to say?



STEVE:  GSM, that sounds right.  I'm thinking, wait a minute.



LEO:  We're in acronym hell here.



STEVE:  CDMA and GSM both have been cracked, that is to say it is possible, by somebody who really, really, really wants to, to intercept conversations.  The question, though, is whether even that really represents in this case a problem because you are being sent by somebody who wants to authenticate that you are the owner of a cell phone and you have it in your possession.  So that's what the cell phone loop really does is they send you a text message which you type into the web page saying "just got it," meaning I have that cell phone.  So even somebody eavesdropping, and it's really difficult to do so on today's era of digital phones, not impossible, I mean, unfortunately possible as opposed to, like, really, really good crypto...



LEO:  Which is impossible, yeah.



STEVE:  Next to impossible.  Anyway, the point is that even somebody who happened to catch, you know, a random text message, well, they're not - they don't have your established HTTPS secure SSL session with the bank.  And any cookies you've exchanged hopefully are secure cookies, so they're in that secure tunnel.  They have no ability to get to the page to enter what you just typed in.  So even if it, like, had a banner, I mean, if it was skywriting and said, you know, here's my one-time code, well, nobody else can use it except you at that moment, and then it's not going to be good again.  So this really is, I mean, it is a clever, nice means for doing a multi - adding a factor of multifactor authentication.  And I just hope, and I presume, that these text messages are sent quickly.  I know that many times, for example, I'm seeing sites where they require an email loop.  And it's like, okay, we'll send you a link to click to authenticate.  And then you sit and you sit and you sit.  And it's like, okay, this is really not working if I don't receive my link immediately.



LEO:  Right.  Email can be slow.  Email is unpredictable.  I have found using this text messaging system, at least with T-Mobile, who's my carrier, and Bank of America, that it's every time.  Actually a number of other things, services use this.  And I haven't yet waited.  You can always resend.



STEVE:  I think it's going to be very popular.  I mean, it's a nice way of doing authentication for people who have cell phones with them.



LEO:  I love it.  I mean, it seems to me very much like the Secura Key.  I mean, it's a one-time password; right?  And I'm getting it by the phone, so I don't have to have a dongle with me.  I just really like that idea.  Moving right along, Neil Roberts in Liverpool, England, uses a literal firewall.  Oh, come on.  Literal?



STEVE:  Well, kind of.  I didn't know how to describe it.  But we'll see what I mean here in a second.



LEO:  Hi, Steve and Leo.  I mean, he's not putting bricks between himself and the Internet, is he?  Being paranoid about security, I've been an avid listener of every episode.  How about this for the ultimate security answer for online banking, PayPal, eBay, et cetera?  I have my regular PC which I use for day-to-day use, web browsing, email, Word, et cetera, but never banking or whatever, you know, secure stuff.  For the few highly sensitive applications I use an old G3 Mac running OS X v10.4.11.  I keep the OS up to date, as well as the Firefox browser.  I have it bookmarked with my bank sites, et cetera.  I only ever visit these sites via the created bookmarks - good, right, because those are always secure unless somebody's hacked in and changing your bookmark.  And I never use this Mac for anything other than visiting these bookmarks.  What do you think of that?



STEVE:  Well, it's funny, for a long time, and I'm sure our listeners have heard me say this, one of the pieces of security sort of advice I've had for, like, moms and dads is never let your kids use, like, the important computer that you have your banking and your checking and your stock portfolio and stuff on because...



LEO:  Because kids mess stuff up.



STEVE:  Well, and kids, lord knows what they're going to click on or where they're going to go or what they're going to do.  And so this notion of, I mean, literally having separate computers, it's like, give the kids their own machine.  And this is in Dad's den, the adult computer, the parents' computers.  And under no circumstances, even when Susie and Johnnie both want to be on the computer at the same time and she's desperate to use your machine, it just has to be no, it has to be off-limits.  So I really do, I really like the idea, if you've got an older spare machine around, to segregate its functions.  It's going to be pretty good.



LEO:  And he's - excuse me, I'm eating a cookie.



STEVE:  I stopped when you weren't expecting it.



LEO:  Usually you talk longer than that.  And by only going to the link as he typed it out, so he bookmarked it and typed it out, he prevents phishing.



STEVE:  Yup.



LEO:  He prevents getting infected by these kinds of cross-site scriptings or the SQL injections by not going to other sites.



STEVE:  He also prevents phishing because he's not ever...



LEO:  He's not even getting email, right.



STEVE:  There's no email on that machine.  So there's - literally it's what he uses as his clean, uninfectable, like his browser interface to his financial things.



LEO:  Would using a virtual machine in VMware have the same effect?  I mean, does he have to use discrete hardware?



STEVE:  It has very much the same effect, although you could have something on the outside which is filtering or involved in his traffic somehow.  And there have been some questions about whether virtual machines are really as secure as they - as being completely virtual.



LEO:  If something can cross the border between the real machine and the virtual machine.  So I'm running my Mac, and I'm running Hardy Heron, the new Ubuntu in a virtual machine of VMware.  Is that Ubuntu completely isolated from the Mac?  No, because I can see the Mac drive.  I don't know if a virus could go across the barrier, but...



STEVE:  Well, and again, seeing the Mac drive is a perfect example of, you know, one of the nice things about, again, an older machine that you - well, and the other thing, too, is the kids probably wouldn't want the old machine because you can't - it doesn't do anything, barely runs a web browser, which is just all it needs to do.



LEO:  Now, it's theoretically vulnerable because it is on the network.  If it's getting online, it's also on the LAN.



STEVE:  Yes.  And so, I mean, you really wanted to do it, you would use the triple router, the Y-connected triple router approach to give it its own LAN segment such that it can't reach the family LAN, and the family LAN cannot reach it.  And then it's a matter of discipline.  But again, good security is always a matter of discipline.  Under no circumstances would Neil ever go or do anything with that, no matter how tempting it is to compromise the security of it.  So it's up to him to maintain it.  But that's great security.



LEO:  Nice job, Neil.  And by using a Mac he's kind of, you know, even if it's a Windows network he's kind of - it's a good idea to do a different operating system, maybe using Linux in a Mac network just because then...



STEVE:  Speaking of which, speaking of which I put the following question after this one just for that reason.



LEO:  Ah. Well, that comes from Dave Mulligan in Calgary, Canada.  He shares his own tip for super safety.  On a few occasions you've spoken about using a VMware image of Windows to access questionable websites or do other risky activities.  I would suggest trying a Linux Live CD rather than going through the effort to reinstall the VMware image.  Modern Live CDs like the new Ubuntu install disk work on almost any hardware and have a very recent copy of Firefox to do your surfing.  Yup, it's 3.0b5 on Hardy Heron.  Since the Live CD does not mount your hard disks, it doesn't even - now, I don't know, wait a minute, I don't know if that's true.  Hmm, maybe they don't mount your hard disks.  Your working install is safe, but it also means that any files you want to transfer will have to be put somewhere else on your network or a USB key.  The safest way to surf, not to have any way for malware to persist on your machine or network.  Because a Live CD generally doesn't save state of any kind.



STEVE:  Correct.  Now, he mentions your network.  You would really like it also not to mount your network.



LEO:  Right.  It does.



STEVE:  And that the only way then would be like a USB key.  So you would use the Live CD to start clean every single time.  It definitely does not want to mount your hard drives.  Because again, the idea is containment.  So, I mean, I really like the idea of a workable OS that you boot from a CD, and it's got a browser.  Of course, it has to be on the network or it's...



LEO:  Right, right.  So it's going to mount your network.  It's my sense that some Live CDs allow you to write to drives.  You're allowed to save data.  So you could really look on the Live distro to make sure that that one in particular does not save data to a hard drive.



STEVE:  Right, right.  But I like this because, again, it's another - on the other hand, no one wants to reboot their system.  That's a big pain, too.  So maybe an old - here Linux makes even more sense than Windows because it's so much leaner in terms of processor need and RAM footprint that you could just use Live CD on a real old PC and just use it to do your banking and stuff.  And again, that's got the advantage over what Neil is doing with his old G3 Mac in that every time you boot it, it starts from a clean slate from a CD.



LEO:  Right.  And then we've talked about those Windows - what was the name of that Windows thing where it starts over each time?



STEVE:  Ready, no, not Ready.



LEO:  Anyway, we did a whole thing on it.  You'd think we'd remember.



STEVE:  SteadyState.  SteadyState.



LEO:  SteadyState.



STEVE:  Windows SteadyState.



LEO:  That would do the same thing; right?  Kind of?



STEVE:  Yeah, kind of.  I mean, in theory it looks like it does a good job.  And, I mean, it's built for public environments and public access terminals where no matter what anyone does, when you restart the system, it flushes everything away that they did.  But again, you've got bad stuff in there, hopefully the isolation holds and it's not able to do something.  But if it had access to a USB key it might be able to jump out through there.  I mean, again, it's still up to the user to make sure that they've got the various holes closed.  And the idea of using a separate old machine with a Linux Live CD, for somebody who's really concerned, it's a great solution.



LEO:  Steve Barta in Rowlett, Texas, likes tiny URLs, too:  I'm a big fan of TinyURL.com and recently discovered SnipURL.com from Steve on a previous podcast.  Steve and I both use that one because you can make your own tiny URLs, which I like.



STEVE:  Yeah.



LEO:  I work for a large defense contractor, so security is a serious concern for us.  The problem I have is URLs on our Intranet, our internal Internet, are often huge, with long text strings in them.  I've noticed that these monster URLs don't always travel well, and sometimes word wrap, breaking apart in emails.  I've found that TinyURL works fantastically for shortening these behind-the-firewall links.  For instance, I can copy/paste a long URL into TinyURL, and the result, though the link resides outside my firewall, will still take me to the intended destination, but with a much tidier hyperlink.  The question is, is there a security risk here?  If I'm inside the firewall, and I click on a TinyURL public link that directs me to an internal website, is there a problem with this ping-pong behavior from a security standpoint?  Always a big fan of Security Now! and an avid supporter/owner of SpinRite.



STEVE:  Well, this is an interesting question.  I'm assuming that the URLs are not useful on the outside of the corporate...



LEO:  That's key; right?  Because if you could enter that URL outside the Internet, then it's insecure anyway.



STEVE:  Correct.



LEO:  You're relying on security through obscurity.



STEVE:  The technology that all of these TinyURL and SnipURL and so forth use is an HTTP redirect.  There's the ability for a web server to return, like, essentially an updated page to the web browser.  I think it's code 302 permanently moved or moved permanently is the code.  So what happens, the way this works is you click on snipurl.com/ - well, the example I gave last week, I created one that was rsa2008.  So your web browser goes out of the corporate Intranet, across the corporate firewall, out to the SnipURL server, and attempts to bring up that page, literally snipurl.com/rsa2008 page.  What is behind that is a database of correspondences of short URLs to long URLs.  So the page that is retrieved by the browser is one of these 302 pages that says that page you asked for has been moved permanently to this URL.  And that's the big nasty long one.  So the browser gets that, and then it immediately, instead of showing you that other page, it brings up the page where the short URL has been in theory moved to, which will be this internal URL that then allows somebody inside the corporate network to bring up the page.



So when he talks about it breaking in email, I'm thinking, okay, well, he must mean internal email.  So he's sending internal email to a colleague saying check out this new update to our internal Intranet page or whatever.  And so the only exposure that I could see is from an information leakage standpoint.  That is, many times URLs have interesting stuff in them.  I mean, what could you learn that might be a compromise?  He says he works for a large defense contractor.  So the question is, is it just gobbledygook, GUIDs and random nonsense in the URL?  Or could these URLs contain human readable content?  Because they are passing in the clear outside of the corporate network.  Other than that, I think it's pretty secure.



LEO:  Yeah.  So I think he's more worried about this translation issue and does it somehow open it up.  But the real key is that your Intranet should not be accessible from outside your network.



STEVE:  Correct.



LEO:  Richard de Tarnowsky, Senior Systems Administrator of LiveWorld, Inc., takes issue with the idea of running everything over SSL.  We were talking about that a couple of episodes ago.  He says:  There were several points brought up in this episode regarding running SSL security on a website that I have to disagree with.  Well, this guy's a senior systems administrator, so I'm going to listen to him.  It might be reasonable to run entirely encrypted on a low-traffic site, hosted on a single machine.  That configuration is not appropriate for a large commercial site.  Remember that SSL certificates - yes, I'm aware of wildcard certs - are only valid for a particular host name.  When building a high-availability, high-traffic site, there may be many servers hosting various bits and pieces of content.  Often a front-end device like a load balancer may handle all the SSL traffic, only one cert per URL required.  This simplifies certificate management and avoids per-server charges.  If the site has lots of graphics or video, there might be a significant performance hit for applying encryption.  Don't forget, if you embed nonencrypted content into an encrypted page, your visitors get that lame popup from their browser unless they've been convinced to turn them off.  I could go on and on for several pages, but I'll just stop here.  SSL is expensive in hardware costs, certificate direct and management costs, design time, and - and I think this is probably the key - operations overhead.



STEVE:  Well, I wanted absolutely to share Richard's feedback.  I'm sure there's some validity to it.  I wanted to take issue only with this idea of its being a performance overhead because certainly certificate management is an issue.  I mean, I've got my own little site, and I have a number of certs because I need - I mean, and I have, like, GRC.com, it has its own certificate; www.grc.com has to have its own certificate.  So I'm paying to allow people to connect securely either with the www or without.  That's two certificates.  And then I have another server, GRCtech.com, and it has to have a certificate.  So, I mean, I'm very sympathetic to the idea that dealing with all of these certs is a problem.



On the other hand, he talks about mixing content.  And it is the case that the only overhead is the initiation of a connection.  He was saying that, for example, running large content like videos and large images and things would create some encryption overhead.  But that's not the case.  It is the establishment of the connection that involves the public key exchange.  Once they've agreed, using random number generation, they then have a symmetric key which is extremely fast, I mean, faster than reading the content from the hard drive or, I mean, like just not a problem in terms of overhead.  And modern browsers leave connections up over time.  So a browser will establish typically up to two connections to a remote web server.  It would bring up SSL connections on them both.  And then all of the interaction with the web server for a great deal of time would be over those connections, with multiple assets of the pages going back and forth through those established connections.  So, I mean, I absolutely empathize with this notion that having everything be SSL would be expensive in terms of management and costs and sort of operational overhead, but not actually performance hit for encryption.  That's just not there.



LEO:  Okay.  Good to know.  Actually I was curious about that.  The encryption process itself is pretty fast.



STEVE:  Right.



LEO:  Now let's move on, ladies and gentlemen, to the Terrific Observation of the Week.  Tyler Larson does it from Arizona:  I'm not sure who caught onto this, but the keynote given on Hierarchical Temporal Memory that Steve pointed out from RSA 2008 makes one thing very clear:  This is the beginning of the rapidly approaching end of CAPTCHA.  The type of problems that this new type of AI, this Numenta AI, is already able to solve are exactly the same set of problems posed by websites in trying to determine whether or not you're human.  For example, read the text in the noisy background, identify words in this noisy audio, or even identify which of the following pictures are kittens.  That's what they did, didn't they.



STEVE:  Yeah, it's so good.  I mean, it's remarkably good.



LEO:  As this new AI technology gains footing, we're going to have to rethink our approach to guest authorization.  Gone will be the days where we could simply sort based on human versus machine.  We'll instead have to grant authorization based on whether the human or machine is acting on behalf of an otherwise allowed party.  That's a good point.  My agents might be logging in and creating that email account automatically for me, and that's intended.  Obviously the implications to the security world are significant.  This is an extremely difficult problem to solve.  But if we don't get a head start on it, we're going to find ourselves woefully behind when the bad guys start catching on.  I think security certifications everywhere.  You'll need a personal cert to do anything on the 'Net.



STEVE:  Well, and our listeners will remember from the coverage that we gave to CAPTCHA how surprisingly difficult it is at the other end of a Internet connection to tell whether somebody is a human or a machine.



LEO:  The Turing test.



STEVE:  The Turing, exactly, the classic Turing test.  And so I think what I liked about Tyler's observation is, I mean, if anyone's interested and did not have a chance to yet go look at Jeff's tremendous presentation of his Hierarchical Temporal Memory at the RSA conference, it was in the keynote, again it's that SnipURL, snipurl.com/rsa2008.  That'll take you to the page of all of the keynotes.  And Jeff just does, I mean, he shows pictures that this technology of theirs is able to correctly identify.  I mean, it's just - it's jaw-droppingly impressive.  And so it truly does make the problem of performing this kind of differentiation much more difficult.



LEO:  Interesting, yeah.  Well, it's a brave new world.  I mean, if Jeff Hawkins can create these chips that work like the human brain, all bets are off in every respect.  I mean, we've got a whole new, I mean, CAPTCHA, losing CAPTCHA is the least of it.



STEVE:  That's true.



LEO:  I mean, everything changes all of a sudden.  And he talks in his book "On Intelligence," he talks about the implications, the last chapter talks about the implications of a chip that thinks like humans.  And, I mean, he says they're not going to - it's not like we're going to suddenly be faced with robots that want to take over the world, he said; but things like air traffic control, you know, weather forecasting, a lot of stuff can be done by machines that humans do right now.



STEVE:  Yeah, good stuff.



LEO:  Good stuff.  Not bad stuff.  Well, maybe some bad stuff.  Mr. No Name in Detroit shares some additional sobering truth:  I have a small computer repair company while I finish up my computer science degree.  And like the listener that wrote in during Episode 140, I, too, maintain small mechanics shops' computer systems.  One day when I was updating the office computers the service guys called me out into the garage to look at a computer.  And lo and behold, they were ripping shop clients' CDs to the computer and wanted to know how to get the data onto an external hard drive so they could take it home.  They were also getting data from thumb drives left on key rings and MP3 players.  I worry less about the music data and more about the personal photos that anyone may have left on a thumb drive they don't want to get out.  We talked in Episode 140 about a mechanic.  Actually a guy sent in a note saying a mechanic that stole everything.  If you leave data in your car, it's gone.



STEVE:  Yeah, I thought it was just worth refreshing one more time.  I mean, this was not necessarily anecdotal.  Apparently this is just what goes on.  And, I mean, no offense to mechanics all over the planet.  But it's clearly something that is happening, and our listeners ought to just be aware of it.



LEO:  Get yourself a valet key and lock everything in the trunk, kids.  Or take it with you.  And we're going to do a bonus one.  This is the Quip of the Week from listener Roger.  You ready for the Quip of the Week?  Funny how VeriSign's EV certification has VeriSign authenticating itself.  Surely you'd think they'd get someone else to vouch for them, even if they are - supposedly - VeriSign.  Hmm.



STEVE:  I got a kick out of that.  You know, we've talked about the chain of certification or authentication where you have an SSL certificate that is signed by somebody you trust to have done their homework, to have done due diligence to verify the identity.  And so what does it mean when VeriSign signs VeriSign's own certificate?  I guess they're very sure about who they are.



LEO:  Yeah.  But are you sure about who they are, and should you trust them?  I don't know.  I don't think so.  That's why we have key-signing parties.  It's that chain of trust.  We go out and, here, I am who I say I am.  You see my driver's license, everything, could you sign my key, my PGP key?



STEVE:  Yup.



LEO:  We've reached the end of this fabulous episode.  But it's just the beginning of your quest for security.  If you want more, you can get more.  Use that Download All Scripts for your Firefox, or CURL and SED.  But somehow you can download all the shows ever recorded.  Steve's got a list of them all at GRC.com.  And along with that you'll find the show notes.  You'll find transcriptions of every show in PDF form.  I mean, it's just a great treasure trove of security information, all 142 episodes.  GRC.com.  While you're there, make sure you take a look at SpinRite, Steve's baby, his pride and joy, that program that saves hard drives right and left.  It's the ultimate disk recovery and maintenance utility.  I use it; so should you.  SpinRite, it's at GRC.com.



Steve, we'll see you on the radio show.  Steve joins us every Saturday on the Tech Guy show to talk about security.  And of course next Thursday for Security Now!.  Have a great week, Steve.



STEVE:  You, too, Leo.  Thanks very much.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#143

DATE:		May 8, 2008

TITLE:		YubiKey

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		Stina Ehrensvrd, CEO of Yubico

SOURCE FILE:	http://media.GRC.com/sn/SN-143.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo delve into the detailed operation of the YubiKey, the coolest new secure authentication device Steve discovered at the recent RSA Security Conference.  Their special guest during the episode is Stina Ehrensvrd, CEO and Founder of Yubico, who describes the history and genesis of the YubiKey, and Yubico's plans for this cool new technology.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 143 for May 8, 2008:  YubiKey.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now!, Episode 142 [sic], Leo Laporte here, Steve Gibson in Irvine, joining us in our new highly technical studio that isn't really working.



STEVE GIBSON:  With the details still coming together.



LEO:  A lot of the details still coming together.  Hi, Steve.



STEVE:  Hey, Leo, great to be back with you for our 142nd [sic] week of Security Now!.  Wow.



LEO:  Practically consecutive.  Have we missed any weeks?  No.



STEVE:  No, we have never missed a week.



LEO:  Wow.



STEVE:  Yeah, you and I used to have to bunch them up when you were running around traveling or when we were together...



LEO:  Isn't it nice?  I don't have to go to Canada anymore, yeah.  I mean, that's really simplified things considerably.  Very pleased about that.  So we have a guest today.



STEVE:  We're going to have a guest joining us by phone from Sweden.  And that'll be someone I referred to two weeks ago, and maybe even last week, and that is Stina, who is the CEO and one of the founders of Yubico, the makers of the YubiKey, which I just happened to stumble on when I was up at the RSA security conference.



LEO:  Boy, that was a lucky thing for both of us.



STEVE:  Really was.  Well, and for our listeners, too.  They have received hundreds of emails and inquiries from my mention of the YubiKey when I did the episode two weeks ago on the RSA security conference.  And I've been in pretty much constant dialogue with Stina and the technical people that they've got.  And the news is virtually 100 percent good.  I mean, the more I learn about this, they've been evolving their policies - anyway, so this week's episode is the Yubico YubiKey.  As we'll see when we get into it, this is an even better authentication solution than I expected it was going to be when I described it last week, or two weeks ago, as the coolest new thing I had seen at the RSA conference.



So this week's episode is Yubico's YubiKey, and I really think - I'm going to go into all the technical details after we have had a chance to speak with Stina.  I asked her to come on because she really has a vision for what she would like to see happen with authentication.  I wanted to understand, you know, where this wacky name came from, a little bit about the company, and just sort of get a sense for where they are because I know that when we've talked about and explained issues of authentication there's been a strong interest.



Obviously I'm a person, I mean, I'm on record here on Security Now! believing that authentication, you know, getting this problem solved is an enabling factor for the whole future of the Internet as we go from Web 2.0 to 3.0.  More applications are moving onto the web.  We hear about now there's, like, all this computing in the cloud where corporations are going to be moving more of their infrastructure onto the Internet as we have people who are able to carry that.  So in every situation where we've got a network and you don't have your typical - I think we once described it as like the Andy of Mayberry authentication, where you know Aunt Bee, and you know Opie.



LEO:  So you give Opie the drugs when he comes to the drugstore for Aunt Bee.



STEVE:  Exactly.  And so here on the 'Net we need a good way of knowing that the person at the other end is who they say.  And we've talked about VeriSign solutions and the eBay and PayPal football and the credit card.  We're going to talk about something now which is completely open source, no subscription fee, lifetime free authentication.  And, I mean, it's - I'm excited because this is, as long as you've got a USB port, this is the answer.  It doesn't have a display, as we talked about it before two weeks ago.  It pretends to be a keyboard.  But you just touch the button and it shoots out into your computer, into for example a web form, this long string of random-looking encrypted stuff that then can be authenticated, either by you or by Yubico or whomever.  And the advantage is that there's no cost to anyone for all of this.



LEO:  Wait a minute.  Obviously there's some cost or Yubico wouldn't have a business model.



STEVE:  No, they want to sell the hardware.  That's all they want to do.  Anyway, we'll go over this.



LEO:  You're giving it all away.  We won't have anything left when Stina calls.  So hang in there.  Now, do you have any news, anything you want to do before we talk with Stina?



STEVE:  Oh, yeah.  We definitely have some news of the week.  One little disturbing bit of news was posted on Dave Jevans' blog.  Remember, he's one of the main founders and president of IronKey.  He posted the news, I guess it was on Friday, that Anonymizer.com was acquired by Abraxas.  And the bad news is that Abraxas provides anonymity services for the national security community - NSA, CIA, DIA, and so forth.



LEO:  Oh, boy.



STEVE:  And so, you know, I'd feel much more comfortable if Anonymizer.com had stayed independent and just themselves rather than now being part of a government contractor.



LEO:  Wow.  Yeah, you've got to really kind of wonder.  Did you ever - have you ever heard the rumors that Facebook was partly sponsored by the CIA?



STEVE:  I've heard something about that.



LEO:  It's a persistent rumor which has been consistently denied, as far as I know.  But it's kind of credible.  You would think, if you were the NSA, if you were the CIA, that kind of a great way to watch people would be to be part of these social networks.  What better thing to do than buy Anonymizer?



STEVE:  Yeah, yeah.



LEO:  But as a user you kind of have to say, well, hmm.



STEVE:  So, yeah.  I mean, I don't know...



LEO:  TOR is looking better and better, that's what I...



STEVE:  I don't know that anything untoward is going on, of course.  But I just wanted our listeners to know, if any of them are Anonymizer customers, that Anonymizer is no longer independent.  It has been acquired, and acquired by a company that does a lot of business with the three-letter-initial intelligence services of the United States.



LEO:  When you said "untoward," did you mean that as a pun?



STEVE:  Uh, okay.



LEO:  Yeah, it's a pun.  UnTORed.



STEVE:  UnTORed, oh.



LEO:  Get it?



STEVE:  You're at the top of your game this morning.



LEO:  It's that quinti venti latte, man.  You're right, those things work.  So let's - okay, so that's one big story.  What else is out there?



STEVE:  Also there was a - this is just sort of just to keep our eye on.  A disturbing constant theme of the FBI has been their request for ISPs to retain data.  There was a recent congressional hearing where FBI director Robert Mueller again called for federal data retention laws to force ISPs to keep records of what their customers do for two years.



LEO:  He's been trying to do this for a long time.



STEVE:  I know.  And what's really confusing is he's not saying what he wants kept.  Now, the weakest information that would be kept would probably be at least the IP addresses that customers have had over that period of time, which frankly would not be that burdensome, I mean, for the ISPs to retain.  But there's talk about it being all the way up to and including a website trail, that is, what websites people are going to.



LEO:  You mean the kind of stuff that Google keeps track of with its web history.



STEVE:  Well, exactly.  And he immediately...



LEO:  Oh, actually more than that because Google's only tracking your searches.  Your ISP knows everywhere you go because of the DNS requests.



STEVE:  Oh, yes.  Well, it's watching your click stream, as it's now becoming called.  And of course he immediately marches out the child porn peddlers and online predators, saying oh, we could do a much better job of catching them.  Well, of course everyone is sympathetic to that.  But it's creepy to think that this whole, I mean, that our ISP that's connecting us to the 'Net has the power that they do to see everything that we're doing and that they would be required by the government to maintain two years of logs of everything every individual does on the Internet.



LEO:  That's the old argument...



STEVE:  I mean, that's really - I'm sorry.



LEO:  That's the old argument, if you're not doing anything wrong, what do you have to fear?



STEVE:  Yeah, and unfortunately our government doesn't have the best track record of dealing with this kind of information aggregation.



LEO:  Well, no government does.  And anybody should be suspicious of any government.  Yeah, I trust our government, but any government that wants to collect this information, that's a bad thing.



STEVE:  Yeah.  And finally, four researchers at Carnegie-Mellon University, UC Berkeley, and University of Pittsburgh, they've come up with an automated, they call it APEG, Automated Patch-Based Exploit Generator.  Essentially this thing is able to take a look at Windows Updates, analyze the pre and post patch, and design an exploit for the vulnerability that the patch fixes.  And so we've talked about how hackers are looking at Windows Update updates and then manually reverse engineering what it was that was changed.  Well, these guys, these computer science researchers have essentially automated that process.  And so they are now urging Microsoft - I mean, no.  Their point is, if they can do it, so can the bad guys.  And we know there's big money behind developing, quickly developing exploits for vulnerabilities.  And there's a window of opportunity between the time the vulnerability is known about, the exploit is generated, and everyone gets themselves patched.



So they're urging Microsoft to somehow really work to minimize this vulnerability window.  For example, maybe getting the updates all distributed, but having them encrypted so that then a key is provided to just, like, simultaneously decrypt them all in place.  Maybe use peer-to-peer networks somehow to push these fixes out much faster.  Because right now, I mean, they trickle out of Microsoft.  When you consider the number of systems that need to be updated every second Tuesday of the month, I mean, it's often the case that my computer doesn't alert me that it's got some updates for several days after those patches began to get pushed out.  So essentially what's happened is there's been a reaction to this constant patching that we're now seeing from Microsoft.  And these researchers are saying, hey, if we can automate it, so can the bad guys.  And you've got to believe that there's a huge incentive for them to do so.



LEO:  You bet.  You bet.  Automated Zero Day.  I like that.  I mean, I don't like that.  But it's, I mean, you have to admire their technical prowess, if nothing else.  And you know, it's really all taken off since there's been a financial incentive for them to do it.  I mean, that's the key thing.  As long as they can make money at it, well, we'll throw resources at it.



STEVE:  That's the change in the last five years.  This went from being script kiddies screwing around say, hey, look, Ma, what I can do, to now to organized crime saying, okay, we're going to pay you hackers to do that.  And it's big money.



LEO:  Amazing.  Amazing.  Any other news?



STEVE:  Well, I did have one, since we're waiting for Stina to call...



LEO:  Well, she's actually here.  She's already here.



STEVE:  Oh, there she is.



LEO:  But let's just finish up, and then we'll get to Stina because I don't...



STEVE:  Well, I had an interesting piece of email that caught my eye, as I always do.  This one the subject was "SpinRite helps kids with cancer."  And I thought, okay, how is data recovery going to do that?  So this is a letter from Pete Harmon that I got a couple weeks ago.  It said, "Dear Steve, I wanted to drop you a line and let you know how much good you're doing in so many ways that you probably never considered possible the day you sat down to develop SpinRite."  He said, "I'm a FedEx pilot" - so a Federal Express pilot - "and I have gotten a reputation as a computer hobbyist/geek around flight operations."



LEO:  Well, if he's listening to Security Now!, that's true.



STEVE:  Yeah.  He says, "On more than one occasion I've provided tech support to friends and fellow pilots."  He says, "I run a website for our pilots called PilotSwap.net."  And he said, "Several weeks back I got a phone call from Bill, who told me his computer was dead, and he heard I may be able to help.  He described the problem, that his laptop was working fine one day in Honolulu and wouldn't boot at all when he landed in Sydney the next day."  Obviously carrying FedEx packages across the globe.  And he said, "I asked him if he could hear the hard drive spinning, and he said he thought he could, but stated it was just clicking and clicking, but nothing was happening.



"Not sure I could help, I agreed to take a look at my next opportunity.  He left his laptop in my locker, and I brought my SpinRite CD with me the following week.  I put it in the laptop, and after two or three dozen attempts to get the laptop to boot from the CD, I was stumped.  His computer was simply not going to boot from either CD or the hard drive.  So just for grins, I removed the top two screws holding the hard drive panel on and took his hard drive out, brought it home with me.  I hooked it up to my PC at home using an EIDE-to-USB cable I have, and the drive spun right up.  But it was mostly unreadable and made lots of noise when I tried to access what few files I could even see in Windows Explorer.  I rebooted my machine with my SpinRite CD and was able to quickly see Bill's drive.  I set SpinRite to work, and about four hours later the data rescue routines were complete.



"I took Bill's drive to work with me the following week and put it back in his laptop.  It booted right up, and Bill was able to recover hundreds of family photos he'd been storing on his laptop for years.  Elated and grateful, Bill offered to pay me for my services.  Instead, I asked that he make a donation for his gratitude.  Here's what I got from him this week.  He said, quote, 'Pete.  Hopefully by now you received my two voicemails letting you know I dropped off your hardware back on your box.  I was able to capture all of my family pics.  Many thanks.  I made a donation to St. Jude's Children's Hospital in your name for $200.  Again, many thanks.  Cheers and regards, Bill.'"  So then Pete ends saying, "I'm glad I could make a difference, but you and your wonderful product SpinRite made it possible."



LEO:  Aw.  Isn't that neat.



STEVE:  So I thought that was really neat.



LEO:  Nice story.  Nice story.  Now would you like to introduce our guest?  Because Stina's on the line with us right now.



STEVE:  Hey, Stina.  Welcome, and it's nice to talk to you again.  I guess it was, what, about four weeks ago that we bumped into each other at the top of the elevators in San Francisco.



STINA EHRENSVRD:  Yeah, that was my lucky day.  It's been - and thanks for inviting me.  And you've been a relief for me.  I mean, it's been literally around hundreds of emails that come from all over the world who's now, you know, ordering our stuff and asking all these kind of questions.  And things are taking off.



STEVE:  Well, that's fantastic.  I'm going to talk about the technology and the detailed operations of the YubiKey after we're through talking to you.  But I loved your story sort of about where the name came from, where the company came from, and also sort of your vision for authentication.  So I wanted you to - I thought our listeners would get a kick out of hearing it directly from you.



LEO:  Are you a security researcher, Stina?  What's your background?



STINA:  No, I'm a product designer.  I went to art school.  And I married an electronic computer engineer.  We've been working as a team for 15 years, and he's learned, you know, he learned with the basics, but they really [indiscernible].  He is, you know, he's the one who helped me.  You know, he's made the mod hex that you read about just a few minutes ago, Steve, you know, he's the one who - yeah.  So and then Simon, who is the - another Internet security expert in the team.  He's been, you know, putting some efforts into this, too.



LEO:  So you're a product designer.  And are you a security buff?  Or was it all your husband's idea?  Or how did this come about?



STINA:  We worked very closely.  I asked all these stupid questions and, you know.  I can tell you, actually, you know, we started together working as a - we actually co-founded a company called Cypak a few years ago, Jacob and I.  And this was in the RFID space.  And one of the many applications for the technology was the [indiscernible] smart card with a PIN keypad on the card itself.  And we called this card the PIN-on-Card.  And we were very proud of it because it was so secure.  I mean, I think it could have been one of the most secure solutions ever invented.  We got the European Innovation Award, 200,000 euros for this.  And we were just, you know, the world wants, needs this.  And we were just so excited.  Until we started talking with customers.



You know, we hadn't even thought about that this card - and it was very secure.  But it required a specific [indiscernible] chip built into a specific card with an integrated keypad.  And it had to be connected in our [indiscernible] reader.  And it needed client software.  So when we actually - we were approached by an online bank.  And we were planning a pilot with them.  But by the end of the day they, you know, one of their bank guys called me up and said we really like the automatic thing.  But we don't like the card reader, and we don't like the client software.  Our customers, they are, you know, they are from all platforms, all browsers.  The Windows versions, the Mac, Firefox.  And this client software thing would probably require us to hire 30 new full-time employees only to take care of all the online support.



So this bank guy, he said to us, you know, you're good inventors.  But, you know, you can come back when you've removed the client software and the reader.  So that was a good challenge.  We, you know, we said okay, thanks, we'll make a try.  And we started to examine it, you know, looked at the computer, Jacob and I, and I asked a stupid question, you know?  I said, there's a keyboard to this computer.  You know, and that doesn't require a driver.  And he said, hmm, yeah, you're right.  So, you know, why couldn't we make a code generator that's simulating the HID driver, you know, acting the same way, with - and we, you know.  And, yes, that's where the idea started.



And so we went back to the bank.  We got - first we got rid of the client software, and then we made it into a USB fob to get rid of the reader.  And we reduced the 12 buttons to one little button.  And this was the first version of YubiKey.  It was a fat, you know, looked almost like any other USB memory.  And that guy who looked at it, he said, hmm, this is an interesting concept.  But there's one problem.  We prefer to buy security solutions from the big guys.  So anyway, I thought it was a good comment.



So this was in May 2007.  And with this first prototype version of the YubiKey I decided to start Yubico.  I did not have a clear business plan.  But I thought it was the only problem was that I was not a big guy.  It was [indiscernible].  And the name Yubico came from the word "ubiquitous."  I did not want a name that had anything to do with secure, verified, ID, trust, you know, all these boring other names that are out there.



LEO:  Like everyone else at RSA.



STINA:  Yes, just without imagination.  So I thought I wanted a friendly name.  And I like the word "ubiquitous."  I envision this to be everywhere, mass market.  So I started playing with the word "ubiquitous," and I ended up with Yubico.  That's it.



LEO:  I like it.



STINA:  So we, you know, so the first step, I had the prototype version.  And now I realized I needed someone to say that this was a good product.  So I asked people, you know, who can write a security report for me?  And I came in contact with Simon.  And he wrote an independent third-party security report.  You know, the one I sent you, Steve?



STEVE:  Yes, yes, right.



STINA:  And the good thing with this was when Simon had written his paper, he was so enthusiastic.  So he said - he asked me if he could invest in the company and work for me.  Well, but the problem was that I no longer had an independent security review, but I had the perfect inventor.  So, yeah, you know.



LEO:  It's a good sign when the guy reviewing your security says can I work for you.



STINA:  Yeah, and it's on the website tomorrow, so anyone can look at this.  It's, you know, it's not third-party, but he was third-party when he wrote it, you know.  And Simon, he's a great guy.  He is very passionate about open source security.  And he recommended me at that time to fly over from Stockholm to an Internet identity workshop in California, and where I could learn more about this OpenID initiative that we think is a great initiative.  And, you know, I would learn how we could fit in YubiKey in OpenID so we could enable one YubiKey to go to all Internets.



So I went to California to this workshop.  And I met a guy from VeriSign.  And he introduced me to another guy at VeriSign.  And this guy, he said that the YubiKey could be quite interesting for them, "if."  You know, this is the story.  It's always been "if."  If we could make this device to fit in a wallet and make it very, very cheap and in big volumes.  So I thanked him for his feedback.  I fly back to Sweden and started, you know, looking for designs.  I'm a product designer, so I went on the Internet and said what are - what kind of USB devices are there that are really thin?  And the other day a friend of mine gave me a very minimalistic USB key.  It was just designed in two parts, a little circuit board and a plastic casing, that's it.  So when I saw it I thought, you can't make it smaller, can't make it thinner, can't make it less expensive.  And that's, you know, that was the inspiration to the current YubiKey design.



And meanwhile I had met this guy at VeriSign, he had introduced me to another guy at eBay.  And I sent him, actually sent him the first version because we had - the thing wasn't ready yet.  But I sent him the first version of the fat YubiKey.  And I asked him to look at it because I thought eBay might be a big customer for me.  And he said, you know, he wasn't very interested.  He even didn't want to look at it.  It took him four weeks before he even answered my emails.  But then one Sunday in October he came back.  And he - yeah.  Actually this is what he wrote.  So I'm reading from his email:  "Dear Stina.  I have now tested your product.  I'm impressed by its simplicity.  I think the YubiKey is the only hardware authentication token that would fulfill the requirements for Web 2.0 services.  Looking forward to a further dialogue."  You know, that was a good email.  So it just took four weeks.  And after that he left eBay, and he started working for Yubico in California.



LEO:  You're stealing people left and right.



STINA:  So now I had an office in California.  So I had an office in California, one in Stockholm.  So it was Simon, me, and Paul.  And, well, in January the little thin YubiKey was ready.  And we started shipping the first pilot box.  It was to one of Paul's friends who has set up a Chinese IPTV company called Dragon IPTV.  We have a, you know, a theme on our website and a film actually show that service.  And, you know, we're very enthusiastic because, you know, within a couple of months we had five pilots starting.  And we didn't really understand, you know, the customers, they were so happy, they came back, and they said this works so perfect, and the users love it.  But the business really didn't - we didn't get any next orders.  And eventually we asked them, and they said, you know, there is one problem.  There's always one problem.  And now they said, you haven't given us a price list, and we don't really understand your business model.  Is this open source, or is it not open source?  You know, you haven't been perfectly clear on that.



So when we started Yubico, Simon and I, we had envisioned Yubico as an open source company, a web shop where it's free SDKs with a developers community around it and with almost no salespeople, you know, people just sort of sending out things from the web shop, and no flashy offices, eliminating all the expensive layers of distributors and resellers who are now driving up the prices in these, you know, existing Internet security infrastructure.  And Simon and I, we were very excited about this idea.  We tested it on some Internet security professionals and other safe people we know in this industry.  And they all warned us.  Actually they warned us. They said you're, you know, it's too risky.  We would not recommend you to do that.



So we were sort of standing on one leg.  You know, we didn't make [indiscernible].  The customers want to buy from us.  We couldn't give them a price list.  Because we didn't know, you know, we didn't know who we were.  We just knew we had a great product.  And then I bumped into you, Steve, so you made us, you forced us to make that decision, you know, emails coming, you know, literally they came in, you know, in my email box, hundreds of them.  And I had to call Simon, you know, they're asking for prices.  You know, we have to give them some prices.  And they're asking for the SDKs.  You know, [indiscernible] software [indiscernible]?  And then I had another investor who actually joined a little later, a former CEO of Microsoft.  So I called - he's the other, you know, we are the only ones taking the big decisions of this company so far.  So it was very easy to make an on-the-phone-call decision, okay, now we go, just shift.  We know we are taking risks.  We know there are big challenges.  But this is the way we want to do it, and this is the way that feels right for us.



LEO:  I have to apologize because we probably should have explained what the YubiKey is because I think there are some people who are probably listening, going, all right.



[Talking simultaneously]



LEO:  ...synopsize, Steve, give us a...



STEVE:  Yeah, I'll be covering that after we're through talking to Stina, in detail.  But essentially it is what we talked about two weeks ago.  It is an amazingly small little, essentially, piece of plastic that is an emulator of a USB keyboard.  So it's - we have pictures of it in our show notes from two weeks ago and also this week's show notes, so people can see what it looks like.  Or they can just go to Yubico.com and see pictures of it there.  It contains cryptographic technology which essentially produces a one-time password which is typed into your computer by this little piece of plastic, by the YubiKey.



LEO:  It shows up as a standard USB keyboard, as an HID device.



STEVE:  Exactly.



LEO:  So it can do that.  I mean, there's no magic, and it works with everything that supports HID, which is pretty much everything.



STEVE:  Well, exactly.  So it's OS independent.  And what Stina was saying before, the problem that people had with the RFID approach was that it needed - there had to be a companion reader, and you had to have client-side software in order to interface it.  And what's so cool about this is, I mean, it's funny because when I bumped into Stina at the RSA conference, she was standing there and saw my press credentials and thought, well, maybe I could - I'm sure she was doing this with other press people, too.  Maybe this person, who I don't...



STINA:  I think I talked to about five people.  You were the fifth one.



STEVE:  Oh, good.  Well, I'm sure she was thinking maybe this person will help me get the word out.  And being an engineer, when she said this is a one-time password device which is a USB keyboard, my mouth just dropped open because it's brilliant.  And that's what I loved about the concept is that it just does what it does beautifully.  And we'll go into the technology because the design that underlies this is spectacular.



But what I'm so pleased with, and the reason I wanted to give this a whole Security Now! episode is that what Stina and her colleagues have decided to do is to make the backend authentication services free.  No subscription, no license, nothing.  They want to just sell the YubiKeys.  And unlike a huge company like VeriSign that has a massive infrastructure that they need to support, and literally all the other companies that I saw on the RSA showroom floor, they were all into locking you in, signing you up, and they were big businesses that were looking for big corporate and offering big corporate solutions.  Well, here is something, this YubiKey technology, that is - and I'm looking at the prices that Stina and her group have come up with.  Quantity 1, price is $35.  Quantity 10 is $25.  Quantity 100 is $20.  A thousand of them are $16 each.  10,000, $12 each.  100,000, $8 each.  So this price drops rapidly.



And their model is to sell the YubiKeys and provide everything else open source.  So, for example, they've already posted their source code up on Google's code pages that shows how to decrypt the output from the YubiKey.  And they're in the process of putting the technology together and the documentation for how to program the YubiKey.  And, I mean, again, it's even better than I thought it was two weeks ago due to the approaches that they're taking and how open they're being about what it is that they've created.



LEO:  It's very cool stuff.



STINA:  Well, there are some bits and pieces we are, you know, we now rapidly need to put in place because there are huge orders coming in.  And it's great.



[Talking simultaneously]



STINA:  Our developers community, I vision that to be really something dynamic, growing.  But now it's just an embryo.  So it's, you know, people are asking where can I find that document, and please, please, give us some weeks.  But, you know, we can produce the YubiKeys in large volumes.  We set up that production.  And anyone can buy these from our website and start downloading whatever they can find there.  And eventually there will be more.  And I think instead of just fighting against these big guys that we mentioned, we believe we can do this in a different way.  I mean, we can - I'm very excited of what this developers community will go.  I'm even envisioning that little guys in countries with little IT budgets could develop their own e-democracy and education and payment system based on the YubiKey and open source, and what will happen, you know, that would be really [indiscernible].  You know, there could be systems that sort of are built on this that would require so - will be so less expensive than what our, you know, the current infrastructures are for security and systems and governments and payment data.



LEO:  And we should make this clear, that you run a server, so people can use your server.  But...



STINA:  I mean, we have - it's more for eval.  And it's more...



LEO:  For evaluation.



STINA:  The server is for pilot, for testing, for anyone who wants to use it.  We believe that most want to write it themselves.



LEO:  Yeah, for security you'd run your own server.  So there's a complete SDK, and there's a server, and there's everything you'd need to do that.



STINA:  And it makes a free choice.  And some small companies or individuals, they don't have a server, or they don't want to invest in servers.  So we give them an option.  But our focus is the keys.  And, you know, downloading software.  And we're not focusing on the server.  We just have it as an option, too.



LEO:  Do you see at some point some sort of unified system so that - see, I don't want to carry 20 different keys.  It'd be really nice if something like the YubiKey would become kind of the standard, much like VeriSign's trying to do with their system.



STINA:  Yeah.  And we have a dialogue with them.  We met them at the RSA show.  And, you know, we don't see it's either/or.  And they support OpenID.  We support OpenID.  There are other standards coming.  And they support OSS, and we will eventually support OSS, too.  So...



LEO:  Well, standards, that's all you need.  If everybody supported OpenID, then I would just use my YubiKey.  When a site asked for my password, I'd plug it in.  It would have to interface, though, with the one-time password code; right?  I mean, it would have to somehow have a server to support that.



STINA:  Someone has to be the identity provider.



LEO:  Somebody has to be, right.



STINA:  And there are a lot of people who want to be that.  I mean, Google is already an identity provider.  Yahoo! is one.  AOL is one.



LEO:  So your next big step is to get somebody like that to adopt the YubiKey system.



STINA:  Yeah, that would be helpful.



LEO:  And then I can go to any OpenID site because that's widely spread.  I could choose that provider, whoever uses the YubiKey, as my OpenID provider, use the YubiKey, and I'm done.



STEVE:  Well, and also, Leo, I mean, there's nothing magic about being an OpenID provider.  So, for example, I would imagine before long it would be possible to get some open source server software that is an OpenID authenticator, that knows the YubiKey, and you just run it on your own server.



LEO:  Yeah.



STINA:  Yeah.  I mean, there is no limitation.  You don't have to be a big guy to be an open identity provider.  You could be, you know, could be a one-man guy that does it, you know.



LEO:  And everything you're doing is open source, the server and everything.  So that it's very transparent.  People know what's going on.



STINA:  Yeah, we figured out that that was the way it has to be.



LEO:  Oh, yeah, I think it's...



STEVE:  And it's completely open spec, also.  So for example, I mean, the business model of, you know, that we've talked about before when we were excited about the VeriSign VIP system, the football and the card, they're a big company standing behind it.  But there's nothing that individuals have to use there.  I mean, it's a large corporate solution, you know, an eBay, a PayPal kind of company, not something that universities or, for example, I couldn't use it as the authentication technology for my forthcoming VPN product.  I absolutely can use the YubiKey.  I mean...



LEO:  Yeah, you could write a server, run a server, and use GRC as an OpenID provider.  If people trusted you, they have the YubiKey, that'd be it.



STEVE:  Well, I could except that I'm going to make the VPN server itself, that is, the thing that you're connecting to will be able to authenticate your user YubiKey, I mean, right within itself.



LEO:  Wow, cool.



STEVE:  I mean, really it's a transformational technology because these guys have committed to just opening the spec, opening the software, and selling the hardware at an affordable price.



LEO:  Very interesting.  Stina, we really want to thank you for joining us, and congratulations on your success.  I think that's exciting.



STINA:  Thank you very much.



LEO:  Yeah, you've created a really interesting product.  I haven't seen Steve get this excited in a long time.



STINA:  Okay.  Take care.



STEVE:  Thank you.



LEO:  Thank you.



STINA:  Bye bye.



STEVE:  Be talking to you in email.



LEO:  That's very cool.  So I know you're going to talk in more detail about how the functionality works.  So we have some questions from the chatroom, but I'll hold off on those until you get, you know, kind of lay it out for us.



STEVE:  Perfect.  Perfect.  Okay.  So, okay.  One of the first things that they realized was since this thing was going to be a keyboard, that is, since you plug it into a USB port, the computer recognizes it as a keyboard, then at the proper time, when you want it to emit its cryptographic string, you just touch a little touch surface on it.  It has a really nice sort of green glow.  It is literally, it's the thickness of a PC board, a printed circuit board.  And remember, Leo, many months ago when I was up in Vancouver, and I showed you something that I had just discovered?  You'd already seen it, of course.  But it was an SD card that was also a USB...



LEO:  Yeah, you flip it open.  I think SanDisk makes it, yeah.



STEVE:  Yes, exactly.  It was a SanDisk product.  And I thought, this is so cool.



LEO:  Because it's as big as an SD card, but it has its own built-in USB interface.



STEVE:  Yeah, so it's both.  It sort of has a funky little hinge.  And so you're able to plug it in as an SD card.  But then you're able to kind of almost, like, break it in half.  And part of it hinges away, leaving the four fingers of the USB interface.  Well, that's what Stina talked about seeing and realizing that they could do an authentication device rather than a memory device in the same form factor.  And the brilliance of what they did is they said let's - it's going to be a keyboard.  Well, so...



LEO:  That's what I really think is interesting.



STEVE:  Yes.



LEO:  Because it types, as you say, when you press the button, it types the password.



STEVE:  Well, and what they realized was, okay, the football that we've talked about so much, the VeriSign technology, and even the RSA SecurID technology, those are all six-digit tokens because that's, first of all, they're one-time passwords, so that's enough of a string length to be - what's the chance of guessing it?  Well, we know that's one in a million.



LEO:  Right, right.



STEVE:  So actually we know it's a little bit less than that...



LEO:  And since you only use it once, I mean, it's not like somebody could bang on it for a long time.



STEVE:  Exactly.  But one of the things these guys realized was, wait a minute, since users don't have to type this string, we're not limited to, for example, something easy to type.  So we can convey much more information in our one-time password string than you could ever ask a user to type.  So, for example, when you touch the contact, it emits 44 characters.  It's 44 characters of gobbledygook.  It goes zoop, it just kind of comes out.



LEO:  Now, of course there's some user intervention involved.  You have to click the field that it needs to be in.  It's not going to figure that out automatically.



STEVE:  Yes, that's correct, because all it's doing is just shooting out this...



LEO:  It's just typing.



STEVE:  Yes, exactly.  Now, the front 12 characters, the first 12 never change.  They are essentially the public ID for your YubiKey.  And every single one of them is different.  So...



LEO:  Ah.  It has to send that, though; right?  Otherwise it wouldn't be able to figure out if the remaining part of the code was correct.



STEVE:  Precisely.  So that 12, the first 12 characters do not encode the key at all.  It's just a serial number, essentially.  It's the public identity for the key.  Then, okay, because USB keyboards don't send ASCII, they send scan codes, that is, the actual - the USB spec, lord knows why they designed it this way, but it's actually scan codes.  Well, that's a problem for internationalization because, when you move the keys around, the scan codes still refer to the same key, but that's a different character.  So one of the problems these guys had to solve, and they call it "mod hex" is their name for it, they had to find scan codes which were invariant across all keyboards, so that the language-specific interface on the computer would still convey the same characters.  Turns out that was not a hard problem to solve.  There are, among all the keyboards, there are enough keys that are always in the same position that therefore always have the same scan codes on the keyboard that they were able to do this.  So the ASCII that you see is always the same, that is, it's...



LEO:  It's kind of the standard set that every keyboard has, as opposed to the extended stuff.



STEVE:  Exactly.  Although it's a bizarre set of characters.  I mean, I'm looking at LVKCCUTLIBFIVJGUTRJNDJBUK...



LEO:  So it sounds like it's alphabetic, not numeric, not punctuation.



STEVE:  Correct, it's all alpha characters.



LEO:  Uppercase and lowercase?



STEVE:  Well, I'm looking at a capital "I" at the beginning.  But then everything else is lower case.  So it looks like maybe they just capitalize the first character.



LEO:  The reason I ask is sometimes passwords are case sensitive, sometimes not.  Sometimes they require you have to do special requirements like a number at the beginning, which really drives me crazy, by the way.



STEVE:  Well, and see, this would not be used by any normal, like, thing that was asking for a password.



LEO:  I guess you're right, huh.



STEVE:  Yeah, the idea is this would always be going directly to someone who's doing your authentication.



LEO:  Got it.



STEVE:  Okay.  So we have - they're encoding four bits, four binary bits in each character, so they have a 16-character alphabet.  So those first 12 characters that are invariant, that identify which YubiKey out of all YubiKeys you've just stuck into the keyboard, those 12 characters convert to 48 bits.  So there's this 48-bit ID which the YubiKey declares itself as.  Then you've got 32 characters which immediately follow.  So that's a total of 44 characters, the first 12 followed by 32.  Well, those...



LEO:  That should be enough.



STEVE:  Oh, yeah, I mean, it just - and it's got - what I was reading a second ago was the output from my YubiKey, which...



LEO:  Notice I interrupted you before you got to all 47 characters.



STEVE:  I was - I had four to go.  But my point is that's what this thing looks like.  So it's 32 characters.  And of course, again, four bits per character means that it encodes 128 bits.  So essentially you are sending a 128-bit blob every time you authenticate.  So the YubiKey contains a write-only 128-bit AES secret key.  So mine is different than yours is different than everybody else's.  Those first 12 characters that the YubiKey sends in the case, for example, of authentication by Yubico, those 12 characters are used to look up in their database the associated 128-bit AES key that is also contained in the YubiKey itself.  So the YubiKey encodes some data that I'm about to describe using its secret 128-bit AES key.  And we know AES is just Rijndael, my favorite cipher of all time.  It encodes the 128 bits of data using its secret AES key, turns it into this mod hex, and spits it out.



It then travels across the Internet or to wherever it's going for authentication.  The receiver knows this key's secret 128-bit symmetric key.  It simply - it does a Rijndael decode to turn it back into the 128 bits of plaintext that then allows it to proceed with authentication.  So the YubiKey itself, you can write the AES key into it, that is, its own secret 128-bit AES key.  But there is no provision at all for reading it out.  It will never tell you, nothing you can do to it will cause it to relinquish its key.  You can only push the button and have it spit out these tokens.  But you cannot get it to tell you its key.  You can give it a key.  It'll never give it back to you.  It'll only give you the result.  So it's very secure from that standpoint.



LEO:  I think this is such a cool technology.  I can see why you got jazzed about it.



STEVE:  Well, and so now we've got 128 bits.  And, I mean, they came up with 128 bits, of course, because that's the width of a Rijndael block.  So that's 128 bits is 16 bytes.  The first six bytes is a unique device ID.  And again, every single key ever made has a unique ID.  This is part of what, you know, they're planning ahead.  They're saying what if this thing really takes off?  Well, we want to make sure that all keys are unique so that we can use them for identity purposes without any collision.  So you've got six bytes, which is 48 bits, which is a ton.  I mean, I don't have a calculator in front of me, but that's a lot of devices.  That's more than we're going to need.  It's like the same six bytes in a MAC address for an Ethernet controller where you want every Ethernet controller in the world to have a unique ID so that - because that's the way that the MAC address identifies Ethernet devices on an Ethernet LAN, and you don't want them to collide or you can't have those two devices on the LAN.  So similarly, this prevents any collision between all the YubiKeys that will ever be made.



Okay.  Then we have a two-byte, what we call a "session counter."  That is a nonvolatile counter, and it counts the number of times the YubiKey is powered up.  So if you plug it in, that session counter increments once when the YubiKey powers up.  And that's nonvolatile.  So it only increments, and it never resets to zero.  Next is three bytes of a timestamp.  And that's a three-byte counter, 24 bits, that runs at 8Hz.  So eight times per second this three-byte timestamp is counting up.  Well, that means that it will run, before it wraps around, it runs for 24 days.  And that always starts at zero when you plug it in.  So you plug it in, the session counter, which is two bytes, increments by one.  And this timestamp starts running.



Well, this has a number of features.  One is it has an anti-phishing feature because it means that they're able to determine when - because essentially you've got time embedded in the YubiKey's output.  They're able to determine, that is, the recipient is able to determine for successive outputs during a single session when these were generated by the key.  So if anything were to intercept this and impose some interception delay and then try to use it, it contains a timestamp.  So by comparing the timestamp received from previous receptions of this YubiKey output, they're able to determine whether these are out of sequence, whether they've been delayed for some reason, because normally the authentication happens in near real-time.  You know, you're on a form, you go to the YubiKey field to authenticate, or maybe you've got this all built in, for example, into a, for example, a VPN client.  And you press the button, it types the stuff out, then you would submit the form.  So there's only, like, a few seconds delay between the time the YubiKey generates its token and the authenticator has it and is able to authenticate.   So just, I mean, they had 128 bits to play with.  And so from an engineering standpoint they said, well, what cool things can we do with all this face?  So they gave us an 8Hz timestamp, so every YubiKey token is timestamped in real-time as it's generated.



LEO:  That actually solves a problem that VeriSign has with their football or their little card; right?  Because if you're out of sequence, sometimes, occasionally, if you press the key a bunch of times or whatever, you'll have to get back in - they can lose track of the sequence, I guess.  Does this solve that?



STEVE:  Well, actually we've got so many bits.  And what we're really doing is encrypting this thing.  In fact, all you really want to do is prove that you have the magic 128-bit AES key.  So the fact is, just decrypting this and doing a sanity check or...



LEO:  Oh, that's all you have to do.



STEVE:  That's really all you have to...



LEO:  You don't have to match it up.  You don't have to generate a matching key or anything like that at all.



STEVE:  Exactly.



LEO:  Oh, I see.  So it really is a different technology than the football.



STEVE:  Yeah, well, it's a completely different approach because they're not, again, they're not having to try to say, okay, we've only got six digits.  Because six digits does not give you enough specificity.  I mean, you know...



LEO:  There's more than a million keys, one hopes, out there, so that's not going to do it.



STEVE:  Exactly.  Okay.  So the next byte is a session use byte, just one byte which increments every time you use it during that session.  So remember we have the session counter that increments once for the whole power-up cycle.  And then the session use byte, it starts at zero for at the beginning of every session.  And then it increments.  And that's just to make every single one unique, even though the timestamp would also do it.  But the next two bytes is 16 bits of pseudorandom data.  So they have a pseudorandom generator that just generates 16 bits of noise that is added in.  The reason they do that is that the one concern that you would have in simply encrypting Rijndael or any symmetric cipher block, we've talked about this before, is that this uses what's called ECB mode, Electronic Code Book mode, meaning you simply take the data, and you encrypt 128 bits into 128 bits.



Well, the problem with ECB mode is the so-called "known plaintext attack," meaning that if you ever are encrypting the same data or potentially similar data, there's a theoretical vulnerability, that is, that you could begin to build up a mapping between the plaintext and the encrypted data.  So what they do is they throw in this two bytes of pseudorandom data in addition to three bytes of timestamp, which is running at 8Hz.  That's much faster even than you're able to emit these key output.  So there's a lot of randomness in those two things.  Or at least nondetermination.  And then they have the pseudorandom bytes.  And, finally, a 16-bit, two-byte CRC, a Cyclic Redundancy Check, which applies to the entire block.



So the idea would be you receive one of these things, which is this funky mod hex code.  You translate each of the 16 different characters in the alphabet into four bits.  That gives you 128 bits.  Then you look up the key's secret 128-bit Rijndael symmetric key.  You decrypt that 128 bits into this data that I've just described.  So now you have the device's unique ID, six bytes; the session counter; the timestamp; the session use byte; then the two pseudorandom bytes that you ignore.  But you do run all that through the CRC just as a sanity check to make sure that you have probably decrypted something that is valid and that there was no data loss or corruption at any point.  And then you've got all this information about the YubiKey, that is, how many times it's been used in that session, a sense of the time flow during that session, and you can use that to authenticate and to provide various forms of anti-spoofing protection.



LEO:  Very cool.  Somebody asked in the chatroom if a keystroke logger could capture these keystrokes.



STEVE:  Absolutely.  And I'd be happy to read mine out to anyone who wants.



LEO:  It doesn't matter.



STEVE:  Precisely.



LEO:  It's a one-time key.  And that's what makes it so powerful.



STEVE:  Yes.  Exactly.  It is a one-time key.  And again, oh, I forgot to mention, that session counter that is two bytes, they actually have stolen the top bit from it.  So it's only 15 bits, meaning that it runs up to a maximum of 32767.  It starts at zero.  When it gets to the maximum of 32767, it stops, and the YubiKey dies.  So that's one thing worth noting.



LEO:  Wait a minute, say that again?  It can only generate how many?



STEVE:  No, no.  That's what's cool.  It's not about - it's how many sessions it can have.  That is, it counts - it's a 15-bit counter.  So it counts up to 32767.



LEO:  So what's a session?



STEVE:  A session is when you power this thing up.



LEO:  Ah.  So you would have to unplug it and plug it in again to start over.



STEVE:  Exactly.  Well, no...



LEO:  Big deal.  You're not going to use 15,000 sessions.



STEVE:  No no no.  No.  Now, remember that the key is - this is a one-time password generator.  Therefore that session counter can never be allowed cryptographically to wrap around to zero because that's where it started.  And although...



LEO:  It would repeat passwords.



STEVE:  Exactly.



LEO:  So are you saying that after 15,000 passwords this stops working?



STEVE:  No no no.  It's very important that people understand this.  First of all, it's 32,000.  It's 32,000 sessions.



LEO:  635, what it is.  No, it's only 15 bits.



STEVE:  It's 15 bits.  So it's not 65,000, it's 32,000 sessions.  But you can generate as many passwords in a session as you want to.



LEO:  And you're saying a session begins when you power it up.  So it sounds like every time you unplug and plug it in, that's a new session?



STEVE:  That is correct.



LEO:  Okay.  So you wouldn't want to unplug it and plug it in.



STEVE:  Well, consider that that's a big number.  First of all, that's 10 times a day for nine years.



LEO:  Okay.  Never mind, then.  We won't worry about it. 



STEVE:  Well, and imagine that this thing takes off.  For example, you're using it as your OpenID token.



LEO:  Which means you'd probably want to leave it plugged in.



STEVE:  That's my point is you're - or you're using it to authenticate yourself to your bank and your corporation and so forth.



LEO:  So before you get to work, you sit down, you plug it in, and you press that button whenever you need it, and you unplug it at the end of the day.



STEVE:  Precisely.



LEO:  You're not going to use - how many per session do you get?  Is it...



STEVE:  No, it's infinite.  There's no limit on the number of keys you can generate per session.



LEO:  Oh, okay.  Then forget it.  Then it's not a big deal.



STEVE:  And the other reason that this is important is, remember, we know about nonvolatile RAM not lasting forever.  That is...



LEO:  So it's not writing to the RAM, or the EPROM.  It's reading from the PROM.



STEVE:  Well, the nonvolatile portion, that is, this two-byte session counter, that's changing.  So they did need to protect against the standard NV RAM fade, because we've talked about how some nonvolatile RAM you can only write to 10,000 times.  Some is 100,000.  Well, in this case, from an engineering standpoint they knew that the nonvolatile portion of this would be aging as it's counting sessions.  So exactly as you said, Leo, I mean, imagine that the typical use might be you plug it into your laptop, turn your laptop on, a little green light comes up.  And then during your use of the laptop over the course of several hours, any time you needed to authenticate to an OpenID site you would just reach down and put your finger on the little touch surface, and it would emit a YubiKey token.



LEO:  I love this.



STEVE:  It is really neat.



LEO:  You know, I use - and actually it's interesting, our new office manager, Frederique, said is it okay if I plug in my RoboForm.  She has, and I use this, too, RoboForm AI has a USB version.  So you plug it in, and your passwords are on there and authenticated.  And it's a very nice system.  But so it's the same idea.  I think people are already used to this.  But this is so much slicker and so much secure.



STEVE:  Well, yeah.  I mean, it is absolutely secure.  You cannot get the YubiKey to tell you its secret 128-bit AES key.  All you can get it to do is to spit out unique tokens which only have meaning if the authentication end already has the key.  And what I was so pleased about as Yubico's concept of what they were going to do with this evolved is, I mean, and they even changed the language on the website in the last couple weeks because there was language about, well, you know, the keys you're buying from them now are evaluation only, and they'll expire.  All of that's gone.  That was, you know, they weren't sure what business model they wanted to have.  And they've settled on, okay, we're going to sell these keys.



LEO:  They picked the right model, I think; don't you?



STEVE:  Oh, I mean, it's why I'm so excited about this.  Leo, I can't - there's no way that VeriSign will tell me the algorithm that they use in their footballs or their cards.  Therefore I cannot...



LEO:  You can't trust it, right.



STEVE:  Well, I cannot authenticate.



LEO:  Oh, you can't do it yourself, either.  Right.



STEVE:  Right.  You cannot do it offline.  There's no way, for example, that this could be used for, like, Windows log-in that is VeriSign stuff.  You have to have a network connection in order to get them to do it.  And it's like, well, okay.  But corporations have a substantial cost associated with using that kind of big corporate authentication solution.  And it's, I mean, VeriSign's model is we're going to be - we have a big network.  We're not going to go down.  You can trust us to be up all the time.  And it's like, well, okay.  But it does limit the applications.  Here Yubico tells you everything you need to know.  I mean, it's why I love it.  I mean, I love crypto, and I love authentication.  Now I've got these keys that I can use for any purpose I want.  I mean, Sue, Greg, and I are going to use this to access...



LEO:  So you're going to do it.  You're going to implement it.



STEVE:  Absolutely.



LEO:  Oh, isn't that neat.  I want to do it.  I don't have anything to do it with, but I just want to do it.



STEVE:  Well, it is immediately an OpenID.



LEO:  You know what I thought it would be really good for?  Now, we're not probably going to do this.  But if you wanted to do a paid, say, paid podcast, a paid show, somebody could subscribe, and you'd mail them, they're cheap enough, you could mail them a YubiKey.



STEVE:  Yes.



LEO:  And they couldn't watch it without the YubiKey.  And it's kind of - I don't want to say, I'm not recommending it for DRM.  But it could be the ultimate DRM.



STEVE:  Well, as a matter of fact one of the applications that Stina mentioned is the idea of for online gaming or even for downloadable games.  It ends up being a very painless hardware key where you would allow people then to download updates and download the software which won't work until they authenticate with their YubiKey.



LEO:  So now it's gone clean out of my head.  I thought of some negatives about this.  I mean, I guess one negative would be if you lose it there's no way they can give you a replacement; right?



STEVE:  That is correct.  Now, I did want to mention my concern over the idea of this 32,000 sessions, or days, or however you would use it.  The comment's been made that if this thing is on your key ring, and you're putting it in, pulling it out, putting it in, pulling it out, it probably mechanically degrades.



LEO:  Exactly, it's going to wear out before it numerically wears out.



STEVE:  Exactly.  And so at some point it's looking kind of ragged.  And so you would tell your IT department, hey, you know, my YubiKey's chipping off, and my dog chewed on it, and can I have a replacement, please.



LEO:  Yeah, and then what do we do?



STEVE:  Well, oh, that's no problem at all.  Or if you lost it.  You'd report it lost the way you would a credit card, and they'd just cancel it.  They'd just hand you another one for, I mean, I didn't go through her whole price list.  But at a million quantity, I mean, I guess a large corporation that wanted to standardize on this, they're $5 each.



LEO:  Okay.  Which is what the football costs from PayPal.  And they're subsidizing it.



STEVE:  Well, yes.  Now, I do want to say that one downside, it's worth mentioning, is that the football and the credit card, that is, the two visual numeric ID solutions, because they don't use any kind of electrical interface, they could be used for authentication over the phone or at a...



LEO:  Right.  You have to manually enter the number or speak it, but you can do that.  You couldn't do that with the YubiKey.



STEVE:  Or like in some sort of a, like a Windows kiosk or something where you don't have access to the physical machine.  So one limitation is it is, being a USB thing, it's for an end-user who has a computer and has access to that computer's USB ports.  Someone in the, I think they have an FAQ on their site where they said, well, wait, my USB ports are all on the back of my desktop.  I can't get to them.  And the answer...



LEO:  Get an extension cord.



STEVE:  Exactly, just get one of those cool little USB extension cords.



LEO:  Right.  And most PCs now have it right on the front.  I mean, that must be an older machine.



STEVE:  Well, because it's becoming so ubiquitous, to use a term.  Anyway, the other thing that I think is interesting is that, I mean, on the positive side, I know that our listeners are thinking about this, and there are ways that this can solve problems beyond just sort of generic OpenID-style authentication.  For example, imagine a corporation where they wanted tight control over their corporate portal so that, for example, they don't want spambots coming in, posting things.  They even want control over what sections of the site you're able to go to.  So it'd be very easy for them to YubiKey-enable their own corporate portal so that, if you want to make the query from a database, it says fine, please authenticate.  And all you do is you just touch this little spot that is glowing green on the YubiKey.  It spits the string out, and then you've authenticated yourself.



So you can imagine all kinds of applications where, again, because once this thing is installed, it's so simple to, like, reauthenticate, that it really provides, I mean, imagine the pain of being asked to continually read six digits from the football or the credit card.  I mean, yes, you could, but it's much easier to just touch the surface, and it authenticates for you.  And your entire involvement is just touching the YubiKey.



LEO:  And as you point out, by virtue of the number of digits it can spit out, it has much more secure setup.  I mean, it's a better way to do it.



STEVE:  Well, I mean, yes.  We would argue that six digits that are changing all the time is secure enough.  But it is the case that this is vastly more secure because you're communicating 128 bits which are encrypted with 128-bit Rijndael key.  Only the matching key will decrypt it and then give you the data.  And as I said, you can really ignore the data.  The fact that you decrypted it means you decrypted it for the proper key.  So that proper key had to be at the other end of the connection.  So it's dramatically more secure than six digits could be.



LEO:  Couple of points from our chat.  [Loveman ph] says if you have to phone home, doesn't that mean that it wouldn't work with static passwords on a website?  What we're saying really is that it's an OpenID device or something like OpenID, where it would establish your identity, and then OpenID - so the website - so say you use it for TWiT.tv, which we support OpenID.  We don't have logins at this point, but if we decide to do logins we support OpenID.  All you would have to do is use an OpenID provider that supported the YubiKey.  Then when you go to TWiT.tv and it says, okay, log in or provide your OpenID identity, you just plug in the - I think, now correct me if I'm wrong, Steve, but you would plug in the YubiKey.  You would click on the place where it said provide open - no, it wouldn't work for that, would it.  You'd have to enter your OpenID identity, so go to your OpenID provider, then...



STEVE:  Then you authenticate...



[Talking simultaneously]



STEVE:  Yes.



LEO:  So then you'd put in your key or press the button, and that would spit out the code that your - you wouldn't even need, say, a log-in and a password, or might you?



STEVE:  Well, yes.



LEO:  You're in effect logging in because you have a unique number in that.



STEVE:  Well, you have the flexibility - that's, again, that's what I love about this is that this is a - it's like a low-level perfect crypto toy that you can do anything with you want.  Now, the reason you probably want a passphrase is that you want to protect against, remember, we're talking multifactor...



LEO:  Somebody stealing your key, of course.



STEVE:  Yes, multifactor authentication, meaning more than one factor.  So you would have something you know would be your passphrase.  Something you have is the YubiKey.



LEO:  Got it.  So you'd want both.



STEVE:  Yeah.



LEO:  Yeah.  That makes sense.  So this is a very cool - also one more comment.  And this one is more about our broadcast than it is about the show today.  Robodog has twittered to me on our Twitter account, by the way, which is TWiT Live, if you want to follow the podcasts, broadcasts, and send us questions.  He says, all right, Steve has the pipes to support many cams.  Can we see Steve by next week, please?  And he also wants a - and I think this is a brilliant idea - a whiteboard for you.  Wouldn't that be cool?



STEVE:  I'm busy enough, Leo.



LEO:  No, no, I can do it.  I'm not asking you for it.  But we will - eventually the set up will be, and it's just we're, you know, in fact after the show today I'm going to open up our TriCaster, which will give us this capability of switching to a camera.  So Steve, all you would have to do is send video with your Skype, which you can easily do.  And then we'd be able to switch to your video as you're talking.



STEVE:  Eh, we'll see how that goes.



LEO:  You don't want to do that?



STEVE:  I don't think so.



LEO:  You don't want anybody to see you?  You're not wearing any pants, are you.  Steve doesn't want to have to put on makeup.



STEVE:  There's nothing to see.  It's me leaning forward, talking into this beautiful Heil microphone. 



LEO:  What do you think it is when they look at me?  At least they'd have something else to look at.  Now, the whiteboard is kind of an interesting idea, and I think we could do a digital whiteboard.  We're going to redesign the homepage for this.  In fact, we have a very nice homepage in mind.  But that's an interesting idea, where we would have something that you're on, on your side - you've done PowerPoints for the TV show - where we could actually throw those things up so that people would have some additional information to...



STEVE:  The problem is that was a TV show, and everyone who was watching it was watching it.  This is an audio podcast.  And I would always be focused on conveying this information through audio.  And I think that's, for me, that's the model of this podcast.



LEO:  No, you're right.  In fact, I don't want ever the video to supersede or in any way impinge on the audio.  Because most, 99 percent of the audience listens to the audio, not watches the video.  So you're absolutely...



STEVE:  .99999.



LEO:  Well, it's not that bad.  It's not that bad, Steve.  There are a thousand people watching the video.



STEVE:  What?



LEO:  Oh, yeah.



STEVE:  How do they even know about it?  No one who is listening to Security Now! has even heard about any of this stuff happening.



LEO:  Well, they have now.  But literally there are a thousand people watching.  So...



STEVE:  Next week watch out.



LEO:  So it's not .999, but it might be 99.9.  I don't know what it is.  But so we will have things like show notes and stuff in real-time on the page.  So we'll at least be able to give you links and stuff if you're watching and you want to have more information right there.  I think that's a good idea.  But you're right, Steve, and I really want to emphasize this to everybody who listens.  You're the audience, so we're not going to do anything to impinge on you.  And you're right, if we started doing a whiteboard that would change the dynamic of it.  So I agree with you, Steve.



Steve, anything else to say about Yubico?  It's Yubico.com.  But it's really not selling to end-users.  It's selling to people who would implement it as part of their system; right?



STEVE:  Well, it is selling to end-users.  And I know for a fact from the email that I've received that a bunch of end-users have ordered $35 YubiKeys.



LEO:  But what would you do with it?



STEVE:  It's an OpenID.  And right now it is useful as an OpenID authentication.



LEO:  But who's...



STEVE:  They provide...



LEO:  Oh, they're doing it.



STEVE:  They are, yes, they are right now an OpenID authenticator.



LEO:  Oh, so at the very least you could use it as an OpenID tool right now using Yubico as your OpenID provider.



STEVE:  Exactly.  And they've also published that they're doing backend authentication.  They've got the secret AES key for every YubiKey they sell.  And they have servers up and running, and a fully published public open source web interface that allows anyone who wants to, for example, well, to finish that thought, anyone who wants to to use their backend authentication right now.



LEO:  Right, right, right.



STEVE:  So, for example, you could use it for access to your own wiki stuff and that kind of thing.



LEO:  Perfect.  Oh, you're right.  So we could use it internally, yeah.  All right, Steve.  Very interesting stuff.  I'm glad Stina could join us.  Stina, we never did attempt her last name, but I think it's Ehrensvrd.



STEVE:  Yes. 



LEO:  And we should probably have said that, and said to her, is that how you say it?  But anyway, of course, as usual, as with everybody I've met from Sweden, she speaks better English than we do.



STEVE:  Well, I'm really glad we've covered this.  We're done with the YubiKey at least for now, unless any other new developments happen.  But I think it's - authentication is crucial for the future.  And I love the policies that these guys have adopted for making this really cool one-time password hardware authentication token available.  It's so useful.



LEO:  Next week we're going to answer your questions and suggestions and share them with the world.  So you've got to go to Security Now!'s website, which is GRC.com/securitynow, and you can submit suggestions and questions there.  You can also find there 16KB versions for the bandwidth impaired, and full transcriptions thanks to Elaine - tip of the hat to Elaine.  Cory Doctorow sent us a note saying is Elaine available for other podcasts, other stuff?  And we said yes.  [Note from Elaine:  Thanks!]



STEVE:  Yeah, she loves it.  She's just tremendous.  [Note from Elaine:  Thanks again!]



LEO:  What else?  Oh, show notes are there.  And of course, don't forget, that GRC.com is the same place you find all of Steve's great free security programs like ShieldsUP!.  More than 50 million people have tested their firewalls using ShieldsUP!.



STEVE:  I think we're at 73 million now.



LEO:  What?



STEVE:  Yeah.



LEO:  Holy comoly.  That's amazing.  Well, we'll add another thousand right now, just like that.  And of course that's where SpinRite is, everybody's favorite, my favorite, hard drive maintenance and recovery utility.  If you've got a hard drive, you need SpinRite.  GRC.com.  Thanks, Steve.  We'll see you again next week.



STEVE:  Talk to you next week, Leo. 



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#144

DATE:		May 15, 2008

TITLE:		Listener Feedback Q&A #41

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-144.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 144 for May 15, 2008:  Question & Answer 41.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now! with Steve Gibson, everybody's favorite kind of fatherly uncle-y security guru.



STEVE GIBSON:  I'm not sure what that means.



LEO:  Uncle-y.



STEVE:  Uncle Steve.



LEO:  I think the word is "avuncular" that I was looking for.



STEVE:  Avuncular, that's good.



LEO:  Yeah, you're the avuncular security guy.  And every week we talk about the latest in security on the web, on your networks, on WiFi, all that stuff.  Good to talk to you again, Steve.  I hear you have your triple venti latte?



STEVE:  It's a quad, and it's my third quad.  So...



LEO:  Whoa, wait a minute.  You're running on 12 shots of espresso right now?



STEVE:  Well, it's at the beginning of the third Americana.  So that would be shots, what, 9, 10, 11, and 12.



LEO:  I need one.  I need one badly.



STEVE:  And actually Starbucks has, like, been - they're trying to reinvent themselves with the return of Howard Schultz, who is back and sort of trying to pull them back into more high-end espresso coffee mode.  One of the things they did was they lengthened the length of the shots, meaning that the machines pull longer shots now.



LEO:  Well, that's not good, is it?



STEVE:  And it really made it bad.  I mean, I had, like, a week of hell before I...



LEO:  You want short pull.  So you ask for short pull now?



STEVE:  That's exactly what I do.  I have them do - I do quad, half shots.  And so I get the first, like the good half of the espresso.  And it's funny, too, 'cause they're not used to that.  So it's like, pull down, pull it down, get it out of the machine, let's go [indiscernible].



LEO:  I don't want the rest.



STEVE:  Are you sure you need more caffeine, Gibson.



LEO:  You crack me up.  The good news is, for people who are thinking he's had, like, the equivalent of 12 cups of coffee, I'm told espresso shots are not as caffeinated as drip coffee.



STEVE:  Absolutely true.  The roasting process, which is longer for espresso than it is for regular coffee, it burns off caffeine.  So it's a stronger taste, but it's actually less caffeinated.  I mean, and the commercial coffees, like Yuban and Maxwell House, they amp up the caffeine in order to increase the addiction factor.



LEO:  Oh, that's interesting.  I didn't know that.



STEVE:  That office coffee is like, oh, that'll give you the jitters.



LEO:  It does.  It does.  Well, that's good to know.  So we have a lot to talk about.  I think we should really launch right in.  This is our...



STEVE:  One of these days, yes.



LEO:  Yeah, one of these days.  This is our even week, even show, question-and-answer session.  So we're going to get to your questions.  Got some really good ones, I see them here.  But you have some news?



STEVE:  A bunch of news.  A lot of stuff happened in this last week.  One of the things that happened is I sort of wrapped up my YubiKey/Yubico coverage, as you know, with last week's episode.  And I thought, okay, I'm going to take all this correspondence - because I had a whole bunch of correspondence with the Yubico folks, Stina and Simon and Paul and those guys.  And I thought, I'm just going to stick them all in a folder.  So I did a email-wide search on the term "YubiKey," I think, or maybe it was "Yubico."  And it uncovered - so I just had to give a heads-up.  It uncovered two early mentions of this from our listeners.  And Eric Roller wrote to me back in October of '07, early October, on the 6th.  And the subject was "Security token with a key that is valid for one second."  And he said, "Hi, Steve.  In case you haven't heard about this new idea from a company spun out of Cypak, http://www.Yubico.com.  The idea is that their token, a thin USB stick with one button, acts like a USB keyboard and sends a 128-bit authorization key which is only valid for one second.  There's no battery, and hence no clock on the token."



Well, this was October of '07, and our listeners already knew about it.  And unfortunately I get so many submissions at the GRC.com/feedback page, I never saw this, obviously.  And then this year, in February, Torkel Hasle looks like is the way I pronounce his name, it says "Smart security dongle" with a similar note.   So I just wanted to give a heads-up and shout-out to those guys and say - I mean, and imagine, they must have been, here I am all coming back from RSA, jumping up and down about the YubiKey.  And these guys must have been thinking, hey, we told you about that months ago.



LEO:  Yeah, yeah.



STEVE:  So thank you, guys, and I'm sorry that I didn't get your message.  I just wanted to acknowledge that you were certainly ahead of the game.



LEO:  We get a lot of mail.  You can't see it all.  Sometimes stuff slips through the cracks.



STEVE:  Also, since - actually I think it was the day that our podcast went public last week, that is to say, last Thursday, Service Pack 3 was finally released for Windows XP.  So I just wanted to mention that to our listeners.  As it happens, I did a setup of a brand new XP.  It was a reinstall, actually, for the manager of my local California Pizza Kitchen.  He's a good guy.  He's been bugging me for about a year.  And it's good for me every so often to see how the rest of the world uses...



LEO:  The other half.



STEVE:  Oh, not half, the other 99.9.  His system had 85 processes running.  It never really did finish booting because it ran out of memory before it got booted.  He was using 574MB just because I don't think there's ever been a software offer to which he has said no.  When IE no longer worked because it had so many toolbars installed that there was about a one-inch space at the bottom where you could scroll the web page.  Oh.  Anyway, I had fun with him, saying...



LEO:  That's pretty funny.  But you're right, I think this is normal.



STEVE:  Yeah, and he didn't understand that, I mean, he didn't understand that everything you install, especially nowadays because everything wants to be running, they want to have some little thing in the tray, they want to be checking for updates, they want to - he had something called Ding.  I said, what's Ding?  He says, oh, that's Southwest  Airlines' flight notifier.  I said, do you need that?  He says, well, no, but I didn't - oh, and get this, Leo.  He did not know how to remove software.



LEO:  Well, clearly not.



STEVE:  I mean, he says, I don't know how to get rid of anything.  So it all just kind of piled up.  And I said, oh, baby, did it.  So anyway, now his machine is beautiful.  But I had an opportunity to reinstall XP from scratch.  And you need either Service Pack 1 or Service Pack 2 in order to install Service Pack 3.  So of course I've got from Microsoft, the most recent XP incorporates Service Pack 2 because it's been so long since Service Pack 2.  So I put Service Pack 3 on top of Service Pack 2.  It worked great with no updates.  I did want to caution people if they haven't heard, though, that there's problems, I'm sure you know this, Leo, with AMD chips.  There are some people who then get into a Blue Screen of Death reboot loop if they install Service Pack 3 - which is, by the way, an upgrade that Microsoft will be offering.  So you'll want to say no to Service Pack 3 unless you're sure that it's going to work for you and you've got AMD chips.  If you do get into this trouble, you can boot into Safe mode.  And Safe mode will not give you the Blue Screen of Death.  Then go to Add/Remove Programs and back out of and remove Service Pack 3 from your system.



LEO:  Oh, so there is an uninstall for it.  That's good news.



STEVE:  Yes.  Yes.  Also many, many, many listeners, as I was going through my mailbag for pulling the questions for today, everyone's worried about this news that just recently came out, although Microsoft's been doing it for some time, this COFEE, COFEE with one "F," stands for Computer Online  Forensic Evidence Extractor.  Unfortunately, the online reports exaggerate what this is.  And, I mean, literally, I think it was even Ars Technica, that I normally have a high opinion of, said that it bypasses PC security.  What this is, this is a USB thumb drive Microsoft has prepared, one of Microsoft's security guys who's been with company for four years, prepared this thumb drive that they've been giving out to law enforcement.  And it's like a forensic, well, obviously a forensic evidence extractor for Windows.  And so the concern is that this is, like, some secret backdoor.  I've seen the words "backdoor," "bypasses PC security," you know, "decrypts BitLocker drives."  Okay, none of that is the case.  So I wanted to, for everyone who wrote in wanting to get some feedback about this, all it is is a command-packed set of tools that are otherwise freely available.  It's got about 150 different commands to make it, you know, basically Microsoft's pulled all this together to help law enforcement.  But it doesn't do anything that you wouldn't be able to do otherwise.  So there's no secret backdoor it's accessing or anything.  It's just a really neat toolkit.  And of course the bad news is that, when you give it to the good guys, the bad guys'll get it, too, ultimately.



LEO:  So that's Microsoft COFEE.



STEVE:  With one "F," COFEE.  And it's just a USB thumb drive loaded with Windows evidence extraction tools that are freely available.  You may remember we talked last February about the sort of mysterious Adobe patch where they released a bunch of fixes but didn't tell anyone even afterwards what it was they were fixing.  They've since made that public.  And they now acknowledge that it fixed eight flaws, six of which were allowing remote code execution, and most of which were flaws in their JavaScript interpreter in the Adobe products.  And some are being actively exploited.  So I did want to mention - probably by now, you know, they've mentioned this, by now everyone who is using older versions of Acrobat, for example, hopefully will have upgraded.  I think it's 8.1.something is the current one.  So if you're back on 6 and 7, it is the case that there are malicious PDFs that can literally take over your computer when you view them.  So you want to make sure you're using the latest Adobe.  And...



LEO:  That's the free reader you're talking about.



STEVE:  Yes, Acrobat Reader.  And it is the case that today is, well, actually while we're recording this, we're recording on Tuesday the 13th, which is Microsoft's second Tuesday of the week [sic], Patch Tuesday.



LEO:  Patch Tuesday.  I should run my Windows Update.



STEVE:  Well, yes, exactly.  There are some important things.  So by the time our listeners are hearing this on Thursday, they will probably have already received that.  I did want to encourage people, as always, to keep themselves patched.  There are three critical remote code execution vulnerabilities, two in Office and one in Windows, and then one moderate vulnerability that actually occurs in Microsoft's antimalware products.  So...



LEO:  I love it.  And there's a special irony when security software has malware in it, or exploits.



STEVE:  And actually, yes, we're seeing that more and more.  It's a problem because they're complex software.  And any antimalware, any contemporary antimalware is in the loop.  It's a filter that's putting itself between your machine and the Internet, which means anything coming in hits it first.  Well, if there are any buffer overruns there, it's ripe for exploitation.  So those being vulnerable are a problem.  One of the SANS editors, of SANS Security, Dr. Eric Cole, had a little editorial note that I thought was really interesting.  He said he was encouraging people to apply patches in general as quickly as possible, and Microsoft's specifically.  And he said, "We're now seeing 'Patch Tuesday' followed by 'Exploit Thursday'."



LEO:  Oh, great.



STEVE:  So, I mean, the point being that this window of opportunity, I mean, exploits are being developed from the patches, as we talked about last week.  And people may have only a couple days before they start getting - before exploits for what's been patched go live on the 'Net.  So it is increasingly important to move that up.



LEO:  I like that you call it - in your notes you call this, today, "Exploit Thursday."



STEVE:  Exactly.



LEO:  You've got Patch Tuesday, two days later Exploit Thursday.  So patch fast as you can.



STEVE:  Yeah.  And I just wanted...



LEO:  To raise this issue, typically corporations do not apply patches right away.  They want to test them.  What do you do if you feel like you should test these things before you install them?  You don't have a chance, I guess.



STEVE:  Well, that is really a problem because in the past corporations have been hurt by patches which...



LEO:  Well, individuals, too.  It's not just corporations.



STEVE:  Yeah, although for example a corporation may need to run this stuff against their own internal proprietary software.  So, for example, Microsoft tests it against sort of the native generic Windows OS.  But there have been instances where patches disabled critical infrastructure systems inside of corporations.  And so now they're much more skeptical about it.



LEO:  Yeah.  But I can remember a number of times where patches have caused big slowdowns or had an incompatibility with one drive or another.  And this has been end-users, as well.  So I talk to end-users all the time, especially after Service Pack 2 and that fiasco, who are very loathe to - you know, most of them say, oh, I wait a week to see if there's any big problem with that patch.  You can't do that anymore.



STEVE:  Right, it's becoming, yeah, that window of opportunity has really closed.  Over on the sci-fi side - as we know, that's a passion of mine.  I wanted to remind our listeners that this weekend is the miniseries of "Andromeda Strain" [S/B Monday, May 26, 2008] on the A&E network that Ridley Scott has produced.  And the trailers look really good.  In fact, I saw an extended trailer for it earlier, I guess it was early last week when I was out in the theaters to see "Iron Man," which I loved, Leo.



LEO:  Everybody loved "Iron Man."



STEVE:  Oh, it is so good.  So I just wanted to toss that in, too.  I loved the movie "Iron Man."  And this weekend is A&E's production of the miniseries "Andromeda Strain."



LEO:  So if you get A&E on your cable system you want to check that out.



STEVE:  Yup.  And it will be released on DVD next month, in June of '08.



LEO:  Oh, that's unusual they do it so fast.  That's good news.  That's great.



STEVE:  Yeah, that'll be coming out shortly thereafter.  And I finished the first patent work, the first patent for CryptoLink, my forthcoming VPN-ish product, has been submitted and is now pending.  So...



LEO:  Let me ask you about that.  A lot of software authors do not use patents because one of the parts, one of the things that's part of the patent process is don't you have to expose your source code?



STEVE:  No, you don't have to expose your source code.  You do need to, I mean, the whole idea of a patent is that the, I mean, the concept, the original concept was that the government wants to encourage people not to keep things trade secret, but rather to make them public so that other people can build on those inventions.  So the idea is that once the patent is issued, it is a publicly available document.  In return for publishing the technology, the inventor of the technology receives a multiyear exclusivity on the use of that.  I believe it's 17 years at the moment.  So my interest is sort of in claiming the intellectual rights.  I mean, I've come up with something that's very cool.



One of the security notes that I saw when I was researching news for the week was that apparently SSH password guessing is dramatically on the rise.  SSH we've talked about, it's the secure shell log-in.  It's a service that runs on port 22.  And so apparently people who run SSH are seeing a distressing amount of activity, meaning that malicious people, even apparently some botnets, are now - they're looking at port 22.  If you accept a connection on 22, they will then perform a brute force password guess, trying to get in.  And of course, if they do, I mean, that's really bad.  They've got access to root, essentially, secure shell.



Well, what this first CryptoLink patent does, since I'll be running a service also, I've come up with a way of doing, essentially, stealthing an open TCP port so that it's not open.  That is, nobody except a matching authenticated CryptoLink client is able to see the port to connect to it, even though it's TCP.  So it's a way of stealthing open ports that would prevent all of this kind of problem.



LEO:  Oh, that's interesting.  Very clever idea.  So when are we going to see CryptoLink on the market?



STEVE:  Well, I've got to start working on it first.



LEO:  Oh, you've patented it, but you don't have any code written.



STEVE:  No.  I haven't even...



LEO:  So the patent just has to say your kind of basic algorithm, your fundamental premise of it?  It doesn't have to...



STEVE:  Oh, no, a patent doesn't have code.  But the idea is you must disclose such that anyone who is well informed, who is trained in the art that the patent covers, would be able to reproduce your work.  So, I mean, it is a guidebook to how to do this.  And this is - I've got it probably to three or four things which are brand new that I've invented for CryptoLink.  I'm still busy working on getting ready to start working on the CryptoLink R&D.  So I'm still plenty ways a way.



LEO:  You're a wise man.  You're not going to make any promises about delivery dates.



STEVE:  Oh, god, I have no idea.



LEO:  Okay.  Good to know.



STEVE:  You wouldn't believe the rat hole I'm down in at the moment.  I'm still messing around with third-party cookies, although it's become phenomenally comprehensive.  So, and we found bugs in every Windows browser as a consequence of this work.



LEO:  Oh, interesting.  Oh, that's very interesting.



STEVE:  Yes, the browsers are leaking privacy, and no one knows it.  So we'll be going public with that here shortly.



LEO:  Oh, that's very interesting.  I can't wait.  So we're going to do some questions in just a little bit.  I know you have a SpinRite letter.  I have an Audible book to recommend.  Why don't you tell us about your SpinRite letter first, then I'll tell us about the...



STEVE:  Well, this is a short little fun story that I got a kick out of.  Again, I look for things that are sort of interesting.  This says "SpinRite Saves an Artwork."  And I thought, huh?  Anyway, Gregory Mills wrote, saying, "Steve."  Oh, he's a sculptor and an IT manager.  That's an interesting combination.  He says, "Steve.  I just ran Panda's new active scan" - oh, no, I'm sorry, he was talking about getting a false positive on DCOMbobulator, which is not uncommon because my freeware sometimes has the same code that the malware has in it in order to do what it does.  So anyway, he said, "I also thought you might like to know that SpinRite recently saved an artwork in the museum I work in.  We currently have an exhibit with a digital artwork running in one of our galleries.  The artwork is actually running on a laptop hidden in a pedestal.  The artwork stopped one day, and the computer would not boot.  Needing to get the exhibit up and running, I quickly bought a copy of SpinRite and was able to burn it to a disk within just a few minutes, thanks to your easy checkout and download procedure.  I let SpinRite work its magic, and about an hour later the laptop booted back up.  I got the exhibit up and running with about 30 seconds to spare before a group of 50 fifth-graders came in for their tour.  I listen to Security Now! every week and really appreciate all the work you do to educate us on computer security.  Say hi to Leo and thank him for his hard work, too."



LEO:  Oh, that's great, that's great.  Well, SpinRite does it again.  GRC.com is the place to go to get SpinRite.  I want to mention also before we get into our questions - we've got, as usual, we've got a dozen great questions.  But we have the Winning Kick Ass Revelation of the Week and the Astute Observation of the Week and the Great Quip of the Week.  So you've got some winners in here.



STEVE:  You know, Leo, I'm watching you as we're doing this.  And you're flailing around with your hands.



LEO:  Well, I'm a programmer.



STEVE:  Well, I'm the same way.  And I'm realizing that, when I get a microphone like yours, then I would feel different about being on camera.  Because, I mean, here I am, I'm hunched over my Heil, kind of like I'm some old-time newscaster.  Well, let's see, "Robb in Orlando, Florida, asks" - and so that would make a big difference.



LEO:  We're going to get Countryman for everybody.  I mean, I think this is the key.  I'm wearing a little headset mic.  And I didn't, you know, I was wearing it last week, and it was very echo-y because the room is very live that I'm in.  But we've, you know, there's stuff.  The room is a lot more full than it was last week, and it's getting fuller still, and I think it's not nearly so echo-y.  So good news.  And for those who are watching at home, I just want to point out the reason you're only seeing me right now - Doug Kaye just sent me a note saying you ought to get a teleprompter so you don't have to look off-camera for the chat.  Good point, I am looking off camera for the chat.  But remember, I'm always on camera right now, where eventually we'll be able to see Steve, and I'll switch to Steve, and then I'll read the chat, then I'll switch back.  So the reason you see me look off camera a lot is because I'm on camera all the time.  We want to see Steve.  We want to see everybody.  So that's going to happen.  So you think you'll be able to send video?



STEVE:  I think that sounds like fun.



LEO:  We'll get you one of these mics...



STEVE:  Yeah, I think that sounds like fun.  I mean, there's not much to see here.  But at least both of us are gray now, so...



LEO:  Yeah, exactly.  Are you gray?  You're not gray.



STEVE:  Oh, my goodness, am I.



LEO:  When did you go gray?  You weren't gray the last time I saw you.  You were a little salt-and-pepper.



STEVE:  Well, there's more salt now than pepper.



LEO:  We'll get you a camera.  And then the other thing I really want to do for you is get some sort of virtual whiteboard we could put on the website so you can draw.  Because I know you like to draw.



STEVE:  Oh, yeah.  I don't have enough going on right now.



LEO:  All right.  So we are going to get to our questions now.  We have a good dozen of them, and I'll start with number one.  This is Mitchell, who listens to us in London.  Hello, London.  He worries about Google Mail cracking his 128-bit AES encryption.  How did they do it?  He says:  Hi, Steve and Leo.  I'm a big fan of the show, long-time listener.  Steve, I'm a SpinRite user.  And although I have no incredible stories to report, I find it to be an invaluable part of my toolbox.  If he has no incredible stories, it means he hasn't had any hard drive failures yet, so he's a lucky man.



He says:  I have a question which I hope you can answer.  I recently rebuilt my Firefox profile from a clean installation of Firefox.  I had accumulated way too much junk from all the plug-ins and so forth.  I had installed - if ever there was a needed piece of software, it would be for a Firefox profile cleaner.  You can actually, I think, just throw out the profile, can't you, and start over?  Anyway, he says, I zipped up my new clean profile, which by the way was now 2MB down from 12MB, and attempted to email it to myself at home.  He says he used WinZip, and he used the built-in WinZip encryption, which is 256-bit AES encryption.  He used a 26-character password.  He attached it to an email in his Gmail account, and he sent it.  After a long think about it, Gmail decided to come back and said it had detected an executable and couldn't send the file.  So now I want to know, how did it detect an executable?  Is it able to look into my 256-bit encrypted file?  That's a good question.  Maybe it just says a zip is an executable.



STEVE:  Well, no.  What's happening is - I've noticed this myself.  I can't remember, I was sending a JPEG to someone through Gmail.  And when I went over to Gmail it said it was checking it for viruses.  So it's filtering attachments.



LEO:  As it should.



STEVE:  As it should, which is a good thing for...



LEO:  As all ISPs should do.



STEVE:  Yup.  And what's happening is, I'm sure in this case it's looking at the file header that he's attached  Maybe it recognizes as a WinZip.  I don't even know, and I know nothing about the container that this 256-bit encryption is in.  It'd be nice, for example, if there was no header.  But if WinZip encrypted the entire thing so the whole blob looks like random noise...



LEO:  Yeah.  I'm sure it doesn't because it has to see it as a WinZip file and then ask for your password and unencrypt it.



STEVE:  Probably good enough, then.  But in this case I'm sure, I mean, either Gmail recognized it was a zip, or it looked at the header and didn't recognize it as something that it was able to interpret because normally the way these AV systems work is they'll look at the header, and they'll say, oh, you know, this is a JPEG image.  So it then knows how to parse the header and check the image for any inconsistencies and, for example, if the JPEG might be carrying a virus that's taking advantage of some image processing vulnerability, which we have had in the past.



LEO:  Now, I've seen in our chatroom a number of people say unless you specifically obfuscate the directory, even though the files are encrypted in the zip, WinZip does send a directory of files.  So it can see the names of the files in that bundle.



STEVE:  Ah, interesting.  So, oh, even the names of the files?



LEO:  Well, I don't know.  I'm looking at the chatroom.  But a number of people have confirmed that.  And apparently there is a setting in WinZip that says you can obfuscate the directory.  So if you don't do that, it might know that you have executables in there.



STEVE:  Wow.  Well, we talked about a really cool encryption program called AxCrypt.  That's what I would recommend.  I mean, if this is the case, there's a lot of information leaking out of WinZip's encryption.  And so it would make much more sense.  AxCrypt is a beautiful, well-behaved little standalone encryption program that would have been able to take that profile and turn the entire thing into noise.  And it would be interesting to see whether then Gmail would say, oh, I don't know what this is, but I don't see any viruses in here, and it may well have been able to go through in that case.



LEO:  It may just reject blobs of random binary, be thinking, well, there must be something here.



STEVE:  It well could.



LEO:  Yeah.  And you know what he didn't say, but maybe, you know, you can save a zip file as a self-extracting executable.  If he did that it would be an EXE file.



STEVE:  He's a Security Now! listener, though.



LEO:  He's a smart guy, he wouldn't...



STEVE:  He's on the ball.



LEO:  He wouldn't do that.  Robb in Orlando, Florida is asking about something that just came out in the news this week, quantum computer cracking crypto:  Hey, Steve, I'm curious.  Will today's encryption stand up to quantum computing?  I can't say that I completely understand the ins and outs of quantum computing - very few people do, don't worry.  But I do know it will enable PCs to be millions of times more powerful than they are now, at least that's the advertising.  How will our current encryption algorithms stand up to that kind of power?  Will we just need to come up with something better?  I'd assume that the government will be among the first to have such computers.  Will encryption become trivial for them to break before those quantum processors are in widespread use?  I'm not at all mathematically inclined, but you have such a great talent for putting this stuff in terms that even I and Leo can understand.  Thanks for that.  "And Leo."  And in fact there was a story, but I'll get to that after you talk.  But there was a story about quantum crypto in fact being cracked.  I thought that's what he was going to ask about.  But let's talk about the fact that this is the promise that quantum - in fact, this is actually something that in the advertising for quantum computing they often mention can crack even strong crypto in minutes instead of millennia.



STEVE:  Well, as it happens, I took the opportunity to ask the guys who invented crypto while I was at the RSA conference.



LEO:  Excellent.



STEVE:  The crypto panel did a Q&A afterwards, and I had known Diffie and Martin Hellman when they were working at the AI lab at Stanford back in '73 when I was there.  And I said, so guys, what's the story with crypto and quantum computing?  Is this just all over now?  And what they said was really interesting.  And I can paraphrase what they said.  I'm going to spend some time looking into this so that Robb and our listeners can get whatever ability I'm able to find to explain exactly what the story is with quantum crypto.



LEO:  I'd love a - you want to do a whole show on it?  That would be a great subject, yeah.



STEVE:  Yes, I'm going to do that.  What they said was really interesting.  They said it's not at all clear that what it is that quantum computers are good at will mean that they're at all good at cracking crypto.



LEO:  Oh, really.



STEVE:  Meaning that essentially the idea being that normal computers the bit is either zero or one, and with a quantum computer it's both.  It doesn't have to choose.



LEO:  And you have multiple states.



STEVE:  Exactly, it's multiple state.  And one way to look at this is that it may very well be that the problem set that quantum computing can be applied to is completely different than this step-by-step algorithmic process that crypto cracking is today, which isn't to say that there may not be a way to crack crypto from a quantum computing angle.  But if so, it'll be completely different from the way we would go about brute force cracking crypto now.  So the idea that quantum computers are super powerful and strong and fast and whatever they are, and multi-state, it doesn't - it wasn't clear to these guys that that was going to create any weakness in contemporary cryptography.  Which I thought was, you know, really interesting and telling.



LEO:  Okay.  That's very interesting.  Yeah, because I know that we interviewed some quantum computing folks up in Vancouver there.  That's where supposedly they've created the first working prototype, doesn't do very much.  And they always use this as an example.  Oh, we'll be able to factor prime so fast that we'll be able to break public key cryptography.



STEVE:  Yeah, well, the guys who - certainly the people at RSA have a stake in that not being the case.  But they, I mean, the way they phrase it, I'll try to understand this better so I can explain it to our listeners in a way that even convinces me.



LEO:  Good.  I look forward to that.  Now, there was a news story, there is also quantum cryptography which uses laser beams and kind of uncertain states to create crypto.  And they were having trouble with the authentication part of it.  But they've since gone on to, I think, fix that.  So I...



STEVE:  Well, the cool thing in quantum communication, the quantum crypto communications, is that we're all familiar with the Schrdinger's cat deal where, you know...



LEO:  Why don't you - I don't if everybody is.  That's a great, I guess it's a mental exercise or mental experiment, as Schrdinger and Einstein used to perform these thought experiments.  They call them...



STEVE:  Yeah, the idea - well, the idea is with quantum uncertainty is that the act of observing the state of something forces it to assume one state or the other.  That is, so it's - and the idea with the cat is you could have a cat in a box.  And the question is, is the cat alive or not?  And it's...



LEO:  It's both.



STEVE:  Exactly.  The idea is, well, it doesn't have to decide until you open the box and look in.



LEO:  Until you observe it, it could be either.



STEVE:  Right.  And so they have actually - the physicists have actually figured out how to create a quantum mechanical link such that the act of observing it breaks it.  Meaning that it is provably unsnoopable.  You cannot snoop on it.  You cannot inter...



LEO:  But how would you get on...



STEVE:  ...[indiscernible] man in the middle.



LEO:  How would you then decrypt it?  Wouldn't that break it?  I guess decryption is not considered observation.



STEVE:  Exactly.  And the idea is that it wants to be, you know, it's like the - somebody wants to set up super secure optical links between two points where there's no way that a cat can be put into it that would allow it to be eavesdropped on.  And the physicists can say we absolutely can guarantee you that nobody can intercept this or it just - it won't work.  It'll completely break.



LEO:  Makes sense.



STEVE:  Yeah.



LEO:  Greg Christopher in the San Jose area, just down a little piece from me, is with Adobe on this one.  He says:  Hi, Steve.  I was behind on listening to your podcast due to a busy work schedule, but was listening to your show on the whole disk encryption when I heard your comment regarding the turf fight between InDesign and TrueCrypt.  My first thought was, little do they know someone on the quality engineering staff from Adobe listens regularly and has the ability to do something about this.  Wow, that's great, Greg.  That's exciting.  You guessed correctly as to the root source of the problem - pun intended - and you guessed correctly that we licensed the technology, as it turns out, from Acresso.  These guys, I loathe these guys, they're Macrovision.  Right?



STEVE:  Yup.



LEO:  That's me saying I loathe them.  Greg didn't say that.  But we've had, I mean, Macrovision has caused all sorts of problems.  You also guessed correctly, it doesn't just affect InDesign.  I'll give you the bad news first.  First, all the Adobe Creative Suite 3 products, Acrobat 8 products, and many other products are affected.  He sent us a whole list.  The good news is that Adobe is changing the licensing code to avoid using track zero, and the next set of Adobe products will ship without using track zero for license compliance.  Yay.



STEVE:  Yay.



LEO:  I'm sorry that some of your very astute listener audience who are wise enough to use whole disk encryption have bumped up against this problem.  See, he's saying really it's great that you use TrueCrypt, and we're sorry that this is causing a problem with our products.  We try to make the process as painless and as invisible as possible, but no test plan is perfect.  I can't speak for the company about anything related to software anti-piracy efforts.  However, I think you might find it interesting that only a fraction of the Adobe software in use is actually paid for.  These losses can obviously add up, resulting in fewer people available to create and test the products.  My personal feeling is we do a pretty good job given our constraints.  Big thank you to those who take software licensing seriously and realize that that is money that keeps the new and interesting stuff rolling out of Adobe.  And of course if everyone did that, this problem would likely never have happened.  Love the show.  Keep up the great work.  So he's giving a rationalization which I hotly debate, but I won't do it here, for why they use copy protection on there.



STEVE:  Yes.  And the good news...



LEO:  And I had that hot debate, by the way, with Adobe people, so I don't need to have it with you guys here.



STEVE:  Yeah.  And the good news is they're going to be moving away from it.  So that's...



LEO:  Well, they're going to move away from that.  They're going to change how they do it.  I guarantee you they're not moving away from anti-piracy.



STEVE:  Oh, no, no, I'm sorry, you're right.  I meant that they're going to be moving away from track zero that was colliding with TrueCrypt.  And remember that 5.0 we immediately got feedback from our listeners saying, hey.  They installed some Macromedia thing, I guess InDesign was what in this case the guy was talking about.  And suddenly he couldn't log onto his TrueCrypt volume anymore.  And of course 5.1 fixed that by making the track zero data redundant, so that it would tolerate having Adobe there sharing track zero with it.



LEO:  The real problem is, and I don't care what they go to, ultimately DRM always causes problems.  It breaks something no matter what.  And it's always the honest guy who suffers from it; right?  That's what really gets me.  Pirates just take it out.



Craig Cuttner in Connecticut has a need for speed.  He says:  Love the podcast - loads of great information with just the right amount of geek speak.  He must have a high tolerance for geek speak.  In SN-140 Steve mentioned a media encoder, MPEG/H.264, he's not sure, that effectively used multicore resources.  Many of the professional encoders that are available just call some stock Microsoft DLL and do a mediocre job.  So what brand of encoder is Steve talking about?  What's the one he likes?  What's the one that uses multiple processors?  Thanks, and keep up the good work.  We should mention this was when you were talking about your monster quad core and how that very little software took advantage of it except for this one encoding program.  What was it?



STEVE:  Yeah.  Well, I've been a media guy, as you well know, Leo, for years.  I just - I love doing stuff with media.  And I watch movies on my Palm Pilot by encoding them.  There is a company that I can recommend absolutely without reservation whose products I've been using for many, many years.  Their very first MPEG-2 encoder had a horrible name.  It was TMPGEnc.  It stands for Tsunami MPEG Encoder.  And it then sort of - it went from shareware to commercial and continued to do very well.  Anyway, this is - it's Pegasys-Inc.com, with a hyphen.  Pegasys-Inc.com.  And they've got English and Japanese versions of their website and maybe, I hope, I think, a couple other languages, too.  I use all of their stuff.  They've got a fantastic encoder that does do MPEG 1, 2, and 4, which is the H.264 encoding.  And they've got a very nice, simple DVD authoring tool.



When you compress the media into MPEG-2, which is what DVD requires, then you've got an MPEG-2 file.  Oh, it also does AC3 compression, which is rare to find in a media encoder.  And that's really the audio compression that you want for DVD because you either have to, for domestic DVD, it's either going to be non-compressed audio or AC3.  European DVD understands MP3, but domestic DVD players won't decode MP3.  So you can only compress with AC3, which is the Dolby  Digital compression.  But when you have that file, that's all you've got.  You still need to author that onto a DVD if you want it to be playable in a DVD player.  They've got something that does that.  And you can set up either a no-menu DVD where you just put the DVD in and it just kicks off and plays, or you can - they've got full menuing editing abilities, so you can do, like, multi-episode DVDs and make them yourself.



Anyway, I recommend their stuff.  I have never had a problem with it.  It's very mature.  And, I mean, the only thing I have found that just soaks this quad core machine.  And boy, I mean, this quad core machine with the Tsunami products, the Pegasys-Inc.com products - I still call them Tsunami because that's what they always were for me.  It's unbelievably fast.



LEO:  Makes a big difference to have all those processors, yeah.



STEVE:  Oh, a huge difference with this machine.



LEO:  I think that that's one thing we've often said, which is it is really things like that, like transcoding, or encoding in the first place, that really multicore processors make a big difference.  Most of the stuff you do, you don't need four cores to do word processing, to balance your checkbook, to surf the 'Net.  But you do need it where there's CPU-intensive stuff.  But that's not a lot of what you do, I think that was the point you made.



STEVE:  Right.



LEO:  I think, you know, I'm looking on the Mac side, I think that there are quite a few now that are multicore-enabled, partly because OS X just kind of makes it so easy to do that.  And the development tools make it so easy to do that.  And that's a case of, again, developers relying on libraries.  And if Microsoft's libraries don't do it, they're not going to do it.  And if Apple's libraries do, they will do it.



STEVE:  And I have to say, Leo, I'm unimpressed so far with Mac's compression.  I've tried, I've got a bunch of Macs, and I own the DVD Studio and the standalone Compressor product...



LEO:  [Indiscernible] that stuff.  You don't like Compressor?



STEVE:  I hate it.



LEO:  Really.



STEVE:  I do not.  Unh-unh.  I don't - I want more control.  And it's all generic.



LEO:  Ah, yeah.  Yeah, QuickTime Pro, surprisingly, gives you a lot of control, if you get into the settings deep enough.  I think that's what Alex uses.  I'll have to ask him tomorrow when he comes with MacBreak Weekly.  Because a lot of people talk about Compressor and like it.  I don't, I don't usually use it.  We might have to start doing it, now that we're going to start doing some video.



Ken Juenke in Sparks, Nevada wants to "Yubi-Logon" to Windows:  Steve, thanks for taking the time and effort to introduce us to this great product, YubiKey.  That was our last episode.  I, too, feel it's revolutionary.  I'm going to follow its introduction to the marketplace with great interest.  As I listened to the last podcast, I was hoping you would discuss the use of YubiKey with regard to authenticating a user's Windows session.  I'd really love to give all my users a YubiKey to use when they log onto their computers.  What a good idea that is.  I've emailed Yubico about this topic and received a reply telling me this functionality is coming.  Can you please keep this on your list of what you'll be discussing in future episodes about the YubiKey?  Thank you so much, keep up the great work.



STEVE:  Well, this is sort of - I wanted to put this question in because so many of our listeners asked about, I mean, they were interested in the YubiKey and enchanted by it.  But because support for it is not yet widespread, they were like, okay, well, I want one, what can I do with it?  And then they're looking around for something to plug it into.  And, I mean, figuratively, like what can they do?  And so let's merge this with the next question because I'll cover both sort of at once.  From a technical standpoint it's got sort of the same answer to it.



LEO:  Okay.  Okay.  The next one's from Daniel Ernst.  He's in West Bloomfield, Michigan.  He wants to use YubiKey for TrueCrypt, another very good idea, I think:  Steve, I was so intrigued with the YubiKey at your first mention of it in Episode 141 I ordered it immediately when the price was still in euros.  What, do they sell it now in dollars?  I just got it today, and I love playing with it.  I wish I had some practical use for it.  Again.



STEVE:  He keeps touching it and spitting out random-looking character strings.  Hey, isn't that cool, that's all crypto.  Wish there was something I could do with it.



LEO:  All right.  Seems like there would be some way - I guess when a website asks you for a password you could do that, but you'd have to have some way of remembering it, maybe RoboForm or something.



STEVE:  We're going to talk about that as we go through.



LEO:  Ah, okay.  I know it's meant to provide authentication via the web, but could it also be used locally to provide authentication for an application running on my local machine, something like TrueCrypt?  I use pretty strong passwords when using my two favorite security apps, TrueCrypt and Password Safe, a great password program originally written by Bruce Schneier.  But it's not easy memorizing strong passwords, then typing them in without error.  I'd love it if I could plug in my YubiKey, touch the button, and be in.  Is it possible to incorporate code into an app so that it can authenticate a YubiKey locally?  Oh, now you got me going.  I'm intrigued.  TrueCrypt and Password Safe are both open source, so I assume it's permissible.  That's what you need to do.



STEVE:  Okay.  So let's talk about the idea of local authentication because it's a mixed blessing.  The way, as both of our listeners understand it, is that the normal way you would use the YubiKey is much as VeriSign works with their VIP system, where you have a - somewhere is a remote server which knows all of the YubiKeys it's responsible for, and one or more relying parties, as the jargon goes, someone who wants to rely on somebody's authenticity will accept the YubiKey token from that person as they're logging on, then turn around and ask the central authentication server is this valid.  That has a couple reasons why that's being done.



First, the relying party does not need to know anything about the YubiKey, that is, it does not need to have its secret 128-bit AES key.  It simply forwards the string that it received to the authenticating server and says, is this correct.  The other thing is that the authenticating server is able to maintain the knowledge of the most recent count which is part of the YubiKey token once it's decrypted it.  So it has the YubiKey's key, and it knows which is the most recent password it has seen.  Well, that's important because it prevents a replay attack.  If you were having multiple authenticators, then someone could catch a YubiKey string going by to one authenticating server and feed that to another authenticating server that wouldn't know that the first one had already seen that.  So that's why you need to have centralization of this in order to prevent replay attacks.  So that's the normal network model for authentication.



Now, both these guys, and many of our listeners, I mean, I saw many questions about TrueCrypt, many questions about Windows log-on.  The catch here is that we would be authenticating locally, meaning that the - presumably the system that you are trying to authenticate to would need to know your YubiKey's 128-bit AES key.  And that's dangerous because it could get away from it.  It could get out of its control.  The beauty of using a third party is that they're super security, super trusted.  They've got big guard dogs, you know, barking at people who approach too close to the building and so forth.  So nobody has a chance to compromise the key store.  Okay.  But I thought about this for a while because it would be cool to be able to use the YubiKey, for example, at boot time to authenticate to TrueCrypt.  And...



LEO:  I should say that the problem you're talking about is exactly why you can't make a DVD that's uncrackable.  Because the key has to be stored in the player.  Right?



STEVE:  That's exactly the case, yes.  That's a good analogy, Leo.  And we've talked about this, I mean, why it's fundamentally impossible because any technology that you have total access to, you have total access to.



LEO:  Right.  And if the authentication code is in there, you're going to see it.  You're going to see it whether you store it in memory or  - that was that whole thing we were talking about with freezing memory is because the key's in memory.



STEVE:  So the TrueCrypt is interesting because it is open source, and it would certainly be possible for someone to modify the boot screen, given open sourcedness, to be YubiKey compatible, if that made sense.  And in the Windows case, Windows has a modular log-on system...



LEO:  It's got a hook, yeah.



STEVE:  Yeah, GINA, G-I-N-A, is the dll that does log-on, sort of the log-on experience.  And that is replaceable.



LEO:  Sure.  That's why you can use a thumb-recognizing or a fingerprint-recognizing, yeah.



STEVE:  Exactly, exactly.  So, okay.  So let's take a look at the TrueCrypt example.  So we've got the YubiKey.  Now, there's stuff that's changing all the time that we would not be able to use, or wouldn't necessarily be able to use.  The idea being we want to associate a YubiKey with a laptop, for example.  There is information which is not changing, though.  Remember that the first 12 characters of the string is in the clear, that is, it's cleartext.  It is just the YubiKey's sort of public ID.  So 12 characters, and they use this mod hex encoding which is very much like hex except they don't use 0 through 9 and A through F.  They use a set of alphabetic characters that are in a uniform position on all keyboards.  So it looks more crypto than it really is.  And they're storing four bits per character.



So that 12-character preamble on the front of the YubiKey is 48 bits of data.  That is, it's six bytes, 48 bits.  Well, that's a lot of bits.  I mean, it's not 128 bits.  But 48 binary bits gives you 281 trillion possibilities.  Actually it's 281 trillion, 474 billion, 976 million, 710 thousand, blah blah blah.  So it's a bunch.  So one interesting possibility is just to use the first 12 characters of the YubiKey.  It's going to save you from having to type those.  It's never going to change.  And brute forcing it, although not impossible - again, it's not 128 bits.  But 281 trillion, that's a lot of combinations.  And they do appear to be highly random, pseudorandom tokens on the front of the key.



Now, if you knew the 128-bit secret AES key, then you could decrypt the balance of the YubiKey data.  And that would give you another unchanging six bytes.  Remember that the first six bytes of the YubiKey is its secret ID.  So if you were willing to have the system know your 128-bit YubiKey AES key, then - and that represents some vulnerability because it could get away.  But if you were willing to have the system know that, then it could decrypt the balance of the 128 bits and get another 48 bits that never changes.  And that would give you 96 bits.  Well, now we're talking serious strength because that's that 281 trillion, 281 trillion times.  So that's, I don't know what big number that is.  But, I mean, that's big.



So one interesting possibility would be, first of all, you might say okay, I'm only going to use this YubiKey for authenticating my various laptops, that is, for running with TrueCrypt.  So if I'm only going to use it for that, I don't care of the 128-bit key gets loose because I'm not going to use it anywhere else, and nobody else can do anything with it.  Anyway, it is going to be in the laptop.



Now, one way to prevent it from getting loose is the TPM, the Trusted Platform Module, which laptops are now generally shipping with, because the TPM is able, I mean, this is exactly what it was designed for.  It performs AES encryption, and it stores keys.  So you could put your 128-bit AES key from the YubiKey into it.  Doing so represents no vulnerability because it can never come out.  And you then give it the YubiKey's ASCII string, convert that back into binary, ask the TPM to decrypt it for you, and that would give you the other six bytes.  So if you put those together you've got 12 bytes, 96 bits, and a ton of security.  Basically that would then allow you to use that as the passphrase to hand to TrueCrypt to decrypt your drive.  And you'd have something that was extremely robust.



LEO:  But of course you're relying on some way of storing these keys on the laptop that is secure, and that's why you're relying on TPM.  And I'm always, you know, I mean, look what's happened with DVDs.  I guess if there's an incentive for people to crack these things, they can.



STEVE:  Well, okay.  Here's the point, though, is that without the YubiKey available, presumably someone's going to take your laptop and not going to have your YubiKey and crack it.  So they're in bad shape.  You've got a 96-bit, high-entropy, I mean, essentially completely random set of bits.  That's 281 trillion trillion, or 281 squared trillion trillion, possibilities.  Now, they could get your YubiKey's 128-bit key.  That doesn't help them, though, because they need a string from your YubiKey in order to catch the first six bytes from the unencrypted preamble and the second six bytes from the decrypted internal in order to get all 96 bits.  Well, so we're assuming they're going to have your laptop but not your YubiKey.  So, I mean, and that's the whole point of multifactor authentication.



LEO:  Right.  If they had the YubiKey, they'd press the button.  And then they wouldn't need the YubiKey.  Right, that makes sense.  Dave Rodgers, Green Bay, Wisconsin has been thinking about DNS.  He says:  Dear Steve, Windows XP allows you to change your DNS server settings to use the Netgear router's gateway IP as a DNS server, 192.168.0.1.  Is this more secure or less secure than using your ISP's default DNS IPs?  Unless the Netgear has a DNS server built into it...



STEVE:  Precisely.  That was what I wanted to mention was that the consumer routers, these little plastic boxes, do not have a DNS server built in.



LEO:  So what's it do?  It goes, I don't know.



STEVE:  It turns around and just basically it does NAT on the DNS query and just sends the DNS query right back out, just like you do, to the ISP DNS which it has received from its DHCP query of the ISP's connection.  It would certainly be possible for a higher end box, if somebody were running Linux or a UNIX machine as their gateway, it could be running a full copy of BIND, as I do on my own FreeBSD box here, in which case I have no ISP's DNS that I'm using, which is what I was talking about before.  But you're right, Leo, one of the standard little consumer routers, they're not doing their own DNS lookup, they're merely forwarding the query that comes in to the ISP's DNS server.



LEO:  The key is you've got to forward, you've got to use an actual DNS server for this thing to work, whether you set one up yourself, you use OpenDNS.  I know people who use Verizon's DNS even though they're not customers.  But whatever you're doing, you're going to use somebody else's.  And the only way to protect yourself for privacy reasons is to run a DNS server, get SmoothWall or Astaro or something.



Tom Fenton and his classmates at CTU in Denver, Colorado - is that Colorado Tech?  I think it is - wonder about Deep Packet Inspection:  My classmates here in the Network Security Class at Colorado Tech University - oh, I got it - want to know what the deal is with deep packet inspection.  We've read that this type of network analysis will break encryption since it works all the way down to level two of the network stack.  Are we wrong in this thinking?



STEVE:  Well, deep packet inspection is - essentially it's a fancy-sounding word for doing more than looking at the headers.  Most firewalls, and NAT routers, for example, well, NAT routers is a little bit of an exception, which actually is a good example of this.  But simple packet filters, they're not concerned at all about the content of the packet.  They look at the headers, and that's where you find IP address and port number and protocol type and packet type, like if there's a SYN packet it's because it's got its SYN bit set.  And so early packet filters, where you didn't want to allow incoming connections, all they did - they were sort of dumb.  But they just looked at the header, and they would drop any packets who had a SYN bit set.  Because if you do that, then no SYN packet can make it past them, and it becomes impossible for someone to access your servers.



LEO:  Is that stateful inspection?



STEVE:  No, that's stateless inspection.



LEO:  That's stateless.  They don't care about what's going - what the conversation is.  They're just looking for certain little things in there. 



STEVE:  And for example, here that factors in perfectly because, for example, that would mean that if you sent ACK packets through, a firewall would allow those because they don't have the SYN bit set.  So a stateless firewall that is not maintaining state, it would only drop SYN packets but allow, for example, ACK packets through.



LEO:  Presuming a conversation is going on.



STEVE:  Exactly.  But a stateful firewall, it would say, what's this ACK packet?  I don't have a conversation happening now.  And, for example, it would see a SYN packet going out, and that would tell it to expect a SYN/ACK coming back and then follow-on packets.  So it would sort of be maintaining a state of what's going on.  Now, NAT routers have to do a little deep packet inspection because some protocols, for example FTP, embeds in the FTP packets, for example, the port and IP number of the client because FTP involves two connections.  That is, active FTP does.  Passive does not.  And so NAT routers that are FTP aware, they will actually see the FTP packet and reach in and modify the contents of the packet on its way out so that it's to adjust the IP and port number that the FTP server behind the firewall has suggested the client connect to it on.  The NAT router needs to change that for active FTP connections to make it correct.  So there's a little bit of deep packet inspection going on.



Now, what Tom is referring to, with his classmates at CTU, this deep packet inspection means looking at the actual contents of the packets beyond just their headers.  And so the question is, does it break encryption?  And the real - the answer is no.  Encrypted traffic cannot be deep packet inspected.  And in fact, using encryption is one way of thwarting and avoiding any packet inspection.  People increasingly use it because ISPs are unfortunately becoming increasingly snoopy about people's traffic.  And if you set up encrypted connections, nothing your ISP can do.  There's no way for the ISP to intercept that traffic, as we've talked about, you know, on many occasions.



LEO:  I bet what they're thinking about is a situation - since they're at a technical university, they're probably learning about networking - is a situation where a business is taking the SSL and doing it themselves.  And in that case they have the ability to decrypt because it's their SSL certificate, not Amazon's or whoever.



STEVE:  Right.  If the business is setting up an SSL proxy, then it's able to decrypt and reencrypt, and in the intervening time look at everything that's going on.



LEO:  Then you could do a deep packet inspection that would actually be meaningful and revealing.



STEVE:  Right.



LEO:  But we've talked about that before.  That's another issue.  Robert Berry in North Carolina doubts that his credit union knows how to factor:  My credit union, he says, has recently, with much fanfare, rolled out what they call "multifactor security."  But it turns out all they've done is to add additional prompts to the log-in process - don't get me started - asking security questions like your mother's maiden name or the name of your first pet.  And they don't even ask these with every log-in, just once in a while.  Is it even legitimate to call this "multifactor security" at all?  Seems to me that it only serves to inconvenience customers while providing no actual protection against identity theft.  They claim they're doing this to comply with a directive issued by the Federal Financial Institutions Examination Council.  I have a hard time believing this satisfies any such requirement.  Oh, oh yes, it does.  I'd be interested to know if you have any recommendations on how I can convince my credit union to implement real multifactor security.  I'm sure cost is a factor, but there has to be something they can do relatively cheaply that is better than this.



STEVE:  Well, what they could certainly do - well, okay, wait.



LEO:  First of all, this does satisfy the FFIEC requirements because they're so pathetic.



STEVE:  It's really distressing, yes.



LEO:  That's why the SiteKey happened.



STEVE:  Yup.  So I would say in response to the question is this real multifactor security, no.  As we know, multifactor means not just more of the same factor.



LEO:  Not just more of something you know.



STEVE:  Yes, exactly.  It's like, so tell me something more that you know doesn't solve the problem because, for example, it's completely prone to any kind of replay attack or keystroke logging or man-in-the-middle interception sort of things.  I mean, that's why something you have is a different factor; or something you are, like a fingerprint, is yet another factor.



LEO:  And I have to say my bank, a big bank, Bank of America, does exactly the same thing as his little credit union is doing.  When we log in from a new computer it says, oh, you'd better answer these security questions.  As if that's somehow making it more secure.



STEVE:  Yeah.  I mean, it makes it - I guess the idea is it tricks the users into thinking it's more secure.  I guess instead of multifactor, it's mobi factor.



LEO:  Mobi?



STEVE:  Mobi factor as opposed to multifactor.  But, yes, this really doesn't do it.  And, I mean, the answer is to go with a common available technology.  I mean, it would be very cool if banks were making YubiKeys available and providing those.  We know they're not very expensive in volume.  Or things like the PayPal football or the VIP security card.  We're still at the beginning stages of this.  But we know that authentication is the big problem that we need to solve.  And we'll be doing that as we move forward, certainly.



LEO:  You know, I wish - you know, I have the football here.  But I wish that more banks would do what my - this is the funny thing.  That little thing that BofA's doing with me with the extra questions is on my business account.  For some reason, and maybe it's just because it's a business account or whatever, they haven't enabled the very real and, I think, good authentication they've enabled on my personal account, which is, if I'm new to the account, or I'm using it on a different computer, it says, okay, we're going to send an authentication code to your cell phone, which has previously validated my number, so I know they know it's my phone.  And now that's something I have, right, it's that number that's come to my cell phone.  That's real authentication.



STEVE:  Yes.  And you're right.  So there's an example of a potentially zero cost...



LEO:  Cheap, yeah.



STEVE:  Yes, yes.  Although...



LEO:  They don't have to send anything out, they just call my phone [indiscernible].



STEVE:  And the thing to do would be to not require it because you might have users that, for whatever reason, don't have a cell phone or...



LEO:  That's exactly what they do, yeah.  They offer it.



STEVE:  Exactly.  And explain that this is - if you want enhanced log-on security, you can turn on cell phone loop authentication, and we'll make sure, we'll take the extra effort to prevent anybody from logging on as you.



LEO:  And I did that.  But for some reason I can't do that on this business account.  But maybe they don't have it on all their accounts.  I think it's a great idea.



All right.  Are you ready, Steve, for the Quip of the Week?  We've actually never had a Quip of the Week before.  This is from Anonymous John in Oregon.  And he says:  Security Now! is costing me a fortune.  So, he says, I just ordered a YubiKey.  Let me tell you how that happened.  I'm listening to the YubiKey Security Now! podcast.  I figure I need a YubiKey (Security Now! influenced purchase) because it sounds so cool.  So I fire up a portable version of Firefox from my IronKey (Security Now! influenced purchase), and I start up a secure session and head to Yubico.com to order the YubiKey, which I paid for via PayPal after securely authenticating my PayPal football - where is my football?  Gotta hold it up whenever anybody says "football" - (my Security Now! influenced purchase), and finish the order.  Really glad you guys don't talk about cars or private jets.  Yeah, well, for that you have to listen to the Daily Giz Wiz.  That'll make you buy other stuff.  Sorry we're costing you money.  But it's good stuff; right?



And then here's Tom Willwerth in Seabrook, New Hampshire.  He has the Astute Observation of the Week.  Now, this isn't the super astute one, this is the medium astute one.



STEVE:  This is not the Kick Ass Revelation.



LEO:  I get confused.  You know, as we do more and more video, I think we need graphics and music and stuff.  It's the Astute Observation of the Week.  Steve, I'm an avid listener of Security Now!, also a SpinRite customer.  Yay.  I've enjoyed your talks about EV certification in the past few episodes.  That was that new high-end certification that we're saying you ought to do, even though it's more expensive.  He has a quick tip of EV certificates in Internet Explorer 7 that may be good to share with the listeners.  He says he tried to follow your example in checking out both VeriSign and PayPal to see that neat green bar that we mentioned.  That's what you get when you go to an EV certified site, as long as you're using the latest Internet Explorer.  He says, the problem is I could never see it.  After doing some trial and error, I found that in order for the green shading in the address bar and the company name display to appear, you have to turn on the phishing filter in IE7.  That's funny because I turned off the phishing filter.  I don't use it.  He says, now, I'm a pro user, and I figured the phishing filter would slow down my machine, so I shut it off.  I didn't relate it to the EV certification.  He thought it was just, you know, a phishing filter.  I would say that Microsoft's support for the EV certificate is part of their anti-phishing technology.  Part of, this is an important distinction.  Many users would just assume the green bar comes as part of the core certificate functionality of the browser.  You know, I wonder because I...



STEVE:  I verified.



LEO:  Is he right?  You have to have it turned on?



STEVE:  He's absolutely right.  And that is really annoying.



LEO:  It is because I don't need to have - because the rest of that functionality is you go out and check a database.  I don't need them to do that.



STEVE:  Well, exactly.  And he's right that, you know, if there's some checking database turnaround time, and you're prevented from going to the site until Microsoft gives you the thumbs up, you could certainly see that that's going to slow down your access.  So, but the idea that turning off the phishing filter turns off the EV certification display, I mean, that's nuts.  It certainly doesn't have to.  I mean, that's just some bozo at Microsoft decided, oh, let's, you know, if you're going to turn off the phishing filter, then we're not going to let you know if you're using an extra secure site.  It's like, uh, yeah, that's a good idea.



LEO:  Well, the good news is Firefox doesn't do that.  So the green bar is there whether - and I don't think - actually do they have a - I don't even know if they have a phishing filter in Firefox.  They probably do.  For the alliteration alone.



STEVE:  I guarantee you they've got an add-on for it, if they don't...



LEO:  Yeah, yeah.  Tim Madison in Westchester County, New York, has the long-awaited Winning Kick Ass Revelation of the Week:  Steve, you mentioned on the RSA 2008 episode - that was a few episodes ago - that your credit card information was stolen while most likely using a site that doesn't support PayPal and/or Google Checkout.



STEVE:  Yup.



LEO:  While I may not be as paranoid as you are online, I do like to refuse many online retailers my information by making use of PayPal and Google Checkout.  For sites that don't support these options, I use one-time use credit cards from PayPal, which is actually very cool.  Actually I used one of these when I bought SpinRite, it worked just fine.  And here's how you do it.  Because you don't support PayPal on SpinRite.



STEVE:  Correct.



LEO:  You need a credit card number.



STEVE:  Correct.



LEO:  But you don't have to have a credit card if you've got PayPal.  You log into PayPal.  You click "PayPal Plug-in" under Tools.



STEVE:  And that's the only entry that's in the Tools menu at the moment.



LEO:  Tool.  You don't need to install the plug-in, by the way, you can use these cards just at the website.  See, I'm glad to know that because I thought I had to install it.  Click "Secure Cards."  You can then generate a one-time use card funded through your PayPal account or a multi-use card that only works for a single vendor.  So if I'm going to always use it at Amazon, I just always use it at Amazon.  That way you could set up something that bills you monthly, but you never have to worry if it's getting stolen.  All charges from any other merchant will be rejected.  This is fantastic.  You're right.  This is a revelation.



STEVE:  It is fantastic, Leo.  I tried, as I mentioned before many, many months ago, to get whatever it was I had to do on PayPal to get access to their little freebie thing.  They had an app that you could download.  But I had to get a PayPal credit card in order to enable that.  And I tried to apply, but something about my credit reports threw it off.  And when I got all my credit reports, there was one time where someone changed my residence information and was sending stuff to another state.



LEO:  Oh, man.



STEVE:  It was a credit card scam.  It was another, again, on my identity problem.  And so I think that's forever thrown off my ability.  So if you don't - if you can't use their automation to one-click credit card approval, and I can't, then I was completely blocked from doing anything like this.  So what I loved was Tim brought it to my attention, and I want to make sure our listeners know.  We know we've got a bunch of PayPal users because look how many footballs we're responsible for selling, at $5 for the PayPal football.  So this means that PayPal will now issue you, without needing anything other than a PayPal account, one-use credit card numbers.  And this is fantastic.



LEO:  More reasons to use PayPal.  Now, I have to ask you, though, Steve.  Somebody called the radio show and said, I was listening to Security Now!, I heard your discussion of the fact that PayPal will log through DoubleClick.  And he said that makes me want to stop using PayPal.  Sounds like it hasn't discouraged you from using PayPal.



STEVE:  Well, and we have been critical of PayPal in the past.  And I will continue to be.  It's certainly the case, he's certainly right.  Remember the time that we talked about all the different URLs, all the different links on PayPal's page that loop you through DoubleClick, even though they've got nothing to do with...



LEO:  With no reason.



STEVE:  No, absolutely no reason.  I mean, so as I have said before, I would love for PayPal to have some serious competitor come along.  And Google Checkout, of course there's Google.  I think they bought DoubleClick, didn't they?



LEO:  Yeah, so you know that's...



STEVE:  We need somebody who's interested in doing this kind of really good job, that arguably PayPal and Google both do, but who also is serious about honoring our privacy.  And anybody who bounces their URL through DoubleClick is just not serious.



LEO:  Nevertheless, they're awful convenient.



STEVE:  I'm using them because they're the ones who are there.  And I just - I wanted to bring to our listeners' attention that they now offer, just having a PayPal account, one-use credit card numbers.



LEO:  I'm on my PayPal account.  Now, you said...



STEVE:  It's a menu bar over on the upper left.  And right under Tools should be...



LEO:  I see Auction Tools.



STEVE:  ...PayPal Plug-in.  Oh, in fact, let me see [trumpeting sound].



LEO:  Products and services.  Because I want to use this.  This is great.



STEVE:  Yes.



LEO:  And in fact I do have - I have a number of subscriptions.  So the idea that I could have, say, you know, Amazon is a good example.  And I can set up this credit card without giving it out.  Because, you know, it's funny, my credit card company called me the other day because I was in Australia, and I bought some shoes.  Dvorak always says if you buy running shoes, that's a red flag.  In fact, he said if you want to get a credit card canceled, fill up two different cars with gasoline, right, one after the other, then buy a pair of running shoes.



STEVE:  I believe him on the gasoline.



LEO:  It makes sense.  He says apparently that's what happens is somebody will steal your credit card, they immediately not only fill up their tank but their friend's tank, and then they buy running shoes.



STEVE:  Okay, now, I just logged in, and I'm looking at a redesigned website.  And on the left-hand side I've got a column of stuff.  Oh, and I've got a nice big green bar up at the top saying "Identified by VeriSign."  And I see PayPal Plug-in is the one thing...



LEO:  Ah, there it is.  I see it, okay.  It's on the left, yeah.



STEVE:  Underneath Tools on the left, exactly, in the left-hand column.



LEO:  Now, see, I went there, and I thought, oh, I don't have Windows.  Oh, I don't want to install a plug-in.



STEVE:  I know.  And so then you go - you click that, and then the first thing down below is Secure Card.



LEO:  You don't have to have the plug-in to do it.



STEVE:  You do not need the plug-in.



LEO:  Oh, I'm so happy about this.



STEVE:  Yeah.  I am, I am really pleased.



LEO:  That's really great.  All right.



STEVE:  So thank you, Tim, for the Kick Ass Revelation of the Week.



LEO:  And thank you, Steve Gibson, for yet another fantastic episode of Security Now!.  We thank you for all your questions.  If people have questions they'd like to submit, how do they go about doing that?



STEVE:  You go to GRC.com/feedback.



LEO:  Okay.



STEVE:  And by all means, don't be shy.  Also I have to say, if I go "doo-to-doo," then Elaine writes, "Steve makes trumpet-playing sound."  It's like...



LEO:  She doesn't know how to spell "doo-to-doo."



STEVE:  I saw that in the transcript I was looking at.  And I thought, okay, I gotta go [trumpeting sound].  There she does it again.



LEO:  I love Elaine.  We should have some fun with Elaine.  Meow.  Mrow.  Ruff-ruff-ruff-ruff-ruff.  We'll just have some fun with her, see what she writes.  That's Elaine who does the great transcriptions, which you can find online at GRC.com.  I know it's sometimes hard to follow everything, but the transcripts really make it easier.  If you're one of those types of people that needs to read along as you listen, or even want to distribute it to friends or classmates, we encourage you to distribute the podcast.   You know, as long as you do it for noncommercial purposes, please spread the word.  We really appreciate it.  And there are 16KB versions on the website, too, so people who don't have a lot of bandwidth can get a copy.  Not as crystal-clear sounding.  But they can get a copy of Security Now! that way.  It's all at GRC.com, along with all of Steve's freebies and his bread-and-butter program, SpinRite, the world's finest hard drive recovery and maintenance utility.  GRC.com.  Steve, have a great, safe week.  And we will talk again next week on Security Now!.



STEVE:  Sounds great, Leo.  Thanks very much. 



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#145

DATE:		May 22, 2008

TITLE:		Secunia's PSI

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-145.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo focus upon a comprehensive and highly recommended free software security vulnerability scanner called "PSI," Personal Software Inspector.  Where anti-viral scanners search a PC for known malware, PSI searches for known security vulnerabilities appearing in tens of thousands of known programs.  Everyone should run this small program!  You'll be surprised by what it finds.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 145 for May 22, 2008:  Secunia PSI.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now! with Steve Gibson.  We are going to talk about protecting your butts.  That's what Steve's expert at.



STEVE GIBSON:  PYB.



LEO:  PYB, Protect Your Butt.  He is the guy who created or coined the term "spyware" when he first discovered it on his system way back when, wrote the first antispyware program, and has handed it off since to many other folks.  But that was just the beginning of many, many free security programs he's created, including the very famous ShieldsUP!.  Of course his bread-and-butter is the world's best disk recovery and maintenance utility SpinRite.  Steve Gibson, hi.



STEVE:  Hey, Leo, great to be back with you for Episode 145.



LEO:  You're beating TWiT now.



STEVE:  145.



LEO:  We'll do 145 this Sunday on TWiT, so you're two days ahead.  Congratulations.



STEVE:  Having started much far behind, we're making good progress.



LEO:  It's those lazy TWiT guys.  So we're going to - today we're going to talk about a way to protect your system, your PC; right?



STEVE:  Well, yes.  It's - I don't know if I'd describe it that way.  I would say it's, from my experience, an absolute must-try utility.  It's free, which it's being published and authored by a well-known security group who I've known of for years, that is a - it's a scan of all the software that you've got installed for known security vulnerability.  So it's, I mean, I think of it as the next thing we need for our Windows machines after we've got Microsoft Update and/or Windows Update, Microsoft Update being sort of the more comprehensive of those tools.  You know, that keeps Windows current.  This thing does its job for everything else.  And, I mean, on every single machine I have, even well-maintained machines, there isn't one where it didn't show me I had a couple of applications with known vulnerabilities.



LEO:  Really.



STEVE:  Yup.



LEO:  Well, I wish they made this for web servers because I had a little problem yesterday with hacking, and...



STEVE:  Oh, no.



LEO:  Yeah.  I think I had a disgruntled user on our private TWiT forums, who I had to ban.  He was just horribly offensive, and I banned him.  And about an hour later a SQL injection attack, and all the data had been overwritten by a hacking, you know, a hacker tag.  And then he did the same thing to another website on the same SQL server.  So I have to figure out where that vulnerability lies.  I don't think it's in the forums software because it also happened to WordPress.  I think there's some vulnerability into my SQL server.



STEVE:  Ouch.



LEO:  Ouch.  So I'm embarrassed to admit that that happened.  In fact, I don't - I haven't really admitted it anywhere else because I don't want to give him any publicity, of course.  But since this is a security podcast he probably doesn't listen to it.  Most script kiddies don't.



STEVE:  I would imagine that, yeah, exactly.



LEO:  And, you know, I think it really is a - it's a scripting, you know, I could tell it was a kit attack, you know, something he'd downloaded from the Internet.  But now I have to go figure out what's wrong with my SQL.



STEVE:  Yeah, there are now botnets which are specializing in SQL injection attacks of websites because this is just - it's a huge problem that they're, I mean, basically web servers are now the prime target for these kinds of attacks, like for where we are in the first half of '08.  And this is going to be the SQL server injection attack problem.  I mean, the number of hits on servers that are attempted to be compromised has gone way up in the last months.



LEO:  Yeah, yeah.  It's too bad, but and so we need - I guess probably there are programs like that program you're going to talk about in just a little bit that will do that for web servers.  If anybody finds one, let me know.  I'd love to run an automated program that says, oh, here's hole number one, hole number two, hole number three and so forth.  Are any big security stories out there you want to cover before we get to...



STEVE:  Oh, I've got a bunch of stuff, as always.  I did want to mention that we talked last week about the what was for us new discovery of PayPal's one-time-use credit card.



LEO:  Which I've now used, like, eight times.



STEVE:  Oh, I love it.  Well, I mean, okay.  I love it with reservations.  First of all, the good news is there is a Firefox plug-in in addition to an IE plug-in.



LEO:  Oh, cool.



STEVE:  And they both behave themselves very well.  I have been impressed when I've gone to an eCommerce site and gotten to the page that wants the information.  The plug-in is watching my pages.  It recognizes, ah, here's the shipping address, here's the billing address, here's the credit card information.  And it populates all the fields for me, including populating the field for the one-time use credit card.



LEO:  Well, see, I haven't - I didn't know that.  I've been going to the PayPal page and getting that information, cutting and pasting and everything.



STEVE:  And that's why I wanted to make sure you and our listeners who use Firefox knew that this is available for Firefox, as well.  It's not currently compatible with the Firefox v3 beta.  I would imagine they'll be fixing that or they'll, you know, one way or another that'll get resolved for us.  But it runs on Firefox 2.  And it's very convenient.  I mean, it's way more convenient to use the plug-in than it is to have to go over to PayPal all the time and do that, go through that manually.  You do have to authenticate yourself.  So I've got my little football, my PayPal football, not far from me.  And log in, give them a football number, and then they sort of run a fun little animated, you know, like breaking the code sort of thing as they invent a credit card number.  I also liked the fact that the expiration that it chooses is always next month.  And there was something I signed up for...



LEO:  Well, it's always next month unless you pick the...



STEVE:  The recurring.



LEO:  The multi-use one, right.  And then it's 2010, I think.



STEVE:  Yes.  There was something that I wanted to subscribe to that sort of had this annoying, well, you know, unless you remember to cancel your subscription, we'll just automatically bill this card every period.  And I'm thinking, ah, no you won't, baby, because this card is good once.  But anyway, so...



LEO:  I did find one little issue on Amazon.com.  If you purchase something from a third party, you can't use the card for Amazon because the third party is the one using it.



STEVE:  Oh, yes.



LEO:  I think that that was what happened.  I'm not sure.  But I got - every time I've used a third party it's been rejected.  So...



STEVE:  And I've never had a rejection.  So, yeah.



LEO:  Hmm.   Have you always bought on Amazon direct from Amazon, or are you buying from third parties?



STEVE:  Yeah, oh, yeah, Amazon loves me.  The first couple of years of Amazon I was getting Christmas presents from them.



LEO:  Oh, me, too.  But sometimes now when I buy on Amazon it's through Amazon, but it's not Amazon, it's another company.



STEVE:  Yes.



LEO:  And, now, maybe there was something else going on.  For instance, my PayPal has a fairly low limit, so it may be that they just prevented it because it went over the limit.  I'm not sure.



STEVE:  Now, my standard annoyance with PayPal does apply.  This is something we've talked about before.  I don't want them pulling from my checking account.  I don't like that.  I want them pulling from my registered credit card.  And we've talked about how when I'm purchasing from PayPal, every single time, because there's no way to change that preference, you've got to go in and manually override PayPal's default of pulling from your registered checking account.  Well, using this one-time use credit card there is no way to do that.  You have no option.  And so I'm going to have to say to Sue, who keeps track of my checking account and stuff, I'm going to say, okay, Sue, now there's going to be some little weird things happening here.  I hope that doesn't throw off her balancing my books at the end of the month.



LEO:  That's too bad, yeah.



STEVE:  It really is annoying.  So...



LEO:  Yeah, because there's really no interface to say anything about it.  It just gives you the card number.



STEVE:  Correct.  Correct.  And, oh, you can create an outstanding balance with them.  So I guess I could move a block of money in, keep a balance with PayPal, and then they would pull from that.  Which may be what I do.  I mean, I really do like the idea of using one-use credit cards.  And that's why the idea is, of course, spreading around the industry slowly.



LEO:  Yeah.  And as I mentioned last week, there are credit - I think most credit card issuers will do it.  It's just not as easy.  It's more difficult to find.  It's almost as if they don't want to.



STEVE:  None of mine do.  So I don't...



LEO:  Oh, really.



STEVE:  ...have a choice at this point.  I wanted to also mention we talked about last week how the extended validation display, the green window, the URL window, which is supported in IE7, we talked about how it is disabled when you disable the phishing filter, and how annoying I found that, and superfluous, and without any reason.  The IE8 beta does not have that behavior.  So the good news is, even if you do disable phishing in IE8, which they call the "safety filter," sort of more generic, I guess, you do keep the extended validation display enabled.  So at the point that we begin to move over to IE8, we'll get the extended validation display regardless.  I also screwed up last week telling everyone that last weekend was the weekend of "The Andromeda Strain" miniseries.



LEO:  Wasn't it?



STEVE:  No.  That's the good news for those of you who...



LEO:  You didn't miss it.



STEVE:  ...forgot.  You did not miss it.  It's actually on Memorial Day itself, meaning it's next Monday, May 26.  I've got my date straight this time.  I checked three times.  TiVos all know about it.  A&E's website agrees with me.  I said, okay, I'm going to get this right.  So it's two hours on Monday the 26th, and the concluding two hours the following night on Tuesday the 27th.  So it's going to be a four-hour event by the Scott brothers, Ridley and Tony, who have produced this.  And again, the trailers and previews really look good.  And there was one - I mentioned also that the DVD would be released next month.  Some person who had never seen it was already badmouthing it as a review on Amazon, saying that it completely destroyed, you know, the wonderful classic from 1970, the original one.  It's like, okay, yes.  I mean, that was a great movie.  I've seen it many times.



LEO:  That was Dustin Hoffman in that; right?  Or was that "Outbreak"?



STEVE:  That was "Outbreak," which I really liked, too.  I've seen that a number of times, too, really like "Outbreak."



LEO:  Who was in it, though?  I remember "Andromeda Strain" very well, but I confuse the book and the movie because the book's so visual, you almost think you're seeing it.



STEVE:  Yeah.  I have no problem with there being another one.  It doesn't, in my mind, destroy the old one.  I mean, I can still watch that if I want to.  But here's this, this really looks like it's going to be, you know, good fun remake.  And on the topic of sci-fi, [sigh], Peter Hamilton has started another trilogy.



LEO:  I am still stuck in the middle of "Night's Dawn."  It is the longest book I've ever read.  It's on my Kindle, thank goodness, or I'd be carrying 80 pounds of books around.  I love it, but I keep looking down, you know, the Kindle shows little dots as you're progressing through the book, and they're not moving very...



STEVE:  Oh, no, they're not going to move much.  I was - I had some time to kill Friday afternoon, actually before seeing "Iron Man" for the second time, which I really liked, again.



LEO:  You saw it again, wow.



STEVE:  It was wonderful for me.  And so I was just browsing through Barnes & Noble and the sci-fi section of paperback land.  You know, it's very familiar territory for me.  It's becoming less more so now that I've moved over to eBooks.  But sticking out on the bookshelf of paperbacks was this huge, I mean, it looked like a dictionary.  And it was titled - it had Peter F. Hamilton's name on it.  And it was titled "The Dreaming Void."  And I'm thinking, oh, well, this is new.  And so it was $29.99 at Barnes & Noble.  It was $9.99 on Kindle.  And then I - it's set way in the future.  3589 is the year where this thing is set.  So it's 1500 years beyond where we were with the whole Prime drama, "Pandora's Star" and "Judas Unchained."



LEO:  Oh, so this might really be the third of that.



STEVE:  No, no, no.



LEO:  It's not.



STEVE:  This is its own standalone trilogy.  What's weird is, there are some characters that have been brought over from "Pandora" and "Judas."  So you probably need to read those first in order to get into this.  But frankly, I mean, Leo, I feel a little bit the way you do.  I mean, from what I've read online, various reviews, it sounds like this is another monster, huge, deep character development, lots of threads running in parallel, I mean, it's another one of these big Hamilton projects.  And I don't have the strength for it right now.



LEO:  Yeah, I know what you mean.  But it's nice to have it in abeyance, isn't it.



STEVE:  It is nice to know that it's there.  I'm actually finishing up the third of [Michael] McCollum's Antares trilogy, which I'm rereading just because it's just such a fun, simple, light space opera.



LEO:  Yeah, yeah, I loved that.  That was a wonderful book.



STEVE:  And in a bizarre thing that we've never done before, I have a wedding anniversary wish, wanting to wish a married couple who listen to our show a happy wedding anniversary.  They'll be - their anniversary occurs before our next week's podcast will air.  That is, their anniversary is May 22.  And Sven Thomas asked me if I would just wish them, he and his wife, a happy wedding anniversary.  They've been listening to Security Now! since the beginning.  They love the show.  And so Happy Anniversary to Sven and his wife.



LEO:  You say "they."  So you think she's into this, too, huh?



STEVE:  He says, "Steve, my wife and I have been listening to Security Now! since Episode 1 and have greatly enjoyed listening to you and Leo talk about everything from turning worms to your run-in with DoS and the many discussions on network security," blah blah blah.  And...



LEO:  That's great.



STEVE:  ...they're using an Astaro Gateway.



LEO:  Well, they must be a geek couple.  That's good.



STEVE:  Yeah.



LEO:  I like that.



STEVE:  And he didn't say which anniversary it is, but I wish them many more.



LEO:  Very happy - many returns of the day and happy congratulations.  So do you have any errata or addenda you want to do from last week?



STEVE:  Well, two little things.  I wanted to mention over on the security news side, nothing really has happened in the last week, security-wise, although what's funny is every one of my XP machines has insisted on having Service Pack 3 installed, even when they are fully patched.  So what was happening for me was there was the second Tuesday of the month where we talked about a substantial set of updates, remember there was Office and something in the Jet database both needed to get fixed.



LEO:  Yeah, I remember that.



STEVE:  So it was a big important cycle for updates.  So even when you're completely current, you still have to do the whole Service Pack 3.  Now, they're saying online that there's like a - the way it happens is you update your Windows Genuine Advantage tool, and then it comes up and bugs you again about your settings for automatic updates, which mine are set to download them but notify me and not install them so I can choose when I want to do that because almost always you've got to reboot your system, and I don't always want to, you know, I've got so many things going at once it's like, okay, I don't want a forced reboot right now.  So I like to have that control.



LEO:  Well, the first thing I asked you when you told me about the security program is do I have to reboot?  I hate rebooting.



STEVE:  Yeah, it is, it's inconvenient.  So once the update for Genuine Advantage happens, then you get sort of a special screen that's promoting the use of Service Pack 3.  Now, they say it's a 66MB download.  Yet Service Pack 3 is huge.  It's 300 and some-odd - 324MB.  And so for me it's like, well, I've got it on a bunch of thumb drives around here.  So I just go and say, okay, fine, I'll take care of that myself.  But I don't know what happens if you push past that and effectively refuse to download Service Pack 3.  But it's probably a good thing to do.  Again, my theory is that Microsoft is now testing everything against fully patched, current machines.  People who run into trouble sometimes do because they're not keeping themselves current.  And so I think it's just like, okay, I've given up this idea of selectively installing these things.  It's like, eh, no, just come on, go ahead and do it.



LEO:  Well, you know, you're downloading the network or the IT install, which is the full install.  You could all, I mean, I think if you do Windows Update it's smarter about that, wouldn't necessarily do that, all of that stuff.



STEVE:  Ah, that is very - a very good point.



LEO:  Yes.  So you're getting - when you do the IT install, the full install that you can put on a CD, it's going to give you everything because it's not making any assumptions about what you've done already or not.  I imagine, I mean, I remember Service Pack 2 was 273MB, I think.  So Service Pack 3 would probably include everything in Service Packs 1 and 2, as well; right?



STEVE:  Well, it does need to be - it needs to be installed after Service Pack 1 or Service Pack 2.



LEO:  Oh, okay.



STEVE:  So it has that as a requirement.  So there's some stuff that it makes - that it assumes you're going to have, you know, probably the few things it didn't change between then and now.



LEO:  Oh, that's interesting, okay.  Because, yeah, in the past service packs included - were basically a rollup of everything.



STEVE:  Right.



LEO:  So now they want you to have SP2 installed first.



STEVE:  Yes.  And, you know, of course many XP systems are XP with Service Pack 2.  That is, as you get them they've already got the Service Pack 2 rollup, essentially, preinstalled in them, sort of merged in.  So, and in my case it makes sense for me to download the full network install and stick it on some thumb drives because I've got so many machines around here that otherwise I'd just be redundantly downloading the smaller one multiple times.  So it does make more sense to do it once.  And then you end up with a much faster, a much faster setup each time because you're not sitting around while it redownloads it again, so.  And I did have this time as a little bit of a twist, a different twist, an interesting SpinRite story because this one's subject was "My First SpinRite Failure."



LEO:  My what?  You're going to tell people how SpinRite didn't work?



STEVE:  Indeed.



LEO:  Steve?



STEVE:  This is Matt Clipper, who wrote from Phoenix, Arizona, a Security Now! listener.  And he said, "Hi, Steve.  I've been a SpinRite customer since March '06 and a fan of yours since first seeing you on The Screensavers many years ago."



LEO:  All right.



STEVE:  That, of course, was your show, Leo, many years ago.



LEO:  Yeah.  That was the Click of Death I think you were talking about for ZIP drives.



STEVE:  Yup.  He said, "I've also been a listener of Security Now! since Episode 1.  I'm not an IT professional, but all my family and friends apparently think I am.  I actually have a mechanical engineering background, but I've always been into computers and technology, ever since my grandfather bought an 8088 IBM clone when I was about 10 years old.  Even at that time I was the only one who could figure out how to do anything with the computer."  Especially that machine, you know, an 8088 with a couple floppies in it.  Anyway, so he says, "Anyway, I've used SpinRite dozens of times to recover hard drives of my own and my friends and family.  However, I've come across my first hard drive that I haven't been able to recover with SpinRite, and I was hoping you might be able to offer some advice.  My sister has a Barracuda 7200rpm, model blankety-blank, whatever, hard drive that has failed.  The only thing that's really on it that she wants to recover are all the digital photos of her son that she's taken over the years.  She sent the hard drive to me, and I installed it in one of my PCs.  At first it wouldn't even be detected by the BIOS, or spin up, for that matter.  I tried a few tricks such as freezing the hard drive and tapping it with a rubber mallet to loosen any stiction that might have built up.  I was finally able to..."



LEO:  You know, we should mention that that's an approved procedure; right?



STEVE:  Oh, absolutely.  I've done it myself.



LEO:  Whack it.



STEVE:  Well, you don't want to freeze the hard drive.  You want to - but putting it in a refrigerator to cool it off, just changing the temperature of the drive can sometimes really help in, like, real end-of-life situations.  So this guy...



LEO:  And stiction is where the head has kind of somehow gotten adhered to the surface of the platter.



STEVE:  Well, yes, it's caused because the head is incredibly smooth, the platter's incredibly smooth, you get actually a level of molecular bonding where those two surfaces, they become so tightly connected that the platter is unable to get itself started because the head has enough mechanical advantage that it'll just keep the motor from being able to start the drive.



LEO:  So you whack it with a mallet, or I use a screwdriver.  And just the jolt is enough sometimes to release the head.



STEVE:  Yup, yup.  But that's more of a historical problem.  I'm surprised if it's a newer drive.  But, you know, it was - if he was in a situation where the drive wasn't spinning up, that's certainly something I would try.  So he says, "I was finally able to get it to spin up and get the BIOS to recognize the drive, but couldn't get my system to read anything on it.  At that point I tried SpinRite.  But it would only get a few squares into the data recovery before the hard drive would stop spinning again."  He says, "So I did some research and decided to buy a replacement logic card for the drive off eBay, thinking that it might have been the culprit."  I mean, that's the next best thing you could do after all of this.  And he says, "I made sure it was for the same hard drive model, same firmware version, even the same manufacturing location and approximately the same date of manufacture.  I removed the old logic card, installed the replacement, and voila.  No improvement whatsoever."  So he says, "I'm not one to give up easily, clearly.  But based on your expert opinion, is there any hope left?  Thanks in advance for any advice you might provide."  So, no.  Matt...



LEO:  It's a dead drive.



STEVE:  You have done everything humanly possible.  You can cut out a chunk of this MP3 and email it to your sister, who will know that you have gone beyond and above the call of duty, that there is, I mean, short of literally submitting this thing to a professional data recovery facility that unfortunately charges, you know, many thousands of dollars to pull this thing apart, I just can't think of anything that you could do.  Within your own shop, you've done everything possible.



LEO:  Yeah, I mean, you know, I talk about this on the radio show all the time where you have soft errors, the kind that, well, either an unerase tool or SpinRite can fix, depending on whether it's a file system level or if it's, you know, a sector level.  But then there's hard errors.  There's physical damage.  Software's not going to fix physical damage.



STEVE:  If the heads fall off the drive, then there's just nothing.  Or if it won't spin up, or if it spins down before you can get to the area that you want to recover, I mean, this drive sounds like it's in really bad shape.  So, yes.



LEO:  Sometimes I worry that - I talk about SpinRite.  I love SpinRite so much.  I want to make sure that people understand it fixes a category of problems, not all hard drive problems.



STEVE:  Yes.  I mean, I'm frankly surprised that SpinRite is able to do as much as it can.  I mean, just as a piece of software, it performs miracles.  But if you don't have a drive there, if it really is a doorstop, then there's nothing any software could do to help you out.



LEO:  Right, right, yeah.



STEVE:  It certainly does have limits.



LEO:  Well, and that's why there are people like DriveSavers, who have cleanrooms and guys in bunny suits, and they have every hard drive mechanism, all hard drive parts.  And if a hard drive, if, you know, the bearings are frozen up and it can't spin, they can take it out, disassemble it in this cleanroom, replace the bearings, replace the platter, replace the motor, replace the head, whatever needs to be replaced, and that's why it costs thousands of dollars for people like that to get your data back.  That's a whole 'nother...



STEVE:  It's the next level.  And when your data is that important and, I mean, if it's worth many thousands of dollars, and $89 SpinRite was unable to save the problem - and by the way, I should mention that we absolutely offer SpinRite with money-back guarantee.  We don't have a demo, and we've never been able to do a demo because unfortunately demoing it would solve the problem.  I mean, it would...



LEO:  Well, there are people, and it drives me crazy, you couldn't do this, but it really drives me crazy, some unerase programs do a, quote, "demo," where they say, oh,  yes, I can see all your files, give me 500 bucks.  And it drives me crazy.



STEVE:  Yeah, yeah.



LEO:  You wouldn't do that.  I can't imagine you ever doing that.  And there are reasons, technically, you couldn't probably know ahead of time whether you'd be able to fix something.



STEVE:  And Leo, we give people their money back with no questions asked.



LEO:  That's the best way.



STEVE:  So if somebody did use SpinRite, and it did recover their data, and they want to go to the trouble of asking for their money back, I'm not going to say no.  It's like, okay, fine, you know.  I don't regard that as a sale that I lost.  It wasn't $89 that got away from me.  And in the process maybe this person will recommend SpinRite to somebody else.



LEO:  And I bet it doesn't happen that much because frankly, even if it doesn't solve your particular problem, it's so useful.  You know, I got a frantic call Saturday, right before the radio show, from my wife's great-aunt, Auntie Dawn - actually aunt, Auntie Dawn - saying, "Oh, Leo" - she's in her 70s - "Oh, Leo, there's pop-ups on my screen, and bad stuff is popping up, I can't control it.  And I called my ISP, and I don't know what to do."  And, you know, I really feel there are a lot of people out there I feel for who just don't know - most users, I would guess, don't know what to do.  Anyway, Auntie Dawn is coming up, and we're going to get it fixed for her.  And of course one of the things I'll do is run SpinRite on it.  And it's a case of, you know, maybe SpinRite isn't needed.  But it's just a good thing to have.  And if it is needed, you're really glad you ran it.



STEVE:  Yeah, I told the story about taking the manager of CPK's laptop, that was that crazy thing that had 86 processes running in it and...



LEO:  Exactly.



STEVE:  Using up all the RAM it had just to get booted up, and it wouldn't do anything.  And after I reinstalled XP from scratch I did give it a SpinRite pass.  It took about two hours.  I think it was an 80GB drive.  Maybe it was 60GB.  But, you know, it went through, I mean, it was just in beautiful shape afterwards.  And so I was able to say to him, look, this is an old tank.  I mean, it was a big old heavy Dell laptop that he'd bought refurbished three years ago.  And, I mean, it was a monster.  But the hard drive is in beautiful condition, which I now know thanks to giving it a SpinRite pass.  So, yeah, it wasn't for data recovery, it was for the confidence of the drive's future.



LEO:  Prophylaxis.



STEVE:  There you go.



LEO:  And, you know, that's a very good reason to have and own a copy of SpinRite.  I'm very glad that I have one.  Let's talk about Secunia.



STEVE:  Secunia, yes.  These are the guys that have produced something that I unequivocally - well, okay, one equivocation - almost unequivocally recommend.  Some people are going to be a little put off by the fact that this does phone home in order to check the signatures of their software with Secunia's database.  So that's the only caveat I have.  I don't care.  I use it, and I am really pleased with this thing.  What this does is it is a very lightweight scanner.  The downloadable executable is 485K.  It behaves itself very well.  I am very impressed with it.  First of all, these guys are an old world - well, old world, they've only been around since 2002.  So...



LEO:  That's a long time.



STEVE:  ...they're six years old.  Well, in our industry and in Internet years that's 200 years.  I'm very familiar with their name because I see their name coming up all the time on vulnerability reports.  They've got a staff of people that look at, that find, independently find vulnerabilities in software, much like the guys at EI do, and like McAfee and Symantec and all the other guys.  And so anyway, so I'm seeing them talked about often, and I'm often at their website reading details of the vulnerabilities in specific software that I want to track down and understand better, often in order to talk about it here on our podcast.



Well, they've been working for some time now on a scanner, that is, to take advantage of this database they've built up of known vulnerabilities in common programs.  They have a database of tens of thousands of program signatures.  So, for example, when I ran it on my own main machine - this was this quad core monster that I had just set up - it found seven different problems.  It notified me that the version of Opera that I had installed was 9.26, that there was a known vulnerability in 9.26, and that 9.27 was available.  It found an old version of UPX, that's the executable compressor that I've been using to squeeze the air out of my Windows EXEs, just to make them smaller, because the portable executable format, PE format that Microsoft developed for Windows is just incredibly inefficient.  It's just got huge blocks of unused space in it.  So UPX compresses.  Well, I had version 1.2.  It was working just fine.  But the Secunia PSI scanner told me that there was v3.02 available.  So it was like, oh, cool, I didn't know that.  I mean, I would have never known that unless something had gotten me to get up and go check manually.  I also learned, although I had just installed the current version of Wireshark, which is the renamed version of Ethereal, the very nice open source free packet capture and display utility, I had version 0.99.8.0.  I didn't even know it had gone to v1.  But this PSI scanner knew.  And I had just, again, like a week before, I had downloaded a copy of Wget, which is a little command line utility.  It's a really nice GNU utility that allows you to grab web resources.  It's sort of like right-clicking and doing Save As in your browser.  But there are often times where you're not able to do that.  And Wget does restartable downloads.  It's just packed with features.  Anyway, the one I had, had a security vulnerability that was known.  And the PSI scanner knew about it.



LEO:  Wow.  So that's what it's getting - when you said it phones home, it's going out and it's say, okay, I see Steve has Wget.  Let me see if there are any vulnerabilities.  That has to be updated all the time, so that has to be local to the Secunia servers.



STEVE:  Yes.  Now, so okay, so what it does is - it is  lightweight.  It does not sit here and stomp all over your machine.  I mean, that's why I'm not installing any Symantec stuff or McAfee stuff because these things are - they're huge, and they just muck up everything.  So this thing is very small and well behaved.  It does put itself in the Start Menu.  And it's happy to run in your tray.  Well, again, I'm not somebody who's got 85 processes running all the time.  So it's like, okay, I gently took it out of my - under my startup group because I don't want it running all the time.  I'll run it when I want to just do a check.  But when you run it, even then it's very well behaved.  It doesn't saturate your machine.  I found out it was using, like, 5 percent of one of my processors.  So it's like, okay, I mean, this is an impressive piece of work.  So it runs through, it looks at every executable, DLL, and ActiveX control.  It generates a fingerprint of it.  And for example, on one machine I had 85 executable things.  And it then...



LEO:  And you were complaining about your friend.



STEVE:  No no no no no no.  Not running.



LEO:  Oh, I see, executables available.  I get it.  I get it.



STEVE:  Exactly, on the hard drive.  Total count installed on the hard drive.



LEO:  That's nothing.



STEVE:  I know.  And so it found those that, well, those were things that it knew it knew about.  So it does download - it downloads something ahead of time, and it shows you what it's doing, and you can sort of see the progress as it goes along.  It's downloading some updated something or others.  Then it scans.  And after that, apparently it - everything is over HTTPS, so it sets up SSL connections to their servers.  And it then checks to see for the information that it then needs to download to show what it knows about these programs.  And my point is that what you end up getting, in my opinion, is worth that tradeoff because you don't just get something that says, oops, you've got a problem.



And the reason I'm so stoked about this is what you get is so comprehensive.  For every single thing, they've got what they call their "toolbox" - a download solution button, a solution wizard, you can rescan the program, get online references, technical details, open the folder where it resides on your machine.  You can tell this you want to ignore that in the future.  Or it just has a little quick link to Add/Remove Programs if you just want to go there in order to remove it.  So with all this information, when you expand it, it shows you links to the manufacturer's most recent version.



I mean, I guess my point is that this is so much more than just, oh, you've got some problems.  It will take anyone through the process of deciding if this is a problem for them and helping you, for example, the solution wizard in one case was a little popup dialogue that just sort of took me through removing, downloading, and reinstalling an updated version.  So, I mean, it's very easy to use also.  I'm really impressed with these guys.



LEO:  Is it essentially just looking for applications with known security flaws?  Or does it also look at other parts of your machine and say there's a flaw here, there's a flaw here.



STEVE:  No.  It's just applications with known flaws.  It does have access to Microsoft's Windows Update database.  That's one of the things it needs is to be able to contact Microsoft because it's checking the Windows components versus Microsoft's Windows Update database.  But it's not checking your apps for unknown vulnerabilities.  Basically it's a very sophisticated version management system.  And it's not checking apps that don't have problems.  So it's not just - it's not going to tell you that WinZip, there's a newer version of that.  It's not trying to do that.  It's saying the version of WinZip you have has a known vulnerability, I mean like known to the world, not just known to these guys, because they've got a team of people that are looking at, you know, they're in the mailing lists and blogs and reading all the security vulnerabilities, and this is free.  They have a commercial version that they called NSI, which is their network operable solution.  And I think they charge $30 US, 20 euro, per workstation per year.



LEO:  That's not bad.



STEVE:  So in a corporate environment this allows you, either with or without something running on the client side, it allows, like, a central panel to keep track of all of the machines within an environment and make sure that there are no known insecure problems in the apps of any of those machines.



LEO:  It doesn't sit and run in the background all the time, though, unlike Norton or McAfee.  You just run it whenever you feel like.  It's a scanner that you run on demand.



STEVE:  Well, that's how I run it.  It does, as I said, it does put itself in the startup group.  So it would like to be sitting there and, like, checking in the background.  I don't know how often it checks.  Maybe daily or something.  There's tons of settings.  It also shows you, not only where your insecurities are, it shows you end-of-life products.  I had - oh, it was UPX.  I just clicked the end-of-life tab and got myself sidetracked here.  Yeah, because this UPX v1, they flagged it as end-of-life.  And it'll show you a list of all the programs that you have and the versions that it detected and whether they've been patched.  So, like, patched things, things that have known problems and were then fixed, it found three instances of Adobe Flash, or Macromedia Flash, that were known.  And I said, wait a minute, three?  And it said there was a general plug-in, an ActiveX control, and an Opera plug-in, and they were all older, even though my machine was only, like, two weeks old, and there were known problems with them.



LEO:  Wow.



STEVE:  So anyway, I just want to - I recommend this.  We've got the links on my show notes.  I'm sure you'll have them on yours, Leo.



LEO:  You bet.  But it's psi.secunia.com.



STEVE:  Yes.  Or if you just put into Google "Secunia PSI," it's the first link that comes up.  And then as you said, the URL is psi.secunia.com.  It takes you to the page.  It is completely free for personal use, or they do have the corporate use solution, as well.  I think, I mean, I know our listeners, I have a sense for who they are from all the great feedback that we get.  I am really impressed with this.  I mean, this is something I'm running on, and I have run, on all of my machines.  There isn't a single machine where there wasn't something I didn't know.  And our listeners are people who want to know.  This will tell them.



LEO:  You know, the other question somebody had from the chatroom, SelfishMan asked, 64-bit Windows applications, he said it seems to have some trouble with those.  Is that the case?



STEVE:  Ooh, that's out of my experience.  I'm not over in 64-bit land.  But I can certainly believe it.



LEO:  I wouldn't be surprised.  I mean, that seems to be a - 64 bits seems to be the sticking point for a lot of software.



STEVE:  Yeah.



LEO:  Free Secunia.  We'll have links at Steve's page and at my page.  You can go, by the way, to Steve's site, GRC.com, and get 16KB version of this show for the bandwidth-impaired, full transcripts for those who like to read along while Steve speaks, which frankly I wish I had that luxury, but I don't as they transcribe them after we record them.  I don't think they've yet found a time machine that allows Elaine to go backwards and do it.  But you could find all of that at GRC.com as well as all the different security software Steve's written - ShieldsUP!, Shoot The Messenger,  DCOMbobulator.  You don't still have that original antispyware program you wrote on there, do you?



STEVE:  OptOut was the original program.



LEO:  OptOut.



STEVE:  And it was so heavily linked to by the time I decided that I wasn't going to pursue this spyware issue - and the Ad-Aware people said, okay, we'll always make a free one, and I said okay, good, I don't want to have to do that, that's not my thing.  But it was so heavily linked to that I replaced it with something that just said OptOut is no longer being maintained, you can go to the Ad-Aware people to get something that'll take care of your machine.  So it's sort of there.  It's sort of a stub of OptOut is there just to let people know where they should look.



LEO:  Yeah, you never get rid of the stuff.  The Click of Death program's there, isn't it?



STEVE:  Yeah, TIP, Trouble in Paradise.



LEO:  TIP, that was it.



STEVE:  TIP, yup.



LEO:  I mean, I imagine somewhere there's somebody with a ZIP drive.



STEVE:  Oh, then if they've still got a ZIP drive, they definitely need some salvation from the trouble of...



LEO:  The Click of Death.  They may well have it.  I'll never forget that.  That's when we first met.  That must, you know, last week was the 10th anniversary of ZDTV, of our launch in May 11, 1998.  And so...



STEVE:  Wow.



LEO:  ...you must have been on in the first couple of years, I would guess.



STEVE:  I guess.  It was, you know, it was...



LEO:  Maybe 2000, thereabouts.



STEVE:  First time we met.



LEO:  No, because Kate was still on when you came in.



STEVE:  Actually, Kate, I'll never forget this, it was so fun because I'd been on several times talking about hard drives and Click of Death and so forth.  And, I mean, you had known of me.  We had known of each other.



LEO:  I read your column for years.



STEVE:  Right.  And it was Kate who found ShieldsUP!.  And so during the show they had like a Kate's Picks or a Kate's Discoveries or something.  And she said, hey, I found this really cool security testing thing called ShieldsUP! from Steve Gibson.  And you were sort of like, what?  Our Steve Gibson?  You know, I thought he was a hard drive guy.



LEO:  Well, thanks to IceStrike in our chatroom, who's watching on the live, you know, we stream these shows live now at TWiTLive.tv, IceStrike said you were first on The Screensavers June 17, 1998.  So Steve, our friendship is almost 10 years old now.



STEVE:  Whoa.  That's very cool.



LEO:  That's cool, isn't it?  I like that.  Thank you, IceStrike, for looking that up.  So 10 years later, and we're still talking about security.  Not about ZIP drives anymore.  100MB drives.  You can now, you know, in your cereal box you get 128MB for free.  And you can buy 3GB or 4GB flash drives for less than one disk would have cost you in those days.



STEVE:  Yeah, .1GB is the...



LEO:  .1GB.



STEVE:  .1GB was the ZIP drive.



LEO:  Steve Gibson, thanks so much for joining me.  GRC.com.  Go there, too, to get SpinRite, the finest disk recovery and maintenance utility in the world.  I'll be using it when Auntie Dawn comes up on Friday.



STEVE:  And we should remind people that next week will be a Q&A episode, and to go to GRC.com/feedback in order to send me stuff, which I'll read and we'll talk about.



LEO:  Great.  Steve, thanks for talking to us, and we'll see you next time on Security Now!.



STEVE:  Okay, cool.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#146

DATE:		May 29, 2008

TITLE:		Listener Feedback Q&A #42

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-146.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 146 for May 29, 2008:  Listener Feedback #42.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now!, time to talk about protecting yourself on your computer, online with your credit card and every other way possible, with Mr. Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Hi, Leo.  Great to be with you again.



LEO:  Good to talk to you.  Now, let's see.  This is an even-numbered episode; am I right?



STEVE:  Yup, it is, 146.  In fact, we are ten weeks away from finishing our third year.



LEO:  Really?  It's been three years?



STEVE:  Can you believe it?  It's, like, where has it gone?



LEO:  That is amazing.  Well, you were the second show I did, right, I mean, after TWiT?



STEVE:  I think that's the case, although they were coming on pretty fast.



LEO:  Amber and I did one.  I think you were first because I remember it hit me, I could do more than one of these.  What a fool that I am.



STEVE:  And, exactly, and if you're doing one, than adding a second one is way less than twice as much work, so...



LEO:  Right.  Well, and that's true.  It's all incremental, isn't it, yeah.  And then turning on a video camera, incremental.  The problem is I've been incrementaling myself to death here.  It's like, can't take it anymore.



STEVE:  Yeah, I've been watching you on camera.  I think you really like this whole...



LEO:  I have fun.  I have fun.  



STEVE:  ...Leo studio routine.



LEO:  As long as people understand that sometimes I have to stand up and go somewhere and, you know.  But they seem to entertain themselves quite well, actually.



STEVE:  There was, oh, it was last Friday that you guys, I think you cancelled your recording with Paul.  And I thought, oh, I'll just see what's going on.  And, I mean, the chatroom was just going crazy all by themselves.  So they really don't need you.



LEO:  Yeah, Paul was on deadline for his book.  He couldn't record on our normal Thursday.  So he said we'll do this tomorrow, I've got to get my chapter out.  Yeah, they're perfectly happy in there.  In fact sometimes - a couple of times, just as an experiment, I've turned off the video but left the Stickam chatroom going.  And there's usually 900 people in there all night long.



STEVE:  Go figure.



LEO:  I don't understand it.



STEVE:  It's the power of your celebrity.



LEO:  No, it's not me.  No, and I think that's really an important point.  It's the community.  And I think that's what's really exciting about what's going on with the web in general is it's all about community now.  It's not about, you know, the old media it was about celebrity.  I think now it's about community.  I like that.



STEVE:  That's a very good point.



LEO:  Yeah, I really like that.  So we're going to talk today about a variety of things, as we always do on an even-numbered show.  You've put together it looks like 12 great questions from all over the world.



STEVE:  Submitted by our - these are issues and mostly questions, some little info tidbits submitted by our listeners.



LEO:  Yeah, I shouldn't just call them "questions."  It's a variety of stuff, yeah.



STEVE:  Yeah, yeah.  And I did want to mention, many people mentioned that apparently I broke the URL for the feedback form.  We've been saying GRC.com/feedback.  And my system appends the .htm to the end.  I added the technology so that, if a page were given without the .htm, the server would add that.  And something I did in the last couple months broke that.  And so it didn't limit our listeners.  They still managed to send 375 questions since I last pulled them two weeks ago.  But several of them did mention that they had to manually add the .htm.  So by the time anyone hears this - I haven't had a chance to get to it because I just read that this morning - it'll be fixed.  So whatever it was I did, I will fix it.



LEO:  It's a little scary that you don't know.



STEVE:  Well, I've been playing around, working on some very cool technology that we'll be talking about in the show before long.  And it involves classifying assets on the site for the purpose of analyzing browsers' behavior in handling cookies depending upon what type of asset it is.  And so something in there I broke.  And it's like, okay, fine, I'll go figure it out and fix it.



LEO:  Apache, which is the web server that I use and most UNIX types use, has a very nice module called "mod_rewrite" that handles this URL kind of massaging.  You're using IIS, Microsoft's server.  What does it do?  Do you have to do something special?



STEVE:  No, it does nothing.  I'm actually - all of this stuff I do, ShieldsUP!, the eCommerce system, the Perfect Paper Passwords, the Perfect Password Generator, all of that is my own code.



LEO:  Oh, you're not running - but you're running IIS as your server, though.



STEVE:  Basically yes.  I've got IIS, and they have an API called IISAPI - or actually there's no two I's, it's just ISAPI.  And it allows me to insert my own code in front of the web server and behind the web server.  So essentially I've completely encapsulated Microsoft's original web server in my own code, all in Assembly language, of course.  And so all the stuff that the site does, it does because I've added code for it.



LEO:  Right, right.  Well, that's interesting because it's so nice, I use the Apache mod_rewrite all the time.  You can do redirects with it.  But you could just take a URL that's incoming - for instance, a lot of URLs on things like WordPress and so forth are really ugly, you know, they have .php, and they have queries and so forth.  And you can just massage those automatically, on the fly, to something looking much, much nicer.  And same thing with incoming that stuff.  Anyway, enough of that.  Enough of that.  So are there any updates from last week, anything you want to...



STEVE:  Always.



LEO:  Always.



STEVE:  Got a whole grab bag of goodies.  Somebody in the Security Now! newsgroup that we have mentioned my comment about how when you disable the phishing filter on IE7, it disables the display of the EVCerts, the Extended Validation Certificates.  And it turns out that you can - there is a way to disable the phishing filter and still have EVCerts displayed, which many people may want because they might want the benefit of knowing what's going on with EVCerts while, for whatever reason, not wanting the phishing filter to be enabled.  In the advanced settings of IE there is an option down toward the end of the very long list, in the last section, called Check for Server Certificate Revocation.  And if you turn off the phishing filter, that's not checked.  You need to check it and then restart that instance of IE7.  And you get EVCert display back.  So anyone can get IE to show EVCert presence, even if they've got the phishing filter disabled, by just...



LEO:  Wait a minute.  Say that again because that was the most arcane thing I've ever heard of.  So you have to...



STEVE:  Who knows why, but that's what Microsoft has got it set up for.  So there's an option in their advanced security configuration called Check for Certificate Revocation.



LEO:  Okay, so you want to check for certificate revocation.



STEVE:  Yes.  And if you do, then you get EVCerts.



LEO:  So if you uncheck that, turn off phishing filter, then check it again, it'll come back on.



STEVE:  Yeah, or just turn off the phishing filter and then go there and...



LEO:  And recheck it.



STEVE:  Yes.



LEO:  Got it.



STEVE:  And enable the checking for server certificate revocation.



LEO:  So the phishing filter just disables a bunch of things, including that.  But you can reenable that one feature.



STEVE:  Yeah.  Actually I didn't verify whether the phishing filter changes the setting of that.  It may be that it's not normally turned on.  The phishing filter also enables EVCerts.  What I do know is that, with the phishing filter off, and you enable the checking for server certificate revocation, you've got EVCert display on IE7.



LEO:  Got it.  Got it.



STEVE:  Also I was talking with some bit of excitement about Service Pack 3 of XP last week.  And I have been bitten by it, and my tech support guy Greg has been bitten by it.  I actually had to remove it from this main, brand new, recently built system of mine because twice - and that's all it took - in the day after I installed Service Pack 3, my Start Menu died.  Which I have never had happen before.



LEO:  That's a weird thing, yeah.



STEVE:  I could press the Start button, and up comes the menu.  But it was completely dead.  That is, mousing over and clicking and things, nothing happened.  And in several cases, I mean, I put up with it briefly.  I could log out and log back in again, and it would bring it back to life.  But it's like, okay, this is ridiculous.  So I just backed out of Service Pack 3.  And that was last week, and it hasn't happened again.  So it does...



LEO:  From a security standpoint, is there any negative to doing that?  I mean, are you now going to be more vulnerable?



STEVE:  Well, it's not clear what's going on with Service Pack 3.  When you use Windows Update, you still do all the pre-Service Pack 3 updates.  And then it gives you a new version of the Windows Genuine Validation tool, and then that says oh, we recommend you install Service Pack 3.  So it's like, oh, good, you know.  And I have had people say that even that non-network install, where it says it's only going to be 66MB, actually downloads the whole thing.



LEO:  Oh, that's interesting.  So you still get a huge file download.



STEVE:  Yeah.  Anyway, so what I'm going to do is - and I wanted to bring this up to our listeners because they may want to consider this, too.  When this happened I did a little bit of Googling, and lots of people are having problems with Service Pack 3.  Just weird sorts of things like I ran across one where somebody's Control Panel applet doesn't run after installing Service Pack 3.  Took it out, and it's back again.  So it's looking like Microsoft is having some problems with this service pack.  And my feeling is let's give it a month, and they may be patching the service pack.



LEO:  What's discouraging is this is a new machine that you're having trouble with.  I mean, it's not like you have a lot of crap on it; right?



STEVE:  Right.  It's brand new.  No age on it at all.  And again, I took out Service Pack 3, and now it's been behaving itself just fine.



LEO:  Well, now we know what it is.



STEVE:  Yup.  And speaking of the PayPal EV certificate, PayPal made a mistake which put them actually in a spotlight they didn't want, which was they had a cross-site scripting error on their EV SSL-enhanced...



LEO:  Oh, no.



STEVE:  ...page.  And so I thought it was sort of an interesting little gotcha because they put out a press release a couple weeks ago saying that non-EV-capable browsers were soon not going to be welcome at PayPal.  And that generated a bunch of furor.



LEO:  Oh, yeah.



STEVE:  So they sort of backpedaled from that a little bit, said well, no no no, we would just prefer that you used EV-enhanced browsers because they're working to promote this whole notion.  Well, here they are with this green bar, this green URL, and this is on pages where there's a demonstrated cross-site scripting vulnerability.  And essentially what this means is, by leveraging that, you can take somebody essentially to a different server that still shows the green PayPal URL, thanks to this cross-site scripting vulnerability.



LEO:  Wow.  Wow.



STEVE:  So the point is that it's important to understand that the fact that you've got the green bar, the green URL, the EV validation, says nothing about the way the site works.  It just says, oh, we paid more for our certificate, and we were checked out more, and the certificate issuer...



LEO:  Checked out more in terms of who you are, not in terms of your security.



STEVE:  Exactly.  Exactly.  So it's a bit of a black eye.



LEO:  Yeah, no kidding.  Especially since they were going to require...



STEVE:  Exactly.  And then the other little interesting bit of news is there is now an unpatched vulnerability in Apple's current version of iCal, their calendaring program.  Apple was informed of this by a security research group back in January.  And they've been going back and forth and back and forth.  And the security group has been getting frustrated with Apple not fixing this thing.  One of them is a remote execution vulnerability such that if you were to open an iCal file by clicking on a link that you received in email, or if somehow this iCal file is displayed, there's a buffer overrun that allows a code exploit to be executed.



And so finally last week the security company said, okay, we're tired of waiting for you.  Apple did say that it would be patched by the end of April and then didn't patch it.  So this group went public with the exploits.  Which has not made Apple happy.  But, I mean, I can understand their position.  It's like, okay, the longer this known hole stays open, the more opportunity there is for exploitation.  I mean, this is what we've been putting up with over on the Windows side, of course, for quite a while.



LEO:  I remember talking to w00w00, one of the security firms that does this.  And they knew about a vulnerability in Windows that had been going on for a year.  I think it's not unusual for these to go on for quite some time.



STEVE:  That's true.  And in this case Apple was saying, look, we're going to get this patched, it'll be patched by the end of April.  And that was after many, many prior excuses and delays and broken promises.  So finally these guys just got fed up and said, okay, good luck.  The only way to put pressure on you to really get this fixed is by going public.  We tried to do it the right way, the responsible disclosure way.  And we're tired of waiting.



LEO:  Right.  I'm sure there's a reason why Apple didn't put it out.  Probably something wrong with the patch, right, or the patch caused more problems.  This does put a lot of pressure on you to do something now because the hackers know about it.



STEVE:  Yup, exactly.  Exactly.  So I had a fun SpinRite story, another failure actually, since sort of we're on a roll doing SpinRite failures.  A listener by the name of Alex Walters wrote, and he said, "SpinRite failed me, but it's NVIDIA's fault."  And I thought, huh, what?  And so he says, "Well, the subject of the email is somewhat deceptive.  It's likely not the video chipset's fault.  But I digress.  A little while back, S.M.A.R.T." - the Self-Monitoring and Analysis Reporting Technology that are built into the drives - "started to give me the dreaded "Backup your data now" error."  Now, he says, "I'm not a dumb person, but I hadn't backed up my data on that drive in some seven and a half years.  I was quite interested in backing up that data."



LEO:  That's a long time.



STEVE:  It's a long time.  So he says, "I was quite interested in backing up that data.  So I booted up and tried to copy the data that I wanted off onto a fresh 500GB external drive that I have had nearly as long as it's been since I last backed up.  It all went fine and good till I got to my brother's basic combat training graduation photos, where Windows could not read the data.  The horror," he says.  "So I shut down and booted to my SpinRite floppy."  He says, parens, "(I have a floppy drive, how novel)."  And then he says, "I let it run and went to take a shower.  No, not with the computer."  He says, "When I came back, the computer was dead.  The video card ate my machine."  So then he says, "Cut to one month later.  I have rebuilt my machine totally.  I hooked up the old drive and ran SpinRite, and it clicked along until it had recovered everything.  Well, everything that I wanted, at least.  It's good to know that when everything in my machine wants to die, SpinRite can breathe enough life into my hard drive to safely recover.  Thanks, Steve."  Signed, Alex.



LEO:  Happy news.



STEVE:  So not quite a "SpinRite failed me," but that's what his subject line said.



LEO:  All right.  Well, let's get into the meat of the matter.  I have some very good questions for you from our listeners.  Are you ready to answer a few?



STEVE:  You bet.



LEO:  All right.  We'll start with number one.  Listener "Steve," in quotes, in Florida, notes we're not out of luck.  He says:  Steve, during last week's Security Now! episode, talking about XP's new Service Pack 3, you said, "But I don't know what happens if you push past that and effectively refuse to download Service Pack 3," which in fact we now know that Steve won't do.  Last Patch Tuesday I hooked up to Windows Update.  I was of course presented with the Service Pack 3 download option.  However, there was some small print down below which said something to the effect that even if you choose not to install Service Pack 3 now, you may still need some updates.  And there was a little button over on the right to click if you don't want to install SP3.  You click that, you get the usual menu of patches and updates for Service Pack 2 XP as usual.  Which I did.  And everyone else can, and probably should.  So in other words, you can get these critical updates even if you don't install Service Pack 3.



STEVE:  Yeah.  I don't know what Microsoft's going to do about this.



LEO:  Long-term it may not work; right?



STEVE:  Service Pack 2 gave you the option of not doing a backup.  And I am really glad that Service Pack 3 forces you basically to keep all the uninstall files around.  Of course it's a huge blob on your hard drive.  But I needed that in order to back out of Service Pack 3.  So now I'm feeling in retrospect like I haven't taken my own advice by waiting a while for the service packs, any new service pack to settle down before I just jump right into it because Service Pack 3 is causing people problems, and not just people with AMD processors.  I know I've got regular genuine Intel, a quad core chip in there.  And my Start Menu dies.  I need my Start Menu.



LEO:  You're referring to that well-known problem with AMD processors, which is even more of a showstopper.



STEVE:  Right.



LEO:  Now, what's interesting is, as far as I can tell, Vista Service Pack 1 has not been a problem for most users.  Don't know why not.  But...



STEVE:  Yeah, Vista did something wacky on a machine that I have, too.  I was using it to do some experiments last week and updated two - there were two updates that Microsoft Update installed.  Now it won't shut down.  It gives me the little spinning wheel and then goes to blue screen.  It's like, oh, that's nice.  It's like, fine.  Okay.



LEO:  Thanks a lot.  Thanks a lot, Microsoft.  Jawny G. in BC, Canada, mentions the Debian/Ubuntu Linux OpenSSL mistake.  Which I'm not familiar with, but I'm sure I'm going to learn about right now.  Steve, I realize this is a simple mistake that has more or less been corrected with a patch now.  But since you were quoted in the article, I was curious as to what you think about all this.  I look forward to your thoughts on the whole problem and possible problems with open source in the future.  What happened?



STEVE:  Oh, Leo.  First of all, although I chose this one note from Jawny G., many of our listeners said, hey, why aren't you talking about this horrible mistake in OpenSSL the Debian guys made?  And many people wrote.  So I thought, well, yeah, I mean, okay...



LEO:  Let's talk about it, yeah.



STEVE:  Now is the time.  We're in our Q&A episode.  Okay, so get this.  Back in September of 2006, so, what, year and a half ago, the Debian guys ran a program over their source code called Valgrind and another one called Purify.  These are automated tools designed to check the security, sort of like an advanced form of Lint, which Lint is a tool that's been around forever that sort of, like, helps people with their C programming find things like uninitialized variables and sort of questionable syntax in code.  So this thing purports to be, this Valgrind and Purify, sort of a higher level version of that.



Well, it finds a block of memory which has never been initialized.  It's just this uninitialized block of memory.  It looks around through the source, can't find anywhere that any code is initializing it to zeroes, which is typical.  And so it flags this as something that needs to be fixed.  So the programmers didn't really understand the code, so they made some changes which caused some errors.  And then they ended up commenting out a critical aspect of the random number generator in the OpenSSL package in Debian in September of 2006.  And this affects the offshoots from Debian like Ubuntu.



LEO:  Oh, dear.



STEVE:  So, okay, get this.  The OpenSSL generator, the random number generator is, as you would expect, a lot of thought's been given to it.  That block of memory was uninitialized on purpose to be just some more random stuff that probably - now, see, you can't really count on it being random every time because, as we will remember from when we were talking about the freezing your RAM stuff, in general memory that you don't initialize tends to come up in the same state from one time to another.  But that's probably going to be unique per machine.  So it's just sort of - and believe me, that's not the only thing they were doing.  They do things like microscopic timing analysis of the hard drive to get speed variations, the mouse movements, you know, all kinds of stuff is all fed into the pseudorandom number generator, which is the heart of OpenSSL, used to generate, for example, all of the security certificates that it produces.  So unfortunately what these guys did is they commented, essentially, all of that out, so that the only thing left was taking the process ID.  So since September of '06 Debian and Ubuntu and any other derivatives, there are a couple others, have had a seriously broken pseudorandom number generator in the OpenSSL package such that there were only - now, okay.  Process IDs are 15 bits in Linux.  So that's 32768.  There were only 32K possible keys.  And they've been brute-forced; they've been reverse engineered.  And tools are beginning to surface.  So...



LEO:  It's using the process ID as a seed, or is it using it as a key?



STEVE:  Well, it uses it as the seed for the random number generator.



LEO:  Oh, but if you know the seed, you can tell what the number that it's going to generate will be.



STEVE:  Well, and the developer's intention, the original coder's intention, was to use all of this stuff as the seed.



LEO:  A variety of things, yeah.



STEVE:  All that other stuff, including this little patch of deliberately uninitialized RAM, just to throw some more entropy into the seed generator.  So what happened was, as a consequence of this so-called let's find security bugs, this automated software that flagged the problem, the guys didn't really understand what the code was...



LEO:  That was the consequence, by the way, somebody modifying code he didn't understand.



STEVE:  Yes.  And commented out everything except using the process ID, which means that there's only 32K possible seeds for the pseudorandom number generator.



LEO:  Whoops.



STEVE:  So it turns out that the bottom line is, the takeaway is, any certificates which you are depending upon, for example SSH certs, anyone who made a certificate pair using Debian and Ubuntu since September '06 when this happened, has a bogus, essentially a bogus certificate.  And there are already hacks that are out there.  There is a test that's available to see whether you've got one of the bad certificates.  So I just wanted to, for those listeners who this affects, you probably know who you are, I mean, it's easy to find information about this.  This is only about two weeks old.  So of course it has been immediately fixed.  So you're going to want to update your OpenSSL, recompile it or get the new package from Debian.  And if you've generated any certificates in the last couple years for any purpose, you need to consider them as really exploitable.



LEO:  Who discovered this, and how did they discover it?



STEVE:  I don't remember who - it was a security researcher.  Luciano Bello is the guy who found it.  And our good old friend H.D. Moore at Metasploit has got an extensive page on it and already writing toys to exploit this problem.



LEO:  Wow.  Wow.  Now, Jawny G. says what are the possible problems with open source in the future.  I think what he's saying is with open source you've got people potentially modifying code that they don't understand.  I mean, I think there's a breakdown in the process here because you shouldn't be able to modify the pseudo number random generators, you know, it's a library, I would guess.  You shouldn't be able to modify that.



STEVE:  Well, yeah.  They clearly thought they were doing the right thing by running this security tool over their code.  And what they did, of course, is they forked the software so that now they're off on their own, and the OpenSSL groups, I mean, there have been a number of other things that have been fixed in OpenSSL since then.



LEO:  So the proper process would be to say, hey, we ran this on OpenSSL, and go to the OpenSSL group and say, hey, what's the deal?



STEVE:  Right.



LEO:  Instead of forking the code - there was the mistake - and saying we're going to fix it.



STEVE:  Yeah, I did read somewhere there were some comments by the OpenSSL people.  And they said, well, after we got through literally rolling around on the floor laughing at what had been done to our deliberately carefully created super high-quality pseudorandom number generator code, we would have explained that commenting that line out was a bad thing to do.



LEO:  Yeah.  So, okay, we've all learned our lesson here.  I think in a way this could be, I guess, ascribed to a structural problem with open source.  But I think in another way it's very clear that, if the proper procedures are followed, it isn't a problem.  And the fact that the security researcher found it has something to do with the fact that it's open source.  Had Ubuntu been a closed source project or Debian been a closed source project, this might happen and you'd never know because you wouldn't be able to see what's going on.



STEVE:  Yeah.



LEO:  Interesting.  Wow, really interesting.  Dave in Grand Rapids, Michigan, he's worried about losing his YubiKey.  You know, it's funny, I was just looking for my YubiKey, and I've misplaced it.  He says:  Steve, maybe I've misunderstood your description of the YubiKey, but it sounds like the only item needed for authentication is the YubiKey, and not even a username or password.  So if a YubiKey is lost and found by someone else at your YubiKey-using corporation, the only thing they'd have to do to logon as you would be to plug it in and press the button.  This seems like a huge flaw.  Or does the user still need to type a username and then in the password field press the button, thus entering the one-time password?



STEVE:  There's been a lot of confusion that I guess I'm responsible for because I got so carried...



LEO:  I don't think so.  I remember you saying it right.



STEVE:  Well, I got so carried away with how cool this was, I - the confusion is that many people have said, oh, okay, I want one, now what do I do?  That is, it's not...



LEO:  That is your fault, by the way.



STEVE:  Yeah.  It's not an end-user tool in the same way, for example, that the PayPal football is.  Or I should say that the reason the PayPal football is an end-user tool is it's offered by PayPal who supports it.  And so immediately upon getting it you've got something to do with it.  The YubiKey is a cool technology.  So it's sort of like it's more like a wholesale rather than a retail technology.  So...



LEO:  Now, I think you implied, though, that I could use it with Yubico as an OpenID key.



STEVE:  You absolutely can.  So they've got an OpenID server.  There's also an interesting site called MashedLife.com that is YubiKey enabled, and they're sort of a third-party password and website log-on provider.  They've got sort of a clever technology that works with a YubiKey.  So the point I wanted to make to Dave when he says, okay, you know, if I only need the YubiKey, what if somebody else gets it, was like, yes.  It's not meant to be anything other than one additional very cool factor in a multifactor system.



LEO:  Yeah, and that you were clear about, I think.



STEVE:  Yeah.  So absolutely, someone could misdesign a system.  And just because you're using a YubiKey doesn't mean that the system is going to be secure because everything else has to be secure.  I mean, again, you absolutely want a something you know to be part of something you have so that, you know, there is a passphrase that says, okay, I am me, and you plug the key in, and it's like, and look what I have.  So again it's - I believe this thing is going to take off, and there will be people who are using the YubiKey, I mean, I know from Stina, for example, that I think she told us during the podcast, that she's received queries from universities that want to give one of these to every single student and faculty member.  And so it would be something that they use to log-on to terminals and things around campus.  And so there these kids are going to get these and go, wow, that's interesting, never seen one of these before, not knowing how much more it is because essentially the IT department will provide all the backend infrastructure for it.



LEO:  So I'm holding my YubiKey right now, for those of you watching.



STEVE:  I'm holding mine, too.



LEO:  So this is something that Stina sent to us.  But so can I use this with Yubico as an OpenID provider, and it would do everything, I mean, in other words, can they become a provider for me and so I can use it standalone?  Or do I need to kind of do...



STEVE:  No, absolutely, they have an OpenID server.  And you could use them as your OpenID authenticator.



LEO:  And what would that look like?  I would still have to enter my login and my password; right?



STEVE:  Yes.  At any OpenID site you would be giving them your username and password.  Okay.  You'd give them whatever it is that site wants because...



LEO:  Well, I'll give you an example.  When I log into a site that uses OpenID, I click the OpenID link.  They say, okay, what's your OpenID provider?  You give them a web page that is an OpenID provider.  So you'd give them Yubico.com.  Then you're pulled to Yubico, where you give whatever Yubico requires.  In this case I presume it would be a username, password, and the YubiKey.



STEVE:  Yes.  I don't know.  I have not looked at that.



LEO:  Right, right.



STEVE:  But I know that they have an OpenID facility that is there and free and will always be free.  So somebody with a YubiKey who was getting into OpenID could use Yubico's OpenID service.



LEO:  Great, great.  And presumably Yubico's implementing it as you would recommend, which is multifactor authentication - name, password, and then the YubiKey.



STEVE:  Maybe.  But they wouldn't have to.  I mean, all they're really saying is, I mean, are they saying this is you, or are they saying you have a YubiKey?  Because the site that you're logging into could also require username and password...



LEO:  Well, but that's the idea of OpenID is it bypasses that.



STEVE:  Okay.



LEO:  So the whole point of OpenID, we use it - we can use it on TWiT.tv, for instance.  You go to TWiT.tv and either provide the credentials we have given you, or say no no no, I want to use my OpenID credentials, at which point you're sent to the OpenID provider, who verifies your identity.



STEVE:  You're right, your entire identity, and then makes the assertion that...



LEO:  I trust them.



STEVE:  ...this really is you.



LEO:  Right.  And then you get sent back to TWiT.tv, which says, okay, I know you're you.  Do you want to set up an account now using this identity?  In other words, should this identity be trusted.  And so that's the process for OpenID.  So, yeah, they would need to do some identity validation.



STEVE:  Right.



LEO:  Kyle Hasegawa in Tokyo, Japan has a tip and a link for me.  Steve, he says, this one's actually for Leo.  Leo mentioned he was looking for a tool to test his server against attacks.  I have more information on our hack attack, by the way.  Fascinating story.  I'll tell you about that in a second.  I use these two Firefox add-ons for security testing, found them to be very good.  They're from http://www.securitycompass.com/exploitme.shtml.  The first is XSS-me, which brutally yet safely slams your site with a torrent of XSS attacks.  I don't even know what those are.



STEVE:  Cross-site scripting.



LEO:  Oh, cross-site scripting, okay.  The second is SQL Inject-Me, which does the same thing except with SQL injections.  After the test the tools provide in-depth reports about your site's security, at least for those two vulnerabilities.  Cool, huh?  I've run these against my Drupal 6.2 site as well as my own home brew websites, and I'm glad to say they all passed.  Probably a good idea to limit testing to your own sites to avoid a visit from your local FBI agents.



STEVE:  Actually these are - we've talked about cross-site scripting and about SQL injection attacks.  These are two tests that do a whole ton of, for example, cross-site scripting script exploits.  So, I mean, it really hammers your page, the pages that you give it, with all kinds of attempts to perform SQL injection and cross-site scripting attacks.



LEO:  Well, in my case it was neither.



STEVE:  Okay.



LEO:  So I found out what happened.  Are you curious?  You want to know the story?



STEVE:  Yeah.



LEO:  It took me a little while to figure out where the vulnerability was.  And it was me.  I was the vulnerability.  I was the stupid person.  So what happened, I guess the hacker sent me another note.  By the way, he said, I'm not Brazilian.  I don't speak English, but I'm not Brazilian.  So we don't know where he's from.  But he posted on my blog, he posted a comment saying you should harden your site, and if you want some help send me an email.  And later sent me a note saying, well, this is how I got in.  I had posted - you know you have a site, kind of a private site on Leoville.com, Steve, where we put Security Now! so you can download it.



STEVE:  Sure.



LEO:  It's not hidden by anything by obscurity.  It's almost like an open directory except there's some PHP code managing it.  So you can go there, and you can see if the new files are there and download them.  I have several of those.  They're not websites, and they're not FTP exactly, they're just kind of file storage places for various people.  I put my commercials up there for the radio shows and stuff.  On one, and only one of them, and I enabled a feature that allows people to upload files.  Oh, dumb.



STEVE:  Oooooh, yeah.



LEO:  And it turns out that the folder it gets uploaded to, the incoming folder, I either didn't set permissions on or set them incorrectly to allow a scripting error to be executed.  So all the hacker had to do was he uploaded a script, which I found.  In fact, I have, and at some point I'd like to go through it, I want to parse through it on camera, and maybe you can be on when we do that.  And it's PHP code, but go through it and show exactly what the script does.  It's very interesting.  It's not a very well written script, by the way.  But it's an interesting script.



STEVE:  It did the job, I guess.



LEO:  It did the job.  Because what it does is it looks for other vulnerabilities on the server, looks for open directories, files it can download, particularly looking for configuration files.  So apparently what it found was a directory with a configuration file it could download that had an SQL, my SQL password in it.  And that's how he got in.  And there were only two of the sites on that server, there are about five sites on that server, but only two of them were unprotected enough that he could zap them.  The rest of them were hardened.  So I've since found...



STEVE:  I think that's a pretty good hack, Leo.



LEO:  Well, it would - yes, it's a great hack.  And I think probably - not great.  But I think what the guy did was he's going around, and probably has an automated tool, looking for open directories that he can upload to and execute.  And he found one.  Foolish of me to leave that there.  I don't know what I was thinking.  I certainly know that's a vulnerability.  And but it did give me - and it's going to be fun.  We'll go through this little C9 script that he wrote - or he got, probably, from elsewhere - and show how it works.  So it'll be a good kind of extra security episode we'll do on TWiT Live at some point.



STEVE:  Yeah, cool.



LEO:  Anyway, these tests would not have found that because it was too stupid of a vulnerability for these tests.  John in Moncton, New Brunswick wants to know about the effectiveness of MAC address filtering.  Not Macintosh, but MAC address filtering.  My wireless network has the ability to restrict address by MAC address.  How secure is this if I'm behind a NAT router?  It would seem to me that as long as a MAC can't be hacked or faked, this is pretty secure.  But could it really be that easy?



STEVE:  We've talked about this before.  I know that some of our listeners are kind of rolling their eyes thinking, oh, Steve, why are we going to go over this again?  The reason is it keeps coming up.  And major tech support people keep telling...



LEO:  Keep recommending it.



STEVE:  Exactly, keep recommending it as if, oh, just use MAC address filtering.  Oh, it'll make you completely secure.  It absolutely won't.  So let me - I won't take too much time, but I want to explain, to John and any other listeners who might be wondering if that solves the problem, why it doesn't.  The reason is that the MAC address is in the clear, even if you've got encryption working in your network.  The MAC address has to be in the clear because it's sort of like the outer address for the packets for any endpoints on an Ethernet.  Ethernet by definition uses 48-bit MAC addresses.  And that's how the packet gets to where it's going on the network.



LEO:  You should mention that every network device has a unique 48-bit address called a MAC address.



STEVE:  Right.  And it's interesting, the way they're guaranteed to be unique is that that 48 bits is divided into two pieces, 24 bits each.  One is a manufacturer serial number, and then the other is a manufacturer's serial number, meaning that each manufacturer gets its own unique 24-bit ID, and then they increment the other 24 bits so that together those are guaranteed to be unique 48 bits.



LEO:  Unless they make more than 14 million cards.  Or whatever that number is, I don't know.



STEVE:  And you can always get another manufacturer ID, so that's not a problem.  And in the worst case, if you had a LAN that had identical MAC addresses, you would immediately get various sorts of alerts from your equipment saying that there's a MAC adapter collision.  An adapter would say, wait a minute, there's somebody else on this network with the same MAC address as I, in the same way that, I mean, those of us who configure IPs manually have probably had IP collisions before, where you get a dialogue saying wait a minute, some other machine on the LAN has the same IP as I do.  So it's just like, whoops, well, we can't use that card, that LAN card on this network because by some bizarre coincidence there's been a collision.  And that can happen because users in more recent adapters are able to change the MAC address.  They're able to set it to be whatever they want to.  So it's not always hardwired into...



LEO:  That's the key.  He realizes, he says, it would seem to me that as long as the MAC can't be hacked or faked, this is pretty secure.  True, but MACs can be spoofed.



STEVE:  Well, yeah, they can be spoofed that way.  But the point is, in a wireless network, if you just turn on a sniffer, you're going to see all the MAC addresses of all the machines on the network.  And so...



LEO:  And then you can set your card to be one of those.



STEVE:  Exactly.  It's trivial to spoof.  So where MAC filtering is good is if you want to prevent inadvertent use of your network.  So, for example, say that you, for whatever reason, you cannot secure your network.  You can't use WEP or you can't use WPA.  But no one really wants to use WEP because it can now be cracked in about a minute.  So if for some reason you can't use WPA because, for example, you've got friends coming over all the time, or you've got some equipment that doesn't yet support WPA, the good WiFi encryption.  It's like, okay, well, for some reason you have to have your network not encrypted.  Well, the problem is that anybody within range will see your network listed and just connect to it.  So the one thing - in fact, many people connect inadvertently.  They just turn their computer on, it finds the strongest signal.  Well, if you've got...



LEO:  That looks good, yeah, I'll take that one.



STEVE:  If you've got a good, strong signal, people will be using your network without your knowledge or permission.  So MAC address filtering is useful if you wanted to prevent that kind of sort of like soft - you wanted to put up a soft barrier to inadvertent use of your network.  But anybody who knew what they were doing could easily use your network despite the fact that you're using MAC address filtering.  So it's just not secure.  WPA is the only solution, using a strong password.



LEO:  And to save us another email, same thing with SSID hiding.  Doesn't do a thing.



STEVE:  Right.



LEO:  Because like the MAC address, the SSID is sent all the time in the clear.



STEVE:  Right.



LEO:  You've got to encrypt.  You've got to.  Tom Terrific worries that if he goes to someone's PC, something might come to his.  He says:  Hi, Steve.  I'm having more and more friends wanting me to work on their computer, so I thought it would be nice to be able to look at their computer remotely via GoToMyPC or something similar, so I wouldn't have to be driving all over the place or trying to diagnose over the phone.  My question is, if their computer is filled with malware, viruses, et cetera, is there any way I could be infected by connecting to them remotely?  Thanks, keep up the good work.



STEVE:  I thought that was a really interesting and good question.



LEO:  I had never thought of that.



STEVE:  Now, okay.  In a perfect world, that would be completely safe because...



LEO:  You're not really running anything on your system.  It's a window into their system; right?



STEVE:  Exactly.  Essentially you're seeing their video, and you are taking over their mouse and keyboard.  So it's purely a remote IO sort of deal.  But we know it's not a perfect world.  In fact, it's substantially less than perfect.



LEO:  Oh, no.  Oh, no.  Tell me.  Tell me.



STEVE:  Seeming less perfect every day.



LEO:  Oh, no.



STEVE:  So if, for example, there were a vulnerability in whatever remote communications software you were using, and malware knew about that, it would be very possible for the malware to detect that you had connected using VNC, GoToMyPC, Remote Desktop, whatever application, and exploit a known problem in order to cause a buffer overrun at your end of the connection.



LEO:  So anytime you're having a conversation with another computer, there's always that potential no matter what protocols you're using.



STEVE:  Yes.  So what I would do if I were a person who was going to be sort of habitually connecting to probably infected remote machines, this is definitely somewhere you'd want to do that in a VM at your end.



LEO:  Oh, good idea.



STEVE:  So you'd fire up a virtual machine session.  You'd use that virtual session to connect with their machine, and that would probably, I mean, again, I'm maybe being overly cautious.  In general it's not a problem.  But again, it's not a problem until it becomes a problem.



LEO:  Well, there have been problems.  I remember with RPC, the Windows remote protocol security, man-in-the-middle attacks, things like that.  So it's certainly something to be aware of.  It's not like these things are invulnerable.



STEVE:  Correct.  And so, again, it is something to be aware of.  And I would say putting yourself in a virtual machine so that only the virtual machine might have a problem if something crawled back up the connection into your machine, that's really probably safe enough.



LEO:  When I brought Auntie Dawn's computer in here last week - and she had complained about spyware.  I said bring it up, we'll see if we can fix it.  Before I connected it to my network, I made sure it was clean.  Even though we run firewalls locally, you know, on all the machines, Windows firewall and the Mac firewall, I wasn't going to connect it to my LAN.



STEVE:  I'll tell you, Leo, I don't let any foreign machine ever touch my network.  Just don't.



LEO:  No.  Well, I did eventually because I cleaned it up, basically reinstalled Windows, completely scanned it.  Once I was fairly - again, there's no perfect answer.  But once I was pretty sure I was clean I did put it on there just so I could update it.



STEVE:  I have a cable modem here that I have nothing else connected to.



LEO:  That's a good idea.



STEVE:  And when anyone is over who wants to, like, check in, I mean, even my buddy Mark Thompson, AnalogX, he brought a laptop with him.  And it's like, sorry.  And he completely understood.



LEO:  Oh, I'm sure he did.



STEVE:  I said I'm happy to let you use this cable modem that nothing else is connected to.  But my own internal network is just sacrosanct.



LEO:  Let me get this straight.  You have a cable modem just for your guests?



STEVE:  Yeah.



LEO:  That's taking it seriously.  But we have more connections in here, and I could certainly dedicate one.  I mean, there's one dedicated to Skype, it's nothing else.  Of course, everything's on the LAN, though, because even the Skype machine has two Ethernet connections, one for the...



STEVE:  There you go, there's a bridge.



LEO:  It has to be because that's how we can see the screen on the TriCaster.  So, yeah, we're always at risk.  I'll have to make a - and people are going to come in here and use our WiFi.  So that's where - would it work, then, to have that triangular WiFi, you know, the three WiFi connection thing?



STEVE:  It's a three-router connection, yes.  That's absolute security.



LEO:  Okay.  So maybe I'll have to end up doing that.  Oscar Aguirre in Gardena, California wonders about URL file extensions:  Hi, Steve.  Thanks for the constant updates you provide for the security conscious.  I eagerly listen every week - hi, Oscar, glad to have you - knowing I'll learn something new Steve and Leo will help me understand.  Question:  I'm currently house-hunting in Glendale, California.  My realtor provided me with a printout with home listings.  The printout had the following page at the bottom of the path - the following path at the bottom of the page.  This is pretty common.  When you print a web page, you'll get the URL of the page, and it ends...



STEVE:  Sort of down in the footer.



LEO:  Yeah, in the footer.  And it ends with mgrqispi.dll.  I'd never seen a DLL file exposed to the user on a printout.  I Googled that DLL file, realized that numerous hits were listing the same file and a scripts path.  Should I be concerned about the home listing web server displaying paths to DLL files?  Maybe I should inform my realtor or work with another realty group whose web server doesn't show their DLLs.  Thanks again for the inspiration you provide for us security software folks.



STEVE:  I thought this was a great question.  And it bears on - really for all of our listeners because we're seeing a proliferation of different file extensions on pages.  Interestingly enough, if you use ShieldsUP!, you see "ne.dll."  "NE" stands for Net Engine, and that's the thing I was talking about earlier in this show.  It is the container for all of my Assembly language code.  The front-end filter and the back-end extensions to the server is a DLL.  We're seeing PHP.  Many people have seen, for example, PL for Perl.  The original was CGI.  So you'd see something, blah blah blah, .cgi.  So those have all been file extensions of either executable or interpreted code.  So when you see .htm, html, shtml you saw before...



LEO:  You may see .exe even, sometimes.



STEVE:  And sometimes you'll see an EXE.  So if you see HTM or HTML, then those are actual text files.  And for example, ASP now, Active Server Pages is one of Microsoft's technologies.  So you can either have scripts which are interpreted by some executable code, or you can actually have the executable program itself, which is typically what you had in the original .cgi type of original web extensions.  Anyway, the point is that many of these different file extensions are going to be seen in the future, more even than we see now.  But there's nothing about a .dll or an EXE should put anyone off.  It's just the way these people have implemented their Web 2.0 functionality.



LEO:  Although, and this gets back to our conversation a little earlier, it's probably a good practice from the point of view of the web guy to use mod_rewrite or some sort of URL modification technology to hide that information.  I mean, I don't think it's a great - it's not, you know, it's again security through obscurity.  But it's not a bad idea to say, you know, not let them know what's running in the background there.  If there is a flaw, for instance, in that DLL, they'd know how to attack it.



STEVE:  That's a very good point.  For example, Oscar says he Googled that filename and found lots of instances where it was being used.  So he was able to use Google to find all of the sites using that file.  If a problem were found in that file - and unfortunately this is how search engines are being used now, in order to find other sites that can be exploited in the same fashion.  So you're right.



LEO:  Yeah.  And in most servers that's a fairly easy thing to do, to hide those URLs.



STEVE:  Well, and for example in mine, when you go GRC.com/passwords...



LEO:  You don't see anything.



STEVE:  Exactly, because it is aliased to an ne.dll URL that invokes the code to display the Perfect Passwords page, but users don't see it.



LEO:  It's also just cleaner.  The guy who invented - Tim Berners-Lee, the guy who invented the World Wide Web, said he'd never intended for URLs to be visible by the end users.  You know, those are always machine readable.  And he just never thought that people would actually have to type in http://.  He just didn't expect that.  It wasn't designed for humans.



Welles B. Goodrich - love that name, Welles B. Goodrich - in Santa Cruz, California, he wants Stealth with his NAT:  Hi, Steve.  Recently I purchased an AirPort Extreme 802.11 WiFi base station from Apple.  After installation and configuration where I chose to enable the NAT firewall, I tested the security using ShieldsUP!  To my dismay, the All Service Ports test indicated that there were ports closed but not stealth.  No possible configuration could change that result.  I've owned several routers with NAT firewalls built in.  My computers, one PC and three Macs, a tiny LAN, have always tested stealth in the past.  Do you want to explain what "stealth" and "closed" is, real quickly, or should I go on?



STEVE:  Let's finish first, then I'll go back.



LEO:  I'm not particularly technically astute, but having my LAN hidden from the larger Internet universe always provided me with a sense of security.  As I couldn't get a Stealth status using our grid scan, I stopped using the AirPort Extreme in favor of a D-Link Broadband Gigabit Gaming Router and an AirPort Express for my WiFi needs, including printing.  So he basically has two routers.  This arrangement has once more restored my stealth mode.



The question is, if the Apple AirPort Extreme truly includes a NAT firewall, why did the ports only read Closed?  Was I overly paranoid to mistrust the AirPort Extreme's insecurity based on the results of the ShieldsUP! test?



Thank you for your work with Leo creating Security Now!.  Since my discovery of the program about eight months ago I haven't missed an episode, even though I'm primarily a Mac user, and some of your subjects are sufficiently arcane that they may as well be spoken in Klingon.  In spite of those limitations, I gain a great deal by listening.  Oh, one more thing:  SpinRite for the Mac, please.



STEVE:  Okay.  So this is actually a little controversial.  That is to say, there isn't universal agreement, especially among the old bearded UNIX guru folk, that stealth has any value.  And you'll see this in postings, I mean, when I'm roaming around the 'Net looking at DSL reports or something, somebody will say, hey, I wasn't all stealth at GRC.  And some curmudgeon, right, will say, ah, that's a crock, you don't, you know...



LEO:  You created this notion, though, of open, closed, and stealth; right?



STEVE:  I coined the term "stealth" as far as I know.  I don't know that there was any real concept of it before.  So the fact is, anything that is stealth is technically breaking the rules.  Any TCP/IP stack by definition should, for example, respond to a ping because that's what ping is for.  It's for Internet engineers who need to ping things to verify that packets are able to get there and get back.  So it's really useful to be able to ping.



LEO:  Again, let's explain.  A port is a connection between the outside world and your computer.  You could think of it as a socket.  You could think of it as a handshake.  It's a highway, it's a path between your computer and the outside world.  There are many ports, 65,000 and some ports that you can use.  If a port has a service at the other end of it, let's say I have a web server running, and you say hello to that port, it'll say hello back, what would you like today?  It'll say yeah.  If there's nothing running on it, you have kind of two choices.  That's open, by the way.  If there's nothing running on it, it could be closed.  It could just say, hey, I'm here, but I don't do anything at that port.  Or it could say nothing.  That's stealth, right, it just doesn't respond at all.



STEVE:  Exactly.  The idea for TCP port, which is really the only one that will necessarily respond when you attempt to make a TCP connection, which is what, like, web and email and many of the most common services used, if you attempt to connect to a port where there is no service listening for connections, again by definition, by RFC formal regulations, that you should get a reset back saying this port is not open.  I mean, you should be actively told that you have found a machine at this IP address, but it does not have that TCP port open.  And similarly, if you ping using a protocol called ICMP, the ping you should get back should say, oh, there is a machine, or there isn't.  So what stealthing is, is a breaking of the rules.  It is a deliberate breaking, saying if somebody tries to connect to a closed port, we're going to just drop the packet.  We're not going to affirmatively respond that, hi, we're here, but that door is closed.  We're just going to - we're going to say nothing, as if the packet just went off into the, you know, yonder.



LEO:  Why would I want to do that?



STEVE:  Well, because I mentioned before that it's very useful for Internet engineers who are wearing white hats.  Unfortunately, it's also very useful for hackers who are wearing black hats.



LEO:  They're looking for machines.



STEVE:  Exactly.  It confirms that there is a machine available at that location.



LEO:  Now, so that's important.  Just because there's an IP address doesn't mean there's something at that IP address.



STEVE:  Well, because yes, there are four billion IP addresses.  And you have no idea when you send stuff to a given IP address if it's going anywhere.  Is it actually hitting a machine or not?  If the machine obeys all the rules, any machine will respond and say, hey, you found me.  But, you know, ping, and it'll respond with a ping, or it'll say, oh, that port's closed, try again.  Guess again.  Try, try...



LEO:  Guess again.



STEVE:  I have 65,535 ports.  Maybe one of them is open.  You know, exactly, guess again.  So I argue that, yes, I'm not saying that it's increasing your security.  I'm saying - and you can argue that it's security by obscurity.  And I'm saying sure.  It's more secure to be hidden than not.



LEO:  It's pretty good obscurity.  If there's no response, there's no way a hacker could tell if there's anything there, right, unless he knocks on your door and says can I see what your IP address is.



STEVE:  There is no way.  The packets hit, and they die.  And that's why typically NAT routers are stealth.  And in fact I'm - ShieldsUP! and GRC are significantly responsible for NAT routers being stealth because there were initially lots of holes where, like, NAT routers would respond with a ping, or they would say their ports are closed.  And, you know, we popularized this idea that, hey, why not just be stealth because stealth is better.



LEO:  Now, I just did ShieldsUP! on my system, and it's all green, all stealth, but I still failed because I respond to a ping.  Why would I not want to respond to a ping?  Same reason; right?



STEVE:  Well, yeah, because you're responding to a ping, therefore somebody knows there's something there.  And so you could argue that it heightens a malicious person's interest.  Or say they wanted to know - say that, I mean, it's giving away information.  It's, you know, like for no reason.  Like maybe they want to know if you're there, if your machine is on, when you're on vacation?  Because then they can go over and break a window.  I mean, the point is, better just to say nothing.  Better just to be absolutely an enigma than to say, oh, good guess, you've got a live IP.



LEO:  This is, by the way, the Comcast router default configuration.  And I will go in there, and I will turn that off.  How do you turn off ping?



STEVE:  It varies.  There's no universal way.  But normally it'll be like there'll be some WAN-side - WAN as opposed to LAN, WAN meaning Wide Area Network - there'll be some WAN configuration where you can typically say - it'll say, like, disable ICMP, WAN-side ICMP.  Or it might say respond to pings or something.  And the good news is, most routers now default off.  Otherwise people complain because they go to Security Now!, and then they say, hey, I'm not stealth, I want to be stealth.  And I say why not?



LEO:  Why not?   There's no reason.



STEVE:  Yeah.  And so to answer Welles's question, there's nothing arguable insecure about the fact that Apple's AirPort Extreme, and this is a well-known characteristic of the Apple AirPort...



LEO:  Which port is it?  Is it the ident port that it turns off?



STEVE:  No.  It's all of them.  They all come up as closed as opposed - it just - it responds by the book.  It responds to pings.  It responds to attempts to open a port by saying this port is closed.  So it could easily just say nothing.  But for whatever reason, that's not what they chose.



LEO:  And worse, they don't give you a way to change it.



STEVE:  Right.  Which, you know, seems dumb.



LEO:  That - at least you should offer that as an option for somebody...



STEVE:  Because people want it.  And again, I'm not saying it makes you more secure.  I'm just saying - and again, the old UNIX curmudgeons who say it's against the rules not to respond, it's like, okay, yeah, fine.  So...



LEO:  Well, that makes sense in a gentle, benign world where there were reasons why you might want to look at the topologies of the network or whatever.  And I'm glad that Yahoo! and Google still allow pings because I use it to test to see if I'm up.



STEVE:  And within my own LAN network I'm pinging myself crazy all over the place.



LEO:  Well, you ping me.  You ping my servers to see if there's a new file for you.  But actually it's a different kind of ping, but that's fine.  I mean, if you're running a server you have open ports.



STEVE:  And in fact people are welcome to ping GRC if they want.  I mean, I have deliberately let GRC be pingable so that people who are having a connection problem, couldn't bring up our pages, could just ping GRC.com to see if we're there.  Because I'm not hiding.



LEO:  Well, that's different.  You're a server.



STEVE:  Exactly.  We are, exactly, we're a big public server.  Everyone knows where we are.  I'm not an end-user.  For example, you can't ping this famous cable modem of mine because it's just stealth.  There's no reason to expose that.



LEO:  Shouldn't be able to.  Gary Warner, who is the director of research at UAB Computer Forensics - ooh, wow, we've got some biggies listening - cautions about certificate dangers:  Steve, I thought you might enjoy seeing an example of one of the dangers that I'm concerned with regarding extended certificates.  If we train users - we've talked a lot about extended certificates.  We just talked earlier on the show about it.  That's the green bar you get on Firefox and Internet Explorer 7 when you go to a site that has a special certificate that goes to extra lengths to identify them.  He says there's a problem.  He says:  If we train users that, quote, "green bars are safe," we still haven't fixed a primary problem, that webmasters ignore security.  You actually mentioned something that proved this with PayPal.  My team at the University of Alabama at Birmingham looked at more than 15,000 phishing sites in the first quarter of 2008.



STEVE:  Okay, the fact that there are even 15,000 phishing sites, I mean, there's a problem right there.



LEO:  Amazing.  And they're pulled down the minute people discover them, so that just shows you how they proliferate.  What started as a very occasional thing is now happening at least on a weekly basis:  Phishing sites are running on sites with valid certificates.  Most are on hacked servers where, for example, a web store is broken into and a phishing site is placed on their SSL-certified site.  We're actually also seeing situations now where the criminals are buying certificates.  Will the high cost of a certificate provide a disincentive to criminals registering an unrelated company, then using it for phishing?  Absolutely not.  They're using stolen funds to pay for it anyway.  The certificate says, quote, "We have documentation that a company owning this site exists."  It doesn't say, "The bank login content on this webpage corresponds to the company that registered this website."  So they could have a certificate that says, yes, we're BadGuys.com, and have the site look like BankofAmerica.com.  I just wanted to point out that making certificates harder to get and training users to trust them won't cure all of tomorrow's problems.  Thanks for all you do.  I've been a fan since your TechTalk columns way back in InfoWorld.  I even bought your "Passion for Technology" books when they were published.



STEVE:  So I thought this was a perfect, a perfect illustration of what we were talking about before.  It is important that we be clear about what it is that extended validation means.  It means that the company that acquired the certificate was much more thoroughly vetted than just somebody getting a random SSL certificate.  So that's what the certificate authority is vouching for.  VeriSign issuing a certificate to Gibson Research Corp. has verified my identity, our corporate address, that our corporation is a company in good standing, blah blah blah, I mean, they're doing all this work to say that for me to get the green bar they've really checked us out.  But it says nothing about my company's security practices.  Am I encrypting all of my eCommerce data?  Well, yes, I am.  Every single node of my B-tree is encrypted.  So I'm going over the top.  But that's not what that certificate says.  So it's important that people understand that all it is asserting is the identity of the company that obtained the certificate, nothing more.



LEO:  And you know, I think most users are going to look at that green bar and say, oh, green means safe, and they mean safe, not green means I've identified this is a person.  So I think he raises a very, very good point.



STEVE:  Actually, do you know that - remember, I think I made some sort of a mildly disparaging comment a few weeks ago about that Hacker Safe certificate that's appeared on all these sites all over the place?  Get this.  It was on the PayPal page that had the cross-site scripting vulnerability.



LEO:  I don't even know what they're - who knows what they're testing for.



STEVE:  Oh, exactly.  It's just bogus.



LEO:  Yeah <sighing>.  Kyle Hasegawa is back.  He has another question from Tokyo.



STEVE:  Good memory, Leo.



LEO:  I don't forget names like Kyle Hasegawa.  He has a quick fix for really dead hard drives:  Hi, Steve and Leo.  In Episode 145 you mentioned there are some hard drive problems even the mighty SpinRite cannot fix.  Those, of course, being hardware failures.  You also said that once a hardware failure occurs, you'll have to spend thousands of dollars to have data recovery professionals dismantle the drive and extract your data.  Well, here's a cool trick that has worked for me, and it only costs you the price of another drive.  I must warn you, this is a last resort and should only be done if software repair attempts are futile and you're not willing to spend thousands of dollars.  What he's saying is by doing this you're making it impossible to fix if it doesn't work.  The trick is to locate a drive that's exactly the same as yours.  Matching the model number is imperative, but matching the production code is even better.  Carefully remove the PCB - that's the, you know, the circuit board...



STEVE:  Printed Circuit Board, yup.



LEO:  ...from your dead drive and replace it with the new drive's board.  If your old hard drive's problem was the PCB board, you're good to go.  If not, well, you're no worse than before, and you're out a few bucks.  Thanks for the great show.



STEVE:  I thought that was worth mentioning...



LEO:  That is worth it, yeah.



STEVE:  ...because it is a - it's a midpoint in between, you know, running SpinRite and hoping that SpinRite's going to be able to do the job, and forking over $2,500 to a DriveSavers group.  And you mentioned something that I also know, and that is that these drive recovery companies, they have inventories of old drives just for this purpose.



LEO:  They've got parts.



STEVE:  Yes, exactly, because they need, if it's a PCB that is fried, and just swapping out the printed circuit board with a good one will allow them to pull the data off, they're not giving you their PCB, they're just giving you the data.  So they'll move an equivalent printed circuit board, the motherboard of the drive, onto the bottom carriage of the drive, suck all the data off, then put that PCB back into their inventory for the next time it happens.

Now, the fact is, when you consider all the complexity of the hardware in the drive, it is statistically far more likely to be a problem in the enclosure, that is, the heads and platters and so forth, especially because drives are often dropped, and the heads are bouncing around on the platters.  So I would say certainly, if it's feasible for you to swap the PCB, do so.  Especially many people will buy a couple copies of the same drive at the same time.  So you may have a machine with the same printed circuit board because you got two drives at the same time, and one of them died.  It's certainly worth giving that a try if you're comfortable with swapping printed circuit boards on the bottom of hard drives.  My sense is it's probably not going to give you the leverage that you could count on that happening.  But it's a really nice compromise between just using software and spending literally thousands of dollars.



LEO:  It's a good point.  I hadn't thought of that, Kyle, thank you.  Yeah, very good idea.  Do you have to desolder the board, the PCB, to replace it?  Or is it just socketed in there?



STEVE:  I've never seen one that you had to desolder.  Normally there's a flat cable coming around, and you can pull the flat cable off.  Or very often now you'll see pins sticking up through a connector.  So if you pull the board, sort of wiggle it back and forth but pull it directly away from the drive, it'll just unplug...



LEO:  Oh, that's cool.



STEVE:  ...very cleanly because of course the reverse of that happens during manufacture.



LEO:  Yeah, they want to be able to put it in easily.



STEVE:  Exactly.



LEO:  Bob J. in Claremont, California has a really bad router:  Hi, guys.  Verizon recently changed my system to their Actiontec modem/router.  It fails the ShieldsUP! test by responding to a ping - oh, that's funny, my Comcast does that, too - something my Linksys router never did.  It also exposes its homepage, which shows my network setup to the world.  Oh, boy.  I typed in the public IP, and it pulls up the router's homepage with all the information.  Granted, I'm using a strong password, but I hate this thing.  I called Verizon, and their assistance was, well, useless.  Any suggestions?  Can I disable the NAT on the Verizon router and go back to using the Linksys?  I've been listening since the beginning.  Thanks for the great information.  A lot of ISPs are doing this now.  Comcast did it to us, too.  The cable modem, or the DSL modem, is built into a router.  So you have to use their router.



STEVE:  Yup.  Okay, first thing.  The fact that he typed in the public IP, and he got the router's homepage, that in itself does not guarantee that that homepage is available from the WAN side.



LEO:  Oh, he needs to do it from home or somewhere else.



STEVE:  Yes, he's got to get a friend of his, somebody he trusts, while he's on the phone with him or while that IP is the same, to type it in from outside and see whether that page comes up.  There is a characteristic of some routers, and not all routers, that if you - you are able to get to them, not only using the so-called "Gateway IP," which is your private IP inside the network, typically 192.168.0 or .1 something.  But you can also sometimes get to the same, essentially the same thing using the router's public IP, but only from inside.  So it may very well be, and I hope that it is the case, that from the outside it is not exposing its configuration page.  And if it is, many routers give you the option, again, in a WAN configuration page, to disable what they will call "WAN Administration."  You absolutely want to have WAN Administration disabled.  You don't even want to expose a login page because someone could just sit there and pound on your login over and over and over, doing a brute force attack until they get in.  And that's not something you want to allow to have happen.



LEO:  Yeah, yeah.  So disable WAN management.  You certainly - it shouldn't pop up a page.  If it does, you should have a password on the darn thing.  So make sure you put a password, change the name of the router if it's a wireless router, all of those things are very important to do.



STEVE:  And also, while you're at it, tell it not to respond to pings, if that's a configuration option.  Now, if none of that is possible, well, if at least it's not possible to tell not to respond to pings, you can still put your Linksys router behind it, that is, have it there out in front and then your Linksys router.  And so you want to bolt that public face down as much as you can.  If there's an admin page, tell it not to respond to ping.  Use a username and password and so forth.  But still you could plug it into your Linksys router and use your Linksys router.  So then you've got all of the Linksys's security.  And we know that that could be bolted down tight.



LEO:  Excellent.  Are you ready to have your bone picked?



STEVE:  Oh, yes.  Pick away.



LEO:  KakeMan in Malaysia says there is a potential problem in using one of those Linux boot disks that we've talked about.  Because I like this idea.  He says:  On Security Now! Episode 142 you recommended the use of a Live Linux CD to access questionable websites or other risky activities.  I'm not sure this is a good idea.  It's true that I can use, for example, the fresh Hardy Heron Live CD, the Ubuntu that just came out for online banking.  However, as time goes by - and this is a very good point - there will surely be security holes and vulnerabilities found in this Live CD.  But by that time I might be vulnerable.  Unless I can build an up-to-date Live CD, I wouldn't use it for that purpose.  I might be wrong, but can you clear my doubt on that?  Thank you.



STEVE:  Well, can you say "OpenSSL vulnerability"?



LEO:  Perfect example.  Perfect example.



STEVE:  Yup.  Yup.  As you said, that's the new Ubuntu.  And unless it's as new as, you know, a week ago, it may very well have the vulnerable OpenSSL pseudorandom number generator that's been in place since September of '06.



LEO:  Now, the point is, if you install it on a hard drive, it has automatic updates just like Windows or Mac, so it would be fixed.  But a CD can't be updated.



STEVE:  Yup.  So I think that when we were answering the question by our listener who was going to be using remote access to help other people with their machines, one of the things I was going to say, you know, I talked about running that in a VM.  An alternative would be if you were using VNC that is multiplatform, you could use VNC on a Linux boot CD and again be very safe, as we said when we were talking about this before, as long as your drives were not available.  Then, I mean, you're really working with belt-and-suspenders security there.



LEO:  Right, right.



STEVE:  But so KakeMan's point is good.  If your Live CD is old, that would be bad.  So it probably makes sense to keep it fresh and not use it for a long period of time because at some point there will be known vulnerabilities there.



LEO:  I guess the point is bad how.  Certainly not bad in the sense that your disk could be modified, because it can't, and so you're safe in the sense that you're not going to have a virus or spyware get on there.  But your network is vulnerable.  And if you're vulnerable and you type a bank login at that moment, then they could be capturing what you're doing.  So it's bad in that sense.  Steve, we've run out of time and run out of questions.  I think it's time to say goodbye.



STEVE:  Well, and isn't it nice that those two things happen at the same time.



LEO:  Well, the nice thing about a podcast is we just go until we're done.  So next week what is on tap?  What are you planning for us?



STEVE:  I've got a whole bunch of topics.  I'm going to have to choose one.  So I don't know yet.



LEO:  Oh, that'll be fun.  People can participate, of course, by going to your website, GRC.com/securitynow.  When you're there you'll see there are transcripts of every show.  There is a 16KB version of every show, so if you need a smaller file, if you're bandwidth-impaired or whatever, you can get there.  Steve puts great show notes up, so you can read along and click links and so forth.  It's all there at GRC.com/securitynow.  While you're there, take a look at ShieldsUP!, we were just talking about that, and many other free programs Steve offers to help you lock your system down, fix bugs, fix problems with Windows, even just simple utilities like Wizmo that are just fun to have.  They're all free at GRC.com.



But don't forget his bread-and-butter, and everybody should own a copy, just if only to keep Steve doing this show, it's SpinRite.  It is the ultimate hard drive maintenance utility, a recovery tool everybody'll want.  It's just a really great program.  I'm glad I have a copy in my toolkit.  When Auntie Dawn came, of course the first thing I do is I SpinRite the drive.  You'll find it all at GRC.com.  Steve, thanks for joining us, and we'll see you next time on Security Now!.



STEVE:  Right-o.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#147

DATE:		June 5, 2008

TITLE:		Microsoft Baseline Security Analyzer

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-147.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the recent hacker takeover of the Comcast domain, then examine two very useful free security tools offered by Microsoft:  the Baseline Security Analyzer (MBSA) and the Microsoft Security Assessment Tool (MSAT).



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 147 for June 5, 2008:  Microsoft's Baseline Security Analyzer.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, time to talk about keeping yourself safe and sound in this modern time.  And what better person to do that than Mr. Steve Gibson of GRC.com?  Good morning, Steve.



STEVE GIBSON:  Hello, Leo.  Great to be back with you again.



LEO:  To talk about saving your butts.  Security.



STEVE:  Yeah.



LEO:  Yeah.  I was having a long conversation on the radio show - this comes up a lot on the radio show, security, how to protect yourself.  Fellow asked, and I think it was a reasonable thing, he'd run a security scan and came up with four different kinds of critters:  adware, spyware, rogue software I think they called it, and trojan horses.



STEVE:  Rogue, I like that, it's roguish.



LEO:  Well, I told him, what I said is nowadays I think it's all malware.  I mean, I don't think that there's much distinction between adware, spyware, and viruses.  They all act the same.



STEVE:  Well, "mal" as in something that you really don't want on your machine.  You just don't want it around.



LEO:  Well, anyway, he was panicked, as all people are.  And, you know, sometimes I get in this battle about whether you should format the drive or if there's some way to do it without formatting the drive.  But every time I talk to somebody, you know, in fact there's a guy on Twitter said, oh, you always say format the drive.  You don't have to format the drive.  I asked him, I said, well, what percentage of malware infections are you able to get rid of without formatting, and how many of them come back?  And he said, well, you know, 99 percent of them come back.  And it seems to me that you have to format the drive.



STEVE:  Yeah.  In fact, there has been some evolution there.  Remember that - I remember clearly when we were talking about this at one point, you know, in the last three years, the formal rule is, if your machine has been compromised, you can never trust it again.  There isn't any way to know what it is that was changed.  And in fact when, you know, I've talked to some people who are sort of old-school sticklers for, oh, I know what every single file on my machine is, you know, back from the DOS days.  And there have been some friends who have spent weeks trying to get stuff removed after an infection.  And you really cannot do it.



It turns out that, I mean, the way this malware has evolved now, it's so insidious and sinks itself so deep into the system and, you know, renames files and sticks itself in places you don't know to look and is able to hook itself in so that it gets started up in many different scenarios, I mean, if you get a serious infection, really, I mean, for two reasons.  First of all, you don't ever - you will never again, by definition, be able to trust the system.  And secondly, you just can't get rid of it.  It won't go away.  And when people say, well, it comes back, what it means is they didn't get rid of it the first time.  There was some little hook left somewhere, some little piece of evilness that is monitoring, and it reinfects the system.  So it's just - I think your advice is right, Leo.  You just - mostly, how could you ever do ebanking on a machine that once had this on there?  I mean, there just isn't a way you can trust a machine that was taken over.



LEO:  Karoli asks in our chatroom, well, what about System Restore, is that enough?



STEVE:  Well, there are now System Restore-aware malware.  Which, I mean, that is a great example of the adaptation that we're seeing in this kind of malicious software is that it's evolving step by step.  Once upon a time, remember, the spyware scanners could remove spyware.  They'd say, okay, we got rid of it, and it would be gone.  Now all kinds of things break because the software is really insinuating itself into the system because it doesn't want to be removed.  And it's successful in not wanting to be removed.  So even System Restore - and the problem is System Restore is sitting on the same system.  If it's in the same system, you can't trust it.



LEO:  Frequently, in fact, people will restore viruses that they got rid of.



STEVE:  Right.



LEO:  Isn't that nice.



STEVE:  Right, yeah.  So, I mean, the only thing that would make sense that you could trust would be if you had offline images, and you reimaged your system from an offline image that occurred before the problem.  As we know, the best solution is not to have the problem in the first place.



LEO:  Well, let's talk about security news, as we always do.  And then we're going to get into our topic of the day.  What do you want to talk about today?



STEVE:  I want to talk about two utilities that Microsoft offers.  We had a great response to talking about Secunia's Personal Software Inspector, which talks about third-party software.  Back when Microsoft got all into security, they produced a couple of tools, one called the Baseline Security Analyzer, which is an interesting, sort of Secunia-like tool.  And the second is called the Microsoft Security Assessment tool.  So I want to introduce our listeners to that.  You'll have links to them.  I've got links to them on our show notes.  So people can experiment with them.  They are, again, they're not something you would get with Windows Update or automatically.  You've got to go to Microsoft and get this.  But they're both interestingly useful, I think.  And I think our users, our listeners of Security Now! would find them useful, as well.



LEO:  Cool.  So we'll talk about that in just a bit.  Any big security news?



STEVE:  The big news, I mean, the really big news actually occurred after we recorded last week's...



LEO:  Of course.  Probably seconds afterwards, yes, of course.



STEVE:  We record on Tuesday, of course, and then air the show on Thursday.  In that intervening period, Comcast got their DNS record, essentially, hacked.  What happened was that somehow, from looking at all the evidence, it looks to me as though that someone malicious inside of Comcast is my best guess, maybe it's an ex-employee, someone disgruntled, it's impossible to know exactly what happened.  But on Comcast's domain, Comcast.net, is hosted by, well, their registrar is Network Solutions.  There's no indication that Network Solutions themselves were hacked.  But the registrar record for Comcast.net was definitely hacked.  There's a bunch of, you know, script kiddoe-ish lingo in the administration contact.  They repointed the primary and secondary Comcast name servers, which are normally Comcast-provided servers.  They redirected them to ns21.worldnic.com and ns22.worldnic.com, which are the name servers that Network Solutions supplies.  And those pointed to a bogus server, I believe it was in Germany.



Now, this basically, I mean, this took Comcast.net off the 'Net for the period of time that it took them to find the problem, change the record, and then for DNS changes to propagate.  So, and it's interesting, too, because I got email from my office manager, Sue, on I think it was Thursday evening or maybe Friday morning saying that a bunch of our eCommerce receipts sent by our eCommerce system had bounced.  And she had noted they were all Comcast.net.  So there was some mistaken reporting, unfortunately, by the nontechnical press, saying that it was only Comcast's portal, that like people who were...



LEO:  That did get hacked, though, I mean, there was some text on there, hacker text and so forth.



STEVE:  Well, this is all part of the same thing, well, unless it was related and different.  It may have been, for example, that some password file that Comcast maintains got out and so someone was able to hack the portal.  But what did happen was Comcast.net got redirected to a different server that was putting up a hacker-esque message.  But this was...



LEO:  Now, they're saying they think they know who it was, and it's these, you know, Kevin Poulsen interviewed these two high school dropouts who say, yeah, we found a security flaw in Comcast, and we probably should have told them, but we just thought, well, what the heck, we'll take advantage of it.



STEVE:  Okay.  Well, again, they may have gotten into Comcast's network, found the information, and then been able to log into it.  It looks to me as though someone got the logon credentials for Comcast's Network Solutions account and then went there and changed that information at Network Solutions, which then redirected Comcast.net to a different pair of name servers from Comcast's, and from there they were able to do, you know, play any games they wanted to.  Anyway, if it happened to TonyNoodles.com, no one would have cared.



LEO:  It happens all the time to TonyNoodles.com.



STEVE:  Exactly.



LEO:  It happened to me.  I mean, you know.  So this is according to Kevin Poulsen's article.  You know, Kevin was a hacker himself but did some jail time.  We've interviewed him many times before.  And now is actually a very credible, really good reporter.  He's an excellent reporter.  And by I think because of his connections with the hacking community he was able to talk to these guys. They respected him.  He said he had an hour-long conference call with this hacker group called Threat Level.  And the hackers - oh, no, I'm sorry, they talked to Threat Level.  The hackers' names were Defiant and EBK.  And it was a DNS hijack, as you say.



STEVE:  Yup.  And in fact Defiant and EBK name is in the edited administrative contact in Network Solutions.



LEO:  Yeah.  And Threat Level, which is the blog that Kevin writes, says he did verify their identities.  They wouldn't say where they were.  His MySpace profile, Defiant's MySpace profile says he lives in Cashville, Tennessee.  I don't think that's accurate.  Network Solutions said it had nothing to do with us, there was no breach in our system, no social engineering.  Of course they're going to say that.  Who knows what really happened.  But as you said, it was a transfer of the account to them.  I always worry about that.  You know, I mean, we have - when you register a domain, most domain registrars will allow you to lock it down so that these can't - there can't be administrative transfers.  They  make it very difficult.  But still, you know, ultimately with a fax and maybe some phone calls you can get that stuff transferred over; right?



STEVE:  Well, and look at what's happened.  Once upon a time, like in the beginning of all this, 15 years ago, it would have been uncomfortable if you couldn't get email for a day or something.  But what's happened is...



LEO:  This is serious, yeah.



STEVE:  Exactly.  In the intervening time we've built, you know, a mission-critical economy on top of all this.  And the underlying structure, while it's been strengthened a little bit, it's still prone to, as you said, social engineering hacks and various types of malicious conduct.  And it's now not a small thing if this happens.  It's a big deal.  You can imagine how Comcast feels.  I mean, their whole network would have been messed up for many hours because any DNS servers whose cached Comcast.net records timed out, they would have gone back to the root server to update, to refresh their DNS.  If they did that during this window where the record was changed, they would have picked up the malicious record.  And even after Comcast fixed it, those servers would still have the wrong information and would have no reason to go back and reverify it.



LEO:  How often do they do that?  They do - it does expire after a while; right?



STEVE:  Yeah, typically it's a day, though, because you don't want to load down your DNS server too much.  So oftentimes it's - especially in a situation like with Comcast, where they have no expectation or intention of needing to change that information.  So, for example, one of the things that is often done for a site that they're under a heavy DoS attack is they'll deliberately bring their record expiration down maybe to an hour, maybe even to, like, ten minutes because that gives them the flexibility of changing their DNS in a much shorter period of time.  But typically it's about a day.  So anything that had happened to expire during that window where the records were wrong, the authoritative DNS records were wrong, servers would have gone back and picked up the new information and kept it probably for a day.  So it was about a day-long problem before this thing got itself cleared out.



LEO:  They said that they tried to tell Comcast, but they wouldn't listen.  Yeah, I bet.  I don't know why I don't believe that.  What else is in the security news?



STEVE:  Well, two things.  I did want to mention to all of our Mac listeners about the major OS X update, 10.5.3, because although it didn't get a lot of press attention, there were a number of remote code execution vulnerabilities which...



LEO:  Well, we talked about them last week, I think the Macintosh vulnerabilities; right?  And we [indiscernible] fixed it.



STEVE:  We talked about the iCal vulnerability.



LEO:  Right.  And I think they - we don't know.  You know, I looked at the update immediately when it - because the update came out Tuesday.



STEVE:  Right.



LEO:  And I immediately looked at it, said has this been fixed?  And it doesn't say.



STEVE:  Yeah.  What I have seen is that there are still some iCal issues that have not been fixed.  Specifically two known problems that Apple has not yet addressed.  And then the last thing I wanted to mention was there is an exploit in the wild for a known vulnerable version of the Adobe Flash Player.  Version 9.0.124.0 is the latest and the current one.  Secunia knows about it.  So if you downloaded Secunia two weeks ago, you can just check, during our episode about that, you can check in with it.  I've just checked my systems, and I did have 9.0.124.  But I remember that it was Secunia that had alerted me to the fact that I was behind and that there was a problem.  I mention this again because there are now Windows-based exploits in the wild.



LEO:  Oh, boy.



STEVE:  Apple's fix from last week does address this.  So there were problems with Apple's version of the Flash Player, as well, but they fixed that in their mega, you know, 200MB OS X update.



LEO:  Now, you didn't mention, I'm kind of surprised at you for not mentioning it, that there was a little bit of a DoS attack against our friends at Revision3.



STEVE:  Oh, that's very true.  I didn't really follow up or know any details.  But I was talking to Mark Thompson, and he said that they were seriously under the weather.



LEO:  Yeah.  Jim Louderback did, I thought, a very good job.  We have Jim and Patrick and Martin Sargent on TWiT, and so we talked quite a bit about it.  Jim did a very good job on his blog talking about it.  But let me tell you what happened.  It's kind of interesting.  It was a SYN flood.  Jim does a great job explaining SYN floods.  We've talked about it before on this show.  I think anybody who listens to this show probably knows what a SYN flood is.  But it was kind of unusual in the sense that they didn't hide the source of the SYN packets.  They were getting 8,000 SYNs a second, which took Revision3 down for the entire Memorial Day weekend.  But it was apparent where it was coming from.  It was coming from MediaDefender, which is a company run by or funded by the recording industry in order to bring down torrent sites.



What MediaDefender does is they create fake bit torrents of illegal content, movies and music, and then seed the torrent trackers with that so that people can't find the legitimate, or illegitimate legitimate stuff and end up, you know, getting non-downloads.  They also apparently, as part of their portfolio, do DoS attacks against BitTorrent trackers.  Revision3 was running without - kind of they really had forgotten about it.  In the early days of Revision3, I mean, really early days, three years ago, they used BitTorrent to distribute Systm and some of their other programs.  So they were running a BitTorrent tracker.  It had - Jim explained this.  But apparently it had become open over the last couple of weeks, which means that other people could put other torrents on there instead of just the Revision3 shows.  And MediaDefender says there were 296,000 other torrents on there.



But here's the funny thing.  It was open.  It was out there.  MediaDefender was using it as one of their trackers that they seed with the phony torrents.  Then Revision3 found out it was an open tracker and closed it, and that triggered the attack.  MediaDefender started SYN flooding it after they closed their open torrent tracker.  It was almost a retaliation for closing the tracker.



STEVE:  Okay.  I'm curious, then.  Because doing what they did, for MediaDefender to do what it apparently deliberately and intentionally did to Revision3 is against all kinds of laws.



LEO:  It's illegal.



STEVE:  I mean...



LEO:  [Indiscernible].



STEVE:  Absolutely illegal.



LEO:  Yeah.  So it's a little puzzling.  I asked Jim, are you going to sue them?  And he said, nah, we don't have time to focus on all that.



STEVE:  Yeah, I mean, I have to agree with that.



LEO:  Yeah, we've got other things to worry about.  But nevertheless, yeah, absolutely it's illegal.  The FBI has been called in.  I don't know if they're going to do anything about it.  But I just think it's just a really kind of an appalling misuse of their resources for the recording industry to go after, you know, Revision3, a legitimate content company; right?



STEVE:  Yeah, that's not okay.



LEO:  Yeah.  And it wasn't, you know, and this is - as we've talked about before, a real DDoS attack they use raw sockets and other ways to spoof the originating server.  They didn't bother.  They wanted Revision3 to know where this was coming from.  But they had enough servers all over the country that Revision3 couldn't just block a single IP address.



Before we get to the Security Analyzer from Microsoft, do you have any SpinRite tales you'd like to tell?



STEVE:  Well, I had one little reminder.  This was a subject, we got a nice note from a Security Now! listener named Dennis Thiel with the subject:  "SpinRite Works on Floppy and Saves Wedding."  He said, "Steve..."



LEO:  I'm just dying to hear how this works out.



STEVE:  He said, "Steve, I've been listening to Security Now! from the start.  Thanks to you and Leo for a great podcast and great source of information.  A while back a friend of mine came to me with a floppy disk that had her address list of guests for her upcoming wedding.  She couldn't read it, and desperately needed to retrieve the data."



LEO:  She didn't have it on a floppy disk, did she?



STEVE:  Yup.  That's what he says.  "She came to me with a floppy disk that had her address list of guests for her upcoming wedding.  She couldn't read it, and desperately needed to retrieve the data since it was her only copy."



LEO:  What is this, 1979?



STEVE:  This came in on May 9th, so it's recent.



LEO:  Who has a floppy drive anymore?  Wow.



STEVE:  And he says, "I bought my first copy of SpinRite at v5 and have since upgraded to v6.  I booted my computer into SpinRite, popped her floppy in the drive, and in just a few minutes it repaired bad sectors and all of her data was recovered."



LEO:  Wait a minute.  You're saying SpinRite works on floppies?



STEVE:  Yeah, it works really well on floppies, actually.



LEO:  I'll be danged.  I didn't know that.



STEVE:  Yeah.  And, well, so he says, "Needless to say she was relieved.  The floppy drive is all but dead.  But I'm sure there are many other people who have data on floppies who don't know that SpinRite will work on them also.  Thanks for a great product."  And then he says, you know, signed Dennis Thiel.



LEO:  I didn't know that.



STEVE:  So, yeah, I'm glad you do.  Not that you have any floppies on any machines these days.



LEO:  No, I don't think I could find a floppy disk to save my life, let alone a drive.



STEVE:  I still have them on every single one of my machines.  And a little stack of floppies that I, you know, boot for various maintenance and setup and...



LEO:  Don't you think a CD would be a better choice for that now?  I mean, SpinRite will make a boot CD.



STEVE:  Oh, it will.  And this guy may well have booted a CD, but then ran it on his A drive, on his floppy drive.



LEO:  Although you could fit SpinRite on a floppy, can't you.



STEVE:  Oh, no, that always has been.  I mean, SpinRite on a floppy, it's like it's 100K or something, so.  Yeah, you can put it on a floppy with a whole bunch of other stuff, too.



LEO:  100K.  Nothing's 100K.  I don't even - the text below your name, below the picture is 100K.  I don't know how you - that's amazing.  Wow, that's so cool.  All right.  So we talked - was it two weeks ago? - about Secunia's PSI.



STEVE:  Yes.  And we had some feedback from people saying, hey, what about Microsoft's Baseline Security Analyzer?  It's like, yeah, yeah, yeah, I know, I'm going to get there.  And we're going to get there right now.  Essentially back when Microsoft decided, sort of woke up from their slumber and said, oh, maybe security is important, remember they launched that whole security initiative, you know, "trustworthy computing" I think was Bill Gates's phrase during one Comdex keynote that year.  He says, oh, we're going to be trustworthy and the most secure operating system available, blah blah blah.  And it's like, okay, you know, that all sounds good.



Well, some interesting useful things came out of it.  These are not things that normal Windows users know about.  Using Windows you would never find these offered to you or suggested downloads or anything.  So our listeners are going to have to go get them.  But both of them I think are interesting and useful in very different ways.  The first is the so-called Microsoft Baseline Security Analyzer, or MBSA.  And people can use the links in our show notes or on the TWiT page or just go to Microsoft and put MBSA or Baseline Security Analyzer into the little search box, and it'll take you right there.  It's not big.  It's only a couple meg.  And it doesn't have any onerous installation requirements.



The other thing I want to talk about today does require the .NET framework, and that's no longer small.  But the Baseline Security Analyzer is not a big deal.  And it's very much like what Secunia has done.  But it's also impressive because first of all it only deals with Microsoft Windows issues.  So it's not a third-party scanner, meaning that it's not a superset of Secunia, nor is Secunia a superset of this.  So really...



LEO:  You could use both.



STEVE:  Well, yes, that's what I would recommend.  Both of them together sort of go hand in hand.  And when I ran it on a VMware WinXP window that I had where I had deliberately disabled automatic updates about a month ago, after I set it up, I brought it up to current patch level.  And I said, okay, now I don't want to be bothered with this.  I want to leave this static for a while.  I ran it on there.  It only takes, you know, a minute or two to do that.  And I got severity assessment, severe risk, with a big, red, unhappy shield.



LEO:  [Mimicking siren]



STEVE:  Exactly.  Warning, warning.



LEO:  Warning, warning.



STEVE:  And it says one or more critical checks failed.



LEO:  Uh-oh.



STEVE:  And it's like, uh-oh, exactly.  And so under security update scan, one of the things it does is it does a comprehensive scan of your system's secure, you know, Microsoft security updates.  And it found that one was missing.  That got the red shield.  And then it also checked for SQL Server security updates to see, well, I don't have SQL Server installed here on this little installation of XP.  So that, you know, it came up with a green checkmark because it says none are missing.  It's like, yeah, and none are installed, either.



LEO:  That's interesting.



STEVE:  But very much like the way Secunia allows you to drill down, so does this.  So, for example, you can click on what was scanned, for example, when it's saying that it's got my red shield.  And then that opens another window which is very comprehensive.  And so here it shows me that MS08-028 is a critical update.  And it gives me a link.  I can click the link, takes me to the knowledge base article. And this was that Jet Database update that we will remember from, like, middle of May, middle of last month.  And so it was like, okay, that makes sense that I would have set this up before then and not updated since then.



Then it also - but it goes on and, for example, tells me that I've got three update rollups and/or service packs missing.  And so I go, wait a minute, what's that?  Well, it's not happy that I'm still using IE6 on this system.  So one of the things that it's suggesting is that I update to IE7, Internet Explorer 7 for Windows XP.  Number two is the infamous Windows XP Service Pack 3 that I'm not getting anywhere near, although I wouldn't mind sticking it in this virtual machine because this is, you know, just sort of a throwaway scratch VM, so that's not a problem.  And then they want an update to, and they always do every month, the Microsoft Windows Malicious Software Removal Tool.  So it's saying those things are missing.



Then under the current update compliance I got a whole bunch of green checks.  It's basically every security patch from Microsoft that's ever been installed with the number, the severity, and a link to its knowledge base article.  So in a way this forms sort of a missing piece of Windows Update/Microsoft Update.  And that is it's a nice UI to the whole database that Microsoft is maintaining and that your Windows systems are maintaining, allowing you to sort of have a UI that we don't normally get.



Normally, you know, you get the yellow shield down in the tray.  And you go, okay, fine, fix me.  And it just goes and does it.  And then there is a way in Add/Remove Programs under XP where you can tell a little checkbox up at the top of the window which is normally not checked, you can say "Show my Windows updates."  And that of course makes the Add/Remove Programs list triple the length that it was before, depending on how much of your own software you've got installed.  Because it'll show you every security update.



But this is just a nicer presentation, and it allows you to see the severity of the patches.  And if you have any questions about them there are links for everything that goes around and tells you exactly what it is.  So beyond that, though, this looks at - so that's just the Microsoft Windows Update scan results.  It also looks, for example, at what they call "administrative vulnerabilities," analyzing the machine that it's on, looking around.  And so, for example, I got another big unhappy red shield saying the issue is automatic updates.  And so it's just reminding me what I already know, and that is that it says the automatic update system service is not configured to be started as automatic.  And it's like, that's right because I'll run it when I want to, not when you tell me I have to.  And then I've got sort of a blue eye that says no incomplete software update installations were found.  And there's another one, Windows firewall is disabled and has exceptions configured.  So that's interesting.  I must have turned off the firewall for something...



LEO:  See, that's good because it's letting you know that you did that.  You forgot that you did that.



STEVE:  Exactly.  And then I've got - it's happy with me on my user accounts, it says, because it checked my user accounts.  And on local account password tests it says no user accounts have simple passwords.  So it's checking for password complexity.



LEO:  Simple being bad.



STEVE:  Simple being bad, yes.  Too easy to guess, easy to brute force and so forth.  Under file system it says all hard drives {1), so it knows there's only one hard drive here, are using the NTFS file system.  So I get props for using NTFS and not having any FAT file system because NTFS, of course, has internal security that allows you to have access constraints on it.  Then I get a green check for the guest account.  The guest account is disabled on this computer, yay.  Then it says this computer is properly restricting anonymous access.  So I got a green arrow there.  And under administrators, no more than two administrators were found on this computer.  Actually I think there's probably only one.  I typically, my standard security practice is, as soon as I get a system set up, I delete the account that it forced me to make, and then I rename the administrator account to my own wacky, you know, nobody's ever going to guess this name, so that there isn't even an administrator account named Administrator on the machine, just because, you know, why not.  And it goes on.  It does basically, I wouldn't say an exhaustively thorough analysis.  But there are a couple auto-login and password expiration it skips because this machine - and it explains why, that the computer is not joined to a domain, which is...



LEO:  Oh, that's interesting.  See, on mine it says, you know, you turned on Autolog, because I am on a workgroup.



STEVE:  Ah, okay.



LEO:  That's interesting, huh.



STEVE:  Yup.  And then, you know, it shows, oh, I thought it was interesting, it said some potentially unnecessary services are installed.  And it's like, oh, that's, you know, I mean, that's a good thing.  Of course Microsoft installed them.  So it's like, uh, okay.



LEO:  Thanks.



STEVE:  Thanks.  And then it tells you how many shares you've got because of course over time you might tend to share things and forgot that you left them shared.  Gives me a status on IIS, which is their web server, which is available in XP Pro, but I have it either not installed and/or not running.  I think it probably installs it by default.  But I have it disabled because I went through and turned things off.  And the same thing for SQL Server.  And finally it looks at IE's zones and tells me that I've got them set up in a way that is making it happy.



LEO:  Yeah, because you have a very restrictive - on mine it says I don't have any zone settings for some users, and that's a security issue.



STEVE:  Ah, yes.  And mine says Internet Explorer zones have secure settings for all users.  So anyway, I wanted to bring this to our, obviously to our users', to our listeners' attention because it's free, it's not big, it's easy to run, and it's just, you know, one more useful check on things that, you know, again, like for example, you know, the firewall turned off, you left some shares on some folders that you no longer need, you turned on your guest account and you forgot to disable it even though you don't need it anymore.  So it's just a simple, easy way of sort of, you know, taking a little check on your machine, just sort of doing a little bit of an audit.



LEO:  So this is free.  It's from - if you Google MBSA, that's a quick way to find it.  It's the first thing that shows up.  And while you were talking I downloaded it and ran it, and it did, it pinpointed a number of things.  It even suggests, you know, it says click here to find out how to fix that, which is great.



STEVE:  Yeah, and again, it gives you - I really like that it gives you essentially a user interface into Windows Update.  Because so it's not just - it's no longer just, okay, I don't know what's going on, just go ahead and fix things, it allows - especially now that I'm, like, being reticent, well, actually I'm more than reticent to put Service Pack 3 on my machines after it hurt two of them.  So of like, uh, no, thank you.  So I just - I like the idea that there is a user interface to that.



LEO:  Yeah.



STEVE:  So that's the first of the two things.  The second one is very different.  They call it the Microsoft Security Assessment Tool.  And I sort of, as I was refamiliarizing myself with it, I thought, you know, this is a little bit like therapy.  This is like security therapy because it doesn't tell you what to do, whereas the Baseline Security Analyzer certainly does.  It basically asks you a bunch of questions.  And so the idea is, I mean...



LEO:  It is like therapy, isn't it.



STEVE:  It's just like therapy.



LEO:  How do you feel about this now?



STEVE:  And so, you know, it wants my company name, and I put in Gibson Research Corporation.  Number of desktops and laptops in use at your company.



LEO:  Wow, that's interesting.  Wow.



STEVE:  I said fewer than 50.  Number of servers in use at your company, and I said one to five.  And so that's like the first page.  And then it just basically takes you through the next status, is what they call a "business risk profile."  Does your company maintain a full-time connection to the Internet?  And so you've got, for all of these, yes, no, and I don't know.



LEO:  I got no idea.



STEVE:  And there's oftentimes a little question mark icon at the side.  And then, like, if you're not really sure, it'll say, like, such as a T1 or a DSL line, cable modem, or other always-on connection.  And so you say okay,  yes.  Do customers and vendors access your network or internal systems via the Internet?  So customer and vendors access your network or internal systems via the Internet.  And so it's like, well, yeah, we've got a website, for example.



LEO:  Oh, yeah, of course, yeah.



STEVE:  Does your company host application services such as a portal or a website or external customers or partners?  Yes.  And so you click that.  And so, for example, for that question, if I float over the little question mark it says, if you are hosting application services for customers or partners, there is an increased risk to the infrastructure due to the potential for data loss or threat or service unavailability.  So basically, I mean, and this is just the tip of the iceberg, this thing, you know, I spent, god, an hour with it.  And, I mean, the reason I call it therapy, and the reason I think it's a useful thing for our listeners, for Security Now! listeners, is in the same way that a therapist asks you questions that are, like, leading questions that cause you to think about yourself in a way you didn't by yourself, similarly this, you know, it asks you questions about how was your network segmented, do you use a VPN...



LEO:  Now, does it make recommendations based on all this, or is it, like, just trying to get information about your system?



STEVE:  No, no, if you finally - if you make it through this whole thing - and so there's like a first pass where you sort of characterize yourself.  Then based on the first pass answers it goes into the next level, which because now it knows enough about, like, the way your network and your company or your home, I don't mean to say that this is only of use for IT sort of people, anybody who's got a network at home could, I think, find these questions very interesting because in answering the question you kind of think, oh, I mean, it asks you about, like, do you use a router with a DMZ?  And so you basically go through a first pass where it gets a sense for who you are.  Then based on that collection of answers it goes into, like, it drills down to a next level of real detail about how your system is configured.  And when you're finally done, it gives you a report card.  It literally tells you, okay, here's the things that you're doing that you need to worry about.  These are areas where you really, you know, your policies need review.  I mean, and it asks you things like do you have an enforced password policy that requires you to change passwords periodically?  Now, of course, as with a therapist, you can say, uh, yes...



LEO:  I'd prefer not to talk about that if you don't mind.



STEVE:  Nobody's making you tell the truth.  You can lie to your therapist.  You can lie to Microsoft's Security Assessment Tool and tell it, oh, no, I never go to those naughty sites.  But if you tell it the truth, I mean, just the act of filling this questionnaire out I think is really illuminating and useful because, although I have to say most of what I found on myself being asking [sic], I was pleased to see that in our coming up on three years, we've covered everything.  I mean, it even...



LEO:  Oh, that's interesting.



STEVE:  It even goes through, if you tell it yes, like does your organization use wireless, yes, then you get a whole expanded box of, okay, which security protocols are you using?  And they're all there.  WPA, WEP, we run an open network block, but, you know, ooh, you don't want to even think about checking that one and seeing what it's going to do, it'll probably just melt down.  But it's - I think it's something that our users, our listeners will find really worthwhile.  Now, the downside is this thing requires .NET v2, which in itself is only...



LEO:  So this isn't just an online survey, which it, by the way, could easily be.  I mean...



STEVE:  That's a very good point.



LEO:  ...this could just be a questionnaire online.  You don't really need to download - but you do, you have to download something.  And you have to have .NET installed.



STEVE:  You have to have .NET installed.  Now, you know, Microsoft's pushing .NET.  I know there are people who are deliberately staying .NET free.  Long-term I think those people are going to lose because essentially .NET is the next-generation API for Windows.  And more and more things are requiring that .NET be there.  So...



LEO:  It doesn't hurt to download it.  If you've got Vista, you've already got .NET.



STEVE:  Precisely.  Well, that's a perfect example.  And this is why I set it up in a VM.  It was just like, I'm going to resist .NET till the bitter end, until I really need something on my main system that requires .NET.  And maybe by then they'll have, you know, we'll be at Service Pack 9 on .NET, and it'll actually be stable and not a big security problem.  Because again, like anything else that's new, Microsoft has had security problems with .NET.  So I just - I work not to put junk on my machine that I can avoid putting on.  So I installed .NET in a VM, and I ran this in a VM, knowing that I'd be able to...



LEO:  This cracks me up.  It's 12.5MB.  I mean, you just talked about SpinRite, which is so incredibly useful, is 100K.



STEVE:  Yeah, I ought to get the right size for that.  It's actually...



LEO:  I think it's more like 90K.



STEVE:  No, no, no.  It used to be 96.  That I, well, it used to be 64, used to fit into a COM file.



LEO:  Then it got a little too big, yeah, yeah.  Well, all I can say is 12MB for basically what is a questionnaire is absurd.  I'm running it right now.



STEVE:  Okay, 169K is SpinRite.



LEO:  169K.  So this is like, what is it, a thousand times bigger.



STEVE:  Now, yes, not so - well, okay.  The actual Security  Assessment Tool is 12.5MB.  .NET, however, is really big.  I think it's maybe up to like 68MB, something like that.  You know, it keeps growing.  They're now at 3.5 is the most recent one, which is the one that I installed.  But anyway, I wanted to bring both of these tools to our listeners' attention.  I think certainly the Baseline Security Analyzer, it's just nice to have it there.  It's small and lightweight.  I think it's 1.5MB.  Easy to run.  And again, it's just another little check on making sure that there's nothing obvious that you've forgotten, and as a really nice user interface into Microsoft Update and all of the endless, you know, the patch stream that we've got.  And then secondly, you know, this security therapist, the Security Assessment Tool...



LEO:  It's ELIZA.  It's ELIZA for security.



STEVE:  Well, except that this is just - well, yeah, I guess that's a good point because it's not quite as interactive as ELIZA was back in the day.  But what it takes you through is useful.  I mean, don't be in a hurry.  Just think about the questions.  Like do external partners or customers connect directly to your company's internal backend systems for the purpose of data access, record updates, or other information manipulation?  You know, it talks about what do you subcontract out?  What services do you get from the outside?  I mean, it really builds a threat and risk model based on these questions.



LEO:  And I could say this looks more like - this survey looks more like a marketing survey than anything else.  I'm giving Microsoft a lot of information about what I do.



STEVE:  Well, yes.  And I was a little skeptical.  I did skip that whole first fill out about - everything about your company and all that stuff.  You're able to skip right over that, and you don't need to fill that in.  And I was, as I was going through these questions, I was skeptical about are they spinning this in a pro-marketing, pro-Microsoft way.  And I have to say no because there were several places where the advice that I was being given was not pro-Microsoft.



LEO:  Well, that's good.



STEVE:  Yeah.  I thought it was, oh, I love "Does your company share office space with other organizations?"  You know, again, it's just...



LEO:  Yeah.  Well, that's legitimate, that's a legitimate thing to ask because...



STEVE:  Oh, no, that's...



LEO:  ...that means other people had physical access to your systems, and that's relevant, yeah.



STEVE:  Yes.  No, I think this is all legitimate to ask.  And again, I recommend this for our listeners.  I think, while a lot of it is more corporate oriented, it's also, okay, like - or, well, do you have roommates?  You know, that's the same sort of question.



LEO:  Right, right.



STEVE:  Brought down to a home level.  Does your roommate have access to your machine when you're not around?  So, I mean, it's these are questions that are really worth thinking about once.  And then you can just drop them, never think about it again.  But it'll push people to think about, oh, I know what the right answer is, but ooh, mine is not the right answer.



LEO:  Right.  Well, that's an important point, yeah.  All right, Steve.  A couple of - we'll put links to both of them, although it's easy enough to find them if you just look for Microsoft security tools on Google or your favorite search engine, your search engine of choice.  It's not hard to find.  But we will put links in the show notes to all of this.



Steve, you're at GRC.com, and I know that's a great place to go if you are a fan of the show because you'll find a variety of things there, including the 16KB versions of this show.  So if you've got not a lot of bandwidth and you want to download the show, or maybe a friend's on dialup who would like to get it, or you just want to put it on a floppy - would it fit on a floppy?  Probably not.  It might.  It might.  Go to GRC.com.  While you're there you'll see transcripts.  Lot of people like to follow along as Steve's speaking because frankly this is, as they were saying in the chatroom earlier today, an information-rich podcast.  There's more in this podcast per square inch than any other show on the Internet, including all of my shows.  So the transcripts help a lot.  We thank Elaine for making those transcripts.  And you can get them, and show notes, and links at GRC.com.



While you're there, don't forget to check out all of Steve's free security programs - ShieldsUP!, Shoot The Messenger, DCOMbobulator, Unplug N' Pray - he's really good at names.  And of course his bread and butter and the program we recommend every program is SpinRite, the world's finest hard drive maintenance and recovery utility.  Somebody in the chatroom asked can I use it on my solid state drive.



STEVE:  You do not want to use it on your solid state drives.  The technology is all about magnetic medium.  And a solid state drive is, as we've discussed on this show, is definitely sensitive to read and write cycles.  So there's no need for it because the kinds of actual physical recovery that it performs does not map onto solid state memory.  And it's bad for a solid state drive because you do not want to write, unless you need to, to a solid state drive.



LEO:  Yes.  So don't mess with your SSDs with Security Now!.  But if you've got a hard drive or a floppy, would it work - it would work on ZIPs, then, I guess, huh?



STEVE:  In fact it was v5.0's support for ZIP which started the whole "click of death" deal is we started, as soon as v5 came out of SpinRite, which for the first time supported ZIP and JAZ drives, those two Iomega technology drives, people were saying, hey, this is a cure for click death, it cured my click death.  And I said, it cured your what?



LEO:  What is that?



STEVE:  And it turned out that SpinRite actually, similar to it on Flash drives, you did not want to run SpinRite on a drive that had the so-called "click of death."  And that's why I wrote the free tool, Trouble In Paradise.  Which again, as I guess you probably - I think you did like the name of that one, as well.



LEO:  TIP.  Because it was TIP.



STEVE:  TIP, Trouble In Paradise, which was a free gizmo for Iomega users that properly assessed the status of their drives.  And we told people, no, don't run SpinRite on them, it'll just make a bad problem worse.



LEO:  And in fact that was how we first met was talking about the click of death and TIP, Trouble In Paradise, many moons ago now, Steve Gibson.



STEVE:  Many good moons.



LEO:  All right.  We're going to wrap this thing up.  Again, GRC.com for show notes and transcripts.  And we'll be back next Thursday and every Thursday for another episode of Security Now!.  Thanks, Steve Gibson.



STEVE:  Talk to you then, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#148

DATE:		June 12, 2008

TITLE:		Listener Feedback Q&A #43

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-148.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 148 for June 12, 2008:  Listener Feedback #43.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



This is Security Now! with Steve Gibson, the Wizard of Security, from his lair in beautiful Irvine, California, where it must be about 100 degrees once you get aboveground, out of the Fortress of Solitude; right?



STEVE GIBSON:  It was drizzling this morning, actually.  We've been having a really weird, like, I don't know if summer's ever going to get here.  I got a piece of solicitation in the regular paper mail yesterday from some air conditioning company that had over-purchased air conditioners.  That was their come-on, anyway.



LEO:  We bought too many.



STEVE:  We thought we were going to be installing air conditioners in '08 summer, but we're not, so we're going to give you a thousand dollars off.  It's like, okay, well, that's kind of believable.  And they said they had 11.  They had 11 too many.



LEO:  Send them my way.  I could use an air conditioner.  It's hot up here.



STEVE:  Not down here.



LEO:  It's got to be in the 90s, believe it or not.



STEVE:  Beautiful day out.



LEO:  It is, it's a beautiful day except I'm inside.  So let's talk a little bit about our listener questions and answers.  We're going to do Episode #43 Feedback.  We've got some great questions from people all over the country.



STEVE:  Yeah, we got a neat variety today.  Some are long; some are short.  It probably balances out to about what's usual.  But there was a lot of good stuff in my mailbag.  People went to GRC.com/feedback and sent us stuff, as I always want to encourage people to do.  I read as much as I can.



LEO:  Including a "Looming Threat Observation of the Week."  But first, before we do any of that, let's get an update on the news, security news, around the world.



STEVE:  Some interesting things in security.  First of all, we're recording this on the monthly Tuesday, the second Tuesday of the month.



LEO:  Patch Tuesday.



STEVE:  Patch Tuesday, Microsoft's Patch Tuesday.  So unfortunately the update details are not available.  I do know because they now release a week ahead of time, they tell us sort of a broad stroke what's coming.  There are three critical updates, and I'm most interested in one which involves Bluetooth because, of course, being radio and with many Bluetooth adapters on laptops, that's of a concern.  So, well, not only laptops but, you know, portable Windows devices of various sorts.  So there's three critical updates:  Bluetooth and IE and DirectX.  On the other hand, when wasn't there a critical update for IE?  And even DirectX has been having lots of problems.  The good news is the BSA, the MBSA, the Microsoft Baseline Security Analyzer that we talked about last week, will inform any of our listeners whether their updates are needed.  All three will require rebooting your system, so it's something that you may want to plan for.  By the time you hear this it'll of course be Thursday, and this'll be two days ago for you.  So the information will be there.  Windows Update will probably know.  But specifically because there is a radio-based critical remote code execution problem somewhere.  I don't know as we're recording this where.  But it does sound like something that our listeners are going to want to make sure they get patched.



LEO:  All right.  Run your patch system if you haven't already.  And I turn mine, automatic patch is on.  Do you do that?  I'm just curious.



STEVE:  No, I don't.  I've got mine set to download and hold.  So download and ask me.  For example, I don't want SP3.  SP3, Service Pack 3 for XP, has caused me two separate sets of problems.  And my tech support guy, too, Greg.  And by removing them in all those cases the problems went away.  So I've confirmed that it was SP3 that did it to me.  It's like, I'm not in a hurry to go there.  Although Microsoft, every time I check they're saying, hey, you don't have SP3.  It'll be good for you.  It's like, uh, no, I don't think so.



LEO:  I installed it on one machine, and it was actually smart enough to back out.  Said oh, problem, and then backed out very nicely.  And then I put it on a - I had it on a - XP SP2 on a virtual machine on my Mac, and it installed just fine, flawlessly.  Then I immediately made a safe point in VMware saying might want to go back to this point.  So...



STEVE:  Well, and it's certainly the case that not everyone is having problems.  These things seem to be very anecdotal.  But I have this, as I said a couple weeks ago, items in my Start menu stopped responding to the mouse.  And it's like, okay, going into Windows Explorer and double-clicking on the EXE is really not very user-friendly.  So I decided I don't need Service Pack 3 for the moment.



Another very important problem for Skype users is an interesting one.  Apparently it's only Windows versions of Skype, although I didn't see that explicitly reported.  Although I say that because the Mac version of Skype I've got is down at 2.7.something.



LEO:  Yeah, yeah, it's way behind, isn't it.



STEVE:  So this is relative to any Windows version prior to 3.8.0.139.  There has been a vulnerability discovered which allows some Skype user to send another Skype user a link which is executable, but it bypasses Skype's executable verification, which would normally warn you before you were going to click on an executable.  So this would allow someone to send you a link masquerading as something else, causing you to run the program on your machine.  So, I mean, again, it's as long as you're not using Skype, or if you only Skype to people you really know and trust, probably not a big problem.  But it is something that has come to the security community's attention.  And it's been fixed.  So as long as you're at .139 and later, 3.8.0.139, you're going to be okay.



LEO:  Good to know.



STEVE:  Now, the last thing is really interesting.  Probably by now people have heard Microsoft saying not to use Windows Safari.



LEO:  Yes.



STEVE:  Yes.  And the reason for this is just freaky.  Okay, so there's a problem, a known problem with Safari on Windows.  Apple knows about it, and their initial reactions were that's not our problem.  Okay.  So what Safari does, Safari has always, both on the Mac and this behavior moved over, well, stayed with Safari when it was ported over to Windows.  And that is, it will allow web pages to download programs without user involvement or confirmation.  So, I mean, to me that doesn't seem very secure.  But...



LEO:  It doesn't execute them, it just downloads them.



STEVE:  That's what I'm saying.  So that means you could go to a web page, and that web page could, without your user involvement, download a file to your machine.  Now, that seems like a bad idea.  But that's the way Safari has always  been.  Okay.  The default directory for downloading on Windows versions of Safari is the user's desktop.  So the first thing that happened was someone realized that - a security researcher called it "carpet bombing."  You could go to a malicious website, a Windows Safari user could go to a malicious website that would "carpet bomb," to use his term, your desktop with files.  And, you know, which is certainly annoying.  Okay.



Then it turns out that a sort of a mistake in the design of Windows interacts with this. Therefore in a security standpoint, or in security jargon, we call it a "blended threat" because Safari by itself can just download the file without user involvement, but won't execute it.  Unfortunately, Windows will.  So what happens is that, when Internet Explorer runs, it loads a number of DLLs into itself, which it finds on the system in various places.  Now, the problem is, and this is an old security problem with Windows from years ago which was known as the "DLL search order," that is, the order of subdirectories that would be searched when DLLs are loaded.



There are three DLLs:  sqmapi.dll, imageres.dll - image resources - and schannel is a secure channel .dll file.  Well, it turns out that if you don't have Windows updated with so-called "secure DLL search order" - and it wasn't until Service Pack 2 that this was set by default to be on, and it's not clear to me if you upgraded to Service Pack 2 whether it would turn it on.  That is, remember there are many things that Microsoft left alone when you went to  Service Pack 2.  For example, if the firewall was off, it wouldn't turn it on.  But if you installed from scratch the Windows with Service Pack 2, then it was turned on.  So there were a number of things like that.



So the problem is you could use Safari to - a Windows user using Safari goes to a bad site which puts, for example, schannel.dll on your desktop.  And you don't noticed that it's arrived, for example.  Many people have cluttered desktops.  So one more little icon it's like, oh, well, I'll get around to cleaning this up later.  Then you later run Internet Explorer.  Well, it turns out that the non-secure DLL search path includes the path where it's first - the first place that DLLs are searched for is the directory that the program itself is loaded from.  So it would look in IE's own directory where the IE executable is.  However, these things live in the system32 directory, that is, these various DLLs do.  So if it's not found there, it goes through a series of directories.  The second directory which is checked is the directory from which the app was launched.  Well, most people launch IE from their desktop.  So the second...



LEO:  Oh, that's interesting.  So it would look on the desktop.



STEVE:  Yes.  And it would find the schannel.dll which was deposited there by someone using Safari.



LEO:  Is that why Apple says it's not our fault, it's Windows's fault?  Is that because it shouldn't be doing that?



STEVE:  Yeah.



LEO:  It shouldn't have the desktop in the path or whatever?



STEVE:  It's very creepy.  I mean, yes.  The DLL search order problem, again, it was something that - Windows has always done it.  At some point someone said hey, you know, Microsoft, this is not a good idea.  And so they said, uh, you're right.  But they were worried, as they always do, and we understand this, that if they change something fundamental to the system like the order in which DLLs were loaded, lord knows what side effects that might have.  So...



LEO:  But I have to say Apple's - that's passing the buck because this is not good behavior regardless of that.



STEVE:  Correct.  So the workaround, Microsoft gently says we sort of recommend maybe that you not use Safari.



LEO:  I think this is a little sniping, don't you think?



STEVE:  Well, you know, and I was curious because the various news reports were, like, in bold print.



LEO:  Microsoft's known...



STEVE:  Yeah, Microsoft warning people not to use Safari.  Okay, so I looked at the actual jargon, the actual verbiage on Microsoft's site, and it's very gentle.



LEO:  It doesn't say don't use Safari.



STEVE:  Not at all.  I mean, well, it gently says that.  All you have to do if you're a Safari user on Windows is have your files go somewhere else.  Create on the root, for example, SR, you know, Safari download, or put it wherever you want to, under My Documents or something.  And then change the default in Safari so that that's where files are downloaded by default.  And then if anybody - if you go to a  malicious site it'll just go into that directory, which will never be searched for DLLs.  So it is the case, this is a little bit of a - it's blended, and so is the responsibility.  I don't like the idea of a browser not prompting me to verify that it wants - that I want it to download a file.  I'm glad that that has been added in IE7 very clearly, where you're really prevented from that.  But at the same time, you could say, okay Windows, that's just bogus that you're going to run files that I might have on my desktop.



LEO:  Shouldn't do that.  And Safari shouldn't be doing what it's doing.  And one of the researchers said you can use this for a, quote, "carpet bomb" attack, which is not a security risk, just really, really annoying.  You can go to a web page that just loads up a ton of files onto your desktop, you know, hundreds and hundreds of files on your desktop.  That's just annoying.  But I think that's a clear flaw.



STEVE:  Yeah, I agree.



LEO:  They should fix that.



STEVE:  Yeah.  I think it ought to be, well, I would like to see Safari changed so that you have to give it permission before loading a file on your computer.



LEO:  You know, Safari has been a problem on the Mac side as well because it would open files that it considered non-dangerous files.  And so somebody showed how this could also cause a security flaw.  And they changed that behavior.  I think it's just a matter of time before they fix Safari on Windows.



STEVE:  Yeah, well, as a consequence of Apple not having been in the crosshairs of hackers as long as Microsoft has been, there are some...



LEO:  Right, they get away with stuff.



STEVE:  Well, yeah, they don't have the maturity of understanding...



LEO:  The paranoia.



STEVE:  ...that anything that can be done, will be done.



LEO:  Right.  Some would say that's paranoia and not maturity of understanding.  But it's exactly the right point of view.  Now that the new iPhone is out I think that this maybe makes us understand a little bit better why Apple was so anxious to get Safari on Windows because the new iPhone has enterprise-grade kind of synching for Windows, as well.  And it looks like there's features that you're going to want to use Safari for.  So and I think Microsoft probably also resented a little bit Apple's pressure on Windows users to install Safari, remember with that update.  You've got to update Safari even if you didn't even have it.



STEVE:  Yeah.  Well, and there were, as I understand it, there was, like, they're trying to get you to load more of their Windows stuff ever you do anything.  One last comment about the iPhone and the iPod Touch both.  I wanted to mention to any of our - I don't know if I want to call them "fat-fingered listeners."  But ThinkGeek just came out with a stylus that works on the iPod Touch and the iPhone.



LEO:  Really.  Because, now, that's a capacitive screen, so you need to use your - normally you need to use a live human finger to do it.



STEVE:  Exactly.  For example the Palms use a film screen that is a resistive technology, so you can tap it with your fingernail or the stylus or whatever you want.  The iPods are a capacitive technology, so you can't use, for example, the eraser end of a pencil.  It won't work.  And recognizing this, some enterprising company came up with a stylus that does work.  And so it solves the problem of typing on the keyboard, which is my main gripe with those is that the keyboard's just unusable.  Elegant as the result is, it's like, okay, I want my little two-thumb keyboard, please.  Like the Treo and the Blackberry have.



LEO:  And that's really - that was really the reason I use a Blackberry, not the iPhone, is the keyboard.



STEVE:  Yeah, it's impossible.



LEO:  Any other tech news?



STEVE:  I have one interesting, well, an interesting SpinRite report.  This is not a testimonial.  And the reason I chose it was that he asks a question at the end which I think our listeners will find really interesting and which I remember, believe I remember feeling was really interesting when I first heard it.  This is Philip Le Riche.  He said - the subject is, "SpinRite Fails Again."  And it's like, okay.  And he says, "Hi, Steve.  SpinRite failure stories seem to be the flavor of the month recently."  And I'm thinking, okay, I don't know if that's such a good trend; but, you know, that is the case.  We've been having some fun with the "SpinRite didn't work for me" stories.  Although typically it's not SpinRite's fault.



LEO:  Well, there's a good reason, and there's always a happy ending, I might point out.



STEVE:  And he says, "And now it's SpinRite floppy tales."  He says, "Well, here's one that combines the two.  I'm one of those people Leo can't understand who still uses floppies."



LEO:  I can't understand that.  I just don't get it.



STEVE:  "In fact, because I need them for data transfer between two systems for which USB memory sticks are prohibited by policy."



LEO:  Oh, interesting.  However, what a silly policy if they still allow floppies.



STEVE:  Yes.  Well, actually he even anticipates you saying that at the end of his note.



LEO:  Okay.



STEVE:  He says, "A few weeks ago I popped a floppy into my trusty old USB floppy drive and got the dreaded 'This diskette does not appear to be formatted.  Would you like to format it now?' message.  Another floppy gave the same result.  However, only a month or two previously I'd finally caved in, after some 60 episodes of Security Now!, and bought my own copy of SpinRite."



LEO:  Yay.



STEVE:  "So I was glad for the chance to try it out when in need.  I hibernated my PC, booted into SpinRite, and set it to work on the floppy.  But I was disappointed.  Almost immediately SpinRite came up with a message, the precise wording of which I have since forgotten.  But the sense of it was that my floppy was not just dead, but as good as fossilized."



LEO:  Well, that's why I don't like floppies, because that happens a lot.



STEVE:  Well, SpinRite is normally effective in this case.  Well, we'll find out why it didn't work here.  He says, "Rarely do I miss a chance of taking something apart.  So I got out my screwdrivers and opened up the floppy drive.  The problem was immediately apparent.  One of the heads had fallen off its carrier and was just dangling by its leads."



LEO:  Okay, now I understand.



STEVE:  He says, "Expecting SpinRite to cope with that..."



LEO:  That's a little much.



STEVE:  "...would indeed be a bit much."  He said, "It looked relatively easy to remove the carrier, superglue the head back on, and put it back together again, provided there was some kind of detent to ensure correct head alignment.  Unfortunately, there wasn't, with the result that..."



LEO:  Floppy drives cost $4.  I'm sorry.



STEVE:  "...with the result that SpinRite still reported my drive as fossilized.  So I had to order a new one.  I'm left with one question."  And here is his question.  "With CD drive speeds now at around 52x, how is it that it's taken 20 years for me to find even a double-speed floppy drive like this smart new one of mine?"



LEO:  Yeah, that's a good question.



STEVE:  Then he says, "Thank you for SpinRite and for Security Now!.  Never before I started listening had cutting the lawn been such a pleasurable experience."  Then he signs off, "Best regards, Philip.  P.S.:  I can almost hear Leo asking, what's the point of a policy that disallows USB memory sticks, but..."



LEO:  He knows me too well.



STEVE:  "...but permits USB floppies?"



LEO:  Yes, and?



STEVE:  He says, "Well, at least with a floppy disk containing sensitive data, if you want to dispose of it, you can open it up and drop the floppy bit in a shredder.  And not many USB sticks have a read-only reset switch so you can be quite sure no sensitive data leaks when you import from a less trusted system."



LEO:  I should point out, and he even kind of raised this issue, that most CD-ROMs now are 20 times faster than floppies.  You just have a read-write CD.  And you can get shredders that will shred CDs, so.  [Indiscernible] do that myself, personally.



STEVE:  Now.



LEO:  Yes.



STEVE:  Why don't floppy drives go any faster?



LEO:  Yeah, why don't they?



STEVE:  When IBM, who is the originator of the original big old eight-inch - was it eight or 8.5 inch?  I think it was eight-inch diameter floppy...



LEO:  And those were actually floppy.  They really flopped.



STEVE:  Yeah, they were floppy - oh, I see what you mean.



LEO:  They were floppy.  That's where the name came from because they were flippy-floppy.



STEVE:  They had a soft outer shell in addition to the Mylar doughnut that was inside, correct.  Get a load of this.  IBM was running those at the maximum speed possible for the head to stay in contact with the medium.  It turns out that you start to have aerodynamic effects if you go any faster than the original floppies did.  And so because of the whole technology basis is a head in contact with the Mylar, instead of flying over - now, remember the Bernoulli Boxes had the heads flying.  They were soft media, but they deliberately spun them fast enough so that the head would fly over the surface.  And of course all hard drives operate on that technology.  But floppies have always been a head in contact with Mylar technology, and you can't spin them any faster or the heads take off and fly.  And then, again, even SpinRite won't be able to save you.



LEO:  Although probably at some point some engineer, as you say, said hmm, flying heads, interesting idea.  Maybe we can use that.



STEVE:  Well, I think what happened - oh, you mean, like, and then they went into...



LEO:  Then they made hard drives, yeah.  Although, now, when IBM made the eight-inch, I mean, they were doing Winchester drives probably at the same time.



STEVE:  I don't really remember the sequence of events, yeah.



LEO:  Are you ready, Steve?



STEVE:  I'm ready.



LEO:  It is time to ask you.  This is from Dustin in Raleigh, North Carolina.  Dustin offers a useful USB thumb drive reminder.



STEVE:  Wait, what are we on?



LEO:  Oh, wait a minute, that's 11.  We'll save that.  Here's Aaron in Union - Steve's going, what page are you on now?  I went out of order.  I saw "1," and I said that must be it.  Aaron in Union, New Jersey has a self-conflict resolving NAT router.  Huh?  Steve, I've been listening to you and Leo since Security Now! #1.  I like to think I'm absorbing all of this wonderful and useful information, especially since I'm taking a collegiate summer course in computer security.  But in all that time I never heard of anything quite like this.  Ready?



He says:  I have Verizon DSL, and in effect I have two routers, a Linksys Gizmo provided by the now-defunct SunRocket - that was a Voice Over Internet provider, a very good one, went out of business - which connects to the outside and DSL, and a Pre-N Netgear router.  I wanted to take the Gizmo off my network since it no longer serves a purpose - he's not using SunRocket anymore - and it's not completely stealth, unlike my Netgear.  Anyway, the Gizmo was set up to be the dialer into the DSL.  He was using the Gizmo to do the PPPoE.  So when I typed 192.168.1.1 to access the login for my Netgear, the router page told me that, due to some conflict with Verizon, my router is now 10.0.0.1.  I thought I remembered you saying that 192.168.1.1 couldn't conflict with any ISP's IP range.  I was also unaware that my router could so easily change its local IP settings, so when it does DHCP magic it now pulls from the 10-dot range.  Are there any security implications?  How is this possible?  Is it common?  Help me, Steve, help me.  What's happening there?



STEVE:  Well, I was very impressed to hear, first of all, that the Pre-N Netgear router would automatically recognize that the upstream net range was conflicting with what it was going to be assigning to by default downstream.  In other words, what happened was the first router that he's got on the Internet, that is, the Internet-facing router, is his DSL router, this Gizmo, as he calls it.  It was taking whatever ISP assignment he had of IP and no doubt translating it through NAT, Network Address Translation, into the common 192.168.1.1 network.  So apparently when the Netgear, which was connected downstream of the Gizmo router, when the Netgear saw that the WAN side was 192.168.1.1, it was smart enough to recognize that it could not use the same subnet, the same network range on its LAN side if it was going to properly perform Network Address Translation because you need non-overlapping networks in order for the routing in the router to understand whether the packet stays local or needs to cross into the outside world.



So anyway, I'm impressed with the Netgear.  What it apparently did was when it saw that its WAN side had a private IP address - which is what 192.168.x.y are, those are private IPs that will not be ever used on the public Internet because there's no routing information for them, there's nowhere for the packets addressed to those destinations to go.  So when the Netgear inside router saw that the outside was already a public IP - I'm sorry, was already a private IP, that 192.168.1.1, it chose 10.0.0.1, for example, as its own internal address.  So I'm impressed with that.  And really...



LEO:  I think all routers do that.  Here, I'll tell you what happened because I've had this happen to me many times.  If you don't say to the second router bridge, if you say assign IP addresses, it's going to take it from the other pool.  It's going to take it from the 10-dot pool.  It's happened to me every single time.  So what he's got is he's got both routers doing DHCP.



STEVE:  Okay.



LEO:  So the Gizmo is doing DHCP, well, most of my routers, when they see that they're also being asked to do a DHCP, they say, oh, well, I guess I'd better use 10-dot.  Because otherwise you will have IP address conflicts, won't you?



STEVE:  Well, I guess maybe I'm just older than I thought because I've run across...



LEO:  You've never seen that?



STEVE:  No, the routers that I've encountered have to be manually reconfigured into another range if their ranges overlap.  For example, you might have two routers that both want to use 192.168.0.0 to 50 or 0 to 100.  And so you can set the second router to be .1.0 to 100.  They don't have to be, like, move over to 10-dot.  They just have to be non-overlapping ranges.



LEO:  The best thing to do, though - well, actually I'm curious.  I'm going to give you a follow-up question.  Generally what I'll do, if I have one router doing DHCP, say this Gizmo, is like I put the second router into bridge mode.  I say don't do DHCP, let guy number one do it.  Then you'll never have any IP address conflicts.



STEVE:  And then I don't know why you would have a second router.



LEO:  For WiFi.



STEVE:  Ah, okay, yes, absolutely, I mean, that would absolutely make sense.  So, yes, you could use it, well, you could either have it bridging or convert it into a so-called "access point" so that it's not doing any NAT at all, it's just...



LEO:  Or vice versa.  Sometimes I have routers attached to WiFi routers as the front end.  But, now, here's the question.  Is double DHCP, as his system is doing, both systems are doing DHCP, is there anything wrong with that?  Is that a bad idea?



STEVE:  No, there's nothing wrong.



LEO:  Doesn't slow things down or anything like that.



STEVE:  No, essentially it means - when you say "double DHCP" it means that the interior router asks on its WAN interface to the exterior router, give me an IP.  And so it received 192.168.1.1, for example.  And then machines on the inside, on the actual LAN, they asked the inner router for an IP.  And the inner router, knowing that it could not have IP ranges conflicting, it jumped over to 10-dot.  Which, I mean, and it makes sense because, okay, for two reasons.  First of all, we do have people who are now stacking routers, as this guy was.  And most people plug them in and just set them and forget them.  So having that function automatic makes sense.



There are also ISPs who are issuing public, well, they're issuing their subscribers private IPs.  So you might, for example, not from your router would you receive a private IP, but from your ISP, that is, on your ISP's network you would have a private IP because your ISP is running their own NAT router.  And so they're NAT'ing all of their subscribers, moving them to private IPs because they may not have enough public IPs in order to give all of their customers their own individual public IP.  And in that case that would explain why routers now are smart enough.  Because if they see that they've received a private IP that's conflicting with the range they were going to assign, they'll just jump over to a different range.



LEO:  So the problem would be if you had this Gizmo both attached to another router and attached to another computer.  And then it might assign the second computer something in the 192 range, and then the second router might assign a different computer, not knowing that there's a computer in that range of the same number.  And then you'd get a conflict.  So that's sensible behavior for the router to do this automatically.  Of course, if you put a third router on it, then you'd really be out of luck.  That's why I just say put it in bridge mode.



STEVE:  Actually a third router would work.



LEO:  Well, you'd have to tell it, okay, don't use 192.



STEVE:  Well, no.  It would, if you have a...



LEO:  Because we're out of private ranges, though, aren't we?



STEVE:  Yeah, but you can ping-pong back and forth.  So if you had a third router, that could be back to 192.  It would translate it at 10, and back to 192.  I mean, it'd be confusing, but it would all work.



LEO:  And overhead is not a concern of something like that?



STEVE:  No, these are all very fast.  So, but he's certainly right.  I would get rid of the Gizmo and tell the interior router, if it's able to do PPPoE and connect you via DSL, then you'd get - apparently it's just a nicer router.



LEO:  Here's another reason people often have dual routers on there.  A lot of times the cable company or the DSL company gives you a modem that has a built-in router.  And you, for whatever reason, may not want to use that router.  That's, I think, our setup here.  We're using an 802.11n router that's attached to Comcast's modem/router.  And in that case, I think in that case - I should check.  I think we're bridging.  But bridging just means don't do the NAT, just pass through.  But it would be okay for us to have it be doing routing as long as we don't have a setup conflict.  And as you say, you can often in the router say, no, still use 192.168, just start at 200, 1.200, and avoid conflicts that way.



STEVE:  Or just 192.168.2.1.  Or 0.1, 1.1, 2.1.  Because normally these routers will only NAT within the lower byte.  So, for example, it looks like 0 to 50 or 0 to 100.  And so as long as you change even the second digit, then you still have something that's clearly recognizable as a private IP.



LEO:  And to answer his question, he was right, 192.168 and 10.0 both are private, can't conflict with anything outside of your LAN.  And there's no security implication to what it did.  In fact, it's a good thing.



STEVE:  Yes, it's secure, good.



LEO:  Brian in Raleigh, North Carolina wonders, how can all possible bit combinations, every possible bit combination, be reduced to a 32-digit MD5 hex hash?  Steve, Steve, how can that hash uniquely identify any of an infinite number of bit combinations?  16^32 equals 10^38 possible combinations that a 32-hex-digit MD5 hash can represent.  But a 700MB file, as your average CD image, has 2 - oh, do I have to read this?  2 to the - he didn't even put in commas.  2^587 - oh, let's see.  58 billion, 720 million, 256 - anyway, there's a lot.  It's a high number possible combinations.  Since the latter is much greater than the former, how are the collisions avoided?  So what he's talking about is how these MD5 hashes, these 32-digit hashes are used to represent the contents of a file uniquely.



STEVE:  Right, yeah, exactly.  He's seeing, for example, that somebody will, maybe a Linux or a UNIX distribution site, will post ISOs, that is, ISO images of CDs.  And they'll say that the MD5 hash is blankety-blank.  And so there's an MD5 hash, as he says, is 32 hex characters.  The idea being that you download the file.  Then you perform your own local MD5 hash.  And you should always get the same result as they have posted on their website, which is the result they got when they used the original file, the advantage being that you're able to verify that nothing has changed in the file.  So he says, okay, if you've got 700MB of data, which the hash somehow reduces to this just little 32 characters of hex, how is it possible that all of those possible bit combinations in a 700MB file don't have any collisions?  How are collisions avoided?  Well, he used the term "avoided" as opposed to "prevented."  So we need to get into semantics a little bit.  Brian is absolutely right that there is no way to prevent collisions, that is to say, many, many, many different combinations of bits in that 700MB file will all result in exactly the same hash.  So it is not an absolute perfect fingerprint for the file.  The only way you can get that is doing a byte-for-byte comparison of the original file.



LEO:  However, it's a long number.



STEVE:  Yeah, the hash has been - the hashing algorithm, the thing that makes it cryptographically secure, is that it is computationally infeasible, as the crypto guys put it, to deliberately...



LEO:  Ah, there's the key.



STEVE:  Yes, to deliberately create a fraudulent 700MB file which will hash down to exactly the same thing.  So the risk would be that somebody could deliberately make - some hacker could create a malicious ISO image and stick it on the website, assuming they didn't also have the ability to change the hash, and I guess they probably would.  Or, you know, or give you an ISO image and say, hey, this is a valid image, trust me, you can do the MD5 hash and check it against the publicly posted MD5 hash, and it'll be the same.  The point is that it is not feasible to design a file which, when hashed, has any arbitrary given result.  And so that's what's being protected.  That's what's being prevented.  And given that we've got 10^38 possible combinations, that is, that many different possible hashes, you know, that's 10 with 38 zeroes after it.  The point is that it's statistically unlikely that any non-malicious change would go unseen.  That is, there would only be one chance in 10^38, essentially, that a mistaken change during download would change the bits of the ISO such that it still gave you the same resultant hash.  It's possible, but one in 10^38 makes it incredibly unlikely that that's going to happen.  So it both prevents with a high degree of reliability a random change from going undetected, and specifically it protects from anyone malicious designing a file that's going to be the same length, but changed in a way that gives the same hash.  You just can't do it.



LEO:  It's just impracticable. 



STEVE:  Yup.  Computationally infeasible.



LEO:  I like that.  That's a good phrase.  I'm going to work that into conversation sometime.  I don't know how, exactly.  Sande Nissen in Northfield, Minnesota worries about the PayPal browser plug-in.  That's the one we've been recommending that will generate for you one-time-use credit card numbers, among other things.  PayPal has a new web browser plug-in that offers some useful services.  Over the years I've been pleased with PayPal's privacy and security and their dispute resolution.  But a browser plug-in?  What?  Given how buggy browsers are, is there any way this new tool could really be secure?  I'd love you to take a look, Steve.  Sande.



STEVE:  Well, I took mine out.



LEO:  Oh, you're kidding.



STEVE:  No.  Not for any security reason.  I was just - it was just dunning me constantly.  Any time I went to a...



LEO:  I don't like toolbar add-ons.  I never install those.



STEVE:  Well, it's worse than that.  This thing, I mean, it's just a little "P" for PayPal, a little icon.  Except that any time you go to a page that has forms, even when you're not buying stuff, if it happens to see, like, a field with "Name," this thing descends down from above in this little, you know, would you like me to fill this in?  No, go away.  I mean, I tried to disable it and turn it off and reconfigure it.  It doesn't seem to obey its configuration settings, if I even understood the way they work because - and then you have to go back over to PayPal's site and say no, I don't want this dumb thing descending from above every time I visit a page that has a form where it says, oh, we can fill in your shipping address.  We can fill in your billing address.  Just leave me alone.



So I finally said, okay, I've had the plug-in experience, I don't need it anymore.  If I need to get a one-time credit card from PayPal, I'll just go log into PayPal and get it there.  So I sort of agree.  On the other hand we've got password plug-ins, and who knows if someone will come in with an exploit.  It is the case that you still have to authenticate yourself every single time you use this.  And if you've got the football, which for $5 I don't know why anybody wouldn't have one of the VeriSign/PayPal/eBay authentication footballs or credit cards, you can require that that be used every time to really prevent any sort of shenanigans.  So I sort of agree.  For me it wasn't a matter of security, it was this thing was just too incessant.  And I finally said I'm always trying to get rid of this thing rather than wishing that it were present.



LEO:  It would be nice to have the auto-generate of the credit card numbers.  But I just do that on the PayPal site.  The one thing I've found, Amazon keeps saying your credit card - I made a multiuse one.  And Amazon doesn't like it for some reason.



STEVE:  Oh, interesting.



LEO:  Because you have two choices, as you pointed out.  You have two choices.  You can make a one-time only, which is really the most secure.  It can only be used for one purchase, and then it's no good.  But if there's sites like Amazon where you buy from a lot, you can make it specific to the site.  But it doesn't expire, it just continues working, but except it doesn't seem to.



STEVE:  I did have a nice experience.  I remember mentioning on the podcast that I used the PayPal one-time card on a site where they were really pushing for, like, a subscription sort of deal, and there was no opportunity to turn it off.  I didn't like the idea that they were going to have my credit card information because I just didn't like the way they were behaving.  And I noticed that the card, whenever you get it, it shows an expiration date of the following month.  And so even your one-time-use card, here we are in June, so if you were to get a card now, it would say that it expires in July of 2008.  So sure enough, I got email like a week later saying...



LEO:  Your card's about to expire.



STEVE:  Yes, we wanted to notify you, so you don't miss any of our valuable services, that the card we have on file is about to expire.  Please come back and update your credit card information.  I was thinking, I don't think so.



LEO:  Yeah, I mean, I'll just keep using the one-time thing.  The one-time thing is great, and it is the more secure because it could only be used for one purchase.  Let's see.  [Curtis] Wyatt, Phoenix, AZ, got the job.  He got the job:  Steve and Leo, I recently graduated from NMSU with a Bachelor of Science in Computer Science.  I went on some interviews with a government contracting company.  In the course of the interview it was explained to me the particular job that I was applying for focused on security, and specifically encryption.  I was asked a few questions, and thanks to your podcast I was able to explain the difference between asymmetric and symmetric encryption.  He didn't learn it in school, but he learned it on our show.  The interviewer was apparently impressed enough to give me a job.  Well, today was my first day.  And after recognizing what TPM is in laptops, my supervisor was impressed, as well.  Thanks, Leo and Steve, from a longtime listener.  That's nice.



STEVE:  I just thought that was a neat little note, yeah.



LEO:  That's really nice, yeah.  I'm sure that they must have covered that.  You probably took the day off in computer science class.



STEVE:  A little refresher always helps.



LEO:  I think one of the things that you do so well is, because we're focusing on just one topic often, you're able to really explain it thoroughly in a way that everybody can understand, and it sticks with you, as opposed to when you're studying this stuff in school it just goes and goes and goes and there's a lot to remember and stuff.  So I'm sure they covered it.  But he remembered your discussion.



Al in Lowell, Mass. was asked an interesting question:  Hi, Steve, I love the show, he says.  This isn't a question about a problem I'm having or anything like that.  I consider myself very well versed in networking and the Internet in general.  But a friend asked me a question I had never really thought about, and I couldn't come up with an answer.  So I present it to you.  Do you think the Internet and all of its protocols, like IP, TCP and so forth that we know and love, will be phased out at some point in favor of more secure protocols?  One of your earlier episodes was on the social implications of Internet anonymity and the bad guys having access to the same encrypted communications the good guys have.  Do you think this will ever change?  Is there a way to protect digital rights and fight piracy without infringing on people's privacy?  In our current model the answer is no.  But may this ever change?  As long as the government doesn't seize all personal computers, we'll always have the ability to maintain our current Internet model.  So a new one would have a hard time replacing the old one.  It's an interesting question.  If you have any opinions on the matter, I'd love to hear it.  So would I.  What do you think?



STEVE:  Yeah.  Well, we're seeing an evolution, certainly.  The whole IPv6 standard which exists now and is sort of trying to move to the forefront, although it's not being adopted with any great speed, it for example does incorporate security, like encrypted communication security, in the base protocol, which the original TCP/IP, the original Internet protocols did not have.  Things like IPSec and L2TP and SSL running over TCP, the things we've talked about in this podcast, those are all sort of optional afterthought add-ons that were sort of grafted on afterwards.  And the main protocols we use, like HTTPS, like POP and SMTP and IMAP, for example, these are nonencrypted protocols by default.  There are people pushing for encrypted versions of those existing protocols to be used.  And also, as I said, IPv6 incorporates really good end-to-end encrypted security in the base protocol.  So if you have IPv6, although you're able to have nonencrypted communications, part of the support for the spec means that you will also have good, strong encryption available.  So it certainly is the case that over time we're moving in that direction, although because as Al mentioned, you know, the protocols we have today are functioning, and they do work, there isn't...



LEO:  They don't work well, but they....



STEVE:  Yeah, they work well enough.



LEO:  Actually they do work well.  I mean, in a way it's a remarkable system.  You know, there is an initiative going on at Stanford, they call it the "Clean Slate Internet Initiative."  And the idea is, if you were to redesign the Internet, if knowing what you knew now you were to set out to design the Internet, what would you do differently?  And it does address all of these issues.  You know, in fact, if you go to the website, which is cleanslate.stanford.edu, they've got articles on all this, including "The Future of TCP:  Train Wreck or Evolution?"  That's one of the articles.  And so, I mean, it's a really interesting question.  Our listener raises the most important question.  Given, you know, let's say you did come up with a better - it wouldn't be too hard to come up with a better solution.  How do you implement?



STEVE:  Well, and for example we've talked about all of the various extensions which have been made to TCP, for example, over time as the world changed.  I mean, the original protocols have turned out to be surprisingly robust and able to have extensions added to them in a forward-looking, backward-compatible way.  So, I mean, I'm impressed that this system is running as well as it is.  But certainly it's the case that we've learned an incredible amount.  And if there was only a way to turn back the clock, then...



LEO:  Well, I guess what you would do, I mean, if you - you see it sometimes when they build a new bridge.  You keep the old bridge.  You build the new bridge.  And you decommission the old bridge after the new bridge is completed.  You'd have to do something like that.  You'd have to design, and it would take decades, design and build a new Internet structure that then you slowly replace the old Internet structure with.  Or maybe not so slowly.  The problem is, it can't be too big of a change.  Look at how hard it's been to do, as you say, IPv6.  You put it in the routers.  The ISP can support it.  You can support it maybe at home.  But who's going to flip that switch?



STEVE:  Yeah, I think it'll happen in a sort of an incremental...



LEO:  It's got to be evolutionary.



STEVE:  Yeah.  For example, many people are now using secure versions of POP and SMTP and IMAP.  They're deciding they want that end-to-end security for, for example, email, that is notoriously insecure.  I mean, exactly the example you were giving earlier about being on the cruise and having your own email conversation intercepted, by default that sort of stuff could now easily be encrypted.  And it's just it's not because of inertia.



LEO:  Well, and it's also, you know, it's the same problem Microsoft has to face.  Do you start from scratch and go through all the pain that involves?  Or do you try to overlay on top of existing protocols more security?  And that's what we've been doing up to now.  But at some point it just becomes a bag hung on a bag hung on a wire on a - it's a kludge.  And at some point you really would like to start over.  Did you ever - programmers do this sometimes.  Did you ever start over on SpinRite and say let's just do it all over again?  Or do you always build on the existing?



STEVE:  Oh, no.  SpinRite's probably not a good example.  Although when I went from v2 to v3 I completely rebuilt the program.  So I guess that's a good example.  What I wanted to do with v3 just would not fit at all within the structure that I had.  And so I just started from scratch.  I built a whole new UI engine underneath it and essentially rewrote it from scratch and added a whole bunch of really cool new technology.  So, yeah, from time to time.  You know, and I think the Perfect Paper Passwords is another example.  I think we're on v3 now.  And it kept getting more sophisticated, and I scrapped it each time and just started from scratch again.



LEO:  Programmers often do that.  Or anybody does that.  You'll start over.  We've done that with a show, where we lost a show, we did it the second time, and it was better the second time because we started from scratch, knowing what we - learning what we learned.



STEVE:  Exactly.



LEO:  Udo Penther in St. Thomas, U.S. Virgin Islands - what a beautiful place.  I would love to be in St. Thomas right now.  He worries about insecure bank logins:  Hi, Steve.  I've been a long-time listener of your show, thoroughly enjoy it.  Did I skip?  I did.  I skipped.  I'm sorry.  You knew this.  You didn't stop me.  I'll go back.  Udo, we'll come to you - actually let's finish Udo, then I'll go back to six, how about that?



STEVE:  Or you could just have Dane edit this.



LEO:  No, Dane's busy as it is.  I don't want to add any more work.  We'll do Udo because there's no compelling reason for me to go six, seven as far as you're concerned?



STEVE:  No, no.



LEO:  He says:  I've been a long-time listener of your show and thoroughly enjoy it.  Today I do have a question.  At least two of our local banks' websites provide a regular HTTP login web page rather than an HTTPS page to enter one's password and userID.  After one provides this rather critical info, the next page it changes to HTTPS, secure HTTP.  So is that sufficient?  I've tried to access the login pages through HTTPS, but the system does not accept them.  I'm rather hesitant to use this setup.  I'd hate to join our local power company and phone company in bankruptcy.  And if it needs to be HTTPS, is there some professional reference I can place on the banks' managements' desks in order to bring their IT departments into the 21st century?  This is a question we get a lot.



STEVE:  Yes.  And it's been - we've talked about this before.



LEO:  I've had this question.



STEVE:  And because it's important, and it does come up a lot, I wanted to just sort of revisit it again.  The way the technology works is funky.  It's an example of the fact that - it's a consequence of the fact that web pages and the web system was originally a read-only medium, that is, you would surf around, and you would read stuff, but there was really no notion of information going in the other direction.  So that was grafted onto the specification in a strange way.  When you're submitting a form to a web server, you're submitting form data, you actually do it in the form of a query because queries is the only thing HTTP, that original protocol, understood.  And so you ask a question that includes the data you're submitting.



The confusion here is that because this site was not well-designed by the web designers, the form is not on a secure page.  But the fact that he mentions that once you enter the critical information the next page changes to HTTPS, what that means is that the query itself that is being sent containing your data is secure because the page you get in response to that query is a secure page.  So what your browser does, when you actually click the button to send this back, it establishes a secure connection.  Then in that secure connection goes the confidential critical information to the server, which then responds to the query as such with the result page saying, oh, yay, you successfully logged in, welcome to the bank.  So anyway...



LEO:  So normally it's secure.



STEVE:  I don't know how to summarize it that way.  I would say that - oh, yes, I see what you mean.  What you mean is that it would be very unlikely for the bank not to secure your login information.



LEO:  But it's possible.



STEVE:  It is absolutely possible.  So IE7, for example, changed the way they handle links and buttons, such that if you float your cursor over the button, down at the bottom in the little tray it will show you the URL that button is going to take you to.  And Firefox v2 and v3 both do the same.  And I know that Internet Explorer has an option to warn you if any form data is being submitted over a nonsecure connection.  So that's something else you can do.



LEO:  You can turn that off, unfortunately.



STEVE:  Yes, you are able to turn that off.  Again, this requires some awareness on the part of the user.  It would certainly be possible for someone to design a web page that accepted form data that was not secure.  So, I mean, again, this is a - it's a fault of the designers of these banks' websites that they didn't put the form request data on a secure page.  Although it's worth mentioning that even if they did, the button to submit it could be insecure.  So your data, even though you were filling the form in on a secure page, it's not the page where you're filling the form data in whose security matters.  It's the URL of the query which is sent to the server when you click the link.  I mean, it's very confusing.  And as I said, it's a kludge.



LEO:  So most banks do it this way, although I notice Bank of America now has changed that.  Amazon does it right.  So when you go to the login page, it's HTTPS.



STEVE:  Yes, because it gives you a warm, fuzzy feeling.  It's how I designed my eCommerce system for purchasing SpinRite, as well, is I put you on a secure page.  You can check, you know, our security certificate.  You know then that we've got good, full, 128-bit, industrial-grade security.  And then you fill in the form, and you move through the eCommerce process.



LEO:  But so you said it only gives you a good feeling because it could still be insecure.



STEVE:  Yes.



LEO:  Because the form button could be insecure.



STEVE:  That's a very good point.  The page you're filling in could be secure, but the form button submission could be insecure, although that would be nutso for anyone to design it that way.



LEO:  It would be hard to do that by accident?



STEVE:  Well, it could be done by accident, yeah.



LEO:  So I guess that's the real point.  So you should really hover your mouse over the button.



STEVE:  Yes, and see where you're going when you click that, you know, see where you're going to go, where the information you submitted is going to go.  God help you if it goes to DoubleClick and bounces over to - if it goes to DoubleClick on the way to PayPal, it's like, oh, goodness.



LEO:  Well, now I really want to see - I'm going to go to Amazon.  See, IE does that, but I don't know if any other browser does that.



STEVE:  Firefox does.



LEO:  It does?



STEVE:  Yeah, I'm looking at my cursor hovering over Firefox 2, and I'm seeing the URL in the bottom of the Firefox window.  And somebody mentioned when we talked about this before that there's a plug-in that you can use that will pop up the - where if you hover over a button, it'll show you like right there, in a tool tip for the button, what the URL is.



LEO:  Amazon puts you on an HTTPS page, and their button says "Sign in using our secure server," which is probably a good idea.  But again, you know, unless you hover your mouse over there and you see that HTTPS, you don't know.  There's no, you know, they could be saying that.



STEVE:  Yup.



LEO:  This is exactly what we were talking about with the last question is that the web isn't designed kind of inherently to be secure, and there's lots of little loopholes like this.  And I don't think - I wouldn't expect any end user to know about this stuff.  Just, you know...



STEVE:  No.  And it is the uninformed user, the people who are not listening to this podcast, that fall into these traps all the time.



LEO:  But that's everybody.  It's a small percentage that know this stuff.  Now we'll go back to Aaron Feickert in Fargo, North Dakota.  He wants longer passwords, darn it:  I'm an avid listener of Security Now!, and I have a pet peeve to share with you.  It's online services that try to limit the security of my account passwords.  Oh, I'm with him on this one.  Gone are the days when an eight-character password is sufficient to protect my personal information.  While most sites are getting better, I'm a paranoid person when it comes to password length.  I started signing up for online services, intending to use my preferred password length of 25 characters, including spaces - that is pretty long - and was rejected.  Heck, even my bank limits me to 16 characters, no spaces.  Mine also.  With modern one-way hashing what it is, can you think of any plausible reason why I should be limited in such a significant way?  If services widened their limit and at least allowed spaces, I could come up with a multiword passphrase that would be easy to remember but nearly impossible to break.  Why do they do this?



STEVE:  Well, yes.  This is a great point.  And we were talking about hashes in responding to an earlier question about, remember, about the MD5 hash on a CD.  The nice thing about a hash is it can take in data of any length, and it always returns a fixed-size result.  That is, it's always 16, for example, in the case of MD5, it's those 32 hex characters.  Even if you give it in, you know, like a three-character password, each character goes into the cryptographic algorithm, and every character sort of changes it that you add, changes the hash's output under the influence of that character and a whole bunch of internal state that the hash algorithm is maintaining.  So what this means is that servers could be designed so that they, I mean, MD5 is fine, although it's regarded now as maybe not the best hash choice to use in the future.  But what must be happening...



LEO:  Why not?



STEVE:  Well, just because it's, you know, longer hashes are better, and there have been some problems found with it.  But for this sort of application it's fine.  The only reason I can imagine that a server would say we're limiting you to this size is they're actually storing, they've set aside in your record, in your logon record at the server, they've set aside X number of bytes.  Well, the reason that's troubling is that says they're storing the password and not the hash. And the reason that's troublesome is that means that if someone got a hold of their database they would end up with all of their customers' names and passwords.  The beautiful side of storing instead, storing the hash, is okay, it's fixed length, so it's got the advantage of them being able to have a fixed amount of data set aside just like a fixed length of password does.  But by not storing the user's password, instead of only storing the hash, it's not something that is reversible.  That is to say, if somebody, I mean, you don't want anyone to get a hold of your login database.  That's a bad thing.  But if they did, and if they weren't able to modify it, they would still never be able to figure out what the password was, even though they had the hash.  And that's one of the cool things about hashing and storing.  So Aaron is absolutely right.  There's no good reason that anyone is limiting the length of a password.



LEO:  Is there anything in Windows Server, whatever, that makes spaces problematic?



STEVE:  No, no, there isn't.  It's just some algorithm just decided they don't want to allow certain wild characters, spaces, you know, maybe underscores or hyphens or who knows what.  And a perfect example of a modern-day hash-based password is the WPA key.  The WPA can be pretty much anything you want, the longer the better.  And it always hashes it down into a fixed-size result.  So there's an example.  And hopefully this is the kind of best security practice that other designers will adopt in the future.



LEO:  Yeah, it's a good idea.  In fact that's, you know, UNIX is always - well, not always, I shouldn't say that.  But UNIX, any secure version of UNIX uses MD5 hashes for its password tables for that very reason.  And that eliminates any issue with weird characters or whatever, just hash it.  It's always the same length.  To be honest, it puzzles me.  All right.  So you're right.  They should be doing that. Aaron.  Go out and spread the word.



STEVE:  Complain.



LEO:  My bank does it, too.  I hate it.  In fact, you know what really gripes me is that banks really encourage you to use four-character PINs for ATMs and stuff like that, which is really bad.



STEVE:  Yeah, I mean, certainly there it's the problem of they want you to memorize it.  They don't want you to write it down.  And they don't want people to say I can't remember what my 12-character PIN is.  So they make them short, which makes them insecure, but it's a classic example of security versus convenience tradeoff.



LEO:  Yeah.  Paul Thomas in York, the U.K., York, England, wonders about deep packet inspection, traffic shaping, and security.  Steve and Leo, great show.  My son Gareth thinks I'm a geek as your podcast - that's all right, my son Hank thinks I'm a geek - as your podcast is generally playing in the car when I pick him up from school.  Hi, Gareth.  He always asks me, do you understand what they're talking about?  No, I reply, but they do, and I will shortly.  I like it.  To my question, which I apologize for if it's been asked and discussed before.  I've just changed Internet service providers, and I've come up against traffic shaping.  My previous ISP didn't do it.  Would it be possible for you to explain how this technology works and whether there are any security issues regarding its use?  It does appear to be the way ISPs are going.  I read today that Comcast in the states has been hit with three new class-action lawsuits due to the company's traffic-shaping practices.  Thanks, Paul and Gareth.



STEVE:  Well, that's a really good question.



LEO:  It's a hot topic right now.



STEVE:  It is.  And essentially the idea is to traffic shape or not.  If an ISP did not do any kind of traffic shaping, as has traditionally and historically been the case, they're selling you basically, or renting to you, one of their IPs which you have full access to.  They're just saying you pay us so much a month, we're going to give you so much bandwidth on this connection, and we're going to give you an IP that allows you to transact traffic in any way that you want.  So things began to change a few years ago.  Actually, unfortunately, Microsoft was the original driving force in this change because Windows was having so many constant problems with security that ISPs began protecting us from Windows by blocking specific ports.  So, for example, I know that I'm using Comcast here - I'm sorry, Community Cablevision, Cablevision.  And if I have a non-firewalled machine, and I use ShieldsUP!, for example, to do a port scan of that, I'll see many ports closed but some stealthed.  For example, 135 through 139 is a range that'll be stealthed.  That's not me doing that.  That's my cable provider that has just blocked off those ports because that's the old Windows filesharing port range that was such a problem.



LEO:  Good.  That's an appropriate thing to do.



STEVE:  Well, you might say yes, you might say no.  I mean, again, that's an ISP filtering...



LEO:  It's Big Brother.



STEVE:  ...my traffic.  What if I - okay.  What that means is that I could not deliberately expose my Windows filesharing, even if I had adequate security, if I used a secure username and password, if I trusted Microsoft not to have any vulnerabilities that weren't known.  Say that I wanted to make some drives available that I could have access to through Windows filesharing.  Well, I cannot do it if my ISP is going to deliberately filter some port ranges that they've decided unilaterally are not good for me.  So it sort of began there.  And of course it's escalated ever since.  Traffic shaping means that the ISP actually looks at, okay, that the ISP has a policy, hopefully it's a public policy.  The problem is this started happening in secret.  And in fact it's not the only thing that's been happening in secret.  Next week we're going to finally talk about the form system, the so-called "Phorm Webwise" technology which has really got people upset because ISPs that have adopted this are changing the pages people download from foreign servers.  That's next week's topic.



LEO:  Oh, interesting.



STEVE:  But what's happening here is that the ISP is looking at the traffic and making a proactive, unilateral decision about whether they want you to be doing what you are doing or not.  So essentially, for example, in the case of using BitTorrent and peer-to-peer clients, what the ISP is doing is they're seeing that your behavior is outside of hopefully their publicly stated policy, and they're injecting packets of their own into your connection in order to alter the behavior of your computer and/or remote computers.  And they're just doing it because they've decided that they want to.



LEO:  This is what Comcast is getting in trouble for because they're deliberately disconnecting BitTorrent peers saying, oh, we didn't want that after all, on your behalf.



STEVE:  Yes.



LEO:  Oh, we weren't really looking for - and then of course all of a sudden your BitTorrent download stops working.  Regardless of whether it's legitimate or not they just decided - they're using something called Sandvine.



STEVE:  Yes.  And really the problem is that people felt that they were buying an unfiltered...



LEO:  Ah, there's a mistake.



STEVE:  ...unshaped connection.  Now, yes, so either the ISP is going to have to be very clear that they reserve the right to play cop, essentially, on the connection, and filter whatever they choose to, or maybe ISPs will offer a premium connection which is unshaped, and then you'll be able to get a cheaper one that is shaped.  It's not clear how this is going to evolve.  But it is certainly very controversial.



LEO:  I'm of mixed mind.  I mean, on the one hand I want to get what I pay for in terms of bandwidth.  And what the ISPs say is, well, if we don't packet shape, if don't do deep packet inspection, if we don't run Sandvine, you're not because there are going to be some hogs out there who are going to use up all the bandwidth and make it not available to you.  So on the one hand I think that maybe that is a legitimate business decision.  But I think they do need to be clear that they're doing it.  And as you say, maybe they would offer a different tier of service.  But then you'd have that problem big-time because these bandwidth hogs would be up on the higher tier where you're paying a lot of money.



STEVE:  Well, and remember that we did a whole episode on bandwidth congestion, on this notion of how does the Internet and how do our protocols and how do routers handle congestion.  What we really need is a more mature implementation of existing technology so that, for example, people who just want to do email or browse the web would have priority over their ISP's routers and bandwidth; whereas somebody who wanted to be doing BitTorrent, huge mega gigabytes of downloads, they'd still be able to do that, but their so-called "class of service" would be such that they get to use any available bandwidth at a lower priority than the people who are just doing email and surfing the web.  And of course then you have the advantage that web surfing is all snappy, and the ISP actually gets more value because they're going to have, you know, all their customers are going to be happy.  They're not going to be doing traffic shaping.  They're going to be doing traffic prioritizing.



LEO:  But that's what gets back to the question that we had earlier, which is the Internet infrastructure.  Doesn't it need to be rewritten to really do this efficiently and effectively?



STEVE:  Yes.  These kinds of problems are not things that originally had good answers.  And they weren't recognized as things that were going to be problems.



LEO:  Question 9, Travis in Indianapolis, he's out driving around, looking for his iPod Touch.  Where did it go?  Well, we'll find out.



STEVE:  Oh, this is a good one.



LEO:  Steve, I had contemplated this concept a few weeks ago while listening to the podcast, also reflecting upon full-drive encryption and so forth.  Then just a couple of days ago I've been able to test this theory myself.  I hope it gets me results.  Someone broke into my car in my driveway and many others, too, I guess, and took my GPS device - they love those, by the way, they're like candy to car thieves - as well as my iPod Touch.  I was devastated about the loss of the Touch, not so much about the GPS, because that's how I listen to your podcast and others two hours a day in my car to and from work.  Man, I know how that feels.  If you don't have that, and you've got that commute, boy, it's like, I've got to listen to the radio?



When I filed the police report right away that morning I told the officer that I'd hacked my iPod Touch, and if the thief tried to check my mail it would show up in the logs of the mail server I run myself.  When I got to work, indeed, I found in the logs that while I was driving to work they were accessing my email.  Bingo.  I got the IP address of where those curious thieves were reading my email.  This guy's smart.  I quickly changed the passwords and for about another hour it continued to try to check email but was now getting failures.  Oh, they continued to try to check the email, but they were getting failures.  Of course my hacker instinct was in full force.  Unfortunately they don't have any ports or remote administration open where they are.



[Talking simultaneously]



STEVE:  And this is where I told you that I removed his last name from his posting because...



LEO:  He attacked their address.  I don't blame him, but...



STEVE:  No, I mean, and sad to say, it's illegal for him to try to penetrate their system, even though they're creepy thieves.



LEO:  It's called vigilante justice.  I did verify via ARIN [American Registry for Internet Numbers] that it was a Comcast address who services my area - he did a WhoIs - and was based in the area, too.  I've passed this information along to the officer.  He's submitted it for a subpoena to find out who the present owners of that Comcast IP address are.  I hope he can use this to help get back my stuff and everyone else ripped off.  You know, if it's a big enough case, that's pretty good evidence they've got there.



STEVE:  Yeah.



LEO:  I'm also doing some war driving looking for the MAC address - oh, because he has the MAC address of his iPod Touch.  He's looking for the MAC address as it's certainly broadcasting unless they've turned it off.  Seeing as how they were...



STEVE:  Can you see this poor guy driving around looking, trying to find...



LEO:  iPod.



STEVE:  ...where's, you know, checking all the MAC addresses that he picks up in the air.  Ohmygod, there's my MAC address.  I mean, he still doesn't - it doesn't tell him where it is exactly.



LEO:  It's just in the neighborhood now.  Couple hundred feet.  Seeing as how they were dumb enough to check my email, he figures it's probably still on.  But here's the question.  Had I made it so that the thief couldn't access my computer to communicate back to the world at all, I wouldn't have been able to get the IP address where it was located.  Now, this is the only way I can get my stolen electronics back.  So in this case if it were a laptop or something, then the whole drive encryption, BIOS passwords, any other of those effective security measures that would limit their access, I'd have nothing to go on.  So I guess in some cases letting them have access to your device can actually increase your security, or at least your chances of getting that device back.  I love the podcast.  Hope this gives you a different view on security that perhaps you hadn't thought about.  Wow, that's - well, there are LoJack devices for laptops that do this exact thing.



STEVE:  Yes, there are a number of companies that sell a tracking technology.  They install themselves down essentially sort of a preboot technology that in the old days they used the phone, the modem in the machine in order to dial out and identify you.  And now of course they use the Internet and IP addresses in order to do that.  So there are - there is that kind of technology.  But it was sort of an - I loved his whole story about seeing whether the iPod Touch was going to be having email checked, and if so, then grabbing the IP and giving it back to law enforcement so they could track these guys down.  Sounds like it's probably going to be successful.  Because I do know from my own experience that if law enforcement gives an ISP a subpoena saying we need to know who has this IP address, I mean, the ISP is absolutely happy to do so.  They only want the protection of being compelled to do that by receiving a subpoena from the court so that they can't be brought I trouble, gotten in trouble from their customer who says, hey, you know, I'm not happy that you told the police where to find me.



LEO:  There's a product for the Macintosh that's very clever.  It looks for - it knows what the IP addresses are for Apple stores.  So hoping that the thief goes into an Apple store, it will immediately log into the open Internet there and take a picture of the thief using the camera built into the laptop and send it back to you and say he's in the Apple store right now.  Which is I think a great idea.  They're having some cases of laptops being recovered with these kinds of technologies.  There actually is a LoJack for laptops, kind of same idea.  I like it.  But it doesn't enhance your security, only enhances your chances of getting the computer back.



Don in Burbank, California has a book recommendation:  Hi, Steve.  Just finished "The Code Book."  Oh, yeah, that great Simon Singh book.  Oh, I loved that.  You guys mentioned it and talked about it before.  This is a must-read for Security Now! listeners.  It starts off a bit slow, but it builds up very carefully, and it really makes - just like our show.  And it really makes you sure you know cryptography when you're done.  What I got out of it was, oh, so that's what Steve's talking about.  Thanks for the great podcast.  I always learn something new.  "The Code Book," Simon Singh.  You have nothing to say, I take it.



STEVE:  Nope.  I just wanted to pass on his recommendation because I...



[Talking simultaneously]



STEVE:  ...it's a great book.



LEO:  Yeah.  And then I have "Codebreakers," too, which we mentioned before, by David Kahn, which is the thick book that actually was a little out of date because I think it ended in the '60s.  But it covers Enigma and everything.  And then he updated that just a few years ago.  Maybe up to the '90s, anyway.  You know where I got the bibliography for those two books was from "Cryptonomicon."



STEVE:  Ah, right.



LEO:  Neal Stephenson's wonderful novel about encryption, which is great to read.



STEVE:  Long.



LEO:  Long.  But it's my favorite book of his.



STEVE:  I really enjoyed it, yeah.



LEO:  And in the back, you know, he did a lot of research on crypto.  In fact, he comes up with his own crypto scheme using a deck of cards in there.  Which I think Bruce Schneier said, yeah, that's pretty good.  I think Bruce helped him do it.  Anyway, he has got a long bibliography in the back of that, that includes those two books, among others.



Dustin in Raleigh, North Carolina.  Finally we get to Question 11.  He says - he offers a useful USB thumb drive reminder:  Steve, I just had a Security Now! moment.  I'm attending a work-provided course this week, it's a PowerPoint-driven course, so the instructor wanted to share his slides with the students.  On the second day of the course, the instructor passed around his USB key that contained the education slides.  When exactly does the red light go off for you, Steve?  Just curious.  Listening to  Security Now! prepared me for situations like this.  I know it's not a good idea to plug an unknown USB key into your computer.  I went ahead and held down the shift key when I plugged it in to prevent anything from auto running.  Good man.  Luckily I did because it was a U3 device, which I can't stand.  Either way, it pays to be safe when plugging in unknown USB keys.  I know the instructor wouldn't try to do something malicious.  But if he wanted to, he could infect all the work laptops in the room.  By the way, so could anybody else in the room.



STEVE:  I was just going to say, if you're passing it around, baby, who knows about the machine that it was plugged into before yours.



LEO:  It's not the instructor I'm worried about.  Just wanted to share this real world application of Security Now! know-how.  Love the podcast, keep up the good work.  Was it enough to hold down the shift key, Steve?



STEVE:  It's really better to disable the feature entirely. So that is optionally done on Windows.  Unfortunately, because Microsoft's bias is still to just make it all work by default, it's something that users have to go in and manually do to turn off the autorun of the USB.  And there are some technologies that make it less easy to do that.  There are USB devices that look like a CD-ROM, not just like a regular static drive.  And so those can be a little more tricky.



LEO:  Oh, that's kind of what U3 does.  It mounts a CD, and it autoruns that.  Yeah, so it wouldn't just have to be the professor.  The next guy he hands it to could - and it wouldn't be hard - could quickly drag something onto the USB key while he's copying the file off.



STEVE:  Or Leo, I tell you, I mean, remember in the old days floppies were the viral medium of choice because it was so-called Sneakernet because you'd stick a floppy in, and then you'd copy some data, and then you'd go somewhere else.  I mean, floppies are the way viruses existed before the Internet because viruses predated the Internet.  And the only way a virus could live would be if some way it could move from machine to machine.  And so it was floppies that were virus carriers back then.  Well, similarly, a USB dongle or thumb drive is, I mean, a virus looks at that and thinks, hey, there's a way I can escape from this machine.  So you can well imagine viruses that are sitting there, waiting for a USB drive to appear and jump over to it as soon as it gets logged onto Windows.  So it wouldn't even be somebody else malicious in the class.  Their machine could be infected with a USB-propagating virus that will put itself on to any drive that comes along.



LEO:  That's a very good point.  So, yeah, it could be - that's easy to have happen.



STEVE:  Yeah.



LEO:  Wouldn't have to be maliciousness in your class.  Just could be incompetence.  Are you ready for Question 12?



STEVE:  The looming threat.



LEO:  The Looming Threat Observation of the Week.  John in Ottawa says:  Steve and Leo, my item of interest is perhaps a bit more vague than your usual items.  My concern arises from my belief that we are at the cusp of seeing a real proliferation of home-use servers emerging onto the Internet.  What does he mean?  What is he talking about?  Steve doesn't like it.  He feels it looming over him.  In particular I see NAS storage boxes - which I use, I have two of them - migrating into server territory and being targeted for sale increasingly to retail consumers.  But are consumers ready?  Here's my point, twofold.



One, these next-generation units are becoming increasingly full-featured and economical.  To illustrate my point I quote a manufacturer's website:  "Build Up Your Dynamic Website."  This is an ad.  "Web Station runs Apache Web Server that allows you to publish websites with only a few steps.  With preinstalled PHP and MySQL you are free to install popular blog or bulletin board programs on your DS107.  No advanced IT knowledge is required to build up your community."  So I guess I didn't realize they're selling these as web server boxes.  And this unit's $260 including hard drive.  So that's point number one.  That is a little scary, isn't it.



Point number two, because these units seem like an external drive, they're all too easy not to take seriously.  Since most people will look to this primarily as a critical data backup, it'll be tempting for them to have the unit central to their LAN.  Bad news if the unit's also accessible to the Internet.  In other words, if it's a web server and your NAS and your backup...



STEVE:  And it's got PHP and MySQL running...



LEO:  Oh, that is terrible.  Oh, the hackers are just drooling over this.  Which, let's see, to me this formula adds up to a real potential for trouble.  I hope the producers of these products will begin taking steps to inform their customers of security concerns.  Perhaps each product should contain a link to the website of a well-known security researcher.  Maybe they should just put all of our podcasts on them.  I'd be interested in hearing your take on this matter.  Thanks for the great show, and keep up the good work.  John.  Wow.  I didn't even know they were doing this.



STEVE:  Yeah.  Doesn't that sound like a bad idea.



LEO:  Well, tell us why, Steve.



STEVE:  Well, I mean, okay.  We've talked extensively about what a big problem commercial websites have with security vulnerabilities which are more or less constantly being found on the Internet.  And so here we have PHP and MySQL, and they're talking about "free to install popular blog or bulletin board programs."  So many of those are exploitable with cross-site scripting problems.  I mean, basically we're talking about a huge expansion of some of the most problematic Web 2.0 facilities which are going to be set up and installed by people who have no appreciation or understanding of the security implications.  Like, oh, look, I can run my own web server and my own bulletin board and stick it up and have it be public.  Oh my goodness, I mean, we're looking at a serious problem in the future.



LEO:  So, yeah, I mean, not only do you open up holes into that server by running services on it, but because it's attached to your network and because you're using it as a backup device, let's say, you may have valuable data on that hard drive.  It may provide a portal into your LAN.



STEVE:  Yes, exactly.



LEO:  I didn't realize they were selling these kinds of things.  Wow.



STEVE:  Yup.



LEO:  We've seen people do this all the time, but it takes some more sophistication.  For instance, you know, people will call me and say, well, I want to run a web server.  I've DMZ'd my computer so that it can serve to the Internet.  It's like, great.



STEVE:  Or Leo, I mean, it's exactly like what happened when Windows was first stuck on the Internet.  It was like, first you had Windows.  And then people, like, oh, I want to put my computer on the Internet.  And no one happens to notice that I've got my C and my D and my E drives all shared.  Because I was never plugged onto the Internet before, I didn't bother with username and password.  And so we've got open drives available through Windows filesharing.  I mean, that was where all this began and the reason I created ShieldsUP!.  So it's like, I mean, we're in the same sort of situation with that sort of a next-generation of nave user who installs this, who then makes this available publicly on the 'Net with a whole bunch of not necessarily secure server-side applications running.



LEO:  Wow.



STEVE:  [Audibly shivering]



LEO:  Now, that's not - we're not talking Windows Home Server or anything like that.  This is a whole 'nother class of devices now.



STEVE:  Well, this is a UNIX-based machine.  It's got Apache running with PHP and MySQL.  And they're saying, hey, feel free to install blogs and BBS.



LEO:  I'm sure that's very tempting, somebody who wants to run a website, they say, oh, well, I've got enough bandwidth on my Internet access now, I could just run it out of my office.



STEVE:  It's going to happen.



LEO:  Well, Steve, we've gone through 12 questions, 12 great answers, had a great conversation.  But I'm afraid our time is up.



STEVE:  But we'll be back next week.



LEO:  We will.  And you said you're going to talk next week...



STEVE:  About the whole Phorm Webwise technology.  There's a very disturbing new trend which is ISPs are actually modifying the pages their customers download.  So when I go to a website and look at the page, an ISP has tacked on their own JavaScript, which is being used to monitor me and track me and profile me.  Not a good idea.



LEO:  Wow.  All right.  That'll be interesting.  We'll do that next Thursday, and every Thursday Steve's here for Security Now!.  If you want to get a 16KB version of the show for the bandwidth-impaired or to share with your friends, or you want transcripts, show notes, it's all available on Steve's site, GRC.com.  Of course that's where you'll also find all of Steve's great security programs - ShieldsUP!, Shoot The Messenger, DCOMbobulator, the fun Wizmo, all those are free.  There's only one program he charges for in his whole life, but it's the one you should buy, and that's called SpinRite.  Because it is the best, the one, the only, the one they all copy, disk maintenance utility, drive recovery utility.  It's just, you know, if you use hard drives, you need SpinRite.  GRC.com.  Steve, we'll see you next week on Security Now!.



STEVE:  Talk to you then, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#149

DATE:		June 19, 2008

TITLE:		ISP Betrayal

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-149.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In this first of two episodes, Steve and Leo discuss the disturbing new trend of Internet Service Providers (ISPs) allowing the installation of customer-spying hardware into their networks for the purpose of profiling their customers' behavior and selling this information to third-party marketers.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 149 for June 19, 2008:  ISP Privacy.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, time to talk about saving yourself, saving your computer, saving your personal identity.  Mr. Steve Gibson is our savior - well, that's a little sacrilegious.  But he's certainly the guy who's protecting us online.  Hi, Steve.



STEVE GIBSON:  Hey, Leo, great to be back with you.



LEO:  You're my savior, Steve.



STEVE:  Yeah, well, I'm glad that we're doing the podcast.  It's a lot of fun, and we're closing in on the end of our third year, which is...



LEO:  That's neat.  That'll be soon, I guess, since we've done one a week.



STEVE:  Well, it will be, actually, because we're doing 149 this week.  And so given 52 weeks a year, which is pretty much standard, 156 will be the end of our third year.  So, yeah.



LEO:  That's really great.  And we should say for those of you who wanted to see Steve at his fortress of security, we are now, well, we can see Steve on TWiT Live.  You can join us as we record the show.  We do it every Tuesday at 11:00 a.m. Pacific time, that's 2:00 p.m. Eastern, 18:00 UTC.  But I should warn you, there's no clues.  The entire background that Steve's got there is completely imaginary.  He's on a...



STEVE:  Matted in on a green screen.



LEO:  Because you can't deduce anything.  It's not really his face.  He's using that Logitech software to put another person's face on there.  It's still anonymous.  You were concerned, you were a little concerned about having cameras on.



STEVE:  Yeah, I just decided, well, I just haven't figured out how I could stick the camera - essentially this camera is sandwiched in between two LCDs.  I've got a lower one and an upper one, with the camera right here in the middle.  And I actually chose, one of the reasons I chose the Logitech was that it has a very thin profile so it can sort of sneak out from in between the two screens.



LEO:  Wow.  So how many screens do you sit and stare at?



STEVE:  Five.  I have five here.  I was thinking I ought to get a mirror.



LEO:  I'd love to see it.  Sometime just [indiscernible] a hand mirror.  We'd just love to see that setup.



STEVE:  I think it was Dick who did that.  It's like, yeah, here's a mirror so you can all see.



LEO:  Yeah.  I would love - I would really think that's very funny.  I would love to see what that looks like.  And that's just how you work day in, day out, huh?



STEVE:  Yeah, it's just I've gotten spoiled.  I used to have three SGI monitors.  And then I sort of changed things around.  I decided it was time to get more real estate.  And after you get used to it, I just, like, I have thing and - it's funny because Mark Thompson and I were talking about the way we work with multiple monitors.  And he's the same way.  You know, I've always got Windows Explorer open on the right side of my right-most screen.  And I've got a couple browsers, Firefox and Opera at the moment, open on my left screen.  My [indiscernible] of course [indiscernible] working area.  But so everything is in a place.  I've got the stopwatch right above the camera so I can see it.  And so everything's sort of - and so you just get used to this notion of not having things overlap.  It makes me think also, remember Windows 1, where Gates was arguing against overlapping windows?



LEO:  Right.



STEVE:  And the first version of Windows, I mean, it did not have overlapping windows.  There was no provision for overlapping windows.  You had dialogue boxes.  But all the windows were tiled, and you could sort of, you know, drag their edges around.  I don't know if that was to avoid copying Xerox too directly, or Apple, or what the story was.



LEO:  No, in fact there was a big debate even at Xerox, and I think at Apple, too, over whether windows should be tiled.  And it was a big academic debate between the two different factions.  So I think a lot of the early Xerox stuff did not have overlapping windows.  That wasn't technically difficult, it's just...



STEVE:  And the idea being, of course, it's like, well, wait a minute, if there's information being shown, then you'd see it.  Why would you want to hide it behind something else?  And the idea is, well, it's the concept of these things that we just now take for granted.



LEO:  Well, and the right side won, I must say, because if it weren't for tiling, I mean, if it were all tiled - do they even have that command?  They had that command for a long time in Windows, you could tile the windows.  I don't even know if they still have that command.



STEVE:  It's around for, definitely for child windows, I know that you're able to, like, arrange those, so.



LEO:  Right.  Hey, you know, today - we're recording on Tuesday, it's Firefox 3 download day.  And Firefox, nutty Firefox thought, oh, we'll see if we can get a Guinness Book of World Records record for the most downloads in one day.  So they got everybody to pledge to download Firefox.  And as we speak, SpreadFirefox.com, which is the locus for all of this download day 2008, is down.  They couldn't plan, I guess they couldn't buy enough bandwidth.  I mean, they must have known.  They were saying let's break a record.



STEVE:  And so they slashdotted themselves.



LEO:  They slash...



STEVE:  I have to say that I'm responsible for several features in Firefox 3.  They returned the checkbox to easily disable third-party cookies.



LEO:  Yes.



STEVE:  As a consequence of my work.  GRC is in the process of producing some new technology which will preemptively inform everyone who comes to our site if they have third-party cookies enabled and essentially give them a little banner at the top of the screen to say, hey, just want to let you know that you're making it very easy to be tracked across the Internet.  Click this in order to get instructions on how to change that.  And the Firefox 3 guys recognized that this would generate so much interest in how do I disable third-party cookies that they decided to put that checkbox back that they mysteriously took out in v2 under the feeling that, well, it's not perfect protection, so we shouldn't have it in at all.



LEO:  Well, I remember, didn't you ask them, and they said, well, it doesn't work, so that's why we took it out.  It never was working anyway.



STEVE:  I guess that's, you know, that's a way they could look at it.  But remember - and remember it was still there.  You had to go to - you had to put in the address bar site:options.  And then you'd get this overwhelming list of stuff.  And then you'd type in COO into the search bar, and it would give you a list of about eight items that you could configure.  Then you had to change one of them to, like, a 1 or a 2 or something.  Anyway, they fixed all that.  And they had bugs in - Firefox 3 had bugs in their third-party, well, overall cookie handling that Firefox 2 still has.  So it's, for example, not possible to block third-party cookies correctly under version [indiscernible].  So Firefox 3 looks like it's going to be a good thing for people to move to.



LEO:  Yeah.  And then Flock, which is a Firefox derivative that I use, is also updated to Beta 1 of v2.  And it has the same security features, many of the same security features, but does not have the third-party cookie feature, which makes me crazy.  I think that's a very important thing.  They've got that - we talked about that green address bar.  That's, of course, an important part now of Firefox.



STEVE:  Yes, I'm very glad, the Extended Validation Certificate indication, yeah.



LEO:  Well, what do you want to talk about today?  What is on our agenda today?



STEVE:  Well, I've got a bunch of random errata.  I'm not sure what we would call today.  This has ended up expanding.  I did say last week that I wanted to talk about the so-called Phorm Webwise technology.  But I think we need to do this in two parts because I completely understand what the Phorm Webwise technology is, and it is really horrible.  It's something which the three largest ISPs in the U.K. have announced they're going to support.  A number of U.S. ISPs are at some stages of adoption.  And basically it's a next generation of behavioral profiling, is the way they're calling it, behavioral tracking where these companies are installing equipment in and-user ISPs for the purpose of literally tracking what we do.  And paying, essentially paying ISPs for the privilege of spying on us.



But I wanted to talk - I have a bunch of errata, and it turns out that because Phorm is not the only company doing it, I wanted to sort of give us an overview of this whole - sort of explain the way things have been done before, how this is different, what many of these companies are talking about today.  And then in two weeks I want to expressly go after an explanation of how the Phorm system works because what they've done is extensive and amazingly intrusive.



LEO:  Yeah.  Wow.  So any errata?  Did we make any mistakes last week?  Anything that...



STEVE:  Well, not errata.  But I wanted to acknowledge the death, unfortunately, of two people.  Of course you know I'm sure that we lost Tim Russert on Friday.  He was in the studios of NBC at 2:00 in the afternoon, getting prepared for his weekly "Meet the Press" show.  He had been vacationing with his wife and son in Italy.  And he flew back early because he needed to do the prep for the show.  He was 58 years old, and he saw his son graduate about a month ago.  And I've been watching Tim every Sunday for an hour for at least the last decade.  And it's just really sad that he died.  It was a coronary thrombosis.  A chunk of plaque that was in his veins came loose and took him out.



And then just, I guess it was late last night, we lost a famous Hollywood visual effects artist.  Stan Winston died.  Stan gave us the dinosaurs from Jurassic Park.  He created Predators, Terminators, Aliens.  He did the cool suits on Iron Man.  And he died at age 52 of cancer.  He had multiple myeloma.  So he's no longer with us.  So I remember seeing the credits of Iron Man scroll up the screen, and there was Stan's name, as it has been so many times for movies that I love.  So I just wanted to acknowledge and mention, if anyone didn't know, that we lost those two people, that they're no longer with us.



LEO:  Yeah, very sad.  And it's...



STEVE:  Also - go ahead.



LEO:  Oh, I was just going to say, it's a little scary for those of us like you and me in our 50s to hear about Tim's sudden demise.  And I know you're a great fitness buff.  We don't have to - anybody seeing you on camera knows we don't have to worry about you.  You're in great shape.  But I'm going to have to start thinking about my diet and exercise plan, too.



STEVE:  Well, it takes time.  I give it - actually I was on my stair climber when I got the news last Friday about Tim Russert on MSNBC.  I was preparing to watch Chris Matthews on his "Hardball" show, as I do.  And it's like, well, okay, yeah, glad I'm working out while this is going on.



I've also recommended the encryption program AxCrypt many times, so I wanted to advise our listeners, those of our listeners who are using it, that there is an important update.  As I understand it, it only affects Vista.  Vista and AxCrypt don't get along due to Vista's address space layout randomization.  We've talked about ASLR, which is one of the anti-hacking technologies that Vista incorporates where it randomizes the address space of applications to make it harder for malware to jump directly into known locations in the OS.  And something about versions of AxCrypt prior to v1.6.4.4, which is now the current one, they might have had problems, apparently did in some cases, under Vista.  That's been fixed.  So there is an update to AxCrypt, which is a very nice standalone file encrypter.  If you don't want to encrypt your whole drive, you don't want to, like, do heavy-duty encryption or have it present all the time, this allows you to perform state-of-the-art, good, strong, AES encryption very easily.



I wanted to come back to our mention last week of the Windows Bluetooth vulnerability.  I didn't know - no one knew anything about it at the time.  I wanted to reaffirm that it's as serious as I was worried it might be.  It turns out that anyone who has not updated their Bluetooth stack, who has got Bluetooth activated and have left Bluetooth discoverable, could be remotely hacked by somebody who sent a lot of service discovery protocol packets.  There was a problem in the SVP protocol that allows, essentially, a remote code execution vulnerability.  So any time there is a situation where radio is involved, of course, security is a little more troublesome.  And that's definitely the case here.  So you want to make sure that you've got Windows Update applied from our second Tuesday of the week [sic] update, which was last Tuesday.



LEO:  So that was part of the update.  So if you did apply that update, you're okay on the stack.  And it's not on your phone, it's on your Windows machine that it needs to be updated.



STEVE:  Well, it would be anything that - I don't know about the portable edition of Windows, whether that was there.  So it may very well be that the stack in Windows CE that many people have in their PDAs, it could have been affected, too.  But certainly laptop-based systems.  We know that that was an issue.  Another thing that happened this week is that McAfee released a very interesting report.  They did a first report about a year ago.  And this is - they called it "Mapping the MalWeb."  And so this next report is revisiting that.  And it contained a whole bunch of interesting statistics.  Anyone who wants to see this report for themselves, if you go to www - in this case you do need the www - .mcafee.com/advice.  Again, that's www.mcafee.com/advice.  I tried it without the www, and it's strange.  It takes you to a McAfee page, but it says, oh, we don't know about advice on this machine.  So you've got to do the www.



When you do, up near the top they talk about this "Mapping the MalWeb" report, which is a PDF, a 14-page PDF.  But it had some interesting statistics that I thought our listeners would find interesting.  Perhaps not surprising, of all of the top-level domains they tested, the Hong Kong domain, which is .hk, is the most risky top-level domain.  Of the sites they tested, randomly looking at sites in the Hong Kong domain, 19.2 percent of these were infected with some kind of malware, meaning that there was some opportunity for anyone surfing to any, you know, a 19.2 percent chance that if you surfed to an arbitrary site in the .hk top-level domain, some sort of exploit was attempted against your web browser.  The China domain, .cn, is number two most malicious top-level domain, with 11.8 percent of its sites trying to do some sort of exploit against your browser.  And the most risky top-level domain is, that is, just overall, is .info, with 11.8 sites infected, which is up from 7.5 the prior year.  However, overall, it turns out that overall very few sites worldwide are infected.  It turns out that it's 0.0717 percent, meaning that overall, if you went to 10,000 randomly chosen sites, only seven sites out of 10,000 have any exploit code.



So we've talked a lot about the danger of surfing with your web browser to sites which are trying to exploit your browser.  So I like the idea of having, from McAfee, some hard numbers about, okay, well, really, on arbitrarily chosen sites, what's the likelihood?  On the other hand, there are clearly areas of the 'Net that are more dangerous than others, and sites like classes of sites which are more dangerous.  For example, of all the sites which are download sites, and we've talked about the danger of acquiring malware or exploits against your machine in download sites, it turns out that 4.7 percent of sites offering downloads do have malicious content on them.  So the download sites tend to be more dangerous by a, well, "tend to be," I mean, by a huge margin over non-download sites, just other types of regular sites.



LEO:  So, well, I guess that's not much of a surprise, nor is it a surprise that Hong Kong and China are the difficult places.  But it's good - do you think that, I mean, these guys have somewhat of an ax to grind; right?  I mean, they're trying to prove that there's danger out there.  I mean, I always get a little suspicious when I read about issues from people who make money on security, so...



STEVE:  Who profit from there being problems.



LEO:  Right.



STEVE:  Right.



LEO:  Just thought I'd throw that in.  You have nothing to say about that, huh?  You don't want to defend them, huh?  No, but a lot of times I think, sometimes, anyway, that they may phrase the stuff in a scarier way just because, well, I mean, this is ultimately the reason they do these studies is to get you to buy their services.



STEVE:  True.  Although it's a large and big and varied market now.  And it's certainly no surprise to anyone that the world's got malware and browser exploits and spyware and all this kind of nonsense.  So...



LEO:  The thing that always amazes me is how much more widespread it is than one thinks.



STEVE:  Yes, yes.



LEO:  There's just a lot of it.



STEVE:  Okay.  So behavior targeting is the next thing that is really preparing to happen.  And it's troublesome because it's something we haven't seen before.  It's a new approach and a new technology that has not been used before.  And it's causing a huge amount of concern among privacy advocates and among end-users.  I mean, for a number of reasons.  Some surreptitious tests have been done by ISPs, specifically BT in the U.K., where in 2006 and 2007, without telling their users, equipment was installed by the ISP into their facility which - by a third party, and a third party of some questionable reputation, specifically for the purpose of intercepting the web traffic of these users, and [indiscernible] things with it.  So the issue is this is a very different style of profiling than what we've seen before.  We've talked briefly about the problem with third-party cookies, that is, the idea that you have images, for example, on a website that are being served by third-party servers.  And by default all browsers except one, Leo, I don't know if you're aware that Safari is the only browser that has third-party cookies disabled by default.



LEO:  I think we discovered that.  I think we were talking about that issue, and I went through all the browsers on my desktop, and that was the one that was off by default.  Which is the right - and you say that's the way it should be.



STEVE:  Well, I believe the way it should be because it was never the intention of the guys at Netscape that created this cookie protocol - that basically added cookie technology, stateful user management to the web browsing technology - it was never their intention that third-party sites should be able to do this.  But the clever people who wanted to advertising-enable the web said hey, wait a minute, not only can we be third-party servers of advertising on sites that people go to, but by having us, we as third parties put a cookie on the user's machine, then we'll be able to see where they go over time.  We'll be able to, essentially, we as a third party build a persistent relationship with this, well, with everyone who surfs sites to whom we are providing ads.  And their theory is that by looking at the sites that people go to, they can build up a profile of these people over time.  And it ends up being more complex than that and actually of somewhat more concern because there are various ways that personal and personally identifiable data can leak out of a user's web browsing experience to essentially create more than an anonymous file of these people on the web.  And this is fundamentally enabled by third-party cookies.  So...



LEO:  So the risk is that they could use third-party cookies to accumulate a profile on you by essentially following you around to sites that this third party, whether it's DoubleClick or some other ad agency, is serving.



STEVE:  Well, it's more than a risk.  It is a feature of their business model.  They brag about the fact that they are building profiles.  They say, oh, because of the technology we have, the fancy stuff we're doing, our ads are going to be more tightly targeted to users, the idea being - and they say, oh, that's good for users because they're going to see ads more relevant to who they are.  As if - I mean, all of their claims are legion in the industry.  They'll say, for example, if we have figured out that you're newlyweds with babies because of the types of sites you visit, then we'll be able to serve you ads that are more relevant to your lifestyle or where you are in life.  And again,  so somebody who's in their geriatric years, they will have figured out that that's who they are.  And so they'll serve ads from this big bin of ads, apparently, that they have, that are unique to the specific users of a generic website.  So the point being that not everyone who goes to the site receives the same kind of ads.



Well, I mean, even that has concerned people.  And there are many people who are security conscious and privacy conscious who have taken the time to disable third-party cookie tracking, that is, the idea being that you need a first-party cookie relationship with a site, for example eBay or Yahoo! or even, well, certainly banking sites are - more and more sites are requiring first-party cookies, typically anywhere that you logon.  There is a cookie exchange with your browser so that as you move through that site's pages you're known by the site.  And it's increasingly expected that the first-party cookies will be present.  But arguably there is no defensible reason for using third-party cookies.  Okay.  So...



LEO:  Except to make money collecting information about what you do.



STEVE:  Exactly.



LEO:  Which is a very good reason for DoubleClick and Google.



STEVE:  And I want to say here, I want to make sure people understand that I'm not saying that this stuff necessarily needs to be turned off.  I'm concerned that all of these companies say, oh, well, anyone who is uncomfortable with this can opt out of this technology.  The problem is, I mean, it was like - it's the classic example of adware purveyors who say oh, no, we always provide opt-out provisions.  It's like, well, if so, it's buried down in the fine print.  And more often than not, when you tell people this is going on, they're upset, meaning they didn't know.  And so I have no problem if people wanted to turn third-party cookies on.  I'm annoyed that they're on by default on all browsers but Safari, and it's necessary to turn them off.



LEO:  There's also an irony because people who run spyware programs that kill tracking cookies, when you opt out, at least with DoubleClick, it sends a tracking cookie to say don't collect these cookies.  And if you used an ad block program or an antispyware program, often it kills the opt-out cookie, and you're back on cookies.  They're on again.



STEVE:  Exactly.  Exactly.  Okay.  So what Google has done with Google ads is, when a website says, okay, they set up a relationship with Google, and they say we want relevant ads to our site, what Google does is Google's technology looks at the page where the ads are going to be served, performs a keyword analysis, figures out what the page is about, and then Google's success is that from their pool of advertisers they use their own logic to populate the ads on the page so they're relevant.  And I know that Mark Thompson has been messing around with this a little bit, curious to see, like, what level of relevance would Google's ads provide.  And I think, you know, many people are [indiscernible] Google ads on an increasing number of web pages now.  And Google does a pretty good job.



Now, the vendors of the behavioral tracking technology say, okay, problem with that is that there are sites that don't have pages where there's, like, available ads that are relevant to their content.  Or you might have, like, a blogging site where there just isn't any clear topic for the page.  There isn't anything that anyone, that an advertiser could lock onto to say that's what this page is about.  So what the behavioral tracking people are trying to do is instead of putting ads on a page based on the page's content, they're purporting to put ads on a page based on the people, the behavioral profile that they've developed of the people who are going to be visiting the site.  So there are a number of companies that are entering this game.  This is just brand new.  This is just beginning to happen.  The company I talked about before, Phorm.  There's a company called NebuAd, one called Front Porch, one called Adzilla, and...



LEO:  Because we're running out of names, and frankly all of these names are terrible.



STEVE:  Oh, NebuAd.



LEO:  Nebu.



STEVE:  Yeah, nebulous ads or something.  Okay.  And there's something called Adzilla and something called Project Rialto.  So NebuAd, for example, they say to site publishers, and this is jargon taken from their promotional material, they say "NebuAd observes aggregated consumer activity across any site on the Internet without collecting and using any personally identifiable information about the consumer.  NebuAd combines this [indiscernible] wide view of pages navigated, searches performed...."  So they're seeing what searches you do.  They're watching, essentially they're in your click stream.  All of these companies, every one of them is installing equipment in the ISP's facility.



LEO:  That's the important thing is that the ISP knows everything you do.  And they're willing to give this information up.  So do advertisers.



STEVE:  Right.  Well, okay, for example, NebuAd says to ISPs:  "To date the role of service providers has been limited to enabling but not participating in the online advertising revenue ecosystem.  Whether you are a wired line or a wireless ISP with national or regional coverage, NebuAd offers a risk-free way to achieve stronger revenue growth and improve your average revenue per subscriber.



LEO:  You know, we talked a little bit about this I think on a TWiT episode because Charter Communications, a big cable company and Internet Service Provider, announced this as - they spun it as, frankly, a valuable thing to consumers.  If you read the FAQ at Charter's site, it says no, no, you're going to get ads that are more targeted to your interests.  And it's not that they're replacing ads that are coming in, but they're willing to sell information about you to third parties so that the ads can be more targeted.



STEVE:  Exactly.  Well, essentially the equipment is installed by these companies and at no cost to the ISP except for it's in the ISP's facility, so they have to make rack space and space available.



LEO:  And maybe the cost of their reputation, but that's another matter.



STEVE:  Well, yes.  That can be huge.  There's been such a bunch of flak that's been raised by the Phorm system and the early technology two years ago that they were testing with BT.  I mean, it was causing all kinds of problems.  That early technology was inserting JavaScript into every page your web browser downloaded.



LEO:  I don't like that.



STEVE:  So it was inserting their own code into the page for the purpose of setting browser cookies on the client, client-side browser cookies.  Sometimes, because this stuff was so ineptly done, people doing forum posts using browser-based forums would get this code stuck into their forum post.  Browsers were locking up.  IE would lock up, and you'd have to use Task Manager to shut down IE because its use of the system would go to 100 percent, and IE stopped obeying its UI completely.  All of this was brought to you at no charge by your ISP.



LEO:  See, it's interesting because I probably blamed IE when that happened.  I thought, oh, there it goes again.



STEVE:  Well, as far as I know this hasn't come yet to the U.S.  It hasn't been done to us.  Although the Phorm guys are actively soliciting U.S. ISPs.  Adzilla, the Adzilla folks say to ISPs, "Adzilla works hand-in-hand with the world's leading Internet Service Providers to help them monetize their traffic, anonymize their data, and offer a better browsing experience to their subscribers."  Then they pose the rhetorical question, "How does Adzilla work?  ISPs install our innovative ZillaCaster device" - oh, goodness - "within their network environment free of charge."  This won't cost the ISP anything.  In fact, no, it's going to make you money.  "ZillaCaster then enables the analysis of terabytes of real-time anonymized data flowing over the ISP's network."  Yeah, over the ISP's network, which is to say all of the traffic that all of the ISP's customers are transacting.  They're analyzing these terabytes of data in real-time and "leverage this data to offer precision ad preferencing information to publishers and advertisers."  It says, "How does Adzilla help ISP monetize data traffic?  When an advertiser pays for a targeted ad placed on Adzilla's advertising network, Adzilla shares the revenue with ISP partners."



LEO:  Yeah.  This is why they do it.  They make - it's a moneymaker.



STEVE:  Exactly.  "By using Adzilla's technology, ISPs create new online advertising opportunities, provide publishers and ad networks with audiences that deliver optimal results, and maintain optimal standards of consumer privacy."



LEO:  I love this spin.  By the way, I just checked, Charter is using NebuAd.



STEVE:  Oh, goodness.



LEO:  So they're - I don't know if they're the first ISP in the U.S., sounds like they are, to do this.  But boy, I think we should keep an eye on our Internet Service Providers.  This is terrible.



STEVE:  Well, I'll tell you about NebuAd in a second.  I have researched their technology.  The good news is it's less bad than Phorm's, but it is also non-blockable.  Whereas Phorm technology can be blocked.  It's so bad.  And that's what we're going to talk about in two weeks.  And so just to finish up, to give people a sense for...



[Talking simultaneously]



STEVE:  Yes, Adzilla says in their promotional material, "Why is Adzilla's targeting so precise?  Adzilla's ZillaCaster device, which sits within an ISP network environment, continuously analyzes the content of actual sites visited, ads clicked on, and keywords searched for each anonymous entity at any given moment to provide precision ad-preferencing information.  Since Adzilla technology offers the most precise ad targeting in industry, publishers that participate in Adzilla-affiliated ad networks can offer premium quality inventory to advertisers at the highest possible rates."  So, I mean, it's what we've seen before in the adware business.  And it's that kind of,  well, it's unfortunately the technology that end-users are not being informed of before it's brought to them.



Now, NebuAd, which is using a substantially less invasive technology than Phorm, they are basing their technology on hashing the IP and some other browser headers in order to determine whether the IP changes.  NebuAd recognizes that over the long term end-user IPs change.  So they're attempting to detect when the end-user's IP has changed.  What they say they do, first of all, so this is essentially a filter technology, it's a shim stuck in the ISP's facility that looks at, essentially, all the queries being made by the ISP's customers.  Oh, and it's important to note that this is only non-encrypted communications.  They have no ability to penetrate, thank goodness, HTTPS SSL connections.  So it's only non-encrypted pages that they're able to see.  And it's also only HTTP traffic presumably to port 80.



But they are looking, they have access to everything that the ISP's customer does.  So every page that you pull up, when you're browser-displaying the page, they have read the page and performed keyword matching, looking for important keywords that they use to tell them what this page is about.  So they know that it's you by your IP.  They are reportedly not putting any cookies or anything else on your system, which makes them vastly cleaner than the Phorm system we'll talk about in two weeks, whose cookie planting is beyond extreme.  So they're just tracking you based on IP, which makes them cleaner.  They say that if you are going to a health or, for example, a sex-related site, that they will not perform any filtering and tracking of that.  What they do is they then broadly categorize the page that you're looking at into so-called "interest categories."  And they have somewhere on the order of a thousand or more interest categories.  And so they reportedly associate your IP with which interest categories you're searching to.



And then if you go to a site which is part of the NebuAd network, as these companies all call this, meaning that a website is getting ads served by NebuAd, then they will, because your browser is, for example, at CNN.com, but it's pulling images from NebuAd's servers, they'll see the IP which is requesting the ad, check their system to see whether they know anything about you by your IP and, if so, serve an ad which falls within this broad interest category delineation.  So basically that's the concept in a nutshell, the idea being that they're not using third-party cookies in order to build a long-term profile of...



LEO:  They don't need to.  They've got even more information.



STEVE:  Well, and one concern is the household that uses a single IP and many machines because they're not disambiguating based on browser, exactly, because all the browsers behind a NAT router are going to use the same public IP.  So that there is, unfortunately, some potential for cross-user leakage.  That is to say, you know, Dad's using the computer doing whatever he's doing, and then...



LEO:  But all that would happen is you would see Dad's ads if, I mean, right, that's all it means, it's just you're going to get ads that are targeted at Dad instead of you.



STEVE:  Exactly.  Well, and the other thing, too...



LEO:  It's not the end of the world.



STEVE:  With all of this, no one has even proven that this concept works, that they're actually, I mean, with all they're going through, I mean, all these companies are just in startup mode.  They're like in the early beta-testing mode.  In fact, over in Adzilla's site most of their site is soliciting - there are job postings for senior server engineers and people that are going to help them develop this Adzilla and their ZillaCaster technology.  But even so, again, nothing has shown that this actually generates higher click-through rates and higher quality results.



LEO:  It's a funny thing because advertisers have known for a long time that ads are less intrusive, less annoying, less resented by consumers if they're targeted.  If the consumer is interested in buying a car, they actually enjoy new car ads.  They look at them.  So, you know, it's an invasion of privacy, but its net result is to give you ads that are less offensive to you and advertisers like better because they're not wasting money on advertising to people who aren't buying a new car.  But it's the privacy implications that we're talking about.



STEVE:  Yes.  And again, Leo, I don't have, I mean, given a choice - and unfortunately a large number of users apparently feel this way.  Given a choice to have that or not, most users say no, I would rather not have any kind of profiles of any sort being made of my use of the Internet.  And notice also that the ISP is generating cash for themselves, essentially by allowing their users to be spied on by third parties.



LEO:  That's what bugs me.



STEVE:  Yes.  And for example, I would not have a problem if, for example, your ISP said, if you would like to - if you are willing to have your use of the Internet profiled, we will give you a discount on your monthly service.



LEO:  I'd like that.



STEVE:  Yes.  And no doubt there would be a lot of people who'd say sign me up.  I'm not concerned about being anonymously profiled.  If the ads are more relevant to me, I want them, and I'd like to save $2.50 a month.



LEO:  Right.  It's a variation - I'm glad you brought this up.  I tried to actually bring it up on a TWiT episode a couple of weeks ago, and people were kind of ho-hum about it.  And I think it's because people didn't really understand what we were talking about.  And more and more U.S. ISPs are looking at these technologies.



STEVE:  Well, yes.  And so I'm glad it's getting attention.  In two weeks - we're going to do our Q&A episode next week.  In two weeks I want to take our listeners - this'll be a propellerhead episode, so I want to warn people in advance to get ready in two weeks to understand what this Phorm technology is.  It has evolved in two years to - because what they tried to do two years ago where they were injecting JavaScript into people's pages, it just - it was a disaster.  It backfired on them.  I don't know if it's just that they didn't do it right or what the story was.  These people, though, are not good people.  They used to be called 121Media.



LEO:  Oh, I remember them.



STEVE:  Yes, Leo.  Yes, Leo.



LEO:  Did they do, what is it, CoolWebSearch?  What was it that they did?



STEVE:  They did something called "PeopleOnPages" and also did something called "Apropos."  Apropos was one of the worst adware that used rootkit technology.  It installed itself into randomly named directories.  And then it installed a kernel-level driver to hook the API Windows to - and it used, it was a kernel rootkit that was in there hiding, inventorying people's machines and monitoring everything that they did.  These are the people that bring us now this Phorm system.  And in two weeks I'm going to talk about the technology that these guys have come up with.  It's just unbelievably invasive.



LEO:  KJ's asking in the chatroom if any mobile carriers are using this.  Because then they really, I mean, they have your phone number, they really would know everything about you, wouldn't they.  I mean...



STEVE:  Somewhere I saw, oh, it was - there's one of these companies called Front Porch that is - in advertising to ISPs says, "Monetize your network through advertising.  Just make a new revenue stream through advertising."  And get this.  I love this.  "Advertise at all stages of the user session, not just first login.  Choose from a variety of high-value ad formats including Ultramercial," whatever that is.



LEO:  It doesn't sound good.



STEVE:  It doesn't sound good.  "Target users based on location or user preferences.  Advertise to the right user anywhere they surf the 'Net."  Oh.  I mean, it's just in-your-face stuff.  And then it says, "Among the popular uses, redirect subscribers' homepage requests to your portal.  Redirect search requests to a partner web..."



LEO:  That's spyware.  That's spyware.  That's adware.



STEVE:  Yes.  "Create a walled garden of allowed sites for specific subscribers."  So they basically, again, the ISP can do this because they have total control over your outgoing requests and your incoming data.  So what we're potentially seeing now is this evolution from ISPs to passive bandwidth providers to saying, wait a minute, we want - here are these companies saying, oh, don't worry, we're going to take care of everyone's privacy.  Everyone will be anonymous.  If you'll just let us install our equipment in your facility and stick us in between you and your subscribers, we're going to pay you.



LEO:  So, I mean, I guess you're saying that they should be more like a utility.  Just sit back, give us the bits, don't get in the way, don't get involved.



STEVE:  Well, okay, yes.  Again, my opinion is that users need to be informed, that if an ISP is going to be making money by monitoring what their customers do and by in any way providing that information to a third party as a source of revenue, whether the ISP justifies it saying that it's good for their end-users because it provides more relevant ads, first of all, it should not be opt-out.  That never works.  It needs to be opt-in.  And if the ISP is concerned that not enough people will opt in - oh, yeah, gee, I wonder why - then they could do some revenue sharing and say, look, we're both going to make money if you allow the places you go on the Internet to be anonymously monitored and to have the pages you see change based on what this third party determines about you, we'll...



LEO:  Well, there's intrusive and there's intrusive.  I mean, if it's like Google ads, where - I guess this is what Charter is saying is what we'll do is we'll sell this information to advertisers, like maybe Google ads, Yahoo!, and so that they can be more tailored to you, even more so than they already are.  That's one thing.  If they're changing my home page and my search page...



STEVE:  Well, that's not - yeah, that's not how NebuAd works.  NebuAd is a - wants to be an advertising network, much like DoubleClick, so that advertisers will advertise with NebuAd, and then NebuAd will get placements on high-profile web pages that users go to.  And the idea being that supposedly there will be a higher click-through rate with NebuAd's better targeting, that the targeting is better because they're literally, based on the IP in the case of NebuAd, based on the IP of your connection, they're building a profile of the ISP's user.  And, when they see that IP pull an ad from a different page, they choose which ad among their multiple ads they're going to serve the page.



LEO:  Right.  And I don't like that.  But again, I think your point is perfectly taken.  If they're going to do it, fine, they just need to say.  The problem - and, you know, let us know, make us...



STEVE:  And they cannot be opt-out.  It has to be opt-in.



LEO:  Ah, good point.  Charter's doing an opt-out thing.  In fact, Ed Markey, who is a member of Congress, said that's not enough.  Yeah, he said exactly that, I want it to be you choose to be a part of this.  The real problem is, of course, there's not much competition among Internet Service Providers.  It's not, you know, most markets have one, maybe two.  And so it's not - if they both do it, it's not like you have somewhere you can go.



STEVE:  Yeah.  I think, again, obviously the listeners to this podcast are going to be aware of this.  In two weeks we'll be talking about the things that can be done proactively to block this kind of technology.  There are some things that can be done in the NebuAd case.  So but I'm not concerned about our listeners.  Our listeners are already hip to all of this stuff.  I'm pissed off that this is something that most people won't know about.  And again it's just - I remember back when I was fighting with Aureate, that renamed themselves Radiate in the same way that 121Media has renamed themselves Phorm, because they ruined that name so they're now changing to a different name, people were furious to find out that this stuff was on their machine.  And the Aureate people said, oh, no, all of our partners, our contract says they're going to make sure that users are advised.  And I said, well, apparently users weren't advised, otherwise they wouldn't be pissed off like this.  I mean, right?



LEO:  Right.



STEVE:  People [indiscernible] I know about that.  No, I mean, people were just going ballistic over the idea that this stuff was installed on their machine.  So it's like...



LEO:  I'm really glad you brought this up.  I think it's such an important topic.  And it is a little complicated.



STEVE:  It is a little complicated.  Believe me, though.  This is nothing compared to what we're going to do in two weeks.  You won't believe what the Phorm people have done.



LEO:  Oh, boy.  All right.



STEVE:  Oh, yeah.



LEO:  So let's...



STEVE:  You know, I never shared one of my SpinRite...



LEO:  I was going to ask you about that, do you have a SpinRite letter?  Usually you...



STEVE:  Right.  Normally I do it at the front, I just forgot.  I did have it written down here in my notes.  I just had a really neat note that I got from a dad.  The subject of his note was "One Happy College Student."  And this is William Turner, who said, "I can't [indiscernible] where to send this."  I think he must have sent it to our sales address.  So he says, "I hope this forum is okay."  Or maybe he posted it.  I can't really tell where it came - oh, no, it came through sales.  And he says, "I wrote this about a month ago, and I'm finally getting around to mailing it.  And he said, "Dear Steve, I'm a long-time listener to Security Now!.  I bought SpinRite about a year ago and have  used it for maintenance purposes ever since.  A few days ago I got a call from my daughter, who was out of state attending college.  She was crying like the little schoolgirl I remember.  She then explained the Blue Screen of Death that all those who use a computer fear.  I told her not to worry, it could be fixed.  Then the tears really began to flow.  She said that a semester-long project was on the drive with no backup of any kind.  'Daddy, what can I do?'  She said, 'I need you to come here now.'



"Well, she's about 2,200 miles from home, so that was not an option.  I told her about SpinRite.  I quickly determined that I would FedEx my copy of SpinRite to her today.  When our phone conversation ended she was sure a failing grade was the only option in her future.  This morning, however, I received a call from guess who, my little girl, who thinks I am the smartest dad ever.  This conversation was filled with jubilation and amazement.  She said, 'It fixed my hard drive.  My laptop is working, and I just backed up all my documents.'  Her worries of a few days ago were all but forgotten.



"Steve, thanks for helping me appear like the dad who knows it all.  You saved my daughter many sleepless nights.  SpinRite is a must for everyone who owns a computer.  All parents should not send a son or daughter away to school without a copy of SpinRite.  Thanks for your great product and all the hard work you do."  Signed, William Turner.  And he may be listening to this right now.  So thank you, William, for sharing that story.  That's great.



LEO:  Really, that's the kind of thing, everybody should go to school with a SpinRite disk, absolutely.  We like that idea.  So, Steve, we're going to - next week is going to be Q&A week.  So we'll talk about Nebu - or no, is it NebuAds or Phorms that you're going to talk about?



STEVE:  Going to talk about Phorm in two weeks, about what they - the hoops that they jump through and what they do to users in the process in order to achieve this, ugh, this questionable, basically spying on and profiling, courtesy of users' ISPs.



LEO:  How do people ask questions for next week's episode?



STEVE:  As always, go to GRC.com/feedback.



LEO:  Okay.  That's simple.  There's a form right there for you, GRC.com/feedback.  While you're there don't forget to check out all the other great things GRC has to offer - SpinRite of course, but also ShieldsUP!, which is free, to check your router.  There's lots of software:  Wizmo, all sorts of free security tools, utilities and more at GRC.com.  And show notes for this show, 16KB versions for the bandwidth-impaired, and Elaine's great transcriptions so you can follow along.  You can read along as you're doing this.  That's GRC.com.



STEVE:  Leo, while you were talking I was reading the chat log going by.  And there's been some question actually going back and forth about whether SpinRite works on iPods.  So I thought I would answer that directly and remind people, maybe these users don't remember, but there was one testimonial that I read where someone did use SpinRite and took the drive out of his iPod and hooked it up to his PC.  And then when it fixed his, remember he had like a collection?  It became a joke.  Everyone was giving him their dead iPods.  And he had, I don't know, like 20 or 30 of them lying around as doorstops, bookends and things.  And so he fixed them all and then gave them all back to them with all their music intact.



LEO:  That's the amazing thing.  That was an amazing story, yeah.  So I guess we're out of time.  But we will be back next week with more of your questions and more of Steve's answers.  And then the following week we'll continue this conversation, talking about these, well, I guess programs or boxes that Internet Service Providers are using now to spy on you, ostensibly to provide you with better ads but really to make some money.



STEVE:  So I just can't wait to tell our listeners about the technology that has been employed.  It's just mind-bogglingly bizarre.  And frightening, arguably.  It's a mess.



LEO:  It's terrible  By the way, Steve, while we've been talking - as I mentioned, we record this on Tuesday, which is the download Firefox day.  And even though Firefox's site has been really hammered - and Sargit in our chatroom is pointing out that it looks like the hammering is coming from an applications server that can't keep up because he can ping the site, but the application server is just not serving the pages up.  I guess they didn't expect this, even though they said they wanted to set a Guinness world record for the number of downloads.  Over 200,000 downloads just as we've been talking, Steve.  They're up to three quarters of a million.  And they're doing 11,000 downloads a minute now.  So it's pretty impressive.  They're really...



STEVE:  Well, I've got to say I've been doing, for the last several months, Leo, I've been working intensely on the issue of cookie handling.  Most of the major browsers out there have cookie-handling bugs which apparently have gone unknown for a long time.  IE does.  Firefox 2 does.  Opera, I think Opera is among the best.  And Firefox 3 has got it nailed now, too.



LEO:  I'm very glad to hear that.



STEVE:  So both Opera and Firefox 3 I'm very impressed with.



LEO:  Everybody should download it.  It's a great program.  And everybody should listen to Security Now! every single week.  We'll see you on Thursdays.  And go to GRC.com for your copy.  And if you want to go back through all 148 previous episodes, they're all there at GRC.com/securitynow.  Thank you so much, Steve.  We'll see you next week.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#150

DATE:		June 26, 2008

TITLE:		Listener Feedback Q&A #44

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-150.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 150 for June 26, 2008:  Listener Feedback #44.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now! Episode 150, our sesquicentennial episode.  Steve Gibson, how are you today?



STEVE GIBSON:  150, I know, as I was writing that today I was thinking, yes, six to go, and we cross our three-year mark.



LEO:  That's amazing.  So today we're going to talk about security.  In fact, we've got your questions and Steve's answers.  We've got quite a few of them, a dozen great questions.  But before we get to those, let's get an update on, first of all, any errata or anything you want to cover from last week's episode?



STEVE:  Yeah, a few things.  I wanted to acknowledge all the people who wrote with the feedback that last week's audio sucked.



LEO:  Yeah, apologies.



STEVE:  That's pretty much the only word for it.  I think it was partly the microphone and partly - we're hoping it was the cable modem, meaning that you're switching your end to DSL, and of course I've got a pair of T1s.  That ought to hopefully bring down any packet loss.  We still have the possibility that it might be the fact that there's just video involved, and video competes [with] audio [for] bandwidth.  And it might be winning.  Anyway, we're going to try this one.  I'm back to the Heil microphone that I've used for several years.



LEO:  That makes a big difference.  Yeah, that makes a huge difference, yeah.



STEVE:  Anyway, so I just wanted to acknowledge that lots of people wrote in to say, hey, Steve, just thought you should know, the audio last time was really bad.  So we're working on it, and...



LEO:  Yeah, I think mostly it was, I mean, everybody knows the audio, the microphone didn't sound as good, but it wasn't inaudible.  It was I think the dropouts.  And I'm still hearing [indiscernible] that, so I don't know what's going on.



STEVE:  Yeah, I'm hearing it from your end also coming back.  Several people made the comment I thought was very astute, and that is that you have the Heil, and if I don't, then the difference in the quality of our audio makes it noticeable.  That is, if...



LEO:  No, I throw that out, you know why, because you're the only one with a Heil in the whole network.



STEVE:  And I also have been told, though, that I've always traditionally sounded better than any of the other netcasts.



LEO:  And I'll be honest, I think it's your bandwidth more than anything else is probably the case.  And I think we're still having bandwidth issues, and it kills me.  I'm not sure why, but we'll figure it out.  Skype is funny that way.  You know, it'll go great for months, years, and then you'll have a bad day.  And it's hard to predict.  But we are on ostensibly the same exact setup we've used before with one addition, one slight change, as you said, is video.  So maybe we'll just stop the video.



STEVE:  Well, yeah.  And it's important to understand, too, that if we use less total bandwidth, then those packets have a greater chance of getting through than if we have just many, many more packets.  So statistically, because as we've talked about many times the Internet delivers packets on a best-effort basis, as we crank our bandwidth up we're going to see larger packet loss.



LEO:  Yeah, maybe that's it.  Maybe just, you know, it's that Internet congestion thing you talked about a few episodes ago.



STEVE:  Yeah.  So I wanted to mention that.  And, oh, and there were some other people who were concerned that the audio portion of our podcast was going to be sacrificed at the altar of video.  So I just wanted to say that that's not the case, that we recognize that the number of people listening to the audio far outweighs the number of people watching the video, and that I'm going to be conscious of that, and I won't start holding up charts and things so that the people who are on the audio channel feel disadvantaged in any way.  So I wanted to make that clear also.



LEO:  All right.  Yeah, I mean, I think a number of the shows actually, because we're sending so much video now, a number of the shows have become very videocentric.  The Giz Wiz, for instance, Dick's always holding up stuff, saying hey, take a look at this.  It's kind of hard when you have a camera going.  People kind of start paying attention to that.  But it is, it's a much smaller audience.



STEVE:  And there actually were a couple people who are major TWiT people who wrote and said hey, you know, I've noticed that some of the other podcasts are sort of not really relying on the video, but exactly as you said with Dick, I mean, he's having fun with the fact that he's on camera.  But people who are listening to audio can't see what he's holding up, so.



LEO:  Right, right.  Yeah, it's something I'm aware of.  I'm going to have to think about it, and I don't know exactly what to do.  On the other side of the equation is video has brought a lot more people to the party, including advertisers.  So I'm not sure I want to dump the video, either.  So we'll have to figure out a happy medium, shall we say.



STEVE:  Yes.



LEO:  So what else is in the security news?



STEVE:  Two little blurbs on a recent event since last week.  There's a weird Microsoft Word problem, believe it or not, with its parsing of bulleted lists.  So that if you open a Word document that can be crafted to be malicious, it uses a buffer overrun in Word's display of bulleted lists to perform a remote code execution.  As far as I know, this is not something that Microsoft has addressed yet, or patched.  But we can hope that that's on the way.



LEO:  Yeah.



STEVE:  And then lastly there is an unspecified remote code execution problem in all versions of Firefox through and including v3.  There's no patch yet from the Mozilla folks.  But I just wanted to let our Firefox-using listeners know that there is a known problem which has been brought to the Mozilla people's attention that has not yet been fixed.



LEO:  Yeah.  There's also been a Mac trojan, did you see that?



STEVE:  No, I didn't hear about that.



LEO:  Yeah.  I'm not sure that - you know, the problem is once again that the people who report this are the people who make the antivirus software for the Macintosh.  Or, you know, the security software for the Macintosh.  So I'm always a little bit, you know, suspicious of the whole thing.  But this for the first time is one that is in fact in the wild.  It actually takes advantage of a vulnerability in the remote access client.  And the fix right now, until Apple patches it, is to remove this ARD client from your system.  You can actually just, you know, zip it up and stick it somewhere else so it won't run.  And unless you're using remote access on the Mac, that's not going to be a problem.



STEVE:  Oh, yes yes yes, in fact I did hear about that.  And someone posted a note asking how it could be that people who were running the Apple service were less vulnerable.



LEO:  Yeah, so I don't know about that.  That's interesting, yeah.



STEVE:  Well, what I heard was that, or when that was reported, it seemed to me that, if the trojan were trying to - technically the term is "bind."  If it was trying to bind to that port, if the port is already open and bound to the application, then that would prevent the trojan from being able to do so.



LEO:  Yeah, that's...



STEVE:  So it is that that would explain the fact that something, a service running makes you more secure technically than not having it running.



LEO:  So that's exactly what happened.  This ARD agent vulnerability was published.  And then immediately somebody wrote a trojan to take advantage of it.  And the companies that found out, first it was SecureMac and then Intego, both of whom make antivirus solutions for the Mac, talked about this.  It does give you, it can give you complete access to the Mac, including this trojan can log keystrokes, take pictures with the built-in camera without your knowledge, take screenshots, turn on filesharing.  So it is a big vulnerability.  Generally will come in via iChat.  So I guess the key is not to accept files from other people.  It's a trojan.  They have to send you an application for this to work, and you have to open it.  So don't.



STEVE:  And I have to say, Leo, your audio has really improved.



LEO:  Yeah.  I think that the video was a mistake.



STEVE:  I think, well, what we can try to do, and we'll try this during our setup next week before we begin recording, is perhaps there's some way - and I'll screw around with it this end - for me to reduce my upstream bandwidth and not kick it into high-quality, high-bandwidth mode.  Because after all, I mean, I'm sending 640x480 at 30fps.  I mean, that's full broadcast-quality resolution.  And the point is that no one - I'm sending it all to you, and then it's being reduced as it goes out through the redistribution and all that.  So it's probably possible to lower the resolution and/or the frame rate, or maybe increase the compression without really having the user suffer at all, but also be much more bandwidth sparing.



LEO:  Right, right.  Yeah, we'll figure it out.  I mean, as video is subordinate to audio, and this just shows, so by turning off the video, the audio is better, that's fine with me.  We don't have to solve it.



STEVE:  Several tens of thousands of Security Now! listeners are breathing a sigh of relief.



LEO:  Well, but the thing is, I like to see you.  I mean, I think it's fun for people to see you, too.  And...



STEVE:  We'll see if we can...



LEO:  At some point somebody's going to say, okay, I want a list of all the books on the bookshelf behind Steve because he has a big, big bookshelf behind him and a lot of books on it, I might say.



STEVE:  A wall worth of books.



LEO:  Hey, speaking of books, I just got Neal Stephenson's new book, and I'm really enjoying it, it's called "Anathem."  It will be out in September.  I got a reader's copy of it.  And it's really...



STEVE:  Oh, very cool.



LEO:  He wrote "Cryptonomicon," which we've talked about before, and is one of my favorite authors.  So I'm reading a paper book, Steve.



STEVE:  Oh, my goodness.



LEO:  It feels so old-fashioned.  



STEVE:  Only because it hasn't yet been read into Audible, I'm sure.



LEO:  Oh, yeah.  In fact, I asked Audible about that, and they said, yeah, we know a lot of reviewers do listen to Audible for reviewing the books because it's more efficient for them to get the book read.  And they said we should really talk to these publishers about when they send out a reader's copy we could also send out the Audible copy.



STEVE:  Yeah.



LEO:  I guess they were - it takes a while to record these books.  This is a big book.  Take them a couple of months to record.  But they start early.



STEVE:  Yeah, I don't think Neal has ever written a small book, has he?



LEO:  No.  His last book, "Quicksilver," if you go to the Science Fiction Museum in Seattle, they have the manuscript.  He handwrote it with a fountain pen.  And they have all the fountain pen cartridges, all the manuscript paper.



STEVE:  Oh, my goodness.



LEO:  It's crazy.  I don't even - it's nuts.  But it sounds like his process.



STEVE:  Well, whatever works for him.  I got a nice note from a listener in Hong Kong - oh, no no no, I'm sorry, in Korea, he's Korean, regarding Security Now! and his experiences on SpinRite.  He says, "Dear Steve, how are you?  I am Yong-Gu Bae."  I guess that's how you - it's B-a-e, Bae?



LEO:  Bae, yeah, Bae.



STEVE:  Yong-Gu Bae.  He says, "I am a Korean living in China."  Oh, living in China.  "I live in northern part of China, so I live far away from Hong Kong Post Office."  Of course referring to our mentioning that as a certificate authority on a number of occasions.  And he says, "...far away from Hong Kong Post Office.  However, it's a malware hot zone nonetheless.  Since I am in export-import business, I travel a lot.  And last year unfortunately I got my laptop bag stolen at Barcelona.  So I lost my laptop, digital camera, external hard drive, and iPod.  It was a big loss, and it took a fortune to replace all of them.  So my European trip last year was the most expensive trip ever.



"More than three months ago I learned about Leo's TWiT podcasts, and I started to listen to Security Now!.  I visited your website and downloaded all the episodes and PDF files.  And I'm proud to tell you that I'm up-to-date with your podcast.  While I was listening to your podcast I noticed that you were that Steve Gibson from GRC, where I copied Perfect Passwords for my routers about two years ago and downloaded SecurAble from about one year ago.  I wish I listened to your podcast a little earlier so that I could have prevented the robbery.  Nowadays, thanks to you, I use TrueCrypt on my laptop to avoid another unfortunate incident, and use Hamachi to connect to my office PC.  Since I was a computer science major, I have a lot of hard drives lying around.  So while I was listening to your podcast I decided to buy SpinRite.



"I will be on a business trip to the U.S. from Thursday.  But suddenly, two days ago, when I was working at the office" - and he says in parens, "(yeah, I work seven days a week these days)" - "my wife called me and told me our home PC isn't working.  Sure enough, when I went home and turned on the PC, it was only showing Windows Vista logo with green dotted lines moving forever.  So I put SpinRite to work using Level 4; and the next day, voila, the PC was working fine.  I've used SpinRite in various hard disks that I own, both by CD booting and using VMware workstation."  And he says, parens, "(I use 6.5 beta free edition and love it)."  I noticed that to use VMware a lot, it's better to have a multicore with lots of RAMs.  I use Vista x64, by the way.  Thank you for reading my lengthy feedback, and thank Leo and you for a superior podcast.  And best regards, Yong-Gu."



LEO:  Thank you, Yong-Gu.



STEVE:  That was a neat note.  I really appreciate...



LEO:  Yeah, yeah, really cool.  You ready for our first question of the day?



STEVE:  Let's go.



LEO:  Let's go.  Mark Madison in Pawlet, Vermont brings router malware to our attention.  Router malware?  Steve, the Washington Post's Brian Krebs - by the way, I read that column a lot, he's very good.



STEVE:  Yeah, Brian's a good guy.



LEO:  Yeah.  Brian Krebs reports that a new variant of the widespread Zlob trojan can change DNS settings in your router.  So even if you reformat after an infection, as you and Leo recommend, you may still have a problem with your router.  I know you've probably covered the basics already, but it might be worth mentioning this extra cleanup step after a bad infection.  Reset your router.  Thanks for the great show.



STEVE:  I thought that was really interesting.  We've talked about the need to disable Universal Plug and Play, UPnP, in routers because of the virtual certainty that malware is going to begin to use that for router reconfiguration.  It turns out that what this trojan, this Zlob trojan, this variant of it, apparently it's very widespread.  Microsoft reports that they've cleaned off tens of millions of copies of it from people's machines using their constantly updating - is it Defender?  I can't remember what they call it.



LEO:  No, OneCare, Windows OneCare probably.  Unless, well, Defender is spyware.  OneCare is their antivirus.



STEVE:  Yeah, I think it's just Defender, you know, the one that everyone just gets, and it's always updating itself.  Anyway, what this thing does is it has a huge list of default username and passwords for all the routers, in addition to hundreds of other likely passwords.  So it's able to see what your gateway IP is.  It then, behind the scenes, without you knowing it's doing it, it communicates with your router and knows what the default page is and tries to bring up that page and literally log into the router in the same way that you would, as someone doing local administration of the router.



And of course it turns out that a huge number of people have left their username and password unchanged.  And I once confessed that I was among those people.  That's since been changed.  This is not for a mission-critical router, not inside my network.  It's a completely disconnected router over on a cable modem that I just have here for visitors because I don't let anyone touch my network under any circumstances.  But it was the case that I was thinking, oh, you know, no one can get in until they're in.  And you have to be in in order to access the inside administration interface of the router.  Well, it turns out that there is a way now, unfortunately, for if malware gets in, what it does is it is able to log into the router, change the DNS settings, which means that then - and this is the other interesting thing is that not only your machine, that is, the one that's already infected, but all the other machines that are using DHCP, the obtain-IP-address-automatically protocol from the router, every machine within your network will get the DNS from the router, which is reset to a malicious DNS server that then causes your browsers to go to the wrong servers whenever they're trying...



LEO:  And why would they do that?  It's not a denial of service, but they inject stuff in.



STEVE:  Yes.  The idea is that you think you're going to PayPal.com, and you're going to their PayPal clone site.



LEO:  Oh, interesting, interesting.



STEVE:  Not good.



LEO:  And this one also pops up spyware.  It does all sorts of interesting things.  It posts spammy forum comments.  I mean, this is a nasty little bug.



STEVE:  Oh, it's a busy nightmare, yes.



LEO:  The chatroom is pointing out that it could also have been Microsoft's Malicious Software Removal Tool.  They update that...



STEVE:  That's exactly what I was trying to remember.  That is the name, yes.



LEO:  So that actually does something.  Because I get those updates all the time.  It actually does something.



STEVE:  You know, Leo, that was a surprise to me, too, because I also - you don't think it's doing anything.  I mean, it's certainly not in your face.  But it's always, every single second Tuesday of the month, oh, we're going to update the Malicious Software Removal Tool.  And I go, okay, fine.  You know, and then it never tells me anything or seems to be doing anything.  But on the other hand, you and I are being very careful about what we do with our machines.  Clearly tens of millions of other people aren't, and they've got this Zlob trojan trucking around inside, messing up their networks.



LEO:  I think probably Microsoft, I don't know, they don't want to give away a free antivirus, partly because they'd put themselves out of business with OneCare.



STEVE:  But yet at the same time they would love to do something about their horrible reputation from a security standpoint.



LEO:  Right, right, right.  I'm looking at their page on Microsoft.  It looks for Blaster and Sasser and MyDoom, which are nasty ones.  So I think in a way, if they have something that's looking for worms and trojans just to damp it down, I think that's a good thing.



STEVE:  Yeah.



LEO:  Just damp down the spread of these things.  Brian in Toronto works for Internet Service Providers using something called "transparent proxying."  He says, Hi, Steve, I used to work for an ISP where proxy servers weren't just encouraged, but enforced.  All port 80 traffic ultimately came through their proxy.  I came to understand that this is more common now than ever.  Usually the giveaway is stale data that refuses to be purged, even if you try to delete your temp files, you know, if you kill your caches and cookies, and you reboot, and you do the one-legged hop and retry.  I've found at least one other ISP, my current one, appears to be using transparent proxies.  Now, normally this would just be an annoyance.  But I seem to recall earlier Security Now! episodes in which you mention SSL traffic terminates at a proxy.  In last week's episode you mentioned that these invasive ISP tracking solutions can't sniff on SSL traffic.  My question is, would this be true even where transparent proxies are in play by that same ISP?  I'm still trying to wrap my head around SSL tunnels and have to go back to reviewing older Security Now! topics.  But in this world of Trust No One, TNO, I like being extra cautious.  By the way, I bought SpinRite, and I think it solved a problem for me.  Boot-up issues auto-magically disappeared on my mother-in-law's - he says "mother outlaw's" - PC.  So first, what's a "transparent proxy"?



STEVE:  Okay.  This is something that ISPs do in order to minimize their bandwidth usage to their upstream providers, and also theoretically to improve the performance and experience of their own users.  The idea is they are - it's called a "transparent proxy" because the users behind it, meaning the ISP's customers, you and I and everybody, for example, who has a cable modem or in some cases a DSL system, we don't configure to use a proxy.  We just use the IP that we're given and believe that we're connecting directly out to remote servers.



It turns out, however, that that's not the case.  There is a hidden proxy server which the ISP has interposed in its network for the purpose of caching.  So the only reason that an ISP would do this is for caching web content.  Again, the idea is that, for example, if you go to CNN.com's home page, well, if I go there I pull the home page.  And in the process I use the ISP's bandwidth that it's purchasing from its upstream provider.  Remember that ISPs are just Internet users and customers like we are, they're just bigger.  So the ISP is purchasing bandwidth, just like we are, except they're bigger.  So they're aggregating...



LEO:  They buy it wholesale.



STEVE:  Exactly.  However, they still want to minimize their overall bandwidth usage.  So the idea is that if I go to CNN.com and pull down CNN's home page, if other ISP customers do the same thing, this transparent caching proxy will notice the URL that is being retrieved and will also look at the so-called "metadata" that came with that page, for example, the expiration time.  And if the page which it has cached has not expired, that is, CNN sent it saying, oh, let this page last for an hour, for example, that has the added advantage to CNN of removing the burden from its servers, so it's not having to reserve the same home page over and over and over.  It sends out a single copy that has an expiration, for example, an hour in the future.  And then the ISP's cache will hold onto it.  Then other ISP customers who go to CNN, they get it instantly from essentially what is a local copy of that page in the ISP's cache.  Now, that's the good news, when everything works correctly.  However, Brian in grumbling about this noticed that sometimes you get stale data that refuses to be purged even if you delete temp files and so forth.  And the reason is there's nothing you can do locally to force the remote transparent proxy to update itself.  That is, it thinks it knows better.  And normally that's the case, that is to say that normally things are going to work well, and servers will be issuing pages that are pre-expired if they never want them to be cached by an intermediate caching transparent proxy.



He also asks about SSL.  The good news is that if you use an SSL connection, unless there's been the deliberate installation of a certificate in your browser that we have talked about which is what's necessary in order for an intermediate proxy to be able to intercept your connection, unless that's done you will avoid the ISP's transparent proxy.  I had some experience with this years ago when I was first developing ShieldsUP! because my own local cable modem supplier, Cox, they use a transparent proxy.  And so when I was connecting to ShieldsUP!, I would be getting the IP of the proxy and be testing that, which of course is not what we want.  We want to test the user's actual machine.  So that's why ShieldsUP! runs customers, people who come to ShieldsUP!, through a secure connection specifically to bypass ISP transparent caching proxies, which are unable to intercept secure SSL traffic.  And they really don't want to.  I mean, the notion there is that there's some reason you've established a secure connection, one being that you want absolute privacy and end-to-end security between your browser client and the remote server that you're talking to.



LEO:  So he shouldn't worry about it.



STEVE:  Well, it does mean...



LEO:  You have to trust your ISP, I guess.



STEVE:  Well, and I should say we've got a number of questions that we will be dealing with this week that are offshoots from last week's topic about ISP spying, privacy and betrayal, which caused a great deal of interest among our listeners.  So it is the case that given that when you have a nonsecure connection, that is, non-SSL traffic or non-VPN traffic, that everything that you transit through your ISP is available and visible to them.



LEO:  That's why we didn't like that Opera Mini browser because that would do the same thing, would proxy your browser.  But AOL has done this for years.  This was how AOL speeded up browsing.  And a lot of ISPs do things like re-encode or recompress graphics and so forth.  Lot of times when you get a dial - this is the old days of dialup.  But you'd get a dialup provider would say, oh, we're faster, we have turbo speed.  And that's all they were doing was proxying, caching, and compressing, recompressing.



STEVE:  Yes.  And you're right, the thing that's different about the Phorm or NebuAd or Adzilla or all those nightmares we first started talking about last week is that in this case, that is, in those cases, ISPs are deliberately sharing this information with a third party.  And that's not good.



LEO:  Your ISP knows a lot about you no matter what.  You really should find one you can trust.



STEVE:  However, what you would like is that you would like for it to take a court order for them to divulge any information, rather than a commercial opportunity to sell a profile of you to third-party advertisers.



LEO:  Right.  Tim McCoy in California worries about, quote, "acceptable levels of hard drive failure," as if any level would be acceptable.  He says:  Steve, I've noticed that some hard drives have close to a million seek failures, or CRC errors, as revealed in the S.M.A.R.T. System Monitor.  This noticeably, he says, affects system performance.  This does not seem acceptable to me, but how do we convince manufacturers they should exchange drives with such a high rating?  Secondly, SpinRite appears not to work with USB keyboards.  Is there an update?  Let's take the first part of that.



STEVE:  Yeah.  It is unfortunately the case that there has been some cost associated with the insane explosion of hard drive storage capability.  And we've talked about this before.  These ECC, Error Correction Code, or sometimes known as CRC errors, are occurring at a much higher level, at a much greater rate than they used to because the data is so densely stored now on today's contemporary drives that drives literally depend upon this ECC, the on-the-fly error correction, to correct sectors which are not perfectly readable.  It's somewhat troublesome, but it's the way things are.



LEO:  You don't have any choice.



STEVE:  Yeah, there have been other instances where drives are, because of the incredibly high track densities, this is where seek errors are coming from.  Drives are having a hard time staying on track, that is, that they have the technology to do what's called "track following," where the head is tweaked on the fly to keep itself over the track.  That has to be done because the tracks are so dense that even minute variations in track position cause the head to go off track.  It turns out that drives are becoming increasingly sensitive to the vibration of their own chasses that they're mounted in.  And I'm seeing now drive manufacturers specifically talking about, like, having extra quality tracking technology in order to help them stay on track.  So these are side effects of buying a trillion bytes of data in a small little box.



Oh, and as for SpinRite and USB keyboards, it is the case that SpinRite is still using the BIOS, as we've spoken of, which is universally supported by the older style PS2 keyboards.  Most motherboards will have an option, they normally call it "USB Legacy Mode" or something like that, where you're able to - they're able to provide transparent operation of a USB keyboard in the BIOS so that you're still able to use SpinRite with no trouble.  But if that's not turned on, you just need to go into the BIOS and set legacy mode for USB support, and then SpinRite can work just fine.



LEO:  That's good to know.  That's good to know.  Jake in Minnesota asks Firefox to forget all about him, forget I was ever here after every use.  It's a little setting in Firefox.  Steve and Leo, ever since I got Firefox for the first time I've been using it with that Clear Private Data option every time I quit.  I've set it to clear everything, including cookies.  Is this a secure way to browse, if I don't mind missing the benefits of using cookies, or am I just fooling myself?  Thanks for the great show.  It's a huge comfort knowing you guys are there making sure we stay informed about security issues.



STEVE:  Yeah.  That is certainly an option for surfing securely.  And I know that Firefox does what it says it's going to do, that is, it removes all the sorts of histories of your use which it's otherwise maintaining.  And he mentions it also includes cookies.  So it does, when you set that, it prevents Firefox from storing that data on the hard drive.  It just keeps it in RAM so that when you shut down Firefox, that data is lost.  And so it's absolutely a useful and good feature of Firefox.  



LEO:  Is it a security benefit, though?  I mean, is it - I mean, it's a privacy benefit.



STEVE:  Yes.  And I think it's a very good point, and worth drawing that distinction.  I think that you could argue that there are ways that security could be compromised when privacy is compromised.  But I sort of think of them as separate issues.  On the other hand, well, no, I was just going to say, you know, having someone else take a look at URLs that you've visited, you know, how often when you start typing a URL it pops down a list of various things it has in its history that it remembers, you know, locations where you have gone to, in order to help you with sort of autocompletion.  So clearly there again is a - you might say that's a security vulnerability that somebody else who had physical access to your computer could see what you've been doing.  But it's also certainly a privacy concern.



LEO:  Right.  Chris W. in Springfield, Virginia has a note about Firefox 3 and cookies:  Steve and Leo, I have been a long-time listener, really like the work you do and have been a SpinRite owner since v3, three versions ago, and now have been hoping for a Mac version since I just switched to a Mac (grin).  I noticed that Firefox has third-party cookies enabled by default.  I was a little disappointed to see that was the case, for the sake of the people who need the most help, the non-techies.  Why do you think Mozilla did it this way?  Is it a nod to advertisers?  Why don't they make third-party cookies off by default?  Safari does that on the Mac.



STEVE:  Yes.  And Safari is the only browser, the only popular high-end browser that does have third-party cookies disabled by default.  I don't think it's a nod to advertisers at all.  I wouldn't believe that the Mozilla folks would be nodding to advertisers.  My guess is that if it caused a problem to ever have third-party cookies turned off, then Firefox could be dinged a little bit and believed to be less compatible or to have some incompatibility.  It is certainly the case that traditionally, historically, all cookies, first-party and third-party, have been enabled by default.  And so I just think it's the Firefox people not wanting to break something.



LEO:  I'll give you an example, a really good example, and I was very disheartened by it.  There's a Firefox extension called Foxmarks that syncs my bookmarks.  It doesn't work if third-party cookies are turned off.



STEVE:  Yes, and I think we actually have someone mentioning that later in this episode.



LEO:  Oh, really, okay.  So I think that that is exactly what it does is it breaks stuff that relies on it, stuff you may not, you know, assume relies on it.  I mean, and so for that reason they probably default to the - this is always the case.  People almost always default, unfortunately, default to the less secure but more convenient choice.  They don't want to do support.  They don't want the calls.



Don in Burbank loved this week's episode, or actually last week's episode on ISP Betrayal.  I love that.  Hi, Steve.  Excellent show last week.  I'm jumping the gun, but what are some simple ways to thwart NebuAd?  We're going to be talking about more of that next week; right?



STEVE:  In detail.  We're going to go into the technology of Phorm, which is just a - it's a horror.



LEO:  Right.  He says:  Charter Communications is my ISP.  And we talked about that last week, that they are using NebuAd.  Using a proxy like Anonymizer or a simple proxy, would that work?  Would a VPN like Public VPN?  Can I write a program that can pollute the data stream, randomly looking at different web pages?  That's interesting.  Is there a legal action I can take against Charter?  Should I switch my ISP?  Is my Yahoo! webmail being spied on?  Just a suggestion, could you lay out different levels of thwarting the spying?  Level one would be easy, level two a little work, level three requiring good tech knowledge, level the hardest but will stop spying.  What do you think?



STEVE:  Well, okay.  First of all, the good news is that any kind of encryption blocks this completely.  So it is only the nonencrypted connection...



LEO:  Oh, that's interesting.



STEVE:  Yes.  Any kind of encryption.  So SSL using HTTPS, if you're able to.  When he asks about is his Yahoo! webmail being spied on, if you're able to, as you are with Google and Google Mail, to establish an encrypted connection to Yahoo!'s webmail server, then you are absolutely safe from any of this eavesdropping.  Now, they are currently saying that they are only intercepting port 80 traffic.  Meaning that, for example, SMTP and POP transmissions, that is, outgoing mail from you to your ISP's web server, I'm sorry, email server on port 25, or incoming email on port 110 or 143 for IMAP, those are, I mean, no, 145 IMAP?



LEO:  143, I think.  That's a good question.  I think it's 143.



STEVE:  Anyway.  So the idea being that they're saying that they're only looking at port 80 traffic.  I'm worried, frankly, about the notion of email being profiled in the same way because think of the wealth of so-called behavioral profiling data that would be available from looking at people's email and doing keyword searches and so forth on that in order to further determine who they are.  They can say, oh, no, it's innocuous, you know, all you're doing, all that's happening is you're being categorized into, you know, one of a thousand broad categories of general interest.  It's like, yeah, okay, but unfortunately it seems that available information is being taken advantage of wherever it's available.  So that gives me a very creepy feeling.



LEO:  Yeah.  And Google, I mean, look, Google's doing that with your Gmail.  There's definitely valuable information in there, they say, in your Gmail account.



STEVE:  Yes.  However, in that case, to address that, for example, Google's doing it with your email in order to show you ads on the Google Gmail pages that are relevant to you.  Right?



LEO:  Right, right.



STEVE:  So there's some containment there.  You know,  the entity that you're transacting with knows about your past usage of email and is saying, look, here's some ads that you may care about.  Of course what's different is they're not selling that off to some third party to do with lord only knows what.



LEO:  Right, right.



STEVE:  So the bottom line is any VPN, any SSL connection, anything you do to encrypt your communications is going to completely bypass these guys.



LEO:  Yeah, so if you use something like Anonymizer, or if you used something like...



STEVE:  Or the TOR network.



LEO:  TOR, the Boss, these things, the iPhantom technology, all of these are basically encrypted out of - from your browser to their host.  Now, of course you have to trust them because they unencrypt it, then pass it along.



STEVE:  Yeah, there was that wacky little thing, too, called iPig, which had the unfortunate name.



LEO:  I don't know what that is.



STEVE:  It's like it was - we talked about it years ago.  Internet something, I mean, it's an acronym [iOpus Private Internet Gateway] that's unfortunate, iPig.



LEO:  It is very unfortunate, yeah.



STEVE:  And it's a little freebie you can download which encrypts your connection to them.  I remember vetting the security of it, and it's a nice solution.  They're not doing a complete VPN.  They're just scrambling the traffic between your machine and their server, whereupon they let it out onto the Internet.  But all you really need is you need it just to be encrypted as it passes through your ISP.  And once it gets out of your ISP's grip, then it would, for example, go to the iPig servers.  And the thing that's nice about it is that it's free.  I think there was some bandwidth limitation for how much bandwidth you could move.  So you weren't - you didn't want to be doing, you know, big music downloads for that.  But for casual web surfing and email, that's another option which might make sense.



LEO:  Pretty cool, actually, iPig [snorting].  Oh, listen to me, I'm sorry.



STEVE:  Thank you for the sound effects, Leo.



LEO:  Had a little snort there [clearing throat].  Dan Hunt in Central Queensland, Australia, has been hunting for the PayPal one-time-use credit card.  Hi, Steve and Leo.  I've been trying to find the PayPal one-time-use credit card for a couple of weeks off and on now.  Now matter where I look, I can't find it on my PayPal account.  I had the same trouble, I was kind of searching for it, but I found it.  He may have other reasons why he can't find it.  Earlier this evening I was having another fruitless search when I clicked on the Upgrade My Account link because I thought, what the heck, maybe it's under there.  PayPal wanted me to upgrade to a Premier account so I could accept high volumes of payment traffic and all that good stuff.



I was about to navigate away when I had a sudden epiphany.  What if, I thought to myself, Steve and Leo have different levels of account than I do?  Certainly with you buying cool security gadgets, Steve, with your PayPal account, maybe you've been upgraded to handle the traffic level and probably avoided excess fees.  My question is, are either you or Leo on basic PayPal accounts?  If not, do you know how we poor, lowly basic accountholders can even use the one-time credit cards?  I wouldn't think that PayPal would withhold something so useful from basic accountholders.  But I have little luck finding any information about it in the PayPal help sections.  Of course it could just be that since I'm from Australia, PayPal may not be sharing the cards over there yet.  That's what I thought it was.  Is it?  What is it?



STEVE:  Okay.  My guess is that's what it is.  What I wanted to tell him was that the one definite place to look is see if you can see PayPal Plug-in.  That seems to be the most visible, apparent, obvious place to look for this.



LEO:  And they're promoting that like crazy, by the way.



STEVE:  Yes.  And, I mean, I just logged into my PayPal account this morning to verify where this was located and how visible it was.  And it came up like...



LEO:  You can't miss it.



STEVE:  ...full, huge screen in the front of me.  So there was no way to miss that.  So I would suggest that Dan take a look for the PayPal Plug-in.  And that's where the Secure Card technology is located.  Now, I want to take this opportunity to mention a little experience I had since we talked about the PayPal Plug-in and about the Secure Cards.  I mentioned during the first time that I discovered it that I enjoyed using a one-time use, or single-use, as PayPal calls it, card on a website where they were sort of like forcing me into a subscription monthly renewal thing that I did not want. but there didn't seem to be any way to opt out of it.  So I thought, well, that's good.  The bad news is, they recognized, their bot recognized that my expiration date was next month, and they snuck in another charge.  Now, I was really annoyed because, first of all, this says "single-use."  So I was assuming that the card died after its single use.  It turns out it does not.  So what I discovered in today's logon...



LEO:  Oh, that's interesting.  So they could use it within the time period before the expiration.



STEVE:  Yes.



LEO:  Oh, that's not single use to me.



STEVE:  No, it's not.  It's certainly limited use.  It's like, you know, this month use.  But it's not single use.  And what's interesting, then, when I went to the Secure Cards tab under the PayPal Plug-in, it shows you all of your still live cards that you have, then the option of setting a checkbox to select them and manually close the card.  So I wanted to inform our listeners that PayPal's single-use cards are not single use.  They stay alive for multiple uses until, presumably, the expiration date is passed.  And so it is incumbent upon the user to manually shut down the card when they want it no longer to clear.



LEO:  Oh, boy.  That's, see, that's not single use.



STEVE:  No, and it's called "active."  You have, like, active cards, and then you manually go there to deactivate the card.  So anyway, it bit me.  It wasn't a very expensive bite, but it was annoying.  And now I know better.  So I wanted to pass it on to our listeners.



LEO:  And I'm pretty sure we both have Premier accounts.  I don't know, is that the one where you have to give them a bank account to make it a Premier account?  What exactly...



STEVE:  No.  That's a verified address account.  I don't know exactly what number, how they refer to it, what their term is for that.  But I may - I'm a verified PayPal user, meaning that I had to give them my bank account information and an address.  And so I have a verified shipping address, which some sellers, for example some eBay sellers require you to be PayPal verified or they just won't - they won't sell anything to you.



LEO:  Right, yeah, no...



STEVE:  So I have that.  My guess is that it's just an Australia thing.



LEO:  I'm looking, too, and I see I'm verified.  I'm not Premier.  So, yeah, it's an Australia thing.  And if you think about it, that makes sense because credit cards are handled differently in every country.  They just can't, you know, that makes perfect sense.  I understand.



STEVE:  And you have laws and regulations and all that mumbo jumbo.



LEO:  Right, right.  Yeah, by the way, verified is probably a good thing.  If you're going to do business with anybody on PayPal, make sure they're verified.



STEVE:  Although the problem is, once you're verified, then you're in that eternal PayPal wants to take money from your checking account mode with no way to override that and have them default to your credit card.  So every single time that I do this - oh, and of course the other problem with the single-use credit card is there's no way to redirect that back to your credit card.  It insists upon taking from your checking account.  So it's probably not even available unless you're a verified user.



LEO:  That's interesting.  Wow.  Yeah, PayPal has some frustrations in it.



STEVE:  Yeah.  Like I said, there's no company more than PayPal that needs good competition to come along.



LEO:  Yeah, no kidding.



STEVE:  And I have to say, though, I really do like Google Checkout.  I'm now using - I'm using it more and more because it's a simpler form.  It's becoming more widely used.  You register yourself in the same way, giving them your own real long-life credit card and your shipping data.  But it's a single-click checkout where Google provides not only the - they privatize, keep private from the vendor your account information.  They merely do the electronic transfer.  But they also provide the shipping address.  So it's just, you know, it saves you filling out a form yet again if you're someone who's buying a lot of stuff, physical goods over the Internet.



LEO:  eBay has announced that they're going to improve the buyer protection on PayPal.  Just right after I got ripped off.



STEVE:  Whatever happened with that, Leo?  I mean, is it still...



LEO:  It's still, you know, I escalated it all the way into a dispute, and they're investigating it.  But I don't have very high hopes of getting my money back.  Because the seller had only insured it - I wish I'd paid a little bit more attention.  You know, I knew enough on eBay to look to make sure that he had 100 percent rating and had done a lot of transactions.  But there was also a little giveaway which was that he'd only insured the transaction with PayPal for 200 bucks.  It's the seller's responsibility to do that.  And it was a $2,150 camera by the end of the auction.  And I wish he'd insured - well, he's not.  He's a crook.  He's not going to insure it for anything.  I'm surprised he had 200 bucks insurance.  He didn't want to spend the extra money on the...



STEVE:  Now, if that was off of your credit card, are you not able to challenge that charge?



LEO:  But it wasn't.  It was out of my PayPal account.  That's why you want to use a credit card.  You're exactly right.  Had it been a credit card, I'd have no problem.  And it's up to PayPal now to decide whether they want to pay me back or not.  And I suspect what I'll get is a check for 100-some bucks minus their fees out of the 200 bucks insurance and that's it.  And so they, you know, because - in Australia it's interesting because they're trying to encourage - they want to make it so you can only pay for eBay purchases with PayPal because they own PayPal.  And the Australian Consumer Commission turned them down.  So I think this is in response to that.  They're adding to the protections, they're increasing the amount that PayPal will be liable if you get ripped off, that kind of thing.  Too late for me.



STEVE:  Yeah.



LEO:  Matt, his real name is Mariusz, but Matt Cybulski in Newcastle, Ontario, Canada is asking about Hotspot Shield.  Hello, Steve and Leo.  I just finished listening to SN-149, ISP Privacy.  And I've been wondering if there could be a bit of hope left for anonymity online.  I've downloaded and installed Hotspot Shield - HotspotShield.com - and ran my computer through ShieldsUP!.  Everything except Ping Reply came back as stealth.  And even the unique string that identifies my computer came back as "Internet connection has no reverse DNS."  Even my IP address changes from one that is issued to me by my ISP.  Wow.  So does that mean I can't be tracked by my ISP?  Of if I can is it then limited somewhat, and what would the limitations be?  Also while using Hotspot Shield should I be concerned about the tracking technologies that you mentioned on your last episode, NebuAds and Phorms?  Please, if I'm missing something, I'd love to hear about it.  There's nothing worse than a false sense of security.  I agree.  I love your shows, and I occasionally revisit them as this is the one show that makes me put my propeller hat on.  In fact, sometimes it gets so geeky I need to hear it more than once.  Keep up the great work.  That's why we have the transcription, so you can read along.



STEVE:  I wanted to mention, I wanted to bring this up because Hotspot Shield is a nice-looking solution for exactly this problem.  It is free.  There is a total bandwidth usage limit.  I believe that they run a rolling 30-day window through your usage.  And so if during any 30-day period of time you hit a certain bandwidth cap, then they'll say, okay, no more.  But you are able to purchase additional bandwidth.  So their hook is that, you know, they get you into their service by making it free.  You download a little client which you run in your machine, which redirects all of your traffic, encrypted, to them, very much like the other similar HotSpot type of technology we've talked about before.  And only if you are a massive bandwidth user do you run across their ceiling.  And then if you decide to, you're able to pay in order to get additional bandwidth transit.  So HotspotShield.com is a solution which, by encrypting your traffic past your ISP, as it flows past your ISP, prevents you from having to worry about any of this kind of snooping going on.



The problem is, as with any of these sort of third-party solutions where your computer is terminating - and the same is the case, for example, with iPig - is you're going to see some performance hit because depending upon their bandwidth and how busy their servers are, all the traffic is going to them first, then coming to you, as opposed to going directly to you.  So it's probably not going to be any faster.  It will be somewhat slower.  The question is, you know, how much is somewhat.



LEO:  By the way, Bull Durham in our chatroom sent me the address for iPig.  It stands for iOpus Private Internet Gateway.



STEVE:  There we go.  That's the exact...



LEO:  Yeah, it's still around.  It's iOpus.com is the company that makes the iPig.  Bad name.  But as you say, good technology.  So this is somewhat similar.  I don't understand exactly how Hotspot Shield works.  Is it a firewall?  Or is it a VPN?



STEVE:  No, it's just - it's a lightweight VPN solution.



LEO:  Okay, okay.  And iPig is not, but has some of the same features.



STEVE:  Well, no, it is also.  What I remember from iPig was that the author and I exchanged some dialogue back when I was originally checking it out, and I participated in their online forums because I wanted to understand - it wasn't very well documented, so I wanted to understand what it was that he was doing.  There are some instances where NAT-sensitive protocols like FTP would not function.  And when I mentioned that to him he said, oh, that's why FTP doesn't work.  And I said, uh, yeah.  So there are some things that it'll have problems with because it's just intercepting your traffic and sort of moving your traffic over to their server and then emitting it again.  And he's just changing the IP on the outside of the packets so that they come back to them.  The problem is, so it's not performing a full packet-inspecting NAT operation, which, for example, our NAT routers do.  So there are some things that won't work quite right.  But things like web serving and email it will have no problem with.



LEO:  Okay.  That's the frustration about these solutions is if things don't quite work right, it's kind of like, how long are you going to put up with that before you go, I'm turning this off.



STEVE:  Yeah, exactly.



LEO:  Carol - I'm sorry, Chris Noble in Wellington, New Zealand notes that some third-party cookies are needed.  Oh, here's the...



STEVE:  Here is the comment.



LEO:  Here's the comment.  Hi, Steve.  Just listened to your latest episode of Security Now!, heard you mention about third-party cookies in Firefox 3.  I, too, am glad I can disable third-party cookies again.  You might like to mention to listeners this will break some very useful add-ons, in particular Foxmarks, which Chris and I both use for syncing bookmarks between different Firefox installs, and Google Reader Notifier for alerting you to news items in your subscribed feeds, new news items.  Both of these add-ons require cookies to function.  And these are treated as third-party cookies by Firefox, presumably as they're set without actually being on the respective websites, which is the exact point of the Google Reader Notifier in particular.  The solution is to leave third-party cookies disabled but to add - ah, I'm going to do this right now - Foxmarks.com and Google.com into the exceptions list as allowed cookies, whitelist them on demand.  There may well be other add-ons that require cookies in a similar fashion, but these two are probably among the most widely used.  Thanks to you and Leo for a fantastic resource in your weekly shows.  Please keep up the good work.  That, I was going to look for that capability, actually.



STEVE:  Yes.  And so we will be talking here before long about cookies in painful detail, coming up with some strategies for people who want a sort of not-in-your-face, quick solution.  And there are people who are willing to do a little more manual cookie management, who really are more concerned about just really not having anyone able to easily track them on the 'Net.  And so this is going to work out well because next week we're going to talk about the Phorm system that has just, I mean, it is cookie overload on steroids, which is what they do to you.  We'll explain how that works.  And then not long from now I'll finally be able to unveil the work I've been doing on cookie management at GRC.  And that'll be the forum for talking about some strategies that people will be able to use in general for managing their browser cookies.



LEO:  I'll defer this till then, but I'm really curious as to really how dangerous cookies are.  And if they're really, I mean, people really get crazy about cookies and worried about cookies.  And I know that third-party cookies are.



STEVE:  Yeah.  And I agree with you, Leo, it's like my feeling is, with very few exceptions like you've just mentioned, for example Foxmarks, you just don't need third-party cookies.  And they're so easy to disable.  And just doing that, and then whitelisting the very few of them that you might need, solves the problem.  And it's just, like, they should be off by default.



LEO:  Right.  Well, I've just changed my browser, as we were talking, to exclude - to accept third-party cookies from Foxmarks but no one else.



STEVE:  Cool.



LEO:  Joshua Brickner in Loveland, Colorado had some interesting questions about data erasure.  He says:  Hi, Steve and Leo.  My question is regarding recovering erased data on a hard disk drive.  I've heard on your show that it's possible for data recovery labs to glean erased data from hard disk drives even after a 35-pass erase, using forensic technology.  Did we say that?



STEVE:  No.  So the first thing I want to do is to correct that mistaken impression from Joshua.  But go ahead, and I'll do the whole thing at once.



LEO:  Okay, we'll do it all at once.  Let's say you have two hard drives, we'll call them A and B.  Hard drive A had sensitive data on it, but that data was purposely removed using a 35-pass erase.  After that...



STEVE:  And 12 months later...



LEO:  No kidding.  After that, hard drive A was then repurposed as an everyday, nonsensitive drive.  Later on, hard drive A is backed up to hard drive B using Time Machine on OS X or some other backup program.  Do the traces of sensitive data left over from before the 35-pass erase that are supposedly there get transferred onto hard drive B during the backup?  Or are they unique to hard drive A?  Would both hard drive A and B need to be destroyed to be truly secure?  Just curious.  Love the show.  So he's asking, if you backup a drive, and there are forensically detectable traces of previous data on the original, does that get backed up, as well?



STEVE:  Exactly.  That's the question he's asking.  Okay, so first of all, relative to data erasure, we absolutely know, and it's been confirmed, that if you simply wipe a drive with zeroes, for example, you just do a low-level format of the drive that just writes zeroes on the sectors, we know that it is possible for that most recent erasure to be penetrated by somebody, a forensic data recovery company that specializes in doing so.  However, if you write a couple passes of pseudorandom data, just noise, every time you write, you are suppressing what was there before.



LEO:  These are like electrical traces that are left around; right?



STEVE:  Yes, yes.  The idea, it's like imagine an audiotape recording, the old-fashioned reel-to-reel days.  If you recorded something on audiotape, and then you recorded silence, you re-recorded over the audiotape, and you just recorded silence, it was possible for technicians to pull the previous analog recording out of the background noise.



LEO:  Right, right.



STEVE:  Sort of like a really, really faint whisper so that - because it was analog data that was written over previous analog data.  Well, even though hard drives are digital technology, the actual waveforms that are being written are so tightly packed together that the square waves meet each other, and you're actually recording something that is more analog-like than it is digital.



LEO:  Oh, interesting.



STEVE:  So there's a whisper of the previous data from before, just faintly in the background.  And if you know what the foreground is, and you subtract that from what you are receiving or reading back, you can - that whisper is still there, very, very faint.  And if you then amplify that, you can recover from one, certainly from one prior erasure.  It is not the case, however, that you can do that after you have written random noise a couple times.



LEO:  A couple of times.  Not even 35.  Just two or three times.



STEVE:  I really - yes, two or three.  And so the whisper that you would recover would be the previous noise.  And then if you tried to remove that, I mean, at that point it just, I mean, two passes is almost certainly enough.  Okay.  Then his second question is, if you were to read the data from drive A and copy to drive B, is any of that whisper going to be copied across?  And there the answer is an absolute, definitive no.  Because the whole point of a drive is to only return the most recently written data.  And it's all digital.  So that all of that little whispering I'm talking about, that exists only inside the drive.  And always what the drive is going to return is nice, clean, digitized results, which is the actual digital data that goes across the cable to the motherboard.  So when all of this forensic magic is being done, they're not doing it at the regular connector that we connect to when we interconnect our motherboards to drives.  They're in there reading analog data off the heads before the drive has a chance to digitize it back into ones and zeroes in order to have a chance to pick up this whispering data which the drive immediately clobbers and only returns to you what was most recently written on the sector.  So there's no way for those whispers to get across to another drive.



LEO:  Just not going to happen.  Don't worry about it.  Rob in Southern Illinois is not happy about next-generation behavioral tracking and profiling systems.  He says...



STEVE:  And nobody is, by the way.



LEO:  Yeah.  I'm happy, well, the people who make them are happy about them.



STEVE:  I don't think even they're that happy at the moment because this has really caused a big storm.



LEO:  If they're happy, they should stop being happy right now.  He says:  Hi, Steve and Leo.  Regarding your podcast about ISP Betrayal, I'm very disturbed by this technology.  If access is given to all traffic, email is an example where a lot of data can be gathered and used for who knows what.  The majority of PC users do not understand email is plaintext in most cases.  This technology would give access to all kinds of information in emails, including usernames, passwords, personal information, confidential information, et cetera.  This is plumb scary to me, both personally and professionally.  This technology should be stopped, in my opinion.  Thanks for the awesome podcast.  P.S.:  Steve, SpinRite's saved the day many times since I purchased the software.  Keep up the great work.  Hey, can I just say one thing?  If you're sending email and not thinking of it as just like sending a postcard, you've got the wrong idea anyway.  You're assuming your email's secure, come on.  Right?



STEVE:  Yeah.  Although I think the point that Rob is making, and this is I think what really put a chill in people, is that when an ISP begins this kind of profiling, they're really on a slippery slope.  I mean, they're trying to say we're just a bandwidth provider.  We're not going to prevent porn or spam or hacking or any kind of obnoxious behavior.  We're just a common carrier.  And there's a formal definition for what a common carrier is.  And part of what - essentially they're saying we're taking no responsibility whatsoever for the content.  We're just providing you the bandwidth.  Well, suddenly now they're saying, ah, but we're going to make some money by selling profiles of you to a third party.  Well, that really does change the nature of their relationship with their customers.



LEO:  Well, I agree with you 100 percent.  But even if none of this were happening, I mean, anybody who sends data through email is asking for trouble because it's not just your ISP.  It goes through a bunch of servers.  And it's unencrypted.  It's in the clear.



STEVE:  Yes.  And you might also note that even if you had a secure connection to your ISP or to even a third-party email server, well, when it's collected by the other end it's going to be in the clear.  So...



LEO:  That's why, you know, if you're not encrypting your email, you must consider it publicly visible.  It's like sending a postcard.



STEVE:  Yes.  If you are not doing end-to-end encryption, where you encrypt it before it leaves your machine, it's a pseudorandom blob of noise during its entire transit between multiple email servers.  And then your recipient receives it as a blob of pseudorandom noise, which they then decrypt at their machine back into plaintext.  That's the only way for email to be safe.



LEO:  PGP or the like.



STEVE:  End to end, yes.



LEO:  I use a Gnu - it's called Gnu Privacy Guard, GPG.  It's free, it's open source.  And for instance, the guy who does our TWiT site, Gordon Heydon, he's a great programmer, he's in Australia, Drupal expert.  He said, can you send me the root password for the server because I'd like to upgrade PHP.  Well, you'd better believe I encrypted that email to him.  You just, I mean, email is not secure.  So let's not assume it is secure or it's suddenly become insecure because of your ISP.  It never has been.



Question 12, Mark De Nardo, Bethlehem, Pennsylvania wonders about possible new trackers in email:  Steve, in getting copies of email to my Blackberry, the Blackberry doesn't offer HTML viewing of email.  By the way, enterprise device, that's why.  Good thing.  So I can see the email source.  I've noticed a company called MX Logic - this is the company that we subcontract our corporate email spam scanning to - is supplying graphics on several emails, but the name of the graphic is blah blah blah images slash transparent.gif.



STEVE:  Yeah, but notice it's portal.mxlogic.com.



LEO:  Okay.  So the graphic is coming from their site.



STEVE:  Yes.



LEO:  Why would an email have a transparent graphic?  Is this another counter/tracker scheme?  I'm also a bit disturbed the Outlook, Outlook Express and Windows Live Mail won't let me read my mail as text-only so I can see these types of hidden graphics.  And finally, if I may, I'd just like to say I drive an hour each way to work daily and listen to Security Now! and several other netcasts provided by Leo and TWiT.tv.  I enjoy the way you and Leo share your knowledge.  I'm a 50-plus-year-old geek who's been able to take his hobby with computers and make a career of it in the corporate world.  Yay, Mark.  Also a proud owner of SpinRite and have found it very useful over the years.  So, yes, this transparent GIF, you see them a lot now.



STEVE:  Well, yes.  And this is absolutely tracking.  And this is why I'm so down on third-party cookies.  This is, I mean, this is what third-party cookies allow is that when your browser opens this image, it's going to pull this, and this MXLogic.com is going to know that you viewed the file.  Now, we have to presume that - he said that this MX Logic is the people that this company, his corporation, is having do their spam scanning.  So what's a little disturbing is in the process of scanning the spam they are...



[Talking simultaneously]



STEVE:  Yes, they're modifying the contents of the email which is passing through their spam scanner.  And we don't know why.  Now, maybe this is part of their feedback.  Essentially he said that it's called transparent.gif.  We have to assume that there's no visual content there, in fact it's deliberately transparent so that it doesn't show up in a normal HTML viewer.  But what that means is that when the email is viewed, their server will receive a little ping.  Now, there's no other information in the URL.  So it's not clear what information they're going to get except they're going to get the IP of the reader of the email at the time that that email is opened and read.  So it's hard to know why they're doing this.  But it is a little annoying that they're modifying the email which they are scanning.  That's, you know, I'm sure it's in the fine print of their agreement somewhere.  But it certainly is the case, I mean, these were called "web beacons" when they first appeared.  And apparently this is still going on.  There are websites that put these, either one-by-one pixel so that they're not very visible, or they're transparent, and they're used specifically for third-party servers to transact third-party cookies for the purpose of tracking.



LEO:  Yeah, I mean, and spammers do this, too.  So, and there are...



STEVE:  So they know if you're...



[Talking simultaneously]



STEVE:  ...if you're somebody, yes, exactly.



LEO:  And it doesn't have to be by your browser because most - and unfortunately most email programs will render an HTML email.  They use your browser's engine.  In the case of Windows they use Internet Explorer; in the case of the Mac they use the WebKit.  They render it using the browser engine.  And at that point they pull that graphic down.  They ping the server and say, yeah, he's reading it.  Got it right now.  He's opening it up right now.  Of course...



STEVE:  And they know that then it's a real person that they've got, and not just some random, made-up email address.  You just verified that you exist.



LEO:  That's the chief value to a spammer, of course.  And that's why I know you recommend this, I certainly do it, is turn off HTML preview in your email program.  In fact, I really - it's hard to get people to get this, that HTML is a bad thing for email.  For so many reasons.  For security, for privacy.  You know, you can hide where the link comes from, that's how phishing works because the link isn't apparent.  You can't see what the link is, it just looks like a good link.  It's fat.  It makes email messages much, much bigger.  There's just - there's no reason for HTML email to exist.  And yet we're moving inexorably in that direction, and all email's going to be HTML now.  It's too bad.



STEVE:  Yes, it is.  And of course it can also carry scripts.  And the last thing you want is your email to be executed.  



LEO:  Gee.  I mean, who thought that was a good idea?



STEVE:  Uh, let's see.  They wouldn't be up in Redmond, would they?



LEO:  Well, to their credit they have, over time, they've disabled this, more and more features of email.  And what they've done lately in Outlook and Outlook Express and Windows Live Mail is it will not display a graphic automatically.  Right?



STEVE:  Yeah, and that only took, what, ten years?  About a decade.



LEO:  But I think they, you know - now, of course, I get a lot of calls to my radio show saying why won't my graphics display?  I don't understand it.  They should display.  No, I think there's a setting in Apple Mail because my Apple Mail does not display graphics.  I don't know if it's default or not, but my Apple Mail does not display graphics by default.  You have to push a button that says Load Images.  So in those cases, if there's a transparent graphic or a one-by-one GIF there, that's protecting you; right?  They won't show up.



STEVE:  Yes, yes, correct.



LEO:  I just wanted to make sure that was the case.



STEVE:  Yeah.  They won't show up, they won't be rendered, and they will not make a query out to some other random server saying "ping."



LEO:  Hello.  I'm here.  Honey, I'm home.  All right, Steve.  We've gone through 12 great questions.  We thank everybody for sending those questions.  It's really nice to have them.  If you want to ask questions for - we don't do it every episode, every other episode.  They can go to GRC.com/securitynow and ask them there; right?



STEVE:  It's actually GRC.com/feedback.



LEO:  Feedback, okay.  Now, if you go to GRC.com/securitynow, that's where you'll find all of the Security Now! episodes, 150 strong.  There are 16KB versions for people who have bandwidth issues.  There are transcripts, text transcripts.  I think that's a great way to read along while Steve talks, to understand it better.  Many people like to have that visual input along with the auditory input.  And don't forget, GRC.com's the same place you go to find SpinRite, Steve's incredible hard drive maintenance utility, must have, and all of his great freebies including ShieldsUP!, Wizmo, Don't Shoot The Messenger - or Shoot The Messenger, actually - Unplug n' Pray - you do want to Shoot The Messenger - and many other great programs.  A lot of them, though, the good news is, and I'm sure you're happy about this, no longer necessary because of changes Microsoft has made to Windows, perhaps to some degree in response to your criticisms.



STEVE:  I don't think that they're responding to me at all.  I just think they're moving forward.  But for what it's worth, people who are able to use all the freeware that I've written had the benefit of these improvements years before Microsoft got around to it.



LEO:  Right, exactly.



STEVE:  So that's certainly been good.  And...



LEO:  And there's still places where you want it, like turning off Universal Plug and Play and stuff like that.  Still very valuable.  You'll find it all there, GRC.com.



STEVE:  Next week we're going to - I warn people now.  Have your propeller beanie hats handy.  It's going to be a very deep technical, but really interesting, episode.  We're going to go into the Phorm system, which is arguably the most horrific of the systems I've looked at closely that supports ISP betrayal of their customers, and see exactly what it takes to track somebody who doesn't want to be tracked.  It turns out what they do is just amazing.  And it bypasses third-party cookie protections.



LEO:  Wow.  This is good stuff.  And I love it when we get geeky.  So get ready, get your propeller hats on, kids, for next week.



STEVE:  Gonna have a full geek episode next week.



LEO:  All right, great.  Steve, thank you for being here.  We really appreciate all your help and the great show you do.  And we'll see you next Thursday on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#151

DATE:		July 3, 2008

TITLE:		Phracking Phorm

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-151.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo continue their discussion of "ISP Betrayal" with a careful explanation of the intrusive technology created by Phorm and currently threatening to be deployed by ISPs, for profit, against their own customers.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 151 for July 3, 2008:  Phracking Phorm.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, our sesquicentennial episode.  Steve Gibson is here from Irvine, California.



STEVE GIBSON:  Aren't we sesquicentennial plus one?



LEO:  Is this 151?  You're right.



STEVE:  Sesquicentennial was last week.



LEO:  You're right.  What was I thinking?  Well, but, you know, it's that old "when does the year 2000 begin" thing; right?



STEVE:  I hate that, that zero or one.  Are we counting from zero, or are we counting from one?



LEO:  Well, we counted from one.  So I guess we can say this is our second...



STEVE:  Go ahead, I'm sorry.



LEO:  It's our second sesquicentennial of - I don't know.



STEVE:  Well, this is a big one, too.  There's been a huge amount of interest about our promise this week to discuss the technology, the horrifying technology which is being used by the Phorm system essentially to spy on ISP customers without their knowledge, unless they're clued in to what's going on.  So we opened the topic two weeks ago, discussing this whole notion of the betrayal of ISP trust which is beginning to happen.  And so this week our main topic is to talk about all of the specific details of what Phorm is doing in order to achieve long-term profiling of ISP customers.



LEO:  These are advertising platforms.  Or at least they bill themselves as advertising platforms, not as spy platforms.  We should mention that.  Actually I got an email, and I sent it along to you, from the folks at Front Porch, who said we'd like to, you know, talk about what we do.  Do you - at some point I guess we could give them a chance to explain it, I don't know...



STEVE:  Oh, I'd like to very much.  In fact, you also sent one, and another guy contacted me through GRC and on the newsgroups who's been very active in the U.K. in anti-Phorm stuff.  And so we're going to have him on the podcast in two weeks to talk about sort of the political and regulatory and, I mean, he's really been in the fray.  And of course Phorm is the - one of the sites that we'll talk about is registered in New York, and they have corporate offices in New York.  So despite the fact that they've also got a presence in the U.K., they're very much planning to attack the U.S., much as they have already been very active - too active, everyone would believe - over in the U.K.



LEO:  Well, and an update on our conversation here, and some really good news, at least I think so, Charter has announced that they're not going to go forward with the NebuAd program that they were talking about.



STEVE:  Yup.  And NebuAd is a different approach to achieving the same sort of concept, you know, it's the same sort of ISP-installed equipment.  And NebuAd, well, it's hard to say one is worse than the other from a technology standpoint.  They do inject JavaScript into the pages that ISP customers download, which is what Phorm was trying to do a couple years ago, in '06 and '07.  That was the early approach that Phorm was taking.  They messed that up so badly that they backed off from that approach.  So anyway, we'll go over all that today.



LEO:  So I'm glad you've kind of lifted, pried this rock up, and you're shining some light in here.  Because clearly the spiders are moving.



STEVE:  Well, and you know, it's the sort of feeling like when I download software now, or go to a website, often now I'm confronted with an interception page that is showing me something full screen.  And then up at the top it says, "If you'd like to bypass this ad, click here."  And it's like...



LEO:  I hate that.



STEVE:  ...yes, I want to bypass this ad.



LEO:  It's so funny that they give you that option.  I mean, of course you don't want to watch it.



STEVE:  And so my point is that we began with less annoying ads.  Then we went to Flash, where they've got dancing fish prancing around the screen.  And now we've got interception pages.  And so my concern is that if we allow ISPs to give third parties a foothold in their facility, if they have the ability to start intercepting our traffic, and that becomes acceptable, then what's next?  I mean, you could easily imagine email filtering follows on.  It's like, oh, well, we're just doing - we're not reading your email, we're just doing a keyword scan to determine kind of what kind of categories you fall into.  And then when you go on the web we'll be able to deliver more targeted advertising.  So my point is, I guess, that I think the sense is this ought to be nipped in the bud and stopped immediately, before it goes any further.



LEO:  Yeah.  I mean...



STEVE:  [Indiscernible] got a whole bunch of other stuff to talk about.



LEO:  Yes, we are.  Okay.  Let's - I tell you what.  I know, there's so many things I want to say.  Let's get to some of the top security stories.  And we also have some updates, I'm sure, from the week past.



STEVE:  Yup.



LEO:  And then we can get to the main topic, which is Phorm.  And then at that point maybe I'll talk a little bit more because I want to say, you know, we're advertising supported.  I don't think advertising is necessarily bad.  But I think that there are ways to do it that are acceptable.  And I think there are some philosophical issues here as well as some security and privacy issues.



STEVE:  And here I am wanting to follow up and continue talking about this.  For example, websites are just not that expensive to put up.



LEO:  Right.



STEVE:  I mean, so there was all this early nonsense about, oh, well, if it weren't for the ads, we wouldn't have the web.  It's like, yes, we would.  We had the web before we had advertising.  So it's not...



LEO:  Well, not only that.  There are, like, a million Web 2.0 sites that are fairly expensive that aren't doing any advertising.  So you don't - obviously the ads aren't necessary.  Yeah, I don't diss anybody's right to make a living doing what they're doing.  And, look, the ads are necessary for what we do.  We spend more than a quarter million dollars a year now on producing content, so we have to have some revenue come back for TWiT.



STEVE:  Right.  And so, for example, I think what's happened is popular websites have said, oh, let's just do a little experiment here and see what kind of revenue we can generate.  And when they actually start generating cash from visitors who are encountering their ads, then they think, wow, this doesn't just have to be a black hole that our money all goes into.  It can support itself.  I mean, which is a good thing.  Although, again, this notion of going to a blocking page presenting you with not the URL you clicked on...



LEO:  That drives me crazy.



STEVE:  ...and then you have to do something or to bypass it, that's, again, it's becoming...



LEO:  I'll tell you what I think about all that in a second.  But let's talk right now about what's been going on in the world of security because there are a few important security bulletins I'm sure people want to hear.



STEVE:  Yes.  I noted that a copy of Acrobat that I had installed on one of my machines updated itself since we last spoke.



LEO:  How could you tell?  It's updating itself every five seconds, it seems like.



STEVE:  Yeah, well, I mean, Adobe's really in the middle of security nightmare land, at this point.  They've got another JavaScript parsing vulnerability which is being exploited in the wild.  There are some situations where, without any user interaction, a PDF document will display itself.  If that were a malicious PDF document, which...



LEO:  Is there such a thing?



STEVE:  Oh, yeah, which this vulnerability now is again closing.  I mean, there are a continuing series of these JavaScript parsing bugs in Acrobat that are being uncovered and are quickly being exploited.  So I did want to let people know, if they've got Acrobat and they use it a lot, they may want to - and they don't have, like, automatic updates and checks and so forth verified, it's worth going into the toolbar and saying check for update and make sure that you have updated yourself recently because there is - this is in the wild.  It's being exploited.  Again, it's not like it's going to be a huge problem.  But people listen to Security Now! because they want to know about this stuff.  So there is one.  Also the Safari version, the Safari for Windows has a number of vulnerabilities that Apple has just recently patched.  Two of them are remote code execution vulnerabilities.  So that's definitely worth updating also for any people who, for some reason, are running Safari under Windows.



LEO:  There's a - Apple updated its own operating system, OS X, with a fairly major update.  At least that's judging by the way they number these.  10.5.4 came out yesterday.  But of course I haven't seen exactly what they patched.  But I'm sure there's some security patches on there.



STEVE:  No doubt a lot.  And you know how we were talking sort of anecdotally a week or two ago, wondering about Microsoft, the effectiveness and value of Microsoft's software removal tool, which they're constantly updating, as we said.  Certainly every second Tuesday of the month we get a new version of the Malicious Software Removal Tool.  There was an interesting statistic that was revealed by Microsoft.   330 million copies of the Malicious Software Removal Tool were downloaded in June, and it was updated to remove a particularly pernicious game-password-stealing malware, and it encountered and removed two million copies of this game-password-stealing software on Windows machines.



LEO:  This is a big business in Asia in particular.  These online games are big business.  And I've seen, there have been a lot of security flaws or viruses trying to take advantage of this fact and stealing game passwords.  You'd think who cares; right?



STEVE:  Well, of course the reason is that now games have become such a big deal that, if someone gets your username and password and logs on as you, they're able to steal the resources and sell them for cash.  I mean, they can turn them into money.  So, and as a matter of fact, you mentioned Asia, it is the case that more than half of these instances of malware were found at Chinese IP addresses.  So there dose seem to be a real concentration of that over in China.



LEO:  I think they're worth more in China, I guess.



STEVE:  I updated Wizmo, my little wacky Windows gizmo, with two new commands.  I don't know, I was just in the mood late last week.  I got another piece of email that my tech support guy Greg forwarded to me with a Wizmo person saying please, please, please could you just give me a command for locking my computer.  I mean, locking the computer, a Windows machine, is not hard.  You do Control-Alt-Delete, and then you choose Lock.  But it's the most requested new feature in Wizmo.  So it's like, okay, fine, I give up, I'm putting "lock" in.  And then I tried combining it with "monoff," which turns off the monitor.  And that sort of - you can do it that way, say "wizmo lock monoff."  And you set that up as a shortcut on, for example, down in your toolbar.  And you just do a one-click.  And so anyway, but it doesn't work as well as it could.  So I did a second command called "blindlock."  And, you know, Wizmo you can find at GRC.com just under our main menu in freeware, or also GRC.com/freeware.  And "blindlock" locks the system and then powers off all the monitors and keeps them off.  So it looks like the system, you know, you're not getting any clues, you can't see the username which you otherwise can see if you just use the "lock" command or if you just lock the system.  So you can't see that.  And of course it's dangerous if you fumble around with the keyboard.  So you want to practice first just using the lock command.  And also Alt-U and Alt-P are shortcuts to the username and password fields.  So you can use those, you know, to recover from a typo when you're not able to see what you're doing.  But anyway, I know that it is the most requested feature.  And so I said, okay, what the hell, we'll just - I'll add that.  And so now Wizmo has it.



LEO:  Lot of people love Wizmo.  It's free.  You get it from GRC.com.  I didn't realize you were still getting so many feature requests.  How long has - Wizmo's been around for years.



STEVE:  Yeah, it has been.



LEO:  It's really neat.



STEVE:  I got my first SGI monitors.  And they had the ability to power down.  And I thought, hey, that's cool, I want to - I didn't use a screensaver.  But I always know when I'm getting up from my machine for some length of time.  I'm not someone who continually power cycles his computer.  So the machine was going to stay on; but I wanted the monitors to, like, turn off when I wanted them to turn off.  And so I just - that was the genesis for Wizmo.



LEO:  Is it a BIOS call that it makes, or is it a bunch of different stuff you're doing, or...



STEVE:  It's in the Windows API.  There's the whole power control API that allows you to manipulate Windows power...



LEO:  But you've expanded it much beyond power.  I mean, it does other stuff, too; right?



STEVE:  Oh, it's got the graviton screensaver that's got, you know, where all the equally gravitationally mutually attracted little white balls do all kinds of cool things.



LEO:  And it's got that new zero, wireless zero config fix, which is good.



STEVE:  Right, for turning off the wireless zero config, which is - it's amazing to me that Windows will install on a machine that has never seen a WiFi adapter...



LEO:  Isn't that silly.



STEVE:  It'll have that service running.



LEO:  Yeah, just in case, I guess, suddenly you get a WiFi adapter.



STEVE:  Yeah.



LEO:  So how could people send you suggestions?  Because already I'm seeing in the Stickam chatroom, like, four different things they want you to make Wizmo do.



STEVE:  GRC.com/feedback is the all-purpose feedback catchall for Security Now! input.  GRC.com/feedback.  Also a new version of Jungle Disk was released.



LEO:  I saw that.  I just downloaded it.  What's new in there?



STEVE:  Oh, I mean, it's got so many new things, I can't even enumerate them.  And frankly, I haven't gone yet to take the trouble to download it.  It is a free upgrade for everybody who has v1.whatever it is.  This is v2.0.  And there is also a new groupware version of Jungle Disk which is specifically designed for allowing multiple Jungle Disks to be logged into the same remote Amazon-located bucket and be able to share files.  So he's solved, basically created the ability to have a shared directory, essentially, through Jungle Disk.  One of the features that I know that it has is you're able to simultaneously access multiple buckets, which is the term he and Amazon use for, like, the equivalent of a directory, essentially.



LEO:  Right, right.



STEVE:  So but it's got a ton of new features, a whole bunch of backup.  He increased the number of things that the built-in backup facility could do because basically he's been listening to users and doing what they wanted to.



LEO:  Yeah, I like it.  The backup now has an interface right on the window so that it's very easy to start the backup, pause the backup.  You have much more control over it now.



STEVE:  Right.



LEO:  That's Jungle Disk, by the way, which we've talked about before.  But if you don't know about it, it's an interface to Amazon's S3 storage.  And it's not free, but it really adds to the - it enhances the value of S3 immensely, and it's cheap.  It's JungleDisk.com, I think it is.



STEVE:  Yeah, and it's very inexpensive.  I mean, it's...



LEO:  Oh, it's great.  20 bucks?



STEVE:  20 bucks, I think, yeah.



LEO:  What else?



STEVE:  Oh.  Also your big TWiT episode on Sunday...



LEO:  You know, first of all, I want to apologize.  What was I thinking?  You know, we're getting old-timers on.  And we tried very hard to get David Bunnell, who would have been great.  What it ended up being is old-timers in the computer magazine industry who had known Bill Gates.  Because we were talking about Bill Gates.  His last day was last Friday.  And why I didn't think of getting you on, Steve, is just beyond me.  I'm sure you have many stories to tell about Bill Gates.



STEVE:  Well, yeah.



LEO:  I apologize.  I apologize.



STEVE:  I would recommend to all Security Now! listeners, if there are any who are not listening to TWiT, it was a great podcast.



LEO:  It's so funny because I never know.  I was so nervous about doing it because it isn't, you know, TWiT's normally a news podcast.  Sure, that's the big story of the day, but we didn't cover any other stories.  It was a bunch of old guys, you know, people your age and my age, Steve.  And I thought, oh, you know, this is not going to be - and I received nothing but positive.



STEVE:  Oh, no kidding.  I'm really glad to hear that.  I thought - I was just - it was fun.  I mean, Gates is a, well, he's the richest man in the world.  But for all of the people listening to this who are involved in PCs and computers, obviously, I mean, you know, he matters.  He's...



LEO:  Yeah.  He matters more than almost any - I can't think of anybody who matters more.



STEVE:  Well, okay.  My problem with Bill is that when we get together, we tend to argue.  And...



LEO:  Why am I not - why am I not in the least bit surprised?



STEVE:  I have the utmost respect for him.  And but I recognize that he is fundamentally a brilliant businessman.  And while he once created a company called TrafOData to process traffic - the punch tape that the old traffic measuring equipment produced...



LEO:  When he was 15, I might add, or 14, yeah.



STEVE:  And then, you know, no one's really clear what involvement in coding Bill had.  But I recognize that his genius, his brilliance is that of a businessman.



LEO:  Oh, yeah.



STEVE:  And so what happens is, the trouble I get into with him is he says something which he wants to be true because it's important to Microsoft's interests that it be true, but it's not.  And most people, you know, aren't sure if it's true or not.  But I am.  And so I call him on it.



LEO:  You stand up to him, yeah.



STEVE:  Well, okay.  So the one most memorable event, and it's funny, too, because as I was listening to the podcast I was thinking, oh, shoot, I mean, I'm sure that Dvorak and...



LEO:  Bill Machrone?  Jerry Pournelle?



STEVE:  Yep, Machrone and Pournelle were all present for this because this was very public.



LEO:  Oh, boy.



STEVE:  This was the announcement of the Pentium.  And there was one - the big annual conference for the computer industry is Comdex, that I was always going to.  At the time, I was in the middle of - somewhere along my eight years of writing my weekly column in InfoWorld magazine called "Tech Talk."  Which, because I really gave it a lot of time and attention, ended up being a very, very strong component of InfoWorld.  There was the Cringely column.  And Cringely and I were vying for first place among all the different assets in that news weekly.  And sometimes he would be - he would pull out in first, and sometimes I would.  But so what I said mattered.  And in fact I was largely credited with launching Visual Basic because the gal from Microsoft, Nevet Basker, who was the original product  manager for Visual Basic, came down, paid me a visit, and showed me VB 1.0.  And I was like, oh my god, everything - this changes everything.  And it's funny because one of my programmers said this is really a bad idea.  And I said why?  And he says, this makes it too easy to program.



LEO:  He might have been right.  That might be the real problem.



STEVE:  But anyway, so I'd established my creds.  And this was the year that the Las Vegas Convention Center was being remodeled.  So Comdex was at McCormick Place in Chicago that year.



LEO:  Oh, I remember that.  I was at that Comdex, yeah.



STEVE:  Yeah.  And so the big deal at the time was Intel's release of the Pentium.  You know, we had the 286, the 386, the 486.  And it was like, okay, at Comdex Intel is announcing this new processor.  So the entire industry, the entire press community - that's why I'm sure that John and Bill Machrone and Pournelle were all there.  In fact, I remember partying with Jerry.  He's got a neat wife.  Roberta is a great hugger.  So...



LEO:  I've never met Roberta.



STEVE:  ...we always hug whenever we're together.  Jerry just sort of looks at me thinking, okay.  Anyway...



LEO:  Here comes that Gibson again.



STEVE:  Tighten your string tie.  So the whole press community is there.  We start off - and this is in the large auditorium at McCormick Place.  And we start off with Intel's presentation of the new, radically different and improved Pentium architecture.  And there are a number, you know, I'm glued to this because I want to be writing, I'm thinking this'll be good for three or four columns.  I want to explain what Intel is doing with this new architecture.  So one of the things they explained is that this thing has - and this was the first chip, I believe, with on-chip cache.  No prior processors had major on-chip cache.  But what was happening was the clock speeds of the processors were - it was moving ahead of the speed of dynamic RAM.  So there was a greater and greater disparity, so that the Pentium - there must have been some little, like, Level 1 cache; but no big, like, Level 2 cache.  So that was a big deal.  And Intel - the buzzword at the time also was still RISC.



LEO:  Oh, what a - yeah.



STEVE:  Reduced Instruction Set...



LEO:  That was the battle because Macs were running on a, quote, "RISC" chip.  And everybody was saying, well, can you get more complex with CISC?  Who's going to win, RISC or CISC?  Yeah.



STEVE:  Right.  And of course MIPS was the big RISC producer at the time.  And so Intel, of course, I mean, as an Assembly language programmer, I'd been programming the Intel chips for years, and I knew just how complex the instruction set was.  I mean, I'm still sometimes picking up my little reference book and going, okay, wait a minute, is carry set on this kind of instruction or not?  I mean, it's incredibly complicated, as opposed to being a long instruction word which is much simpler and flatter.  But Intel wanted to have RISC because, oh, that's - it was a buzzword.



So they said, oh, we've reengineered our processor from scratch.  This is a RISC core with an emulation wrapper which runs at very high speed.  So it still runs the relatively horrible Intel instruction set, but it does it much faster.  And we've profiled all this code out there.  And for the first time, thanks to this RISC core, many of the instructions which are used more often now execute in a single cycle.  And that was new.  The idea of one-cycle instructions, back in the 286, 386, 486, these things were so heavily microcoded, meaning that there was actually a ROM on the chip, and the chip was basically emulating the Intel instruction set, which is called "microcode," because the instruction set was so complicated you just couldn't do this in hardware.  You had to sort of make a computer within a computer in order to execute this instruction set.



So, okay, so we got - a whole bunch of instructions are now able to execute in a single cycle.  We've got a big on-chip cache for the first time.  So as long as all of the data for the instruction is in the cache, that's part of the requirement for a single-cycle execution.  So it meant that the benefit of executing from the cache would be much better.  And the penalty for so-called "cache miss," where you had to go out and pull that data from the increasingly slow-seeming dynamic RAM, that penalty was much greater.  So, I mean, so okay, I absorb all this.  And so...



LEO:  I just want to say something real quickly before you get to your point.  This was the beginning of a very bad road for Intel which ultimately bit them.  But go ahead.



STEVE:  Okay.



LEO:  I mean, no, seriously, this was kind of some of the problems that they ended up having was this penalty for backing up.



STEVE:  Oh, right, exactly.  Well, and the problem is that the instruction set that they were moving forward over time for the sake of upward compatibility, it was really hard to make it faster.  They had parallel execution pipelines and speculative processing where instead of - in computer jargon, you come to a branch.  And you either take it or you don't.  So they would do both.  They would take it and not take it and, like, split the execution stream.  And they were trying to execute ahead of the code so that by the time the code got there, then they would know what path to take.  I mean, it's just - it's bizarre how, I mean, like what effort they had to go to to continue making this system faster and faster.  So after the presentation, the hall lights come up in the auditorium.  And we're going to have a panel.  Now, the panel members were Philippe Kahn, Bill Gates, Fred Gibbons, and Jim Manzi.



LEO:  Now, we should probably, because there's a lot of people too young to know any of those names, which were legend in the industry then, of course...



STEVE:  Yeah, I mean, these were, like, "the" guys in the PC industry.  And the moderator was someone I knew, Stewart Alsop.  Stew wrote the PC Letter for years.  He was - for a while he was the editor-in-chief at InfoWorld, in fact.



LEO:  Little side trivia, Stewart Alsop, John C. Dvorak, Fred Davis, Gina Smith, and I did the first pilot TV show for CNET, a show I produced.



STEVE:  Oh, very true.



LEO:  And it was a great roundtable.  It was basically the precursor of TWiT and Silicon Spin and a bunch of other shows like that.



STEVE:  Yeah, and he also was a major industry figure and follower.  So he was going to moderate this panel.  Now, okay.  There was a long, long-existing blood feud essentially between Borland and Microsoft.  That is to say, between Philippe Kahn, president and founder of Borland International, and Microsoft.  What happened was that when Microsoft began all this, remember they were the language people.  And in fact that was the - back in the genesis of the PC, IBM went to DRI for the operating system and went to Microsoft for the languages.  This notion that Microsoft was an OS company hadn't been born yet.  Microsoft was into languages.  They started, of course, with BASIC for the Altair and those machines, and then they did - they had a BASIC for the Z80 and some Pascals.  Well, Microsoft's financial model at the time had their languages priced at $499.  I remember Microsoft Pascal, I mean, I just was drooling for it.  But, you know, $500, it's like, ow.



LEO:  This is where Philippe Kahn comes in.  I know where you're going.



STEVE:  Yes.  And so out of nowhere, I mean, from a company no one had ever heard of, were these huge, full-page ads for something called Turbo Pascal.



LEO:  And I loved it.



STEVE:  For $49.



LEO:  49 bucks.



STEVE:  It just blew the crap out of Microsoft's whole pricing model.



LEO:  Well, not only that, it was better; it was fast.



STEVE:  Oh, it was fantastic.  I think it was the first place, the first time we saw an integrated development environment, or at least one that size.  So you...



LEO:  And you could compile and run - write, compile, run, like this, boom boom boom boom boom.



STEVE:  Yes.  Yes.  So you run in Turbo Pascal, and your editor is there, it executes there.  And, I mean, it just ran like a bat out of hell.  Okay.  So you can imagine how Bill Gates felt about this.  It was like, I mean, this was just, you know, talk about twisting the knife in him.  Because it, I mean, it destroyed their whole pricing model.  So needless to say...



LEO:  I can see the steam coming out of his ears.



STEVE:  Oh, needless to say, I mean, there was just, I mean, it was a feud between those guys.  Now, Fred Gibbons was the CEO of Personal Software.  And I think this was just...



LEO:  They did PFS Write, PFS - all those PFS programs; right?



STEVE:  Right.  And I think this was after the medical trouble that he had, that John referred to on Sunday's podcast.  Because he had a stroke.  And, I mean, again, he was enough of a figure in the industry that this was just horrifying for those of us who knew Fred.  And, I mean, he was a neat guy.  But he was back on his feet, and so he was present.  And then Jim Manzi was Lotus, the other major factor in the PC industry with spreadsheets.  And of course Bill was pissed off at them, too, because he wanted to do Excel and everything.  But mostly he was furious with Philippe at Borland.



Okay.  So Stew, Stewart Alsop, the moderator, says first, right off the bat, first question - and I remember Philippe was on the far right of this table.  It was Philippe, Bill, Fred, and Jim Manzi was over on the left, at the left-hand side of the stage.  So Stew was closest to Philippe.  And so he says, "So, Philippe, we've just seen this presentation by Intel.  You guys, as the preeminent language compiler makers" - and there again Bill is just [growling] - "does this mean you're going to be coming out with a new line of compilers for this new processor?"  And Philippe said, "Oh, absolutely.  You know, we've been working with Intel," and he gave his Intel, pro-Intel spiel about they've been on the inside, they know all about this stuff, and they'll have immediately Pentium-aware compiler versions for their software.



Okay, now the other thing I forgot to mention was that Microsoft had been suffering under the reputation of being several chips behind for a long time.  Remember that, Leo?



LEO:  That's the story I've told where Andy Grove was just furious because Microsoft wouldn't keep up with Intel.



STEVE:  Right.  And so Microsoft's OSes - and this was the joke in the industry at Microsoft's expense was, like, the 486 was out, and they were only supporting the 286.



LEO:  Just killed them.



STEVE:  And you could run Windows on the newer processors because Microsoft had made them backward compatible.  But Windows wasn't taking advantage of any of those features.  And remember that at one point there was Windows 3.0, and then there was a Windows 386 which was sort of this weird, okay, we did something that now uses a 386.  So please just shut up about it.



LEO:  It doesn't run well, nobody uses it, no software runs on it, but we made it.



STEVE:  So the worst possible thing for Bill Gates was that another new processor has come out, and they don't have anything for it.  And...



LEO:  And it was a Pentium - it was 32-bit, too; right?



STEVE:  Yes, yeah.  So they, you know, and they have no language, you know, plans...



LEO:  New instruction set, so everything...



[Talking simultaneously]



STEVE:  So Philippe says, oh, absolutely, we're going to come up with a whole new set of languages.  Okay.  Bill cuts him off.  I mean, he finishes, but Bill interrupts him and says, "That's ridiculous.  The Pentium is completely upward compatible."  Oh, and by the way, I don't know if he's changed it now or since, but at the time Bill couldn't say "processor."  He said "prosser."  He was in a big - I don't know if he was in a hurry or what it was.  But he said, "The Pentium prosser."  We knew what he meant, and we all forgave him because he was Bill.  So...



LEO:  But I have to say also he is a first among equals at this point.  He is not Bill, the Bill Gates of later years where he's really the titan.



STEVE:  True.



LEO:  It wasn't like people were afraid of him at this point.  They were kind of - they knew him.



STEVE:  So anyway, he rails against Philippe, saying that that is ridiculous, there's absolutely no need for new languages or new compilers or new anything, this thing is compatible with the existing "prossers," and that's just a bunch of baloney.  And so I'm following this fight and waiting for Philippe to rebut.  Which he doesn't do.  And so I was, like, in the third row in the auditorium, and I stood up.



LEO:  Oh, boy.



STEVE:  And Stew saw me standing up and said, "Oh, it looks like Steve wants to weigh in..."



LEO:  Oh, boy.



STEVE:  "...on this.  And so I turned to Bill, and I said, "Well, Bill, you're wrong."  And he stares at me, not happy.  And I said, "You know, just off the top of my head, I mean, we just saw Intel's presentation.  Now, they explained that with this so-called 'RISC' core, many of the instructions which are used most often now execute in a single cycle.  Whereas other instructions are heavily microcoded because they're not used that often.  So in order to save silicon they've not tried to implement the things you don't do that often in hardware.  They've microcoded that more heavily.  But overall, it ends up being better.



"Now, a compiler has several different stages.  The back end, the so-called 'code generator,' is what takes sort of a pre-parsed language and turns it in - it emits the absolute final machine language."   I said, "That is, an optimizing compiler is all about running the resulting program as fast as possible.  So if a compiler were targeted at the Pentium processor" - I think I might have said "pro-ces-sor."



LEO:  Pro-ces-sor, three syllables, Bill.



STEVE:  "So if a compiler were targeted at the Pentium processor, knowing that it was generating code for that particular instance of the universal Intel instruction set, it would definitely choose different instruction mixes for its final product because that would run much faster on a Pentium than it would on a 486, and so on."  I mean, and to the tech-savvy audience, everybody knew I was right.



LEO:  Of course.  Intel, when they make a new chip, the first thing they do is make a reference compiler for that chip, an optimizing compiler for that chip.



STEVE:  Okay.  Then I said, "And another thing.  This is the first processor with a large Level 2 cache.  All these instructions only execute in a single cycle if all the pieces that they need are available on the cache.  Now, again, we know that there's a huge benefit for maximizing cache hits and a huge cost for going off-cache.  So again, if the compiler were targeted at a Pentium, it could know" - I think they were 4K caches at the time.  I sort of, you know, I'm not sure, but I think that's what it was.  "If it were targeted at this Pentium, and it knew that it had a 4K cache, again, it could optimize the instructions so that, like, loops and things would tend to fit in the cache and maximize cache hits in order, again, to increase performance.  So it seems very clear to me that it does make sense, as Philippe has said, to have compiler technology that recognizes what chip it's writing to."



LEO:  Yeah, but we don't have that yet, Bill.



STEVE:  And so, I mean, this is like - you could have heard a pin drop in the auditorium.  And it was extremely uncomfortable.  And then Stew said [clearing throat], "Well, okay.  Moving along, then..."



LEO:  So Bill didn't even respond.



STEVE:  He didn't at that point.  But then after, you know, we got through the whole thing, and we were milling around a little bit, he came up to me.  And he said, "Steve, you're a technical guy.  It's very important that the world not get the wrong impression about the compatibility of the Pentium 'prosser.'  And, you know, that's...."  And I said, "Bill," I said, "you know me and the care I put into communication."  I said, "I absolutely will not give the wrong impression.  But I want to be technically accurate."  And he kind of glared at me a little bit and then wandered off.



LEO:  His big concern was that, well, of course his big concern was that people would continue to buy his products over the better product from Philippe Kahn.  But I can see what he was saying is that, you know, well, this could - and by the way, this is what John was saying.  The message Bill said, and ultimately was right, is you don't have to worry about optimization because it's all going to be taken care of as these things get faster and better and better.



STEVE:  Oh, and I have to chime in something...



LEO:  He was right on that, though.



STEVE:  Had I been in the TWiT group, I would have agreed with Jerry wholeheartedly about Pascal.  It is - the failure of Pascal to win is one of the great losses in computing science.



LEO:  For people who didn't see or hear TWiT.



STEVE:  It is absolutely, absolutely my favorite language of all time.  I could write code in Pascal, and it just worked the first time.  And more significantly, if I came back to something a couple years later and looked at my own code, it was still clear to me what it did.  It was just - it was a fantastic language.  And they were right during that podcast that it was because it was - and originally UCSD Pascal was an interpretive Pascal.  You had a little front-end pseudocompiler that compiled the pseudocode, which a Pascal interpreter ran.  It allowed you to bootstrap the language environment, the UCSD Pascal environment to, you know, many different processor architectures very quickly.



LEO:  Much as Java is today, actually.



STEVE:  Yes.  And in fact one of the things that Turbo Pascal did differently was it emitted native executables, EXEs, and just ran like a bat out of hell, so...



LEO:  Yeah, well, and Jerry's point was that it was a strongly typed language.  So programmers didn't make - it actually has a security impact.  Programmers didn't - weren't allowed to make the same dumb mistakes about typing and casting and so forth.  And probably, I don't know, I'm guessing, we'd have fewer of these buffer overruns, as well, because Pascal wouldn't let you do things like that.



STEVE:  Well, it was - and it was just visually beautiful.  I mean, you know, there were...



LEO:  See, I was a C guy.  I liked C.  But that's...



STEVE:  Well, and there are languages like C where there are contests, like okay, how much can you do in one line?  



LEO:  Obfuscation, yeah.



STEVE:  You know.  And I'm trying to think, there was, oh, APL was famous for this, too.



LEO:  APL didn't even use English.  You had to put key caps on your type, on your keyboard, before you used it.



STEVE:  Yeah, you had bizarro symbols, super powerful, but they were wacky.  But anyway, so I wanted to share that anecdote because that was, you know...



LEO:  You know, if Pascal lives - I think probably most people don't use it.  But if it lives, it would live on in Delphi, right, which is pretty Pascal-like, the database programming language.



STEVE:  Yes, well, it's basically a heavily object-oriented Pascal is what Microsoft, I mean is what Borland did to it with Delphi.



LEO:  But I think that's probably the only place it still does live on except maybe in an academic environment.



STEVE:  And in my heart, Leo.



LEO:  I wish you could still get Turbo Pascal.  I think if you could get Turbo Pascal for Windows Vista, you'd see a lot more great shareware and freeware programs out there.



STEVE:  Yeah, it was a great language.  I'm sure it's around.  I mean, it probably still runs.  I wouldn't be at all surprised.



LEO:  It's not native anymore.



STEVE:  Yeah, that's true.  And lastly there were some - several people made a comment about one of Jerry's books.  This was relative to Audible and your dialogue...



LEO:  Jerry did.  Jerry said to Audible, start doing "Mote in God's Eye."



STEVE:  Well, that's the book.  In my opinion it is one of the classic sci-fi books of all time.  He and Niven, Larry Niven co-write it.  And I've read it maybe three or four times.  And it's just - it's just a fantastic read.  So I wanted to add my own "hear, hear" to Jerry, and I think also you and John also talked about "The Mote" being a spectacular book classic.



LEO:  I've never read it.  I'm going to admit it right now, I've never - I've read all of the Ringworld novels.



STEVE:  As soon as Audible does it in an Audible book format you should jump on it.



LEO:  Absolutely.  I'm in the middle of Neal Stephenson's new novel right now.  It's very, very long, and it's wonderful, but it's taken me a while to get through it.  



STEVE:  My last little point was I'm setting up a new machine.  I think I've - I know that I've told our listeners how annoyed I am that I've got a quad core machine as - I'm sitting in front of it, it's my workstation, and that only one core is ever doing anything at any point because there's nothing I'm doing that taxes it in the way, for example, that doing media does.  And so I finally got so annoyed, I had to - something I was doing, I can't remember what, I was recompressing something that took a little over 24 hours to do a two-hour video file on the machine that I had.  I thought, okay, that's just - I can't tolerate that.  So I built up a new really strong machine.  It uses the quad core Intel extreme 9675 or 9560, something, I don't know what it is.  But it's four cores, 12MB of on-chip cache.  It's in two 6MB chunks shared by each pair of cores with a 1333MHz front-side bus, DDR3 RAM.  I gave it 8GB...



LEO:  I just want to point out you're building essentially the ultimate gaming machine.  That's almost exactly the specs that we're doing for the ultimate game.  You bought the 9770.



STEVE:  Yes, that's it.  And, oh...



LEO:  $1,500, I just want to point out, $1,500 processor.



STEVE:  Oh, and in fact I used a Supermicro motherboard and case.  And Intel, in the documentation that came with the processor, they were talking about how the new and improved fan and heat sink - this thing, I mean, it's huge.  It's like a big mushroom cloud.



LEO:  But why - you just said you don't use all quad cores.  What are you doing with this?



STEVE:  This is for my media stuff, for my media work.  And but the point is that the case did not fit this huge mushroom fan heat sink.  I had to literally - I had to modify the holder of the back fan, cut away some of the plastic, and then it worked.  Because I guess Intel had just increased the size of the heat sink for this thing.  And they even have a blue LED that they've got shining out through this thing, like all those aftermarket wacky...



LEO:  People want that, what the hell, costs a penny more.



STEVE:  Exactly.  So anyway, but my point was that this thing now, as a test, I had it recompress the same thing that took 24 hours.  And it did it in better than real-time, in 57 minutes.



LEO:  You're kidding.



STEVE:  No.



LEO:  Oh, that's a significant jump.



STEVE:  So, I mean, it was...



LEO:  What kind of hard drives did you put in that?



STEVE:  I did a - I have a 3TB RAID using...



LEO:  RAID 5...



STEVE:  ...a HighPoint caching...



LEO:  I'm writing this all down.



STEVE:  ...SATA II.  So four 1TB drives that give me - running RAID 5.  So I'm pulling from essentially all of them at once and getting three times the throughput that you would get from just a single one.



LEO:  Did you use the VelociRaptors, those new 2.5-inch, 10,000 rpm drives, or...



STEVE:  No, I don't - 2.5-inch drives scare me.



LEO:  Makes you nervous, I know, yeah.



STEVE:  They just all seem like kind of flaky laptop drives to me.  I know that's crazy.



LEO:  Well, they're getting the speed because of the increased areal density.



STEVE:  I used some big 1TB Hitachi drives.  Like there's the Hitachi consumer grade, and then there's a server grade.  And I went with the server grade.  I put four of those in the case.  So, I mean, anyway, this is just my...



LEO:  How big is the power supply?



STEVE:  650 watts, I think.



LEO:  That all?



STEVE:  Think so.



LEO:  You need more, man.  I think the processors need more than that.  That's an amazing box.



STEVE:  It's got a pair of Panasonic...



LEO:  The only thing that's going to be different probably in the ultimate gaming machine, it's very close, DDR3, the 9770, 8GB of RAM, yeah, very likely, maybe less, but probably 8GB.  The only thing that's going to be different is the video subsystem.  We're probably going to do - we might do four-way SLI.  I'm not sure yet what we're going to do.



STEVE:  Ooh, wow.



LEO:  You're getting it; right?



STEVE:  It's tricky, though, because...



LEO:  Got to fit in the case.



STEVE:  You're going to have to have slots...



LEO:  I know.



STEVE:  ...that are going to fit all those cards.



LEO:  I know.  And the cards are double width.  They're huge.  So we may just do dual SLI because we just - for practical purposes.  And we're going to liquid cool.



STEVE:  Anyway, the point of all this was that in reinstalling my favorite software, I encountered one of my programs, it's called DVD-Lab PRO 2.  It is my absolute prize-winning choice for DVD authoring.  The things you want to do, like just make a DVD where you put it in and it plays a two-hour movie, it does those easily.  If you want to do more fancy, like multi-episode DVDs of, like, your favorite shows that you've captured on the air and so forth, it's easy to do menuing.  And it even gives you access to the VM in the DVD player.  I don't know if our listeners know, but DVDs actually have a virtual machine in them.



LEO:  Really.



STEVE:  And DVD authoring tools hide all that from you so that when you build a menu they're actually writing - they're, like, using canned virtual machine code to basically do all of the work behind the scenes.  Well, you don't have to mess with any of that, and I haven't yet.  But I know that it's all there.  And, for example, the authors, it's a company called MediaChance, they have, for example, a demo of a quiz system written, basically it's a quiz technology that runs on the DVD player itself using their virtual machine code.  But all of that is available.  They've got an emulator and an editor and a debugger and - anyway.



LEO:  Who makes this?  Is this Ulead?  Who does this?



STEVE:  It's MediaChance, MediaChance.com.  And the program's DVD-Lab PRO 2.  Anyway, the point of this is that when I was installing it, maybe I was upgrading or something, I went back to the site because I'm a licensed, registered user.  And one of the things that he said was "does not bother you with any online activation."



LEO:  Yay.



STEVE:  And I thought, exactly.  Because the other tool that I absolutely love that does this compression, my killer compression favorite tool, we've talked about it before, is TMPGEnc, the Tsunami MPEG encoder by Pegasys, or Pegasys-Inc.[com].  Anyway, that's the one.  But what really bothers me about these guys is that every so often it reauthorizes itself.  And so, I mean, I've paid them.  Over the years I've paid them a lot of money for a bunch of their different stuff.  And so I'm worried that this thing, they're going to go away one of these days, their authentication servers are going to be down when I need them, and this thing will not run unless it "renews your license," unquote, which it's doing autonomously, meaning that you have to have an Internet connection, and that it's, you know, it's not even, like, doing it once, like activating Windows, and then Windows will stay alive for a long time.  And then I wanted to - I was looking for a good simultaneous burning tool.  The one that I had been using didn't like this new motherboard and SATA interfaces because I've got four DVD burners, four Pioneer...



LEO:  I'm not going to ask you what you're using four DVD burners for.



STEVE:  Well, because if I need four copies of something, I don't want to have to wait and do it four times...



LEO:  Of course not, why would you.



STEVE:  ...on a single burner.  But anyway, so I used a very nice program called Gear Pro.  But it was through Digital River, who I hate.  That's the eCommerce folks.  And everything about Digital River just is...



LEO:  I have to buy stuff through there from time to time, and I don't like it either.



STEVE:  And in this case what happened was I activated it once.  And then I can't remember now why, but I rebuilt my hard drive, and it deactivated it, and I could not reactivate it.



LEO:  So you had to buy it again.



STEVE:  And, oh, well, no, I mean, I had to send an email and to explain that I, you know, I told them I resized the partition.  And I think I was just messing around with the RAID system.  And so I knew I was in trouble.  But it just bugged me.



So the point of all this is I just wanted to sort of explain my own philosophy and where SpinRite is in this spectrum.  When you buy SpinRite you receive a transaction code which is a 13-character and digit token which we email you, you see it on the screen, you can cut and copy, paste, I mean, that's the keys to the kingdom.  That's all you ever need to download SpinRite anytime, anywhere.  It does no activation, no online nonsense.  I mean, I've never done any kind of copy protection.  And I've survived.  And the last thing I'm going to do is annoy people the way so many of these contemporary software platforms now annoy people, by certainly not periodically activating and certainly not in any way imposing a limit on the number of times you can use something or download something.  And it's really come in handy for people who, for example, they're traveling with their laptop, SpinRite's at home, but they're able to, like, call home, get the code from someone else in their family, enter it into GRC's website, it gives them a fresh download link, and they download their copy of SpinRite right from our servers.  So...



LEO:  Thank you for doing that.



STEVE:  Anyway, I just - I was thinking about my approach to this relative to all of these crazy approaches that are increasingly annoying.



LEO:  I think it's good for people like you to talk about the fact that this works for you because I think there's the general impression that, well, yeah, maybe copy protection is a bad thing; but if you don't do it you're going to lose your shirt.  So I think it's really important for people who know, no, in fact, you can, this is a legitimate business practice, and it works, and you're living proof, and I think there are many examples of this.  I just wish that people would come forward and say, yeah, no, you don't have to do it.



STEVE:  And I know that SpinRite is being used illegally.



LEO:  Of course.



STEVE:  But I don't think those are lost sales.  Someone who's going to use it illegally, who's going to borrow a copy from his friend or find it somewhere online or somehow do that, they're not someone who's going to buy a copy from me.  And so...



LEO:  Don't think of them as illegal copies.  Think of them as customers who haven't paid you yet.



STEVE:  Well, and we've heard so many testimonials over the years from people who did loan, and I have no problem.  If they loan their friend a copy, it saves their butt, and then their friends - and then they say, look, SpinRite just worked for you, help GRC out, buy it.  And they do.



LEO:  People want to, I think - I believe in people.  I think if they find something of value, they pay for it.  They really do.  And if they didn't realize the value yet, then they just - they haven't paid you yet.  But people are honest, I think, in most cases.



STEVE:  And if you treat them with respect.



LEO:  If you treat them that way.  And the minute they feel like you say, oh, you're a criminal, I'm going to copy protect, then they don't mind stealing something.



STEVE:  Well, as an example, Tsunami has a lock, in my opinion, on compression.



LEO:  Yes.



STEVE:  I mean, it is a fantastic tool.  But in the same way that PayPal has a lock at the moment on what PayPal does...



LEO:  We can't wait for somebody to come along and replace them.



STEVE:  Exactly.  If there is an alternative to Tsunami that is a better compressor, that doesn't worry me by constantly needing to renew its license, I would much prefer using that.  And I'd rather support that than this nightmare of, like, worrying one of these I'm going to lose access to my favorite compressor.



LEO:  Let's talk about Phorms.  Is it P-h-o-r-m-s?



STEVE:  No "s," P-h-o-r-m.



LEO:  Phorm, okay.



STEVE:  Okay.  So this is a company that we began discussing in overview two weeks ago that pays ISPs to have their equipment installed in the ISP's data center for the purpose of monitoring the actions of the ISP's customers and aggregating profiles for the purpose of understanding what kind of websites the customers visit.  It's then an advertising networking company much like DoubleClick and so many others, which then places ads - they sell ad space on websites.  And the idea is that, for example, using Google ads as we were saying two weeks ago, when you go to a page, the Google ads you see are relevant to the page you're on.



What's different about the Phorm system, and there's a whole bunch, a collection of next-generation nightmare companies like this, they track the user, not the page.  So they figure out, by profiling what pages you look at, they figure out and divide you into categories.  And their marketing brochures talk about how they have, like, a thousand different categories that users get check-marked in.  And then when you're on any website which is using ads hosted by this advertising network, you're not getting ads relevant or relative to the page, but to you because they're tracking you separately from where you go. 



So as I mentioned, a couple years ago Phorm began this work in '06.  And they stumbled a bunch because they were trying to inject JavaScript inline into people's web pages so that when you would go to a page, the page you received from the server had actually been altered by this spy technology, for lack of a better term.  I don't know, I mean, that's what it is.  They would insert code that your browser would execute.  The problem is they weren't very good at it.  Maybe it can't be done in a robust fashion, you know, nothing I even want to think about.  But as a consequence people would find that this - they were pasting this JavaScript into Web 2.0 blog entries and things.  It was like, it was leaking out and being seen.  IE would hang and go into an infinite loop and had to be shut down by using Task Manager to lock it down because it would use 100 percent of the machine's resources.  I mean, there's, like, all these problems.



And what really annoyed people is that this was all being done surreptitiously with, I think it was BT, one of the top three ISPs in the U.K. was, like, allowing Phorm to use their customers unwittingly, causing them all these problems.  So and these are also - this Phorm is a renamed company.  It used to be Media something, like Media 247 or something...



LEO:  I'm thinking of a bad word that I'm just not going to say.



STEVE:  Anyway, so these are not good people.  And back then they were doing rootkit spyware that was installing itself in people's machines, profiling them and hooking the kernel in order to hide from anyone being able to see the randomly named directories that they created.  So there's just a history of badness here.



Okay.  So come forward to current time.  Now we're in today.  Phorm somehow has continued to exist and is causing a huge kerfuffle in the U.K. because the main three ISPs have been seduced by the money that they'll be able to make.  The idea is, you know, ISPs would like to make some money rather than just selling bandwidth to end-users.  And these other companies come along and say, hey, we'll pay you.  We're going to anonymize everything we do.  We're going to respect your customers' privacy.  We're going to put our hardware, insert it into your network flow, and we'll pay you.  Doesn't that sound like a win-win-win?  And unfortunately ISPs are saying yes.  As you mentioned, Charter here in the U.S. has been made gun shy of this in the case of a partnership with NebuAd because this was really upsetting people.



So what I want to talk about, the reason I warned people to bring their propeller hats, beanies, is what it is that Phorm is doing now in order to forcibly track ISP users without any JavaScript injection.  JavaScript injection is the easier way to do it.  But that can - people are - maybe people who listen to the podcast are disabling JavaScript.  Or they've just never found a way to do it safely.  Or the idea of modifying the web page that I download from CNET, you know, just really, really crosses the line.  The good news is that U.K. apparently has substantially more stringent privacy guidelines than we do in the U.S.  And so, I mean, there are all kinds of people getting ready to talk lawsuit here about just the idea that I go to CNET and get a page, and secretly some spy machine in my ISP is injecting code into the page I retrieve for the purpose of tracking me and profiling me over time.  So Phorm came up with a solution which is amazing, amazing in how...



LEO:  Increasingly awful, yeah.



STEVE:  Amazingly awful.  Okay, so here's how it works.  I'm an ISP.  I'm a customer of an ISP that has subcontracted this system with Phorm.  So Phorm has installed a bunch of hardware in the ISP's facility.  When I go to - and we'll just use CNET as an example.  I started with that.  We go to www.cnet.com.  My request - oh, and let me back up a little bit, give a little quick background on cookies.  This is a quick refresher.  Cookies, as we know, are little tokens which are offered by servers and are then returned by the browser for subsequent queries to the same server.  The server is identified by domain.  So, for example, if you go to CNET.com, like with a virgin browser, it's got no cookies in it, it's never seen the Internet before, you put in the URL www.cnet.com.  The CNET server, in responding to you with a page, will include in the headers that you never see, that's not part of the page content, but it's things like the expiration time of the page, how long the page should live, and how many bytes long the page is.  And there's a bunch of sort of metadata that is sent out first that helps the browser display the page.  One of those things is a cookie header which is offered by the server.  The browser will retain the cookie for varying lengths of time, depending upon how the browser and/or the cookie is formatted.  And with subsequent requests to CNET.com the browser will - it'll look at all the cookies it has, and it remembers cookies by domain.  So as it's making a request for an asset from CNET.com, it'll check to see if it has any CNET.com cookies.  And, if so, it adds them to the requests and sends them back.  So that's how they work.  So all of that is called a "first-party cookie."  A third-party cookie...



LEO:  And I just might add that I don't think there's anything wrong with first-party cookies.  This is really how the web works.



STEVE:  I agree.  I agree.  And in fact it's because of the fact that there's no enduring relationship with your browser from one page to the next...



LEO:  We call it "state."



STEVE:  A state, right.  I put in a URL, and it gives me a page.  Well, then, if I put in another URL, it gives me another page.  It doesn't know I'm the same person unless I hand back the token it gave me.  And then it goes, oh, that's that guy, okay.  And in fact that's the way you're able to log into eBay or to PayPal or to, you know, virtually anything that requires you to have some credentials.  I went back to the WallStreetJournal.com yesterday to look up an article that was in there, and it said, oh, hi, Steve.  And I'm thinking, isn't that nice.  I mean, I'm glad it remembers me.  If I went there with a different machine, I'd have to give it my username and password again.  But I told it remember me on this machine, and it did so by giving my browser a cookie, which I then send back.  So for low security sorts of authentication, like staying logged in at WallStreetJournal.com, that makes a lot of sense.  It's a convenience.



The thing that originators at Netscape, I don't think they thought about this, I think it just sort of slipped through, is what if a website offered ads by somebody else?  That is, the actual ad URL on the web page said www.doubleclick.net?  Well, it turns out that the server whose domain you're on, like CNET, that's the first party.  We call assets which come from other servers "third parties" because they're not - the server's the first party, I'm the second party, and this random other thing is the third party.  Well, it turns out they're able to do cookies, too.  In the normal configuration of browsers, third-party cookies are enabled except in the case of Safari.



LEO:  I think that's because...



STEVE:  [Indiscernible].



LEO:  But I think that's because they're kind of seen as owning part of that page.  So it's, you know, you've gone to a page, and there's - because these banners are coming from another site.  It's almost as if there's a little frame on the page, and that's another site you're looking at there.



STEVE:  Correct.



LEO:  That's the thinking, anyway.



STEVE:  Well, and so here's the problem with that is that the clever marketing guys, I mean, and these marketing guys are nothing if not clever, they realized that if they gave me a cookie, they DoubleClick, for example, gave me a cookie because an ad was displayed when I went to pull up a CNET page, the cookie that I get is for DoubleClick.net.  That's the domain that the cookie's for.  Well, that means if I then later go over to the WallStreetJournal.com, and The Wall Street Journal is also buying ad space from DoubleClick and displays a DoubleClick ad, my DoubleClick cookie that I received at CNET goes back to DoubleClick while I'm at the WallStreetJournal.com.  And one of the things that is part of the headers in a query, that is, when I'm sending a request to something, like when the ad is being requested from DoubleClick, the URL of the parent page is so-called the "referrer."  So DoubleClick knows what I'm looking at. That is, it knows not only who I am anonymously, but from this token it knows that somebody was at CNET who was later at The Wall Street Journal and knows what articles I'm looking at and what pages I'm pulling up.  And so you can see that if DoubleClick succeeded significantly so that they had ads spread all over the Internet, over time they would be able to build up a history of all the places I had been that were serving their ads.



LEO:  I mean, it's not everywhere you've been.  Again, just places that...



STEVE:  That were serving their ads.



LEO:  ...served those ads, right, right.



STEVE:  Yes.  But now...



LEO:  Of course sites like DoubleClick, now owned by Google, are in so many places, that can be a pretty bleak picture.



STEVE:  Okay.  So that's the model.  Now, notice that, okay, it has to use third-party cookies.  Now, people who are privacy aware are turning third-party cookies off.  I'm going to be coming out very strong with a facility for allowing people to verify.  And I will be autonomously letting people know who come by GRC to, like, run/use ShieldsUP! or for any purpose, I'll just notify them, oh, by the way, you've got third-party cookies turned on.  If you're interested in turning them off, click here, and I'll show you how to do that.  Because there's just no purpose for them.  They should be turned off.  They're used for tracking people around the 'Net.  The other problem with the profiles generated by DoubleClick is that they only have visibility into me, as you said, Leo, for all the sites who are serving ads.  They don't know anything about me for all the sites I go to that are not using DoubleClick ads.  Well, except there are variations on that.  For example, as we've seen when you go to PayPal, many PayPal links actually redirect you through DoubleClick.  So there's another way that DoubleClick is able to access a user by actually using a redirected link.



LEO:  Could you block it in other ways than by turning off third-party cookies?  For instance, using a hosts file to say block DoubleClick?



STEVE:  Absolutely.  That would null any of the ads which were being served because your browsers looks in the hosts file first.  It would not get the IP address for DoubleClick.  The problem is that there are side effects, like none of the PayPal links would work.  You couldn't click on a DoubleClick.net PayPal link because...



LEO:  And as we know now, some of those links lead to pages you need to get to.  They're not just to ads.



STEVE:  Right.  And so it's a way of...



LEO:  I think that's why they do that.



STEVE:  ...enforcing that not being done.



LEO:  That's why they do that. 



STEVE:  Okay.  So now imagine...



LEO:  I bet DoubleClick pays them.  Now we understand why that DoubleClick referral is in there.



STEVE:  Well, there's even something worse.  And that's called "cross-context leakage."  But I'm going to leave that for the episode where we really get in and talk about first- and third-party cookies because it's possible for browsers that do not block outbound cookies, but only block inbound - and, by the way, that's IE and Safari - it's possible for them to receive a cookie in the first party and then subsequently leak it out through the third party, even when you've got third-party cookies disabled.



LEO:  Sounds like a legal document.  The party of the first part just leaving cookies that the party of the third part is going to get.



STEVE:  Okay.  So now we understand, we've got some background for cookies.  Now listen to what Phorm is doing.  The only nice thing about DoubleClick is that they're relatively hands-off.  They're not involved with the ISP.  They have a relationship with the website that you go to.  And they have sort of a forced relationship with your browser because they're putting cookies in there, and you're displaying their ads.  But, you know, they're still - they're not nearly as invasive as what we're seeing now with this next new generation of advertisers.



So I'm a customer of an ISP using the Phorm system.  I go to www.cnet.com.  I put that URL into my browser and send a query out to the Internet.  Well, my ISP receives it because that's what my ISP is there for.  They're the way I get to the Internet.  Equipment that has been installed by Phorm in the ISP's facility intercepts this query.  And it looks to see whether my browser has a cookie that is in the CNET.com domain for something called WebWise.  WebWise.net is the domain owned by Phorm.  So WebWise - and if you look WebWise.net up in WhoIs, you'll see Phorm, Inc., in New York, NY, and the names of the technical and administrative contacts for Phorm.  So they're intercepting my bringing up a CNET page to see whether I have a CNET cookie that they planted in the CNET domain.  Now, let's take this from the beginning.  So initially I would not.  If there's not, if I don't have a WebWise cookie in the CNET domain, they block my access to CNET.  A server steps in and - get this, Leo - pretends to be CNET.



LEO:  Oh, see, that should be completely prohibited, banned.



STEVE:  It pretends to be www.cnet.com...



LEO:  Because it's a proxy, you can do that.



STEVE:  Well, it's in the ISP's facility.  It answers the connection and this query that I've made.



LEO:  If I were CNET I'd be - all right.



STEVE:  Oh, wait, we're just getting warmed up here.  And so it responds as the CNET server and returns what's called a "307 temporary redirect."  A 307 - normally when you bring up a web page you get a 200 response, 200 and, like, an okay, which is like, here's the page you asked for, no problem.  A 307 response tells your browser that that URL you have asked for has been temporarily relocated to somewhere else.  It tells it that it has been relocated to WebWise.net.  So the CNET request you made comes back to your browser from this intercepting server, and your ISP is saying, oh, CNET is moved.  It's now WebWise.net.  And then there's a - then it says /bind/ and a question mark, and then some parameters which include the original URL at CNET that you were trying to access because they have to hold onto that since they've just intercepted you and redirected you.



So now your browser, not knowing anything the wiser, goes, oh, the page I want is moved.  So it now makes a query to WebWise.net with this fancy thing on the end which contains the original CNET URL and parameters that you tried to access.  The reason it does that is, if your browser has a WebWise.net cookie, that it will give it up.  That is, that WebWise.net cookie that your browser has will then be sent along with this redirected query to WebWise.net.  Once again, that's intercepted at the ISP, doesn't actually go to WebWise.net.  Their server located at the ISP intercepts it and checks to see whether that redirection query contained a WebWise.net cookie.  If so, they now know who you are.  That is, there's a WebWise.net domain cookie on your machine if you've ever used this ISP before.  So then they know who you are.  If there's not a WebWise.net...



LEO:  When you say "who you are," you don't just mean, oh, they've seen you in another session before.  They know who you are, Steve Gibson, Leo Laporte.  They know who you are.



STEVE:  Well, your ISP...



LEO:  Because you're their customer.



STEVE:  Exactly.  Your ISP knows everything about you.



LEO:  Right.  So they know where you live, they know your credit card number, they know who you are.



STEVE:  Right.  Now, there can be and probably is a hands-on relationship between your ISP and the Phorm people.



LEO:  I hope so.



STEVE:  But again...



LEO:  But who knows?



STEVE:  That's the kind of thing that changes in the fine print of the license agreement.  And then, oh, wait, you didn't read the license agreement?  Okay.  So now if there's not a WebWise cookie, which there would not be if you were just like, you know, Mr. Virgin, never used the Internet before, they would assign you one.  That's a 128-bit pseudorandom value.  So it's just a random token, but it uniquely identifies you to their system.  So they respond to this, your access to WebWise.net, by again giving your browser a 307 temporary redirect response, this time back to CNET, to a special fake page at CNET.  But since it's the WebWise.net pseudoserver which is serving you, if you didn't have a WebWise.net cookie, you do now.  And notice that it's a first-party cookie because you went directly, your browser went to WebWise.net, requesting a resource from that URL.  So it's a first-party, most privileged cookie which your browser has now received.



LEO:  So unless you block all cookies, you've got it.



STEVE:  Yes.  So now your browser receives another redirect, a 307, from WebWise.net, telling it, oh, we were wrong, CNET turns out to be where you want to go after all.  Except it's another fake page at CNET.  Now your browser re-requests a CNET.com address.  Because of the way it's formatted, the technology, the Phorm technology again steps in, pretends to be CNET, fakes it out, and answers the query.  In that fancy URL is still hanging on there for dear life the original URL you tried to go to at CNET.  And encoded is the unique ID for WebWise in this query.  That allows the server, which is again for the second time pretending to be CNET even though it's not, that allows it to obtain from your CNET query the WebWise UID, unique ID, and it sets a - this is where it sets a WebWise cookie in the CNET domain because your browser thinks it's at CNET.  And a server has stood in and intercepted the CNET server and is faking it out.



So your browser, in getting the response back, back comes a WebWise cookie for the CNET domain containing your unique ID.  And that response is another 307 temporary redirect, finally, to the actual page you wanted to go to on CNET.  So your browser receives that along with the WebWise.net cookie, which is now in the CNET domain, and makes the request to CNET.  Now every time your browser brings up any CNET assets, it includes, in addition to any cookies, the real CNET cookies which CNET has given it; a WebWise cookie containing your Phorm unique ID.



And so all of the work you do on the 'Net, any time your browser is making a query, there's this spy server that checks to query to see if the query contains for that domain, no matter where you're going, Apple.com, CNET, CNN, MSNBC, TWiT.tv, no matter where you go, what's happened is essentially every single site you visit is given an extra cookie.  So your browser ends up filled with these WebWise cookies for every single domain you visit.  And those are first-party cookies.  And any query you make outbound is checked for the presence of one of these WebWise.net cookies.  If it's missing, it sends you on that multiple server dance, the triple 307 temporary redirect dance, jumping you around between fake servers in order to get your WebWise cookie, in order that it can essentially migrate that over from the WebWise.net domain into the domain you're attempting to go to.



LEO:  So is the whole process, the intent of the whole process just to get these cookies, these WebWise cookies on your system for every site you visit?



STEVE:  Yes.  That's the whole...



LEO:  That's why they're doing this dance.



STEVE:  That's what these people have achieved with this horrible...



LEO:  And a first-party cookie, to boot.



STEVE:  First-party cookie planted in the domain of every domain you visit, and one in the WebWise.net domain which is essentially replicated among all the other domains that your  browser ever visits.



LEO:  With your unique ID.



STEVE:  With your unique ID.  Now, imagine a couple things.



LEO:  Now, I just - I want to say something because there's some confusion in the chatroom because you used CNET as an example.  CNET has nothing to do with this.  No site you visit has anything to do with this.  This is Phorm doing this.



STEVE:  Yes.  In fact...



LEO:  In fact, I'm sure CNET would hate this.



STEVE:  Well, yes, because your relationship with them is being polluted by a cookie that they never set for your browser and that someone else's server is pretending to be them, giving your browser multiple redirection commands, bouncing it around URL space for the purpose of planting cookies across all the domains you visit.



LEO:  Now, there are some companies that do want this because there's no value in doing this unless you can sell this information to an advertiser.



STEVE:  Well, okay.  So notice that what this does - okay.  The other thing happening.  So now imagine a query to CNET that does contain the WebWise cookie, as it will after this three-redirect dance that your browser is taken on.  So now finally the result of that final third redirect is you actually - the browser is allowed to contact CNET.  In the process, this system removes the WebWise cookie component from the query.  So CNET does not see the WebWise cookie that is essentially - they're trying to corral it so it only stays between you and the ISP in sort of an ISP, you and ISP private dialogue.  So they do remove the WebWise cookie if they can.  When can't they?  Well, if I take my laptop to Starbucks, and I'm on T-Mobile...



LEO:  You're not using their ISP. 



STEVE:  I'm not using my ISP at home that was the source of this infection.  So every site I visit cannot have that WebWise cookie stripped out on the fly.  It goes out.  And so this ID that I've been assigned is visible to every site that I visit.  And that's a common ID.  Normally sites give you their own ID per site.  There's no aggregation.  This aggregates your identity across all the sites that you might visit because your browser has been polluted with a common cookie for every domain you've visited while you were under the influence of this Phorm-based ISP.  The other instance where they are unable to strip out their cookie is over secure connection because they're not, at this point in the game - and god help us if our ISPs ever start requiring us to accept an SSL certificate as part of our agreement to use the ISP because that would allow them to intercept our secure socket connections.  But at this point the whole system is blind to any secure conversations we have, any secure traffic.  So any time I am using HTTPS, I am bypassing, even from my ISP, my Phorm-ridden ISP, I am bypassing that technology, and the WebWise cookie again is leaking out and is visible to any sites I'm visiting over a secure connection because there's no way that the Phorm system can filter SSL connections at this point.



LEO:  So again, to underscore this, this isn't CNET doing anything.  This isn't TWiT.tv doing anything.  This is your ISP in collaboration with Phorm doing something to essentially track what you're doing on the Internet.



STEVE:  Yes.  A highly comprehensive, cross-Internet tracking.



LEO:  It goes far beyond anything third-party cookies ever could do.



STEVE:  Oh, yeah.  Well, because, now, look what else happens.  So finally my request to the real CNN page gets through because it's been - it's had this WebWise cookie embedded in the domain that my browser is carrying.  When the page comes back, this system inspects the page.  This system reads the page that is being sent back to me and does an analysis of it to determine what I'm interested in.  So it's reading - this is where the spying really comes in, beyond identity tagging.  Now it's reading everything I'm reading and building a profile of who I am and associating it with this tag which it has built up.  And over time it builds a database of it knows every page that I go to.  They say they are not maintaining a record of that.  What they're doing is they're scanning the page, doing some sort of semantic analysis, determining within categories, they say they have over a thousand...



LEO:  They're looking for keywords.



STEVE:  Yeah.  Well, they have a thousand categories.  And so they, like, put checkmarks in categories for people of, like, oh, this person is interested in the following sorts of things, based on their history of their Internet usage.



LEO:  But that's not what this is limited to.  They could do more.  That just happens to be what they say they're doing.



STEVE:  Well, and there again, I mean, this notion of inserting themselves in the pipeline means, well, wouldn't it be more valuable if I could also read this person's email coming and going between the ISP?  You know, web, oh, that's, you know, that's really not as specific because these are those pages that have been pre-prepared.  Imagine if I could read the email content of the conversations.  And oh, don't worry, we're not going to save it.  We're not going to keep it.  We're just going to scan and analyze it, determine more about who you are.



So one of the things that's different about this from DoubleClick is the level of visibility.  That is, say that only one, only one company hosted ads from Phorm.  Well, that one company has the advantage of all of your surfing.  That is, the ad being served is about you, even if only one, only if you go to one place.  Whereas DoubleClick needs to - it's only able to build up a profile based on the places you go.  This system builds a profile based on everywhere you go and makes that available to any of the people who are using their ad network for advertising revenue.



LEO:  Is any Internet Service Provider in the U.S. currently using Phorm?



STEVE:  I don't know.  The hope is...



LEO:  Nobody would admit to it, probably.



STEVE:  Well, I mean, this has now become a real hot potato.  Our guest in two weeks is going to give us the inside skinny on what's been going on over in the U.K.



LEO:  It's illegal in the U.K., isn't it?



STEVE:  Well, I mean, there are people who are really up in arms.  And I'm glad.  I mean, again, my role is to explain what this thing does, what the technology is.  There can certainly be people who say, well, wow, I like the idea of more relevant ads.  Or I like the idea of...



LEO:  Well, that's the other side of this, which I was going to get into; but we've gone way over, so I don't want to get into it too much.  And that's the case that, for instance, Charter was making, is all it does is give you ads about stuff you care about.  What's wrong with that?



STEVE:  Right.



LEO:  I mean, we're not trying to steal your personal information.  I guess your point is that the technology could do that.



STEVE:  The technology could.  And I'm concerned about drift and migration of capability.



LEO:  Right.



STEVE:  I would have no problem, for example, if this was an opt-in system.  If you had to go to your ISP's page or a Phorm page and say hey, I'd like a $3 a month discount on my bandwidth, please.  I'm happy to contribute my profiling habits on behalf of this technology in return for a discount on my bandwidth.  I mean, if it were an opt-in system, that makes sense.  I love that the language I read somewhere said, well, the reason we made it opt-out is that we feel that more people will be able to benefit from it than an opt-in system.  What happens, of course, is that people are furious when they find out that this kind of game is being played.



LEO:  Yeah, well, I'm furious already, and I'm really glad that you actually raised the issue and talked about this because this is pretty appalling.  But as you say, it's not necessarily how it's used.  And I think that this is why  people like Charter are kind of surprised when we stand up on our hind legs and say, well, wait a minute, we don't want that.



STEVE:  Yeah, this is not for us, this is for them.  This is for Charter.  Charter is getting [indiscernible]...



LEO:  Benefit to them, yes.



STEVE:  ...from Phorm in return for letting Phorm profile us.



LEO:  But their spin was totally this is to your benefit because you're going to get ads that are more targeted at you.



STEVE:  And my feeling is, fine, make it opt-in.



LEO:  Yeah.  Simple.



STEVE:  Intercept the first time I try to go to the 'Net.  I mean, they have the capability of intercepting, you know, god himself.  So the first time I go to the Internet, my access to CNET.com is blocked, and I get this wacky page, I go what the heck is this.  And it says, hey there, we're offering a new service that will allow advertising by selected advertisers on websites to target you and serve you ads that are more specific, blah blah blah.  So, I mean...



LEO:  I got a big bulls-eye pointed on my forehead, that's what they mean.



STEVE:  Entirely possible for them to make it an opt-in where...



LEO:  Well, I love the idea they can say we'll cut five bucks off your bill every month.  They're going to make a hundred bucks.  But, you know, give me some.



STEVE:  And I guarantee you a lot of people would say heck, yeah, I don't care about privacy, I care about my wallet.  And so I don't mind that.



LEO:  And we should really underscore that we are at the mercy of our ISP anyway.  I mean, they see everything we do.  If they you know, the FBI put boxes in every Internet Service Provider's center years ago.



STEVE:  In order to scan email.



LEO:  Yeah.  So the Internet Service Provider has all this information; right?



STEVE:  Yup.



LEO:  All right.  I'm not going to get angry, and I'm going to keep my blood pressure down.  Steve, thank you so much.  What a great show.  It was a lot of fun.  Fun.  I mean fun in the sense that we get to really understand, as usual on this program, a very deep and a difficult topic.  You've done a great job of explaining it and of raising our awareness about it, too.



STEVE:  I just - it's horrific what these guys have done.



LEO:  And, you know, I don't think there's any - there's no mainstream media outlet anywhere that can explain how this works.  And this is where we're really, I think, increasingly in a situation where technology has outpaced the general public's ability to understand what's being done to them.  And I think we're doing a very important job getting the word out.  Now, all the geeks who are listening who understand this, now you need to figure out a way to explain it to your friends and family and to stand up to your Internet Service Providers and let them know this is not something we want.



STEVE:  Yeah.  The good news is there does seem to be a lot of outrage that this is causing.  It's certainly causing the ISPs to back off and, you know, rethink that this is - oh, look, it's free money.  No.



LEO:  Right.  It isn't free money.  We're going to get the money out of them in one way or the other.  Make them let us have the choice, I guess is the idea.  Hey, if you want 16KB versions of this show - I know some people say, oh, the audio quality's good, but it's big, I'm on dialup.  We have listeners all over the world, many of whom don't have the high speed that you might want for the large version.  We do have a small version.  It's available at Steve's site, GRC.com.  You can go there and download that.  He also has transcripts.  And I think on a show like this it's very helpful to be able to read along as Steve's talking.  You can find transcripts, the 16KB version, complete show notes, and of course SpinRite, Steve's bread and butter, his ultimate disk recovery and maintenance utility.  It's all at GRC.com.  And Wizmo, too.  How would you find Wizmo?  You just go to the front page there, Steve, is that...



STEVE:  Yeah, GRC has now a really nice sitewide menu, you  may remember, that does not use any scripting.  And so under - I'm not even sure where it is now.  But it's right there under the top-level menu, under freeware and utilities, is Wizmo.  And that'll get you there.  And I'll remind people who are inspired to send in a question or write for next week's Q&A, by all means, please do, GRC.com/feedback.  And I will read your stuff, and we'll do 12 questions next week.



LEO:  That'll be a lot of fun.  And that way we get a little more variety.  We've spent a lot of time with Phorm.  And we're not done with this topic, I think.



STEVE:  Nope.  I think, well, clearly people are passionate enough.  I think it'll be fun to talk with a Phorm world insider who has been, I mean, who is rapidly anti-Phorm.  We're going to do that in two weeks.



LEO:  Good.  All right, Steve Gibson.  Thank you very much.  Thank you all for being here.  A little side note, you can also watch us do this show live if you're so inclined.  We record on Tuesdays at 11:00 a.m. Pacific - that's 2:00 p.m. Eastern time, or 18:00 UTC - at TWiTLive.tv.  And everybody was saying, Steve, in the chatroom, as you were talking, they loved watching you because you gesticulate with your hands.  They said it's actually easier to understand Steve because you can see his thought process.  You can see how he's working.  And they really enjoyed it.  So I thank you for allowing us to do the video.  I think it's really great.  They want to know if you're Italian.



STEVE:  We figured out - there is some Italian in there, yeah.  We figured out a way to do video and audio both over separate Skype channels.



LEO:  And the audio quality is great.  We're back to our usual audio quality.  I think that's really what's most important, yeah, because most people listen to it in audio.  But, you know, there are around 3,000 people who are watching and enjoying your performance, your bravissimo performance every Tuesday on TWiTLive.tv.  Thank you, Steve.  We'll talk to you again next week.



STEVE:  Thanks, Leo.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#152

DATE:		July 10, 2008

TITLE:		Listener Feedback Q&A #45

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-152.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 152 for July 10, 2008:  Listener Feedback #45.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now! Episode 152.  And from his bunker deep within the mountain they know as - what is the mountain in Irvine?



STEVE GIBSON:  Saddleback.



LEO:  Saddleback.  Deep within Saddleback Mountain, Mr. Steve Gibson, in beautiful Irvine, California.  Hi, Steve.



STEVE:  Hey, Leo.  Great to be back with you again.



LEO:  Yeah, yeah.



STEVE:  We're rapidly coming up on three years.  I love it.  152, four weeks to go.



LEO:  That's kind of neat.  I don't know what we're going to do for a three-year celebration, our entry into the fourth year, but we'll find something fun to do.



STEVE:  Well, I read a lot of the feedback we've received from people over the last couple weeks.  And it's just gratifying for them to say they love the podcast, and they want another 150 weeks, and they don't know what they would do if it stopped.



LEO:  That would be bad.



STEVE:  We have no plans to stop it, folks. 



LEO:  No.



STEVE:  We're going to - we're just getting going.  You're in a whole new era now with your studio and your staff and...



LEO:  Yeah, and I'm starting to record these video versions that we do.  And I don't know if Security Now! really lends itself to a video version.  But if people want it, I'll be glad to do it, you know.  Certainly the gadget podcast does because then you can see the gadget.  And, you know, we're doing a lot more stuff in the TWiT Live realm where we have interest, like Woz is going to be on on Thursday.  So those we'll probably start putting out as video podcasts here, yeah. But if you tune in live, 11:00 o'clock every Tuesday morning, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 18:00 UTC on Tuesdays, you can watch us do it live.  If that's not a spoiler.  Might spoil the show for you.



Let's get to - before we get to - it's a Q&A segment.  We've got 12 great ones.  Before we do that, do we have anything to catch up on, any errata, addenda?



STEVE:  Oh, every week there's security news, which was the original concept you had for this podcast.



LEO:  Yes.



STEVE:  Yes, a number of things.  Over in the new exploits and problems category, I wanted anyone who is using what used to be called Microsoft's Great Plains Accounting - also known as Microsoft Dynamics.  It's now called Microsoft Dynamics GP.  They sort of merged them all together.  Anyway, this is a very popular accounting program which Microsoft has naturally extended to make it network capable and, in the process, opened it to remote exploits.



LEO:  Oh, boy.



STEVE:  So there are multiple, now in the public, remote code execution exploits for Microsoft Dynamics GP.  Updates are available.  So anyone who's using them or whose corporation is using this, you just want to make sure you've got yourself updated because the last thing you want is hackers getting into your business's accounting system and rummaging around.



LEO:  No kidding.



STEVE:  I wanted to make sure that Mac people knew that they needed to get updated to 10.5.4 because there were some HTML rendering exploits.  I think I referred to them last week.  But now we're beginning to see the public appearance of some exploits, not widespread yet, but there were some mistakes found in what Apple calls the "WebKit," which are used by different things that render HTML, like Safari and Apple Mail and so forth.  And also 10.5.4 fixed some bugs in third-party apps that Apple bundles in with the whole OS.  So definitely want to make sure you stay current there.



And lastly, the common code base for the whole Mozilla family of browsers - Firefox, Thunderbird, SeaMonkey - have a problem.  So there are updates available.  So if you're using Firefox, Thunderbird, or SeaMonkey, you want to again make sure that you update those.  Firefox 3.0 has the improvements that are necessary.  But, for example, if you were using Firefox 2 and hadn't yet moved to 3, moving to 3 is a good thing when you're comfortable doing so.  I'm always reluctant to push people into new versions.  I've really learned my own lesson with Service Pack 3 of Windows XP.  It's like, oh, boy, was that a mistake.  But so if you are comfortable moving from version, you know, major version 2 of Firefox to 3, that's one way to solve this problem.  Otherwise, make sure you're updated.



And finally - this is just, like, browser day - Opera.  I just, like last week, updated to 9.5, from I think I was at 9.3.  And 9.5 is a really nice sort of a .x update, not quite a major version, but a strong minor version update that changed the UI around a little bit and I think really cleaned things up.  I like what Opera's doing.  However, even in this period, in this little window, I was surprised when I checked on things that there's an incremental security patch to 9.5, bringing it up to 9.51.  And so sure enough, when I checked, you know, I clicked on Opera's menu and said check for updates, it says, oh, you've got - there's a new update available.  So Opera users want to bring themselves current, as well.



LEO:  All right.  Very good.



STEVE:  In news, the big news - and our listeners are clued in.  I can't tell you how many notes I have received in case I didn't know about TrueCrypt v6.0.



LEO:  Yeah, I got a few.  I got a few of those, too.



STEVE:  And so I wanted to thank everybody for making sure I knew.  This was a release on the Fourth of July, which of course in the U.S. is our Independence Day.  And there were a number of new features.  People who were using 5 will probably want to move up to 6.  Among other things, the volume format was changed to increase the redundancy of critical information in the header.  One of the gotchas, the potential gotchas of an encrypted - of any kind of, like, well, really any kind of encryption, as our listeners know, is good encryption turns data which is readable into pseudorandom noise.  Absolutely, if it's sufficiently good, it's indistinguishable from pure random noise.



Well, that makes data recovery a real problem because, for example, anything that goes in and tries to read the file system, unless it's able to decrypt the file system, it can't go in and, like, find lost clusters, fix directory entry mistakes and so forth because the entire thing is just random noise.  That means that an encrypted file system is more dependent on the encryption header data than a non-encrypted file system.  So one of the things that these guys did in moving from 5 to 6 is they've made their volume format, the encrypted volume format, more bulletproof by putting a redundant set of headers at the end of the volume format, and a way to reliably locate that so that if the system is unable to properly read the front, it'll be able to get it from the back and use it just the same.



One of the other cool things they did, we've been talking about multi-core stuff here in the last few weeks because I've been frustrated with my lack of use of my own multi-core workstation, and then I of course built a big multi-core monster for doing media and other kinds of compression stuff.  TrueCrypt 6.0 adds multi-core support for compression.  And the performance gain you get is directly proportional to how many extra cores you give it.  So if you have a dual-core system, the compression/decompression path will run twice as fast.  And if you have a quad-core system, it'll run four times as fast.  And I heard you over the weekend, Leo, on your weekend show, talking to some guy who had - I think he was buying a dual quad-core system.



LEO:  Yeah, yeah.  Overkill.



STEVE:  And it was less than a thousand dollars.



LEO:  That was the amazing thing, yeah.



STEVE:  Coupon or something, yeah.



LEO:  Is there a disadvantage, I guess is the question.  If you get it for a thousand bucks, should you avoid it even so, just because of problems with the multiple cores?



STEVE:  Well, there aren't compatibility problems with the multiple cores.  I did find myself, as I was listening to your side of the conversation, I found myself thinking, okay, well, it's got to be something has been cheated from the system.  I mean, he can't have graphics that's running at high performance for that price.  He probably doesn't have a really high-speed front-side bus and not high-speed memory, or not much memory.  I mean, you know, that's just a really low price.



LEO:  Here's the funny thing, is these quad-core chips are now about 2 or 300 bucks each.  And he did actually have a decent NVIDIA graphics card, not the top of the line, but I think it was a 9800.  So he wasn't suffering there.  I didn't ask him about the bus speed.  But I think - I don't know how many choices you have if you put one of those quad-core chips in.  I think this stuff has just fallen in price.



STEVE:  Wow.  Well, and of course you really need to provide these things with power.  As I think I've mentioned, the heat sink on the new Intel quad-core, I had to literally redesign the fan mounting a little bit because it was like this huge mushroom that wouldn't fit in the case any longer because they - and they were saying, hey, we just increased the efficiency and size of our heat sink.  It's like, uh-huh, yeah, and it won't fit in the case anymore.



LEO:  Right.



STEVE:  So, yeah, so that's a downside.  Oh, and the last thing is, in TrueCrypt 6, they now support a hidden OS where you're actually able to hide an OS in - remember how they used to have a hidden partition?



LEO:  Right, right.



STEVE:  Where you could have, like, a - you could say, well, that's just noise at the end of the slack space.



LEO:  They called it "plausible deniability," where it just didn't look like it was anything.



STEVE:  And now with 6.0 you're able to create a bootable OS in that space.  Which is, you know, I'm not really sure how useful that is, but a lot of people are excited about it.



LEO:  How would that work?  Because you'd have to decrypt before you could boot.  So they'd have to have a little decrypter stub running on the master boot record?  How would that work?



STEVE:  I haven't even looked at it.  But yes, essentially you would need to be able to boot into that optionally, but in some way that gave you plausible deniability.  I just - I've been so busy I haven't had a chance to sit down and go over it.  But enough people were excited, I think we'll give it a little bit more attention in the future.



LEO:  Yeah.



STEVE:  I did want to mention that there was an interesting report, just in terms of sharing sort of reality-based security news, which is what all this is with our listeners, of course, a number has surfaced from a study that actually Dell commissioned.  More than 637,000 laptops are lost annually in airports.



LEO:  Airports alone.



STEVE:  Airports alone.



LEO:  Wow.



STEVE:  637,000 laptops lost every year, 12,000 a week.  67 percent, so two thirds of them, are never recovered.  And users who lost their laptops were surveyed in this report.  And 53 percent said their laptops held confidential data.  Yeah, well, no kidding.  I mean, like, whose laptop doesn't have something in it that you wouldn't want people to get.  42 percent said their data was not backed up.  16 percent said they would do - that they could do nothing if they lost their laptop traveling on business because they depend upon it.  It's like their portable desktop, essentially.  And 77 percent of the people surveyed said that the chance of recovering a lost laptop was less than 10 percent.  So I wanted to remind people again, TrueCrypt 5 and now 6 is a robust technology which is highly recommended... 



LEO:  Encrypt.



STEVE:  ...for encrypting your laptop.  I mean, it's less important, arguably, to encrypt a desktop system that's not moving around, that has no chance of becoming one of those 637,000 laptops lost in airports every year.



LEO:  When they say "lost," they don't mean stolen, they don't mean somebody's ripped them off, they mean they just kind of were left behind, I guess.



STEVE:  Yeah, well, the report said that the two highest locations of loss was just going through the security line.



LEO:  Oh, yeah.



STEVE:  Just the confusion.  I don't know if you've noticed, Leo, but I'm feeling under tremendous pressure when I finally...



LEO:  Move, move, move, move, move.



STEVE:  Exactly.  It's like you've got to take everything apart.  Then you've got to get it all through the little scanner tunnel, and then you've got to put everything back together again.  And it's like, you know, there's a lot of pressure.  And you can imagine how someone would just forget one piece of their little world in that process.



LEO:  You'd think they'd make an effort to kind of, hey, there's a laptop here, hello, anybody?



STEVE:  Well, Leo, you and I travel a lot.  You've seen what level of concern there is from anybody.



LEO:  Ooh, a laptop.



STEVE:  You wonder where they're going, that's the question.



LEO:  Yeah, no kidding.



STEVE:  In another bit of interesting news, and you may - you're clued into all of what's going on enough, you may have heard this.  Blizzard, who makes World of Warcraft, has now adopted a bizarrely painted PayPal football for World of Warcraft authentication.



LEO:  Yeah, somebody mentioned that to me, and I thought, that's - so when you play World of Warcraft now you can use your football to say this is me.



STEVE:  Now, I don't know if you can register an existing PayPal token.  What I found interesting was that they are offering this at a very low price.  Just like PayPal, they're trying to encourage people to use this for authentication.  $6.50.



LEO:  Great deal.



STEVE:  Unfortunately, they're all sold out.



LEO:  Already.



STEVE:  You go to their website, it's like $6.50.  Oops, sorry, sold out.



LEO:  Wow.



STEVE:  So I don't know how many they had, how quickly they sold out, or any of the stats for that.  But if we have World of Warcraft listeners, you should know that there is a way to increase the strength of your authentication using the technologies that we've talked about here many times.  And it may well be, I mean, it does, it looks like the same technology that PayPal is using.  I don't know, but it's worth exploring, whether an existing PayPal football might be transportable so that you'd be able to register that and wouldn't need to set up another one.  I would think, I don't know, whether Blizzard is using, like, a VeriSign backend or whether they've implemented their own backend servers.  It's impossible to say.



And lastly, in a completely non-security-related topic, this relates to a question that I heard you answer, again during your Tech Guy show.



LEO:  You've got to stop listening to the radio show.  Hey, by the way, I have a warm line I could give you.  If you ever hear me say something really stupid, I'll give you this number, you can call in and correct me.



STEVE:  Oh, okay, well, you don't ever say that, Leo, but I don't think you - I've heard you say things...



LEO:  But it's always good to have an extra opinion in there.



STEVE:  Well, we know I'm a media guy.  I love media.  So the question was, it was a question that you spent some time on during the show about - it was a guy who wanted to record Flash video.  He wanted to record, like, YouTube videos.  And there have been times when I have wanted to do that.  And so I've searched around, I've looked at plug-ins in web browsers.  I've found nothing until now which is incredibly robust.  And this thing is robust because it's some serious technology which brings, you know, causes me to respect it a little bit more.  It's www.wmrecorder.com, as in Windows Media Recorder dot com.  So it's just www.wmrecorder.com.  However, it's way more than just Windows Media.  It does grab Windows Media and also Flash and many other formats.



What's cool about it, Leo, is, get this, it installs into your system the most popular Windows packet capture library, WinPcap.  So what it does is, and this is the reason this thing is so robust, there's never been anything I've encountered that it can't get because it's literally installed a tap into the network interface so that it's watching all the traffic going by.  And it sees anything that your system, while it's running and while you have it primed, it sees any media that your system starts to receive and pops up a little capture window and just starts sucking it in.  So it's literally, it's like watching your computer receive it, parsing all the network traffic, seeing the media streams, and capturing them.



LEO:  Does it save it, Steve, as a FLV file in its native form?  Or is it capturing it and saving it as a Windows Media file?



STEVE:  It does no conversion.



LEO:  So it literally saves the FLV.



STEVE:  It's doing a stream capture, and you end up with absolutely identical, for example, FLV files.



LEO:  So you could capture the Stickam stream that we do using this, and you'd have a copy of it.  That is really great.



STEVE:  And when I saw they were installing WinPcap, it's like, whoa, wait a minute, this is serious rocket science.



LEO:  Right.



STEVE:  So, I mean, they've done a lot of work in order to make this thing work as well as it does.  And in my experience it pays off.  It's not free.  I did buy it because I wanted to be able to capture stuff.



LEO:  How much was it?



STEVE:  It's not expensive.



LEO:  Let me click on the button, it'll say.



STEVE:  They've got a family of tools.



LEO:  Do you do WinCapture, is that the one you want?  Or that's the one that has - the capture is just the simple capture tool.



STEVE:  Yeah.



LEO:  And you can get WmRecord if you want.  So the full package is 80 bucks.  And if you just want WinCapture, 40 bucks.



STEVE:  Right.  I think that's correct.



LEO:  Yeah.  Wow, that's cool.  Somebody also said that the free - and this I know you're - don't choke.  Don't get mad at me.  The free RealPlayer and now Real 11 apparently doesn't come with anything else, it's just a standalone, also will allow you to right-click and save.



STEVE:  And did you verify that?  Because I thought on the show...



LEO:  Yeah.



STEVE:  Oh, and it did?



LEO:  Well, it was something about my system I think that wasn't doing it.  But yeah, apparently it does.  And I do - what I did verify is that you can download the free RealPlayer and not get, if you're careful about what you check, not get a bunch of extra stuff on there.  It's just the RealPlayer, which I guess means Real has finally seen the light on that one.



STEVE:  Only took them, what, five years.



LEO:  That was just awful, yeah.



STEVE:  Oh, in fact there are some places, for example C-SPAN will produce videos of their stuff that for a while I was watching.  And it's only in Real format.  Or I think maybe now it's changed.  But it used to be only in Real format.



LEO:  It's hard to believe that somebody in this day and age would still do that.  Awful.



STEVE:  Anyway, so there is, of course, a set of codecs called Real Alternative that you're able to download, and it's just the core Real codecs that allows your Windows Media Player to then play Real content.



LEO:  Right, right.  That's probably a better way to go.  Although they've clearly seen the light, and they say, oh, people don't download our stuff because we have all this extra stuff, bag and baggage we bring along.  So maybe if we just give them the player.  And if you're careful and you don't get the premium and the platinum and all the doohickeys with it, you just click the live free, who knows?



STEVE:  And then you tell it, no, I don't want these Explorer bars and add-on bars, Google desktop and everything.



LEO:  Yeah, you have to be a little vigilant.  Now, let's move on, Steve.  First, before we have a question, do you have a fine Security Now! SpinRite letter of any kind to tell us?



STEVE:  Well, you know, so many people who ask questions in this week's episode refer to SpinRite and their...



LEO:  Uh-oh.



STEVE:  I felt a little guilty putting in another little one.  It's like, okay, we're going to hear enough about SpinRite this time.



LEO:  All right.  Well, let's get right to the questions there.  This is starting off with Chris Simpson from Simpsonville, South Carolina.  He says:  What happens when I die?  Do you have an ans- oh, no, there's more.  Okay, let me elaborate.  Because I just wanted to let you answer that one.  Steve, I would like to have your opinion on something that's recently affected my life.  In May my grandfather passed away - I'm sorry - from a completely unexpected heart attack.  In the days following, my family and I spent hours hunting important financial, insurance, and medical-related information.  I'm sure this is something that all families go through, but it did help me realize something very important.  What happens when something like this happens to me?  Being a network engineer, security plays a very important part of my job and my personal life.  I encrypt virtually everything.  I use TrueCrypt to encrypt all of my hard disks on my laptops and desktops.  I'm trying to figure out the best and most secure way to document my encryption keys should anything ever happen to me.  This is actually a really good question.  I'd like to know the answer to this one.



The problem is, I don't want to have my encryption key floating around.  I absolutely hate the idea of writing a password down.  In previous episodes of Security Now! I remember you talking about having your attorney hold onto your CD full of information, while your mom held another.  While this may work well for you, I have a hard time trusting a lawyer to hold the encryption keys to my entire life.  You know, I guess I understand that.  But if you have, I mean - while I certainly do trust my mom not to snoop, she's not the most security-minded person.  She'd be likely to leave the information sitting around for anyone to see.  I'd appreciate any ideas from the Security Now! crew or Security Now! listeners.  Thanks, Steve and Leo, for a consistently great show.  What a great question, Steve.



STEVE:  Isn't that great?  I actually ran - I ran across this question a couple weeks ago and didn't have any more room for it.  So I moved it down into today, the first question on today's show, because I thought it was a really good point.



LEO:  Fantastic, yeah.



STEVE:  All of us are all, we've got everything encrypted.  And the problem, of course, is if for whatever reason, it may not just be if we die, but if we're incapacitated or some tragedy befalls us of some sort, how do other people gain access to this stuff that we arguably would want them to have access to.  You can imagine that this guy's grandfather, I mean, they scurried around trying to locate information that they didn't have put together.  So, I mean, having some plan to deal with encrypted content is right up there with having a will to deal with the other consequences of your lack of presence on the earth.



LEO:  This is something totally new.  I mean, we've never had to deal with it before.  But I think about this all the time, frankly.  How's my wife going to find out all my accounts?  They all have passwords on them.  I don't even use TrueCrypt, and I think it's an issue.



STEVE:  Yeah.  Well, now, one thing, first of all, I saw you stop in reading this where I stopped when I was reading it the first time, with this guy not trusting his attorney.



LEO:  Right, right.



STEVE:  I just wanted to say, I mean, I know my attorney.  I've got a great friendship with the guy.  And, I mean, he's my lawyer because I trust him.



LEO:  If you don't trust your attorney, you might want to get a better, a different attorney.



STEVE:  Sort of what I'm saying, yeah.



LEO:  There must be somebody you trust.



STEVE:  Well, there are a couple interesting hacks that could be put together to essentially maintain privacy, yet not being required to trust a single person.  For example, you could take a long key that, for example, is a master key to a file that's on a CD or on a floppy, if you still have that.  Or it probably makes more sense to put it on a thumb drive because a thumb drive is going to be more reliable.  And chop the key up into several pieces.  For example, if you just chopped it in half you could give your attorney half and your mom half or your sister half or something.  Now, the point is that you no longer have to trust a single person because the attorney only has half the key.  He can't do anything with it unless he gets the other half from the other person.  So he can know who the other person is.  They can be instructed not to release their half unless whatever criteria are met.  Neither do you then have to absolutely trust the other person.  That is to say, it takes everyone getting together in agreement in order to assemble the full key.



And you can do, of course, you could chop it into more pieces and give it to more people.  The problem with doing that is that then, if any one of these people are for whatever reason unable to provide their piece of the puzzle, essentially, the key being the puzzle, then you're completely locked out.  So you can do something a little more clever.  You can chop it into many pieces and then allocate the pieces so that there's some redundancy, so that one person has piece one and three and maybe five.  Somebody else has, like your attorney who's more reliable, only has piece two.  But you see what I mean, you could give multiple pieces to multiple people so that a subset of the total number of people would be able to reassemble the key in - of course they'd still have to have the file, so that's in a safety deposit box or something.  And when they unlock that, then they've got all the other keys that you use.  So you can do...



LEO:  That's a good idea.



STEVE:  ...some simple, clever things to maintain your privacy and to make the probability of that privacy being breached very, very low while still creating some redundancy so that you're sure when you want someone to have access to this information, they're able to gain it.



LEO:  One of our chatroom participants, Jmath, suggests a site called DeathSwitch.  Get this.  Imagine that you die with - this is DeathSwitch.com.  Imagine that you die with computer passwords in your head, leaving coworkers without access to critical files.  Imagine your loved ones can't find your bank accounts or that you die with a secret you longed to reveal during your lifetime.  Doesn't just have to be passwords.  DeathSwitch is an automated system that prompts you for your password on a regular schedule to make sure you're still alive.  When you do not enter your password for some period of time, the system prompts you again several times.  With no reply, the computer deduces you are dead or critically disabled, and your prescripted messages are automatically emailed to those you named.



STEVE:  I love the Internet.



LEO:  Is that wild or what?



STEVE:  What a bizarre thing.  But, I mean...



LEO:  It is so strange.



STEVE:  You can imagine there are people who are like, oh, this is exactly what I need.  You know?



LEO:  If you set up - now, you'd have to have some sophisticated friends.  But if you knew your friend's PGP key, you could encrypt a message, save it on something, a system like this.  They wouldn't be able to read it.  Only your friend would be able to read it.  That would actually be a secure way of doing it, as well.  As long as you could use PGP.



STEVE:  And the one thing you would want to absolute- presumably the reason DeathSwitch has this content for you is that it has secrets you want to absolutely make sure are not released while you're alive.  Otherwise you're...



LEO:  You want to keep entering that password.



STEVE:  You want to be very sure you don't have a false-positive DeathSwitch event.



LEO:  That would be pretty bad.



STEVE:  Yeah.



LEO:  Isn't that interesting?  I'm sure there are other sites.  But that was, I thought, very interesting.  Thank you, Jmath, for passing that along in our Stickam chatroom.  Peggy Willingham in San Marcos, Texas, wonders about blocking Phorm.  Phorm was that system we talked about last week.



STEVE:  Oh, yes.



LEO:  Oh, yes, that caused such consternation in our audience.  Steve and Leo, this is probably a stupid question.  I'm wondering at what level Phorm intercepts itself into your data stream and if a hosts file would bypass the process.  I've been a listener for two years and have been an avid SpinRite fan since version 2.  The happiest day of my life is when you created a version that supported NTFS as SpinRite v6 does now.  I came to Security Now! through GRC.com and now listen to almost every podcast Leo does.  Thank you, Steve.  Thanks for brightening and enlightening my days.  Thank you, Peggy.  What a nice email.  So could she just change - could she block Phorm by just changing her hosts file?



STEVE:  Yes.  Last week's episode went long, was long in length, because I wanted to squeeze my Bill Gates anecdote in and so forth.  And so I didn't want to make it any longer by talking about Phorm blocking approaches.  But remember from our discussion that your browser is told to go to the website that Phorm is using, Webwise, in order to induce it to give up its Webwise cookie.  If you block Webwise in your hosts file, your browser will be unable to do that.  Now, that's a problem because the redirect will fail, and you'll go nowhere.



Now, they've got technology in there so that the system will learn if something has happened to cause this whole redirection dance that we described in detail last week, remember there's three different redirections where your browser is bounced around between sites or servers pretending to be the websites you're going to for the purpose of tricking it into giving up and accepting cookies in a first-party context.  So you can also ask the question, for example, well, what would happen if my browser gave me the ability to blacklist cookies by domain?  Could I blacklist the Webwise domain and therefore not have my browser accept such a cookie?  And yes, you can do that, too.  So this system is vulnerable to blocking, and it's not difficult actually to block because of the way they've implemented this.  It would have been more difficult if they were injecting, for example, JavaScript into the page as they tried to for the first couple years of this, in '06 and '07.  Now it's not so difficult to block.



However, the problem is, well, how does that mess things up?  What happens is their technology notices something is wrong.  You keeping trying to get to the same page.  You never come back from a redirection.  No matter how many times they try to give you a cookie, you never give it back to them.  And what they do is they then put you on an "okay, I give up" list that lasts for 30 minutes.  And for 30 minutes from that time, while you're on that connection, they no longer bounce you around.  And so you just have normal Phorm-free access to the Internet.  And then after 30 minutes they're still wanting to try to get their hooks into you, of course, so they're hoping something has changed.  And whatever it is that was broken has been fixed.  And so they will again intercept a web page, bounce around a little bit, see if they can now relock their tracking technology onto you.  And if not, they back off again for 30 minutes, and you are Phorm-free.  So there are things that could be done to block these guys.  My problem, of course, is that savvy people are going to be aware of this, but the bulk of ISP users won't, and it's not an opt-in process, it's an opt-out process.



LEO:  But you can, in fact, rather than changing your hosts file, a better procedure would be to go to your ISP and opt-out.



STEVE:  Yeah, that's a little annoying, too, because opting out means that you get a special Webwise cookie which is then, similarly, you still have the same dance.  That Webwise cookie is implanted in every website that you visit so that, when it comes out, they're able to say, oh, this person doesn't want to be tracked.  Well, you've already  been tracked in order to have them know you don't want to be tracked.



LEO:  Right.  But they're not saving the information is the difference.



STEVE:  Correct.



LEO:  Mainly I would say, if somebody starts using - is there any way to know?  I guess if you see Webwise cookies, that's how you know you're being Phormed.



STEVE:  Ah, we've got a couple good questions about that.



LEO:  All right, we'll get to that, we'll get to that.  Let's get to our next question.  This is from Jeffrey T. Darlington in Beckley, West Virginia.  He takes a webmaster's view of Phorm:  Greetings, Steve and Leo.  I know it's highly unlikely I'll get this to you in time to make it into this week's Q&A episode, but I'll send it regardless.



STEVE:  Surprise.



LEO:  He did make it.



STEVE:  Yes.



LEO:  Surprise.  I just finished listening to your latest episode, #151 about Phorm, and I thought I'd share a tangentially related experience and hopefully solicit your thoughts on the matter.  I maintain a moderately popular website which has enjoyed a rather lengthy, decade-long lifespan, an eternity on the web.  Unfortunately, it is largely ad supported - pauses to allow the boos and hisses to subside.  Hey, we're largely ad supported.  I'm not hissing.  Being privacy and security conscious, I've always wrestled with this issue, but I've never enjoyed pushing ads on my visitors.  But being a small-time, one-man operation means I need to make concessions to pay the bandwidth bills.  While I could easily debate your statements in previous episodes about bandwidth being cheap, suffice it to say that none of my other revenue streams come anywhere near paying my hosting costs.  And if it weren't for advertising I would have folded up shop years ago.  Online ads are like politics.  Sometimes you have to go with the lesser of two - or more - evils.



Recently I was able to change my hosting arrangement and, in the process, become truly the master of my own domain, giving me full control over what advertisers show ads on my site.  I've carefully surveyed many of the third-party advertisers out there, found a few I believe to be more reputable than most.  As yet I haven't run into any glaring privacy or malware issues reported by my visitors.  It should be noted, however, that I make that statement with every available digit and limb tightly crossed, and maybe even a pair of eyes.



However, after listening to Episode 151 and hearing about Phorm's odd cookie-setting habits, it reminded me of some odd observations I had noticed among my own cookies.  My site uses cookies for various services such as a subscription-based premium service that allows subscribers access to exclusive content for a fee.  This service is based largely on the presence of a cookie which contains, of course, numerous security features to protect both my users' privacy and access to my protected content.  However, upon examining the cookies in my browser associated with my domain, I've noticed several unaccounted for by any of my code or any third-party applications I've installed.



That's right, just like Phorm, some other third party, likely an advertiser, has installed cookies linked with my domain that were not set explicitly by me.  Unlike Phorm, however, these cookies don't appear to be intercepted anywhere before reaching my site because they show up in the list of cookies returned to my server.  Google searches for the names of these cookies have shown that they crop up all over the web in similar situations, all set to the first-party domain, but not set explicitly by that domain.  To date I haven't figured out what usefulness these cookies might serve.  If they were set for my domain, how would the third party that set them even read them?  The cookie specification should prevent that.  It wasn't until your explanation about how Phorm works that I saw the possibility of such a system working.  However, I know my ISP doesn't use Phorm, and these cookies have existed for a lot longer than the Phorm storm has raged in the media.  As a developer it burns my biscuits to think that someone else is polluting my domain's cookie space with junk I didn't set; as a web surfer, it annoys me even further to think somebody other than the domain I'm visiting is infiltrating my browser.  Either way I'm not a happy camper.  And I'm not sure that my visitors know about this.  I'm sure if they did they wouldn't be too happy, either.



The thought occurred to me, I don't particularly want my visitors to be tracked without their knowledge.  Assuming some third party like Phorm is inserting cookies for my domain, what's to stop me from poisoning their cookies, stirring a little of my own arsenic into their dough, so to speak?  After all, if these cookies are set for my domain, I have the capability and every right to overwrite them with whatever I want.  I've toyed with the thought of testing for the existence of these cookies and, if present, resetting to something hopefully benign, such as all zeroes for hex data or a common string for all users.  I suspect that if the mysterious third party were then able to read these cookies somehow, all users who visit my site who previously had these cookies installed would then appear as the same person, or at least they'd get garbage in the cookie they would hopefully not be able to use.



I wanted to do some code - this is a long - let me take a breather.  I wanted to do some code tests with myself as a guinea pig before sending this to you, but unfortunately I haven't had time.  I wanted to get this to you ASAP in hopes it might make it to you before this week's recording session.  I do plan to carry out my experiments; and, if you're interested, I could send you the results.  The worst-case scenario I can foresee is that the third party and I will constantly overwrite each other's copy of the offending cookies.  While this may taint the third party's data, it could also annoy the neck out of visitors who have their browser set to notify them every time a cookie is being set.  I certainly don't want that.  Another possibility is I might be breaking some unseen usage agreement between myself and the third party.  Personally, that might be a risk I'd rather take under the banner of protecting my visitors.



I'm curious to know if you have any thoughts to share.  If you're curious, I've included the cookies at the bottom of this message - oh, good, because I want to know what they are - if you'd like to investigate them further.  I'll also keep you updated on the results of my tests if you'd like to hear them.  Thanks for many great episodes, hopefully more to come, from an avid listener and happy SpinRite customer.  So what were those cookies, Steve Gibson?



STEVE:  Okay, Leo.  Now you can take a break.



LEO:  Wow.



STEVE:  Yeah.  I really liked his posting, I thought it was well written, and I thought it was an interesting view, that is, sort of the view of this issue from a webmaster's perspective, someone who's noticed that something is infecting his domain with their cookies.  I have a sneaking suspicion that this is something he's probably put on his site without recognizing the consequences.  I saw exactly this during the period of time that I had Google Analytics installed at GRC.  There is something known as a client-side cookie which is distinct in browsers' minds from server cookies.  And interestingly enough, servers cannot change client cookies without injecting code into the page in order to give them access to client cookies.  So what's happening is, you know how Google, for example, just to use them as an example, I don't know that these are the cookies that this listener was seeing, but they bought some technology, I think it was Urchin.



LEO:  Yeah, Urchin is a statistics program, yeah.  That's what Google owns, yeah.



STEVE:  Exactly.  And so if you look at your own browser's cookies for many sites, you'll see _ut something, like utm, ut different things.  And this is, unfortunately, the tracking technology which anyone using Google Analytics, which is extremely popular, and maybe Google Ads - I have not looked at it closely, but I wouldn't be at all surprised if this is not similar technology.  Essentially, you have links on your pages to JavaScript which comes from Google's servers.  And that script runs, and it's running in the context of the page, which is to say in the context of the server that you are visiting that has hosted this page.  And so script is able, JavaScript, for example, is able to set cookies as well.



And I did some experimenting with this.  It is not possible for the remote server to change those cookies because its cookies sort of exist in a separate name space.  They are server cookies as opposed to client cookies, client cookies being set by scripts.  So it is likely that, you know, we know that this guy's site is advertising based.  If the ad insertion technology is script-based rather than just link-based, that is to say, sometimes all you put is you put a link to an image on the page, and then the remote advertising server simply supplies an image that fills in the box.  However, naturally we've seen an evolution of this technology so that increasingly people are putting their - essentially, advertisers require you to put some script on their page.  Even VeriSign, that little "Secured by VeriSign" seal, I'm not using it in this dynamic fashion because it's script they want me to run whenever this little animated...



LEO:  Oh, it's not just a little banner.



STEVE:  Right.  And it's like, I'd like to avoid that if at all possible.  And that's why, frankly that's why I removed the Google Analytics stuff from my site because I just - I felt uncomfortable inviting Google to run whatever code they wanted on my pages.  It's not static code that Google provides.  I provide a link to their server, which every time the page loads goes and gets the code from them.  So it just sort of seemed like something I didn't want to do.  But it seems very likely to me that that's probably how these first-party cookies are getting stuck into this guy's domain.



LEO:  Did you look at the cookies that he sent you?



STEVE:  No, unfortunately he's unable to attach things...



LEO:  Oh, he can't attach things, yeah.



STEVE:  ...on our online form.



LEO:  So that's the difference between a server-side cookie and a client-side cookie.



STEVE:  Right.



LEO:  If you have a tracker on your site, it's setting cookies client-side.  Is that right?



STEVE:  Exactly.  If you have a tracker that runs in a scripting way, it is setting client cookies.  Essentially your browser's running the code there on the page that sets the cookie locally, rather than it being sent back and forth across the Internet where the remote server sets the cookie.



LEO:  Okay.  But from the point of view of privacy, that doesn't make any difference.



STEVE:  Correct.  It's...



LEO:  It's still a cookie.



STEVE:  Yup.



LEO:  Okay.  Number four, Gilbert Langevn - looks like there's a missing vowel here.  Gilbert Langevn in Le Gardeur, Quebec, Canada.  Another Phorm-mitigation idea:  Hi, Steve.  First, great podcast.  This is my first source of information about security.  Now, about Phorm.  If we're using cookies allowed for session in Firefox - I'm not sure, is that a setting? - I think it would reduce the effectiveness of Phorm.  Firefox could still remember that it will accept the cookies for a specific site, but deletes them when we close Firefox.  Do you know what he's talking about here, Steve?



STEVE:  Yeah, essentially there are sort of two classes of cookies.  Cookies can contain an expiration date where the cookie says keep me - telling the browser, keep me, or I am valid until the following date.



LEO:  Right.



STEVE:  Well, so-called "persistent cookies" have dates far in the future because they want to be kept around as long as possible.  There's another class of cookie, though.  Any cookie that does not contain an expiration date by definition is known as a "session cookie."



LEO:  Session.  So it's only for this session.



STEVE:  It's only until you close your browser window.  And by sort of universal agreement, and I've been pleased with how widely this approach has been adopted, session cookies are never written to permanent storage.  They're never written to hard disk.  They're only kept in RAM.  So what Firefox allows, and some other browsers allow this also, or some add-ons do, they allow you to force what would otherwise be persistent cookies containing an expiration date, basically they strip the expiration date off the cookie, forcing it to be regarded as a session cookie.



LEO:  All cookies would then expire at the end of your session.



STEVE:  Yes.  And so Gilbert is very right.  If you were to configure this in that fashion, for example, or if your browser allowed you to, for example, force the Webwise cookies to always be session cookies...



LEO:  Ooh, wouldn't that be nice.



STEVE:  Yeah.  Then what happens is, it always thinks you're a new person, every time you launch a new browser session.  And it assigns you its random 16-byte ID and profiles you only during this one session of using the browser and attempts to serve you useful ads if you happen to go to anyone who's using its advertising service.  And then when you shut your window down and start it up again later, again, you've lost the Webwise cookie.  It says, oh, here's a new person, gives you a new random cookie, and basically it breaks the profiling into individual browser-length session, and which is - it allows everything to work, yet no longer term tracking is being done.



LEO:  And, well, can you, is there any browser that'll let you do that?  Is that unheard of?



STEVE:  Oh, there are allow-for-session features.  We're going to be talking about cookies in painful detail here not long from now.



LEO:  Okay.



STEVE:  Because I think it's something that has been known about for a long time, different browsers have different features, and we'll be covering those in an upcoming episode.



LEO:  Great.  Rick Nyman in Virginia had a clever Phorm detection idea:  I love your podcast.  It got me into podcasts.  I listen to it on my Treo every week.  He uses something called Resco News to stream it, I'm not familiar with that.  That's cool, though.  How about adding an HTTPS link to ShieldsUP! that will look for any unknown cookies and flag possible Phorm?  Oh, interesting.  The only issue is Phorm may stop setting up cookies for GRC.com in order to avoid detection.  If they could figure out you were doing it, they might not let you do that.



STEVE:  Well, this was under the category of great minds think alike.  I had posted this to our newsgroups sometime last week because it had occurred to me also that anytime a user came to GRC over an SSL connection, as we said last week, the Phorm system is unable, thank goodness, to penetrate Secure Socket Layer, SSL connections.  That is to say, HTTPS, secure browser connections.  And anytime someone comes to ShieldsUP!, they are briefly taken through an HTTPS session, as I also mentioned recently, in order to avoid an ISP's proxy.  And in the process it avoids all of this Phorm stuff.



So what occurred to me was, the query that I receive from them for the secure page will show all the cookies, all the GRC cookies, including any Phorm cookies that may have been set by their, you know, anytime they were in non-SSL pages at GRC.  And I could proactively notify visitors that they had non-GRC cookies from anywhere that GRC had not set, but something potentially nefarious had.  And that's a feature that's coming.



LEO:  Well, good.



STEVE:  And I ought to mention also that we crossed the 80 million mark in uses of ShieldsUP!  It was a couple days ago.  Since we last spoke we went from...



LEO:  Congratulations.



STEVE:  We're over 80 million.  And uses of ShieldsUP! is way up, too.  We're running like around 95,000 individual users per day.  So...



LEO:  Why do you think that is?



STEVE:  I know that several Linuxes are now including a mention of ShieldsUP! in their, like, test your firewall, test your security sort of thing.  And I just think the word is spreading, you know, it takes time.



LEO:  That's really interesting, huh.  We've got a Steve Bradshaw in Bobbington, U.K.  He wonders how Microsoft knows so much:  Hi, Steve.  Just finished listening to SN-151, our last episode.  You mentioned that the Malicious Software  Removal Tool, or MRT, had encountered and removed two million copies of this game-password-stealing software on Windows machine.  Whilst this is good, of course, how does Microsoft know this, unless MRT is phoning home to report what it does?  Am I being nave here?  Does XP phone home with such statistics often?  If so, did I agree to this one night after a glass too many of brain tonic?  Thanks for the show.  I genuinely find it invaluable and am often amazed by how much I find useful in my everyday job working with IBM Power Systems and Blade Centres.  Steve from Bobbington, U.K., proud SpinRite owner.



STEVE:  Well, this was an interesting question, so I did a little bit of research.  And sure enough, in the fine print which you click on, it informs you that Microsoft will be sending statistics back to them.  I did a little more digging and found the Knowledge Base article where, under the topic of "Reporting Infection Information to Microsoft," it reads, "The Malicious Software Removal Tool will send basic information to Microsoft if the tool detects malicious software or finds an error.  This information will be used for tracking virus prevalence.  No identifiable personal information that is related to you or to the computer is sent together with this report.



LEO:  So that's exactly it.



STEVE:  Yup.  They are doing some profiling just so they get feedback about what the MRT, the Malicious Removal Tool, is doing.



LEO:  Hmm, very interesting.  James in Vancouver, B.C., Canada, our old stomping ground, Steve, wonders about Phorm-induced surfing overhead, or PISO:  Hi, Steve.  I really enjoyed the podcast with Leo regarding Phorm.  After listening to your discussion of how this tech works, I cannot help but wonder how much of a hit this will have on Internet browsing performance.  This must impact the ISP's overall bandwidth, as well, yes?



STEVE:  Well, it's interesting.  One of the reasons that they run your browser through this dance is actually to minimize, well, to maximize tracking and minimize overhead.  Certainly if this was really providing or creating substantial overhead for all of the customers who use an ISP, the ISP would be pushing back on this, saying wait a minute, you know, this is going to increase our bandwidth cost more than it's going to justify itself in the money, the revenue that we receive as being a Phorm-hosting Internet service provider.



So what they've done is, by the first time you go to a site you've never been to, when you attempt to go there, you will not - the cookies for that site will not include one of Phorm's own cookies.  So it'll run you through this triple redirection dance which is - actually it's very quick.  I don't think most users would even notice it.  But the result of that is, of course, they get the Phorm Webwise cookie from your browser, and then they use that to plant that as a first-party cookie in the site you were trying to get to.  Then they let your browser try to get there again.  Phorm sees that you've got the cookie and lets it go by.  After that point, after that one triple redirection dance, the first time you visit a new site you will have their cookie for that site.  And then there's no overhead at all.  Essentially your query goes to the ISP, it sees the cookie, strips it out, and passes it on with virtually no delay.  So they did do this in order to minimize the impact in surfing performance and the consumption of ISP bandwidth.  The bottom line is it ends up being negligible.  Doesn't make it any better, in my opinion, but at lest it's not a constant problem.



LEO:  Very interesting.  Let's see here.  Andrew Steer near London notes it's not just PayPal that makes life awkward for people who block DoubleClick in their hosts file.  In the U.K. the bank, Abbey, now uses DoubleClick link-throughs on its home page.  See the lower graphics links to saving products on Abbey.com.  It's becoming pretty insidious.  Wow.  That's bad when a bank's doing that.



STEVE:  It really is.  I went to his link.  It's www.Abbey.com.  And sure enough, up comes the little happy home page for a bank.  And there's an ad down in the lower right of the page that's offering you some interest rate, something or other, 6.5 percent is the number that I remember from looking at it when I was assembling these.  And if you float your mouse over it and look, and you have a browser that shows you the link, sure enough, there's ad.doublelick.net and a bunch of mumbo-jumbo afterwards.  Which is truly disturbing because exactly as Andrew says, here's an ad on the bank site which is redirecting you through DoubleClick and then back to the Abbey site.  And I was curious to see whether the link took me to a third party, to somewhere else, but indeed it's back to Abbey.  So, I mean, that's really troublesome.



LEO:  Yeah, no kidding.  Santiago Rivero in Miami, Florida mentions a very nice Free Pascal.  We were talking about Pascal, remember, and Turbo Pascal in your Bill Gates anecdote.  And he says:  Steve, on the last Security Now! episode I heard you express your love for Pascal.  I remember seeing a while back there is still an open source, still-supported Pascal compiler, Free Pascal.  It's available at FreePascal.org.  Did you give it a try?



STEVE:  I did not have a chance to give it a try.  But I checked it out, and I am very impressed.



LEO:  Oh, that's neat.



STEVE:  It is supported across a huge array of platforms - Windows, Linux, Mac.



LEO:  Not surprised, by the way, that the open source community would do this.



STEVE:  Oh, and it's like state-of-the-art, syntax-compatible.  It mentioned TP7, so I assumed that's Turbo Pascal 7.  And there's an object Pascal version.  It's also very compatible with Delphi, that is of course Borland's commercial version.  And it's still alive.  I think the most recent version is last month.  So I think it was June of '08 that they were working on it and adding new features to it.  So this is a project that is very much there.



The reason I wanted to include this is that many people wrote saying, gee, you know, I really loved Pascal.  They felt the way I did.  They were happy to hear me mention it and said I wish there was one, that I'd like to kind of poke around at Pascal again.  So I wanted to tell all of our listeners about FreePascal.org, where there is an open source, very nice-looking project.



LEO:  That's really good to know.  That's really neat.  I'll download it and try it.  I haven't written in Pascal in ages.  You know, most of the original Macintosh stuff was Pascal.  If you worked on the Mac, you worked in Pascal pretty much.



STEVE:  Yes, in fact all of the Lisa stuff was Pascal.



LEO:  That's right, yeah.  Although they were basing it on Smalltalk because it was all Smalltalk originally.  Chris Noble in Wellington, New Zealand, asks the Important and Obvious Question of the Week.  I need a drum roll.  Hi, Steve, thanks for your recent episode on Phorm.  Scary, but good to be informed.  The trouble is, now I want to know how to tell if this is happening.  Is there a way to tell if your ISP is doing something dodgy by inspecting cookies or some other process such as header data inspection?  Thanks again for all your hard work and a wonderful resource.



STEVE:  You know, that's a great question.  And that is, I mean, and I'm sure listeners of last week's Phorm episode and the one two weeks before are saying, wait a minute, how do I know if this is happening?  Well, all browsers except maybe IE, I don't think IE has a cookie viewer.  There is a very good cookie viewer called, not surprisingly, IECookiesView.  I think it's by the guy at Nirsoft.



LEO:  Oh, yeah, he's good, yeah.



STEVE:  I like his stuff a lot.



LEO:  He does a lot of good stuff, yeah.



STEVE:  Very good and lightweight.  In fact, I'm using it with IE during the cookie development work that I'm doing because it lets me see what's going on.  But I know that Opera and Firefox and all of the Mozilla-descendent browsers do give you, even Safari does, the ability to see your cookies.  What you can do is, if you just look at the actual cookies that your browser has for a bunch of domains, you know, CNN, CNET, MSNBC, Microsoft, whatever, if something is there that is installing first-party cookies in every domain you visit, you will see a common link between all of the cookies that you've got.  That is, most sites have an arbitrary cookie format that they made up.  GRC is using cookies only for the sake of this technology that I'm developing, which will shortly be notifying people if third-party cookies are enabled on their browser when they come to GRC.  And so I made up my own format for my cookies, my own cookie names and cookie values.  And pretty much everybody does.  So if you saw something that was common in the cookies that your browser had across many different websites, that would immediately tip you off that there was some common factor that was linking otherwise separate sites together, and it would have to be something like a Phorm technology.



LEO:  Very interesting.  Calvin, maybe not his real name because you put it in quotes, located at an international airport, recounts the Interesting Story of the Week:  Hello, Steve and Leo.  I'm an IT person in a medium-sized international airport, and I have a story to share.  One day recently I noticed that our pool of DHCP addresses were completely used up.  This is unusual as we normally have about 20 percent of our addresses available at any given time.  That's not a lot.  I mean, I guess he's using most of them.  Upon closer inspection, I saw all kinds of computers and devices I didn't recognize taking leases from our DHCP servers.  An abnormally high number of devices were iPhones, but there were also computers with names like "Johns Laptop," et cetera.  Every time I tried to ping one of these devices, it was no longer attached to the network, which made it difficult to figure out their location and how they were getting onto our network.  Not having any live rogue devices on the network made troubleshooting difficult.  I won't go into the details of how I finally figured out the source of the problem.  It turned out one of our office wireless access points had mysteriously become wide open.



STEVE:  Whoops.



LEO:  Whoops.  The WAP had been configured with WPA, and I had even used GRC's Ultra High Security Password Generator to create the key.  But now the key was blank and the wireless access point was wide open.  This WAP is located in a conference room that shares a common wall with the airport passenger screening area.  How convenient for the passengers.  It didn't take long to put two and two together and realize that people cued up for airport security screening were still attaching to our network.  Because of the nature of the queuing area I don't think anyone was intentionally connecting or even realized that they had connected.  It's true, I think an iPhone, if there's an unprotected WiFi access point, will just join it automatically.



STEVE:  Yeah, it's free WiFi while you're going through airport screening.



LEO:  Yeah.  Thanks, airport.  They would go through the airport screening area and continue on with their life, not knowing they connected to our network.  That would also explain why none of the devices were live when I tried to locate them.  The problem with the WAP turned out to be that it had reset itself back to factory defaults.  I didn't want to have to climb up in the ceiling to replace the WAP, so I quickly reconfigured it back to its formerly secure state.  Upon restarting the WAP, it was back to default settings again.  Whoops.  Apparently this device, for some unknown reason, stopped holding any configuration that was given to it.  It wasn't a high-end device.  It wasn't low end, either.  It was a business-class model WAP, Wireless Access Point.  Needless to say I had to climb into the ceiling to replace it.  I felt it a bit disconcerting that a business-class WAP would reset itself to factory defaults upon a failure, and that those defaults would be zero security, wide-open wireless operation.



Thanks for the great show.  For obvious reasons I can't give you my real name and city.  But I'm signing off with the name Calvin because of Calvin and Hobbes, my hero of mischief.  Wow, that's interesting.  I guess if CMOS could no longer hold memory, just out of age or something, it would have to default to the default settings.



STEVE:  Yeah, I guess my point is, or the reason I thought this was interesting, is that it is certainly the case that routers today are shipping with no security by default.  However, this thing could ship with wireless off by default.



LEO:  That would be much better, wouldn't it.



STEVE:  Yes.  So that instead of wireless being on and all the services being on when you do a full reset, why not have the default state be wireless off so that in any situation like this where the router gets reset, it'll reset and shut down, rather than reset and open up.



LEO:  Right.



STEVE:  So we could wish.



LEO:  Yeah.  I mean, you can't - any device is going to, at some point, or could at some point fail to hold its settings.  I mean, that's just the nature of technology; right?



STEVE:  Right.



LEO:  These chips sometimes just won't hold settings.  So it's really what happens when it can't, what the failover is that's important.  And I agree with you, it should have a much more secure failover.  I understand why it wouldn't fail over to wireless on with a WPA password because you wouldn't know what the password is.



STEVE:  Correct.



LEO:  Although I guess it could have, like, a standard one or something.



STEVE:  And you wouldn't want that, either, because then it's subject to a brute-force attack.



LEO:  Right, yeah, because anybody could know that.  Now, Steve, are you ready?



STEVE:  I'm ready.



LEO:  It is time for our Horror Story and Fix of the Week.  This is from Ruan Viljoen in Cape Town, South Africa.  And he writes:  Hi, Steve.  In a previous episode you mentioned how important it is to make sure your router's default username and password is updated.  Or changed, anyway.  Luckily I had this in place but was shocked to find my router's admin interface was exposed to the Internet on my public IP, leaving it open to a brute-force attack.



Initially I thought maybe this was only allowable from, you know, accessible from my own machine on this IP.  But asking a friend to login from his home proved successful.  The most annoying part of all this is that my router has a setting to hid the admin interface from the Internet and only enable it on my local LAN, and this hiding was enabled.  That's that, you know, "turn off WAN administration" which we recommend.  Steve's recommended that many times.  But apparently even when I did that, it didn't work too well.



In the end the workaround for this problem was setting up a NAT rule to forward all traffic on port 80 to a non-existing IP on my local LAN.  This seemed to work.  My interface is now only accessible to me.  Regards from a rainy Cape Town, South Africa.  Have you ever heard of this?  Isn't that the WAN administration port?  Isn't that what we're talking about here?



STEVE:  Yes, that's exactly what it is.  And I was horrified to hear that there are any routers out in the world, this guy has one, that apparently ignores the setting for "disable WAN access."



LEO:  Oh, that's terrible news.



STEVE:  So I wanted to bring it to our listeners' attention.  And the first thing I was thinking, well, have a friend attempt to logon to your IP, except it's kind of hard to know what your public IP is, and maybe you don't want to expose this problem to anyone.  One thing you can do conveniently is use ShieldsUP! at GRC.com to scan your service ports.  And port 80 is where the WAN port will be.  And unless you know you're running a web server on port 80, in which case you've already got this external port mapped through to your web server, unless you know you're running a web server on port 80, it should either be closed or probably stealth.  You should not see port 80 open.  And if by any chance port 80 is open, and you're not running a web server, then it's your router that is, unfortunately, accepting connections on its web port from the public internet.  And you definitely don't want that to be the case, especially if it's serving up your login page, which would then allow anybody to sit there and try to guess what your username and password was.  And of course that makes it doubly bad if you have left them to their default settings.



LEO:  Right, right.  Wow, I'm shocked.  You know, I guess it means that those of us who use wireless routers and have turned off WAN administration might want to test this to make sure that we've got it set up properly.



STEVE:  Well, yeah, that's my point is, in fact, I would ask our listeners...



LEO:  I'm going to try it.



STEVE:  Yeah.  If they haven't gone to ShieldsUP! and made sure that port 80 is closed...



LEO:  So that's all you had to do was just go to ShieldsUP!.



STEVE:  Yeah, just use ShieldsUP!.  It'll show you...



LEO:  You don't have to try to login or anything.



STEVE:  No, you should not have port 80 open.  This guy would have had port 80 open, which is how his friend was able to go to his IP and bring up his login page.  ShieldsUP! would show you that port open.  But I wanted to ask our listeners, if we have any other listeners who encounter this problem, please go to GRC.com/feedback and let me know and put something in the subject line so that I'll be sure to see it.  Because I would love - this individual did not tell us what brand of router.



LEO:  Yeah, we want to know.



STEVE:  And it's like, whoa, this is a serious problem.



LEO:  I'm going to go there right now.  I'm using a Linksys.  But I'm pretty sure, I'm pretty sure I don't get my port 80s open there.  I mean, I would have noticed that.  I always use GRC's ShieldsUP!.  GRC.com, that's the place to go, not only for ShieldsUP!.  I'll actually run my - if you do common ports, port 80 will be in there; right?



STEVE:  Yeah.



LEO:  Yeah, I'll run that right now, just check.  And while I'm doing that - oh, whew, it's stealth, whew - I invite you to go to GRC.com not only to do that.  Everybody do that and let us know if you find a router that doesn't comply.  Make sure you have WAN administration turned off, though.  And then you'll also go there to get show notes, 16KB versions of the show - Steve makes those available for people with limited bandwidth - and some transcriptions, too.  Elaine does those, and that's a great way to follow along.  GRC.com.  And it's Steve's site.



And by the way, while you're there, get a copy of SpinRite.  It's a great tool for maintaining - it's THE tool for maintaining your hard drives and often very useful in data recovery, too.  SpinRite from GRC.com.  Steve, it's been a great 12 questions.  What are we going to do next week?  Got something planned?



STEVE:  Well, yeah.  We're going to do our last show talking about this problem with ISP spying nightmares.  There's a neat guy who's been very active over in the U.K. who has really - I think I mentioned he sent you email, he sent email to my office, he posted it in our user group news server, he's on the inside of sort of the whole social, political, legal battle going on about Phorm.  And I thought it would be fun to have him on as a special guest since he really knows from the front line what's happening.  And I'm going to talk then also a little bit about NebuAd, just because it turns out it's bad, too, and it's another one of the really obnoxious companies that are inserting their technology into ISP facilities.



LEO:  Right, right.  Well, I look forward to that.  That'll be Episode 153, and it'll be up on next Thursday, a week from today.  If you want to watch live, we actually do these live on Tuesday, and you can watch it live at TWiTLive.tv.  We do it at 11:00 a.m. Pacific time, that's 2:00 p.m. Eastern time or, let's see, 18:00 UTC.  And so you can watch live, and chat in the chatroom, and I watch the chatroom sometimes and get some suggestions from there, too.  And you can see Steve's smiling face, which is the whole reason to watch live.  Look at that.  Hey, thanks, Steve.  We'll talk again next week on Security Now!.



STEVE:  Thanks, Leo.  Talk to you then.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#153

DATE:		July 17, 2008

TITLE:		DePhormed Politics

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		Alexander Hanff

SOURCE FILE:	http://media.GRC.com/sn/SN-153.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo conclude their coverage of the serious privacy invasion threat from the Phorm system with a discussion with Alexander Hanff, a technologist and activist located in the United Kingdom, who has been at the center of the public outcry against this invasive technology.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 153 for July 17, 2008:  Bad Phorm.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, the program that helps you protect yourself online with all the tips you need to know.  Not just, by the way, your security, but your privacy as well.  The host of Security Now! is here, Mr. Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you.



LEO:  Good to have you.  And we are going to talk about privacy today, aren't we.



STEVE:  Yeah.  Actually we've got one of our rare guest appearances, someone named Alexander Hanff, who's in the U.K. and is pretty much leading the anti-Phorm charge in online newsgroups and in privacy circles.  We've talked for the last two non-Q&A episodes about this real problem of sort of this new, growing - unfortunately - tendency towards ISPs to sell access to their customers' bandwidth in return for revenue.  And we talked in detail two weeks ago about this Phorm system, about the technology that they have installed.



Alex is going to talk to us today about sort of like the human side, the political side, the history of this in the U.K., which is where Phorm began experimenting in '06, secretly, and in '07.  And there's been a huge outcry.  I heard you mention, oh, it was in the last couple of hours on TWiT Live, that over in the U.K. there seems to be a stronger resistance and concern for privacy rights.



LEO:  That's ironic because the U.K. has more cameras per square foot than any other country in the world.  I mean, they already in many ways have lost privacy rights.  So maybe that's why they're more sensitive about it.



STEVE:  Well, anyway, so Alex is going to tell us all about that.  We've got some security news.  And I've got a really fun SpinRite anecdote to share.



LEO:  Very good.  Let's get to security news before we go to Phorm.  What's up?



STEVE:  Well, the galactically huge, mind-blowing security issue...



LEO:  Oh, yeah.  I know where you're going here, yeah.



STEVE:  Of course you do, is that it was revealed - let's see, what is this?  This is Tuesday.  Was it yesterday, or I guess it was...



LEO:  No, it was a week ago.  And, unfortunately, it was just after we finished recording.



STEVE:  Right.  What the computer industry learned is that very, very quietly, all of this year, and especially during the last few months, a well-known security researcher named Dan Kaminsky has been working with every major vendor of DNS servers - Cisco, the open source BIND folks, Microsoft, and others - to very silently fix a big problem that he found at the beginning of the year in DNS.  So what happened is there was a synchronized - I mean, this has never been done before in the history of the Internet.  First of all, this absolutely didn't leak.  There was no leakage of the information at all.  And all at once, all of the DNSes were updated in a big sort of synchronized patch, the idea being to deliberately minimize the exploit window from the time that news of this would leak out to the time that systems actually got patched and rebooted.



LEO:  You know what I really liked is that they also said the patch was not reverse-engineerable.



STEVE:  Well, okay.  So this is about DNS spoofing.  And it is our topic for next week.  Dan is not talking about specifically what he found until he reveals it himself on August 6th at the Black Hat conference in Las Vegas.  So I've shot a note off to Dan to see if he's interested in joining us in our recording the week after that, where he'll be able - we could get it, you know, if he's available, if his schedule permits.  I mean, you can imagine he's way busy right now.  But it'd be fun to hear from him directly what it is he found.



But two weeks before that, which is to say next week, we're going to talk about something we have never covered.  We've never talked about DNS spoofing.  And that will lay all the foundation for what Dan has found because the topic of DNS spoofing is well understood and well known.  There are things you can do to harden your DNS servers.  What's going on is that many of them didn't implement some simple-to-do things.  And it sounds to me, from reading between the lines, as though Dan discovered that the things they were doing to thwart spoofing ended up not being good enough.  And I think that's what he'll probably tell us.



So I just wanted to let all of our listeners know that we absolutely know about this big DNS news, and we're going to give it probably two episodes and complete coverage because this is really interesting from a theoretical standpoint.  I know that our listeners that have enjoyed our more propellerhead podcasts are going to get a kick out of this because I'm going to explain in detail how the DNS protocol works between DNS servers and how spoofing works in general.  And then two weeks later, after Dan has been able to go public with the details, either he or I will explain what it was specifically that he found.



LEO:  Yeah, it's a really interesting story.  What's really sad is that the patch went out on Patch Tuesday, went out to Cisco and Microsoft and many Linux, you know, BIND, which is commonly used in Linux.  However, many Internet service providers didn't apply it.  So Dan made a great site, DoxPara.com, that you can test your Internet service provider's DNS.  And I was shocked to learn, you know, I have three different Internet service providers here.  DSL Extreme had done it, OpenDNS did it, but my local Comcast hadn't done it yet.  I was surprised.



STEVE:  Yeah, actually OpenDNS has always been running strong DNS servers, which were doing something called UDP port randomization.



LEO:  Oh, so they were doing it from day one.  That's...



STEVE:  They were always, yeah, or query port randomization, depending upon who you talk to, the idea being that some servers always issue their queries from the same port, from a fixed port.



LEO:  Or sequential ports, or guessable ports.



STEVE:  Exactly.  And so the more random that is, that's one of the things servers can do to thwart this.  Anyway, the takeaway, if anyone is concerned about this right now, and we've talked about OpenDNS before, anyone could switch their DNS over to OpenDNS in order to sidestep the possibility that their own ISP's DNS servers might be spoofed.  Now, I mean, again, I don't want to get ahead of ourselves.  We're going to completely cover this next week.  My sense is it's a really good thing that this is being fixed.  DNS has been known to be vulnerable for a long time.  This is forcing, for example, Yahoo! to give up BIND v8, which everyone has been saying they ought to get rid of for a long time.  They're finally going to switch to 9, which is just stronger and better.  So this is going to end up being a good thing.  And we'll talk about it in detail, the nature of the kind of problem that this represents.  It's not like end-of-the-world.  But it's really good that this is being fixed because there's no doubt the bad guys would have had a lot of fun spoofing DNS servers wherever they chose to.



LEO:  Right.  Okay...



STEVE:  The other news in security world is that there are two new zero-day exploits.  They just came out after Patch Tuesday.  These are Windows exploits.  And of course they were timed, typically, to come out, like, on Patch Tuesday so Microsoft doesn't have time to respond.  One of them only affects users of Word 2002 Service Pack 3.  So it's a bad problem because the idea would be if something was - if something sent you a document that was maliciously designed, which you opened in Word 2002 Service Pack 3, it can perform a remote code execution exploit on your machine.  Microsoft offers no workaround for this except says, uh, maybe upgrade to Word 2003 or XP or something else.  Don't use Word 2002, it's vulnerable.  I'm sure by next Patch Tuesday in August that this will be one of their fixes that they'll be offering.



Okay.  The second one, the second zero-day exploit - and by the way, just to remind people, zero-day means that it was found in the wild, that is, exploits of unknown vulnerabilities were found in the wild.  Oh, I ought to mention, however, that virus updates, virus signature updates have been updated and are being updated by the various virus-scanning companies to detect this particular type of maliciously formed document.  So even if you had Word 2002 Service Pack 3, and you were a person who likes to open documents that you receive in spam or unsolicited...



LEO:  What kind of person is that?



STEVE:  Good luck to you.  But it does mean that if you've got a good antiviral scanner that has been updated, it'll probably stop you from hurting yourself by doing that in any event.  Okay.  So the second zero-day exploit is once again an ActiveX control which Internet Explorer can invoke if you visit a malicious website.  You know, we've talked often and repeatedly, unfortunately, about ActiveX and the problem it represents because these are essentially DLLs which normally exist on your system and which, because Internet Explorer is all powerful, you're able to visit a site which runs a script that invokes an ActiveX control that was really never intended to be used by Internet Explorer.  You probably don't want to ever use it with Internet Explorer.  But the site found that there was a mistake in some sort of the parsing of data in that control which it is able then to leverage to execute code on your machine.



Well, this is the Access Snapshot Viewer, which affects Access 2000, 2002, 2003, and the standalone viewer.  It does not affect the Access that ships with Office 2007 because it doesn't include an ActiveX control for that.  On our notes page, on the show notes for this episode 153, I've got two links.  I've got a link to Microsoft's Security Advisory about this because there is a workaround.  We've talked before about the so-called "kill bits."  Kill bits is a bit you can set in an ActiveX control's registry entry that prohibits it from being instantiated - as is the jargon in object-oriented land - that prohibits it from being instantiated into Internet Explorer.  So the second link on our show notes page is a reg file which anyone who wants to can just click on it, and they can either save it or they can just run it.  And that will set the three kill bits for the three different variations of this control.  If you then shut down and restart Internet Explorer, what's happened is, even if you've got Access 2000, 2002, or 2003, or even the standalone Access viewer, IE won't be able to load it, and you'll be safe.  And again, I'm virtually certain that, by next Patch Tuesday in August, this will be one of the things that Microsoft is fixing.  But in the meantime, both of these things, this Word document exploit and this ActiveX exploit, are in the wild, and they appeared before anyone knew that there was a problem.  Thus, those are zero-day exploits.



LEO:  Very interesting.  I have a story for you, I don't know if you saw it in the San Francisco Chronicle.  It just broke today.  A disgruntled computer engineer in the city has commandeered San Francisco's multimillion-dollar computer network and prevented access to anybody.  He's a computer administrator, and he has changed the passwords at this new FiberWAN network.  It's their Wide Area Network over fiber.  It's a $5 million, or a multimillion-dollar system.  I think they spent hundreds of millions of dollars on it.  And nobody can get in.  They threw him in jail on Sunday, and he won't tell anybody the password.



STEVE:  Oh, goodness.



LEO:  The whole thing is down.  Apparently he's been having trouble, and they've been trying to fire him, and so he did this, started this on June 20th.  He basically modified the system so that only he would have, you know, he could pull a cord, and only he would have access to this system.   He did, and now they're stuck.



STEVE:  So he built some sort of like trapdoor that would allow him to get in and change the master password in a way that nobody else could deal with.  Wow.



LEO:  And they're saying right now that undoing this denial of access could cost them millions of dollars.  They're also worried that he may have told somebody, a third party, how to set off a bomb in the system, a logic bomb in the system that would destroy data.  And they're trying to find that quickly.  He has no access to the outside world.  He's in jail.  But it's a little scary, if you think about it.



STEVE:  Wow, that's crazy.



LEO:  It just shows you that the guy who knows how to run the computers wields a lot of power.



STEVE:  Yes, more so every day.



LEO:  Yes.  It's very interesting.



STEVE:  The jocks in high school are no longer laughing at us, Leo.



LEO:  No more wedgies, huh?  No more super atomic wedgies for us.



STEVE:  Okay, so my really fun SpinRite story for the week came to me with the subject line "SpinRite Got Me a TC1100 Tablet PC."



LEO:  Oh, I like that.



STEVE:  Well, actually, you like the Tablet PC or you like the subject line?  



LEO:  I like the subject line and like the fact that it got him one.



STEVE:  Yeah.  He says, "Steve, my wife's laptop was in the trash for three days after dying a slow and relatively painless death."  Okay, he calls this painless.  I would call this painful.  But he says, "It had been having problems for a while now, and so I was only using it as a TV display in my office.  One day it finally died completely.  And without hesitation I tossed it in the trash.  I normally hate parting with legacy technology, as my wife can attest.  But I resisted retaining it on this occasion.  So there it sat for three days in our trash can, collecting coffee grounds, mayonnaise, leaking ketchup, and all manner of other exotic sauces.  On the third day" - poor laptop.



LEO:  Oh, my.



STEVE:  "On the third day it dawned on me to give SpinRite a whirl.  So I pulled the laptop, docking station, and cables out of the trash, cleaned it up, and placed the SpinRite CD into its half-broken CD drive.  Sure enough, SpinRite booted, worked its magic, and completely recovered the drive.  SpinRite brought my computer back from the grave, only this time with a 'For Sale' sign attached.  I sold that laptop to a friend and used the money to purchase an HP TC1100 Tablet PC on eBay.  It still runs great for my friend, and I was able to purchase a legendary TC1100 on eBay with the proceeds from the sale.  Thank you, Steve; and thank you, SpinRite."



LEO:  Wow.  That's a great story.  I love it.



STEVE:  And by the way, I mentioned before we were recording that I have two of the HP TC1100s.



LEO:  Why is that?



STEVE:  Well, do you remember the gal who used to come on the show when we were recording Call For Help in Toronto?  She had one.



LEO:  Oh, Jenn, yeah, Jenn Cutter.  You fell in love with it, that's right.



STEVE:  I did.  Every time I saw that wacky thing I thought, oh.  I was lusting after it.  It's like, okay, I don't have one of these.  So I have to fix that problem.



LEO:  She loved it, yeah.



STEVE:  Oh, and I've got to say, I mean, for, like, used to be when I was involved in my homeowner's association I would be jotting notes in the meetings.  It's perfect for jotting notes.  And Microsoft has that very cool application, that organizer.  I can't remember the name of it.



LEO:  OneNote.  I love OneNote.



STEVE:  OneNote, yes, which works perfectly with a Tablet PC.  Anyway, it's interesting to me that Tablet PCs never really caught on.  But I have to say, anytime I want to, like, really use a laptop, it's just easier to use it with a traditional pointing device and a keyboard, especially when you really want to put text in.  But the handwriting recognition is very good.  I installed Vista on one of them, and I've got XP on the other.  And they're just kind of funky machines.  But I do like them.



LEO:  Love it, too.  Let's get our guest on, Alexander Hanff.  And he's calling from England.  Am I correct?  Is that right?



ALEXANDER HANFF:  I'm from England.



LEO:  Ah, wonderful.  It's nice to have you.  Thank you for joining us.



ALEXANDER:  You're a bit quiet, then.  You could turn yours up a little bit.



LEO:  I'll just talk louder.



ALEXANDER:  Okay.



STEVE:  Okay, so Alexander, tell us the story from the beginning.  Like what happened with Phorm, how did it come to people's attention, how did you get involved, and what's going on?



ALEXANDER:  Well, on February 14th, earlier this year, Phorm gave out a press release stating that it had signed deals with Carphone Warehouse through their Talk Talk company, BT, and Virgin Media regarding this deep packet inspection technology for the purpose of behavioral advertising.  Obviously that made the news fairly quickly on a technology news site called The Register.  They've been - they've covered this issue extensively from the beginning.  And the outrage started.



I read about it first on The Register.  Being somebody who's, A, from a technology background for 17 years; and, B, a sociologist, a lot of my work during my studies over the past three years have been based on privacy issues and issues surrounding technology.  So it was something that I was interested in both from an academic standpoint and from a professional standpoint of having worked in the technology field for such a long time.



STEVE:  Okay.  So go ahead.



ALEXANDER:  Okay, yeah.  So I got involved in looking at some of the different laws which I felt may have been violated by this technology.   The news continued to flow on The Register, with a whole bunch of articles over the period of about six weeks.  And more and more information came through about what was happening, how the technology worked, so on and so forth.  And then we found out about the covert trials in 2006 and 2007.  And at the time I was working on my dissertation, which at that point was a dissertation on the validity of Microsoft within the public sector, so the effect that has on the economy, et cetera, as opposed to using open source solutions.  However, I started to write a paper on Phorm purely out of my own interest.  And that ended up taking on the role of my dissertation.  With six weeks to go before the deadline, completely changed my topic and ended up writing this legal analysis of the covert trials in 2006 and 2007.



Then in April I was invited by Simon Davies, who's the CEO of 80/20 Thinking, who were doing the privacy impact assessment for the Phorm system, to appear as a guest speaker at what they call a "town hall meeting" or a public meeting, where Phorm and their executives addressed the press and the general public to discuss the technology and discuss their concerns.  There was me there; there was Dr. Richard Clayton from Cambridge University; there was Phorm's CEO Kent; and Phorm's technical director I believe was there.  So we all did our own little speeches.  I was asked to give a speech based on the perspective from the general public.  So I gave a speech about the privacy concerns, the issues under Human Rights Act that this causes, and the fact that people just find the entire system offensive, that it's an anathema to society to be profiled in this way.



So that's where it all started.  And then a week later I was called in to do an interview on a BBC News show called "Click," which is a technology news show, where I had a head-to-head debate with the CEO of Phorm for that show.  Then I published my dissertation shortly after that, which has now been downloaded over 70,000 times since May the 1st.  So that's been particularly successful.  And I continued my interest from there.  As a result of the attention I was getting, obviously I kind of became a natural leader for the campaign.  Then we announced the protest event, which takes place tomorrow.  And everything's stemmed from that point.  So that's where my involvement came from and how I'm moving forward with the campaign at the moment.



STEVE:  Well, so I would imagine, with the confrontation that you've had with the CEO of Phorm, I mean, where you guys have literally been head to head on this, he's justifying or defending what they're doing on the grounds that it's anonymous.  And they've, like, gone to great measures to anonymize, they don't know anyone's identity, they assign random 256-bit tokens to people.  Given that - and I don't mean to play devil's advocate because obviously I'm way in your court on this, but I want to sort of expand our understanding.  Given that, from your perspective, how is that not a useful counterargument?



ALEXANDER:  Well, basically, in the U.K., and Europe as a wider area, we have a number of laws which protect us from this type of interception.  And purely the act of processing data in the first place is covered by these data protection laws.  So in order to anonymize this data that they claim that they're doing so effectively, obviously they need to process that data.  So there was an issue there.  There was an issue with regards to the interception of communications under a piece of legislation we have in the U.K. called Regulation of Investigatory Powers Act, which is basically entrenching certain aspects of the European Convention of Human Rights into the British statute and makes it a criminal offense for any party to intercept the communications of another without the consent of that person.  Or, in the cases of national security and the prevention of a crime, the police can obtain a warrant to intercept those communications.  Then there's other situations with regards to secret trials such as the Computer Misuse Act, based on the fact that they were, certainly in the covert trials, they were altering the content of the data stream, or the "click stream," as people like to call it now, to insert their JavaScript.  So that's forcing the CPU of the computer to run extra cycles to use resources within that computer without the consent of the person who owns the machine.  So the Computer Misuse Act came into play there.



The Privacy and Electronic Communications regulations here in the U.K., which is a European directive, also prevents intercepting and dealing with communications data without consent of the people who are engaged in that particular communication.  So we have a whole host of laws here in the U.K. - and certainly that's not all of them, that's just a short summary of some of them - which protect us from this type of behavior.  And when you have laws in place, it's pretty difficult to offer a counterargument to say, well, it's illegal, but we're anonymizing it.  So do you get my point?



STEVE:  Yeah, I mean, that makes absolute sense.  So it must be that the ISPs just sort of ignored the fact that anyone could argue persuasively that what they were allowing a third party to do in return for monetary gain was a violation of a bunch of laws.



ALEXANDER:  Yeah.  Of course the ISPs involved were claiming that they've had legal advice, and they're perfectly happy with the legal situation.  They believe it's legal.  But a number of technical experts, a number of legal experts, peers in the House of Lords, people at the European Commission, MPs in our own government, all believe that this technology is currently, and certainly was during the covert trials, illegal without the informed, and it has to be the expressed informed, consent of the individuals involved.  So it isn't a case of they can bury the terms in some end-user license agreement or the terms and conditions.  These must be explicit informed consent because it's dealing with communications and issues around privacy.



STEVE:  So, for example, I know that you've listened to the last couple of podcasts where we've been talking about this.  And Leo and I have both been saying that, if this were an opt-in system, which would be easy for the ISP to do, where when the system is being deployed somebody tries to go to any random website, the ISP intercepts their page request and says, hold on a second, we want to just talk to you for a second, we want to get your permission to do the following.  If it were opt-in in that fashion, then they would have a position to argue, wait a minute, you know, it is something that people are doing only through informed consent.  And of course they know that a huge percentage of people would say, uh, no thank you, I don't want to be watched while I'm surfing the Internet by my own ISP or my own ISP's agents.



ALEXANDER:  Exactly.  And that's the point.  Certainly, if it was an opt-in situation, I would have fewer arguments.  There would still be issues regarding the consents of content providers, people who are providing these web pages which are being basically stolen for the purpose of commercial gain.  They're being copied, which certainly infringes on copyright.  So whereas I may not be the biggest fan of modern copyright, certainly in this situation it could turn around and bite them.  But yes, if it was opt-in, then there would be far fewer arguments against technology.



STEVE:  So when you say that they're stealing the web pages, you mean that it's the keyword-searching algorithm which is parsing all the pages that are being retrieved by the user in order to categorize their interests and build a profile of them.



ALEXANDER:  Yeah, I mean, essentially they do a little more than that.  They actually take a copy of the page and process it offline so it doesn't interfere with the routing hardware that they have in there.  Obviously they need to keep as much resource available for routing all these people through this Layer 7 technology, this DPI kit, as we've come to know it.  So in order to lower the overhead on that piece of equipment, the page is actually copied to another piece of equipment, which does the analysis offline.



STEVE:  I see.  So unlike their earlier work, where they were inserting JavaScript - which as I understand NebuAd is still doing in their current technology, but Phorm no longer is - instead they're doing, as we've talked about two weeks ago, the detailed technology, this redirection dance in order to push their cookies out in a first-party context across all the domains that anyone visits and using that to track people.



ALEXANDER:  Yes, certainly this whole 307 cookie dance, as you put it last week, which I found quite amusing, is a big issue and infringes on a piece of legislation we have here called the Fraud Act.  Basically by their equipment claiming to be a third party, when they really aren't, is an issue of fraud, especially in a commercial transaction between an end-user and a website.  Say for example they were purchasing some goods on Amazon, for example.



STEVE:  That's really interesting.  So the user puts the URL in for a domain they've never visited before while Phorm has been in place, thus they don't already have a Phorm cookie.  The Phorm system sees that and fraudulently intercepts their clear and explicit request to be connected to whatever website they were trying to get to and pretends to be them, redirecting their browser instead over to Phorm's domain.



ALEXANDER:  Exactly, yes.  It's not new technology.  It's basically a cache, a proxy cache, in respect to the way that it works.  So it's not new technology, and this sort of technology has been used with positive results in the past for the purpose of network, alleviating network resources and overheads.  But certainly for the purpose of advertising it puts it in a much more sinister light.



STEVE:  Right.  So what's been traditionally done is, for example, and we talked about this recently in fact on Security Now!, an ISP's caching proxy where their customers are - the ISP's customer's query goes to the proxy server.  It reissues the query for the web page, which it caches based on the caching rules which are provided on the page.  And then the customer receives that copy, the benefit being that another customer, another of the ISP's customers, might request that page or components of the page, images and so forth, which could then be served by the caching proxy and minimize the ISP's bandwidth out onto the Internet and give the ISP's customers faster response time, potentially.



ALEXANDER:  Yes, exactly.  So it has had very positive uses in the past.  But this is the first time - perhaps not with Phorm.  NebuAd have been doing this for some time now in the U.S.  But certainly this type of application of this technology for behavioral profiling is new and is very sinister and something that we find very offensive.



STEVE:  So where does this go from here?  What do you think happens?  Do you have, like, a sense for the strength of both sides of the argument and how it's going to evolve?



ALEXANDER:  Well, I am traditionally a technologist, so I am in some respects in the unique position to be able to see this from both a technical understanding and also from many other viewpoints, such as being a father, such as being a social scientist, such as being somebody with, I like to think, reasonably high-quality morals and ethics.  I'm not anti-advertising per se.  Obviously we use advertising every day in our lives.  But there's ways of doing it which are acceptable and don't intrude on people's rights and don't infringe on their privacy the way that this technology is going to do.



And obviously we have issues with mission creep, or function creep, as well.  Certainly as a technologist you'll be aware that DPI technology has the ability to do pretty much anything it wants to do to that network stream.  And in that situation we've only got the word of an anti, you know, an ex-spyware company that they're not going to add new functionality to this technology, which for an experienced admin wouldn't even take a great deal of time because basically we're just looking at regular expressions or parsing text.



So whereas it's complex for a nontechnical person to understand, certainly for an experienced technician making changes to the system to change the way that it's looking at these pages or this data can be done very quickly and almost be completely undetectable.  Because there's no oversight of these systems.  There's no way that they're using open source.  Everything is proprietary.  Certainly in the previous trials they used Squid, but they were running other technology on top of that.  So if there's no oversight, and there's no measures in place to monitor what they're doing and keep an eye on any updates they make or any access they have to the systems, then how can we trust the company that were responsible for what was pretty much regarded as the worst rootkit ever to be deployed on the Internet with all our communication data?



STEVE:  Yeah, I think you're exactly right.  One of the concerns that we've talked about while we've been discussing Phorm in the past couple weeks is this idea that this already makes people feel uncomfortable and really upsets users who discover or learn that this may be going on.  And that's only this much of it.  But you can imagine that if these kinds of companies, these third parties get a foothold in ISPs with the technology, that just as you said, it's not a huge stretch to imagine them saying, oh, well, look at how much better job of profiling we'll be able to do if we also parse people's email.  Because email between the user's client and the ISP's SMTP server is typically not encrypted in any fashion.  It's like, well, yeah, we could do a better job, make a better set of decisions about who this person is and what sort of information they're interested in.



The other thing that I find really interesting is that there's even been a question raised about how effective this profiling would be.  I mean, even if it weren't being done the way it was, the question is, has it even been shown in anything I've been able to find or read that you get a demonstratably better result after doing all this?



ALEXANDER:  Well, certainly we haven't been able to find any information that suggests you can.  NebuAd are pretty much claiming that they're still in trials, and they're not going to be willing to disclose that information to the public.  Phorm haven't done so, either.  So, no, I mean, there's no evidence.  It's an untested system in reality, and it's entering into an incredibly competitive marketplace.



STEVE:  Well, so tomorrow there's a big demonstration.



ALEXANDER:  Yeah, we've got the protest in London outside BT's AGM tomorrow.



STEVE:  And so that'll be just the idea being to raise additional awareness and get it, like, bring it to a head with BT where they're saying okay, we're going to move forward with this or we're going to abandon it.



ALEXANDER:  Certainly, yes.  And one of the other functions of the protest will be to deliver a case file to the police with a complaint regarding the covert trials of 2006 and 2007, with the intent that they're going to investigate that and hopefully lead on to a prosecution.



STEVE:  So you do have attorneys, then, involved over on the anti-Phorm side of this.



ALEXANDER:  Sorry?



STEVE:  So you do have legal counsel involved on the anti-Phorm side, and so there's some legal pushback, not just outrage among users.



ALEXANDER:  Oh, there have been some very influential legal experts who've been involved on our side of the debate, yes.  Nicholas Bohm, who's general counsel for Foundation of Information Policy Research here, which is the U.K. government think-tank on technology issues, he's a retired solicitor.  He also is quite heavily involved in Cambridge University technology law as a guest lecturer there.  And certainly he's made comments as regards to his position within FIPR - Foundation for Information Policy Research - that this technology's illegal.  And his legal analysis pretty much paralleled my own, actually.  So that was a very positive thing.



STEVE:  Do you know anything about, or have you looked at where we are in the United States in terms of the laws and issues and interception of our traffic relative to the legal framework that you've got in the U.K.?



ALEXANDER:  Well, certainly recently I wrote a paper on the sunset articles within the Patriot Act, which is an academic paper I wrote.  And as part of that I touched on information regarding personal data in the U.S.  Now, as far as I understand it in the U.S., the Fourth Amendment, which is what would normally cover privacy issues, doesn't afford any rights to the individual who volunteers their information to a third party.  Excuse me a second [coughing].  So obviously there's an issue there that there isn't sufficient protection within your Constitution.  And the Patriot Act, again, takes that even further.  So with regards to strong legislation, you're actually in a worse position than we are in the U.K.



That said, however, you've had a lot more success with your politicians there in Congress than we have here in the U.K.  I think under the Cable Act your congressmen have stated that the NebuAd technology would fall foul of the law.  Now, obviously the Cable Act is an act of legislation, so it is important.  But it's not really one of the bigger pieces of legislation you hear talked about in the U.S.  So it was interesting to see that a single section of a relatively unknown piece of legislation in the U.S. can stop NebuAd and Front Porch dead in their tracks as regards to Congress.  Whereas over here we have multiple pieces of legislation, I think seven or eight different pieces of legislation, which this technology falls under.  And we haven't been able to get a positive response from our own government.  So whereas you may not be as protected, it's unusual for us to see a country that is normally seen as being less secure with regards to privacy than the U.K., certainly receiving much stronger support from your government than we are here.  And that's a great thing to see, obviously.



STEVE:  Well, and it may also be aided by the fact that, thanks to the Patriot Act and what this country has been going through for the last seven years, ever since the events of September 11, that there's an awareness and a concern about the issue of privacy.  So we just may be more primed and ready for addressing these things.



ALEXANDER:  I had a meeting with the Earl of Northesk here in the U.K.  He's a peer in the House of Lords, which is one of our houses of Parliament.  And he's been covering the Phorm issue from an official perspective in his position.  And he believes - he actually lives in the U.S. for half of the year.  And he believes that your Congress are actually much more knowledgeable about technology issues than our politicians are here in the U.K.  Maybe there's younger blood in your political system, or maybe simply because of the massive tech industry that's there, it's something that's unavoidable.  But certainly his belief is there's a huge lack of knowledge of these issues and a huge lack of understanding of these issues within the British government.



LEO:  It's funny, we've been saying that about American government for some time.  But I guess it could be worse.



ALEXANDER:  In this case, yes.



STEVE:  Leo, can you think of anything else that...



LEO:  No, I'm just - Alexander, I'm just really glad that you've brought this to light and that others are fighting so hard.  I think in a way, by leading the way on this, you've kind of protected us here in the states against it.  I mean, you've raised awareness to the degree that by the time it came to our shores there were people prepared and ready to fight it.  So thank you.



ALEXANDER:  But we owe you some gratitude, as well, because obviously the storm that's raised in the U.S., Phorm are very much interested in expanding their markets into the U.S.  And certainly this was one of the arguments they were using to try and attract investors over the past couple of months.  Now with companies like NebuAd and Front Porch effectively being frozen out of the market by Congress, this obviously affects Phorm's financial interests.  And as a result we've seen a stunning fall in their share price over the past five months.  And that's partly been down to the action that's been going on in the U.S.



LEO:  Well, great.  Thank you so much for your time.  I really appreciate it, Alexander.  I know it's late there, and we're glad you could speak to us.



ALEXANDER:  Thank you very much for having me on, and thanks for other two shows you've done on this and the continued coverage.  I look forward to listening to the rest of the show.



LEO:  Thank you, Alexander.  Take care.



ALEXANDER:  Thank you, bye bye.



LEO:  I'm sure we will do - you're planning, I'm sure, doing more about this in time.



STEVE:  Well, absolutely.  I mean, we've got a communications link established with Alexander.  He and I have been exchanging email.  He's been participating over in the newsgroups at GRC.



LEO:  Oh, great.



STEVE:  So I'm sure he'll be able to keep us appraised of what's going on.  And I will let our listeners know as things develop.



LEO:  Steve Gibson, what happened to your Kindle, my friend?  What happened?



STEVE:  Well, okay.  The good news - this has a happy ending, and I'm very impressed with Amazon.  I was sitting in a restaurant on, like, a bench seat.  So only, like, two feet off the ground.  I had my legs crossed, and the Kindle was in my lap.  And I was, you know, eating or drinking some wine or something.  And it slipped out from between my legs.



LEO:  Oh, no.



STEVE:  Now, I knew it was slipping, and the floor was carpeted, and it was two feet.  And I figured, eh, big deal.



LEO:  Let it go.



STEVE:  And actually about a week before it had done the same thing, exact same position, same bench.  I have my, you know, the table that I like in one of my favorite restaurants.  And so it was like, eh, you know.  So it drops two feet to carpet; right?  No problem.  Except this second time I pick it up, and the screen image is severely damaged.  Like the upper quarter inch across the entire top of the screen and about an inch over from the left vertically streaking down was just dead.  Sort of like dead scan lines.  So I was like, ooh, ow, no.  And so, figuring that it was sort of like the high-density edge connector that a screen like that would use, I sort of squeezed on the top of it?  And, sure enough, it changed the nature of the outage on the screen, but didn't improve it, really.  It just sort of modified it.  So I knew I was, like, in the right area.  So I'm thinking, oh, my, you know, now what?



So, okay.  No Kindle is more than a year old because they were only selling them since last November when you and I both got ours.  And so I went online, looked around in the online groups and saw that several people had had very good experiences when they'd, like, done something bad to theirs, or the Kindle had died or something, as is going to happen with any consumer product when you're pumping out as many as Amazon is.  So I contacted Amazon about a week ago.  I don't know if it was email.  No, I think I phoned them.  Oh, yeah, I found a phone number in the online forums.  I phoned them, talked to an Amazon person.  He said, oh, yeah, no problem, we'll send you a replacement.



LEO:  Wow.



STEVE:  And you have a month to send back your other one.  And I'm going to send you email with a link to a UPS prepaid return deal.  So I've printed that out.



LEO:  That's amazing, Steve.



STEVE:  I am very, very impressed.  In two days I had a brand new Kindle.



LEO:  Wow.  And the account was transferred over?



STEVE:  Yup.



LEO:  Wow.



STEVE:  Yup, I was able to move the content over.  And I boxed up the old one and sent it back.  And, I mean, and I have to say, Leo, speaking of the Kindle, just as that was happening, I was noticing that the battery was already beginning to show some fatigue.  That is, it was - normally I could, on a full charge, I only turn the cell radio on for, like, briefly at 5:00 a.m. when I'm at Starbucks in the morning to update my Wall Street Journal and Slate and periodicals; then I turn it off.  So it's barely on.  And normally I could go for several weeks before I would even notice that the battery gauge came even the first increment down below full.  But here, now, what, eight months old, it was clearly not lasting as long.



LEO:  Interesting.  Of course you're using it very heavily.



STEVE:  I am using it every day.  Although a lithium ion battery should have about two years of useful life.  They actually do get old, even if you don't use them at all.  There's, like, sort of a freshness factor to them.  The good news, of course, is unlike some consumer products made by that company whose name starts with "A"...



LEO:  You could change the battery.



STEVE:  Yes.



LEO:  In fact, you know, it's funny, when I ordered my Kindle, I ordered a second battery.  They're cheap.



STEVE:  Yes, they are inexpensive.  And so I know that a year from now, assuming that this is the same, that my replacement Kindle's battery begins doing the same, I'll just get a second battery and, you know, and be back...



LEO:  I have my second battery, but I haven't ever used it.  I got it because I thought, oh, maybe I'll bring it with me in case I go on a longer trip and I can't charge it up, like when I was going to Egypt.  But I never needed to use it at all.



STEVE:  No, I mean, the Kindle's battery life is spectacularly long.



LEO:  It goes a long time.



STEVE:  Anyway, so my story of dropping my Kindle had a happy ending, and I'm very, very impressed with Amazon's customer service.  And I thought, I mean, literally, I'm bound to this thing.  So I thought maybe they would make me send it back, and I would be without it for a month or something.  I was considering buying a second one just so I could have my own overlap.  And then I thought, well, what am I going to do with a redundant...



LEO:  Two.



STEVE:  Yeah, exactly.  So they just - they solved the problem in a very satisfying way.



LEO:  That's truly impressive customer service.  I have to say, credit to Amazon for that.  Yeah, it may cost them a little bit in the short run.  But in the long run, boy, what great word of mouth you get when you start doing stuff like that.  I mean, to be honest, you broke it.



STEVE:  I did.



LEO:  They didn't have to fix it.



STEVE:  Yeah, it wasn't their fault; it was my fault.  Even though I have to say, Leo, that should not have broken it.



LEO:  It shouldn't break after a two-foot fall to carpet.



STEVE:  It was a gentle fall.  And so it was like, okay.  Although up till that point it had been absolutely perfect.  So it's not like I had any other complaint.  And I've got to say I'm still of two minds about the page turn.  It's annoying that it's so easy to do it by mistake, but it is so nice that it is so easy to do it when you want to.



LEO:  Yeah, once you learn how to hold it, which is down on the keyboard, counterintuitive though that may be, it's not such a bad thing.  And I do a lot of reading on the Kindle.  Although in between the audio books, and now I'm reading Neal Stephenson's book, and the only way I could read it was in paperback because it's a pre-release, and that's a thousand pages.  That's kept me pretty busy.  So I've actually been reading a paper book.



STEVE:  Oh, my god.



LEO:  They're heavy.  You've got to hold them up.



STEVE:  What's paper?



LEO:  I don't know.  This thing, it's not going to work.  Actually, when I mentioned that to Audible they said, you know, we record these ahead of time.  And they said we really ought to talk to the publishers about the readers copies, offering - because we know many reviewers like to use audio books, maybe doing audio versions for the reviewers.  And actually I think that's a great idea.



STEVE:  I'll bet it helps, I bet it would help to get books reviewed.



LEO:  Yeah.  I know I'm looking, yeah.  Hey, thank you for covering this.  I think you've done the best job of anyone covering Phorm and NebuAd and all of these creepy little ISP things.  We do have a victory already under our belt because Time Warner decided not to use NebuAd.  I think that this is so important to get the word out about this.  And I think we might have stemmed the tide.  And I think a lot of credit goes to you for that.



STEVE:  This is something we had to nip in the bud.



LEO:  Yeah, no kidding.



STEVE:  And next week I want to tell all of our listeners to wind up their propeller hats because we've got a terrific episode planned on explaining exactly how DNS can be spoofed.  What happens when you do that is you stick the wrong IP address for a website into a DNS server, such that anybody who then queries for the IP address of that site gets the wrong IP address, and they are then directed to a potentially malicious server instead of the right one, even though everything looks just fine from their browser.  So we'll talk about how that happens next week.



LEO:  Yeah, that's a creepy one, and I'm glad we're going to be talking about that.  And that'll lay the foundation for our interview with Dan Kaminsky, we hope, after Black Hat.  Once he's told the world, he'll come on and give us some greater detail.



STEVE:  Yup.



LEO:  Steve, always a pleasure.  Make sure you go to GRC.com.  That's where you'll find Steve's great SpinRite, the bestest repair utility and maintenance utility money can buy, a must-have if you've got hard drives.  Also you'll find his great free programs including ShieldsUP! to test your router and a whole bunch of useful little tools like Wizmo, and 16KB versions of the show, and transcripts for those who like to read along as they listen.  It's all at GRC.com, the Gibson Research Corporation.



STEVE:  And this week I will remind our listeners that the show notes for this episode has the links for people who are concerned about the ActiveX exploit of Access that allows them to easily set the kill bits for the three variations of that control in order to just shut that down until Microsoft patches it.  Certainly I'm virtually certain they will during next Patch Tuesday, which will be the second Tuesday in August.



LEO:  Thank you, Steve.  We'll see you next week.



STEVE:  Talk to you then, Leo.



LEO:  On Security Now!.  Bye bye.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#154

DATE:		July 24, 2008

TITLE:		Listener Feedback Q&A #46

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-154.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 154 for July 24, 2008:  Listener Feedback #46.  This show and the entire TWiT broadcast network is brought to you by donations from listeners like you.  Thanks.



It's time for Security Now!, Episode 154, our sesquicentennial plus four.  I'm just going to keep saying that, Steve.  I just like saying that word.



STEVE GIBSON:  I think it's plus two now.



LEO:  Oh, plus two, even better.



STEVE:  We're zeroing in on it, yeah.  Two episodes to go.



LEO:  So Steve Gibson is here.  He is the man at GRC.com, the Gibson Research Corporation, where you'll find such great things as ShieldsUP!, which has become world-famous as a way to test your firewall or your router when you first get it working.  Everybody goes to ShieldsUP! at GRC.com.  He's also, of course, the creator of SpinRite, the world's finest disk recovery and maintenance utility.  How are you today, Steve?



STEVE:  I'm great.  It's great to be back with you for approaching the end of our third year, Leo.



LEO:  Wow.  Questions and answers today, as always on the even-numbered shows.  And we've got some really good ones, including, I might add, the Sad and Disturbing Truth of the Week and the Creative Writing Award of the Week.  I love how you get these awards, Steve.



STEVE:  Well, they're deserved, as our listeners will hear when we get to them.



LEO:  Oh, good.  I can't wait.



STEVE:  We do have first some security news.



LEO:  So, Steve, what's happening in the world of security this week?



STEVE:  We've got three interesting things.  First of all, there are new updates to Firefox, both v2 and v3.  2 went to 0.16.  Seems that every time I talk about this there's another subversion of Firefox 2.  Last time it was .15; now they're at .16.  So I wanted to let our users know that they want to check in with Firefox, those who are using it.  I have to say, Leo, I'm very impressed with the people who use GRC.  I don't know if this is an overall trend, but more than half of GRC's visitors are using Firefox over IE.



LEO:  I think we're, like, almost 60 or 70 percent on TWiT.  It's great.



STEVE:  Yeah, it is.  The Firefox browsers, especially v3, I'm very impressed with.  They fixed some bugs that are still in v2 and that I think there's very little chance they're going to fix in v2 because they're more architectural problems, not little cosmetic patchy things.  So 3, as soon as people are comfortable with the move to 3, I never want to push anyone to move to a new major version of something...



LEO:  Although I just saw a very interesting study - oh, where did I see it? - that said what a surprisingly few people were using the most recent version of their browser.  And I think you and I would both agree that that's a pretty important thing to do is update.



STEVE:  Well, for example, the reason these were both fixed was to fix that blended threat we talked about a few weeks ago that involves having both Safari and IE or Firefox on the same system.  Remember that Safari by default downloads things to your desktop.  And unfortunately Windows searches for DLL files in a really brain-dead sequence which involves your desktop.  So it's possible for someone to cleverly, by hoping that you've got Safari and a non-Safari browser both on your system at the same time, to get Safari to download something to your desktop which then Windows will discover when you're using a non-Safari browser and get it to run this code.  So that's what was fixed, that and a few other little less significant things, that was fixed in this version of - in these most recent versions of Firefox.



LEO:  This study was from the Swiss - I found it now - Swiss Federal Institute of Security, IBM, and Google.  And 60 percent of people use up-to-date, fully patched web browsers.  But that means there's 40 percent out there who are running kind of vulnerable.  I like IE7, though.  I think IE7's pretty secure.  Do you have an opinion on that?  I know you've always been an IE user.



STEVE:  I have, and I have to agree with you.  I think that, I mean, it is - my annoyance is that it takes Microsoft so long to fix this stuff.  I mean, it's years, years, years.  I mean, and I think the greatest comeuppance for them is that they have given an alternative browser like Firefox such a huge window of opportunity to come in, arguably with a much more secure solution than IE.  I mean, it's Microsoft's own fault that Firefox has the huge market share that it does.  And you've got to know that Microsoft is not happy about that.  They fought like crazy to get IE to the position it is now over Netscape back in the day.  And here it's because people have left IE because of all the problems it's had for so long.  It's just shocking to me that it's taken Microsoft so long to fix these things.  But yes, it is substantially more safe.  The fact that you get - you've got good built-in pop-up blocking; the fact that you get a notice when an ActiveX control attempts to run.  And so, I mean, many problems are now no longer problems under IE.  But it's got such a bad reputation which is now going to haunt it for the next who knows how long.  They may never recover from that.



LEO:  Well, yeah, it's true.  And I think a lot of people, once they use Firefox, like the extensions so much, like the capabilities so much, they don't even go back to IE.  So it really doesn't matter that IE is now safe.  It's too late.



STEVE:  And Firefox is a - as I was just saying, Firefox v3, and even 2, but 3 even more, is a beautiful solution.



LEO:  Oh, yeah, I agree.  Things like NoScript, which really I know you love, Adblock, some of the things that you can do in Firefox you just can't do in any other browser, really makes this a good choice.



STEVE:  Right, right.  A report that came out on the 'Net from a security monitoring organization had something to say that I thought was rather humorous, not really good news.  It was a report on the changing structure of cybercrime organizations.  And this report noted that there has been a huge fall in the price of compromised financial details.



LEO:  It's cheap now.  We're having a fire sale.



STEVE:  And guess why?  It's due to an overabundance of supply.



LEO:  Yeah, yeah.  Oh, boy.



STEVE:  There are so much now, bank account details including PIN and so forth, that the price has fallen because there's just so much of it available.  Used to be that the bad guys would pay about a hundred dollars for bank account information including the PIN number.  It's dropped now between 10 and $20 just because there's so much of it around.  And the bad guys are now, like, well, that's sort of more commodity.  They're now looking for other sorts of information that they can get higher margins on because they would like something that's more valuable because bank account information, ah, that's just, you know, not a big deal anymore.



LEO:  Anybody can get that.  That's amazing.



STEVE:  Also in the news - and we may cover this more, in more detail if necessary.  But Bruce Schneier, the well-known security researcher at Counterpane, founder of Counterpane Security, worked with a bunch of students.  And it's actually the students he says who did the heavy lifting.  They demonstrated that systems which are not fully encrypted, that is, that do not have whole-drive encryption, but which instead encrypt portions of the hard drive, actually don't succeed in the plausible deniability, for example, which TrueCrypt attempts to offer.



It's just a fact that the OSes have not been designed to properly sanitize the debris.  So things like funky drive letters that are lingering in the registry and in various history lists and things, if a forensic research acquired a machine which, for example, had one of these - one of the features of TrueCrypt, for example, is that you're able to create like a hidden partition in the unused space of an encrypted partition, and the idea being, oh, you can say no, no, no, here's the keys to the partition that I've got encrypted.  And you have plausible deniability that there's actually another partition hidden behind that one.



Well, it turns out, unfortunately - and again, this sort of makes sense when you think about it.  Accessing that hidden partition brings it into currency in the OS.  And there are enough little traces left behind in the OS that a good forensic researcher would be able to determine that, uh-oh, there was another partition there that now has disappeared.  And then I guess they twist your arm harder and make you give them the second set of secret keys.  So just a little heads-up.  Again, a fully encrypted partition, because the entire thing is encrypted, doesn't have this vulnerability.  On the other hand, the vulnerability that is created is a feature that some users might want.  It's worth noting that it's now been demonstrated that that plausible deniability, it's broken.



LEO:  Interesting.



STEVE:  Also, I didn't intend to go into great detail, and I still don't intend to go into great detail, in another one of these heinous ISP-sponsored third-party spying outfits.  We've talked of course now for several weeks on our non-Q&A episodes and even in some of our Q&A episodes about the Phorm system.  One of the other ones we mentioned in the very first week of this was NebuAd.  Well, some of the people in the GRC newsgroups mentioned that they have received updated terms and conditions from their ISPs notifying them that they're going to be using NebuAd.  And in reading through postings, submissions from our listeners, in order to select the questions for today's Q&A, I ran across another couple Security Now! listeners who wrote that when we talked about NebuAd, that kind of rang a bell in their memory.  And they went back and looked at some updated stuff that they - fine print that had been sent to them.  And sure enough, their ISPs were notifying them that they were going to be using NebuAd.



So I did want to just mention the technology very briefly that NebuAd uses because it's way annoying.  It does not perform the script-free multi-browser cookie dance that I described a couple weeks ago where remote sites are being faked by the equipment hosted in the ISP's facility which intercepts your attempt to access a remote server and instead bounces you to a NebuAd server and makes your browser dance around a few times using redirection in order to basically salt everywhere you go with their own cookies.  Instead, this does what Phorm was trying to do in the '06 and '07 pre-release testing with British Telecom, BT.  It actually inserts script onto the pages you download.  It inserts JavaScript.



Essentially what it does is it spoofs a final packet into the stream coming back from a web page.  When it sees the web page ending with a backslash html closure in the html code, that triggers it to inject its own script reference at the end of the pages you download.  So it is actively modifying the pages you receive from websites you visit.  And that JavaScript includes a URL to a site owned by NebuAd that causes your script-enabled browser to then go and fetch whatever scripting code they choose to be inserting into your browser page at that time.  And of course your browser then runs that script, and that's the way they succeed in planting cookies on your browser and enabling tracking.



So it is really bad and annoying also.  Does it in a different way, but essentially achieves the same thing.  And they've got the same opt-out mumbo-jumbo.  But here we have an instance where ISPs are sending out fine-print boilerplate that people are not reading, not giving people the opportunity to explicitly opt in, but rather requiring them to opt out if they don't want this kind of third-party tracking going on.



LEO:  They just keep trying, don't they, Steve.  It's amazing.  They won't give up.



STEVE:  It's a bad trend.  And lastly I wanted to mention that, since we last talked, Service Pack 3 of Windows, XP SP3, switched from being a separate sort of called-out notice, if you've got your system set for downloading but notifying you for - since the release of SP3 there was like a separate notice that was offering you SP3.  And as many people know, probably everyone who's been listening to the podcast, there have been lots of problems with SP3.  Many people have no problems, which of course is why it's still out there.  But there have been all kinds of instances of selective problems occurring in XP after the installation of SP3.  I had two different problems.  My tech support guy Greg had a problem.  I think I heard you mention that you had a problem.



LEO:  Yeah.



STEVE:  With a post-service pack...



LEO:  I have one machine it just, I mean, to its credit, it tries to install it, can't install it, rolls back.  I'll have to figure out why, though, because it's going to keep doing that now, I guess.



STEVE:  Well, that's why I'm bringing this up.  It turns out that Greg, my tech support guy, brought this issue to my attention.  And I put into Google - thank you, Google - "service pack blocker tool" or something like that.



LEO:  Ah-ha.



STEVE:  Turns out Microsoft themselves offer a very small, simple, lightweight executable, downloadable from their site.  Just put in "service pack blocker tool" into Google or into Microsoft's own search.  It's easily findable.  What this does is simply set a bit in the registry.  So you don't even really need the tool if you are, like, a registry hacker kind of person.  But part of this is a very small, a little 10K, I don't think I've ever seen Microsoft do anything for 10K, it doesn't have a fancy...



LEO:  It's probably just a registry modification.



STEVE:  It's just a little command-line EXE which basically puts a DWORD variable into the registry telling Windows Update not to update this service pack.  So I wanted to let individuals know, also people who are responsible for, like, corporate updates or even small office groups, that it is possible - first of all, that this Service Pack 3 has switched into this mode.  And if they feel as I do that I don't know, it's still not time for SP3, you can keep Windows from sneaking it in behind your back.



LEO:  We should point out that anybody who does that, though, should be a security wiz and know what to do to protect themselves against the patches that SP3 is adding; right?  I mean, it's...



STEVE:  Yes.  So far the patches that have happened since have patched around SP3, yes, and haven't required it.  There was some question about whether this most recent DNS patch might be requiring SP3.



LEO:  Oh, did they put out a patch for that DNS flaw?



STEVE:  Yeah, Microsoft actually beat everyone else to it.  It was in the last...



LEO:  Oh, that's right, they did it Tuesday, yeah.



STEVE:  Right, it was in the last round.  So that's been out.  Of course that is our serious propellerhead, really fun, techie topic for next week is how DNS spoofing works.



LEO:  There was an interesting post, I don't know if you saw it on Slashdot, on the IT part of Slashdot, with a guy explaining - because you know Dan Kaminsky hasn't really revealed the details of this DNS poisoning exploit.  Somebody apparently figured it out, and it's actually been published now, which means people will be using it now.



STEVE:  Oh, absolutely.  So it'll be interesting to see.  And lastly, I've got a great, fun SpinRite story to share with our listeners.  This is from, I think, a Security Now! listener, I'm not sure, a Steve Balaam.  He wrote just recently, says, "I bought SpinRite 3 around three years ago and made a CD from it, and then completely forgot about it.  Just recently I was composing music for a game..." - so he's a game music composer.  And he said, "...and all of a sudden my brand new, non-networked, non-backed-up machine started to make some very strange, irregular noises from the hard drive.  Fearing the worst, I grabbed my high-capacity portable drive and tried to back up all my files.  Unfortunately, the hard drive then froze."



LEO:  Oh, boy.



STEVE:  Uh-huh.  "And when I tried to reboot, I could not then even get past the POST sequence, the so-called Power On Self Test the BIOS does.  I feared the worst, as it seemed to give all the indications of complete hardware failure, and was mentally preparing myself to write off six weeks of hard work.  Then I remembered SpinRite, grabbed the CD, and set the BIOS to boot from it.  Amazingly, SpinRite found the hard drive.  And so with my heart in my mouth I selected to recover the data.  Six hours and many alarming graphs posted from SpinRite later" - you've seen that Dynastat...



LEO:  I was going to say, that's Dynastat, yeah.



STEVE:  Yeah.  He says, "And many alarming graphs later, it said it was done.  I took out the SpinRite CD, pressed the reset, and waited.  As if by magic, the PC booted.  I logged on and found everything was as it should have been.  I have since added another drive for resilience and will now periodically run SpinRite as preventative maintenance.  This program truly is a lifesaver, and probably the best money I've spent in a long time.  Thanks for a great product."  So thank you, Steve, for the great report.



LEO:  Isn't that nice.  Steve, are you ready for some questions, laddie?



STEVE:  Aye, captain.



LEO:  We've got some good ones for you.  Starting off with John R. Baskwill at Penn State Harrisburg.  He has all the details.  He says:  I was listening to some past episodes of Security Now! recently, when I heard a question from a Penn State student concerning ShieldsUP!.  Since I work for Penn State - wow, now this is getting the answer from the source here - I thought I'd try to clear things up a little bit here for you.  He says the student was concerned that the IP address on his computer was the same as the IP address that ShieldsUP! was showing, which means there must be no NAT being performed; right?



STEVE:  Yup.



LEO:  Right, right.  Well, during your answer you said that they, Penn State, must have a big network where they can afford to give individual public IP addresses to the students in their dorms.  You were absolutely correct, sir.  When I first started working for Penn State I was surprised by the large size of the address pool the university owns.  Each student living in the dorms must register his or her MAC address with the university.  A lot of universities do something like this.  Obviously they want to keep people off of their network who aren't students.  But it's a tricky thing to do.  So here's how they do it at Penn State.  So they register their MAC address, which is locked to a specific port, interestingly enough.



STEVE:  Yup, so there'll be a data switch which is intelligent, and you're able to say only allow this low-level Ethernet traffic from this MAC address.



LEO:  That's really good.  And each MAC address is assigned its own IP address via DHCP.  That's a public IP address.  So that's why the address on the computer is the same address ShieldsUP! displays.  A little different than a router at home.  It doesn't use a private pool of addresses.  It's actually giving up the public address to each - you've got a static IP address if you're at Penn State.  Also during your answer you and Leo said that since no NAT is being performed to provide stateful incoming security, the university could have a firewall which is blocking all inbound traffic.  That is true.  All data ports in the dorms are behind a firewall.



You also indicated the setup as described by the student made you a little nervous because a student could put a NAT router in his or her room for additional protection, or should put a NAT router.  That's not true.  He says the only device a student is allowed to connect to the network is that single personal computer.  That makes sense because the router would have a different MAC address.  They may not connect hubs, routers, print servers, terminal servers, or other network devices.  There are other limitations the students must adhere to, including bandwidth limitations.  The students are encouraged to read the Housing Connection Agreement before signing it.  Additionally, the students must watch a short video that details what they may and may not do while on the Penn State network.  Any inappropriate or illegal activity is traced, if circumstances dictate, by the IP address.  That's why they use a unique IP address, because it belongs to that individual student.  Does that clear things up a little?  Go Nittany Lions.



That's great.  I mean, I think most universities have to deal exactly with these problems.  And this sounds like a good solution.



STEVE:  I think maybe part of the reason - I don't know how Internet-savvy the students are.  But if they, certainly like our own listener who originally wrote in with this question was asking, if they realize that the IP they've got is static and assigned to them, then it seems to me they're going to tend to be more responsible if they don't think that they're hiding behind a NAT router, no one can trace them back behind the router.  If they're doing things, like things that are in breach of the university's policy, for example the MPAA finds their IP address out sniffing around, downloading lots of movies, and the MPAA wants to stomp on them, it's like, okay, this IP address owned by Penn State has been found to be downloading this content.  Well, that's directly traceable back to a given student.  So maybe the students understand that.



Now, it's certainly the case that this is a pretty much locked-down system.  It seems to me, well, I don't know, maybe a little overkill because this means, for example, that a student can't take their laptop from their dorm room to somebody else's dorm room and, like, both be online on that other person's connection.  So, I mean, I understand certainly universities are crazy about student behavior on the network.  This really does create accountability, which I'm sure is good.  But one of the things I'm sure John who posted this knows, and many of our listeners probably know...



LEO:  And that they're all saying right now in their heads...



STEVE:  Yes.  And that is, you can certainly change the apparent MAC address of a router to emulate the MAC address of a PC.  In fact, that's a feature that all NAT routers now offer, specifically for this reason.  Some ISPs lock their subscribers' MAC address to a given machine because in the old days they were sort of fighting this whole idea of NAT routers and, like, well, no, we want you to buy five IPs from us, if that's what - you're going to be using five machines.  Well, good luck.  I mean, from a networking standpoint, a PC with a firewall is indistinguishable from a NAT router.  And so all you would have to do, and I know there are Penn State students who are aware of this, is just copy the MAC address from their PC into a router, plug it in, the university is going to be none the wiser.



Now, the university I'm sure knows, one of the things this certainly allows is for, again, enforced accountability.  It is probably the case that you could detect, if you really were concerned about it, whether a router was at the endpoint or a PC because there's going to be different behavior outward facing from a router than a PC.  But again, that would be - that would require some very sophisticated equipment.  And I think mostly what the idea is, a student would have to be clearly violating the agreement that they signed as part of getting access or agreed to as part of getting access to the university network if they were doing this.  And again, it certainly enforces accountability.  But we never really talked about DHCP, as I'm listening to this, and he's talking about assigning specific IPs by MAC, DHCP is a far more powerful protocol than most people are aware.  I think we're going to have to talk about that sometime soon.



LEO:  Oh, I'd love to because we all use it.  But I think we use it in a very kind of simple way.



STEVE:  Yeah, I mean, it does, actually can do many cool things more than just giving you an IP address.



LEO:  Oh, I'd love to know more about that.  That's great.  Yeah, I wonder how many kids, first thing they do, they check into the dorm room, put a WiFi access point in there, spoof the MAC address, and provide bandwidth for the whole dorm?



STEVE:  And I guess my feeling is that really the - and I'm saying nothing negative about Penn State.  I mean, we've got John, a Security Now! listener, I don't want to upset him.  But what they've done seems like so onerous, I mean, so restrictive that you're almost forcing students to break out of that jail because you're not letting them, for example, have their friends over and all plug their laptops in, in order to do their - get together and do a little homework.



LEO:  And as you know, the more onerous you get, the more likely somebody's going to be figuring out ways around it. 



STEVE:  Exactly.



LEO:  Let's get to another question.  Christos Kirst in Huntington Beach, California wants the stat of his net.  Okay?  Okay.  Steve, first off I want to say I own SpinRite.  I've talked at least four people into buying it, as well.  It's amazing.  Also your podcast keeps my drive interesting.  Always great info that's making my network more and more secure.  My question is this:  When I run the DOS command - actually you could run it on any machine - "netstat -an" on my Windows 2000 server, I get the normal info.  But then what gets me worried is this UDP thing.  It shows UDP 0.0.0.0:65518 *.*.  Should I be worried about this?  What is it?



STEVE:  Well, okay.  What that says, first of all, netstat is a command universally available from the early days of UNIX machines, which were the first machines to be doing networking like this.  It's a command, very useful command that I often run in a DOS box.  It is a DOS-style command, so a command line-style command.  Netstat -an actually happens to be my favorite prompt, my favorite command line...



LEO:  What does it do?



STEVE:  ...switches also.  It gives you just exactly the display that you want.  It shows you all of the various ports which have something going on, that is, that they're open and listening, you've got established connections, they may just have been shut down, in which case they're in time-wait mode.  You can really sort of - it's a snapshot into the networking status of your machine.  Now, this one command line, or this one example that Christos cited, where it says UDP 0.0.0.0:65518, what that says is that something, some process in the system, has opened and is listening for incoming traffic on that very high-numbered port.  Ports only go up to 65535.  So this is - and he's at 18, which is just below the upper ceiling.  So this is not something that just said give me any UDP port.  It apparently said, I want one kind of way up out of the way, maybe sort of trying to be obscure.  So especially on a server machine, which tend to be rather lean and mean and don't have a whole bunch of random applications running, this is something to kind of be worried about.



Now, the problem is that Windows 2000's netstat lacks a feature that was added in XP which is very useful.  In XP there are additional commands.  There's a "-b" command-line option which will show you the name of the process which has opened the port, which would immediately allow you to determine what it was in your machine that had done this.  The concern is that something may have gotten in there, and it's set up shop.  I mean, this is what a trojan does is traditionally they would open a listening port and wait for someone to come by and connect to them, discovering that they were installed on that machine.



So I don't want to be alarmist.  But this is certainly something that says - that 0.0.0.0 is essentially wildcard.  It's like *.*, you know, like ****.  For example, when I do a netstat on my XP machine, I'll see a whole bunch of things that are 127.0.0.1.  That's a sort of a special reserved network block, the whole 127 block is.  But 127.0.0.1, that's sort of shorthand for this machine.  So what that says is that something has opened a port on the local machine, that is, it's listening for other things on this machine that want to use the networking system to talk to each other.  And this is something that UNIX machines have done since day one.  And it's a practice that has become very commonplace, even on the Windows side.  So those are not something to worry about.  Those are, for example, I saw that Firefox has opened such ports.  IE has opened such ports.  Many other things that I've got running have said, like, okay, we're going to use my system's own networking system to talk among these processes.  But the fact that it's 127.0.0.1 means that that port will not accept incoming connections from other IP addresses.  But this 0.0.0.0 will.  It's basically saying, I'm open for business, I'll accept incoming data from anybody.



Now, having said that, if this machine is behind a NAT router, as we know, that provides incoming protection.  So that won't be accessible from the outside.  And hopefully, if you're running a server, you are absolutely behind a firewall.  And rather than in the old days, where you would block things that you knew were bad, the only way to configure a firewall these days is to specifically open incoming ports that you know you want.  So, for example, he probably has 80 open for allowing web traffic, maybe port 443 if he's also allowing SSL secure connections to a web server.  I don't know what kind of services he is serving on this Windows 2000 machine.  But my point is that, even if this were something bad that had, like, snuck itself up into the top of the port space and was hoping to receive word from mission control somewhere out on the Internet, there's nothing going to get into that port because certainly any sane configuration today will have blocked that.



So part of the good news is, even if this were something bad, there's not anything it's able to do.  But you do - I would say this is suspicious enough that you ought to go about figuring out what it is.  Now, there are some free utilities available for Windows 2000 that do this kind of port mapping.  In fact, this is one of the features that one of the Sysinternals apps offers.



LEO:  Autorun.  Autoruns.



STEVE:  No, autoruns is things that start up a system.



LEO:  The process program, what's it called?



STEVE:  No, it was a networking-based tool.  But one of the things that...



LEO:  Current ports.  Is that it?  I'll look it up while you talk.  You talk, I'll look.



STEVE:  Anyway, there is something that the Sysinternals guys, I know that Mark Russinovich added that feature that would map open ports back to the processes.  It turns out there was no solid way to do it under Windows 2000, so it took lots of reverse engineering and system hacking in order to do that.  But that's of course what Mark Russinovich was known for, and that's how he acquired his rep, and ultimately why Microsoft acquired him.  So anyway, I don't know the name of it.  But it's easy to find.  Just...



LEO:  If you Google Sysinternals, you'll go right to the site.  And I'm just trying - there's some process tools.  There's Proc Explorer, PsTools, PsFiles, see what files are opened remotely.  TCPView?  Is that it?



STEVE:  There you go, that's it.  TCPView.



LEO:  Active socket command-line viewer.  Oh, that's cool.  Look at that.  So that tells you what sockets are open, what's going on.  That's very cool.



STEVE:  It's very much like what Microsoft added to XP and Vista.  And I'm sure that Windows 2003 has it, too, because of course Windows 2003 is really just XP moved forward further.  I'm sure that's a feature they added to their stack.  But Windows 2000 doesn't have it.  So you need to use a tool like TCPView in order to do that.



LEO:  94 kilobytes, too, in the true Steve Gibson style.



STEVE:  Ah, very good.  Nice...



LEO:  Mark's good.  Mark's real good.  T.O. Galloway in Prince Frederick, Maryland wonders who's watching.  I just finished listening to Episode 152 of Security Now!.  Yeah, I'm behind.  Not that bad.



STEVE:  But not far.



LEO:  Not far.  You'll catch up.  And I got to thinking about the guy in South Africa that had the router admin sign-in that was open on port 80 of his router.  Oh, yeah, we talked about that.



STEVE:  And by the way, I never mentioned this, but other people have that, too.  So our asking people to use ShieldsUP! to check to make sure that port 80 was closed, a lot of people discovered that they've got bad UI in their routers.



LEO:  That's terrible.  T.O. says:  I have a couple of network security cameras that monitor my home.  I travel a lot.  It's nice to monitor what's going on while I'm gone.  But these cameras use port 80 to stream the video out.  By opening port 80 on the router, am I exposing my router's admin remote sign-in or anything else on my computer to the possibility of having it hacked?  Could I use some other oddball port, say something like 41 or 41,587 to stream the video out through and get the router's sign-in still hidden?  How high up do the port numbers go that are commonly used?  Thanks to both of you and Leo for the valuable information you provide.  It's necessary.  And thanks for SpinRite.  It's saved my bacon more than once.  And P.S. to Leo:  To kill two birds with one email, on a recent episode of The Tech Guy you made some recommendations for network cameras.  The ones I use are from 4XEM.  Oh, good.  Their quality, I think, equals or exceeds Axis, and the software they provide for free download is excellent, just for future reference.  I will check those out.  Thank you, T.O.  4XEM.  So port 80 is open because those little cameras are really web servers.



STEVE:  They are web servers.  However, okay, here's what's happening.  In order for him to be connecting through his router on port 80, he had to have set up port forwarding on his router, so that any incoming connection requests from his browser when he's out wandering around somewhere would be forwarded through his router and either go directly to his webcam hardware, if the cams themselves are network-enabled; or he's forwarding it to a computer, where he's got a bunch of these webcams hooked into USB ports on his computer and running the server software on a PC behind the router.



So there's two issues.  First of all, he's safe from his router's admin because by forwarding port 80 to something, to hardware, either his webcam hardware or to the PC, it's not having a chance to touch his router.  So that problem he need not concern himself with.  And in fact the solution that we suggested for people who find that their administrative interface on their router is open to the world is to forward port 80 to the twilight zone, send it off to some IP behind the router, 192.168.0.222 or something, send it to nowhere, and that ends up just essentially stealthing that port.  So that's a nice workaround for people who've discovered that their routers are not properly blocking incoming connection requests to the router on port 80.



However, it's worth also noting that he mentioned this 4XEM company and likes their software.  The vulnerability is that maybe their software has a problem.  And so basically you're running a web server which is listening for connection requests on port 80.  It's dicey.  I'm not saying, you know, to be overly concerned.  But you are - you're trusting a service which you are exposing to the Internet.  And the universal rule is hackers will find vulnerabilities in exposed services.



LEO:  That's true anywhere.  Anytime you're running a service of any kind, you're relying completely on whether that service is safe.  And look at this BIND service that we were just talking about, the DNS problem.



STEVE:  Right.



LEO:  Lot of people run their own DNS servers.  Well, when you're running a server, you have to trust the server software.  And if there's a problem, you're at risk.



STEVE:  Yeah.  And so the advantage of sticking with, like, IIS, although believe me it had its problems...



LEO:  But it's been banged on, anyway.



STEVE:  ...in the heyday.  Yes.  Yeah.  Or a big name - or like Apache, for example, that has just had all the dust beaten out of it.  The advantage of one of those mainline servers is you get all the benefit of the pounding on that it's had.  It's trivial to write a web server.  And so the concern is that they hired some random programmer off the street whose job was to get this thing working in the afternoon because they're going to ship it tomorrow...



LEO:  Now, we're not saying this is the case.  It's just the risk.



STEVE:  Exactly.  And but it's always the risk when you're dealing with any service that hasn't had the benefit of being seriously pounded on.  And, I mean, look at the troubles that real servers have, and imagine the challenge of just someone writing one in the afternoon and saying, oh, look, you can see yourself wherever you are.



LEO:  Now, Mark Thompson has written a little web server.  But I trust Mark.



STEVE:  I don't.



LEO:  You don't?



STEVE:  No.  I mean, he would never do anything malicious.  But it is just so...



LEO:  You might make a mistake, yeah.



STEVE:  It is so difficult to - you have to, I mean, literally every line of code you write has to be written with security in mind.  I mean, you really have to be challenging yourself step by step.  And frankly that's just not most people's orientation.  If you're in the security business, if that's where you live, that's how you think.  I mean, when I'm doing stuff for my site, that's all I'm thinking about.



LEO:  So what's the safest thing for him to do?



STEVE:  Okay.  What I would do if this were me, if I had to run unknown software, that is, whose fundamental security I couldn't vouch for, I would give it its own machine.  I would give it its own computer, not have it, like, talking to my main desktop.  And then I would isolate it to the best degree possible.  For example, maybe route it through - put it through its - put it behind its own router and map that port through so that basically it's in jail.  So the computer is essentially as isolated from the rest of your network as possible, so that if something, if there was a security problem there, and somebody did exploit a buffer overrun in order to install code, the code couldn't do anything.  It would be sitting there going, well, okay, what kind of a network is this?  There's nobody here.  There's nothing else on the machine, no valuable information on that machine, and no exposure of the rest of the network from that machine.



LEO:  Well, I guess it's something for us all to be aware of because more and more we're using these kinds of cameras and little devices on our system.



STEVE:  Oh, just wait till you plug your dishwasher or your refrigerator...



LEO:  I know, exactly.



STEVE:  ...into the network.



LEO:  We talk about that all the time, the refrigerator that calls home, you know, I'm out of milk.  Well, that's a server.



STEVE:  Yup.



LEO:  Oh, boy. Oh, boy.  All right, moving along to, let's see, our next question is from Henry Cocozzoli in Troy, Michigan.  He wants to make sure he doesn't have a Trojan.  If you live in Troy you should have a Trojan.



STEVE:  I'm glad you caught that, Leo.  Because I was chuckling to myself.  Okay, he's in Troy.



LEO:  As a long-time Security Now! listener and SpinRite customer I wanted to try your Wizmo - which is a great little tool that Steve gives away for free at GRC.com.  I was listening to Security Now! 151 at the time, but my Trend Micro Office Scan 8.0 Antivirus flags it as a virus.  It says "PAK_Generic.001."  I thought you'd like to know.  Oh, I bet he knows.  If you need more information, please let me know.  Keep up the great podcast.  Not the first time we've heard this, Steve.



STEVE:  No, and not the last, unfortunately.  There's a - generally what happens is this is certainly a false positive.  I'm very sure Wizmo has no viruses.  Nobody else has reported one.  So some little window of time goes by during which the increasingly annoyingly heuristic nature of AV products will say, oh, look, here's a byte sequence that might be bad because we found a similar byte sequence in something else that we know was bad.  So this is a virus.  Okay, well, it's not a virus.  It's just the problem is there are now so many viruses that there is, you know, a phenomenal number of signatures.  It's like a million a year new viruses, or a million total, I think it is, and three quarters of them in the last year.  It's just it's been an explosion of this.  And now of course the viruses are becoming more polymorphic than ever, so that they're deliberately trying to hide themselves, which means that in terms of this cat-and-mouse game the antivirus companies are having to, like, increase the generality of the windows that they use, these scanning windows.  And they're getting an increasing number of false positives.



So it's not just my stuff, it's everybody's stuff that is increasingly being accused of being infected when in fact it's just not.  And this will go away.  In another, you know, the next time Trend Micro updates their signatures, it'll go away because it never was the case.



LEO:  Right.  But I think you're right, I think we're going to see more and more of this.  Viruses use two techniques - or antiviruses use two techniques to find viruses.  The signature technique, where they're just dumb, they're just searching for a matching string that occurred in the virus, that can cause false positives.  That seems less likely.  But you mentioned heuristics, and that's where they try to be a little smarter and say is this virus-like activity or is this string kind of like the other string.



STEVE:  Well, yes, they try to be more general because for whatever reason a match doesn't work.  Now, my software in the past has had some false positives, even in signature matching, because I've been in the antimalware business, because I've, for example, been, like, in - I think it was like there was something I did with the RPC server where I was shutting that down.  Well, I had code that was working in a similar fashion to what the virus was doing, although I was doing it for benign and beneficial reasons, where the virus was doing it for malicious reason.  There actually was a valid signature match because we were sort of in the same area of the sandbox, essentially.  So those problems went away, too.  People - basically people will report those to the virus makers, and they'll go, oops, sorry.  And then they'll, like, tweak their signatures to narrow that or specifically put in a special case saying, okay, we know Steve's stuff is not malicious, so we're going to make sure we don't false positive on this.



LEO:  Well, anyway, nothing to worry about, I guess.



STEVE:  No.



LEO:  I guess you can kind of tell from the generic nature of the virus.



STEVE:  I was going to say...



LEO:  That clearly doesn't see a virus, it's just...



STEVE:  Even has it in the name, "PAK_Generic.001."



LEO:  That's basically saying, I don't know what it is, but it could be a virus.  It looks a little virus-like.  Danny  Richardson in Fremont, California wonders about whitelisting.  Hi, Steve.  I saw an article on CNET, thought it might make for an interesting discussion on Security Now!.  Briefly, it's a discussion on the future of antivirus software.



STEVE:  Well, what do you know.



LEO:  Well, there you go.  And how some companies are moving from a blacklist to a whitelist model.  What do you think?  Love the show.  What does that mean?



STEVE:  It's interesting.  Well, what's happening is that traditional - this is the virus companies' ultimate reaction to the fact that they're beginning to realize this is getting out of control.  That is, their existing model has always been find the badware.  Now they're beginning to think, okay, that's not working any longer because there's so much badware, there are so many tricks that the malware authors are performing, that we're having a hard time, even with everything we're doing, separating the malware from the good ware.  So now they're saying, okay, and this is especially true in a corporate environment.  We're going to flip it around.  We're going to specifically whitelist software that we're going to allow to run on the machines, and just assume anything not known to be good is bad.  Now, this is a problem, of course, for end users because look at all the software out there.



LEO:  That's pretty much everything is going to, yeah, I mean, that will limit what you can do very much.  Although I guess it might be ultimately the only way they can keep up.



STEVE:  You can see, you can imagine that in a corporate environment where there are inherently more restrictive policies, it makes sense.  I mean, you can imagine, in fact, corporate IT just saying, yeah yeah yeah yeah, let's go for whitelisting.  Because essentially it means anything not whitelisted will be absolutely blocked from running.  And then of course you've got to go to your IT guy with your tail between your legs and say, uh, why can't I run the Martha's Vineyard mapping application?



LEO:  We never heard of that.  You can't run it.



STEVE:  Exactly.



LEO:  It's too small.  We're not going to support that.  Yeah, that's too bad.



STEVE:  Yeah.  So I do see this happening.  And it's going to be rough for end users.  I don't think that model works in end-user cases.  I think - I know that lots of end users feel better having something there sifting through their data.  And every so often, I mean, if nothing else, a false positive or two lets them know their antivirus scanner is awake and paying attention.



LEO:  It did something, yay.



STEVE:  Hey, good, maybe it'll find the bad stuff next time.



LEO:  Bill Barnes in Charlotte, North Carolina worries about his provider's DNS service.  So what do I do if the report at DoxPara.com tells me I'm vulnerable?  Remember we talked last week about Dan Kaminsky's discovery that many DNS servers were flawed, and he set up a site, DoxPara.com, to test your DNS.  He says:  I manage several clients with different ISPs, and a number of them are not yet patched.  For most of them, Kaminsky's page displays a different DNS than is configured in my router or was given to me by the ISP.  I don't have any leverage with the ISP and certainly don't want to make a public show of the fact that they're putting me at risk.  At least my EarthLink DNS did get patched a couple of days after the first time I checked.



I have to say I did it as an experiment on the air, I gave people the URL of DoxPara.com - this is when the flaw was first announced, about a week and a half ago - and asked them to come into the chatroom and tell me.  And a surprisingly large number of ISPs were not patched at the time.



STEVE:  Yeah, it's going to be interesting to watch this.  I noted that when I went back and looked just this morning, Dan had put in a "don't panic" message.  I think what happened was his little DNS tester freaked out people because he was saying, yeah, you're vulnerable.  And they're like, aaaagggghh.  Now what?  And so it's like, okay, calm down.  Literally, like it says something like that, words to that effect.  It says - I'm sitting here, I've had it brought up here.  He says, "Do not be concerned at this time.  IT administrators have only recently been apprised of this issue and should have some time to safely evaluate and deploy a fix."



So, and I will tell our listeners the same thing.  This is, even at its worst, it is a highly targeted attack, and it's not like suddenly all of DNS 'Net-wide is going to be poisoned.  The idea is that it's possible to confuse a DNS server so that while its cached data is non-expired, it's routing your browser to a bad server.  Now, that's not a good thing.  That's why everybody in the industry is patching this.  But it does mean that it's sort of a focused attack.



Now, what you can imagine the bad guys doing, however, because I've been giving this some thought in preparation especially for next week's podcast, where we're going to really go into this and get our propellers wound up, is that it is very easy to discover servers that are not patched.  So as ISPs across the 'Net get their servers fixed, that will bring a heightened focus upon those ISPs that haven't gotten their DNS servers patched.  And you can expect a higher incidence of games being played against those servers.



So anyway, we'll be going into this in detail next week.  My advice for people who are truly concerned, I mean, I haven't done anything at my end.  On the other hand, I'm running a fully resolving server myself, so I'm not dependent upon anyone, like any ISP's DNS server.  You could certainly, however, as we said when we brought this up last week, is just aim your DNS at the OpenDNS servers, which have always been well designed and are spoof-proof as much as is possible.  So...



LEO:  Yeah, they do a good job.



STEVE:  Yeah.  Yeah.



LEO:  Nick Cody in Ipswich - that's in the U.K. - wonders why ZoneAlarm broke GRC, darn them:  Hi, Steve.  I'm a long-time listener to Security Now!, and I think I may have identified a slight problem for ZoneAlarm users like me trying to access your site, GRC.com.  I needed one of your fabulous passwords today, so I used IE7 to browse to www.GRC.com.  It looked like the site was loading, and then it stalled before ever getting to the main page.  I tried it a couple of times, and the same thing happened.  It could only get so far and never showed your main front page.  So I tried Firefox 3.  Same thing.  Always ended up hanging while trying to bring in something from GRCtech.com.  I wondered if it could be ZoneAlarm throwing a spanner in the works, so I looked at my privacy settings in ZA.  He's using v7.  Ad blocking was turned off, so it couldn't be that.  But cookie control was set halfway up at medium.  Turned cookie control all the way off, cleared my cache, restarted Firefox 3, tried again, and bingo, your site loaded straightaway.  I closed Firefox 3, cleared the cache, and used IE7 to navigate to GRC.  Again, right away, no problems.



I repeated the experiment a few times using both browsers.  There's no doubt I can't reach GRC.com when ZoneAlarm's cookie control is set to medium.  And this is where my concern lies because according to the settings, "medium" blocks third-party cookies and removes private header information, and you can't reach GRC.com unless these privacy features are disabled.  What's going on?  Surely there are no third-party cookies at GRC.com.  A quick mention of this issue might help those of us who use ZoneAlarm and want to look at your site.  All the best.  What's going on?



STEVE:  [Sighing].



LEO:  I have a feeling, because that GRCtech.com, that would be a third-party site, wouldn't it.



STEVE:  Exactly.  For the last two years, since I first deployed my third-party cookie testing technology, one of my servers, GRCtech.com, has deliberately been offering browsers cookies from non-GRC.com.  This is part of the system I am just on the verge of releasing publicly to notify people when their browsers have third-party cookies enabled.  There's a very cool page, Leo, if you take a look at it right now, go to GRC.com/cookies/stats.htm.  You'll get a kick out of the - there's a 3D bar chart there.  GRC.com/cookies/stats.htm.



LEO:  This is based on incoming stuff on your site?



STEVE:  This is, yes, this is the history of all of the GRC visitors in the last week.  And it shows a by-browser profile of which users, by browser, who's got third-party cookies disabled.  And it really shows the effect of Safari's disabling third-party cookies by default.  It's alone in the industry in doing so.  It also shows that our Linux visitors, who are using Gecko browsers rather than Firefox 2 or 3 for Windows, they're also very security and privacy...



LEO:  And Opera.



STEVE:  Yes, Opera has a lot of third-party cookies disabled.  Very cool stuff there.  So anyway...



LEO:  I'm surprised that 2 percent of Safari users have turned on third-party cookies.



STEVE:  I know.



LEO:  I don't know what that means.



STEVE:  I think that's exactly what's happened is they don't understand the implications of doing so.  But anyway, so what happened with - and I don't understand what ZoneAlarm is doing.  I mean, it seems onerous to entirely block a site which is...



LEO:  Just block the cookie.  You don't have to block the site.



STEVE:  Exactly.  It just, I mean, literally, no one can get to GRC.com after upgrading to ZoneAlarm 7.  It's been a serious problem.  And it's like, okay, I'm really glad I helped ZoneAlarm out in the old days.



LEO:  You mean that's the default setting?



STEVE:  Apparently, because it's zapping everybody.



LEO:  Oh, that's terrible.



STEVE:  Although the days of ZoneAlarm 2.6, which was the last one I ever used and liked, you know, those are long gone.  And ZoneAlarm has become a kitchen-sink product that I, you know, I'm not loading it.  But I'm going to have to run a copy to figure out what's going on one of these days.  Apparently it's also doing script page injection, which is another annoying thing.  It's modifying the pages you download.  I guess since it's your software, though, and not some third-party gunk at the ISP, that's very different.  But I'd like to know what it is that it's installing into my  browser pages.



LEO:  Wow, that's pretty serious stuff.



STEVE:  It's gotten pretty heavy-duty, yeah.  It's invasive.



LEO:  Okay.  Okay.  Samir Talwar in London, England - by the way, you could presumably say, instead of disabling the, you know, not use the medium setting, but say site-by-site, okay, allow third-party cookies here; right?  I presume that you could set it.



STEVE:  Oh, yeah.  Well, yes.  Apparently they're, I mean, I know that ZoneAlarm is aware of this because some users have called them, and I've seen reports from them saying that -  like them saying that they, like, whitelist GRC and GRCtech.  Apparently it doesn't work.



LEO:  Oh.



STEVE:  I know.  I don't know what's going on.



LEO:  Oh.  Samir Talwar in London, England does need third-party cookies:  Hi, Steve.  There's a reason for third-party cookies.  I'm not recommend that you enable them by default, just enable them one by one as you need them.  That is, in fact, what I do.  I have two set up:  RememberTheMilk.com, I use that, it's a very good to-do list manager; and Disqus.com.  I also use this.  This is the commenting system I use on my blog at Leoville.com.  So Samir must be reading my mind.



Both of these hook themselves into other sites, making third-party cookies necessary.  In the case of Remember The Milk, it has an iGoogle widget and a plug-in for Google Calendar; and Disqus loads itself into a lot of different blogs.  It's true.  Although I haven't noticed that.  Oh, that's interesting.  You would have a cookie from Disqus when you visit my blog.  That's where the comments live.  Again, not saying they're definitely a good thing, but they're not always bad, either.  Oh, and one more thing, why don't browsers treat JavaScript loaded from external sites as third-party code, thus making any cookie access appear to be from that site?  Oh, that's an interesting question.



STEVE:  Yeah, I thought that was a great point, too.  Okay.  So it is certainly the case that with Web - what are we up to now, 7.9 or something?  We're beyond Web 2.0; right?



LEO:  I think so, somewhere out there.



STEVE:  There are beginning to be valid uses for third-party cookies.  The so-called "mashups" where you're running somebody else's site's code in, like, an IFrame or in some sort of a window in some other site.  Or like Remember The Milk.  It makes sense.  And so wholesale disabling of third-party cookies I think still probably works for most people.  But if there were something like, exactly like Samir suggests, like RememberTheMilk.com, where there's a reason for your - you know, you're cookie and privacy conscious.  In general you want to deny third-party cookies.  Most browsers allow you to whitelist cookies by site and allow RememberTheMilk.com and whatever site, you know, whatever site you know you need third parties enabled.  Normally you don't because you only need to exchange cookies with the site you're currently visiting, not sites you're not visiting.  And that's of course what we mean when we say "third party."  And we'll be getting into all of this in really interesting, painful detail not long from now.  But anyway, so I did want to acknowledge the fact that not all third-party cookies are bad.  And sometimes they really do have a use.



LEO:  Yeah.  In fact, I use them, apparently.  Michael Tiller in Canton, Michigan loves his YubiKey.  But Steve, he says, I got a YubiKey to play with.  I agree the concept's quite nifty.  But I think there is one thing that makes it impractical, and that is the fact that it uses a symmetric encryption scheme.  The key issue here - pardon the pun - is that for somebody to be able to verify your identity, they must implicitly have the ability to steal.  In other words, they'd be able to fake your credentials.  It seems to me that the killer version of this device is one with asymmetric encryption.  That way I could give out a public credential and use my YubiKey to prove, using a private credential, that I am the same person.  This issue came up in the YubiKey forum, and it seems like the summary here is that asymmetric encryption would require more sophisticated, read more expensive, hardware, and that it would require far more information to be communicated in order to be practical.  We've talked a little bit about this before; right?



STEVE:  Yeah.  I completely agree with Michael.  So what he's saying is that - and this is, I mean, this is an issue with the YubiKey.  We've talked about it with this notion of acquiring the private, the secret symmetric key from YubiKey.  You could write to them and say I want my YubiKey's secret code because I want to provide it to somebody else to authenticate, I want to be able to authenticate it myself, or whatever.  In the process of doing so, and liberating it from them, then you're responsible for it.  And anybody else who got it could fake your credential.  So the problem is asymmetric encryption is not just a little bit more time-consuming or difficult or number-crunching intensive.  I mean, it is so much more than symmetric key as to be in an entirely 'nother order of magnitude.  I mean, there are SSL accelerator hardware add-ons for servers that offload that SSL setup process because there is such a burden.



Now, I've talked about how it's much less today than it used to be because CPUs are so much more powerful.  I mean, you know, a lot of the connections to GRC are SSL.  I force an SSL connection to anyone starting to use ShieldsUP! because I want to avoid ISP transparent proxies that we've discussed before in order to get a direct connection to the user's machine so I can obtain their actual IP address.  But, you know, and so I'm not using any hardware acceleration.  And that's - it's fast enough.  But the point is that there's a little tiny little processor on the YubiKey that is easily able to do standard symmetric Rijndael AES encryption.  Rijndael was designed, in fact, with hardware implementation in mind.  It was designed so it's very simple to implement in hardware or in a little firmware-programmed chip of some kind, which is what I presume is in the YubiKey.



But to do full asymmetric, public key-style encryption is dramatically more compute intensive.  And when you really think about it, it's not exactly clear how that would work because you would - you probably need bidirectional communication.  I haven't sat down and thought this all the way through.  But the YubiKey, one of the things that's so cool about it is it just pretends to be a keyboard.  You don't need to give it something and have it encrypt it in order to prove that it is what it is.  It maintains its own internal state and merely increments that in order to, well, I guess it could, as I think about it, it could simply use its private key to encrypt that state and send that out.  It would be a lot larger.  It would be a lot larger.  It would be the length of the modulus of the public key.  So that would be a longer string to type.  And then you ought to be able to use the public key in order to decrypt what it encrypted.  Of course that would give you access to the encrypted contents, which might be a problem.  Anyway, it would work...



LEO:  It's not a simple thing.



STEVE:  It's not a simple thing.  But more than anything you would press the button and probably have to come back tomorrow in order to get your results from it.



LEO:  And that's why PGP uses a symmetric key initially, doesn't it?



STEVE:  Well, it's why any of these systems...



LEO:  SSL uses symmetric keys.



STEVE:  Yeah, well, any of these systems do not encrypt the bulk payload.  What they do is they generate a random number, a big random number.  That's the symmetric key.  Then that's the only thing they encrypt using the asymmetric encryption is they encrypt the symmetric key.  That's what they send.  And then using the other side of the asymmetric cipher, they decrypt with the other half of the asymmetric key that gives them the symmetric key.  And then you decrypt the whole bulk payload.  And now we're all confused.



LEO:  What he said.



STEVE:  Yes.



LEO:  Jez Goldstone in Manchester, U.K., has been thinking about the Phorm browser dance.  Talked about it extensively last week and a couple of weeks ago.  Steve, I really don't want to give these nasty guys any ideas.  But your recent discussions about Phorm have centered around how they bounce a user's browser around to set a cookie for profile purposes.  Since they can see the IP address of any request, the ISP can simply tell them which unique subscriber has that IP address at any given time.  They can then associate the current IP address with their unique reference and know who's sending the request and what profile to use.  They can then inject a cookie into the requested page between the user sending the request and it being passed on to the required destination.  They could then pick it up using their advertising service on a third-party site that they're providing advertising for, in your example CNET.com.  There would be no way to take anti-Phorm measures apart from using TOR or JAP or some other SSL anonymizing service.  I know that this approach does not work for multiple users behind a common NAT router, but then neither does the cookie-based approach when multiple users share the same log-in account, for instance within a household.  Did I miss anything?



So he's saying the ISP says match this Internet address to this unique subscriber, associate that address with a cookie reference, and then you'll know who's sending the request, what profile to use, and then inject the cookie.  It's complicated.



STEVE:  Yes.



LEO:  Does it work?



STEVE:  Well, it works.  Bu the thing he missed, if you can put it that way, is that requires clear collusion between the third party and the ISP.



LEO:  In every case the ISP is saying we're not revealing personal information.



STEVE:  Yes.  And even so, everyone is up in arms about Phorm and NebuAd and their ilk of these third parties where they - I mean, and I have to say, I mean, the Phorm folks, I can't really say that one way or the other about the NebuAd people.  But certainly the Phorm folks, because I've gone through their technology, they go to extreme measures to anonymize the data.  You know, that's not satisfying people.  They still don't like the idea that they're being profiled, even in that fashion.  But at least, I mean, Phorm can argue, look, we really have a hands-off approach.  Sure, we're sniffing and modifying the ISP's data stream.  But we're doing it in a completely hands-off fashion.  We're getting no account information from the ISP, and we are completely independent of IP.  So I think, if somebody actually could tap into the ISP's database and say who's currently the customer on this IP, oh, boy, I mean, that...



LEO:  Well, yeah.



STEVE:  You'd just go down in flames.



LEO:  Right.  So in other words, they've thought of this.  They know they can do this.  They're just...



STEVE:  They'd love to be able to do that, but they dare not.



LEO:  They dare not.



STEVE:  And even so they're in deep doodoo.  



LEO:  Yeah, exactly.  All right, Steverino.  Are you ready, my friend?



STEVE:  The final two.



LEO:  The final two questions.  And they're good 'uns.  Steve's given them special awards, awards of special merit.  First, Pat Kugel in London, Ontario with the Sad and Disturbing Truth of the Week:  Hi, Steve.  I've been listening to the podcasts over the past several weeks and thought I'd pass along a little information from Canada.  One of the two primary service providers in Canada is Bell Canada.  They provide a PPPoE-based carrier service - notice this is not an ISP service; that would be Sympatico - for a large number of smaller ISPs.  So they're basically the carrier, and then there's an ISP on top of it.  They're being sued by a Quebec organization in addition to being audited by the CRTC - that's the Canadian FCC - due to their installation of DPI, Deep Packet Inspection servers.  Their intent, to deep scan all PPPoE packets so they could target advertising and block websites they don't agree with.



Under CRTC regulations, this is illegal as the PPoE packets are considered private, and as a carrier Bell Canada does not have the legal right to open the contained packet.  They're only allowed to examine the PPPoE wrapper for a destination.  I've been reading and hearing that this kind of thing is happening more and more by ISPs and by carriers.  If memory serves me, wasn't Comcast just given a warning by the FCC for the same thing?  As a netizen I'm concerned that we're slowly losing the 'Net Neutrality war.  Are we sacrificing too much in the name of profits and advertising?  Or am I just being paranoid?



STEVE:  That is the sad and disturbing truth of the week.



LEO:  They're all doing it.



STEVE:  I know.  It is really becoming distressing.  I mean, I think that Pat expressed this perfectly.  And that is that a common carrier is - they have obligations under the law.  They're certainly not able to spy on the data that they're passing and essentially censor it based on its content.



LEO:  It'd be like listening to your phone calls and saying, oh, no, you can't call that person.



STEVE:  Yeah, we don't like what you said.



LEO:  No, no, no, sorry.



STEVE:  No.  And unfortunately the technology is here, this Deep Packet Inspection, basically DPI, it was nice when it just meant Dots Per Inch instead of Deep Packet Inspection.  Unfortunately, I'm afraid that DPI is ending up being renamed because unfortunately, as the cost of doing this has come down, as processing power has gone up and networking has matured, it becomes virtually inexpensive for this kind - for carriers to examine, deeply examine the traffic that they're carrying.  And, I mean, this is like sort of the next level of problem from the Phorm and NebuAd type companies.  Here Bell Canada themselves are doing this.



LEO:  It actually seems to happen a lot in Canada.  In fact,  Sandvine, which is the service that Comcast uses for DPI, is a Canadian company, I think from that area, I think from London, Ontario, as a matter of fact.



STEVE:  Yeah.



LEO:  "Jake" - I put that in quotes - writing from some time in the future, wins the Creative Writing Award of the Week.  Subject:  A Big Thank You from the Future.  Dear Steve and Leo:  Since back in 2003 I've been working on a time machine - for 10 years.  I was so buried in my work that I didn't pay much attention to issues like hard drive health until recently.  With the current state of electronic security in 2013, I came upon Security Now!, which is really now Security Then!.  And I listen to it for the nostalgia of the good old days when security was comprehensible.



One day my computer came to a halt.  With all of my data and designs at risk, I immediately bought a copy of SpinRite 7, and in hours I had recovered my data.  By the way, v7 makes great toast.  SpinRite allowed me to complete my time machine, so I took my first trip back to 2008 just to thank you.  Keep up the good work.  You're our only hope, Obi-Wan Kenobi.  Best regards, Jake.  P.S.: Please visit us in 2013 for a demo of my perpetual motion machine.  But don't count on free energy.  That's a pipe dream.  Very cute.  Very cute.



STEVE:  So I got a kick out of that.



LEO:  I love that.



STEVE:  Ever since 2003, for the last 10 years, he's been working on his time machine.  And of course we do not have SpinRite 7 yet, folks.  We're selling SpinRite 6.



LEO:  You're going to get emails now, people saying where's SpinRite 7?  I want it.



STEVE:  I know, what Jake talked about.  Well, okay, Jake is from 2013, and he traveled five years back in time to 2008.  So we just want to let you know, SpinRite 7 apparently makes great toast.  I didn't have it on my list of things to add.



LEO:  Now you do.



STEVE:  Don't have that at my update.  But, you know, I'm not arguing with Jake.  Apparently he knows more about SpinRite 7 than I do at this point.



LEO:  Toast is good stuff.



STEVE:  There you go.



LEO:  Oh, Steve, it's been fun.  It's been a great 12 questions, as always.  How can people send you questions or suggestions?



STEVE:  GRC.com/feedback.  And thanks to you, Leo, they need add no extension to the end of that.



LEO:  No .htm.



STEVE:  And no wwwwwwwww on the front.  Just GRC.com/feedback.  435 people sent me their questions and comments and notes and things in the last two weeks.  So I really appreciate those.  I just have such fun plowing through them and finding 12 to share with our listeners.  So by all means keep them coming.



LEO:  Thank you for doing that.  And by the way, if you want to go to GRC.com for other reasons, there's lots there.  Wizmo...



STEVE:  And more coming, too.



LEO:  More, something neat Steve's working on.  But ShieldsUP! is there, and of course don't forget SpinRite, the world's finest disk maintenance and recovery utility.  It's all at GRC.com, along with 16KB versions of the show, transcripts, show notes, it's all there.  GRC.com.  Steve, thanks a lot.  That was a great batch of questions, some fascinating stuff.  Next week what's on the agenda?



STEVE:  Another great 90 minutes spent with you, Leo.



LEO:  Yes, sir.



STEVE:  Next week I will say again to our listeners who do have propeller-head beanie caps, this is going to be one of our great techie episodes.  We're going to delve into, in detail - and this is, I mean, again, everybody's going to understand this.  I promise you, no matter how much of a neophyte our listeners consider themselves, they're going to understand how DNS protocol works at the level required to spoof your own ISP's server if they haven't patched by that time.



LEO:  Okay.  Strap on your pseudorandom number generators and head into the future.  We'll be back in a week.



STEVE:  Strap on your pseudorandom number generator?  That's right.



LEO:  Put that right on.



STEVE:  Make a few passwords, while you're at it.



LEO:  Steve, we'll talk again next Thursday on Security Now!.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/

        

SERIES:		Security Now!

EPISODE:	#155

DATE:		July 31, 2008

TITLE:		BailiWicked Domain Attack

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-155.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the deeply technical and functional aspects of DNS, with a view toward explaining exactly how the recently discovered new DNS cache poisoning attacks are able to cause users' browsers to be undetectably redirected to malicious phishing sites.



INTRO:  Netcasts you love, from people you trust.  This is TWiT.



LEO LAPORTE:  Bandwidth for Security Now! is provided by AOL Radio at AOL.com/podcasting.



This is Security Now! with Steve Gibson, Episode 155 for July 31, 2008:  How DNS Works.  This show is brought to you by listeners like you and your contributions.  We couldn't do it without you.  Thanks so much.



Time for Security Now!, Episode 155.  We're talking about security, protecting yourself on the Internet, learning how the Internet works, a lot of great topics with a guy who certainly knows this subject inside and out, Mr. Steve Gibson, the guy who coined the term "spyware" first, first guy to discover spyware, has made so many great security utilities on his website, GRC.com.  And of course best known, well, I don't know what best known is, Steve, but certainly well known for SpinRite, his hard drive maintenance utility.  But also you got well known, I think I first became aware of you with your InfoWorld column.



STEVE GIBSON:  Yep, I think that was probably early on.  Actually it was fun, it was for the promotion of SpinRite that I approached InfoWorld.  And I said, hey, would you be willing to trade an ad for a column?  And they were like, uh, who are you?  I somehow talked them into it.  And so we just did a trade-out deal.  I didn't need any other compensation, but just having a chunk of space to let the world know about SpinRite was my goal.  And of course the column ended up really taking off.  I wrote it every week for eight years.



LEO:  I loved it.  I was so sad when you quit.



STEVE:  Well, it just, you know, I did it for eight years, and I pretty much said all I had to say.  And I was getting busy with other stuff.



LEO:  Sure, sure.



STEVE:  And so it was like - and frankly, I remember, too, as you probably remember, the magazine really began to change, not for the better.



LEO:  Well, it became a business magazine instead of...



STEVE:  The techie magazine.



LEO:  It was the journal of record for Silicon Valley.  Between you and Dvorak, those were...



STEVE:  And Cringely.



LEO:  And Cringely.  You had to read that magazine every week.  And I did, and I loved it.  But then it became really more like a business magazine, and I became much less interested in it.  And of course it faded away as a result.



STEVE:  Uh-huh.



LEO:  What was the name of your column?



STEVE:  It was TechTalk.



LEO:  TechTalk.



STEVE:  Yeah, I originally named it Behind the Screens.



LEO:  I like that.



STEVE:  I did, too, except that it turns out that CompuServe made a trademark claim to having Behind the Screens.  And it's like, okay, fine.  So I got a call from InfoWorld.  They said, okay, Steve, you've got to rename your column.  And it was like, uh, well, okay, TechTalk.



LEO:  Yeah, that's a good one.



STEVE:  It flew forward as TechTalk for eight years, and it was a lot of fun doing it.



LEO:  What are we going to talk about - speaking of tech talk - what are we going to talk about today, Steve?



STEVE:  Well, our plans have changed a little bit from the last two weeks we've been talking about what we're going to talk about today because essentially what is probably all of the information that we were going to embargo for two weeks until after Dan Kaminsky had officially released it during his planned-for talk on August 6 during the Black Hat conference in Las Vegas, all of the information has made it out into the Internet.  So it's no longer necessary to embargo it.



And we're going to talk about, first of all, how DNS works to create a real good foundation for understanding how it is that it is possible to exploit it, essentially what it is that Kaminsky realized early this year.  It isn't a bug.  It wasn't a defect.  That is, it wasn't, like, coded wrong, which is why it affected Microsoft DNS and the main BIND issue.  DNS essentially Internet-wide turns out to be more readily exploitable than was believed before.  DNS spoofing is not new, but this is basically a new, really more potent type of attack.  So we're going to really explain - and I've never done it in our nearly three years of the podcast, we've never really focused on DNS.  So I want to lay down a nice foundation of understanding, which is why people need to get their propeller-head caps going.  And then we'll talk about, because we'll understand how DNS works, we'll be able to talk about what it is that makes it vulnerable and what the vulnerability is.



LEO:  Yeah.  I'm surprised we've never covered how DNS works.  That seems like a - because early on in the show - and I highly recommend people go back and listen.  All of the episodes are available from Steve's site, GRC.com, or on TWiT.tv.  We covered really a lot of the fundamental technologies of the Internet.



STEVE:  Yeah.  I referred to name servers and DNS spoofing and man-in-the-middle attacks.  And we've sort of - we've talked about it tangentially, or maybe it's circumferentially, I'm not really sure.  But radially.  But we've never really just said, okay, let's nail this down.  And interestingly, it is not a very well understood technology.  We all sort of - people know, oh, well, I've got DNS servers somewhere.  I point my computer at them.  And of course we've talked about OpenDNS on several occasions when DNS issues arose.  But we've never really explained in detail how it works.  And there are - as always, it's in the details that this attack functions.  So we're going to explain it all the way, completely.



LEO:  So what's going on in security news?  Besides this Dan Kaminsky story has been just dominating the headlines for three weeks now.



STEVE:  Well, yes, it has.  And essentially the news there, because there's a little bit of news, I alluded to before.  And that is that essentially, as is so often the case, when you know that there's a problem, you're much more likely to go and see if you can figure it out than if you don't know there's a problem.  And when I started thinking about, okay, if I were to test for this problem for visitors who come to GRC, how would I induce their name server to generate a bunch of queries so that I could see what it was doing in order to measure its randomness?  And it turns out that that's one of the ways, that's one of the components of this attack.  So what happened was, over the course of the last couple weeks, unfortunately for maybe for some people who get caught by this, which essentially is going to be like a major phishing trap, unfortunately a lot of people in the industry began speculating.  And some people started guessing and posted their guesses on blogs.  And other people said, no, no, it won't work because of that, but this would.  And what happened was basically...



LEO:  People figured it out.



STEVE:  Figured it out.  It ended up being figured out.  And then finally one security researcher made a guess, and then somebody who was actually in the loop, who had been told directly by Dan what the problem was, confirmed it.



LEO:  So Dan wasn't going to say anything until Black Hat, which is next week, right, or the week after.



STEVE:  Yeah.  It's next week.  And then our original plan was to have him on the following week, and just as our guest, to hear it from him.  But basically, unfortunately, his talk has probably been preempted.  Now, it's worth noting, though...



LEO:  Oh, he'll still talk, and still give it the full treatment, I'm sure.



STEVE:  Oh, well, yes.  But it's worth noting that we don't know that we've figured out, we the industry have figured it out.  There could still be something else.  What is known is that something new has been found and is being exploited.  And there are now exploit tools for this.



LEO:  Right.



STEVE:  Anyway, so there's that.  But I did want to mention two things.  And this, of course, is the big security news.  And blessedly, there wasn't much else that went wrong in the last week...



LEO:  Hallelujah, yeah.



STEVE:  ...since we last talked.  Yeah.  Except that another problem was discovered in Mozilla-derived browsers.  There's a memory corruption bug which was already fixed by the most recent release.  But it's a more serious problem than the reason we went to, in the case of Firefox 3, to v3.0.1, and in the case of Firefox 2 to 2.0.0.16.  So I wanted to reinforce in our listeners' minds, I said this last week because there were other things that those were fixing.  But a more serious problem came out.  So I just wanted to make sure that our listeners who are using Firefox had brought themselves up to date because there are some other things that ended up being fixed sort of in the process that have since been found to be wrong with the down version versions.



LEO:  Excellent, okay.



STEVE:  And my only other news is I got a really interesting SpinRite story from one of our listeners, Alain Donais.  He said, "I bought SpinRite recently, and talk about great timing."  He said, "Right after I bought it, my parents called me because their computer won't boot.  And since it's still under warranty they brought it to the store's technician, where he told them that the hard drive was done," as Alain says.



LEO:  Done.



STEVE:  It's done.  Oh, it's done.



LEO:  It's cooked.



STEVE:  And it had to be replaced.  "This was a big problem as they had no backup of their photos and other important data.  So I told them to bring the computer over, and I ran SpinRite.  After several hours the computer was working as new.  The tech at the store was extremely surprised to know that I had fixed my parents' hard drive.  The next day, and I kid you not, when I get home from work, my co-tenant informs me that his computer's power supply died, and after replacing it the computer won't boot.  So I take out SpinRite, and after several hours another hard drive fixed.  And finally, recently, my brother had to replace his computer..."



LEO:  No.  Wow.



STEVE:  "...because his very old computer was dying on him.  And after putting his old hard drive in the new computer to transfer the data, the drive is unreadable.  And once more, SpinRite to the rescue.  So as you can easily figure out by now, this was one of the best investments of my money ever.  Thanks, Steve, for writing such a useful and efficient software."  Signed, Alain.



LEO:  That's really neat.  I actually have a SpinRite-didn't-work-for-me story, as you know.  But it wasn't - one thing I think we - I try to make this clear is that SpinRite is for a particular category of problems.  But there are other kinds of hard drive problems.  For instance, if it's a file system problem, your partition table got mucked up, then SpinRite won't help.  It helps with bad sectors, right, I mean, that's really...



STEVE:  Well, it also helps, for example, many times we've read testimonials where people say that their machine is in an infinite reboot loop.



LEO:  Right.



STEVE:  Well, it's probably, I mean, it's a sector-level problem, but so the sector is being read incorrectly or not at all, and so that's causing SpinRite to keep from booting.  So that is a file - it's in the file system, so it's a file system problem.  But in your case, Leo, I mean, it just stopped being a drive.  It became a doorstop.



LEO:  Exactly.  We use a very cool device called the TriCaster for the video, the TWiT Live video stream.  And it allows me - it's basically a video control room in an XP box, the size of a Shuttle PC.  And, you know, it allows me to switch cameras to put CGs up, record video, playback video.  And it's really great.  But it's a computer, and the hard drive - we're in the middle of recording, and blue screen.  And so I tried to reboot it, and it said no operating system.  And so I knew immediately it's a hard drive; right?  And of course I knew immediately what to do.  I pulled it out, put it - because this doesn't have, which is a little frustrating, doesn't have optical drives.  There's no room for them.  So I had to put it in another machine so I could boot into SpinRite.  An interesting thing happened.  And I was curious as to what your take on this was.  The BIOS says, yeah, there's a drive there, gives me the correct ID number.  But the BIOS says 0.0GB drive.



STEVE:  Yeah, that's an indication that the drive isn't even online.  I mean, it's responding to some commands.  But there's a low-level fundamental command that says tell me about yourself.  And if the drive is unable to do that, as you suspect, it's probably the circuit board on the drive, not the actual magnetic media on the drive.



LEO:  Yeah, because I don't hear any noise coming out of the drive.  It's spinning up fine, you know, it sounds like it's acting normally.  You know, I'm used to bad sounds, so like access sounds [vocalizing], none of that.



STEVE:  Can you hear it, like, loading the heads?  Like, is there like some fluttery sound in the beginning?



LEO:  Yeah, at the beginning, [vocalizing], yeah.  And so it spins up.  I hear the heads, well, actually, you know, that's a good question.



STEVE:  Because it might just spin up, and the heads never even...



LEO:  I think it's just spinning up.  The heads never start moving, I think.  I'll have to listen.



STEVE:  It sounds to me like the little motherboard or the daughterboard, some child sibling board on the bottom of the drive is just, well, and you've only had it for, what, maybe a month?



LEO:  Yeah, couple of months.  And it just failed.



STEVE:  So it's probably classic instant mortality, where one of the electronic components on the board just gave up.  It passed all the QA, it got through manufacturing, it made it through the TriCaster folks.  But there was still some fundamental weakness that finally manifested itself.  And that's an example of something that, I mean, nothing can fix except somebody like a DriveSavers, who would have an identical drive and would be able to, like, pull the board from it and then swap it onto yours.



LEO:  Yeah, that's what they do, they actually put a new circuit board on.  That would be the first thing.  If I had a circuit board, if I had a matching drive and I had the circuit board, I'd try that immediately because that's sure what it looks like.  And of course if the machine can't access the drive, SpinRite can't, either.  SpinRite's not magic.  If there's no physical drive to see, it can't do anything.  So I immediately booted SpinRite, and it didn't see a drive.



STEVE:  Yeah.  And the good news is that we all know how much more reliable solid state stuff is than magnetic state stuff.  So I don't think I've ever, maybe once or twice in 20 years I've seen an instance where a hard drive's daughterboard died.  Typically it's not that.  It's sector problems, and of course that's what SpinRite is made to fix.  So normally it can help.



LEO:  So the good news is NewTek, which makes the TriCaster, immediately sent a new drive because we're just going to swap it out.  And this, you know, and people got mad at me.  They said, Leo, you always say back up.  Well, I was backing up.  And we didn't lose any data.  We backed up all our videos except for the one video we were making while we - when the drive died.



STEVE:  That was actually in, yeah, exactly, in there, in the can.



LEO:  And I might bring it to DriveSavers just to get that video back, or just for fun to see if they can, see what was really wrong.  But what I didn't do, and I should have done, is made an exact copy of that drive so we could just swap another drive in.  And that's what I will do this time.  I'll just...



STEVE:  Well, and you probably thought you had a little more time before it became critical, too.  I mean, this did catch you off guard. 



LEO:  It did.



STEVE:  It was still brand new.



LEO:  Yeah, and we had planned to.  I had told Colleen, by the way, let's make an image of this drive and keep it safe so that we can restore if the drive dies.  In this case I don't think I want an image.  Actually your consultation on this would be also useful.  I don't think I want an image because I don't want to restore an image.  What if - if this happens again, the drive's dead, what I really want, I think, is to be able to pull that drive out and put an identical one in and just get going again immediately; right?



STEVE:  Right.  So you want to make a clone.



LEO:  A clone.



STEVE:  An exact, bit-for-bit duplicate, you know, partition table, partition sectors.  And being that this is like a proprietary drive from inside of a device, they might very well have some anti-copy-protection stuff.  I don't...



LEO:  Exactly.  I don't know what's on it.  Yeah, we don't know.  So that's why I think a bit-for-bit copy is what I want to do.



STEVE:  Yup.



LEO:  Yeah, okay.  And I'm going to try - there are various applications that'll do this.  My instinct is to try one of these free ones that all the drive manufacturers - I have an Hitachi that I'm going to make a duplicate on.  And I think all the drive manufacturers offer these bit copiers, you know, like the Max Tools and stuff, so that when you buy a new drive you can just take the old drive and make an exact copy and then put the new drive in.



STEVE:  Yeah, they're wanting to promote your migration upward to an ever-bigger drive.



LEO:  Precisely.  I'll have to see if Hitachi - is Hitachi an okay - I got a deal on it.



STEVE:  As a matter of fact, I was talking about the big monster machine that I recently built, the quad core with the - I think I've got five 1TB drives in a RAID.  I chose Hitachi drives.



LEO:  Oh, really.



STEVE:  I think they are absolutely among the best.



LEO:  Oh, excellent.  



STEVE:  I feel very good about Hitachi.



LEO:  Patrick Norton tweeted on Twitter than Newegg was selling 750GB drives for $119 plus an instant $20 rebate for a hundred bucks, for 750GB.  So I bought two.  And there was a choice between Seagate and Hitachi.  And I love Seagates; I've used Seagates for years.  But the Hitachi had a bigger onboard cache and, it looked like, better sustained throughput.  And I thought, well, I'll take a chance.  So that's good to know that it wasn't a mistake.



STEVE:  Yeah.  And the cache is important also for, you know, you're doing heavy bandwidth media stuff.



LEO:  Exactly, exactly.  Yeah, this is a great, I mean, these are amazing how cheap these drives are.



STEVE:  Incredible.



LEO:  But because they're so big, I'm with you, I'm a little nervous.  I'm going to make a clone.  I'm going to have a couple of clones just in case.



STEVE:  Here come the clones.



LEO:  All right, I'm prepared now.  I've got, you know, I think a lot of times when you talk I like to jot down notes.  So I've got my notepad in front of me.



STEVE:  Okay.



LEO:  And we're going to talk about DNS.



STEVE:  Okay.  So back before DNS, the way the Internet - whoa, we're having an earthquake.  Oh, a big one.



LEO:  Oh, he's shaking.  Oh, you're really shaking.



STEVE:  Goodness.



LEO:  Hold on, Steve.  Hold on.  I'm watching the books behind you.  They look like they're okay.  But you're getting quite a temblor there.



STEVE:  Wow.



LEO:  That was a big shaker.



STEVE:  That was an earthquake.



LEO:  Holy cow.  Wow.  Steve's in Irvine, California.  



STEVE:  Yes.  On the San Andreas fault line.



LEO:  Are you?



STEVE:  No, no, no.  But it's, wow, it's still going on.



LEO:  Wow.



STEVE:  Somewhere there was a big earthquake, probably not that far from here.  But this was more roll-y than jerky.  And the closer you get, the more abrupt and sharp it feels.



LEO:  That's right.  So you know this is maybe a little bit distant.



STEVE:  Wow.  That was...



LEO:  You know, I've only had one other live earthquake.  We had it on the...



STEVE:  Sorry, folks.



LEO:  No, don't apologize.  That's amazing.  We were doing The Screensavers, and I'm talking along and oblivious.  And Kate says, "Did you feel that?"  And I said, "What?"  "We just had an earthquake."  And I had no idea.  But this one I could tell.  We could hear it.  We could hear it rattling.



STEVE:  Yeah, well, all sorts of stuff fell over all over the place, too.  I've got to do a little cleaning up now.



LEO:  Do you want to pause?



STEVE:  Oh, no, no, I'm fine.  Yeah, that was - I'm in California.  We're used to earthquakes.



LEO:  Holy cow.  That's a first.  That is a first.  By the way, up here in Northern California - I'm about 500 miles away from Steve - we didn't feel a thing.  So it is something probably centered down there in Southern California. 



STEVE:  Probably out in the desert is normally where they are.  So I imagine you'll have some people in the blog checking the earthquake log, and we'll know before our podcast is done how big it was and where it was, so.



LEO:  Pasadena had some.  Dogs are going crazy in Hesperia.  So, yeah, Apple Valley five seconds after Steve said something; felt it in San Diego six seconds later.  It was probably pretty close to where you are, actually.



STEVE:  Yeah, it was - it's the biggest earthquake we've had in maybe five years.



LEO:  Big shake in Fontana.  Yeah.  I could see it.



STEVE:  Things have been quiet actually.  So I'm glad to have a little stress relief because you don't want to let them build up too much.



LEO:  You're right, much better to have something like you just had.



STEVE:  Lots of little ones, yeah.



LEO:  Yeah.  Wow.



STEVE:  Okay.



LEO:  Back to DNS.



STEVE:  So once upon a time there was actually a single hosts.txt file which maintained the machine names of everything on the Internet.  It was one file.  It was maintained by the original Internet authority, NIC.  And they would maintain it, and they had it on an FTP server.  And every...



LEO:  No, wait a minute.  You're kidding me.



STEVE:  I'm not kidding you.



LEO:  So it was automatic?  I mean, wasn't automatic, you would actually FTP the tables?



STEVE:  Yes.  Whenever - periodically other people on the Internet would FTP the master, single master hosts.txt file to their machines, and that was the only way their machines had of converting names to IP addresses.  And of course, needless to say, that became rather unwieldy after a while as changes began happening more often, as the single master hosts file for the Internet became extremely large.



LEO:  So people were running locally the software that would do the lookup, and they would download the tables kind of at will.



STEVE:  Well, there wasn't even software that would do the lookup.  It's like our hosts files that you and I talk about all the time?  It's on their computer.  And so their email, their web browser, well, even before, their gopher client,  their IRC or their Usenet newsreader, those would look in the hosts file.  Actually the hosts file is supported by the so-called "sockets layer" in UNIX.  So there were low-level commands that were sort of an API in the networking stack, where you could say look up the address, the IP address of this machine.  And all it would do is look in your hosts file.  There was nothing like DNS.



LEO:  So but that's interesting because that's really where the hosts file came from.



STEVE:  That's its origin, exactly.



LEO:  I just want to - just let me break in.  CNN is now showing pictures of a smoggy Los Angeles and saying there's an earthquake.  The U.S. Geological Survey is reporting a 5.8.



STEVE:  Wow.



LEO:  Which is a fairly serious earthquake.  They're saying it's roughly the Chino Hills.  But you're pretty close to it.  And it is Greater Los Angeles.  Now, given the size of that and the fact that it is an urban area, I imagine we will start hearing some damage reports soon.  But just to give you an update on that.



STEVE:  Yeah, cool, neat.  Okay.



LEO:  Not so neat if you're in a building that fell over.



STEVE:  Yeah, not if you're near Chino Hills.



LEO:  You know what's impressive is the Internet's rock solid.  Skype was rock solid.  You were shaking, but everything else was fine.  Video looked good.  Few books fell off the shelf, but that's it.



STEVE:  Okay.  So what happened was, as this hosts file, the Internet master hosts file, became unwieldy, the engineers decided, okay, we need something better.  We need something scalable.  We need something distributed.  And they had a whole bunch of criteria.  The idea was they wanted what they call a "hierarchical name space."  And what that means is that you would not - machines would not be known just by a name because of, well, the problem of name collisions.  It's like, for example, you can't get an eBay account under your name anymore because somebody else already has it.  And so it's yourname3267295 or some nonsense.  And so, which is annoying.  On the other hand, you can have your name if it's in a subdomain.  And so what they did, they created this notion of a hierarchical name space.  And that's what this com and then eBay and then www, there's three levels of hierarchy - www.ebay.com.  And the hierarchy is shown by the periods in a domain name.



So their idea was that there would be a set of servers which would know the IP addresses of sort of the next layer down.  But those top-level servers, the so-called "root servers," they wouldn't know anything about, for example, eBay.  They would just know about .com.  And so the idea was that this would create a tree, essentially, where there's a root to the tree, the so-called "root servers," that are aware of the first level in the hierarchy.  And then the second level in the hierarchy is known to that first level, and the third level is known to the second, and so forth.  So that's where this whole something.something.something.something comes from.  So what happens when I want to look up some domain that I've never been to before is in my own machine, Windows or Mac or Linux, we all have a local cache, that is, our machines will store the IP addresses of domains we've looked at since we've been powered on, or until they have expired.



LEO:  That's independent of the hosts file.  That's in memory.



STEVE:  Actually that's - it's in memory, but it's after a check for the hosts file.



LEO:  Oh, interesting.



STEVE:  The hosts file is still in place.



LEO:  That's the first thing that gets checked.



STEVE:  Yes.  And what's cool about that, and we've talked about this in a couple different contexts in the past, is by putting things in the hosts file, you can preempt your computer from making a true query out onto the Internet's DNS system to look for something.  Which for example is how you could, if you didn't want your computer ever going to DoubleClick.net, or you didn't want it ever going to certain bad sites, you know, you can download hosts files which essentially prevent your machine from going to a whole range of domains which you've decided, or the people who maintain this hosts file have decided, are just bad.  You don't want your computer going there.  You stick that list in the hosts file, and it preempts your machine from making a query.



So the other thing that it's important to understand is that all of the information in the DNS system has an expiration time, that is, it says I'm some information, and I'm good for six hours.  And what that means is that as the information is obtained by DNS servers, they cache it.  They store it, and they keep track of how old it is so that when a query comes for that information, if it has expired, the DNS server will be prompted to go update itself and get a fresh copy.  And this is a wonderfully clever solution for the problem of a distributed database like this because there's - where we've got it, we've got the information spread out all over DNS name servers all over the Internet.  It makes no sense if every single time someone makes a query we have to start up at the root and work our way back down to find the information.  First of all, the root servers would just be overwhelmed.  And we're getting then no benefit from this distributed hierarchy.



So I'm at my computer, and I put an address into my web browser.  And first my computer looks to see if it's in the hosts file.  If not, it looks to see if it's in my local cache, that is, does my computer already have the address because, for example, I put the same address in five seconds ago or five minutes ago, and it hasn't yet expired.  So if my computer does have a copy, nothing happens except it just looks up within its own cache the IP address.  If it's not in my computer, then my computer makes a query out to the DNS server that it's been configured to ask.



Now, that's for most customers, that's sort of an automatic operation.  For example, in Windows, if you say "obtain IP address automatically," your machine gets an IP address, and it also receives the name of two name servers, that is, two DNS servers that have been approved by your ISP and are typically provided by your ISP, either actually by them or they've got a deal with somebody else that allows their customers to use some other DNS server.  One way or another, your machine has the IP addresses of two DNS servers.  And two is an important number also.  It's just it's always been the case that, for the sake of redundancy, we don't want to rely on a single DNS server.  So all domains have a minimum of two DNS servers, sort of just by administrative fiat.  The original gods of DNS said there shall be two, at least.  The idea being that, if there were one, and it were down, basically you're in trouble.  You're not going to be able to figure out the name of something on the Internet.  So for redundancy we've got - and just by convention there's always at least two.



So your machine sends a packet, a DNS request packet to the remote DNS server located typically at your ISP.  Now, what's interesting is this uses the UDP protocol rather than the TCP protocol.  We've talked about TCP and UDP in the past a number of times.  But we'll discuss it here briefly because this is part of the problem with DNS, which is also part of the economy of DNS.  The original DNS designer said, okay, a query is a tiny thing.  It's just basically a what's the IP of www.GRC.com, I mean, a very short request.  So it will fit in a single packet.  So - I mean, with lots of room to spare.  So - because a packet can be, like, 1,500 bytes, and this probably takes 100 bytes.  So they decided it makes no sense to establish a TCP connection when that requires sending a SYN packet to the server, it responds with a SYN/ACK, we respond with an ACK, so that's the so-called TCP three-way handshake.  Then we send our query, and then it sends back the answer.  Then we say, okay, we're done, so we send a FIN packet, and it sends a FIN/ACK back to us to shut down both directions of the conversation.  So that's a huge amount of packet traffic just to send 100 bytes.



And this is exactly what UDP was designed for.  It is a connectionless protocol.  It is the most popular connectionless protocol.  And so essentially a single packet gets sent from my machine to one of the IPs that's configured for DNS on my machine.  And it says - basically that packet is a query saying what is the address of GRC.com?  So if the server already knows, it'll instantly send me its response.  The reason it might already know is, first of all, I might have asked it, for example, on a different computer here in my network.  So this computer didn't have that in its cache, in its local cache, but another computer might.  So I go to a different computer here, ask the same question.



Well, the point is that my ISP's DNS server is serving DNS for a huge number of ISP's clients.  So super-popular domains like Microsoft.com, like...



LEO:  Google.com.



STEVE:  ...Google.com...



LEO:  Or Amazon.com.



STEVE:  Yeah, exactly, Yahoo!.  All of those are almost certainly already in its cache.  So before it responds to me, it'll make sure, first of all, that it's got it in its cache, and that entry has not expired.  And if it has not expired, it instantly sends back a UDP reply to me, one little packet coming back, that says this is the IP that I have in my cache for GRC.com.  And my machine then says, okay, fine, and then it establishes a connection using the IP address, having had it looked up for it by my ISP's DNS.  Now...



LEO:  I'm really surprised, I didn't realize that the hosts file was consulted first.  I see the value of doing that.  But boy, usually when you think of a cache, the point of a cache is to speed queries so you don't have to make that hard drive access.



STEVE:  Right.  Well...



LEO:  The queries are fast enough, obviously.



STEVE:  It might be that the cache is between, from an architectural standpoint, it's sort of moot.  But it could be that the cache is - that the cache holds the result of either the hosts...



LEO:  Oh, it might do that.  I see what you're saying.



STEVE:  ...the hosts query or a remote fetch.



LEO:  There is, I know on UNIXes - Unices? - there is a configuration you can set to say whether you look at the hosts.  But the default is the hosts.



STEVE:  Yeah, well, see, the reason I'm assuming that it checks the hosts file first is changing the hosts file generates an immediate change in DNS.



LEO:  Right.



STEVE:  Whereas if it were hiding behind a cache, then - oh, and actually, Leo, it can't be, because the hosts file doesn't have any notion of expiration, and the cache is all about expiration.



LEO:  Right.



STEVE:  So a change to the hosts file takes effect immediately, whereas - and there's no notion in the hosts file of, okay, these things have a certain amount of expiration.



LEO:  I wonder why even have the cache, then, if you were going to always check - I guess because most results are not in the hosts file.  Not anymore.  Not anymore.  They used to be.



STEVE:  Yes.  And most users have a null hosts file.  They've got an example hosts file, but nothing actually in it.  So, and again, the danger of that is its obsolescence.  If, for example, you put - and you could, you could put www.Microsoft.com and Microsoft.com's IP in your hosts file.  That would prevent you from ever having a lookup delay when you're putting www.Microsoft.com into your browser.  It would instantly be provided by your hosts file, much more quickly than any sort of network traffic out to your ISP, even if the ISP had that IP in its cache.  The problem is, first of all, Microsoft has a bunch of IPs that are delivered in round-robin fashion, which is one of the features of DNS is you're able to give DNS name servers a list of IPs for a given domain, and the DNS server itself will automatically rotate those to sort of distribute the load out among a number of IP addresses.  The hosts file has no such facility.  But more importantly, if Microsoft ever changed their IP address, there's no way for them to notify your hosts file that it's now obsolete.



So anyway, so DNS works.  And basically it's been well thought through.  So imagine now that we make a request to our ISP's DNS server that is either not in its cache, or its cache has expired.  That is, the entry it has when it looks, it realizes, oops, this thing has gotten stale.  That prompts it to essentially go upstream, that is, the ISP will have a cache for - may not have GRC.com in its cache, but it will certainly have the .com servers themselves because there's a huge number of top-level domain servers, the .com servers.  So one of those will probably be in its cache because that's going to be asked for all the time.  Anytime any domain expires in the ISP's cache, it's got to go to the com servers, in the case of a .com or .edu, .gov, .mil, .whatever.  So the com servers are the ones that are - the term is "authoritative."   They're the authoritative - they have the authoritative records, for example, for all of the .com domains - GRC, Yahoo!, Microsoft.  Well, let's see, TWiT, you're in the TV domain.



LEO:  Yeah, which is Tuvalu runs that one.



STEVE:  But Leoville.com, so there's Leoville.  So the com servers have the authoritative records for all of the .com domains.  So the ISP's server is able to ask one of the .com servers, hey, what are the name servers for GRC.com?  Because what the .com servers have is the name servers for GRC.  So the com servers tell the ISP's name server, here's the two name servers.  And they might be, for example, NS1.GRC.com and NS2.GRC.com if I'm hosting my own name servers.  And because - there's sort of a chicken-and-egg problem here.  We're trying to get the GRC.com IP, except that the name servers are in GRC.com so there's something called "glue."  Those are additional records that can be provided.  So the .com server will say, oh, and the IPs of NS1.GRC.com and NS2.GRC.com, those two name servers are as follows.  And so they'll provide the IP addresses of those.  So now the ISP has the IP addresses of GRC.com's name servers.  It's able then to ask, for example, for the IP of www.GRC.com, which it then stores in its cache for the length of time that that record has before it expires.  And if they went to GRC.com, my server, for example, says I don't know, probably like eight hours or something, or maybe 24.



One of the cool things that it's possible to do, if I knew, for example, that tomorrow I was going to be changing my IP addresses, I could deliberately bring down the so-called "TTL," the Time To Live, on GRC.com's DNS records.  That would have two effects.  It would mean that as GRC.com's records expired in various places on the Internet, and the records were refreshed, they would be getting new records with shorter TTLs.  Well, that would increase the load on my DNS server because basically it's making all of the various servers come back to me much more quickly.  But the tradeoff is, when I make a change to that information, it will get out into the Internet much more quickly.



And we've all, I'm sure, there have been many times we've talked about DNS propagating, this idea of it'll take a while for DNS to propagate.  Well, that's really what that means is it's something that the DNS server itself, the authoritative server for a domain, is able to control because it's able to specify how long it wants its records to live out on the Internet.  And so, for example, after making an IP change, I would probably go back to a 24-hour TTL, which then when people came back relatively quickly because I had had a short TTL, they would then be getting this 24-hour TTL.  And they'd go, okay, fine, we can confidently deliver these records to anyone who asks for one full day, after which we'll come back just to make sure nothing has changed.



LEO:  Of course you want to balance - it's a balance between updates and bandwidth.  You don't want to overdo it, either.



STEVE:  Yes, exactly.  So, yeah.  And in fact there was - actually I remember a mistake Microsoft made where they inadvertently had a very low TTL on some of their records, and their DNS servers were being slammed by the entire Internet.  They were a very popular - I'm pretty sure it was Microsoft, a very popular domain.  And so...



LEO:  Now, explain to me why they'd be slammed.  Wouldn't that get uploaded to the main servers?



STEVE:  Well, yes.  They were being slammed, I think the TTL was down in the order of a few seconds, though.



LEO:  Oh, geez.  So they were getting hit by the DNS servers asking for updates.



STEVE:  Exactly.  They're getting hit by all of the ISPs saying, oh, look, you're telling us that your records are only good for five seconds, so we've got to ask you again.



LEO:  Wow.



STEVE:  We don't want to ask you again.  We know you don't want us to ask you again.  But you're saying these records are this short-lived.  And...



LEO:  So the ISPs will go directly to Microsoft instead of to the big 13 domain name servers.  They'll actually go to the person providing that information.



STEVE:  Well, yes.  And that's critical to our discussion.  So what they'll do is, what they need to get from the com servers, for example in the case of Microsoft.com, they need to get the name and the IP address of Microsoft's name servers because it's Microsoft name servers that have all the information about Microsoft.  That is, you know, www.Microsoft, any other subdomain, secure.Microsoft.com, any subdomains.  And even Microsoft.com itself, even that, that IP for Microsoft is different than the name servers, which exist on their own separate IPs.



LEO:  Okay.



STEVE:  So the only thing that the com servers have are the name server name and IP.  And when you think about it, Leo, I know you've registered domains before.



LEO:  Yeah.



STEVE:  When you register a domain, what you give it is name servers.  You give it - you say, okay, it's NS1...



LEO:  Here's where my name servers live.



STEVE:  Here's where my name servers are.  And so then whoever's maintaining the name servers, they have established the DNS records in those name servers, which ISPs' DNS servers then query.  So the only thing that is in the top level domain, the .com, .edu, and so forth, are the IPs of the name servers.  And then the DNS servers go to those name servers in order to get the specific details.



LEO:  Interesting.  Okay.



STEVE:  So, okay.  Now back in the early days there was really no concern for security.  I mean, the Internet was small enough that you had the whole Internet in one hosts file.  And we've talked about how back then you had people in white lab coats who made sure they wiped their feet before they went into the computer room, and there was .gov, .edu, .mil, I mean, there were some high-level domains.  There were just basically a number in the hundreds or thousands of machines in total, total IP addresses on the Internet.  There just weren't that many.  So they made DNS so that it worked, but there was no, I mean no concept of security.



When I was thinking about this yesterday, how I was going to drive home the fact that there was no concept of security, I thought of a perfect example.  And that is SSL, that we've talked about many times, the Secure Sockets Layer, and HTTPS.  That was all added on afterwards.  There was no security in TTL at all.  That was the Netscape guys that came up with the first SSL specification, adding that way after the fact to TCP.  So it wasn't even possible to have an encrypted TCP connection.  You couldn't send email that was not in the clear unless you encrypted it yourself and then had somebody decrypt at the other end.  So there was just no notion of this.  They were amazed it worked at all, rather than worrying about how bad guys could attack it and make it not work.



LEO:  It's very telling, though, I mean, the whole Internet was designed pre-security concerns.



STEVE:  Yes.



LEO:  And this is kind of such a fundamental part of the Internet.  And they just weren't thinking.  They were thinking about a lot of other things, obviously.  They did a good job designing it, just not secure.



STEVE:  Oh, I mean, the documents that describe what I'm talking about today, it's RFC 1034 and RFC 1035, were written in November of 1987, 21 years ago.



LEO:  Why do you think they just - was that just the general thing was that nobody was thinking about security?  I mean, just nobody did think about it, I guess.



STEVE:  Well, there weren't any bad guys.  I mean, the bad guys all came along later.



LEO:  Why would anyone mess with their nice little system here?



STEVE:  Yeah, and there wasn't any commercial use of the Internet.  It was all government and edu and research and just sort of, oh, look what we can do.  We're able to send packets off, and they get to where we aim them.  Which was amazing to these guys, I mean, and should be.  It was great technology.  But there just, I mean, it was fundamentally about getting it to work.  And whereas now we think, oh, well, of course it works.  We wish just that it were bulletproof.  It's like, okay, back then just making this whole DNS thing work was amazing.  So when a DNS query is sent out, any kind of a query, we've talked about how IP ports and IP addresses work.  You have a port at each end which is just a number from one to 65,535, and an IP address which is a 32-bit number.



A DNS server at an ISP is pretty busy.  It's sitting there, and it's receiving queries from all the ISP's customers.  And it's checking its cache to see if it knows the answer already, and if it has not expired, if it knows it.  And if so, it sends the answer back.  If it needs to make a query to another server above it, to like a .com server in order to find out where Microsoft.com's name servers are, what it does is it uses a 16-bit value which is called the "transaction ID," or also sometimes known as the "query ID," or "QID."  And the idea is that that was in the original implementation, was just an incrementing counter, that it would simply count up, and it would be a larger value each time an outbound query was made.  And so the idea was that when the answers came back, the DNS server would use this query ID as, like, a serial number to match up the response with the request.  And that was essentially used as its own housekeeping mechanism.



Now, a long time ago, and this is, like, way predating our current dilemma, as people began to recognize that there were bad guys on the Internet, some of this infinitely trusting nature of especially DNS came - people realized, okay, DNS is way too trusting.  The reason is, it was easy to spoof DNS.  If you wanted to know at any point where DNS's counter was, you could simply cause the ISP to send your own name server, your own server a query.  You would see where this transaction ID counter was and then be able, essentially, to spoof your own reply.  You could cause the DNS server to have an outstanding query, and then you send it the answer before the actual response gets back.  Basically you beat it to the punch.  And since this was just a simple incrementing counter, and you could get it to ask you a question, you could determine where the counter was and essentially send a whole bunch of replies really fast after you know that you had caused the ISP's server to emit a query and essentially spoof the result.



Now, one of the reasons this was so easily done, unfortunately, is the use of UDP because, unlike TCP, where this three-way handshake confirms the IP address at each end, remember we've talked about often how you cannot spoof a TCP address, that is, a TCP/IP, because in order to set up the connection you must have packets make a round trip in each direction.  That's part of what the whole TCP handshake is doing.  Whereas with UDP it's just a single packet.  Off it goes to the server, and then back it comes.  But there's nothing to authenticate that packet.  So if your system has full raw sockets...



LEO:  Whoa, the raw sockets.



STEVE:  Ah, yes.  If your system has access to raw sockets, you're able to build your own UDP packet and put any source IP in it that you want, not the source IP of your machine, but the source IP of the server you are spoofing.  And you can send that packet out, and you can send as many of them as you want to, even like with a range of these query IDs, or transaction IDs, hoping - because this DNS server is busy, it's sending a bunch of queries out.  So even if you're able to read the current state of the counter, it might be making other queries before you're able to get it to make the query you want.  So the counter might have moved forward a little bit.  But still that creates a window that you can pretty much guess where its counter is going to be.  So you flood it with fake replies, and essentially you're able to poison its cache.  When we talk about a cache, a DNS cache poisoning attack, that's what this is.



So one of the things that they realized was, okay, DNS has been too trusting.  We're not going to use linear counters anymore on our transaction IDs.  We're going to use a pseudorandom number generator so that the transaction ID jumps all over the place.  So that substantially strengthened DNS.  That made it much stronger.  It meant that you had to guess, well, basically it meant that you had no information about what the transaction ID was going to be, assuming that it was using a good random number generator.  It just meant that it was issuing queries from using any 16-bit transaction ID following a path that you could not guess.  So that made it much stronger.



On the other hand, networks got faster.  Computers got faster.  And remember, a 16-bit transaction ID is only 64K things.  For example, we would never want to trust our security to something that was 16 bits.  It's just too guessable.  And we've seen from the way a birthday attack works that the chance of two things colliding - remember the birthday attack is in a room with people who all have birthdays, by definition.  You may not be able to guess one particular person's birthday, or if you had a given date it might not be that anyone in the room had that.  But the chances of two people in the room having the same birthday is much higher because of all the number of possible matches.  It's the number of people squared.  It's NxM-1.  So the point is that even a random number generator that's only 16 bits long isn't random enough.



Okay.  Now, two things are required in order for a reply to be matched.  Not only must the transaction ID match, but the packet must return to the same port it was emitted from.  The TCP stack itself, the IP protocol, if you send a UDP query, a UDP packet out, you're then listening for a reply to the same port.  Well, originally DNS servers ran on port 53.  That is, they always are listening for queries on port 53.  That's the universal DNS port.  In the same way that the web is port 80, and SMTP is 25, and POP is 110, DNS runs on port 53.  That is, all DNS servers listen to queries coming in on port 53.  That's the DNS service port.  So, for example, when my computer is asking my ISP to do a lookup for it, it sends that UDP query to port 53.  But the source port, that is, the outbound port as opposed to the destination port, that can be anything.



Well, originally DNS servers, often they would either - they would just emit their own traffic from port 53, or they would just, when they got fired up at boot time, they would allocate a port, and all queries would go out from the same port.  So that meant that replies had to come back to the same port.  But that meant that the only thing that the spoofer had to guess was the transaction ID.  Dan Bernstein, who's a well-known, well-respected security researcher, he said a long time ago that, you know, having a fixed query port, that is, a fixed port from which queries are emitted to other servers on the Internet, is insecure.  He wrote a DNS server that did what's called "query port randomization," meaning that deliberately, every time the server wanted to make a query, it would open a new port and emit the query from that port, so that the response had to come back to the matching port.  Well, as we know, ports are 16 bits, one to 65535.  So essentially doing query port randomization and transaction ID randomization gives you 32 bits of entropy and makes spoofing DNS vastly more difficult.



LEO:  Ah, very interesting.



STEVE:  I mean, it is 64,000, you know, 65,536 times more difficult, and virtually impractical at that point.  The problem is that most DNS servers - Dan Bernstein's DNS servers, I think it's djbdns, have always done this, have always done query port randomization.  The OpenDNS servers have done it.  Sort of high-security DNS servers have done that.  However, a couple things caused that some problems.  Depending upon the configuration, for example, of corporate or ISP firewalls, it may not be convenient for them to have queries going out on all ports because that means you've got to have replies able to come in on all ports.



So, for example, sometimes a firewall policy will restrict DNS to a given locked-down port.  One of the other things that happens is sometimes NAT routers can derandomize DNS.  That is, you might have a good DNS server with really good query port, or query source port, randomization.  Yet when it goes to the NAT router to traverse outside, the NAT router says, eh, we're going to, you know, NAT routers often remap ports.  It might make them linear.  It might just say we're going to use the next port up from the one we used last time and linearize it.  Well, as soon as you've got ports being linear, again, they're easy to guess.  You can guess what the next port or the next range of ports is likely to be and send your spoof UDP packets there.  So essentially one of the things that was done by some DNS servers was this query source port randomization, which essentially made spoofing DNS 64K times more difficult and virtually impractical.  So...



LEO:  A good thing.  A very good thing, indeed.  And it's interesting because you mentioned a couple - Randal Schwartz said that's one of the things that makes OpenBSD so secure.  You mentioned OpenDNS.  Do they use their own servers?



STEVE:  Don't know whose servers they're using.  But I know that from the beginning they were...



LEO:  They were secure.



STEVE:  Yes, they were secure because of this.



LEO:  But almost nobody, I mean, Cisco, Microsoft, even BIND, the traditional Free Software Foundation DNS server that's used by almost everybody, all had this vulnerability.  None of them were using randomized.



STEVE:  Yes. Some of them had the opportunity.  Some of them, I mean, it was an option that was often not used.  And it's interesting because many times in the last few weeks I've heard people lamenting that Dan Bernstein was right.  We absolutely had to have query source port randomization in order to thwart this kind of attack.



LEO:  Very interesting.  Let's talk about the attacks, in fact, this attack that Dan Kaminsky found, because he's now revealed how it works.  And now that you understand...



STEVE:  Oh, but actually he has not revealed how it works.



LEO:  Oh, others have - well, and that's the thing.  He may say, no, you were close.



STEVE:  Yeah, but I'm going to tell our listeners what it is that everyone believes, and what it is that was found.



LEO:  Yeah, it's very interesting.  And we are starting to see these attacks.  And that's what's really discouraging because even though patches exist now for all the servers, many ISPs aren't applying them.  All right.  So let's talk about the attack.



STEVE:  Yes.  Okay.  So what we believe is that Dan - okay.  Basically everything I've said so far, everybody has always known.  I mean, that's what DNS spoofing is.  That's DNS cache poisoning attacks.



LEO:  And but it was more theoretical because it was complicated and difficult to do; right?



STEVE:  Well, the transaction ID was normally randomized, but the source port for most DNS servers was not.  So but it was believed that even if, I mean, the worse you could do would be to affect one record in a DNS server.  That is, it would only be when www.Google.com, it would only be when that record expired that the server that had cached it would be induced to go and update its knowledge of the www machine IP at Google.com.  So there's a tiny window of opportunity.  There was nothing you could do to, like, force an ISP's DNS server to accept a new www.Google.com IP.  There would be - when it would finally expire, then you had an opportunity.  But, I mean, it would immediately be asking.  And you had transaction number randomization.  So there was just - it wasn't practical.  It was sort of a theoretical attack.  It wasn't practical.  What we believe Dan realized, what now exists in exploit code being circulated around the Internet, HD Moore, who maintains the well-regarded in hacker circles, the Metasploit Framework, instantly implemented this late last week in his framework.  And he called it the BailiWicked Domain Attack.



LEO:  I like that.



STEVE:  "Bailiwick" is the term used to refer to the sort of the neighborhood, the domain that you're in where once upon a time it was possible, in early DNS servers, to fool them by sending information back that they did not ask for.  That is, you could actually, the way a DNS query and reply are structured, you have a query and then an answer to the query and then additional information and authority information, four sections.  And you're able to put whatever you want to in the additional information.  Normally, it's as I was saying, it's this glue to sort of help the server.  For example, if the server you're querying has some additional information for you, like the IP addresses of the name servers or other information that you might otherwise have to go get again, it'll give it to you to sort of, just for the sake of efficiency, to improve the way DNS operates.  And there were some servers where you were able to give it - and this is early DNS servers - you were able to give it information about an entirely different domain.  So that in a response to a query about Yahoo.com, you could actually put in information about Google.  And this has not been seen for a long time, so don't worry about this.  This got fixed quickly.  But, I mean, this is how trusting the original DNS was.  It just believed anything anybody sent it.



LEO:  Whatever.



STEVE:  And so those were called "out of bailiwick," that is to say, the additional information had nothing whatsoever to do about the query.  They weren't in the same bailiwick as the query.  So now DNS servers were made smarter, and they were taught not to, well, to completely disregard any additional information that is out of bailiwick, that is not relevant to the query that they're making.  So what we believe Dan realized is that there was a way to force, now, as opposed to waiting for the cache to expire and then having some futile race in order to get a reply in before the real reply was able to get in, we believe he realized there was a way to force a fundamental change in the DNS cache.



And this is how it works.  You first - let's use - I'll use Example.com.  So you look up the two name servers for Example.com.  And that'll be NS1.Example.com and NS2.Example.com or whatever they are.  You look up the two name servers for Example.com.  Those are the servers that an ISP's DNS server will query when it needs information about Example.com.  So you're able to look them up just the same way the ISP is.  So you know the IP addresses that the ISP's DNS server will query.  And so you're going to attack this given ISP's DNS server.  And this will be a lame ISP that has not updated their DNS servers to add random query port queries.



LEO:  A surprisingly large number, even now.



STEVE:  Yes.  Even now we're seeing a huge number that have just not bothered, even though it's been - there's been a lot of concern raised about this.  So what you do is you send a query for a fake machine, Aaaaaaa.Example.com.  And, okay, that doesn't exist.  So you know it's not in the cache.  That is, you're forcing a cache miss, which forces the ISP's DNS server to ask the Example.com server for the IP of Aaaaaaa.Example.com.  So what happens is you know that upon making that query to the ISP server, the ISP server is going to send an outbound query to get the machine, the IP address of that wacky Aaaaaaa machine.  So you know that there's a query outbound.  If they're not using source port randomization, you know the port from which the query was emitted.  And even though they're using random transaction IDs, 64K is not enough.  So you flood it with maybe 100 UDP packets.  You spoof your source IP as the IP that you know it's asking, the IP for Example.com's name server, which you were able to look up.  And you know the port that it's bound - you know the port that you send it to.  So you flood it with replies.  Even if that misses, it doesn't matter because now you ask it for Aaaaaab.Example.com.  And you flood it with more spoof replies.  And then Aaaaaac.Example.com.  Essentially what we've done is we're able, by making up machine names at Example.com and querying an ISP's DNS server, we're able to force it to ask Example.com for the IP.  Now, our spoof replies include new name servers for Example.com.  And because they are name servers for Example.com, they are in bailiwick, and they will replace the name server records at the ISP.



LEO:  Wow.



STEVE:  And it works.  It takes about 30 seconds, maybe as much as a couple of minutes.  It is being exploited right now, and it works.  What this means is you're not just changing one record.  You are essentially redirecting all the name services for an entire domain - Google.com, Microsoft.com, eBay.com, Yahoo!, I mean, whatever the attacker wants.  They're able to flood an ISP's server with spoofed replies.  Even though the transaction ID is jumping all over the place, the nature of the birthday attack means that you're going to get a collision.  When you get a collision, it's going to look like a valid reply from the real server.  And that real server, the so-called "glue," this additional information will be accepted because it's in bailiwick.  In the process what you've done is you have told the ISP server that these are the name servers for an entire domain, which is where it will go from now on.



And you can give that record a super-long TTL, a super-long Time To Live.  Time To Live is 32 bits.  That's a long time.  Essentially, it will never expire.  That record will never expire, and it will sit there being wrong.  At that point anybody who is a customer of that ISP who is using that ISP's DNS and puts www.Google.com, for example, into their browser, their machine will receive a fake IP for Google.com.  It'll come up, and it'll look just like Google.  You look in your URL, you can make sure, oh, yeah, www.Google.com, that's it, there' s no phishing going on.  Wrong, because the ISP's DNS has been poisoned with this attack.



LEO:  And none of the anti-phishing measures that the browsers implement will work because it looks like it's the normal place, you're going to the right place.



STEVE:  Yes.  Now, what does work is...



LEO:  Certificates work.



STEVE:  Certificates, yes, SSL.  There is no way that some random malicious server in Russia that is spoofing Google or spoofing eBay or spoofing PayPal, and these are going to be the targets, there's no way that they're going to be able to have a certificate for PayPal.com.  However, not all users are cognizant of security.  That is, it's PayPal, when you go to www.PayPal.com, PayPal switches you to a secure connection for login.  We just take it for granted.  And it's only the most recent browsers that even color the bar and show you that you've got a secure connection.  No, it's a little padlock down in the bottom.  People don't look.  And they just assume PayPal is going to, when they log in, it's going to be secure.



LEO:  It can never be a secure connection because the certificate doesn't match the URL.  You don't own - you can't get PayPal's certificate.



STEVE:  Well, and my point is that the spoofed site will not switch you to SSL.



LEO:  It can't.



STEVE:  But, see, it doesn't want to.  It doesn't need to.  Because you put in www.PayPal.com, which by default is http.  So you establish a connection not using SSL.  It gives you the login page.  You think you're at PayPal and that it's going to be a secure login.  But it's not because you're actually at the wrong IP, which every customer of this ISP will be going to as long as that cached DNS record is wrong.



LEO:  And they couldn't really ever make it an SSL connection, a certificate, because a certificate would have to - would it have to say "PayPal.com" to match?



STEVE:  Yes.  But, see, they don't have to.  I mean...



LEO:  Well, I understand they don't have to.  But what this means though is there's a hole because I can check to see if I have an SSL connection.  And if I don't, then I know it's not the right page.



STEVE:  Oh, absolutely, Leo.  You and our listeners are probably not going to get caught out by this.



LEO:  Well.



STEVE:  And so you're right.  You could...



LEO:  Have to remember to check.



STEVE:  ...put in https://www.paypal.com.  If you manually put in a secure connection, PayPal, the real PayPal, will accept it.  A fake one, well, they're probably not even going to have a server running on port 443 for https because they know they're not able to spoof PayPal's certificate.  But they could do something even trickier.  They could, at www.PayPal.com, they could have a redirect.  Remember we talked about the redirect dance a couple weeks ago that Phorm was doing.  They could have a redirect to PayLal.com, some subtle misspelling of the name, and they'd get a certificate for that.  So they're able to accept a connection on PayPal, redirect your browser to https://paylal.com...



LEO:  But it would say PayLal in my browser.  It wouldn't say PayPal in my browser.



STEVE:  Right, or it could be PoPal or something, you know, like "O" versus "A," where at a glance it looks the same.  But again, if there were some need for them to establish an SSL connection, they have, I mean, when you go to the site nonsecured, they can do whatever they want to with your browser, which believes it is at the right location.



LEO:  Right.  That's fascinating.  So if you are sharp-eyed, you can spot this.  There is a way to always spot it.  Well, I guess if you're going to a site that has SSL.



STEVE:  Yeah, I mean, a blogging site or all, I mean...



LEO:  You wouldn't spot it.



STEVE:  Unfortunately SSL connections are still the rarity. They're not used except normally only briefly during login, even, for example, when you log into Gmail, as we've talked about.  If you initiate a connection to Google Mail that is secure, it'll keep it secure.  Otherwise it briefly moves you into secure and then back into nonsecure.



LEO:  Very interesting.



STEVE:  So it is, I mean, this is a - and this is serious because, first of all, HD Moore has implemented this in the Metasploit Framework.  These attacks are underway.  They take on the order of a couple minutes to get the collision of the transaction ID on a server that is not randomizing its queries.  And unfortunately a huge number of servers now are not.  Now, Dan created a page that we talked about last week and the week before, I think, his DoxPara site.  He's updated it a few times.  I've seen and others have reported inconsistent results from it.  Sometimes it says all the queries are coming from a single port.  Sometimes it says they're coming from random ports.  I've even seen it say that your DNS server is doing something better to thwart the attack.  You don't have anything to worry about.  But he's being cagey about it.



So there is another site that I wanted to tell our listeners about.  It's got a long URL which I am putting in our show notes.  I'll just say it for the sake of saying it once.  But I've created a SnipURL, a short version of it.  The full URL is entropy.dns-oarc.net/test.



LEO:  But don't write that down.



STEVE:  You don't need to write that down.  The easy-to-remember one is snipurl.com/dnstest, which is just a little redirection URL that I created for our listeners.  What that does is take you to a very nice test that actually charts the source port randomization and the transaction ID.  It issues up to 25 queries and watches the DNS server that your browser is using, which is typically your ISP's DNS server, it watches it issue queries and is able to show you a chart and lists all the ports that were used and all the transaction IDs.  It then does a standard deviation of those.



LEO:  It's amazing, really.  I mean, if you looked at the old DoxPara, it's incredible.



STEVE:  Yeah.  This is a really nice tool, and it will allow people to determine if their ISPs have figured out that this is really important to fix.  And we should mention again that the OpenDNS system, which has always been available and for use as an alternative DNS, you've got to manually configure it in your system, but they're using source port randomization, and they're not going to be spoofed.  And it might, if you're a person who's concerned about this, you might want to take matters into your own hands until your ISP gets around to fixing this.



LEO:  Yeah, OpenDNS is great for so many other reasons, too.  I think that some people have worried a little bit about the notion that they put ads up if you get a, you know, you enter the wrong URL.  Doesn't bother me.  They have to monetize somehow.  And it's so useful in so many ways.  And it's secure. and it was secure from day one.



STEVE:  Now, there have been some questions about whether personal routers have a problem with this.  And personal routers for the most part are not doing any caching.  The little inexpensive Netgear, Linksys-style routers, all they're doing is passing DNS queries on.  However, the Linux-based routers, like the OpenWrt stuff, those are known to have this problem.  So people who are using the ww-wrt and OpenWrt, you're going to want to do some Googling and find out what's going on because those routers may be caching.  But again, it would be - it would have to be a highly targeted attack.  That is, somebody would have to see your router issuing a DNS query and have some reason to poison you.  In the process, they're only going to poison your one network.  Of course, you're concerned about that.  Except that it makes far more sense for bad guys to go after major ISPs.



And essentially what this means is they're able to insert new name servers into any domain they want and poison for any length of time that domain.  And the only way an ISP would probably know is if customers began complaining that when they go to PayPal something seems wrong.  And then the ISP goes, uh-oh, and flushes that cache record and gets rid of the problem.  But who knows how many people would be affected in the meantime?  I mean, this is why all of the DNS solution providers updated their DNS servers.  They may be - we don't know what the full fix is.  That hasn't been revealed.  We don't really know for sure what Dan is going to say on August 6th.  Maybe they are tightening up their in-bailiwick management.  So, for example, they're looking to see whether, like, another reply came back from the real server.  They could be doing rate limiting on incoming spoofs.  I mean, there are a number of things DNS could do to harden itself even beyond source port randomization.  But certainly adding another 16 bits of randomness by virtue of emitting queries from an unknown port, that is just much, well, it's virtually impossible.  Well, again, "impossible" as we now know is a relative term.



LEO:  Never say "impossible," yeah.



STEVE:  Never say "impossible."  But it's so unlikely that both the transaction ID that's 16 bits and the port number which is 16 bits minus one, so unlikely that both of those would match an incoming reply as to not be worth anyone's while trying to guess it.  So certainly the best defense is to have an ISP whose DNS servers are emitting queries on random ports.  But I think that this point our listeners probably know and understand, hopefully, this entire problem.



LEO:  Wow.  You know, I had read the explanations that others had come up with about how this works.  But you've got to have the fundamentals of how DNS works before you can understand this.  And I didn't really quite understand this whole port thing.  And now that you've explained it, I do.  And the exploit makes sense.  And I think the thing to point out is that we're seeing this exploit in the wild.



STEVE:  Yes, yes.  Interestingly, HD Moore commented somewhere that this was available on Linux, and they were porting it to the Mac OS X, that is, the exploit.  But it would not be ported over to Windows because Windows cannot spoof UDP because...



LEO:  Because...



STEVE:  ...thankfully it does not have full raw sockets.



LEO:  And this was a fight, just because I know Steve won't toot his own horn here, this was a fight Steve brought to Microsoft when XP first came out and it did, in fact, have this raw sockets capability.  Microsoft put it in saying, well, it's in UNIX, we ought to have it in Windows.  They underestimated the security issue.  Steve really raised a ruckus.  A lot of people, I have to say, criticized Steve for that, saying oh, it's a tempest in a teapot.  Well, he's been proven right time and time again.  And eventually Microsoft finally got the message and did take out that full raw socket capability from XP.  And thank goodness.  Otherwise these exploits would be much more widespread.



STEVE:  Well, what we would have is we would have Windows-based bot fleets that were able to do this.  And that would really up the ante.  It's also worth mentioning that Dan has come under a lot of heat.  People are accusing him of promoting himself and making a bigger deal of this than it is.  I mean, I think there's no way not to feel that Dan has really done the Internet community a great service.  He realized this was a problem, presuming that this is what the problem is.  Again, we're all having to really finally wait until his presentation at Black Hat to know.  But he brought this to the attention of the proper DNS authorities, got them to really explain the problem, got them to understand that this wasn't just a theoretical problem.  Everybody fixed it, or that is to say, changed the software so that it could then be deployed.



And then, as we announced two weeks ago, this thing all went public.  Not any knowledge of what it was, but just the fact that people had to upgrade their DNS.  And maybe they're strengthening DNS even beyond good source port randomization.  We really won't know until Dan tells us the whole background of this.  But it is certainly the case that old DNS servers are still on the 'Net.  I mean, tens of thousands of them are.  And tools now exist that within a few minutes can change the DNS records of any domain they choose, to redirect everyone who uses that, who depends and relies on that DNS server, to any other IP on the Internet.  And that's not good.



LEO:  Well, and he handled it so responsibly.  I mean, I don't think you could ask for a more responsible way to handle this.



STEVE:  No.



LEO:  So no reason to criticize Dan in the least.  In fact, he did, it seems to me, exactly the right - and there's no way he could have known that ISPs would be so slow to adopt these patches.  And what are you going to do?  You've got to make - you've got to do it.  Anyway, soon as the patches go out, people know something's up.



STEVE:  Well, and now what'll happen is we will - ISPs, for whatever reason they're being reluctant, they don't want to bring their DNS servers down, the guy with the password's quit and they don't know how to bring them down, I mean, who knows what.  But we're now going to see some horror stories, isolated horror stories of major exploits of this against unpatched DNS servers.  I will say again what I said last week.  It is very easy to determine if a DNS server is exploitable.  So that means that those servers that have not yet been updated are going to - they're, like, drawing fire to themselves.



LEO:  Is there any way to tell?  I mean, yeah, you could run one of these programs, I guess, like DoxPara or DNS Test, and you could tell.



STEVE:  All you have to do, yes, all you have to do is cause the server to emit some queries...



LEO:  Oh, you can see it immediately.



STEVE:  Yeah.  You're able to see - you would set up a domain, and you would ask it for fake machines in your domain.  That would force it to ask your domain servers for those fake machine names.  You look at those, you instantly know whether that DNS server is exploitable or not.



LEO:  Wow.  Very interesting stuff.  Thank you, Steve Gibson.  You can find this podcast, plus a transcript, plus 16KB versions if you'd like to share it with your bandwidth-impaired friends, at Steve's site, GRC.com.  That's also where you'll find SpinRite, the world's best, must-have disk maintenance and recovery utility.  It gave me a great feeling to know I had SpinRite and I could test this drive when it failed. GRC.com.  Also a lot of great, useful utilities like ShieldsUP!.  Steve's really been doing this for a long time and is a great boon to the Internet community.  And we're really glad he's there.  GRC.com.  Steve, we will do a Q&A next week.



STEVE:  I look forward to it, Leo.  I'll talk to you then.



LEO:  All right.  Thank you, Steve Gibson.



Copyright (c) 2008 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






