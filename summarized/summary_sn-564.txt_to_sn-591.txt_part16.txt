GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#564

DATE:		June 14, 2016

TITLE:		Listener Feedback #235

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-564.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I catch up with a busy week of security happenings including Symantec's worrisome purchase of Blue Coat Systems, a bad bug in Chrome, more news from the hacker Peace, Let's Encrypt's email glitch, more Microsoft telemetry concerns, some sci-fi updates, and questions and comments from our terrific listeners.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  It's another Patch Tuesday, and Steve has the deets.  Plus a look at more database hacks and in fact why Peace is in the business of selling passwords.  And then we'll answer questions, 10 of them, from you our audience.  It's going to be a jam-packed Security Now! coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 564, recorded June 14th, 2016:  Your questions, Steve's answers, #235.



It's time for Security Now!, the show where we talk about security, now.  Right now.  Like exactly now.  Steve Gibson is here.  He is the man behind GRC.com, the security guru for all of us, the man who discovered spyware, coined the term, and wrote the first antispyware program.  And of course he's well known for a lot of different programs, including SpinRite, the world's best hard drive recovery and maintenance utility.  And he joins us every week to talk about stuff in the security world.  How are you doing, Steve?



STEVE GIBSON:  So, hey.



LEO:  Hey.



STEVE:  Great to be with you again, as always, my friend.  Lots of news to talk about, although after two weeks of the IoT Infancy we're going to do a Q&A.



LEO:  Woohoo.



STEVE:  Oh, boy, there's some fun stuff in here, including an amazing utility for Windows users that I was turned on to by one of our listeners that I just - I didn't believe it until I checked it out this morning.  So it's like, oh, my god, this works.



Anyway, we've got the news of Symantec's purchase of Blue Coat Systems, which has got a lot of people concerned because these are the people that do the man-in-the-middle SSL/TLS decryption on the fly.  There was a bad Chrome bug that we never knew we had.  Some more news from the hacker who calls himself Peace that's kind of fun.



Let's Encrypt had a little bit of a mistake with their mass mailing.  It's a bug that I just love that we're going to talk about.  Another little concern that arose over Microsoft and telemetry in a surprising place.  And then I want to briefly talk about some science fiction and sort of amend some snarkiness that I've been self-conscious about, and then get into our Q&A.  So a great podcast.



LEO:  The snarkiest amendment.  The snarkiness amendment.  That sounds like fun.



STEVE:  So two things happened while I was assembling this.  And the first is that this is the 14th of the month, which is a Tuesday, meaning that it's the furthest into the month that it's possible to have the second Tuesday.  Which of course means patches for Microsoft and Adobe, nominally, because it just dropped.  And in fact my Windows 7 machine has been on for an hour, still checking for updates.  So I don't know.  Anyway, I haven't had a chance to dig into them, but I do know there's a bunch because Brian Krebs at least dropped the news that there were more than 36 security vulnerabilities addressed today.  So anyone using Windows...



LEO:  Kind of amazing.



STEVE:  You're going to want to update yourself.



LEO:  I'm opening my Windows device right now.



STEVE:  Now, Adobe normally drops on the second Tuesday.  But apparently, when they were getting ready to release their update, they became aware of a critical zero-day that was in use, being exploited actively.  So they deferred their June update until later this week.  I mean, again, I hope that a problem with Flash no longer actively affects any of our users because, if nothing else, everyone should be using a browser which requires you to touch your nose with your middle finger of one hand while spinning around counterclockwise and then clicking the "Yes, I'm sure I want to launch Adobe" when the X'd window comes up and says, "You really don't want to launch Adobe."



In other words, our listeners, it's hard to imagine anybody at this point could still be caught out by an Adobe Flash problem because we're on the way of saying goodbye to it.  HTML5 is a replacement, and it's only legacy at this point.



LEO:  Yeah.  I still haven't installed it on my Linux box.  Probably will never do so.



STEVE:  Don't need it, yeah.  It doesn't run on any of my iOS devices, and I seem to be fine.



LEO:  Yeah, right.  We've survived somehow for it's now nine years without it, yeah.



STEVE:  Yeah, there's one really neat site, NutritionData.Self.com.  And I'm so bugged because they have these cool little graphics which are Adobe applets, which show the amino acid spread of whatever you're looking up.  So it's a big database site, NutritionData.Self.com.  Really neat.  But unless you've got Flash, you get a much smaller view and much less useful view.  Oh, the other thing is a cool triangle where it's got protein, carbohydrate, and fat on the three corners in different colors.  And so there's like a spot showing you what the ratio of fat and carbohydrate and protein is for anything you look up, like a Carl's Jr. hamburger or something, I mean, they've got all kinds of stuff like that.  But again, without Flash, it's - and I keep waiting for them to get their act together and redo this without Flash.



The other piece of news that just happened this morning that I knew you, Leo, would find interesting, and our listeners, too, is that this morning the court ruled upholding the Net Neutrality rule.



LEO:  Yeah, I saw that, yeah.  It's good news.



STEVE:  Yes.  And this was a federal appeals court that upheld the effort to make the Internet service providers treat all web traffic, and more broadly Internet traffic, equally.  Which of course delivers a major defeat to the cable and telephone companies.



LEO:  Who will appeal it, of course, to the Supreme Court.  So it's going to be a Supreme Court case.



STEVE:  Yes, in fact, AT&T immediately announced that it would appeal the ruling, saying it's always expected the issue to be decided by the Supreme Court.  So it's like, eh, okay, fine.



LEO:  We knew we'd lose.



STEVE:  Yeah, right.



LEO:  We knew this.  It's okay.



STEVE:  Which of course, at this point, with the Court sort of 4-4, missing the ninth deciding vote, at this point in the year it probably wouldn't happen.  So essentially it...



LEO:  Defers it, yeah.



STEVE:  ...may end up coming down to who wins the presidential election.



LEO:  Yeah.  Well, you know what it's going to really come down to, and of course AT&T and everybody, Comcast, are spending a lot of money at this point on Congress members because ultimately, even if it fails in the courts, they expect Congress to - because FCC can only do what it does at the behest of Congress...



STEVE:  Correct.



LEO:  ...to rein in the FCC.  And that's the thing we've got to watch out for.  I'm glad the courts agree, though.



STEVE:  So, okay.  This is interesting.  The news came out, when was it?  It was weird, because it was like Sunday.  And I thought, what news happens on Sunday?  But Symantec purchased Blue Coat Systems for $4.65 billion.  Now, Blue Coat are the people that make the carrier-grade - which is to say very high-speed, high-performance, like NSA/FBI kind of stuff, I mean, like those are their customers - SSL/TLS man-in-the-middle gear, which is used by corporations and governments in order to intercept and decrypt otherwise encrypted connection traffic on the Internet.



And what's interesting is that Bain Capital - we all remember Bain Capital from the previous election.  That's Mitt Romney's venture capital firm.  They had purchased last year for 2.4 billion.  So it's nearly doubled in value somehow in the last year.  And so I guess Bain is happy.  Unfortunately, I was going to say, it'll be the bane of our existence.



So here's the problem.  And we talked about Blue Coat and Symantec a couple weeks ago because it was discovered that Blue Coat had a Symantec intermediate certificate which allowed that equipment to mint, on the fly, certs for any other sites that you were visiting.  I mean, and that's how these encrypted-communication man-in-the-middle systems work is, in order to function, they have to be able - you have to trust their certificates.



Now, what's completely different is that normally this is on the border of a corporate Intranet.  And all the systems running within that corporation have added a certificate so that they trust the certificates being created by that corporate box on the Internet.  So it's sort of like, okay, you're using - and we've talked about this often.  You're using corporate equipment, the corporate network.  You, as an employee of the corporation, you implicitly acknowledge, and maybe explicitly, that your communications will be scanned for security purposes.  Maybe that allows them to do content filtering, deep packet inspection as it's often called, and protect the infrastructure of the corporation.



So now what we have, though, is Symantec, which of course previously purchased Verizon - no, I don't mean Verizon.  The people I used to buy my certs from before I...



LEO:  VeriSign.



STEVE:  VeriSign.



LEO:  It's like Verizon, only just as bad.



STEVE:  Only different.



LEO:  Only different.



STEVE:  Same location in the alphabet.  So, of course, so now we have a certificate authority whom we all trust.  I mean, every system on the planet trusts these certificates which Symantec/VeriSign are minting.  VeriSign is one of the oldest original certificate authorities.  So this is sort of - so this is why this purchase generated some concern is that the manufacturer of the leading connection-decrypting appliance is now owned by the leading certificate authority.



Now, we talked about this a couple weeks ago, and I said, you know, okay, yeah, that seems not good.  On the other hand, remember that our browsers are now trusting upwards - I don't remember the number.  Was it like 800?  I mean, it's like everybody in the world.  And certificate authorities that are trusted exist in all major nation states.  And it's nave to imagine that none of those, for example, random foreign certificate authorities that we trust because we want to be able to go to websites that are using certificates that they signed, it's nave to imagine that someone in the government can't require them to produce a certificate to install in equipment on their borders to allow them to perform deep packet inspection.



And stepping back from all of this, I sort of found myself thinking, okay, well, what does this mean?  What this really means is that connection encryption had a brief, shining moment - and then it died.  That is...



LEO:  Sigh.



STEVE:  It's over.  For a while we would bring up a connection just to give our username and password in a way that someone passively eavesdropping couldn't see.  And even then it wasn't really secure.  I mean, that would prevent them from seeing our username and password.  But then the site was in a big hurry to switch us back to HTTP with a cookie, which is what kept us then logged in.  But the cookie over HTTP could be sniffed.  And that's what Firesheep did, which we talked about years ago, was it sort of automated the process of allowing somebody who would just be running Firesheep as an add-on to Firefox to grab all of the logged-on authentication cookies of everyone around them and just click on one to log in as them, to impersonate them.



So then, of course, we had this migration to encryption, where oh, you know, can't have that happening.  And processors got faster.  Servers got faster.  We got SSL accelerators.  And it stopped being the case that encryption was a performance and a computational burden on the server.  So it started to become ubiquitous.  Well, the powers that be don't want ubiquitous encryption.  So now there are appliances which will be minting certificates on the fly that will almost certainly not require our clients to have a certificate from the appliance.  They will be doing this, and we won't know.



And so the way to prevent this, or at least to be aware of it, is something we've also talked about, and that's certificate pinning, because what cannot be spoofed, no matter how much technology you have, is the fingerprint of the certificate.  And this, of course, is the way Google has been catching any instances of their certificates being misused like this, somebody else signing a Google.com cert, because the second Chrome sniffs a Google.com cert that didn't actually come from Google, all hell breaks loose because Chrome has embedded in it the valid fingerprints of the certificates from Google.  And if anyone ever tries to go to a Google property and receive a non-authentic Google-signed certificate, the browser immediately alerts Google.



So this is sort of, I mean, that's nice.  And of course this is why I built the GRC's fingerprinting pages because GRC offers this service where my connection, which is sitting right on the Level 3 backbone and definitely has no third-party appliance between it, my connection looks at the certificate and shows it to the user, and they're able to compare that with the certificate they have received.  And of course they should be the same.



So anyway, what I think this means - and everyone listening to this podcast has sort of watched my evolution over a relatively short span of time, going from thinking that this is a horrible idea that a corporation should be doing this, to then - I guess this is probably some stages of grief that I've gone through because at some point there's resignation, and then somewhere there's acceptance.  And then, you know, it's like...



LEO:  Did you get to anger and denial, or did we just skip right through that part?



STEVE:  And at this point I'm at the give up stage.



LEO:  Acceptance, yeah, that's it.



STEVE:  Because, yeah.  What this means is we need to plan.  And so, again, the listeners of this podcast, it's like, okay, wait, then what do we do?  Now what?  So things that we've been talking about for years, like TNO, Trust No One, it means that you yourself encrypt something, and you absolutely put no trust in the encrypted channel.  And actually, later on in the Q&A is an interesting thing that I've failed to mention about SQRL is that its technology is so strong, you don't need to protect it with encryption.  In fact, we had until recently in the spec you could use SQRL://, or QRL://, meaning not secure, and it doesn't care because it's completely safe against a man-in-the-middle eavesdropping attack.  It's that good.



LEO:  That's cool.  That's really cool.



STEVE:  Yeah, it's very cool.  So anyway, Symantec owns Blue Coat.  They say it's beefing up their corporate enterprise offerings.  And I'm thinking, uh-huh, yeah.  And so it'll make it much easier to deploy this technology in a corporation because I'll be very surprised, I mean, there's no law that I'm aware of that says Symantec - well, no, there probably is.  There's probably the CA Browser Forum would look down big-time on Symantec simply supplying certificates for that hardware which was going to be implicitly trusted because what that would - or, no, I guess it would, well, it would be Mozilla and Google and so forth.  It would be the manufacturers of the clients that implicitly maintain the cache of public signatures of the CAs which are used to verify the certificates.  Symantec would be endangering itself and the trust that our clients have in certificates signed by Symantec/VeriSign.



So anyway, bottom line is I don't think connection encryption is long for this world.  I mean, it'll be there, and it'll mean that we're no longer having in-the-clear connections.  But there will be little way points throughout the Internet where that traffic is decrypted, somebody snoops on it, and then it's reencrypted, and off it goes again.  So it sort of raises the bar, but it's no more like you have any clear reason to firmly believe that end-to-end encryption that is provided by standard off-the-shelf TLS with the public key crypto system, that that's going to be safe.  I just - there's no reason to believe that anymore, and lots of reason to say, eh, don't think so.  So we'll need to do something for ourselves.



Without any of us knowing it, Google's Chrome browser fixed a frightening bug which existed in its integrated PDF viewer.  The guys at the Talos Group of Cisco identified a problem with JPEG 2000 image rendering, which is the image renderer built into Chrome's integrated PDF viewer.  They notified Google, and it got fixed.  The open JPEG library doesn't have this problem - that's where this code came from - just because the build process prevented this from happening.  Google's somewhat different build process is what exposed this problem.  And what this meant was, while this existed, if it was known to anyone - and it's not clear that it was ever exploited.  But a malicious site could create a PDF which, if it were viewed by Chrome, would execute code in the context of the browser in the user's machine.



And this highlights, I mean, the fact that this did exist, it got found, it was reported, it was patched, and everyone got it, this is now the way this ecosystem has to work.  We've acknowledged that, in these very complex systems, no matter whether the code is open source or closed source, no matter how many people have looked at it, there are going to be problems.  What we need is exactly this kind of system.  We need a system where a researcher finds it, privately reports it, it gets patched, and that patch is automatically pushed out so that it's removed from actual use in the field.  And at that point the researcher is able to say, "Look what we found.  We know what we're talking about."  And users are not put in danger, and the problems are solved.  That's the model.  That's what everyone has to do who is producing complex systems with this level of connectivity.



And it was controversial in the beginning.  I remember when Microsoft first began to do this with Windows.  It was like, whoa, you're not patching my system without me deliberately knowing what's going on and inspecting it.  And it's like, well, okay, now it's, hey, it's June 14th; 32 bad things have just been found and fixed, so make sure you update your system soon.  It's the world we're in now.



LEO:  Well, I've just finished updating Windows.  It didn't take all that long, what, about 20 minutes.



STEVE:  Oh, and as a matter of fact, you mentioned it, and I'm looking at - now it did say 11 important updates are available, and one optional, 77MB.



LEO:  You know, that optional one you're going to love.  It's this thing called Windows 10.  You're just going to adore it.  But don't worry, you don't have to do anything.  We'll take care of it from here.



STEVE:  Just give it a try.  You'll love it.



LEO:  You're going to love it.



STEVE:  Speaking of which, we're at 1,150,000 downloads.



LEO:  That's amazing.



STEVE:  It's slowed down now to only 20,000 new ones a day.



LEO:  Oh, my god, that's amazing.



STEVE:  I meant of Never10, of course.



LEO:  Yes.



STEVE:  Okay.  So we talked in the last, actually the last couple weeks about this hacker named Peace, apparently short for Peace of Mind.  I'm not sure.  Maybe that's tongue-in-cheek.



LEO:  It's P-E-A-C-E, so no puns about piece of anything else.



STEVE:  That's correct.



LEO:  It's Peace, baby.



STEVE:  And of course he came in the news because he was the person offering the additional 117 million LinkedIn account credentials from 2012, which is what we believe tied into Mark Zuckerberg's breached Twitter account and "dadadada."  Somebody tweeted me my face during the podcast when you switched over to the dadadada.  I was like...



LEO:  It was very funny.  By the way, I after the show went to HaveIBeenPwned, and yes, my email address anyway showed up on all four.  The Adobe breach is a long time ago, the LinkedIn, MySpace, and Tumblr breaches.  But this was the thing that blew me away:  359 million MySpace accounts breached.  Only 164 million LinkedIn accounts.  So, whew.



STEVE:  Funny, the number I had is 360.  And I'm about to get to that.



LEO:  Right there, yup.  Anyway, just pointing out.  Of course I changed my passwords.  But just because you're in this database doesn't mean anything; right?  Those are old, probably old records, I would think. 



STEVE:  Yes.  And so he was back in the news because he is now offering 51 million account credentials obtained from iMesh, which was a peer-to-peer filesharing service started in '09 that just shut down last month.  And so these contain email addresses, usernames/passwords, IP addresses, location information, and other information on users.  Now, the good news is they were all hashed and salted.  The bad news is, unfortunately, they used MD5.



LEO:  Oh, well.



STEVE:  Which produces a short hash and is highly accelerated on many GPU platforms, so it just doesn't pose much of a barrier for anyone wishing to reverse those one-way hashes.  All of that data, the 51 million accounts, are currently on sale on the "dark web" for half a bitcoin.  And when I saw that half a bitcoin was $335, I went, what?  And I went over, and bitcoins are now, like, yeah, 650 bucks.  So Mark Thompson is a...



LEO:  Happy camper.



STEVE:  Happily cranking away.



LEO:  And no longer has to pay for heat.



STEVE:  So as a consequence of all of this - well, it is getting into the summertime, so I don't know what that does to this.



LEO:  Now he has to pay for cooling.  There goes all that bitcoin riches.



STEVE:  So as a consequence of Peace of Mind being in the news, Wired reached out, the editors at Wired reached out and posted a message in the dark web forum - it's called TheRealDeal marketplace - and said, "Hey, we're Wired magazine.  Would you be willing to talk to us?"  And they arranged some secure IMing and decided that - oh, and this Peace person said yeah.  So we know a lot more.  First of all, there is a seller rating system on this RealDeal marketplace, where the seller Peace has a 100% satisfaction rating.



LEO:  He does good work, that Peace.



STEVE:  He does good work.  A+++ feedback, and comments like "Follows up with questions and delivers promptly."  So when you're looking for 167 million user accounts from LinkedIn, this is the guy you want to go to.  So he does have a growing inventory - currently 167 million user accounts from LinkedIn, 360 million from MySpace, 68 million from Tumblr, the 51 we just talked about from iMesh, also 71 million from Twitter.  And then also there's a Russian social media site called VK.com.  He's got 100 million of those.  So we learned a few things during this conversation with Wired.  



LEO:  All right.



STEVE:  Okay.  So during this conversation, the IM conversation with Wired, the Russian hacker...



LEO:  Peace of Mind, piece of whatever.



STEVE:  Peace of Mind said, well - and so they were asking, like, okay, what's the whole deal here with selling these blocks of stolen, hacked, whatever?



LEO:  Are they asking him why he does it?



STEVE:  Well, sort of like what's the background.  And he said:  "Well, these breaches were shared between the team and used for our own purposes.  During this time, some of the members started selling to other people.  The people who we sold to were selective, not random or in public forums and such, but only to people who would use the data for their own purposes and not resell or trade.  However, after enough time went by, certain individuals who had obtained the data started to sell it in bulk, $100 for 100,000 accounts, et cetera, to the public.  After noticing this, I," writes Peace, "decided to start making a little extra cash to start selling publicly, as well."



So then Wired responded and said, well, "Why didn't the crew want to sell the whole collection earlier?"  And Peace explained, "It is not of value if data is made public.  We had our own use for it; and other buyers did, as well.  In addition, buyers expect this type of data to remain private for as long as possible.  There are many databases not made public for that reason and in use for many years to come."  So Wired says...



LEO:  That's interesting.



STEVE:  Yeah, isn't that?  Wired says, well, "What was your own use for it?  How were able to make more by selling the data privately?"  And he said:  "Well, the main use is for spamming.  There is a lot of money to be made there."



LEO:  So it's just the email address they're selling.



STEVE:  Yeah.  Well, no, using.  They're...



LEO:  Oh, using their accounts for spamming.



STEVE:  Correct.



LEO:  Yeah, okay.



STEVE:  He says:  "...as well as in selling to private buyers looking for specific targets.  As well," he says, "password reuse, as seen in recent headlines of account takeovers of high-profile people.  Many simply don't care," as he writes, "to use different passwords, which allows you to compile lists of Netflix, PayPal, Amazon, et cetera, to sell in bulk."  And then he finally said that they generally get somewhere between $15,000 to $10,000 and sometimes down to as few as a couple thousand dollars for a list.



But so really what was interesting was that there's more going on than is revealed publicly.  We're notified of major breaches.  Obviously one means is when the company recognizes itself that there was an APT, an advanced persistent threat of some sort.  The other way is when the evidence demonstrates somehow the data got away from them.  But then there's another classification, and that is databases that have been exfiltrated where, as he writes, they're more valuable if that fact is kept secret.  Meaning that in targeted attacks people are getting accounts breached, and that's because no one has notified them of a breach.  The site may not realize that it's been breached and had all of its passwords taken.  So I just thought that was some interesting - and yay for Wired for taking the initiative to do that.



LEO:  Yeah.  Very interesting.  I wondered myself, how does this get used?



STEVE:  Yeah.  So I just love this bug.  And I like the way Let's Encrypt handled it.  They were completely upfront and dealt with it immediately.  They wrote:  "On June 11," so that's three days ago, "we started sending an email to all active subscribers who provided an email address" - and I should mention that that's 383,000 subscribers - "informing them of an update to our subscriber agreement.  This was done via an automated system which contained a bug that mistakenly prepended" - and the way they first explain it is not the cool part.  They say "mistakenly prepended between zero and 7,618 other email addresses to the body of the email.  The result was that recipients could see the email addresses of other recipients.  The problem was noticed and the system was stopped after 7,618 out of approximately" - and here's the number - "383,000 emails."  That is to say 1.9% were sent.  



They said:  "Each email mistakenly contained" - here it is.  I love this.  "Each email mistakenly contained the email addresses from the emails sent prior to it, so earlier emails contained fewer addresses than the later ones."  So I just love this.  So there was a bug where some buffer of email addresses wasn't being zeroed.  And the recipient for this email was appended to the existing one in some fashion so that the longer you waited, the more email addresses accumulated in the email that was going out, up until some person, the 7,618th person, received all previous 7,617 email addresses.



So they finished, saying, "We take our relationship with our users very seriously and apologize for the error.  We will be doing a thorough postmortem to determine exactly how this happened and how we can prevent something like this from happening again."  Oh, that's good.  "We will update this incident report with our conclusions.  If you received one of these emails, we ask that you not post lists of email addresses publicly."



And, you know, I think that was - they handled it as well as they could.  As they say, stuff happens; and they 'fessed up and shut it down as quickly as they could.  But I just got a kick out of the idea that, as this thing was rolling along, doing their mass mailing, it was just adding email addresses to the existing ones.  Or they said it was in the body of the email, so maybe it was somehow transferring them in.  Who knows.  But anyway, whoops.



Microsoft raised some concern.  It actually first appeared on Slashdot and then got some coverage because a developer using Visual Studio 2015 discovered stuff in his binary that he didn't put there.  And it was unfortunately named "telemetry_main_invoke_trigger."  So it was like, wait.  I wrote some code, and I compiled it with Visual Studio 2015, and in my code is "telemetry_main_invoke_trigger."  So everyone of course is a little touchy about Microsoft these days, with all of the telemetry being not only in Windows 10, but also then being ported back into earlier versions of Windows just because Microsoft wants to know how we're doing.  So Steve Carroll, who is one of the high-ranking managers of the Visual Studio team, answered everyone's questions regarding what they're calling an "undocumented feature."



He said:  "Our intent was benign.  Our desire was to build a framework that will help investigate performance problems and improve the quality of our code optimizer should we ever get reports of slowdowns or endemic performance problems in the field.  We apologize for raising the suspicion levels even further by not including the source in the Common Runtime for this."  And they said:  "This was just an oversight on our part."



Okay.  Well, I dislike the idea that telemetry code is being embedded in everything that Visual Studio 2015 compiles.  But I'm not using Visual Studio 2015, and won't.  So for what it's worth, anyone who is, it would be nice if there was an option, if it was opt-in rather than just Microsoft assuming that we all want it and embedding it in binaries.  No, thanks.



And I did want to mention that next week's topic is something extremely cool.  Intel has a next-generation technology which they're hoping will go a long way to thwarting one of the major weaknesses in the bare metal-style exploitation.  We've talked about so-called "return-oriented programming," where return-oriented programming is a technique whereby malicious code can get around the problem that it can't execute its own data by cleverly finding existing code at known locations and using that to achieve its ends.



So, for example, the stack is often where short-term buffers are allocated.  And one of the tricks of old was that you would - say like this JPEG 2000 problem.  The system would fill a buffer with data from the JPEG image, and then that buffer would be on the stack of the system, and then a mistake in the JPEG interpreter would allow the instruction pointer of the processor to jump into the stack and execute the data as instructions.  Well, that got fixed by marking these various segments of memory as executable or not.  That was data execution prevention (DEP) that we talked about years ago, where the stack, which is meant to be data, the processor hardware would disallow executing any memory marked as data.



So then what the bad guys did was they said, okay.  They looked around in the kernel and found little snippets of code, like at the end of a larger subroutine, just it might only be a few instructions, that would do something useful.  And because it was already in the system, and it was actually code, that couldn't be protected with data execution prevention.  It had to be executable.  So they would jump to that location toward the end of a subroutine and get a little bit of work done.  And then the return instruction at the end of the subroutine would jump back to them.  Then they would jump somewhere else into some code, probably in the kernel somewhere, and get a little work done.



Okay.  So then the way to thwart that was address layout randomization (ASLR), address space layout randomization, where we started scrambling up where things were in memory so they weren't always at the same known location.  Problem is, turns out there's a lack, for architectural reasons, there's a lack of granularity in where things can be put.  They just can't be put on arbitrary boundaries.  They're generally pretty well fixed.  And it turns out there have been lots of ways that people have come up with for figuring out where things are in a way that doesn't set off any alarms.



Intel has a response now that solves this problem, potentially.  They call it CET, Control-Flow Enforcement Technology.  And it is very cool.  It will be next week's - get your propeller-head ready, wound up.  And I think it'll probably be fully unwound by the time we're done with that podcast next week.



I did want to mention my talking about SQRL, as I'm starting to more, that we're getting near release point.  I got an interesting note that evidenced some confusion.  Chris M. in Tennessee asks, he says:  "Hi, Steve.  Love the podcast and proud owner of SpinRite.  I have a question about SQRL compatibility."  He says:  "Will all websites work with it, or will each individual site have to turn something on for it to work?  Does it work with applications, or is it solely a website thing?"  He said:  "For example, will it work with the Dropbox or Google Drive applications on Windows?"  And he says:  "I got excited when I heard you talk about it, but then I started thinking that maybe I misunderstood what it was."



So, Chris, and anyone else who's wondering, it does require that SQRL be supported by the website that has chosen to offer it for login.  The good news is that the credentials it is storing in order to do its job are small, and all of the work, essentially, is done in the client.  The server-side just performs a single cryptographic operation, just the signature verification.  So the implementation on the server side - and this was all deliberate.  We wanted to keep the complexity in the client because we only have to make a few of those.  We need my client for Windows that also runs under Wine.  And so Linux and Macs can use it.  And I'm sure we will get native clients for those platforms.  Jeff's had his iOS client running for some time.  Ralph had the one under Android, and there's some guys working on their own Android clients.



The point is we need very few clients.  But those few clients can run on many, many more servers.  So we wanted the server side to be very simple and essentially minimal.  And so the idea is that it needs to store only a little bit of data per user and just perform a signature verification is the entire burden on the server.  So unlike a password manager, for example, where the password manager manages passwords, and either you remember your password or you use the password manager, but there was no server-side implication, SQRL does have a minimal server-side impact, so servers will need to decide that they want to support SQRL.



The flipside of that is they don't have to protect their databases.  We've spent a bunch of time so far talking about Peace and all of these credentials that he's exfiltrated from systems and the vulnerabilities.  We're constantly running around having to change our passwords when we find out that some major site has had a breach.  All of that goes away.  Websites no longer even need to keep those credentials secret as a consequence of the way SQRL works.  So it has the potential of solving, not only the problem from the user standpoint, but it completely removes the burden of having to keep these secrets secret over on the server side.  And that's huge, another reason that I think we'll probably see some adoption driven.



I wanted to mention, we were talking about Let's Encrypt a minute ago, and the email screw-up that they had.  I had an amazing experience Saturday evening, 7:30.  I'm sorry, Sunday evening, 7:30.  I was, as I mentioned to Leo before, I think before the podcast, I was bringing up a new server for GRC and got to the point where it was all working under HTTP, and I needed to bring up encryption.  And I thought, you know, I need a certificate.  And I use, as everyone knows, DigiCert's certificates and services.  And I like the green bar to show up on iOS devices and in browsers and to get the extra treatment.  Let's Encrypt, of course, has been a huge success only providing domain validation, which is the only level of a certificate they offer - not organization validation, that is, OV, nor extended validation, EV certificates.



Anyway, the point is that about maybe two months ago DigiCert contacted GRC and said, hey, it's time for us to reverify your corporation information.  And we weren't getting a certificate at the time, and I remember thinking, wow, that's, okay, proactive.  And I didn't really get it.  Except I was able Sunday night at 7:30, thanks to DigiCert having been proactive, having recent current information about GRC, company ownership, status and all that, everything that you need to do for the extended validation certificate.



As a consequence, I was able to mint my own DV certificate on a Sunday evening and have it in about 10 minutes.  I mean, from start to finish, 10 minutes.  And I just thought, okay, this is too cool.  And so I put a note here in the show notes just to say, yes, Let's Encrypt will give - oh, there's Fred.  I forgot to mute this iPad next to me, so it's been making noises during the podcast.  I apologize.



So, yes, Let's Encrypt does domain validation.  But for anyone who needs and wants a higher level of certification, organization validation or EV, extended validation certs, I've never had - all of my experiences with DigiCert are amazing.  And I get feedback from people who have followed me into DigiCert and said their experiences have been similar.  So I was just sort of sitting here two nights ago at 7:30 thinking that was amazing.  Now this new server that I'm bringing up has an EV cert 10 minutes after I set about making it happen.  Wow.  How the world has changed for the better.



Maybe six weeks ago or so I feel like I was a little bit snarky about something, and I wanted to correct the record.  And this was with regard to the books by Richard Philips, whom we've talked about before.  He has a trilogy called the Rho Agenda, R-H-O Agenda trilogy.  "Second Ship" is the first one.  And in fact he has a website, SecondShip.com, just like a web page placeholder there.  And then "Immune" is the second book, and "Wormhole" is the third.  Anyway, he then wrote a second trilogy which is actually a prequel to the Rho Agenda trilogy, which explains where Jack and Janet came from.  They're two cool, super-secret spy people who we're introduced to in the Rho Agenda trilogy.  And so he goes back in time, and he wrote three books there.  And now he's started on the sequel to the original trilogy.



And the point is, I just reread all seven of them.  There's the original trilogy.  I guess I started by reading the Jack and Janet "Once Dead," "Dead Wrong," and "Dead Shift."  Then I reread "Second Ship," "Immune," and "Wormhole."  Then I read "The Kasari Nexus," which is the first of the next trilogy.  And I just had a ball.  Leo and I were talking before the podcast about Peter Hamilton.  And there's sort of a different style that they have.  And what I felt I was a little snarky about was just being, like, as if to say, well, Richard's aren't as good.  And I retract that completely.  I just had...



LEO:  They're different.



STEVE:  ...so much fun.  Yes.  They're, for one thing, Peter has never written a short book in his life.  And so on the Kindle it shows little dots for where you are in the book.  And the Hamilton novels, if you load them in the Kindle, it rescales all of the dotting for all the other books so that they shrink down because Peter's are just all so long. So these are just - they're fun.  If you are a Kindle Unlimited subscriber, as I am, they are also all free.  So if you're just looking for - if you haven't read them, then I can recommend them without reservation.



I would start with the second trilogy, which is the prequel trilogy, starting with "Once Dead," then "Dead Wrong," then "Dead Shift," just because then you're reading them in proper temporal sequence.  And then the Rho Agenda, and then into the next trilogy.  The bad news is he isn't finished with the next trilogy.  I think we get the second of the final trilogy later this year.  So for what it's worth, without reservation, I know that people have read the Rho Agenda series before.  But I just found all of them.  I just reread them all and really, really enjoyed them.



LEO:  Cool.



STEVE:  And, finally, a note from Dan Hankins in Scottsdale, Arizona, who asked an interesting question, I thought, in the spirit of this being a Q&A episode.  He asks:  "Does SpinRite mask impending catastrophic failure?"  And it's like, oh.  Now, remember that we talked a couple weeks ago, someone else, another listener introduced the notion of zombie drives, where he kept saying, you know, drives keep failing, and SpinRite brings them back to life, so they're zombies.  They're like life after death.



And so Daniel says:  "I run SpinRite in maintenance mode" - or I guess he means for maintenance purpose.  There really isn't a maintenance mode.  It just fixes whatever it finds.  He says:  "...in maintenance mode on all my drives a few times a year.  Then I had a thought:  How am I to know when a drive needs replacing?  If SpinRite keeps fixing up a drive that's becoming increasingly marginal, the first warning I'm likely to get is when the frequency and density of errors overwhelms SpinRite's ability to correct them.  At what point" - I'm sorry.  "At that point, wouldn't I be left with a used-up drive that even SpinRite can't fix?  If I'm using SpinRite to keep my drives running smoothly, what should I look for to tell me when it's time to retire a drive?"



I thought that was a great question.  So there is a screen that is worth looking at.  It's the SMART screen, S-M-A-R-T, Self-Monitoring - I always forget that acronym, S-M-A-R-T.



LEO:  Because it's not what you think it is.



STEVE:  Self-Monitoring something Reporting Technology.



LEO:  I always want to say "and recovering," but it stands for...



STEVE:  Yeah, it might be "and recovering."  No, it's not, no.  And reporting.



LEO:  It's not what you think it is, yeah.  It's something.



STEVE:  It's reporting.  I can't remember what the "A" is, though.  Analysis.  Self-Monitoring Analysis and Reporting Technology, SMART.



LEO:  That's it, that's it, yeah.  



STEVE:  Anyway, that's the drive's own publishing of its view of its internal state.  And so that's like metadata.  That's drive metadata, completely separate from here's a sector, read it, give me that sector back.  Or, no, here's a sector.  Write it.  Give me that sector back.  Read it.  This is metadata saying how hard it was to do that.  Did it have to work?  How is its spare sector pool holding out?  Those things show, and SpinRite will reveal them to you on that SMART screen.



So, Dan, while you're running SpinRite, you can just rotate through the UI and look at the different screens.  Just go look at the SMART screen.  I have a page on GRC that completely explains, with little highlights and callouts and bullets and everything, all of the different aspects of that SMART screen so you can figure out exactly what it's showing you and how.  And the point is that you're using it in maintenance mode.  You're not having any problems with your drives.  I would say, I mean, that's the ideal situation.  If at some point you do have a problem, then SpinRite will probably fix it.



But at that point then you need to decide, okay, am I keeping this backed up?  Would I be inconvenienced if it did suddenly die in a way that SpinRite couldn't recover?  So there is sort of a gray zone where you need to think about how much life support do I want to have SpinRite continuing to provide?  Because at some point, you're right, if the drive is absolutely positively determined to terminate itself, it will win that battle because ultimately it's the drive's responsibility to return data.  And if it just refuses, nothing we can make it do will get it to work.



LEO:  And that's just smart.  Steve Gibson, it is time for a Q&A.  Are you feeling smart today?



STEVE:  Ready to go, yup.



LEO:  Raring to go?  Well, you chose the questions.  You probably have had time to think about the answers.  So I'm going to assume the best.  This comes to us, first question, on the Twitter from Scott Norris.  He's @scottnorris2012.  He says - I love this.  Can a six-digit PIN, numeric, ever be safe for online banking, even with other mitigations?  What if the database were published, for instance, as we just described?



STEVE:  I thought it was sort of an interesting question.  That is, our first reaction might be to say, oh, no, no.  There's not enough entropy in a six-digit PIN.  On the other hand, that's one in a million.  And so the point that I wanted to make is that the question really comes down to how that PIN entry is managed.  That is, there's a one in a million chance for - if we assume the PIN was assigned randomly.



So one concern is, if the user is assigning their own PIN, then there's a problem because people are not good with random stuff.  I mean, it's almost - it would be very surprising if the six digits itself were high entropy, if it wasn't something that the user chose thinking, oh, well, this really doesn't matter; right?  So it was something easier than six completely chosen at random digits.  So one concern is that the actual entropy in user-chosen six-digit PINs is way lower than one in a million.  So that's a reason that our multifactor authenticators, like the one-time six-digit authenticators, as we know, that's not really - they are six digits, but we all remember that the fifth digit, well, the sixth digit, I'm always numbering from zero, so technically.



So one of those digits is incrementing to show, to sort of perform better time synchronization so we don't get a high level of misfires when the clocks are out of sequence.  But if six digits are, for example, in an SMS message, where it's not time-based, but it's just "We've texted you this PIN to your phone, what is it," those are chosen at random.  Then you've got literally full entropy, one in a million chances of guessing.  So the point is that one in a million chances of guessing, if the system also has good lockout, is probably still secure.  That is, if it just lets you guess constantly without limit, then we could say, okay, there's just not enough entropy there.



It would be feasible for a million guesses to be produced, just exhausting the whole search space.  But if, after one or two mistakes, the system says we're sorry, you're locked out until you then provide some additional level of authentication, yeah.  I mean, just saying "six digits" isn't enough.  It absolutely depends upon how the six digits are chosen and how the system that authenticates them behaves itself.  But I could see something - I wouldn't feel comfortable doing it, but I could argue that, yeah, it could be made safe.



LEO:  Fair enough.  But of course most of time, why bother?  I mean, why not have a stronger password?



STEVE:  Right.



LEO:  Matthew N. Dudek, who is @mndudek on the Twitter:  Steve, I have a request for a podcast topic, or at least a Q/A session.  Can you review BitTorrent Sync at GetSync.com?  I'm interested on how secure it is, but also how it works as far as how it uses the keys and identities and ports and network connections.  Is it possible for the same key to be generated?  Is the data encrypted as it's synced?  And how does the user's identity factor into it?  Thanks again for a great show.



STEVE:  So Matthew, you have asked a question that I have been asked so many times. 



LEO:  And we've answered.



STEVE:  And, well, I would dearly love to answer.



LEO:  To the best of our ability, yeah, right.



STEVE:  Right.  And they even released a whitepaper about a month ago which says nothing.  Since the very beginning, I was in touch with them.  I made the mistake of starting up a relationship with their PR flack, and unfortunately that's the best way to describe the guy.  Then I started getting spammed with promotional nonsense about how wonderful this is.  And I said, you know, tell me how it works.  Get somebody who can produce a specification.



Now, apparently the protocol has been reverse-engineered because we did talk about it being available, there being a compatible clone on GitHub somewhere.  But what was beautiful about working with Joe Siegrist at LastPass was that Joe said, yeah, here's how the entire system works.  I mean, he even produced a web page that had readable JavaScript that demonstrated how the encryption/decryption system worked, answered all the questions, published and produced all the information, which is what allowed me to say, okay, these guys nailed it.  This is what I'm using.  And I did.



Unfortunately, the BitTorrent guys, for whatever reason, don't feel they need to do that.  Clearly, people are using it without any idea how it exactly works in an official document for them.  And so my feeling is, sorry, I'm not going to help you guys to promote this if you won't tell me how a secure system functions.  Maybe somebody they'll get around to doing that, in which case I'll definitely do a deep dive into it.  But at this point they won't tell me.



LEO:  It underscores my position all along, which is you want to use, if you're going to rely on something like that, you want to use open source because you want to be able to validate that it does what it says it does, know what technologies it uses, et cetera, et cetera.  That's kind of the whole idea.



STEVE:  LastPass was not open. 



LEO:  Right.



STEVE:  But it's open technology.



LEO:  Well, you looked at the source; right?



STEVE:  It's open protocol.



LEO:  Right.



STEVE:  Yeah.  So, I mean, open source means that you could, you have the ability to check it.  However, we see as many problems at OpenSSL as in anything else.  



LEO:  Right, right.  But it got caught, and it can get fixed, because it's open source so people can review it.



STEVE:  Right.



LEO:  And the problem is, in closed source software, you're just kind of saying, well, I trust you.  I use BitTorrent Sync.  And I use it to back up my Minecraft server.  So it's, like, not a high-security issue.



STEVE:  Mission-critical, right.



LEO:  Mission critical.  It's a really convenient way to back - so I take those three folders that are the Minecraft servers, and you get a unique number, as you know, you get a unique number.  You share that number with BitTorrent Sync running on another system.  And it'll automatically synchronize.  And I can do it on multiple systems.  So I can have, I mean, in that sense it's very convenient.  And so you're not saying don't use it.  Just don't assume that it's safe somehow.



STEVE:  Correct, correct.  And relative to open source, while we're here, what I would say is that I think it's the future.  That is, in terms of the arc of the industry, we began in a complete, I mean, there was no notion of open source.  It was proprietary software with ridiculous license agreements that left the users no recourse despite any problems the systems would have.



The good news is the open systems are continuing to mature and increase their breadth and capability.  I just brought up a complete front-to-back open source server with FreeBSD as the underlying Unix OS, Apache 2.4, the MariaDB instead of the MySQL database, and PHP 7, 100%.  And, I mean, it's fully functional.  And I'm completely happy that I can understand anything that I want to about it.  Nothing is hidden.  And it was a great experience.  So I really do believe, I think the future is in that direction.



LEO:  In more ways even than operating systems or servers.  I think even on desktops.  We're already doing it to a certain degree on Chrome OS.  And even Macintosh has - its underlying components are Darwin, which is an open source system.  History is on our side, on the side of open and free software, I think.



STEVE:  Yeah.



LEO:  And if you're talking about quality, I think you could say it's every bit as good.  In many cases.  Not in every case.



STEVE:  Yeah.  I would say polish, it lacks a little of the polish.  But it's getting better.



LEO:  As people who - as accomplished programmers continue to start contributing to these things, you're going to get better and better stuff.



STEVE:  Right, right.



LEO:  And what's nice is you might have a thousand people working on something.  And that's why keeping stuff up to date is in some ways easier.  But it also has negatives.  Software that's not popular doesn't do very well in the long run because you need a certain number of people supporting it.



Johannes Dankel in Chicago, Illinois wonders if Steve's running a double standard:  Steve, last week you went after Microsoft's claims that Windows 10 is more secure, saying only history can prove a system's security.  So what about SQRL?  Aren't you doing exactly the same thing by asserting SQRL's security as you have been doing?



STEVE:  I thought this was an interesting question.  And my response is that SQRL is unbelievably simple compared to Windows.  There is no - I was going to say there's no person that understands Windows.  There's no group, there's no team, there's no building of people up in Redmond that understand all of what Windows is doing.  And this is part of the problem is, as we know, complexity is the enemy of security.  The more complex these systems are, and the more unknowable they are, you know, how could anyone make an assertion about something they don't understand, that they don't know?



And so SQRL, by comparison, is drop-dead simple.  It is a few cryptographic operations.  And what's very cool is there's maybe 20 or 30 other people who each individually understand the entire thing.  So SQRL is so tiny that an individual can look at it and say, I understand the whole thing.  Well, okay, except for maybe the equations of the Identity Lock Protocol that I don't understand, except that I'm able to demonstrate that they're simple equations, and they hold, and it does what it says.  But really that's the difference.  And you'll also hear me say "as far as we know."  As far as we know, blah blah blah.  Because that's what any responsible crypto person says is you're always couching your assertions in "To the best of our knowledge, this is what we think."  Which is how I always try to address this.



But the beauty of SQRL is that it is so tiny.  It is completely knowable and understandable, comprehensible by just one person.  And there are many people who understand it completely and as deeply as I do.  And that makes it completely separate from Windows, which nobody understands.  There's nobody who could possibly encompass, whose knowledge could encompass Windows.  It's just too huge.



LEO:  Mike in Taiwan shares a chilling story from when he was in Greenville, South Carolina:  Steve, I enjoyed your last segment on the insecure baby monitors.  It brought to mind something I encountered in the early '90s.  I had just purchased a radio scanner.  I was scanning through the 49 MHz range.  This was around 6:00 p.m. on Friday before Memorial Day Weekend.  The scanner locked onto a carrier with the audio of a husband and wife arguing.  At first I thought, well, this is just a TV show.  But then I recognized the voice of my neighbors about seven doors down.



These neighbors owned - oh, this is amazing - a high-end custom diamond jewelry design store.  It was a family-owned, second-generation business, employing other family members, as well.  It seemed a sister had left the store earlier in the afternoon to head for the coast for the holiday weekend.  My neighbors were getting ready to leave for the coast around 6:30 to join her.  But shortly after the sister had left, they received a shipment of $100,000 worth of unmounted diamonds to the store.  The problem was the sister had left with the keys to the safe, hence the argument.



The husband was mad because they were going to have to cancel the trip and stay home to babysit the diamonds.  The wife said, "No, we can just put the package under the bed and stuff it up against the headboard, and no one will ever know.  Even if the house were broken into, no one would look there for anything to steal."  So they put the diamonds there and headed off for the coast for the long weekend.



If an unscrupulous person had overheard this, it would have been easy pickings.  The house backed up onto some woods.  All that person would have had to do in the wee hours of the morning, enter the property through the woods, break in through the back door.  They'd be in and out in 30 seconds, gone with $100,000 worth of diamonds, without anyone seeing them.



The range of these 49 MHz monitors was about 700 feet.  Flash forward to 2016 and the current crop of Internet-connected baby monitors.  Can you imagine the potential consequences if this conversation were broadcast worldwide?  So the warning is be aware of what you say and do around these monitors.  Also be aware that audio range is not just confined to one room.  It could pick up sounds from other rooms, especially if you're a noisy family.  Mike, currently living in Taiwan, formerly from Greenville, South Carolina - and, no, not $100,000 richer.  That's a funny story.  That's great.



STEVE:  I thought that was great.  And I've often spoken on this podcast about the analog cell phone days, when I was playing around with a scanner and listening to people's cellular conversations that they assumed were private and personal.  And it was like, oh, goodness.



LEO:  Woz admits to doing that.  Woz says it was great fun.



STEVE:  Oh, yeah.  I mean, it was - it's like, well, sorry, you're using a radio.



LEO:  And I can listen.



STEVE:  Yeah.  Anyway, so of course the flipside, the information had context because Mike knew the voices of these people.



LEO:  True.  He knew where they lived.



STEVE:  Exactly.  And so as I was thinking about this, I thought, well, okay.  If you had the IP address of this - you knew that you heard this conversation, had the IP address, then I was trying to think if there's any way to get the MAC address from that.  Maybe if you could localize it closely enough, if you could get the MAC address, then you might be able to drive down the street until you found where the WiFi was, assuming that they had WiFi in the house, and so forth.  But anyway, I thought that was just too fun not to share with our listeners, that, yes, you do need to be careful about what gets broadcast out of your home.



LEO:  Hysterical.  Nicklas Keijser in Stockholm, Sweden reminds us about the Shodan search engine:  To put a bit of a fine point on your excellent scary baby monitor coverage last week, if you have a paid account for Shodan, you can search for specific ports which require no authentication.  Images.shodan.io, paid version, search for port:554, that's the RTSP port, and you'll be even more frightened.  Wow.  If you don't have the paid version, just type "port:554 has_screenshot:true."  You'll still find them.  Yes, some baby monitors are there, but a lot of other stuff, as well.  No one seeing what's there right now would consider putting devices with known security problems online.



STEVE:  So we haven't talked - we've talked about Shodan a few times, and I've heard you mention it on other TWiT podcasts.  I went there; and, boy, has it matured.  It is nice-looking.  And I don't remember that it used to say "The Search Engine for the Internet of Things."  But it says that now.  That and refrigerators - it literally says refrigerators and buildings and power plants.  They're clearly having fun frightening people with what their machine finds.



And so what Shodan is, think of it as a port scanner for the Internet.  It's not just scanning port 22 or 23 or 25 for specific services.  It's scanning them all across the 4.3 billion IPv4 space and indexing it.  And so it's like, yeah, want to see what's on the real-time streaming protocol, port 554?  Sign up, and we'll show you what we found.



LEO:  Do a lot of things use RTSP?



STEVE:  Yeah, apparently a lot of cameras are using them to stream.



LEO:  Interesting.  Well, well, well.



STEVE:  Yeah.  



LEO:  Sean Schwegman in Huntsville, Alabama wonders about password managers:  Mr. G, Mr. G, would you offer your opinion on what to look for when choosing an app for storing passwords?  I currently use Keeper (KeeperSecurity.com).  However, like most people, I have no idea what to look for regarding effective encryption methods and best practices.  I can only trust what the developers publish on their websites.  Would you please take a moment and talk about what security methods to avoid and/or trust?



STEVE:  So I thought this was interesting because apparently, I don't know how long Sean has been listening to the podcast, but our longtime podcast listeners all know, as I was mentioning before, that when I looked at password managers years ago, I was searching for information.  I want to know how they work.  And it was the founder and designer of LastPass whom I was able to get the best answers from.  And so I chose them.



I don't know anything about Keeper Security.  But, for example, I just went to KeeperSecurity.com.  They have business and personal versions, or offerings.  And under the Keeper Free, as they call it, they offer the features of local password storage, single-device, and email support.  And then, if you pay $30 per year,  you get unlimited password storage.  So I guess that means that there's a limit to your password storage for the free version.  Unlimited devices and sync, and so we know that the free one is a single device without sync.  Unlimited secure cloud backup, so we know that the free one doesn't do cloud backup.  And unlimited secure record sharing, so we know the free one doesn't have that; and fingerprint login, so the free one doesn't have that; web app and 24/7 support.



So just in terms of - so I know nothing about the crypto level because none of that is available.  None of that is shown.  But what I do know is that LastPass, my chosen password manager, gives you all of that stuff that you're paying them $30 a year for in the free version.  So, and a complete disclosure of the technology, cloud syncing, multiple devices, runs on all the platforms, yada yada yada.  So there's been some concern that LastPass was purchased by - do you remember who, Leo?  I'm blanking on...



LEO:  Yeah, LogMeIn.



STEVE:  That's right, by LogMeIn.  We were a little concerned that big fish was buying little fish.



LEO:  Nothing bad has happened yet.



STEVE:  Yeah.  And I don't expect it.  I mean, I think Joe, you know, Joe is still at the helm.  And the acquisition gives him more resources.  So LastPass is my choice.  And Sean, the problem is, unless companies completely open their kimono and show us how their stuff is working, like BitTorrent, for example, with BitTorrent Sync, if they want to keep it proprietary, they can.  But people who care about the details are then unable to audit what they're doing and recommend it.  So I can't recommend Keeper Security.  And frankly, just what they're offering is not comparable to what LastPass offers. 



LEO:  There is an open source solution called KeePass that a lot of people like.  And you could at least verify those details for yourself on that.  The interesting, I mean, if you're asking what attributes to look for, one of the things you and I have gone back and forth over is the tradeoff between convenience and security.  LastPass stores your password database on their servers, which is of course inherently risky.  Not a big risk; but if their servers were compromised, and somebody got all the databases, they'd be able to try to crack them, brute-force them at their leisure because they'd have them.  And that's a problem with a password vault.  It's a single point of failure, all your passwords in one blob.



And so there are other password programs.  I think Keeper might be one that offers this, that allow you to deal with the details of syncing yourself.  You don't have to put your blob on their servers.  I know 1Password does it that way.  And so for some people that's more desirable.  1Password has other issues, which we've talked about.



STEVE:  Yeah.



LEO:  So it's hard, I think, for an end-user to know what to do.  I mean, you could look at - anybody could say AES-256.  But that's only a small part of the overall equation.



Larry Hamid in Ottawa, Canada wonders about trusting biometrics:  Steve, I was wondering if you had any thoughts or would consider doing a small segment on biometrics.  In particular, we've seen many biometric products and capabilities getting a lot of attention lately.  These include behavioral biometrics, like the way you hold your phone or the way you swipe, et cetera.  Others are wearables that monitor your EKG, your heartbeat.



Some years ago I was in the biometrics industry.  Back then we were bombarded with legitimate concerns and challenges regarding the accuracy of the biometric.  Have things improved?  To me, it seems strange that this sort of dialog has been lost, as if it really isn't that important anymore.  I'd like to know how the accuracy of a fingerprint system, for example, compares with some of the smartphone-based behavioral schemes that are being proposed.  That's a good question.



STEVE:  So we've talked about all kinds of biometrics in the past.  I've mentioned how getting into the datacenter at Level 3 required me to put my hand on a reader or a scanner in order to verify the physical properties of my hand, and then also enter a short PIN.  So there was two-factor.  And of course inside I'm under camera surveillance, and all of the individual facilities are locked, so there's a lot of security there.  And of course we were talking about fingerprint readers and the Apple products, for example, and now being made available over on Android devices also.



However, what we often see is that these things can be spoofed.  There's been some concern, for example, about this new facial recognition which has become popular.  But until that technology is actually able to do a 3D recognition to see that it's actually a curved face, what's been demonstrated is you just hold up a picture of the person and it unlocks because it can't tell the difference between a picture and the real person.  There just isn't the sophistication there.



Similarly, we keep running across, no matter what kind of fingerprint technology it is, people invariably create gummi bear fingerprint copies of various sorts and fool the fingerprint sensors.  So something that's even weaker than that, like how am I holding my phone, or the specific timing of the keystrokes as I enter my password, those we would call "heuristics," sort of seat-of-the-pants rules of thumb or weaker signals.



Stepping back from all of this, I just keep coming back to something you know.  To me, something you know seems like the ultimate better way to secure.  But the tradeoff, for example, that Apple has made, where you have a fingerprint that you're able to use under certain circumstances - for example, you can't use it if you haven't logged in for two days because they're wanting to protect the user.  So there's a set of tradeoffs to lessen the vulnerability presented by the weaker signal that I think all biometrics probably is.  And if that fails, then you fall back to something you know in order to say, yes, this really is me.



So, and I don't see this as a technology problem.  That is, I don't see it getting better in the future, except maybe the more parameters of the person you took, for example, a fingerprint and a retina scan, you sort of up the ante in order to create a composite signal from more biometrics.  And then, if you really care about security, also something you know, I think, is probably the way to go.  But biometrics, I mean, this is the classic tradeoff of convenience and security.  Biometrics are, almost across the board, implemented for convenience, not for security.



LEO:  There you go.  And it's always that tradeoff.



STEVE:  Yeah.



LEO:  Let's see.  Moving on.  Steve in Hong Kong, the one with the famous post office - I take it he wrote that - voices a SQRL worry:  Steve, in SN-563 you noted that SQRL allows an identity on a site to be reset without authentication, and access only then granted again by the use of a master key.  Isn't this a potential attack mechanism on SQRL itself, whereby users could be deauthenticated en masse?  Further, a man-in-the-middle attack could trigger a reset when it spots SQRL being used for authentication, and then simply sit and wait for the master key to be entered.  Just thinking aloud.  Thanks for all the great podcasts over the years.



STEVE:  So two things.  First of all, I wanted to make sure that I corrected the record.  It's not possible for just anyone to go and disable the SQRL identity.  He's using the word "reset," but he's talking about what I was talking about where you're able to disable the identity if you believe that your SQRL identity may have been compromised.  But you use your SQRL client to perform the disable.  So not anybody can just disable anyone else's SQRL identity.  You have to still use SQRL to tell the site, "Hi, it's me, but I want to now disable future recognition of me."  And so that prevents any sort of a denial of service of this sort on the system.



And then at that point is when you need the higher level of authentication provided by the so-called "rescue code" in order to say, okay, now I've got my rescue code.  I want to reenable access, and I'm also going to rekey the identity to solve this problem of being concerned that the identity may have escaped from me.



And then the other thing he brought up is this man-in-the-middle attack.  And I will say again that one of the coolest things about SQRL is it is so safe to use that you can do it over a nonencrypted connection.  Until only maybe a few months ago, this was an argument over in the newsgroup where all of this has been debated, is whether or not we ought to formally allow nonsecure use of SQRL.  And I finally sort of unilaterally said no.  Yes, it is secure to do that, but why?  We're in a world with Let's Encrypt, where we can get domain validation certs for free.  Encryption is the future.



I was worried that people wouldn't understand that SQRL is so strong that it could be exposed to nonencrypted communications without in any way reducing the integrity of the protocol.  And so I thought, there's just no - I understood the argument that there might be places for nonencrypted use.  But it's 100% encrypted on top of the existing security of the protocol.  So a little bit of belt and suspenders.



LEO:  Nothing wrong with that.  John in Montreal wonders whether a human brain really is better:  Perhaps you, as I, have experienced the horrible feeling that can overcome you when stopped at a traffic light and a car in your peripheral vision moves backwards.  Admittedly, this does not happen often; but when it does, your instinctive reaction is to assume that your vehicle is creeping forward.  You step on the brake with enough force to break it and nothing happens.  Panic sets in momentarily until you realize what is going on.  The trouble is that, during this period of confusion, really bad things can happen.  It is what cost Kennedy his life while piloting his small plane.  Who?



STEVE:  I wasn't sure.  I thought maybe you as the great repository of knowledge would know what Kennedy...



LEO:  I don't know.  I don't think - I don't know.



STEVE:  ...mispiloted his plane.  But this was interesting.  First of all, I loved John mentioning this because this has happened.  I assume it's happened to all of us, where for some inexplicable reason the car next to you goes backwards.



LEO:  John Jr.  It is actually what happened to John John.  That's right.  John Kennedy Jr.  I forgot, yeah, that's right.



STEVE:  Whoops.  Anyway, so I've had that happen to me, where a car next to me, in my peripheral vision, moves backwards.  And your assumption is you're moving forwards.  And so it's a bit of a jolting moment.  Anyway, I liked this because I wanted to follow up.  John was of course talking about following up on the self-driving car discussion we had last week.  And I've been thinking about it.  And what occurred to me is that the advantage the car has - and I can't believe I'm saying this because I can't believe cars are driving themselves.  It just seems too soon to me.



LEO:  Too soon.



STEVE:  But cars have the advantage of 100% vigilance.  They're not going to get distracted.  They're not going to be sleepy.  They're not going to be intoxicated.  They're not going to be arguing with somebody else in the car, or turning around halfway to make sure that the kids in the backseat are okay.  And I just think, okay, that's a substantial advantage, that the car is 100% irrevocably, permanently focused on its job, and it allows the people inside not to have to be so concerned.  So, yeah.  Again, it just seems too soon.  But, wow, that 100% vigilance factor I think is a significant benefit over people that are just inherently not 100% vigilant.



LEO:  One last question before we wrap this up.  And it comes from...



STEVE:  Oh, and this is the Incredible Tip of the Year. 



LEO:  Of the year.  It's from Jon Borgen.  He's local.  He's in Vacaville, California with an incredible tip for Windows administrators:  Steve, I just finished the podcast from yesterday.  You had mentioned you wanted to perform a clean install of Windows 7 on your new Carbon X1 from Toshiba - or Lenovo.  Says that you didn't have the drivers as Toshiba, but I think he means Lenovo.



STEVE:  Oh, yeah, he does say that, yeah.  He meant Lenovo.



LEO:  There's a terrific piece of freeware called Double Driver that I've been using for years.  It's made things like a refresh install so easy.  You can find the software at BooZet - not an auspicious name, B-O-O-Z-E-T -BooZet.org/dd.htm.  With it, you can view, backup, oh, backup and restore any and all drivers on your machine.



STEVE:  It's unbelievable.  But keep going.



LEO:  When you first run it and do a scan, it'll show you all drivers it detected - even printer drivers - and will automatically check the box next to everything that's not from Microsoft, although you can quickly "check all boxes" if you wish.  The default settings have always grabbed everything I needed, and I have never had to back up any of Microsoft's drivers.  After that, you can back up to either a single compressed zip file or a folder hierarchy containing all of your drivers.  I've experienced some issues in the past using the built-in compressed zip function, so I just usually back up the drivers to a folder and then manually compress the main folder if needed.



In addition to daily backups of my machine, I also keep an offline compressed zip containing all my drivers, just in case.  With the drivers backed up, you could either then manually install them one by one in Device Manager or use Double Driver again to batch-install them all for you, which is what I usually do.  The only issue I've run into is getting the drivers back onto the freshly formatted disk, as I've often been without USB drivers, so I can't use a thumb drive.  If the machine has one, the CD/DVD drive will usually work; but then you need to burn a disc with the drivers on it, and you also have to include the Double Driver utility.  I've forgotten to do that once or twice.



I believe the X1 Carbon, though, doesn't have a CD drive anyway.  In this case, before reformatting the disk, I would create a new partition from within Windows and put both the driver backup folder and the Double Driver utility on it, as well as any other files or folders you want to keep, and then reinstall the OS in the original C partition, so you can then access the driver backup natively from within Windows once you're back up and going.  I don't know if you were still looking to reformat that X1 Carbon or not; but, if so, I hope this finds you well.  Thanks for everything you do.  And you've got a link.



STEVE:  Well, okay, so here's the deal.  First of all, when I started reading this, I'm thinking, eh, what's it going to do?  Like copy the sys file or the something somewhere.  This utility is amazing.  I don't even know how it does what it does.  But it recreates the original set of files - the INF, all of the whole file set.  Because a Windows driver is not just one file.  There's a whole bunch of other registry gobbledygook and settings, and as I said, INF files.  There's a .CAT file and other stuff.  It finds it all and pulls it all back together.  So it's like what the manufacturer originally had, which allows Windows to install it.



Now, the bad news is, not only is BooZet.org a somewhat worrisome domain, but neither of the download links work.  The first link goes to Dropbox, with Dropbox complaining that there have been too many uses of the link, and so the account is shut down.  And the other link went somewhere else.  I can't remember now where.  It went to some strange page that didn't seem related.  So I thought, okay.  I have to find this.  So I went looking, and I found three copies of it.  And I was very careful because I'm not wanting to download malware into my machine, certainly not to recommend or cause anyone else to do so.  I found it on three different download sites.  And I took hashes of the three zips, and they're identical.



And one of the sites is one of Mark Thompson's very good friends, SnapFiles.com, which is a website I know through Mark, the guy who runs it.  He scans everything.  It's 100% aboveboard, and I would trust it completely.  So what I did for the podcast for all of the people listening to this that this sounds interesting, is I grabbed the file from SnapFiles.  You could certainly go there and get it.  But I put it on GRC.com only because - and I read the license agreement.  I'm not prohibited from doing that.  It is freeware, and it's freely available and copyable.  And I made it as easy as possible:  GRC.com/doubledriver.zip.  GRC.com/doubledriver.zip.



And again, I was just - I'm astounded by this thing.  This is - I wish I knew about this years ago.  But anybody who juggles Windows systems around who doesn't know about this, check it out.  It's very nicely written, brings up a clean list box of all the drivers in your system, as he said, with the ones that are not Microsoft checked.  There are options for "uncheck all," "check all," "check only Microsoft."  You can back the whole thing up into a directory hierarchy, which you then zip.  And then it adds its own little INI, which is an information file for it, which is what it uses if you want it to do the driver reinstall.



Anyway, I was so impressed:  GRC.com/doubledriver.zip.  I inspected the files, looked at them carefully.  And as I said, multiple download sites have the exact identical zip.  So I'm as comfortable as I could be without having downloaded it from the site of origin, because you can't, that this thing is legitimate and is free of any problems.  And I know that the place I got it from, SnapFiles, aside from it being absolute bit-identical to several other locations on the 'Net, this guy really checks the stuff over as well as - better than I would.  So there you go.



LEO:  I'd have to guess it's abandoned, where the program hasn't been updated since August 2010.  And the two things he links to, as you mentioned, one is a Dropbox, the other one is Ubuntu One, which is a service that was discontinued some years ago.



STEVE:  That's what it was, right.



LEO:  So I think that he's probably either passed or just completely lost interest.



STEVE:  And the site, when I saw - he uses jpegs, and it came up blurry and then slowly got clear.  And so it was doing incremental rendering on a low-bandwidth connection.  And I thought, wow, I haven't seen that for a long time.



LEO:  I think this has been in the closet, this server's been in the closet for a while.



STEVE:  Uh-huh.



LEO:  And maybe he got a job, I don't know.



STEVE:  I know that there are people who manage Windows, I know that Simon Zerafa, for example, will just be jumping up and down.  This thing is just - it's astonishing.



LEO:  Yeah, pretty cool.  Pretty cool.  Steve, we've come to the end of the show without error.  At least as far as we know.  But it there were errors, we'll let you know next week.  That's why you want to be here every week.  No, not for that.  You want to be here every week because there's always great stuff.  You can find Steve's SpinRite, the world's best hard drive maintenance and recovery utility, along with SQRL and all the other cool things he does, at his site, GRC.com.  He also has the audio version of the show and human-written, readable transcripts so you can read as you listen, or just read.  And search, great for search, too.  All of that, GRC.com.



We have audio and video of every show, of course, at our website, TWiT.tv/sn.  And let's see, what else?  You can find it everywhere because it's been around for a few years.  Just subscribe to the show on your favorite podcatcher, or use one of those great TWiT apps on every platform.  And make sure you come back each and every week.  You wouldn't want to miss it.  We do the show Tuesdays, 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  And you can join us in the chatroom, too, at IRC.TWiT.tv.



STEVE:  And next week have your propeller beanies handy.



LEO:  Oh, what are we doing?



STEVE:  Because we're going to do that cool look at Intel's solution to the problem of hackers being able to execute code on your system with this CET technology that further enforces and locks down what can be done when something malicious gets into your system and is trying to execute code that was never intended to be run that way.  That's Intel upping the bar in another very cool fashion.  So I guarantee everybody will have fun getting down at the bare metal level.



LEO:  Very cool.  Thank you, Steve.  We'll see you next week.  Bare metal level...



STEVE:  Thanks, my friend.



LEO:  ...on Security Now!. 



STEVE:  Bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#565

DATE:		June 21, 2016

TITLE:		Control-Flow Enforcement Technology (CET)

HOSTS:	Steve Gibson & Father Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-565.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  Father Robert and I begin by catching up with a week of mostly clickbait stories and case studies of real-world insecurity.  Then we take a very deep dive into the operation of Intel's forthcoming anti-hacking chip enhancement known as "Control-Flow Enforcement Technology."



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  And, boy, do we have a propeller-head episode for you.  Palantir got owned, but in a good way.  Two-factor is no factor with SMS.  Your cameras are probably spying on you.  And Steve pushes, pokes, and pops with stacks.  Security Now! is next.



FATHER ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 565, recorded June 21st, 2016:  Control-Flow Enforcement Technology.



It's time for Security Now!.  It's the part of the Internet where we only trust you if you trust no one.  And the man who trusts the fewest people is none other than Steve Gibson from GRC, Gibson Research.  Steve is my personal security guru and the big brain behind Gibson Research, SpinRite, and of course ShieldsUP! and the coming non-password overlords.  Mr. Gibson, it's so good to see you.



STEVE GIBSON:  Well, it's great to see you for a change.  We have Leo on vacation with his family, actually somewhere around here in Southern California.  I think they're doing the various amusement venues, and also being in a boat in Newport Beach or something.  So you're, I guess, filling in for at least this podcast.  I don't know if you're going to be doing any others, but we're delighted to have you.  We always get a lot of great feedback, Father, when you're my co-host.  So I'm glad for it.



PADRE:  Oh, that's fantastic.  I always enjoy it.  I will say, I like it that Leo's getting out.  He should enjoy life.  He should get out there.



STEVE:  We want to keep him fresh.



PADRE:  Keep him fresh.  But I do enjoy when he goes away because it means I get to chat with you for a few hours.



STEVE:  Well, and coincidentally, this ended up being a perfect one because, as I promised our listeners last week, this will be a wind up your propeller beanie and concentrate because what I want to talk about is for our main topic, after we cover the week's news, is some forthcoming hardware technology which Intel has added, or will be adding, to their processors to finally, hopefully, meaningfully help with all of these, like many -  well, not all.  But, well, maybe all of the buffer overrun problems, and many of the ways that hackers have found to cleverly exploit systems using vulnerabilities in code in order to essentially arrange to get their own stuff executed.  Intel calls this - abbreviates it CET, which is their abbreviation for Control-Flow Enforcement Technology.



So in order to talk about this, we're down where I live, down at the machine level, with registers and the stack and instructions and things.  But it's understandable.  So I think everyone's going to enjoy spending some time, not up in fluff land, but a serious technology podcast this week.  And you're a perfect co-host for it.  So it's perfect.



PADRE:  Well, I mean, it is an interesting list of topics.  It's basically everything is busted.  Our CPUs, our SMS, our data analytics, our Internet of Things, pretty much everything we use today is going to be kind of beat up today.



STEVE:  So there was a story about Palantir, the very well-known sort of security company that was actually founded with some CIA dollars, getting owned.  Some confirmation of something that I had said a couple week ago when I was choosing what second factor to use, a reason why SMS is really not something we can trust as much as we would like to.  A frightening true life experience with the Internet of Things, perfectly following on the last two weeks of topics.  Or I guess actually three weeks ago was we did a pair of episodes that I called "IoT Infancy," talking about the fact that the Internet of Things world is still trying to get itself going.



Also GoToMyPC had a massive password reset, but their coverage of their own problem was inconsistent and odd.  And then of course something that was probably the most tweeted thing to me was the story of a hidden rootkit computer underneath our main computer.  And so we're going to cover that and then get into a little bit of miscellany, but not much, and then a great topic.  So I think we have a great podcast for everyone once again.



PADRE:  Indeed we do.  And this will be the no-fluff, no-fat podcast, only the meat.  Only the best of the marrow is what we're going to be bringing you.  Steve, tell me about Palantir.



STEVE:  Well, you know, I got all worked up thinking, wow, how hired hackers got complete control of Palantir.  And so I dug into the story thinking that there would be a lot of meat there.  And I came away thinking that, okay, this is just clickbait.  First of all, Palantir hired a group of hackers and then deliberately let them in.  So it was like, wait a minute.  Okay.  So what they did was they simulated somebody within the company, well, the simulation was of their making a mistake, clicking on a piece of phishing email.  But everyone knew that was positioned to allow this so-called "red team" of hackers to establish a foothold within Palantir.



What was annoying was that this whole process, I mean, this sort of internal security review is something that responsible companies do all the time.  And I was annoyed because Palantir ended up with egg on their face, where the way the article came off was that they were blundering in some way, that they had made a mistake, like hackers got complete control.  And the real story here is that somehow the report that the security company generated under Palantir's pay and permission escaped to the press because that's what normally doesn't happen.  No, these reports never looked good.  They're not something that you want the public to see.  They're meant for internal purposes only.



And so I salute Palantir for being proactive about their security.  They simulated a very possible real-world event of somebody in the company falling for phishing email.  And then the test was, once people got in, what could they do?  And very much as we saw in the case of the Sony attack, any network which is sufficiently large and has been around for a while, stuff has been bolted onto the sides because, oh, we didn't realize we need another database over here; and oh, look, we need another, bring another website over there.  These networks, in large corporations especially, just sort of grow organically.  And what was originally well planned ends up just naturally evolving into sort of a Rube Goldberg contraption, which has all kinds of exceptions and corners that haven't been visited recently, and ends up not really being designed, but evolved.



And so, yes, the bad guys were able in a really large company to, once they got in, with Palantir's permission, to set up shop and find credentials and use some credentials to elevate their privileges and basically take over the network.  But again, the report they produced provided Palantir with really useful feedback that allowed them to then respond by fixing all of the problems that the employed benign hackers were permitted to come in to find.  So it was a little disturbing to see Palantir's PR branch trying to explain that, like, okay, this is the way the industry operates.  This is how a security-conscious company functions is you hire a red team to come in and see what they can do.  So, like, okay, on one hand, yes, these people got complete control.  But it was intended.  And Palantir benefited, and all of Palantir's customers benefit hugely.



PADRE:  That was the disturbing part of the story for me because, like you, I got a lot of people tweeting me links to this.  And all of the links were - they were link bait.  It was data analysis company that does work for the government is breached.  And that wasn't the story.  This is actually a security firm that did it right, that hired an outside consultation firm to come in and test their security.  They let them in.  So none of the initial borderline security was in play.  This was only what would happen if one of our employees accidentally let you into the network.  And a lot of the - I read a more detailed whitepaper on some of the hacks, and it was a lot of pivoting.  So that's one of the most difficult things to account for right now.



But if someone takes over a computer and then is able to pivot it to be the attacker inside, but they're smart about it, so that it doesn't always throw off attack traffic, there's no network I know that can survive that.  It doesn't matter how segmented your network is.  Once they start pivoting on the inside, they're going to get access to credentials.  They're going to get access to certificates.  But what Palantir did was they were very open about where the security flaws are, and now they can fix them.  This is what we want to encourage in the industry; right, Steve?



STEVE:  Right, right.  And so that's exactly right.  I think no one should be put off by this, the idea that they're being proactive.  I mean, for example, they're in a much better position today, except from a PR standpoint, than they were - I think this was done, I think it was in October and September, so the end of September and into October of last year.  And Palantir's customers have a stronger company they can rely on as a consequence, not a weaker company.



PADRE:  Right.  In fact, I'd go one step further.  I'd say if you're looking at trusting your data to a data analytics firm, don't trust them unless they release the results of their latest breach test.  I mean, that's what I'm going to be looking for.  I'm going to be looking for a company that is forthcoming about any potential hazards to my data while I have control of it.  So I want our audience to get out there and tell people, no, no, no, no, you've got that story all wrong.  The fact that you're hearing about it is good.



In fact, Dan Geer at Black Hat two years ago, his keynote address was all about transparent failure.  The goal of our industry should be 100% transparent failure.  When something happens, you should not feel ashamed.  You should not feel reluctant to release that information because that's how the security industry grows.  So, yeah, I'm with you.  I think this is something that [crosstalk].



STEVE:  Yeah, I guess the only modification I would make to that I that they never intended that internal report, which they purchased, essentially, from these hackers, I mean, the question is, how did this leak to the press?  Because this was juicy for the press.  And unfortunately the spin that got put on it, as you also saw, was a negative spin.  Instead, it was intended to be internal and to stay internal.  And so Palantir would say to their clients, either current or future clients, we hire red teams to attack our networks on a semi-regular basis so you can be assured that we're taking our internal security seriously.  And it just shouldn't have gotten loose because the value is to Palantir and to their customers, not to the public at large.



PADRE:  Right, right.  And hopefully I hear more.  I'd love to hear more companies release the findings of their penetration tests.



STEVE:  Yeah.



PADRE:  All right.  What about - on my device right now I have a super secure - I'm sorry, did you want more on the Palantir story?



STEVE:  No, no, no.  That was perfect.  I was just going to say that a couple weeks ago I was setting something up, and I don't remember now what it was, but I told our podcast listeners and Leo that I had a choice between having an SMS message sent for second-factor authentication, or using a one-time password, I mean, sorry, using a time-based, like a Google Authenticator or Authy-style six-digit temporal-based token.  And I didn't hesitate to choose the time-based solution.  And I said at the time that the reason I did that was that it's much more secure.



The idea there is that one time over a secure TLS connection to whatever the server was I was establishing this with, I don't remember now what it was, it provided me with the cryptographic information required, basically the key to key the standard time-based protocol, TOTP, which would then generate a series of six-digit numbers, given an authentication application.  And back then I said I'm not using SMS because the problem with, as we know, with our cell phone system is that it's not secure.  SMS messages are not secure.



And the way, with the choice I made during a truly secure point-to-point connection, I obtained one time a secret from that server which would then, for the rest of time, drive this time-based token generator.  And so never again would they need to be providing me with a secret on the fly, which of course is exactly what simple messaging system (SMS) messages does.  It's like every time you're logging in, send me a message to my phone, which I then look up and enter into the web page.



So anyway, this all kind of came back, and I got a kick out of this because a security company, Positive Technologies, put out a press release that popped up on my radar.  They wrote, and this is in press release format, I'll just read the first couple paragraphs:  "Positive Technologies researchers able to compromise many popular social media sites by hacking the SS7 network, intercepting a one-time password, resetting passwords, and taking ownership of accounts."



So they wrote:  "Positive Technologies, a leading provider of vulnerability assessment, compliance management, and threat analysis solutions, today confirmed its researchers have exploited a flaw in the SS7 protocol to intercept one-time passcodes used by many online services to reset passwords.  Facebook, WhatsApp, Telegram, Twitter and many other online services offer password resets via SMS message.  But instead of strengthening security, this ability actually introduces a vulnerability hackers can, and will, exploit.  Positive Technologies researchers recorded themselves demonstrating the hack against Facebook and WhatsApp accounts with the owner's permission, proving the dangers of this authentication method."



And so we had been talking about the SS7 system and how old it is and creaky it is and how, unfortunately, it's another one of these things where it was never intended to be secure.  It was intended to - it was originated to glue together separate cellular networks to provide like a call-forwarding technology from one network to the next.  And among many things it lacks is strong authentication.  There just isn't strong authentication as part of the SS7 protocol.  And we all know that, if you can't be sure who you're talking to, then you can't trust anything they tell you.  And you don't want to be giving them any secrets.  So we've heard anecdotal reports of SS7 protocol compromise.



But I love that here was an affirmative, yes, just the other day we did this.  The system is still broken.  And again, it sort of puts a point, a little bit of punctuation on what I was saying a couple weeks before when I said I chose a time-based authenticator rather than SMS for exactly this reason.  I don't want something secret constantly going through the cellular network every time I need to authenticate.  That's just not - now, okay.  Using it for password reset, there your window of vulnerability is going to be smaller.  But on the other hand, if you've got somebody who's set up looking to suck all of the SMS messages that go by in, and they're seeing six-digit codes or something obviously that is meant to be secure, well, then that creates an opportunity for them to grab it, so not good.



PADRE:  And you know, Steve, I've been telling my users for the longest time to use multifactor authentication.  It's the standard model - something you know, something you have, something you are.  And most of them have tried using some sort of, well, I get texted a password.  I get texted a unique number that I can enter in, and that's my two-factor.  And they get confused when I've told them don't do that because they think that's the something you have.  You have your phone.  But it's something you have that's receiving a transmission, therefore it kind of invalidates that part of the multifactor authentication equation.  I have seen a couple of apps, though, that will use secure communications, non-text, over TCP/IP, encrypted, that I do trust.  Would you trust that more than like a time-based RSA token?  Or are you still going with a token?



STEVE:  It just occurred to me that one way you can explain this is this is not - if you use SMS, it's not something you have, it's something you blab.



PADRE:  Right, exactly, yeah.



STEVE:  So not what you want.  So to answer your question, the issue is always authentication.  It always comes down to that.  And this is something that Leo and I go around and around about because like he was all excited about Telegram for a while.  And I said, well, yeah, but there's no authentication.  He says, well, but it's secure.  It's like, yeah, maybe.  But if you don't know who you're talking to, if you don't know who it is secure to, then it could be a man in the middle.



And frankly, I'm even skeptical of systems like iMessage.  I've talked about that.  The problem is they're handling the keys for you.  Yes, it's hugely convenient.  But the tradeoff for that convenience is that, since Apple is providing the keys under which the messages you send out are being encrypted, they could toss in an NSA key, and who would know?  I'm not saying they are, but they could.



So messaging apps, for example, have to have, I mean, if you really care - and there's a spectrum of how much this really matters because remember, even if you have super-secure messaging with authentication and encryption, if you're using a phone which has been rooted so that there's something in there watching you send stuff before it's encrypted and capturing it after it's decrypted, outside of the point-to-point encryption, then you still don't have security.



So one of the things, sort of one of the concepts we've been looking at more in depth recently is sort of the fallacy of absolute security.  So, yes, we want security.  But unless we went out onto the beach and got some sand and extracted the silicon and then designed our own chip and wrote all of our own software, that to the degree that we're trusting anyone else, or as you started the podcast off with Trust No One, well, fact is it's totally impractical not to trust anyone.  We have to.  Otherwise we'd get nothing done.



PADRE:  Right.  I was actually just about to ask you that because, yes, if whoever's doing the authentication for you is compromised, you've got a problem.  If the end device that you're using to receive your authentication is compromised, you've got a problem.  But, I mean, even if you're using a time-based security, you still have a server that's running the time-based equation and then authenticating against your token.  If that's compromised, then you've got a problem.  At some point you have to assume, and I know that's a horrible, horrible thing to do in the security world, but you have to assume that some level of security is trustable.  Right?  And it can't just be you.  It can't just be your equipment.



STEVE:  Correct.



PADRE:  Something out there you have to trust.



STEVE:  Correct.  And, for example, I've been deep into SQRL now for quite a while.  What SQRL does is it is, as far as I know, the most minimal requirement for trust of anything we've got so far because it is only a compromise of the secret in your client which represents a vulnerability.  The beauty with SQRL is that, because servers are dynamically challenging you to sign a secret, and all they have is a public key representing you, which is only valid for that domain name, you're not requiring them to keep any secrets.



So exactly in your example, Padre, they don't have a key which they're trying to keep secret which generates the one-time, the time-based token.  And if that got loose, then anybody else would know what it was.  So the vulnerability you point out is exactly correct.  And SQRL doesn't have it.  So ultimately what I think is going to happen is we'll end up with something like SQRL for YubiKey, where that one master secret which we have to keep secret ends up being in a little piece of easily managed hardware, and then it's just not possible for it to get loose.  And you don't want to lose it, though, either.



PADRE:  But that's the right way to think about it.  I don't trust you; but I know that, even if you let all this out, it doesn't compromise me entirely.



STEVE:  Right.



PADRE:  That's kind of - I think that's the best-case scenario.



STEVE:  Right.  Sort of in terms of trust perimeter, SQRL has - or maybe diameter - has the smallest trust diameter of any of these technologies that we've been talking about so far.



PADRE:  Wait, did you just coin a new phrase?  Can we TM that, trademark it?



STEVE:  I like that.



PADRE:  Trust diameter.  I like this.



STEVE:  The trust diameter, yeah.



PADRE:  Hmm.  Someone, oh, hold on, no, don't, don't [crosstalk] the domain.



STEVE:  Maybe radius.  Trust radius?



PADRE:  Trust, oh, trust radius, oh, that's even better.  Trust radius.



STEVE:  That's better.



PADRE:  How about a trust sphere? 



STEVE:  Because you get a little radius in there, too.  You want radius.



PADRE:  Of course.  All right.  Yeah, you can't trust SMS.  But you know what I can trust, Steve?  I can trust my home security cameras.  I know they're rock-solid, designed from the ground up to keep me safe and not let anyone else into the most private parts of my life.



STEVE:  Okay.  So the timing of this could not have been better.  The IoT Infancy - oh, by the way, we did coin an acronym there, and that was I Don't IoT, which of course is I-D-I-O-T.



PADRE:  We used to call that an ID-10-T error.  When you had a user who just wasn't there, and you needed to convince them that it wasn't their fault, you said, "Oh, yeah, see this all time, it's an ID-10-T."



STEVE:  That's good.  So the original IoT infancy podcast was going to be about baby monitors.  But I ended up breaking it up into two podcasts because there was just too much to talk about, and the details were just so juicy of the ridiculous lack of security that these technologies had, things like the URL that you used to go to a website to view your baby cam on the 'Net.  The URL had a serial number, and you could just change some digits and view other people's babies.  It was just, I mean, just horrifying lack of security.



So then when this popped up on Reddit, I thought, oh, this is wonderful.  So the title of this article on Reddit was "I bought and returned a set of WiFi-connected home security cameras.  Forgot to delete my account, and I can now watch the new owner."  So this guy, oh, it's just horrifying.  This guy wrote, he writes:  "A few months back I purchased a Netgear Arlo home security camera set.  I set up an online account, connected the cameras, tried them out for a few days, and ultimately changed my mind.  They were returned to the store, and I never gave it another thought - until today.



"I got a random email alerting me that the camera had detected motion, but I don't have any cameras.  So I logged into my online account, and I can see the new owner, their house, and everything they're doing.  Netgear obviously doesn't have a system in place to prevent cameras on multiple accounts.  If I'm not mistaken, anyone could get the serial number off your cameras and link them to their online account, to watch and record every move without your permission.  A creepier dream.  Does anyone else see this as a serious security flaw on Netgear's behalf?"  And then he says:  "I'm even happier that I returned them now."



And then in a subsequent edit he said:  "I left a message with Netgear this morning," which was yesterday, 6/20.  He said:  "Received a return call from a Senior Support Engineer saying they're aware of this issue.  Since the cameras aren't supposed to be resold,"  he says, "I suppose they didn't think it would be an issue."  What, are you supposed to destroy them and get credit?  Anyway, he says:  "I was assured they were working on a fix within the next three weeks to prevent cameras on multiple accounts and force a hard reset on the cameras, if cameras were previously registered in the system."  Oh, and I should note that I tweeted this earlier, and several followers said, "You know, I have those cameras, and the same thing happened.  You just plug them in, and they don't ask any questions.  Everything just works."  And, oh.



PADRE:  Here's the sad thing, Steve.  This is not just a Netgear problem.  I have seen this on so many cameras where the only thing that protects you is either a registration number that they've created and put into the firmware, or more likely it's the MAC address.  You have to know the MAC address.  And I've seen way too many supposedly secure products that use a MAC address as a layer of security, which it was never designed to be.



STEVE:  No, you're right.



PADRE:  In fact, JammerB, if you go back to the screen real quick, this is an actual - this is posted on that Reddit page.  So if people want to go and find out what this owner is doing right now, they could just use that.  The information that's on this label right now you could use to get into that camera.  In fact, you could go down to your local Best Buy and take pictures of all of these tags and then just wait for them to get bought.  And unfortunately I've seen this, and I won't name any of the other manufacturers, but a lot of the other companies that compete in the same space as Netgear are doing the same low-cost authentication, which is - it's sad.



STEVE:  Yeah.  So this returns to the theme of IoT infancy.  The only way to regard this is, first of all, we're in an incredibly early stage where companies are rushing to get their products on the market.  And I'm sure that the front of the box says "Secure encrypted webcam system."  I'm sure that's a bullet point.  And here's the consequence.  I mean, here's the reality of it is that the architecture offers none of the secure encryption.  Maybe the connection is.  But obviously anybody who's able to get on the website and see what's going on in the new owner's home, oh, wow.



PADRE:  You know what I think, when I think about this, I think of the GM hack that they did.  Was it Black Hat and Defcon last year?  I think it was last year where they found out that the only security was the IP address range.  So they just thought no one's going to guess the IP address.  Well, I mean, once you had one device, you knew all the other devices are probably going to be near that, so you just kept scanning it until something responded.  And it's this sort of lazy security that lets people think that, well, I paid a lot of money for this device.  Therefore, it must be secure, which is completely not the case.



STEVE:  In fact, that's exactly the way ShieldsUP! first got created because I had the first, back in the early days, the first - it was a DSL or IDSL connection for GRC.  And I don't remember if we had multiple IPs or just one, and maybe an early NAT router.  But I had a public Internet Protocol address, an IP address.  And I thought, I wonder what's in the neighborhood?  And so I scanned, like, plus or minus a hundred IPs and found all these C: drives, all these other Windows machines with their C: drives exposed.  And it was like, oh, my lord.  Someone's got to do - someone's got to raise the flag about this.  So of course I created ShieldsUP!.  And, boy, in the early days of ShieldsUP! people went there, and I showed them their C: drive.  You could browse your own C: directory on my web page.  It was just horrifying back then.  So there was an example of another aspect of infancy.



That was the infancy of Windows machines' first contact to the Internet, and that was the reality.  Now, as a consequence, all ISPs now block ports 137 through 139 and 440 - is it 445 or 443?  I always get those confused.



PADRE:  443?



STEVE:  One is secure email.



PADRE:  Right, 443.



STEVE:  I think it's 445, and 443 is email.



PADRE:  Okay, thank you.



STEVE:  Anyway, so all ISPs block that in order to protect their own clients, who may still somehow have a drive on the 'Net not behind NAT, not behind a software firewall, just exposed and flapping in the breeze.  But anyway, so the good news is there's hope.  We are at this stage now with webcams and home security systems and so forth.  We were once at that stage with people's hard drives on their computers.  And we're finally, it took a long time, but now we're secure.



Unfortunately, I think this is going to be similar escapades for a long time on IoT, until we finally get some standards.  I think what we're going to need is some sort of standards body to come in and establish the way this stuff has to work and come up with a protocol.  Because right now it's the Wild West.  Every manufacturer just does whatever they want to, as little as they want to, and then stamps "It's secure" on the box.  And people at Kmart say, "Oh, let's get some cameras," and stick it in their cart, and off they go, and now everybody else can see what they're doing.



PADRE:  I remember a few years ago it was Access Communications, which sold high-end cameras, I mean, way more expensive than the ones you would buy at a consumer Best Buy.  But unfortunately, the login page was searchable, so Google could index it.  And you could look for a particular page that would bypass security.  So you would just do a Google search for this one page name, and it would list all the cameras, the Access cameras, that could be bypassed, just by clicking on the link.  It was a little bit scary.



But Steve, it's funny because all of these zero-configuration devices - and again, Netgear, D-Link, think of the lower cost hardware.  Most of them are built off of a singular reference design.  I mean, if you crack them open, they vary very little on the inside.  And the reference design was created, along with its firmware, for you to improve upon.  And some of these businesses have not improved upon it.  All they've done is they've added their branding.  And then they add a password screen, which is really just a couple of lines of code that compare one string against another string.  And that's it.



And I'd love to get your input on this.  We've had talks at the last three CESes, the last two Black Hats, the last two Defcons, from high-level officials in the U.S. government who are saying, look, we understand that you're in a rush to get your creations out into the market, but security can no longer be an afterthought.  Because that's what it is right now.  It's get it working, and then I'll think about security later.  Well, unfortunately, it stops at the "get it working" part, and security is tacked on as an afterthought.  How do we change that?  Because it's so difficult for some people to think security first.



STEVE:  Say, for example, and while you were talking I was trying to come up with a way, something that would be foolproof, that would allow a device to know if it should randomize something in itself.  And so, for example, imagine that, okay, because we know there's a lot of technology in these things.  Often there's a little Linux microkernel.  They've got firmware.  They've got nonvolatile storage.



Imagine if, when power comes up on this thing, it reaches out to well-known NTP servers and checks the date.  And that allows it to know autonomously how long it's been powered off.  And if it's been powered off more than some period of time, like 24 hours, it has to be repaired in some fashion.  It just decides, okay, I'm no longer going to trust my own current configuration.  The user's going to have to do something in order to reassociate the camera with their account, something like that, so that it can still be simple, yet it can protect users from themselves because that's what they need.



PADRE:  Right.  I want to bring up something from the chatroom real quick because [pschops] brings up a good point, something that a lot of us think, which is, and I quote:  "If only companies were liable for lapses in security, things would get straight pretty quickly."  I understand that.  I understand that sentiment.  I feel that way sometimes.  However, there is the flipside to it, which is you want to reward companies for being honest.  And if a company thinks it's going to get dinged for a security lapse, they are much more likely to sit on a potential security hole, rather than announce it immediately.



STEVE:  Ah, good point, yes.



PADRE:  So many of the best policy examples I've seen have been, if you announce a security hole within the first 10 days of you learning about it, then you get sort of a blanket immunity because you were trying to do the right thing.



STEVE:  Or how about if we add to that concept, if they open source the software, then they're also let off the hook.



PADRE:  Right.  Precisely.  Yeah, if you allow it to be vetted...



STEVE:  [Crosstalk] the ability.



PADRE:  And that's, I think, because we can talk about security vulnerabilities all day, and they're fun because we get very creative when we look at ways of getting around authentication.



STEVE:  It's a target-rich environment.



PADRE:  It is a very target-rich environment.  But ultimately, as security professionals, we want our fellow professionals to have a reason to do the right thing.



STEVE:  So...



PADRE:  What's next?



STEVE:  So this story, I don't really know what the truth is because GoToMyPC - and they've been a sponsor of the TWiT Network through the years.  I don't know if they are still today.  But of course their parent company, Citrix, has been a longtime sponsor.  Again, this felt like clickbait.  But it looked like it was clickbait, well, it looked like it was a problem maybe of their own initial disclosure.  So the headline read:  "After suffering a 'very sophisticated' attack," which is their words, "GoToMyPC forces all users to reset their passwords."



So of course a lot of people use GoToMyPC.  I imagine a lot of our listeners do because they've been an advertiser on the TWiT Network for a long time.  So everybody knows that they would have gotten a password reset email; or, when they have attempted to use GoToMyPC, they then were told you must reset your password in order to proceed.  So what's weird is that - oh, and in the context of maybe there being a really bad breach of all their passwords, it occurred to me that they didn't mean GoToMyPC quite as literally as it was perhaps now being used.



But what they wrote in an incident report under status.gotomypc.com was:  "Dear Valued Customer" - now, this is their own disclosure.  "Unfortunately, the GoToMyPC service has been targeted by a very sophisticated password attack."  It's like, whoa.  And of course the good news it wasn't a junior attack because then that would be embarrassing.  It's a very sophisticated attack.  This is big guns were required.  And continuing:  "To protect you, the security team recommended that we reset all customer passwords immediately.  Effective immediately, you will be required to reset your GoToMyPC password before you can log in again."



And then further down in this status report of incidents they said:  "We have experienced" - it was under Investigating.  "We have experienced an issue which requires you to reset your password if you are having trouble logging into your account."  Okay.  "Please reset your password through the Forgot Password link if you are having trouble logging into your account."  Okay, so that seems a little inconsistent with what was said at the beginning of the same page.



But then subsequently they say:  "John Bennett, product line director at Citrix, said that once the company learned about the attack, it took immediate action.  But contrary to previous published reports" - and it was their own published report.  Apparently he says:  "There is no indication Citrix or its platforms have been compromised."  He said:  "Citrix can confirm the recent incident was a password reuse attack, where attackers used usernames and passwords leaked from other websites to access the accounts of GoToMyPC users."  So not so very sophisticated after all.



PADRE:  Steve, what you don't understand is it is so sophisticated that not even they understand what's been going on.  So that's how - yeah, crazy sophisticated, really.



STEVE:  Yeah, so then he concludes his emailed statement, saying:  "At this time, the response includes a mandatory password reset for all GoToMyPC users."  And so I sort of - I pushed back from this; and I thought, okay, wait a minute.  Now we're at a state where, if other companies suffer major publicly disclosed breaches, all the other companies on the Internet have to force all of their users to reset all of their passwords, too.



PADRE:  Yeah.



STEVE:  Sad state of affairs.



PADRE:  It's a sad state.  But, I mean, if you look at the Next Steps page that Citrix put up, it's most of the same things that we've been saying for years.  Don't use words from the dictionary.  Select strong passwords that can't be guessed, eight characters or more.  Make it complex with random capital letters, punctuation, or symbols.  Then do the whole substitution, zero for "o," three for "e," two-step verification.  So the problem is people read this, and they go, "Yeah, yeah, yeah, yeah."  And then they promptly reuse that password on another site.  And that's human nature.  We can't change that.



STEVE:  Yeah.



PADRE:  Oh, my.  And actually, this is the second high-profile case of a potential breach that was caused because some other site lost their passwords.  Twitter just suffered this.  People said that, well, there's a lot of Twitter users being attacked.  And Twitter was actually able to look at the accounts that were affected.  They found out - because they segment their authentication databases.  And they were saying, like, a few here and few here and a few here.  So they said, look, they didn't get the database because, if they did, you'd have contiguous blocks of users.



STEVE:  Ah.



PADRE:  This is obviously a case that someone has been compiling these passwords, and then they just threw them up against Twitter to see which ones would work.



STEVE:  Right.  Well, and of course we talked about how Zuckerberg was one of the people who got compromised.



PADRE:  Right, right.



STEVE:  With the rather embarrassing password "dadada."  It was just D-A-D-A-D.  So it was like, oh, okay.  But it was from a 2012, was it, or even older, it was from an old Twitter account that he hadn't used.  It had been just sitting idle for a long time.  But, oh, I am sorry, it was from an old LinkedIn account, and we believe it was part of the LinkedIn breach.  And then they tried to reuse that because he's a high-profile person, and they were able to compromise his Twitter account with it.



PADRE:  Right.



STEVE:  Okay.  So this one was the most tweeted story, with lots of people saying, Steve, can't wait to get your take on this on this week's or next week's, depending upon when they sent this, podcast.  And this, again, was - this was an article on BoingBoing that was really over the top, with the headline "Intel x86s" - and actually it's not x86s because those chips, if they're only x86s, they don't have this.  It's newer processors, so it's going to be x64s.  And it's not actually in the CPU, either, it's in the chipset, it's in one of the outboard chips - "hide another CPU that can take over your machine."  And then "(you can't audit it)."  So this is a guy, Damien Zammit, who has sort of made this his personal crusade.  And the problem is this generated a great deal of concern.  And it's not that some concern isn't warranted.  What I wish is that there was a little switch on the motherboard where you could turn this off.  And that's what we're lacking.



So here's the background.  So, okay, first of all, the story starts out:  "Recent Intel x86 processors implement a secret, powerful, control mechanism that runs on a separate chip, that no one is allowed to audit or examine.  When these are eventually compromised," as he puts it, "they'll expose all affected systems to nearly unkillable, undetectable rootkit attacks.  I've," writes Damien, "made it my mission to open up this system and make free, open replacements before it's too late."



Now, first of all, good luck with that, Damien.  I'm going to explain why you're going to have to have some serious voodoo powers in order to make that dream come true.  So here's what's going on.  First of all, there is sort of an acronym stew.  We have something known as the Intel Management Engine, sometimes referred to as IME, or sometimes ME.  And then this outboard thing is known as the ARC, the A-R-C processor, which is a 32-bit RISC chip.  So it's not like another x86 Intel, well, it is an Intel processor.  They produce a chipset.  But it's not Intel instructions.  It's a RISC processor.



Then there's something called AMT, Active Management Technology, which IME implements.  And this all replaces a previous IPMI, which is the Intelligent Platform Management Interface.  So Intel's intention here is to create a - we could call it sort of base band.  It's on the motherboard.  It is built in.  It is, where present, it is ubiquitous, meaning that users don't have any control.  BIOS doesn't have any control.  You can't turn it off.



When I was setting up my big new box a couple months ago where I put Windows 7 in it, and it was a Haswell chip, and I wanted to get that because of the news that future hardware platforms would not necessarily be backward compatible to Windows 7, that essentially Microsoft was saying we're not going to keep making our newer - Microsoft was saying we're not necessarily going to be providing drivers for newer hardware on our older OSes.  So I said, okay, I can't wait for my current system to die.  I need to get one now that I like a lot, that I'll be able to run Windows 7 on it, because I never want to have to go further than Windows 7.  And I made the comment that I had removed the Intel Management Engine.  What I had done was I had uninstalled the Windows drivers for it, where it allows Windows to interface with this.  But it can't itself be disabled or turned off.



So the concern is, my concern is that not only is this thing responsible for setting the bus clocks, it's a processor that gets things going.  It sets the various counters on the master clocks that run the bus that starts the system going so that then the big expensive Intel x86 or 64 or whatever processor that you've got is able to come to life.  So it's sort of the pre-life, get things going processor.



PADRE:  Steve?



STEVE:  The really annoying thing is that it has deliberate access to the motherboard's network interfaces.



PADRE:  That was the question I was going to ask, yeah.



STEVE:  Yes.  And that's deeply disturbing.  Now, apparently this is what Intel - this is technology Intel is providing for corporate enterprise-level management, the idea being that using some ports at the enterprise level, regardless of whether your computer is on or not - and that's the other creepy thing.  And I'm sure anyone who's been using or who's looked inside their machines anytime in the last 10 years or so, even when the machine is off, sometimes you look in, and there's a little LED staring back at you, glowing, on the motherboard.  And it's like, wait.  It's off.  Fans aren't spinning.  Everything's quiet.  Yet there's a little green LED.  Or even worse, if you look around the back, if there are lights on the network connector, they're sometimes on and flashing.  Like something is alive in here, even though all is quiet; no heat's being generated; no fans are being spun.



And so that's this thing.  That's the Intel Management Engine running and apparently listening on the network and able to respond affirmatively, even with the computer off.  And so that's what's got Damien all worked up here is that what if Intel has made a mistake?  What if their code is not perfect?  And as he says, "when these are eventually compromised," dot dot dot.  "They'll expose all affected systems to nearly unkillable, undetectable rootkit attacks."



And in fact it is the case that this Management Engine technology has, while the system is running, complete access to everything, unrestricted access to the system's main memory so that it can, if it were compromised, snoop.  And we don't even know how it works, what it does.  It is completely closed by Intel.  It is not documented.  It is, essentially, it is as secret as they're able to make it.  And the people who've been looking at this consider this Ring -3, like the deepest, darkest Ring level of access, like what was it, some rings of - I'm trying to think of...



PADRE:  Rings of hell, actually.



STEVE:  The seventh ring, yeah, the seventh ring of hell or something.  So everyone's familiar with the notion probably of Ring 0.  We talk about that a lot because that's where the kernel typically operates.  This notion of rings is the privilege at which the instructions are executing at that time on the processor.  And the Intel hardware supports four rings.  So it's got two bits, two binary bits; so there's four different possibilities.  So that gives us Ring 0, Ring 1, Ring 2, and Ring 3.  And the original architects said, yeah, that ought to be enough.  Well, it turns out that two rings was enough.  They could have spared themselves a bit and just had one bit because nobody uses Ring 1 and 2.  You're either in Ring 3, which I userland, or you're in Ring 0, which is the kernel.



So there is this notion of a ring transition where you go back and forth.  And that's something that, due to the Intel architecture, is a little bit painful in terms of overhead, which is, for example, why Microsoft, in their less than wonderful wisdom, moved GDI, the Graphics Device Interface, from Ring 3 down into Ring 0 because there are so many calls to GDI by Windows that it was expensive to have it up in Ring 3.  And so they made the mistake in retrospect of putting it in the kernel.  And that then allowed things like JPEGs to take over your computer because the graphics device interface would be interpreting JPEGs, and they made mistakes, and that allowed your computer to get taken over.



So in this ring terminology we have the positive rings, Ring 3, and we're not using 1 and 2, and then 0.  And then people consider hypervisors, which run underneath multiple Ring 0 kernels, they consider that to be Ring -1.  And then there's the SMM, the System Management Mode.  That's considered Ring -2 because that's even deeper than the hypervisor.  And that's where we get to Ring -3, which is sort of what this is considered, this whole management engine thing, because it's arguably deep - it's not system management mode.  It's even deeper than that, where it really provides the low-level control over the whole system and, unnervingly, is also monitoring the network.



Now, Intel has done arguably everything modern design permits them to do.  I mean, they understand they don't want anybody messing with this.  So first of all, it cannot be disabled on systems running the Core 2 series processors.  It is kept absolutely secret.  Damien notes that there's no way for the main CPU - there's total visibility from it, from this IME, like so-called Ring 3, up into the higher rings, but none in the reverse.  There's no way for the main CPU to detect whether this management engine may have been compromised - no way for it to access it at all, no way for it to repair a compromised management engine, no way to detect if malicious entities have been able to compromise it or infect it.



On the other hand, Intel has done everything to lock it down, everything possible.  There's a public key in the hardware, not even in the firmware.  I mean, there's a public key in the silicon of this management engine.  And there is an SHA-256 hash which is taken of the public key to verify that it hasn't been changed.  And maybe the public key is in the firmware, and the hash is in the silicon.  Again, details are sketchy because Intel doesn't want to share any of this.  The only thing we know is from deep reverse-engineering.  And again, it's like almost pop the lid on the chip in order to reverse-engineer this.  There's little known about it.



But so the public key is verified with an SHA-256 hash in a way that firmware can't change it.  Some components are in the silicon at manufacture.  Then the signature of what is in the firmware, because it is firmware updateable, which is a concern, the signature of the firmware is verified using that public key.  So we know that only Intel will have the matching private key to allow them to create firmware that this IME will ever consider running.  And that firmware image has custom compression which the hardware decompresses.  It's not even decompressed through any known algorithm.  And there's, I guess, 11 versions of it which have subtly changed over time.



So that part has been reverse-engineered.  The people have extracted the compressed firmware and arranged to decompress it into the RISC processor's instructions.  But it's not possible to change even a single bit of that, even knowing what the compression algorithm is, because then that ARC, that 32-bit ARC RISC processor will not run it when the system is first plugged into the wall, and that little green LED on the motherboard first turns on, and all of this begins to come alive.



So they've done everything they can.  They've locked it down utterly.  Nobody can change a bit.  People - and this is why I say Damien wants to come up with a public domain open source version?  Well, okay, who's going to sign it?  Intel's not going to sign that.  And if Intel doesn't sign it, this hardware will not run it.  I mean, maybe you can get in there with your soldering iron and fuse the silicon.  But it's not going to be a widely applicable, download this updated IME firmware sort of thing.  And believe me, I mean, it is a concern that this thing is on our network interfaces.  And apparently independent of IP address or MAC address or anything else, it's there sniffing traffic coming in and out.  But it comes along with the hardware.



So again, it's like, yes, it's a little annoying.  But all you can do is pull the plug.  And I mean literally the plug, either the power plug or the network plug, out of the back of your machine.  If both the power plug is plugged in, and the network is there, there's a link up, and this thing is waiting to receive instructions from the mothership.



PADRE:  Now, as an enterprise guy, I understand why they built this, because...



STEVE:  Good, tell us.



PADRE:  ...we've been dealing with out-of-band management forever.  That's how I've always been taught to build.  So you have the main network, and then you always have a way to get into your devices, even when the main network is broken or not working properly.  So this is a way for you to get management that bypasses even the hypervisor inside of an Intel chip.  So especially if you're running a server that's running a lot of VMs, or you're running it as a container box, this gives you the ability to get in even below that in case something goes tragically wrong.  So rather than walking to the box, you actually have the ability to get in there and not just power cycle, because we can already do that with power distribution units, but to actually figure out what state a computer is in.  So that's, from the enterprise guy, that's incredibly fantastic. I love this solution.



However, and I think this is the same concern you have, the problem I have is that it has no audit.  There's no way to find out what's going on inside.  I would never let that on my network because it means, well, I now have an unknown, an always unknown on the network.  I just have to assume that no one has broken their way into one of these processors.  Now, as you describe, it is a very difficult, complex technical task to do so.  Right now I can't think of a way to do it.  But we've seen in the past that hardware security protection, where it's baked in, is always the most secure until the first time that it's broken, and then it's absolutely worthless and a huge security risk.



STEVE:  Okay.  So now we have this 32-bit ARC RISC processor, and these guys have figured out, they reverse-engineered the hardware-based decompressor.  So they're now able - and then through the 11 versions of this, so obviously Intel trying to change it.  That's not going to help.  I mean, it may be the case that nobody can change the firmware, no third party can change the firmware.  But now look what we've got.  Now we've got a group that are figuring out what the code is.  We know that, once you know what the code is, you can then - you disassemble that and come up with the, what is this chip doing with the NIC?  What is it doing on the network?



My point is, if it has preemptive control over the system, that is, if it's not just read-only, if it's not just a monitoring tool, I mean, that's bad enough, depending upon how deep and what it monitors.  But what this means is that third parties will know everything Intel knows about this thing's capabilities.  They will reverse-engineer the language.  They will reverse-engineer the instruction set, that is, the high-level, network-level instructions that this thing uses for communicating.  So now you've got the possibility that something malicious that knows this gets onto a large enterprise network and has the free rein of the place, even at 2:00 a.m. when all the computers are off.  It just seems like a bad idea.



PADRE:  It does.



STEVE:  To have something that is in - we are in the process of reverse-engineering it.  So anything Intel has enabled that to do, we will know.  And if anyone knows it, everyone knows it, just exactly as you said.  And it just seems troublesome.



PADRE:  I would actually like to get one of these processors, so a processor that I can confirm has this built into it, and then run it on an OS that I strip out all network controls.  So you take out all the stacks, so it doesn't have the ability to communicate with the network adapter, and then just sit on the line and listen.  I want to see if this is actually talking to something, rather than just waiting, because I believe the article mentioned that, in order for this to be useful, there has to be some sort of TCP/IP service running on that little processor.  There has to be...



STEVE:  Yes, in fact the article did say what's most creepy is that it runs a full TCP/IP server on the network interface, and packets entering and leaving the machine on certain ports bypass any firewall running on the system.  Of course, because it's hardware.  The firewall is in your OS.  And so really the only way to protect yourself would be to use an outboard physical firewall that is drop all, and then where you specifically allow your own higher layer traffic to get through.



PADRE:  At the very least this could be a couple of interesting weekends, just sniffing around.  Actually, I'd sniff first.  I'm betting it's probably not sending out any traffic.  It's probably just waiting.  But then I'd start bombarding it with traffic, just to see what it listens to.  And that is kind of fascinating.  I look forward to seeing how this develops over the next couple of months.



STEVE:  So there's the behavioral approach, which you talk about.  And if you can get the firmware, and you can decompress it, and you can decompile it or disassemble it, then you just work your way through it, and you end up with a complete lexicon of exactly what this thing does.  And so at some point we're going to know.  And, I mean, maybe it's already known.  Who knows?  I mean, again, it's a little annoying that this thing is sitting in our machines.  I just hope, I mean, so, for example, is it Ethernet level?  It says TCP/IP, which presumes that it's got a TCP/IP stack.  And TCP/IP, as we know, is Internet protocol, so it's routable.  So what IP does it use?  Yeah, it really, I mean, it raises a lot of really intriguing questions.



PADRE:  Is there an easy way for me to find out which processors are affected?



STEVE:  There's more detail in the story.  There was something called a vPro, and I think it has to be vPro processors, and non-vPro processors are not.



PADRE:  I got it.  Okay.  But a recent vPro processor.



STEVE:  Yes.  Well, because older ones had the previous, the IM whatever that was, the older technology.  Intel's been doing this for a while.  They've been up to this.  The IPMI was the Intel - the Intelligent Platform Management Interface was their earlier one.  And I think I've got servers, I think my servers at Level 3, those are from '04, and they've got that in it.



So again, there's 12 years ago Intel was like, oh, we've got to create this.  So, I mean, you know, maybe if it's for inventory management, like the corporation is able to scan their network and get - because I know that there's like all kinds of funky serial numbers and things in the BIOS of these older servers that I have, where there are FRUs and all kinds of strange stuff that I never bothered with because it wasn't about running my stuff.  But it seemed that there was a lot of enterprise-class management stuff.  And that's apparently what Intel's doing.  But the question then is who else knows about this?  This isn't of value if Intel is the only one who knows.  It must be that they provide some enterprise-level interconnectivity that allows corporations to do something with their fleets of machines that are all enabled with this.



PADRE:  Right.  But, I mean, like for asset management, which is one of the biggest things that we have to do in enterprise, I can do that just by looking at the NIC because all NICs will stay in low power state as long as the machine is still plugged into power somewhere, which will allow me to see if it's still connected to my network.  And I can even get a warning if a device suddenly is removed from the network.  So I don't need a second processor to do that.



STEVE:  Right, right.



PADRE:  Which, I mean, again, I don't think it's a nefarious thing.  I think it's something they thought was a feature.  Maybe they didn't think it all the way through.  But like you, I would love for Intel to come out and say, okay, this is exactly what it does.  This is how we access it.  This is how it's secured.  And this is why we think it's still a useful feature for enterprise.



STEVE:  And why can't I, as the owner of my system, turn it off?



PADRE:  Exactly.



STEVE:  Or at least turn off the COM part.  Turn off the NIC interface.  Like go set up the bus, get everything going, but stop, you know, don't even think about talking on my network interface without my permission.



PADRE:  Steve, we've been talking about this a lot, but I could see this as becoming a thing past Intel.  More and more of the devices that we use are always on, always connected.  And I could see real benefit to having a management layer of hardware that I as an IT person could access that nobody else could.  I'm actually pretty firm in my belief that this is going to start spreading to other product categories.  So when it does, is there a safe way to do this?



STEVE:  The problem we have with the whole IoT concern, the reason it causes so much trouble, is the tradeoff between ease of use and security.  Obviously, what Netgear was doing with Arlo made it extremely simple for their users to hook up their webcam systems.  Look, oh, just plug it in, and go to the website, and it finds you.  So what we're going to have to come up with is in general this Internet of connected things is some sort of compromise solution that gives us security and also ease of use.  We don't have it yet.



PADRE:  Oh, is that all.  Oh, so I just want it secure, but I also want to make it dead simple to use.



STEVE:  That's right.



PADRE:  That's the cry of every security professional from the dawn of security.



STEVE:  So just a couple last things.  I did get a nice note from a Corey Grant, who's in Livingston, Texas, where the subject was "Testimony."  And I thought, what?  And he kind of meant testimonial, but thank you, Corey.  He said:  "Greetings.  I'm a network engineer in rural East Texas and moonlight on the side for a few local businesses.  I got a distress call about a PC that would not boot."  And of course we all know where this is going.  "This machine had lots of tax data from previous years that" - and he just wrote "she," meaning the person who called him, I guess - "was actively using for research."



He says:  "I have used SpinRite many times to increase performance of lagging desktops, but this was the first time it actually resurrected a dead machine.  She is happy, and I am a hero, thanks to you."  So Corey, I really appreciate you sharing that with me and letting me share it with our listeners.  So another SpinRite brings the drive, and in this case apparently years and years of tax data, back from the grave.



PADRE:  Those stories aren't even really surprising anymore.  We've heard them so often that we know.  Actually, I got...



STEVE:  Yeah, yeah, yeah, another - so it's like, how do I make this more dramatic?  Yeah, yeah, yeah, SpinRite fixed the drive, okay, fine.



PADRE:  Well, I've got one for you.



STEVE:  Oh.



PADRE:  TWiT.tv was covering the Electronic Entertainment Exposition down in Los Angeles at the Staples Center.  And I was at a booth.  I won't say which booth.  I will just say it's a company that makes operating systems as well as gaming consoles.  But we got an invite into the lounge, this sort of second-floor type thing.  And there were a couple of workstations up there that were controlling some of the major displays that are going on around the booth.  And one of them was down.  And as we were recording, I kept sort of glancing over.  And then I realized it was running SpinRite, and they were running SpinRite on the internal SSD.  I guess they had had some issues right before the show started.  And then by the time my interview was done, it was booted back up.  So I'm like, oh, okay, well, evidently this company that makes operating systems and game consoles has gotten the word that this is the software to use.



STEVE:  Interesting.  Very nice.



PADRE:  So you saved E3.  Steve Gibson saved E3.



STEVE:  Well, and what's funny is that we've heard anecdotally that companies that are professional data recovery firms, they use SpinRite as the first thing they do because most customers don't know, and the bill is going to be often north of a thousand dollars, right, for like a professional data recovery firm.  But they don't want to put their good guys on it if SpinRite'll fix it.  So they just run SpinRite.  And they still charge the customer an arm and a leg, but they didn't have to expend the expensive heavy-gun resources to do platter change or PC board swap-out or all the things that can be required if, well, if the hardware's really dead, and then SpinRite can't do anything to fix it.



PADRE:  All I know is that it's been in my toolkit for the last two decades, just about.



STEVE:  Yes.  Thank you.



PADRE:  So if it's a hard drive, if it's an SSD, there's a reason for you to have SpinRite, folks.  And that reason is Steve Gibson.  Shall we get into some miscellany?



STEVE:  Yes.  Well, I just have one piece.  This is something I've mentioned before, but it was triggered by somebody tweeting me and didn't remember what it was.  He said, what was that thing you recommended years ago for archiving all your email?  And what happened was there was some event, I think it was just that I had - I'm still using old Eudora v7.1, which keeps on going.  I like the UI.  I've tried other email clients.  They just - they're not the same.  So I've stayed with it.



But I realized Eudora was having a horrible problem with a million years, or at least two decades, worth of email that I was just dragging along behind it.  So I went looking for a solution, and I found a free solution.  It is still free.  The company's called MailStore, and it's called MailStore Home.  Now, I was using v8, and they're now at 9.7.1.  And it is free for personal use.  And so I wanted to renew my recommendation.  I'm still using it.  I still love it.  And it is amazing.



It now has 2.5GB of my past email archived.  I can put in - in fact, I used it to find you, Robert, a couple days ago, when I first sent you mail, or I guess it was last week when I knew that you were going to be my co-host.  I didn't still have you in Eudora.  So I fired up MailStore, and I put in "Father Robert," and bang, it found all of our previous communication, and then I grabbed your email address and addressed a piece of email.  So it is itself a pop3 and/or IMAP client, so you can just aim it at your server, and it'll suck things in and index them.  It can be a central archive for all your email.  It can do Gmail, Yahoo Mail.  It knows about all versions of Microsoft Outlook, Windows Mail, Windows Live Mail, Exchange Server, Office through 365, Mozilla Thunderbird, Sea Monkey, also PST, EML, and other files.  It can suck those in, as well.  And it runs perfectly next to my creaky old Eudora v7.1.



It's funny, too, because when I fired it up, it noted that there was a new version.  Or maybe I checked.  I don't remember.  But it's like, oh, yeah, there's a v9.7.1.  And so I thought, okay, fine.  So I tried to update, but it said no, not compatible with your OS.  So it's like, oh, okay.  So I'm using 8.  And I did note, when I went to their site in order to bring it up - by the way, it's just MailStore.com, M-A-I-L-S-T-O-R-E dot com - that 9.7.1 is Windows 7, 8, and 10.  Of course I'm still on XP, so I'm going to stay with 8, which works perfectly. So anyway, I just wanted to remind people about it because I did get a lot of positive feedback from those who adopted it after I first mentioned it.  So I thought it was useful to say, hey, I'm still using it.  I'm still loving it.  And it's hard to beat the price.



PADRE:  I still have a few old versions of Eudora that will work.  They actually connect and work just fine.  But I'm doing it the more advanced way now, Steve.  I have about 30GB worth of old Outlook PST files just sitting on a SkyDrive, a OneDrive somewhere.  Not quite as efficient, really.  Go figure.  So MailStore?  That's my new joint?  I'm going to be doing that one?



STEVE:  I think you ought to check it out because you could feed it those PST files.  It'll suck them in and index them.  And then you can really give them the Deep Six.  Maybe keep them around.  But this gives you total access to their contents.  And as I said, I don't have as much as you.  I'm at 2.5GB.  But again, instantaneous index keyword search of all of my back email, which is really handy.



PADRE:  I have a lot of attachments.  A lot of attachments.  Now, actually, let me ask you about that.  Because my old policy, back when I was still using Eudora, was nothing gets deleted.  Everything gets saved.  I might refer to it later on.  But it's gotten to the sheer volume of mail, and it's not all spam, some of it's actually decent, means I delete probably about 96, 97% of it, and I save about 3%.  What's that ratio for you?



STEVE:  I don't keep any attachments, but I do keep all the text.  Well, because I've just got it set up as automated now.  It's just it's all happening in the background.  Any mail to me ends up being archived.  So from Eudora I just delete things whenever I want to.  I have no problem at all now with just wiping things out.  Like sometimes, for example, I lost a few months ago a neighbor whom I met because we were both on the association board, and he died.  He was in his late '70s.  And so I sorted by name and marked them all and just deleted them because there was just no point in keeping it around.  But I did so knowing that, if anything ever came up in the future where I needed to refer to some conversation that I'd had with Leonard, it was in MailStore, and I'd be able to grab it.  But there was just no need to keep it online in Eudora because at some point Eudora does seem to get a little choked up when things get too big.



PADRE:  I just checked.  JammerB, if you look at the other screen, I'm really close to zero inbox, on the lower left-hand corner.  I've only got 1,516 items in the main inbox.  So I'm pretty good, actually.  This is a good day for me.  Oh, no.



STEVE:  No, I'm the same way.  There's just too much incoming from all different directions.  And so I deal with what I can.



PADRE:  All right.  Now let's get into the real meat.  And it was fun talking about breaches, fun talking about SMS.  It was fun talking about Intel's little hidden processor.  But now we need to learn all about control-flow enforcement technology.  What is that, Steve?



STEVE:  So I'm excited about this because this represents an evolution of - a simple and compatible evolution of the architecture of the Intel processors to directly address two of the biggest problems that we currently have with what hackers are able to do to abuse code that has errors.  We're closing in on the end of Year 11 of this podcast.  And for the entire duration of that time, we've been talking about the famous buffer overrun errors.  And then also more recently the so-called ROP (Return-Oriented Programming) hacks where - and in fact I'm sure it was a podcast you and I were doing.  We were talking about an Adobe Flash exploit.  And they used a return-oriented programming hack in order to run some code in order to get loose of their containment and run some code that was in Flash that allowed them then to essentially bootstrap themselves to full system privileges.



Okay.  So Intel has added, or will be adding, two new features to all future processors.  There's something called - they're adding a new instruction called the ENDBRANCH instruction, and a new feature of the architecture known as the "shadow stack."  And of course, again, these problems have been plaguing the industry for, well, forever.  And I remember talking about once Steve Ballmer had a meltdown during some sort of Microsoft security summit - I don't think it was a public event, but it ended up being public - where he was ranting, asking how it was - I think it was after XP's launch because of course he was very vocal in talking about how XP was going to be absolutely the most secure operating system ever.  And of course it was after XP and due to XP that we had Code Red and Nimda and, I mean, those were really the last highly prevalent worms that got loose on the Internet because Windows XP was such a catastrophe.  And so he was famously ranting, asking how can it be possible that we're still having these problems?  He just didn't understand.



And of course what we've been talking about recently is that older software, which you leave alone, that you find the problems in, but you resist touching, ends up being more secure than newer software, even if the newer software is implementing new security features, because the software itself is the problem, rather than the features that it's trying to offer.  What we find is, in the real world, any new code generally has problems.  And so what that argues for is, if it's not broke, don't fix it.  Leave it alone.



So I got a big kick out of this because I talked about last week how this will be the subject of this week's podcast.  And I got a tweet from somebody from Intel, his name is Steve Fintel.  I guess that's his real name.  Maybe it's Steve F. at Intel.  I don't know.  But anyway, he tweeted me, he said:  "I see your Security Now! topic for next week is Intel's CET.  I," writes Steve, "was the Atom Processor CPU planner when we got approval to integrate CET into Atom, ahead of Core on Xeon.  When I was preparing the material to pitch CET to management, I pointed people to Security Now! Episode 211 to explain what ROP was."  So I got a big kick out of the fact that this podcast was used to explain to management why return-oriented programming was a problem, and that they were using this CET, this control-flow enforcement technology, to deal with it.



Okay.  So, as I said, there are two components to CET.  We'll tackle them separately.  The first is ENDBRANCH, and the second one is the shadow stack.  So the problem with return-oriented programming is that it's a clever way that hackers have figured out to get code executed that already has privilege to execute.  What I mean is that one of the ways that - so there have been previous efforts, sort of an ongoing effort over time, to better secure and lock down our systems using hardware, that is, using architectural improvements.



One of them is the so-called NX bit, the No-eXecute bit.  And that was added to systems after noticing that a frequently occurring problem with security, that is, that hackers were able to leverage, is that they were able to provide data to the target system, the exploit target, and get that data to execute.  That is, there was no differentiation, there was no separation between the data and the instructions.  And in fact, in classic architecture, standard von Neumann computer architecture, you do have a mixed data and instruction space.  You have a single memory space, as opposed to a Harvard architecture, where instructions are separated from data.  They're completely separate.  The architecture that has generally succeeded has data instructions existing in the same memory environment.



Well, that creates an inherent problem because it means that, if you can somehow get the chip, get the processor to execute a jump instruction into the data, it will execute data as if it's instructions.  So the so-called NX, the No-eXecute bit, it's a flag which was added to the hardware, so it's enforced by hardware, which says this region of memory cannot be executed.  So any time the instruction pointer in the processor is jumped into a region of memory with the No-eXecute bit set, it just causes an abort.  Basically, it safely terminates the program, and without executing even that one single instruction that it was aimed at.  So that was the first countermeasure against bad guys being able to use a buffer overrun to provide the data that would be then executed.



But they're very clever, these hackers.  And so they said, okay, now the data is marked as non-executable.  So what are we going to do?  And they said, well, where can we find some executable instructions?  And it's like, well, the computer's full of them.  Look at that operating system.  It's got all kinds of instructions, all over the place.  So what they cleverly figured out was it was possible to execute instructions already there, that is, little snippets of code, typically at the end of a subroutine, because they generally don't want to do all of what an existing subroutine does.  That's not going to be what they want.  Typically, they'll find some instructions that already exist in Ring 0 in the kernel that are privileged, which when executed do something they need.  And typically it's lift any other restrictions on them.  That is, they can't do too much.  But if they can simply find a little snippet of code that, for example, turns off the NX bit, then suddenly they can execute whatever they want to in the data space.



So what the hackers do is they arrange to jump to near the end of an existing subroutine of code, which naturally is executable because it's in the kernel.  It is executable by definition.  And those few instructions will be executed, and then the return instruction at the end of the subroutine is reached, which returns control to them - and normally, with whatever they wanted to get done, done.  Maybe the NX bit has been flipped off, or the range of memory they can access has been extended to the entire range, so they're no longer restricted by the memory map of the system.  Whatever.  So Intel was saying, okay.  How can we fix this problem?  And they came up with just the cleverest solution.



PADRE:  Would this be ASLR?



STEVE:  Well, okay.  So good point.  That was the first mitigation, was address space layout randomization.  So here we had this problem of people jumping into known locations in the kernel and just, like, doing that with abandon.  So the first mitigation, well, okay.  The first was DEP, data execution prevention that we talked about, with the NX bit.



The second one was, after that sort of didn't solve the whole problem, they added ASLR, address space layout randomization, where the operating system at boot time, as it's loading, would deliberately randomize where the various blocks of its own code were loaded in memory.  There's a whole process called "fixup," where the addresses of all the different modules are sort of established.  But the loading order was normally fixed, that it was just sort of default.  It didn't have to be that way.  It was just that way because no one bothered to scramble it up.



So they said, well, let's scramble it up on purpose.  So that's address space layout randomization.  It turns out, though, that for architectural reasons, the granularity of their ability to place things in random places isn't very good.  And it's possible for malicious code to probe for the location of code in the kernel, or just to not work as well.  For example, oftentimes the granularity is just eight bits, so 256 possible locations for the various modules.  So if it just guesses one of the locations, it's going to be wrong 255 out of 256 times.  But it's going to be right one out of 256 times.  And so that's a low probability of success exploit, but it's better than zero.  And if you've got enough machines in a huge environment on the Internet, and if you just - if somehow you can try again, even on the same machine, you're going to get lucky sooner or later.



PADRE:  Steve, if it guesses wrong, if it's one of those in the 256 that it didn't get, does it just crash that thread?  Does it crash the machine?  What would a user see if it was an unsuccessful attempt to access code where it thought it was in memory?



STEVE:  It would be bad. 



PADRE:  Okay.  It would be a bad thing.  I got it.  Okay.



STEVE:  Yeah.  It would be like I don't know why my computer just froze.  



PADRE:  All right.



STEVE:  I don't know why my mouse stopped working.  I got a Blue Screen of Death.  So you go, oh, shoot.  And so you reboot, and it doesn't happen again.  It's like, huh.  That was weird.  I wonder what happened?  And so you don't know that something just tried to own you, but guessed wrong.



PADRE:  Right, right.



STEVE:  All you know is that your system went wonky, but now it seems fine.  So okay.



PADRE:  Let me back my propeller hat off a little bit because I love the execution of this.  I mean, of course it can be used for nefarious reasons.  But when we typically talk about exploits, we talk a lot about buffer overflows because it allows for arbitrary code execution, which I've always enjoyed.  But this idea of being able to do what amounts to arbitrary code execution, using code that's already loaded into memory, that's far more elegant.  I mean, this seems like something that would be incredibly difficult to figure out because it's not your code that you're running.  You're running snippets of other people, other companies' codes, to get it to do what you want it to do.



STEVE:  Right.  And I've looked at what they've actually done.  And in some cases it's as clever as - okay.  So instructions are typically multi-byte things.  So the opcode, some opcodes are just, like operation codes, are just eight bits.  But Intel is a variable instruction-length architecture, where instructions that are more complex or used less often will have a prefix that says the instruction is a member of this group, and then the succeeding bytes provide more definition.  And then you often have arguments to that instruction.



So these guys, the hackers, are so good that they're not even jumping into the beginning of an instruction.  In some cases they're jumping into the middle of a single instruction's multiple bytes and realizing that they want this opcode, which happens to be the third byte of a multi-byte instruction, but it's going to do what they want.  I mean, it's just, when you look at it, you think, wow.  I mean, we're talking serious deep voodoo in order to make this work.



PADRE:  See, I don't even get that because - especially with ASLR.  So since it's pseudorandomized, where those little bits and snippets will be placed inside of memory, it only has to guess wrong once in that entire string of bytes that it's puling out of different available spaces of memory.  It seems as if the odds are not just stacked against this working, but they're incredibly stacked against it working.  And yet, as you're describing it, it seems to work.  How do they do that?  Can they just naturally assume that some spaces in memory are going to be safely where they think they'll be?



STEVE:  Often it's possible - well, for one, yes.  But often it's possible to probe where these large block modules are located.  So, for example, when you return from a subroutine, the stack - and we'll be talking about the stack when we talk about the second part of this, the so-called "shadow stack."  The execution stack is where the return address is stored when you go to a subroutine.  And so it uses the return address on the stack to get back to you.  But it's often the case that you're able to look at the code that called the subroutine, and that completely decloaks it.  If you're able to see a call to the subroutine, now you know exactly where at least that large module is located.  And then you use an offset from that in order to execute the code you want.



PADRE:  So once you get the proper response, you know how long that code snippet is, and you know exactly where you need to jump in to get the opcode you want.



STEVE:  Exactly.



PADRE:  So how deep are we getting?  Are we talking about like assembly type codes at that point?



STEVE:  Oh, yeah, yeah.



PADRE:  Are they pulling, like, pushes and pops?



STEVE:  Yes.



PADRE:  Really.



STEVE:  We are down at, for example, a return - okay.  There's a no-op and a return.  They're either 60 or 90, and I don't remember which is which.  But, I mean, this is the way I code.  So I don't actually always look at the machine language, but I'm used to seeing 90s and 60s, either as no-ops or returns.  And so it's literally that pattern of bits is the computer interprets it that way.  So here's the brilliance of what Intel's - the first part of this.  They created and they defined a new instruction called the ENDBRANCH instruction.  And it is simply this.  That instruction must be the target of a call or a jump instruction.  That is, in this new architecture, when this is enabled, that instruction, ENDBRANCH, is the only valid destination for a call or a jump.



PADRE:  Okay.



STEVE:  So what that would mean is the beginning of every subroutine would start with an ENDBRANCH.



PADRE:  Got it.



STEVE:  And what's so clever about the implementation, I just love this, is we talked about the architecture of processors years ago, did a whole series, followed the evolution of architectures all the way up.  And at some point in any processor, you have an instruction pipeline.  That is, you have a series of instructions, one after the other, that the processor is executing.  And the brilliance of this ENDBRANCH is that the way Intel implemented it, as the processor is reading through instructions, there's a little - it has a tiny little state machine.  When it encounters a call or a jump, which are the two instructions - a call says I'm going to call this function and expect it to return to me.  A jump is I'm going to jump somewhere, and then whatever happens, happens.  But either of those have to have and have to land on an ENDBRANCH.



But think about what that means in terms of the instruction pipeline.  It means, in the pipeline, there is going to be a call or a jump instruction.  And the immediately following instruction has to be ENDBRANCH.  That is, the thing fetching instructions on behalf of the processor, after it fetches a call or a jump and executes it, the next thing it fetches is an ENDBRANCH because that's where the call or jump have to jump to.



PADRE:  It hands off control to that ENDBRANCH. 



STEVE:  Exactly.  And so the Intel design, they added a tiny little state machine that just sort of supervises the execution stream.  And if it ever sees a jump or a call, it looks to verify that the immediately succeeding instruction is ENDBRANCH.  If not, it raises an exception and aborts the process.



PADRE:  Okay.



STEVE:  So this completely solves the ROP, the return-oriented programming problem.  You can no longer jump.  Nobody, not even good code, but good code doesn't.  Good code has no reason to do a far jump or call into the middle of some subroutine somewhere.  It always wants to come in at the top.  So essentially what this does is, by putting ENDBRANCH instructions as the first instruction of all of your subroutines, it defines the single legal entry point for subroutines.  And any attempt to jump into the middle or near the end, which is the way the ROP typically occurs, immediately aborts the process, and nothing bad can happen to your system.



PADRE:  I love that.  That's absolutely elegant.



STEVE:  So elegant.  Oh, and Intel also chose the specific ENDBRANCH instruction so that it is a no-op, a no-operation, on all current and past generations of chips.  It's an unused, do-nothing byte sequence.  Which means that, when compilers begin compiling code with ENDBRANCH awareness turned on, so that they're sticking these little ENDBRANCH instructions at the beginning of all the subroutines in the system, that same code can run perfectly on older systems that don't have ENDBRANCH.  The processors are just going to say, gee, that's weird.  I wonder why all of the subroutines start with a no-operation?  Oh, well.  Who cares?  There's nothing here to do, so we'll just go on to the next one.  So it's beautifully backward-compatible to previous architectures.



PADRE:  The only way you could exploit this is if somehow you exploited that stateless machine that's looking for the ENDBRANCH.



STEVE:  That's in the hardware.



PADRE:  That's in the hardware, so good luck with that.



STEVE:  It's built, it's like, right down in the instruction set.  The only thing I could think is that, if there was a full function that you could use, that is, not just a few instructions at the end of a subroutine, but if somehow the whole function was usable, but that's generally not doing what you want.  Normally it's a clever re-use of existing code, very much near just before a return instruction, is what the bad guys have been using.  And this ends that.



PADRE:  Besides, calling on a full function, if it will be allowed by the ENDBRANCH stateful processor, that's going to hand off control to whatever that function had originally been connected to.  It's not going to come back to you as the attacker.  I couldn't think of a complete function that you would be able to use to bypass authentication.



STEVE:  Yeah.  It would be unexpected.  But Part 2:  The Shadow Stack fixes that.



PADRE:  No.  Why can't we just end with the happy news, Steve?  Why do we have to get to the depressing stuff?  All right.  You've heard about the brilliant way to stop ROP, the brilliant use of ENDBRANCH, and now Steve Gibson is going to let it crash down all around us.



STEVE:  Okay.  So the second part of this is another new feature that Intel put into this CET technology.  To understand this we need to go back a little bit and look at the concept of a software-accessible stack.  I would argue that the concept of a stack is probably one of the greatest innovations in computer science.  Old machines didn't have a stack.  These three PDP-8s have no stack.  There was no concept of a stack in them.  There's an instruction to allow a jump to a subroutine.



But the way it works is - so the problem is, if you jump to somewhere because you want a subroutine to be executed, how do you get back?  If you just do a jump instruction, then you're somewhere else.  But how does that place where you are know where you were?  So on these older machines, on these 12-bit PDP-8s, there is a jump to subroutine.  The way it works is the best they could do at the time, and that is the instruction that you jump to is where the address is stored of where you were.  And then execution begins with the instruction afterwards.



So on those old machines, the first instruction of a subroutine is blank because that's going to actually be where the computer stores the address that you came from so that, at the end of the subroutine, you're able to go back.  Now, that's cool, but it's got a problem.  And that is that it doesn't allow recursion.  That is, for example, that subroutine itself, nor any other subroutine it might call, could ever call it because, if they did, they would overwrite that return address that was stored at the top.  In other words, that system it works, but you have to be very careful that no way for the code to execute would ever allow the subroutine to be called again before it had returned to its caller.



So that older system does not support any kind of recursion.  We solved that problem not long after that, actually, by implementing a stack architecture in the machine.  And, I mean, it's such a win that you don't - there just are none any longer, unless they're operating on my bookshelf, that don't have stacks.



So what is a stack?  Everyone's sort of familiar with this notion of pushing and popping.  You push something on the stack; you pop something from the stack.  To really understand its value we have to go a little bit beyond that.  But just looking at that, and using the example I was just giving with a non-stack machine, imagine that there's this thing, which we'll sort of leave undefined for a moment, called a "stack," where you can push and pop.  That is, and you don't have to worry about any of the details.



So in a stack system, when you're jumping to a subroutine, you push on the stack typically the address of the next instruction, and then you jump to wherever you want to go.  And then that subroutine is executed.  And then the way that subroutine gets back to who called it is the stack is popped, which reveals the address of the instruction underneath the one that called the subroutine.  And so you do what's known as an indirect jump, that is, you jump to the address on the stack, which brings you home, brings you back.



Now, one of the beauties of that is now you can do recursion because, for example, that subroutine that you jump to, it could call itself, if it wanted to, because it would, if it called itself, it would push the instruction next in line for where it's calling itself on the stack and then call itself.  And then if that subroutine then returned, it would pop the stack, which would reveal the instruction in that subroutine, returning to where it came from.  And then if that returned, it would pop the stack again and come back to the original caller.  In other words, it's this incredibly convenient scratchpad, but it is strictly sequence-based.  That is, the order in which you push things, they are popped off in the reverse order.



And so that's one of the brilliant insights to this concept of a stack.  And with that, for example, you get this amazing convenience of having subroutines able to call, you know, pretty much do anything they want to.  They can call themselves; they can call other people that call them.  And finally it all sort of unwinds itself back to the original caller by removing things in the reverse order that they were put on the stack.



Well, there's something more you can do with it that is even more clever.  And that is you can use it to pass parameters to functions.  So say that you wanted to put a circle on the screen at a certain coordinate where the upper left corner and the lower right corner were at two coordinates.  And so you had a subroutine that could draw circles.  But it didn't know where you wanted to draw them.  So what you do is you push on the stack the coordinates for the upper left and the lower right.  And then you call the circle function.  The circle function knows to expect its parameters to be on the stack.



So in all these systems there's something known as the "stack pointer."  It's a register that points to the top of the stack.  Well, since several of these parameters were pushed down on the stack, then the return address was pushed on the stack, this subroutine is able to look at an offset from where the stack pointer currently is.  That is, it's able to sort of look down into the stack, into the history, and find its parameters there.  So it goes and looks deeper in the stack, finds its parameters, draws the circle.  Then it returns, and the function which called it, which pushed those things on the stack, typically removes them from the stack.



So the calling function pushed some things on the stack; called the circle draw, which knew where to look for them.  Then it returned, and then the caller says, oh, I put some stuff on the stack which the other guy used.  Now I'm going to free them.  So essentially the same number of things it pushed on the stack, it pops, in order to discard them, essentially.  So this has been very, very clever.



Now, there's one more thing that the stack is typically used for.  And that's local variables.  We just talked about passing parameters on the stack.  The final thing is, say that this circle draw subroutine needs to use some memory to do its work.  It needs some scratchpad memory.  It can use the stack, too.  It essentially can do the equivalent of pushing some blanks, some blank space on the stack.  And it knows where those blank spaces are.  So it's freely able to use them as scratch memory.  If it calls some other function, that's fine.  It might push those parameters on the stack, then call the function, and so forth.  The function comes back.  It pops those parameters, and everything is sort of undone.  So again, we have this incredibly convenient scratchpad facility where we're able to put parameters on the stack.  The stack is able to store where we came from so we can get back there, and we're able to use that stack as local scratchpad.



Now, it turns out this is, clever as it is, convenient as it is, this is the cause for more of the pain.  This is why Steve Ballmer had a meltdown.  This is the buffer overrun problem.  Why?  Because, think about it, we are mixing in one place both data and execution pointers.  Those return addresses that are on the stack that get us back to where we came from, the processor just assumes they're valid.  It doesn't know.  When you hit a return instruction, it pops it off the stack and goes where that says.  But that return instruction was living right next to data, scratchpad data, that the program may have been using for its own purposes.  What if the program allocates a buffer on the stack and then fills it with data that it receives from the Internet?  And what if that...



PADRE:  Oh, no.



STEVE:  Yes, yes.  And it's so convenient.  The stack is there.  It grows and shrinks as you need it.  Everybody uses it because it's just - it's self-serve.  It's like, oh, I need a buffer.  Allocate a block of memory on the stack.  It's always going to be in memory because it's not going to get swapped out.  It's local.  It's fast to access.  It's brilliant.  But you have to use it perfectly.  Otherwise you get in trouble.  And so hackers have exploited mistakes in code to write their own data and even overwrite like four bytes past where you should.  That's the return instruction from that subroutine, which the processor is going to believe.  And so if a bad guy can supply data and manage a buffer overrun, that wipes out the proper return instruction.  So when the processor tries to return from that subroutine, it goes somewhere else.



PADRE:  And this would get them past ENDBRANCH; right?  Because, I mean...



STEVE:  Precisely.



PADRE:  It's just checking for the ENDBRANCH.  It's not actually verifying that it's returning to what the ENDBRANCH said it should return to.



STEVE:  Right. 



PADRE:  Great.



STEVE:  Right.  So it provides a way for malicious parties to disrupt the proper execution of the code.  So, and where does the problem come from?  The problem comes from the fact that we are mixing data and execution.  We're mixing like program data and processor instruction data, mixing it all up in the same structure on the stack.  So what Intel did is another piece of brilliance.  They said, we're going to create a shadow stack.



The problem with the main stack is that, I mean, the beauty is it's so handy.  You push parameters on it.  You call a function.  The function can allocate its own local variables, and they'll be discarded when the function exits because the stack will be popped.  And then the return instruction returns to where it came from, and the caller pops its parameters that it had pushed for the callee, pops them, I mean, it's brilliant.  But the problem is it's under program control, and it mixes data and execution.



So Intel with CET is creating a shadow stack that the programmer, the normal system, has no control over.  And the only data that are pushed and popped are the ones that have implied use of the stack.  That is, a call instruction has an implied use of the stack because the return from the call is automatically pushed on the stack.  Similarly, the return instruction from a subroutine has implied use of the stack because the return instruction always gets the address it's going to return to from the stack.



So what the shadow stack does is it obeys the same implied activities for calls and returns.  But the programmer has no access to it.  That is, when you're pushing things on the stack, you're only pushing them on the visible stack.  When you pop them, you're only popping them from the visible stack.  But when you do a call, the visible stack and the shadow stack both store the return address.  And here's the key.  When you do a return, the system verifies that the shadow stack's return address matches the visible stack's return address.



PADRE:  Ah, there we go.



STEVE:  If they don't match, something is wrong, and the process is terminated.  So that completely prevents malicious use or even mistaken use.  This will catch bugs faster than anyone's business, immediately catch the bug.  But it will also immediately shut down anyone trying to use stack manipulation, buffer overruns, in order to get their own code to execute, to disrupt the function of a return instruction, to have that return instruction go somewhere else because it won't match what the shadow stack has because the shadow stack they have no control over, and it will always have the original true and correct return address.  If the system tries to return to an address that the shadow stack doesn't agree with, it immediately produces a system exception and stops running.  So it's just beautiful.



PADRE:  I see how this works, Steve.  But am I going to get a performance hit from checking two stacks?



STEVE:  No, it's all in the hardware.



PADRE:  Oh, nice.



STEVE:  Yup.  No effect whatsoever.  The burden's on Intel.  The chips are going to get bigger.  The wattage is going to go up.  They're going to burn more power.  There's going to be another bazillion little transistors.  But it just all happens by magic.  So I just think it's very cool.



PADRE:  [Vetman] in the chatroom asks if this requires OS support.  It shouldn't, though.  It's hardware control; correct?  I mean, the OS just would be told it's an invalid instruction.



STEVE:  No, I think it would require at least a driver.  Something in the kernel would need to turn this on.  And Intel will be defining some new exception errors.  And so the operating system would gain control and then decide what to do with it.  So there would be new features in the chip.  But it would probably be a matter of just adding a kernel driver to it instead of like a whole new operating system.



PADRE:  Okay, so then that's what they would go after.  They would go after the driver and basically just tell the driver to keep saying it's okay, it's okay, it's okay.



STEVE:  In order to disable the shadow stack.



PADRE:  All right.  So that will be on a future episode of Security Now!.  Once this gets implemented perfectly, someone will have infiltrated the driver, and the shadow stack will no longer work.  I love the game of cat and mouse, Steve, and no one plays it better than you.  We've heard about SpinRite.  We know that it's the tool that needs to be in all of our toolkits.  Can you tell them where they can find you?  Where they can find your work?



STEVE:  Well, after 1.26 million people, I think it is, downloaded Never10, everybody pretty much knows:  GRC.com.



PADRE:  I did not download Never10.  And I actually had three different machines that were hit by just weird Windows 10 updates.



STEVE:  Yeah, 1.266411 million downloads.



PADRE:  Wow.  And how long did that take?



STEVE:  To do what?



PADRE:  To get that 1.2?



STEVE:  Actually, I think this began in April.  And it sort of - it cruised along for a while.  But it was only like in the previous month, when Microsoft really put the screws on and really began to get more desperate, we saw a huge surge in downloads.  But it is the fastest, most popular piece of freeware in the history of GRC.  We have things that over two decades, things like - what was that little firewall tester?  Leaktest.  I don't know, like seven million downloads or something.  But it's been decades.  This thing is a few months old, and it's at 1.266 million downloads.  There's never been a more popular piece of freeware that I've written.



PADRE:  It just goes to show you, we've got empirical evidence on how many people are annoyed by Microsoft's super-aggressive Win10 upgrade.



STEVE:  Exactly.



PADRE:  Steve Gibson, of course, the brain behind the GRC.com.  He is my personal guru for all things security.  And more than that, Steve, it is always a pleasure to be able to chat with you, just to sit back and let the propeller-head go.  Sir, please, please, next time Leo goes away, please put in a good word for me.



STEVE:  It's been my pleasure, Padre, as always.



PADRE:  Of course, that does it for this episode of Security Now!  Don't forget that we're live here on TWiT.tv, live.twit.tv, every Tuesday at 13:30 Pacific time.  Steve will always be here to inject you with some healthy paranoia and keep you safe in the wonderful world of insecurity.



Now, you can find all of our shows on the TWiT show page at TWiT.tv/sn, that's for Security Now!, as well as on iTunes, Stitcher, and wherever fine podcasts are aggregated.  You can also find high-quality audio downloads on GRC.com, which is also where you'll find all the goodness that is SpinRite, ShieldsUP!, and coming soon SQRL.  Oh, and don't forget Never10.



I'm Father Robert Ballecer, the Digital Jesuit, in for Leo Laporte, saying that, if you want to keep your data into the future, you've got to remember Security Now!.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#566

DATE:		June 28, 2016

TITLE:		Listener Feedback #236

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-566.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with a fun and interesting week of security happenings, including an expensive Windows update, a worrisome FBI hacking court decision, a fix for slow Windows 7 updating, more Comodo slime, JavaScript cryptomalware, yet another way to exfiltrate data from an air-gapped computer, a worrisome Netgear router flaw, the COOLEST brilliant new idea of the year, some miscellany, and questions and comments from our terrific listeners.



SHOW TEASE:  It's time for Security Now!.  It's been a busy week.  I'm really glad to be back.  Steve Gibson will have a rundown on the latest security news, including a way to speed up those updates on Windows 7.  And then we'll answer 10 of your questions with 10 of Steve's answers.  It works out well that way.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 566, recorded Tuesday, June 28th, 2016:  Your questions, Steve's answers, #236.



It's time for Security Now!.  I'm back, baby.  And so is Steve Gibson of the GRC - what?



STEVE GIBSON:  I never left.



LEO:  You never left.  You never left.



STEVE:  I never left.



LEO:  In fact, by the way, first of all, thanks to Father Robert for filling in.  Did a great job.  Such a good job, people are saying, why is Leo back?  So I'm sorry, I'm back.



STEVE:  Well, we've solved the problem of you taking vacations.



LEO:  Robert's fantastic.  The sad thing is, I didn't realize, and you didn't say - you were so cute.  Because I'm telling you, I'm going down to Newport Beach, I'm going to stay at the Pelican Hill, and you're going, "Mm-hmm, mm-hmm."  It turns out I'm like a mile from you.



STEVE:  Actually, you never mentioned it on...



LEO:  I didn't.  Oh, okay.



STEVE:  You didn't mention it before you left.  And I only knew because I think I heard you say it to Paul and Mary Jo on Wednesday.  And then I thought, well, now, wait a minute.  And I sort of did a little bit of math, and I thought, I think that means that I'm not going to have Leo next week.  And so...



LEO:  I apologize for not telling you that.



STEVE:  I sent email to Father Robert, and I said, are you co-hosting with me?  And he had a busy weekend, and I didn't hear back from him till the beginning of the week, and he apologized.



LEO:  I'm so sorry.



STEVE:  He said, "Yeah, sorry I didn't get back to you sooner."



LEO:  No, that's my fault, I thought I had told you.  I totally apologize.  But I even further apologize because I'm literally next door, and I didn't realize it before, but I realized it when we got down there, and I'm driving by Irvine, I'm going, "Oh, that's where - oh, we're here?"



STEVE:  The only thing I could have provided mostly was tips on the right places to eat because...



LEO:  Yeah, because we went to all the wrong places to eat.



STEVE:  ...that's what I do.  And so, yeah.  I have a nephew who's with Salesforce, and he's now traveling a lot.  And so he spent a couple - he's got a couple business meetings down here in Southern California.  And so we'll get together, and I've been introducing him successively to one fabulous restaurant experience after another.



LEO:  Well, I now know why you live where you live.  For some reason, when I hear "Irvine," I feel like it's like City of Industry or something.  It's not.  But Newport Beach area, that coastal area is gorgeous.  It's out of town.  So you have the benefits of being in a city, but not living in the smog-laden L.A. valley.



STEVE:  What happened was, when I left the company that I had been at for a few years previously, and the president of a company down here in Southern California phoned, and he said, "Steve, I heard you're available." And I said, "No, Paul.  I've been working my butt off for a couple years.  I'm just going to take some time and see my friends again, who I haven't seen forever."  And he said, "No, no, no, no, we want to hire you."  And I just sort of said, "Well, no, you're down in L.A."  And he said, "No, no, no.  Irvine is not L.A."  And I was very skeptical.  And he said, "Let us just fly you down, and we'll spend a day, and then you can see what you think."  And it's like, oh, okay, fine.  So they flew me down into what at the time was a shack of an airport.  It was...



LEO:  It's still pretty small.



STEVE:  It was, yeah, the Santa Ana Airport.  And then picked me up and drove to Balboa Island.  We took the ferry over there.



LEO:  I love that.  Isn't that awesome?



STEVE:  We drove down the coast to Laguna.  And I'm looking around thinking, wow.



LEO:  It's just amazing.



STEVE:  This is not Los Angeles.



LEO:  Yeah, yeah.



STEVE:  Because I'm really - I'm not a city person.  I'm a suburb person.  And so I spent the day down here and saw the company.  And I said, okay.



LEO:  You didn't take the job, but you took the town.



STEVE:  No, I did take the job.



LEO:  Oh, you did take the job.



STEVE:  Stayed for exactly one year.  I hated it, and I quit on my anniversary.  Get me out of here.



LEO:  And of course that little shack is now the John Wayne Airport.



STEVE:  Oh.  And, please, do we have to - of course, you guys have the Charles Schulz Airport, so I guess that's what we do is we name small airports after famous people.



LEO:  What's nice is I can fly from Charles Schulz Airport to the John Wayne Airport, and it's a nice, easy flight.  So we'll come back.  I'll come back and say hi.



STEVE:  There's now a direct flight.  It began on March 26th, actually.  It's Alaskan Air that has a point-to-point for the first time.



LEO:  We drove because we wanted - I don't know why.  There was four of us, and I thought it'd be easier.



STEVE:  I know, and so I was figuring you weren't seeing that second-to-the-last episode of "Game of Thrones" because you were on the road probably.



LEO:  No, we saw it the night before we saw the last episode.  So we saw them back to back almost.



STEVE:  Oh, okay.  Right, right.  So you delayed that one by six days.  Yes, nice.



LEO:  We have the technology now.  It's kind of amazing.  Wow.



STEVE:  Oh, and thank god we do because I don't know what I'd do without my...



LEO:  Lisa's saying, okay, we're not going to watch "Ray Donovan" until the whole season's over, and then we'll watch it all at once.  And I said, yes, let's do it.  So what did we do?  We turn on the TV and, oh, "Ray Donovan" is on."  So we watched that.  It's hard.  It's hard.



STEVE:  So it's Q&A day.



LEO:  Yay.



STEVE:  Number 236.  This one, I have a really good feeling about this podcast.  Lots of fun news.  We had, I mean, and boy, this was just a Twitter-driven podcast because our listeners were sending me, breathlessly tweeting, things that were happening.  And I said, oh, yeah, yeah, it's in the show notes already.  Oh, yeah, yeah, I know.  So we had one particularly expensive Windows update for Microsoft, a troubling court ruling about FBI hacking computers, hope for slow Windows 7 updates.  Comodo drops to a new low level of slime behavior.  We've got new cryptomalware in pure JavaScript.  Yet another way to exfiltrate data from an air-gapped computer.



And you're not going to believe this one.  A worrisome flaw found in most Netgear routers.  And in fact I made it the bit.ly link of the day because people are going to want to check their Netgear router to see if it's among those.  And so I just thought, okay, that's the best use for this week's bit.ly link.  And what is probably the coolest and truly brilliant idea of the year.  Just so clever.  Then we have a little bit of cool miscellany I'll breeze through.  And then, really, some really great questions and listeners following up on last week, and a bunch of other new stuff.  So I think I can promise a really entertaining and informative two hours.



LEO:  And jam-packed, as usual, which is great.



STEVE:  Yeah.  I've got a great model that I really like with GRC's old-school NNTP news server because we just have a really perfect community there that...



LEO:  This is mostly for SQRL; right?  Or is it for other stuff?



STEVE:  Well, and it'll be for SpinRite, as soon as I get back to it, when SQRL's done.  But absolutely for SQRL.  And then - but like all the stuff I've done.  The DNS Benchmark was the same way.  And basically all of the projects I do, I do it in a community where I provide it to them, get feedback, lots of great ideas, and then go away, gin up the next iteration, and say, okay, how about this one?



LEO:  Steve's so old-school, I love it.  And actually, I mean, we use IRC, which is as old-school as NNTP.



STEVE:  Yeah.  Well, when I...



LEO:  Which predates, by the way, the web.  That's how old this is.



STEVE:  Yeah.  Well, and what works is that it's just text.  There's no rich media.  It's a pain to, like, attach anything.  But really it's just - it's dialogue is what we really want.



LEO:  Right, right.



STEVE:  When I mentioned recently bringing up a FAMP stack, a FreeBSD, Apache, PHP, and actually it's MariaDB, that's for GRC's forthcoming web forums because I recognize, once SQRL is done, we've got something like a quarter million listeners because we know we had 165,000 in one week, so that's probably two thirds of the total download.  The point is there will be a huge number of people playing with it.  And I can't accept email from everybody who's got a question or wants to know something.  So there needs to be a public place to organize that.  And so I'm in the process of bringing up for the first time a public-facing, high-visibility web forum.  It won't replace what we've got going on in the back because that's just so valuable to me.  But I just need something where people can ask questions and sort of help each other.



LEO:  Yeah.  Yeah, in about 20 years you'll get to GitHub and JIRA and, yeah.  No, I'm actually 100% supportive of this.  It's use the right tool for the job.  Whatever works for you is the tool to use.  And it's silly to abandon classics just because they're old.  I mean, I think that's fine.  I don't have a problem.



STEVE:  Well, I'm looking at my XP desktop here.



LEO:  I know, I know.



STEVE:  And it's working just fine.  Speaking of.



LEO:  Yes?



STEVE:  The Seattle Times, Matt Day wrote sort of the reference coverage of this.  All the other articles ended up sort of referring back to Matt's.  And he also quotes Mary Jo and Paul.  So this is about Microsoft settling a lawsuit that a woman whose name is Teri Goldstein brought because Windows 10 was just such a problem for her.  Matt wrote:  "A few days after Microsoft released Windows 10 to the public last year, Teri Goldstein's computer started trying to download and install the new operating system.  The update, which she says she did not authorize, failed.  Instead, the computer she uses to run her  Sausalito, California travel agency business slowed to a crawl.  It would crash, she says, and be unusable for days at a time."  He quotes her saying, "I had never heard of Windows 10.  Nobody ever asked me if I wanted to update."



"When outreach to Microsoft's customer support didn't fix the issue" - and by the way, she, like, spent days on the phone, so this is not like she's complaining easily - "Goldstein took the software giant to court, seeking compensation for lost wages and the cost of a new computer.  She won."  Then Microsoft, of course, couldn't let that stand, immediately said that they were going to appeal.  However, last month Microsoft dropped their appeal, and Goldstein collected a $10,000 judgment from the company.



And then Matt goes on, but later in the article he says:  "Mary Jo Foley, a journalist who has closely followed Microsoft for decades, wrote recently that the company has made saying no to Windows 10, particularly for non-savvy people, quote, 'nearly impossible to implement.'  Paul Thurrott, another longtime Microsoft follower, criticized a recent popup asking users if they were ready to get Windows 10.  In the prompt, the X in the upper right corner, long known to Windows users as a way to exit a software program or abort a process, is interpreted by the update tool as an agreement to go ahead with Windows 10."  He then quotes Paul saying, "The violation of trust here is almost indescribable."



So anyway, I think clearly what happened is Microsoft was concerned that they might lose on appeal, and that would have set just a horrific precedent for all of this Windows 10 upgrade fervor.  And so they thought, you know, better not to set that precedent.  We'll just, I mean, Microsoft said they didn't want to invest any further in this case.  And it's like, come on.  Microsoft doesn't even feel $10,000 or whatever their cost of litigation.  If they thought they were going to win on appeal, that's what they would have done in order to foreclose anybody else thinking that this was a good idea.  So I think they just thought, look, we can't afford to lose on appeal.



LEO:  The good news is our long national nightmare is almost over because it ends July 29.



STEVE:  Yes.  I was interviewed for an article in the San Jose Mercury News last week, and I have an interview scheduled with Consumer Reports tomorrow on the whole - on my involvement in this with Never10.  The downloads have slowed from about 35,000 is where they peaked per day, down to 15.  And we're at about 1.365 million downloads of Never10.



LEO:  Wow.



STEVE:  So it's been going crazy.



LEO:  Wow.  That is amazing.  And the thing about that is there's no reason to download it more than once.  So that means really very close to that number of people have used it on that number of Windows installations.  That's really impressive.



STEVE:  Well, and as you'd expect, all the other download sites have jumped on and are offering it also.



LEO:  Right.  With their ugly wrappers.



STEVE:  So it's maybe probably not as much as GRC, but maybe in aggregate again about that much.



LEO:  And according to Ghacks.net, this is the new Windows 10 invitation, which is much clearer and has a button that says "Decline" on it.



STEVE:  Yes.



LEO:  And it also has much better prose underneath on what to expect, including that you can roll it back, and how big it is, and it's going to be a big download.  I mean, I think this is good.



STEVE:  Yeah.  So they finally, like when they exhausted all other possibilities, they said, uh, okay, fine.



LEO:  Black mark.  It was just a black mark on their escutcheon.



STEVE:  We'll do what we should have done.  It's, yeah, crazy.  Okay.  And this is the second most brought to my attention issue was a very troublesome ruling which is tantamount to the court saying that users have no expectation of privacy for the contents of their own computers in their homes.  So, okay.  The timeline here is back in 2014.  The FBI tracked down just a horrific child pornography site, just horrifically called "Playpen," of all things, which was a Tor-hidden service.  And their strategy was to also rope up, not just the people who were running the site, but to get the people who were using Tor as an anonymizing service to access this creepy site.



So they kept the site up, and they arranged to inject some of their own technology - it was called "NIT," N-I-T, for Network Investigative Technology - into the machines of subsequent visitors to this hidden Tor child pornography site called Playpen.  So one of these creeps, first of all he's alleging that the traffic or the bandwidth that the FBI has obtained from his machine may have been unencrypted at some point, so some third-party man in the middle could have injected this content.  In other words, he's saying - he's trying to use the defense that, oh, no, they didn't really get this from my computer.  My computer is clean.  I'm innocent.  This came from someone who somehow thought to, I mean, that's this guy's defense.



So the problem is, and we have zero sympathy for this person and anyone else who's there, but the problem is the ruling of the court in this case and the possibility for creating some very worrisome case law because some of the opinion which the judge has generated hinges around IP addresses and whether IP addresses - because of course that's what the Tor network is hiding.  The whole point is by jumping through Tor nodes you're hiding your IP address.  So the question is whether IP addresses are private and subject to Fourth Amendment protection or already public.



So there's a senior United States district judge named Henry Coke Morgan Jr., who wrote:  "Generally, one has no reasonable expectation of privacy in an IP address when using the Internet."  This, he posits, is because we all voluntarily give up our IP addresses to third parties every day, such as to our ISPs and any websites we visit.  And when it comes to Tor, users have to connect to and disclose their IP address to the initial node of the network.  Well, of course, that reasoning is a little flaky because the whole point of using Tor is to hide your IP.  And we know that the Tor system does the best, is the best technology we have currently for making that happen.



And then there's something else interesting that I encountered as I was digging around into this, which sort of factors into some of the reasoning, which is known as the "broken blinds test," which allows passing law enforcement officers to legally peer into someone's home if their blinds are closed, but broken in such a way that there's some visibility allowed.  So there was clearly some case law in the past where this was argued over somebody had their blinds closed, but one of the louvers was a little bit ajar, leaving a crack, and so somebody was able to see in through the broken blinds.  And so that generated some case law about whether or not the intent of the owner was to have privacy and so on.



So then, continuing, the FBI's investigative software then grabbed more than just the suspect's IP addresses.  It also obtained their username and some other information from their machine and sent it to the FBI.  And that information is undoubtedly within the user's computer.  So there was some argument here that, well, the IP address is not actually in the computer.  It's the way the person connects to the Internet.  So that's really not theirs, and it's not their private information.  And so the argument was, oh, but what's inside the computer is private.  Well, but what the FBI got came from inside their computer.



So then again, in arguing against that logic that this person's defense attorney was coming up with, Judge Morgan said that - he said the defendant has no reasonable expectation of privacy in his computer.  He wrote: "The NIT [Network Investigative Technology] only obtained identifying information.  It did not cross the line between collecting addressing information and gathering the contents of any suspect's computer."



But then, finally, most horrifyingly, he writes - and this whole case is full of horror.  He says:  "It seems" - get a load of this.  "It seems unreasonable to think that a computer connected to the web is immune from invasion.  Indeed, the opposite holds true:  In today's digital world, it appears to be a virtual certainty that computers accessing the Internet can, and eventually will, be hacked."  He then references a series of media reports on high-profile hacks and posits that users of Tor cannot expect to be safe from hackers.



Now, of course our friends at the EFF are apoplectic over this.  And I'll just share the beginning of a longer post where the EFF wrote:  "In a dangerously flawed decision unsealed today, a federal court in Virginia ruled that a computer defendant has no 'reasonable expectation of privacy' in his personal computer located inside his home.  According to the court, the federal government does not need a warrant to hack into an individual's computer.  The implications for the decision, if upheld, are staggering," writes the EFF.  "Law enforcement would be free to remotely search and seize information from your computer without a warrant, without probably cause, or without any suspicion at all.  To say the least, the decision is bad news for privacy.  But it's also incorrect as a matter of law, and we expect there is little chance that it would hold up on appeal."



LEO:  Oh, that's interesting.



STEVE:  Yes.



LEO:  The broken blind defense isn't necessarily apropos.



STEVE:  Yes.  It doesn't - I think that's where the judge went too far is to say that experience demonstrates that computers are not secure.  Therefore it's like saying all blinds are broken.



LEO:  Your blinds are broken; right.



STEVE:  And it's like, eh, come on.



LEO:  I mean, there's even a larger issue about the FBI running a child porn site for any length of time.  I mean, maybe that's legal, but that's creepy as hell.



STEVE:  Well, certainly it's creepy.  I guess, I mean, someone I guess would argue, and I don't know the law, but where does entrapment begin and end?  I don't know where that boundary is.



LEO:  Well, it's not like they set up the site themselves.



STEVE:  Correct, correct.



LEO:  But they kept it running, which I think is kind of creepy.  I mean, again, it may well be legal.  I'm not saying [crosstalk].  I just think it's creepy.  They ran it for months.



STEVE:  Yeah, they ran it for a long time.



LEO:  For months.



STEVE:  In order to snare the people who were going, which no one is going to say that's not a good thing.



LEO:  I was on a jury trial that was thrown out halfway through for entrapment.  It was one of those Dateline "To Catch a Predator" cases.



STEVE:  Right.



LEO:  And the prosecution got to do its whole thing.  Then the defense moved, "Your Honor, this is entrapment."  And the judge said, "Yeah, you're absolutely right," threw the whole thing out, and we all went home.  Because, I mean, but this is - that was different.  They really did set the whole thing up.  The guy was never chatting with a teenager.  He was always chatting with an adult.



STEVE:  Well, didn't they - I thought that they were able to get some convictions.  



LEO:  I'm sure they did.



STEVE:  [Crosstalk] different court?



LEO:  Yeah, different courts.



STEVE:  Because it would seem to me that - I remember for a while MSNBC was running that show.



LEO:  Oh, horrible, horrible.



STEVE:  And it was sort of really very creepy.



LEO:  Yeah.



STEVE:  But they were all sort of this - they were variations on exactly the same theme.  There were no underage people involved, so they were always getting people acting underage.  And so I would think, if it's entrapment for one, it's entrapment for all.



LEO:  And that's why you and I aren't judges or lawyers, my friend.  



STEVE:  Yeah.  So we got good news, but it's going to take some action on the part of our listeners.  And that is that - and this was Woody Leonard who had the best coverage.  He's been writing for InfoWorld forever, "Woody on Windows."



LEO:  Yeah.  Wow.



STEVE:  He's been in the industry also forever.



LEO:  Good, good, good.



STEVE:  And when I turned my Windows 7 machine on today, one update, it always wants to try to give me Silverlight.  And it's like, no.  And it's so funny because I keep marking it no and don't ever ask me again, and Microsoft doesn't care.



LEO:  You know what's funny, they don't even put Silverlight on Windows 10.  They don't like it.  They deprecated it years ago.  It's crazy.  Crazy.



STEVE:  So the other one, which was optional, is 3161608.  That finally fixes the slow update problem.  Woody's article, and I have the link to it in the show notes if anyone's interested, but you can probably find it if you just maybe google "Woody on Windows."  And I'm sure it's a recent column.  He's talking about two different patches.  One's actually a knowledge base - yeah, there it is.  And it's this 3161608.  It was suggested as optional.  And it's funny because I'd just put the show notes together, and I thought, wait a minute, 3161608?  That sounds really familiar.  And that's the one.



So it's a rollup of a bunch of other updates.  Woody goes into it in detail, and it will just make your eyes cross because it's all kinds of interactions of five or six different things, and one's going in one direction, and one's going in the other.  And so finally you just get down to, okay, 3161608.  I want that.  And what Woody's been reporting, because of course he's been feeling this, and remember Paul's story about trying to install Windows 7, basically it ate his entire weekend because hours go by.



LEO:  Oh, that's right, yeah.



STEVE:  Even days, with it just sitting there saying, updating Windows, while no network activity, no CPU usage.  It's like, what is going on?  So it turns out that there was a problem in the win32k.sys DLL, or device driver, that this fixes.  The problem is, if you've got Windows set not to install optional updates, you won't get this.  So people who are on Windows 7 - and it's an out-of-cycle update.  This wasn't last Tuesday or Tuesday before.  I don't know what day it is.  Anyway, here we are at the end of the month, this is the 28th, so this wasn't a Patch Tuesday.  This is something that just - and Woody mentions it's just coming out now.  But my machine got it, and I did not have to go ask for it.



And so we'll find out on the second Tuesday of July - July 4th is Monday, so the 5th is the first Tuesday, so I guess it'll be the 12th - whether this has been fixed.  So everybody who's got Windows 7 and has been having trouble with these slow updates, the good news is it's fixed, but you've got to go get it at the moment.  Maybe Microsoft will move it over into recommended or important or whatever at some point.  But at the moment they need it.



Okay.  Comodo, who is always in the doghouse, has put themselves there again.  Of course they were the Superfish people and so on.  And there's just no excuse for what they tried to do.  Their CEO finally went into their own forums to try to defend their behavior.  They have tried to acquire the Let's Encrypt trademark.



LEO:  What?



STEVE:  Yes.



LEO:  Jerky jerks.



STEVE:  It's unbelievable.  So Let's Encrypt posted on their blog:  "Some months ago, it came to our attention that Comodo Group, Inc. is attempting to register at least three trademarks for the term 'Let's Encrypt,' for a variety of certificate authority-related services.  These trademark applications were filed long after the Internet Security Research Group" - the ISRG that we've talked about often are the group that did Let's Encrypt - "started using the name Let's Encrypt publicly in November of 2014" - which is when we started talking about it because I have always been so excited about this being the solution - "and despite the fact," writes Let's Encrypt, "the fact that Comodo's 'intent to use' trademark filings acknowledge that it has never used 'Let's Encrypt' as a brand."



So they attempted to use their size, essentially, their clout to simply trademark, to get trademarks on Let's Encrypt.  The Let's Encrypt folks continue:  "We have forged relationships with millions of websites and users under the name Let's Encrypt, furthering our mission to make encryption free, easy, and accessible to everyone.  We've also worked hard to build our unique identity within the community and to make that identity a reliable indicator of quality."  Which of course, if Comodo had it, would be blown.  "We take it very seriously when we see the potential for our users to be confused, or worse, the potential for a third party to damage the trust our users have placed in us by intentionally creating such confusion.  By attempting to register trademarks for our name, Comodo is actively attempting to do just that."



And there was such backlash in Comodo's own forums, I read some of these postings by the CEO, who I just couldn't believe it.  He was claiming that Let's Encrypt stole their idea.  And it's like, what?  No, they didn't.  And, like, we came up with 90-day certificates, and these people have stolen it, so we're just going to steal their name.  And it's like, what?  Anyway, the good news is all of this happens now on the Internet, and it's impossible for this to happen without everyone knowing.  There was a such an outcry and backlash that they then abandoned this effort.  And in an update to Let's Encrypt's posting, they have notified the industry that Comodo has dropped their effort to obtain Let's Encrypt's trademarks.  Unbelievable.



So again, Comodo, no.  If you want a certificate, get it from DigiCert.  If you want a domain name, get it from Hover.  DigiCert is, like, it's just everybody that I've recommended has come back and said, wow, these guys are great.  And of course I've had the same feedback from Hover.  And I thank our listeners.  Many of our listeners suggested that when I was deciding to move away from Network Solutions finally, that I switch to Hover.  And if I didn't make sure - I want to make sure everyone knows that it is standard in the industry, which I wasn't aware, that any remaining time that you have at a different registrar is honored by the receiving registrar of a domain transfer.  So there's just no reason not to move.  And Hover continues to be a great experience for me.



The Sophos guys do their Naked Security Blog, and what has come to their attention is that there's a new approach that malware is taking which is quite worrisome.  I mean, it's not necessarily more potent, but it's maybe potentially so.  And that is that in 2015, where they have a full year's worth of research, it turns out that even now, in 2015, Word macros, that is, Microsoft Word macros are, and were in 2015, the number one vector of infection.  So it was phishing mail and email coming to people with attached DOC and DOCX files, which were getting into people's machines.



Now, they note that Word macros are now blessedly disabled by default.  But the document can sense that and tell people, oh, look, you've got Word macros disabled.  This document requires them to operate.  Please turn them on.  And so somebody who doesn't know any better will go, oh.  Oh, and it's like, if what's below looks scrambled, it's because you need the macros turned on.  And so there's a scrambled document being shown.  The person then figures out how to turn macros on, and the virus launches in their machine.  So these are typically JavaScript macros.



Now, the problem, of course, is that by default, as we know, Windows hides file extensions.  And the trick is that you name the file "invoice.txt.js."  So Windows strips off only the final .js, showing the unwitting user invoice.txt.  The other problem is that the icon for scripting is kind of that yellow scroll-y parchment-looking thing and so kind of looks like a text.  So it doesn't, the icon doesn't make it look like it's non-textual and it's going to run code because users don't know what scripting is.  And so Microsoft designed an icon for scripting that's ambiguous, at best.  So people end up running this, not knowing any better.



What's changed now - now, normally what Sophos has seen is that the JavaScript simply fetches an executable from a remote website and sucks it in and runs it.  The problem is, now that perimeter defenses are getting better, script-pulling EXEs from a remote location, or even if the file is renamed, because of course it could be named something else, and once it arrives,  the script itself could rename it to an EXE and then invoke it in order to run it.  But deep packet inspection that we now have increasingly on proxy connection boundaries in corporate Intranets, they're looking into the file, and they will see that this is a renamed EXE and prevent it.



The problem with JavaScript is it's just text.  And so what has happened is we are now seeing 100% pure JavaScript crypto ransomware.  So as we know, the whole cryptoware is the new scourge because it encrypts people's files that they need and then demands ransom in order to decrypt it.  There is publicly available, high-level, full RSA public key and AES symmetric key crypto libraries in JavaScript which are beautifully written.  The Stanford JS security library is one of my favorites.  And so these guys don't even have to do this themselves.  They can grab these modules.  The crypto is as good as any that you can find anywhere.  No external EXE needs to cross the boundary.  The entire crypto ransomware is built into the user's machine.



Now, the big problem is that this is executed by the Windows scripting host, WSH.  And JavaScript, the .js file extension, the handler is the Windows Scripting House by default.  So what I would recommend our listeners do for their own safety, and also especially for their family members and nontechnical friends who don't know any better, how often are you deliberately running scripts by double-clicking on an icon?  That's so rare and so dangerous, it should not be the default.  But all of Microsoft's defaults are for the first 10 years, until they finally get a clue and decide, oh, look, everyone's getting infected this way, and no one's actually using what we have, so let's turn that off by default, like they finally did with Windows, where they've got Windows macros disabled.



So the first thing I would recommend people do, certainly the first thing I do when I'm sitting down at a new Windows install, is I turn off "hide extensions for known file types."  I just can't imagine seeing only the first names of files.  It's just part of - I'm sure that that's the case for our listener base, too, is you look at the type of file that you're dealing with.



The second thing is you want to change the association, the file association, so that it opens with Notepad, which is safe, rather than the Windows Scripting Host, which is not.  Which is easy to do.  You just name a file hello.js and then - create a new text file, rename it .js, then right-click on it and choose "open with," and it'll default to Windows Scripting Host.  Instead, go down and find Notepad.exe, or put it in if it's not made available to you, and then choose the "always use this app to open .js files."  That will change the association away from the dangerous Windows Scripting Host and just not run JavaScript.  If anything tries to execute the JavaScript, it'll just pop up in Notepad rather than execute.



And, boy, in this day and age, that's the way Windows systems should be configured.  Especially now that it's no longer necessary to pull executable content in from the outside.  What they were finding, what the bad guys were finding was their EXEs weren't getting fetched by the script that was running because the border defenses have gotten smart enough now to keep that from coming through.  So now it's just pure text.  And that can bite you just as badly as traditional executable content.  Okay, Leo.



LEO:  Uh-oh.



STEVE:  Yet another way to exfiltrate data from air-gapped computers.  We've talked about all of the crazy emanations that computers generate.  Back in the day, you used to put an AM radio on top of an IBM 1401 and play Christmas carols by changing the length of the loops in order so that AM radios set in between stations would pick up different audio frequencies as essentially a heterodyne of the carrier that the big computer was emitting.  And of course all of our machines are shielded and insulated from generating radio frequency interference.  But we've talked about how even a cable extending out of the machine creates an antenna that allows people to obtain information.  And then there's the screen, where you're able, just from, again, from the leakage of RF, radio frequency information, through a wall, the image on the screen can be recovered without seeing it, just based on the emanations.



So some researchers have gone to the next, well, I don't know if this is the next step.  This is really - this is, like, obvious in retrospect, but not something we probably need to worry about too much.  And that is they ask themselves what else does software have control over in our computers?  Well, software can control the fan speed.  And believe it or not...



LEO:  Oh, no.



STEVE:  ...just sort of for some giggles, as they say, these guys thought, let's do the math.  Let's make it happen.  So they analyzed the spectrum of sound generated by a PC case's fans.  And they wanted to find a set of frequencies where it wouldn't be obvious to someone sitting there that the fan speed was changing.  So they settled on 4100 rpm and 4500 rpm, just moving the fan back and forth, or fans back and forth between those two speeds.  And it turns out that it generates a significantly distinctive frequency that a spectrum analysis of the sound made by a smartphone four feet away is able to differentiate.  Now, because of inertia, it takes a while for the fan to get up to speed or down to speed.  So the best these guys were able to do is 10 bits, 10 binary bits per minute.



LEO:  That's like the Mars Rover.



STEVE:  Yes, it's slow Morse code.  Actually it's slower than Morse code, right, it's very slow.  That would be 600 bits per hour, which for a full day would be 14.4 kbits per day.  Now, of course, old modems were 14.4 kbits per second.  So this is painfully slow.  On the other hand, it works.  So imagine a scenario where, I mean, you can sort of imagine maybe a system where - well, now, you would have to first infect this machine.  You'd have to want data out of it that you can get no other way.  So it's infected in some bizarre means where the infection is one way, yet you will never then - it has no network connection, no WiFi or wired connection.  It is air-gapped.  Yet you have some facility that is hi-fi audio and a means of listening to this thing.  And you can export 14.4 kilobits of that machine's private internal data per day.



LEO:  Well, if it were just a PGP key or something, that'd be enough.



STEVE:  Yeah.  I mean, that's a good point.  There are, for example - that's a very good point, Leo.  If, for example, it was protected with TrueCrypt or VeraCrypt or any of the encryption tools, as we know, while those drives are mounted, the key must be in memory in order to drive the symmetric encryption and decryption.  So the weakness of those is anything that's able to access the process running the crypto could find the key.  And we've seen those exploits.  And exactly as you say, those keys are - they're, what, typically 256 bits.  So a couple hours. 



LEO:  Yeah.  In a related story, a hacker has modified his floppy disk drives to play the "Game of Thrones" theme [plays media].  Just thought you'd enjoy that musical interlude.



STEVE:  Yes, I love those big arrays of floppy drives doing various pieces of music.



LEO:  That's more than 14.4 kilobits a day, let me tell you something.



STEVE:  That's a lot of data.  Okay.  So today's bit.ly link, bit.ly/sn-566.  That will take you to Netgear's knowledge base page, where you can look up the model number of Netgear router.  Because here's the problem.  This is not a showstopper, but this is a good reason to get on the ball and update your firmware.  What's been found is that there is a worrisome vulnerability in Netgear routers such that - and Netgear does not go into detail, and I didn't bother to dig because it would have been academically interesting, but not crucial.  If you don't have password recovery enabled, apparently there's a problem.  If anyone can get to your router, they can get your password.  So that would mean anyone on your LAN that is inside the network can obtain your password through some fault in the firmware.



Or, even if you have a strong username and password, and you're counting on that to protect your web facing, that is, your WAN-facing interface, if you have remote administration enabled by default, that could be cut through right now.  Now, it's disabled by default.  So someone would have had to deliberately turn on remote WAN admin.  But the problem is that, of course, exposes a server, probably a web server, running in the router to the Internet.  Now, a user might go, okay, but I put in a really good username and password.  What this means is that won't help you.  Anybody can obtain that and get into your network from the outside.



The good news is most people are not going to have that enabled.  I mean, it's horrifying to think that that would be enabled.  But what's weird is that - so Netgear's workaround is, if you enable password recovery, which is sort of strange, I mean, if you forget the password of your router, you just do a factory reset, and then all is forgiven, and then you reconfigure it; right?  But there is a password recovery feature.  And when you turn it on, it gives you the two fields of previously prepared questions about your mother's maiden name and your first pet's name and the middle name of your oldest sister and so forth.



So the idea would be, some people would not want to do a factory reset if they forgot their username and password.  They would rather tell the router the answer to the questions and then have it ask them if they need password recovery.  Okay.  So the point is, if you turn that on, dumb as that is, that's a short-term workaround until Netgear gets the firmware updated to address the problem.  And believe me, the list of routers is extensive.  It's all of the WNDR routers, I mean, it's like, it's not just old creaky routers.  It looks like the Who's Who of Netgear routers.



Which is why I made a bit.ly link, bit.ly/sn-566.  That will allow you to quickly see whether your router's on the list.  You can then - there's a link there where you can sign up to receive email from Netgear as soon as they've got a firmware update.  It's my.netgear.com/register.  So that's sort of generic, register with Netgear as an owner of a Netgear router.  I don't know if they do anything specific when you go there.  But Netgear wrote:  "Netgear is aware of the security issue that can expose web GUI login passwords while the password recovery feature is disabled."  And by the way, it's disabled by default.



"This vulnerability occurs when an attacker can access the internal network or when remote management is enabled on the router."  So any contact with the router allows someone to defeat your username and password, no matter how clever it is, if password recovery is disabled.  So in the short term, if your router is one that is affected, turn on password recovery and just put gibberish in the Q&A fields there, and you'll be okay until Netgear is able to address the vulnerability.



Okay, Leo.  Now there's not much conversation in this YouTube video.  So it would work wonderfully if we had a high viewership of this podcast, but we know that it's predominantly audio.



LEO:  You can narrate it.



STEVE:  This is the coolest idea of the year.



LEO:  A car with a person.  And our voices are transmitted through speakers.  Problem is, anyone can hear the transmitted sound.



CLIP:  Users of smart watches make calls on speaker phone, meaning they have almost no privacy.



LEO:  Oh, this is our friend.



CLIP:  Your phone rings, shattering the silence.



LEO:  That's [C.P. Grey].



CLIP:  But it's deep inside your bag, and you frantically fumble through your belongings.  Then how can we solve the aforementioned problems?  [Buzzing]  Finally, we found the answer, taking cues from vibration.



STEVE:  It's so good.



CLIP:  TipTalk is a new UX.  It's a product of watch strap type, so you can change the strap with any existing watch.  Of course, you can also accessorize with it as a band.  The smart strap has Bluetooth and BCU vibrator inside.



LEO:  This is like robot voice.



CLIP:  When you receive a call, your smart phone ends a signal to TipTalk via Bluetooth.  TipTalk vibrates the BCU, and it transmits sounds through fingertips, not through the app.  Users touch their ears with their fingertips and hear the sound.  TipTalk can read your messages in private.



STEVE:  Is that too cool?  I just love that.



LEO:  Well, if it worked, it'd be cool.



STEVE:  Well, watch the people's expression.



LEO:  They're going, "What is he saying?"



STEVE:  When they try it.



LEO:  So he's putting it - now, this is real people.  Of course, we're not hearing what they're saying.  They could be saying, "What the hell is that?  Oh, that tickles.  What did he say?  Oh, my.  Huh?  What?"



STEVE:  Anyway, I just love the idea.



LEO:  Well, would you like to contribute to a Kickstarter fund?



STEVE:  Hey, I got a great coffee mug.  I got a great thermal insulating coffee mug, and it only took three years to get it.



LEO:  I've got, let's see, I've got a little Kickstarter project starting up here for this watch.



STEVE:  Anyway, I just love it, the idea.  So for our listeners...



LEO:  It was at CES.  We missed it somehow.



STEVE:  Just the idea that you just - you touch your ear, and this thing vibrates your finger, and you hear the audio.  Oh, there it is.



LEO:  This is at CES, and this is XDA developers.  So they're smart.  They know what...



CLIP:  Not that many people have gone into the smart wristband.



LEO:  But why, you know, this was announced in January.  Why don't we have it yet, if it's so cool and all that?



STEVE:  I figured you'd be first in line, Leo.



LEO:  I have learned.  I'm still waiting for my floating bonsai tree.



STEVE:  Sure.



LEO:  And my Temperfect Mug, by the way.  Sounds like they made just enough to get Steve Gibson off their ass.



STEVE:  Okay.  So a couple quick bits of miscellany.



LEO:  Yes.



STEVE:  I have an incredibly exciting announcement over on the Healthy Sleep Formula front.  I put up the news on the page last week - or, I mean, yesterday - that I would have something.  Over the Fourth of July weekend I will bring it up.  Essentially I have what I think is a breakthrough, reducing the formula to two tablets which are far more effective than anything we had before.  So I just wanted to give our listeners a heads-up.  That's all going to go away.  And anyway, I've been testing this new approach for a couple days.  I've never had reliability this high.  What I had didn't work for some people.  I think this may be a home run.  So I just wanted to point people there.  I will have additional information up a week from now.



And Leo, I heard you mention on MacBreak Weekly that you had not seen the last Terminator, the most recent Terminator.



LEO:  "Terminator Genisys," right?



STEVE:  So I just wanted to say it was a ton of fun.



LEO:  Ah.



STEVE:  It was really - it was faithful to all the mythology.  It used some really wonderfully tangled time travel-y stuff.  And everybody loves time travel paradoxing.  And so it had a lot of that.  I just - I loved it.



LEO:  Good.  I'll watch it.



STEVE:  So I did want to - I wanted to recommend it.  I can commend it without reservation.  A lot of good computer-generated special effects.



LEO:  Yeah, they make Arnold look young.



STEVE:  It was a great movie.



LEO:  Which is quite an effect.  And Emilia Clarke's in that.  That's why we were talking about it.  The Mother of Dragons from "Game of Thrones" is Sarah Connor.



STEVE:  There will only always be...



LEO:  One Sarah Connor.



STEVE:  ...one Sarah Connor.  And not her.



LEO:  But that's okay.  I can do suspension of disbelief.



STEVE:  It was a great movie.



LEO:  Good, good.  I'll watch it.



STEVE:  And I got a nice note from a Steve Reed, who's in Rockville, Maryland.  And he ended actually a much longer note by saying:  "Thanks for the time you put into the podcast and all the other great products you make.  I have our company halfway to a site license and expect to get the other two very soon."



LEO:  What is it, $45?  I don't understand.  What, he's passing the hat? 



STEVE:  Well, yeah.  So he said, every time SpinRite fixes a drive, we buy another license.



LEO:  Oh.



STEVE:  And so, okay.  So here's the deal.  And this is sort of interesting.  I never thought of sort of this incremental approach before.  But my license agreement, I mean, all of our listeners know that I'm very understanding about the SpinRite license.



LEO:  Generous would be the word.



STEVE:  From the beginning, I always felt it was ridiculous and unreasonable to think that somebody would buy a license per drive.  But what's interesting is, if you look at any other hard drive utility or backup or mass storage or anything, they all say you can only use this on one single machine, or on one hard drive.  And I remember getting into a fight with my company when I had 30-some employees because they wanted to go the same route as everyone else.  And I said no, come on.  If some person buys this, I'm not telling them they can't run it on, like fix all of their drives, or maintain all of them.



Now, admittedly, back then, drives were $10,000 or $5,000.  I mean, most people had floppies back when SpinRite was being born in the late '80s.  But still, this has always been the case.  And we all know that I don't even mind if you fix your friends' or family's computers with it.  I mean, it's paying the bills, and it's made a great living for me, and I'm happy to do that.



For corporations, though, it seemed like, you know, if they've got a big building full of computers, maybe $89 is not enough to ask for.  But I also kind of wanted to allow people to try it, verify that it works, and then somehow sort of move up to a license, a site license.  And so I just thought, okay, four copies of SpinRite.  If a company buys four copies, then they have - and it's all on the honor system.  There's no DRM.  There's no protection.  I won't know.  That's the right way to do it.  They buy four copies.  Then, with our blessings, they can use it forever on all of the drives they have in that location.



We do have what we call an enterprise license, which is 10; in which case, like IBM has an enterprise license.  Actually, they have an international license, which is 20 copies.  So IBM gets to use it in all of their offices everywhere on Earth.



LEO:  Wow, on like their 800,000 machines.



STEVE:  Yeah.



LEO:  You're very generous, Steve.



STEVE:  Very generous, yeah.  So I'm making less per, but that's fine.  So what Steve has done, he's like, okay.  And I think this is like a neat compromise, is SpinRite fixes a drive, they buy a license.  So it's recovered two drives so far.  And he says, as two more fail, then he will each time buy another one.  They'll get up to four.  Then they have a site license.  And, Steve, stop buying them at that point because then you're fully site-licensed.



So that's sort of a cool - and that's why I did it was to allow people - if I had like a site license, and then a SpinRite license, people would say, well, but we already got SpinRite license.  Now we want a site license.  It was like, oh.  So, like, what, we had the discounted site license for people who already have a single-copy license and all that.  And I said, no, no, no.  Let's just - I'll make it one copy for end-users, four copies for corporations that want to use it at will across all of their machines.  And then, of course, if it's a multisite license, that's 10.  And if it's an international multisite, then it's 20.  And it allows people to move forward.



And my expectation in the future was that at some point, once the 6.1, 2, 3 series is behind me, I'll be working on 7.  That will be a paid upgrade, whereas all the 6-point releases are free, as we know.  And then the idea would be that people would simply upgrade how many copies they have on whatever license they have in order to move to 7.  So the whole thing sort of fits together.  It's weird, but it sort of made sense to me.  So that's the plan.



LEO:  And that's why Steve is Steve.  Leo Laporte with Mr. Steven "Tiberius" Gibson.  And we go to Question #1 from Simon C. in Lymington, United Kingdom, who was paying close attention and thinking about the ENDBRANCH instruction.  Was this from last week?



STEVE:  That was last week, yup.



LEO:  Did you talk assembly language when I wasn't here?



STEVE:  Oh, we did some deep assembly language.



LEO:  What'sa matta you?  Oh, man.  Now, that I would have enjoyed.



STEVE:  Leo, you know it's been recorded.



LEO:  Oh, I could listen to it, couldn't I.  What do I do, I google "adobe marketing cloud" and "ENDBRANCH," and then I'll find it.  He says:  I was listening to SN-565, where you were describing how the ENDBRANCH instruction would limit an attacker to calling complete functions instead of small snippets as the destination of a call has to be an ENDBRANCH. But an attacker would actually have a little more freedom than that because the control flow within a function would cause there to be an ENDBRANCH at the start of any basic block targeted by a jump.  An attacker could jump to one of these and execute a subset of the function, presumably some part of an otherwise valid control flow.  Of course, this makes it a lot harder to find useful code to execute, as the granularity of jumping is now basic block rather than instruction or even sub-instruction level.  Make sense?



STEVE:  So I deliberately omitted a detail because we already, as everyone who survived last week's episode knows, there was plenty of detail as it was.  But I appreciated Simon's note because he had his pencil sharpened, and he was paying attention.



LEO:  Paying attention, yeah.



STEVE:  And it is only indirect calls and jumps that are subject to this ENDBRANCH instruction as their landing pad.  So the way Intel instruction set works, conditional branches and jumps within subroutines are fixed offset jumps.  They are not indirect jumps, that is, driven by data, but they're compiled in with a jump forward 32 bytes, or jump backwards 526 bytes.  So they have assigned offset that advances or retards the instruction pointer.



So anyway, as a consequence, that is exactly what Intel was thinking.  That's why they only made it for long indirect calls and jumps so that the innards of subroutines are not peppered with ENDBRANCH instructions, only the sanctioned entry point to the function which is being jumped to through a ring transition or from another process or another module where dynamic linking has created indirect linkages between these pieces of the system.  So you're right on the money with your thinking, Simon.  But it turns out I didn't add that complexity because people's heads were exploding as it was.  So good on you.



LEO:  Wow.  I'm listening to this episode.  Fascinating.



STEVE:  It was neat.



LEO:  Mike Woolard, Cleveland, Ohio wonders why SQRL even needs a button to log on:  I was talking to a coworker about SQRL.  He said, well, wait a minute.  Does it even need a button to initiate the logon process?  Wouldn't a user just go to a site, the site senses if SQRL is installed on the machine and logs you in if possible?  No SQRL:  Show a marketing page saying, hey, if you had SQRL you'd be home by now.  Authorized SQRL user:  Proceed immediately to authorized content.



STEVE:  If you had SQRL, your nuts would be warm.



LEO:  Yes.  They'd be buried by now.



STEVE:  Okay.  So this is a great point.  And I see questions, all kinds of variations on this.  So I just sort of wanted to take a second to note the current embodiment of the concept of a per-domain unique public key that the site has and uses to verify a real-time challenge.  That's the kernel of the SQRL nut.  And so, for example, the SQRL client for Windows that we'll be playing with soon, or even Jeff's client for iOS, these are sort of like they're working implementations, but only one way of applying the technology.  As I mentioned before, Stina of Yubico has indicated a strong interest and the ability to move the most critical crypto into one of their little dongles, which would be very cool.  But exactly as Mike suggests, or Mike's coworker, I wouldn't be surprised if we see SQRL clients as browser plugins, and maybe eventually built into browsers, where they could absolutely do the same thing on behalf of users. 



So I guess the point I wanted to make was that there is sort of a very clear, well-defined technology, and then lots of ways to skin the cat.  Lots of ways to wrap that, with or without passwords, using biometrics.  Or, if you wanted to, making it completely transparent.  Now, understand that all of these have a tradeoff that we're always talking about, the security versus convenience, because if you simply go to a site, logs you in, then how does anything know it's you sitting at your computer?



So the reason, for example, that my Windows client has a SQRL password with that password hint technology is to create a compromise.  It doesn't need it at all.  But it feels like we've delegated to the SQRL system the ability to represent us to the Internet.  So we need a way to prove to it, who is basically our identity proxy, that it's us sitting at the keyboard.  It's us using it to log into a site.  Otherwise anybody could come along and log in as you, which would not be good.  So anyway, it's absolutely the case that the technology, the core technology is independent of its particular use case.  And I have no doubt that, if this thing gains traction, we'll see all kinds of it being used in a compatible way in all kinds of other packaging.



LEO:  And of course somebody was asking in the chatroom, and where can I get a SQRL sticker just like that on your mic flag?  Are you offering SQRL stickers?



STEVE:  The logo is in high-resolution downloadable form at GRC.  So I've got a big...



LEO:  Make your own.



STEVE:  I've got vector format and bitmap format, very large.  So you just grab it, scale it to an inch and a half, and print it on your color printer, and you've got one.



LEO:  M'kay.  Sean Jones, Houston, Texas says:  How hard are firewalls?  Oh, look at that.  It's giant.



STEVE:  It was funny, too, because last week I had it back on the bookshelf, and it ended up being right next to this one, and they were exactly the same size.



LEO:  Parallax.  It's an amazing thing.



STEVE:  It was strange-looking.  And the depth of field on this camera is so great that it was in focus back there.  And it's like, wow, that's really weird-looking.



LEO:  I saw it yesterday, I mean last week.  Sean Jones, Houston, Texas, wants to know:  Steve, I've been talking with my cuz about security appliances, and he pretty much hates the company that I use for UTMs, which is Sophos.  He complains that their UTMs are just "software firewalls" and that "hardware firewalls" are better.  I really don't understand what he means by this because all firewalls/UTMs have to have some form of software on them to work with the hardware.  Can you explain to me what he probably means by this?  And say this carefully, by the way, because the new studio is all Sophos firewalls.  And I understand it's similar to pfSense, which is what you use; right?  Which is software.



STEVE:  Oh, I wanted to - I'm so glad you just said that because I wanted to just tell people.  As everyone knows, when I lost my two T1 trunks and switched to cable modem, I did some replumbing.  I switched to gig switches.  And among the other things I did is I built a cute little - I took a little embedded PC from - I'm blanking on the name.  It's an engineering company.



LEO:  Oh, I know you love them, too.



STEVE:  Soekris.  Soekris.  Although, frankly, the pfSense people have their own hardware.  And I think, had I known about that at the time, I would have chosen that over the Soekris engineering.  I love this little router.  So it's pfSense is free.  Install it in a PC.  It just needs a few network interfaces.  You can use the pfSense hardware.  But, boy.



One of the things I will be talking about in the future is an ARP scan of a LAN in order to find all the crap that's sitting there that you've forgotten about.  And anything on the LAN, no matter what it is, will show up.  And so this morning I thought, I wonder what pfSense has for showing the ARP table?  And I did an ARP-A on my Windows machine, and I only got two entries.  So I fired up the pfSense page, brought up the ARP table, and here was a listing of every single device on my LAN, and all the MAC addresses, and all the IPs they have, because of course they're all talking to the gateway, and it's recording all of the MAC addresses in order to forward Ethernet packets to them.



So I just wanted to say that pfSense and I are having a ball together.  I've done things like - I'm mapping Skype through so that we get a point-to-point connection.  I have port shifting, where because my Cox blocks a bunch of ports, some that I want to use to get to Level 3, so I shift the port to a different number at this end and then shift it back at Level 3 so it bypasses Cox's filter, yet the devices at each end here and there both see traffic on the port that Cox is blocking.  And pfSense does all that.  I mean, it is just - it's incredible.



And in fact one of the things I need to add to the SQRL client is support for proxies because it doesn't handle web proxying right now.  And some corporate users who have wanted to beta test it, or alpha really, were saying, hey, I can't get SQRL to work inside our corporate network.  It's because they've got a proxy.  So I thought, huh.  This was a couple days ago.  I wonder, I'm sure pfSense must support proxies.



And so it turns out it's got a whole library of downloadable modules.  It supports the Squid proxy.  I clicked a couple buttons.  It downloaded a latest update, installed it, didn't reboot or anything.  It just said, okay, now you have a web proxy.  So I'll be able to use that, once I add awareness of that in the SQRL client, I'll add that to the client and then test it using my own little router.  So I'm just, you know, it's free.  And, boy, there's nothing that I have found that it won't do.  And for somebody who really enjoys having control of their network, this is what I would put on the border.



LEO:  Well, and to the question, I mean, that's a software router; right?



STEVE:  Yes.  Now, okay.  Sean's question about his friend, that is a distinction without a difference.  When I was first setting things up and didn't know any better, I bought a, quote, "hardware firewall."  It was a red box meant to look all like a fire department or like a firewall.  And, ah, can't quite remember the name of it.  I had it on my mind this morning because I knew I was going to be talking about this.  But it had three NICs with a DMZ and a WAN and a LAN.  Fire - no, I can't remember.  Anyway, but when I plug a console into it and turn it on, it's booting open source software.



So Sean is exactly right.  I mean, technically, a hardware firewall, I would define that as pure hardware.  That is, like an FPGA, where there's no OS; there's no programmable.  Like it's receiving packets and disassembling them and interpreting them and checking them and operating against hardware-based rules.  You could do that, but you'd have to have some strange reason.  Maybe - no.  I was going to say maybe wire speed performance, but we've even got firewalls running at wire speed.  So I just...



LEO:  And look what you'd be giving up.  I mean, you'd be giving up all the...



STEVE:  There isn't such a thing.



LEO:  ...configurability and patches.



STEVE:  Yeah, there isn't such a thing as a hardware firewall.



LEO:  And it'd have to be perfect out of the box because you couldn't update it.



STEVE:  Yeah, yeah.  So technically, yes, you could block traffic in hardware.  No one does.  They don't - it doesn't exist.  Everything is a software firewall.  It may just look like it's not booting an OS, but underneath that's what it's doing.



LEO:  There's always something in the firmware.



STEVE:  I mean, light bulbs are booting Linux.



LEO:  Nowadays, yeah.  If you get a 43-page GNU public license with your light bulb, you know.  Actually, Sophos bought Astaro, which was our first sponsor on the network and on our show.



STEVE:  Ah, nice.



LEO:  And I think that they also make Astaro's stuff.  And remember the Astaro guys, one of the cool things about it is you could buy Astaro hardware, or you could download for free the Astaro software.



STEVE:  Yes.  Yes.



LEO:  And install it on a beige box.



STEVE:  And that's all they did.



LEO:  That's all they did.



STEVE:  They just did it for you.



LEO:  They just integrated with the hardware.  And that's pretty much what everybody else is doing.  Although I tell you the one exception.  We're going to be getting - get ready for this - Symmetric 10Gb fiber into our new studio.  And 10Gb.



STEVE:  From the outside?



LEO:  Yeah.



STEVE:  Wow.



LEO:  From Sonic.



STEVE:  Nice.



LEO:  And one of the challenges of this is you do have to have a hardware switch that can handle 10Gb; right?



STEVE:  Yes.  



LEO:  I mean, it's not - you can't just plug in your PC and expect throughput of 10Gb.  So we are getting a Sophos box that is rated for 10Gb.  I think it's a $45,000 box.  They're very expensive.  



STEVE:  Yeah.



LEO:  But so to that degree, there's a hardware throughput thing, and you would spend money for that hardware.  But then on top of it is software; right? 



STEVE:  Right.



LEO:  Abe Sloan, Indianapolis, Indiana - hello, Abe - shares his company's anti-phishing training scheme.  I wonder if it involves hazing in any way:  Hi, Steve and Leo.  I wanted to write in about something my company has started doing.  I work for a local hospital network - oh, and we know what a big deal that is, right, because those hospitals that got phished and then ransomware?  He says:  I work in the IT department.  The security department of IT has started sending out phishing emails - oh, this is smart.



STEVE:  Yup.



LEO:  With a link in them.  And if you click on it, you're sent to a page with mandatory training.  Not a long story, but I thought it was something that you two would get a kick out of.  Thanks for the great show.  Ive been a loyal listener from the beginning.



STEVE:  I think that's so smart because there's just no way to get through to most users.  They've got a job to do.  They're harried.  They attend some training where IT says, look, do not click on links in email, period.  And they're, uh-huh, uh-huh, uh-huh.  But, boy, I tell you, send them some tests.



LEO:  Get their attention, yeah.



STEVE:  That's smart.  Because then they're going to get caught out.  And quickly it'll be like, oh, who clicked the link?  Oh, you know, John over there, and Shirley over there.  And it's like...



LEO:  Hah-hah.  You clicked the link.  Heh-heh.



STEVE:  Yeah.  I think that's...



LEO:  Good.



STEVE:  I mean, that's probably the only way to do it, if you really - and exactly as you said, Leo, hospital networks, we've seen them getting infected by ransomware.  They just can't afford that.  So I think the only way to enforce a policy is, like, there will be a test on this, and we're not going to tell you when.



LEO:  I also think they should do training, global training on social engineering.  Because this is really the big challenge is you've got customer service reps who are trained to serve the customer, even if the customer is a hacker.  And it really - I think they need to be trained in that and phishing, for sure.



STEVE:  I have two of the most wonderfully skeptical co-workers.  And they just - Sue, you just can't pull anything over on her.  And it's like, okay, good.



LEO:  No, you need that.



STEVE:  Because, you know, it's just - yeah.



LEO:  Terry Richard, writing from Toronto, Ontario, Canada...



STEVE:  This is one for you, Leo.



LEO:  ...wants to delay Windows 10, but still get it someday for free:  Steve, you stated in your most recent podcast you never, ever, will ever use anything beyond Windows 7.  That's my feeling, as well.  However, July 29th the free upgrade runs out.  I'm currently running three computers on Windows 7.  The thought of upgrading to Windows 10 today makes me nauseous.  Yikes.  That's kind of strong.  But the thought of having to pay for Windows 10 times three, for my three computers, when support for Windows 7 ends on January 14, 2020, makes me positively ill.  I'd be curious to know what thoughts you have on this conundrum Better to upgrade now, or pay to delay what seems almost inevitable?



STEVE:  And the reason I say this is for you is that I'm very sure, but I need you to corroborate, that we've heard, and I've heard you saying on other of your podcasts, that once a system has been upgraded to Windows 10, it then obtains a key for that, which then it always has; and that you are then able to back out from Windows 10 back to 8.1 or 7 and keep that upgrade right intact for the future.



LEO:  Right.



STEVE:  What do we know about that, exactly?



LEO:  Yeah.  And this comes from Paul Thurrott.



STEVE:  Okay.



LEO:  No less of a resource than Paul Thurrott, our own expert.  And Microsoft calls this an "entitlement."  The new licensing scheme in this particular case is called an entitlement.  So your machine, not you, your machine gets the license for Windows 10.  It gets an entitlement.  So, yes, if you have an authorized copy of Windows 7 or 8.1 installed on your Windows machine, and between now and July 29th you take Microsoft upon that offer, and you upgrade to Windows 10, you go through the whole process.



STEVE:  If only for a day.



LEO:  If only for a day.  And then, must do this before you go on, check to see if the Windows 10 activation occurred, which it should, instantly.  But just make sure.  You right-click on My Computer, you get the properties, and it says Windows X, and you see - and look at My Computer, and you'll see that it's licensed.  Once that's the case, you can do anything you want.  You can wipe out Windows 10.  Technically, you have a 31-day rollback period.  So you could go to the recovery control panel and say...



STEVE:  Nauseous, Leo, nauseous.



LEO:  Yeah, take me back.  Take me back.  Calgon take me away.  You can go back to Windows 7.  That does not always work, so I wouldn't rely on that.



STEVE:  I was going to say that what I would recommend is make an image of your system first.



LEO:  Yes, exactly.



STEVE:  I want to say DriveImage, but there's one that I like now more.  Image for Windows is my favorite.



LEO:  Oh, a new one.  You keep changing on me.



STEVE:  Yes.  Image for Windows.



LEO:  It was DriveSnapshot.de.  Then it was DriveImage.  And now it's Image for Windows.



STEVE:  Image for Windows.



LEO:  Okay.



STEVE:  I think it's TeraSoft.  And that guy does beautiful work, and I'm very impressed.



LEO:  Terabyte Unlimited.



STEVE:  Terabyte, that's it.  Unlimited, yes.  Image for Windows.  It also has...



LEO:  And it's free?  No.  It's not free.



STEVE:  [Crosstalk] Linux.  Sorry?



LEO:  There's 30-day free trial, though.  That would be enough to use it, I guess.



STEVE:  Yeah, yeah.  Although, I mean, anybody serious wants this in their toolkit.  It's beautifully done.  So make a snapshot of Windows 7 on the machine.  Then do the upgrade.  Make sure that Microsoft acknowledges that it's been activated under 10.  Then back out using Microsoft-sanctioned rollback.  And if anything happens along the way, that's okay because you've got an image, and you're able to restore the disk from the image, and then you're good for four years until you decide you want to take Microsoft up on it.



LEO:  They have a lot of other cool-looking...



STEVE:  Yes, Image for Linux also.



LEO:  Ahh.



STEVE:  And also for DOS.  Yeah, every single one of their things, very reasonably priced, absolutely bulletproof.  Multi file system format aware, so FAT32 and NTFS and UFS and EXT and the works.



LEO:  Nice.  Oh, by the way, and when you buy it for Windows, you get a copy of it for DOS and Linux, as well.  So you know what, I'm going to buy this.  I mean, it's only 39 bucks.  That's a good deal.



STEVE:  I know.  It's great software.



LEO:  All right.  Good recommendation.  Yeah, make a backup.  Don't trust the restore.



STEVE:  No, in fact, we know that the restore has failed.



LEO:  Oh, yeah.  It's failed on me.  It's worked on me, and it's failed on me.  And I think the whole process sounds kind of wonky anyway.  Just make an image.  You'll be glad you have it later.  Somebody else is saying you also could just get an external drive or a second drive, do it on that, and then you'd have a copy of Windows 10 installed.  Whatever.  You know, there's lots of ways to do this.



STEVE:  I don't think so.  I think you want to have - because we're not exactly sure.  Microsoft's always been a little coy about how they lock onto the system.  And one of the things they do, drives have serial numbers which are readable.  And so there was like a - if you only change a few things at once, I mean, back when Microsoft began doing this, it created a huge upheaval.  And it was like, wait a minute.  What if I want to, if my system dies, and I bought Windows, but I have a new system, or what if I change my hard drive, or if I change the amount of RAM I have and blah blah blah.  And so they lock onto it and plant some seeds, but also do things like look at all the serial numbers that they're able to find.



And so I'd upgrade on that machine and roll back, and just be glad if it does.  And if not, just restore from the image.  And Leo, given Microsoft's push, I could understand them stopping pushing at the end of July, but why wouldn't they always just make it, like, go here, click here to download, to upgrade?  The user has to go get it rather than it being, quote, "offered," unquote, to them.  I just can't imagine why they would ever say no because they're just in such a burn to get everyone moved over.



LEO:  Right.  Absolutely.  But also don't...



STEVE:  Charging anything, especially after this, I mean, basically his sentiment makes total sense.  I don't want it now.  I want it someday.  So why would Microsoft say no, you have to have it now, or we're going to charge you someday?  That doesn't make any sense.



LEO:  We spend a lot of time talking about that on Windows Weekly, what's going to happen July 29th.  The consensus seems to be, no, they will start charging on July 30th.  They will.  So don't - but who knows.  You know?  It's all baffling to me.



STEVE:  Leo, I'm not going to do that.  I'm going to stay with 7.



LEO:  You're not going to bother.  All right.  You know, by the time, by what was it, 2020? 



STEVE:  Yeah.



LEO:  You'll be using BSD by then anyway.  I guarantee it.  I guarantee it.  Actually, Linux looks better and better all the time to me.  I just love it.  I just love it.  And maybe there's a hook here to Linux with Sebastiaan Langenberg, his email from Bergen op Zoom.  I want to live in Bergen op Zoom.



STEVE:  That is a great place to live; isn't it?  Oh.



LEO:  Yeah.  Oh, man, The Netherlands.  Dutch sounds that way.  It's like all shwoopy doopy language.  It's a very shwoopy doopy language.  And I mean that in the nicest way.  I'm going to be in The Netherlands in September.  Steve, during the time you spend with good Leo on the podcast, you talk about your love for assembler a lot.  I am a more modern-day programmer, and I'm interested in the workflow of how one goes and creates his or her software.  Therefore, I'm curious to learn what IDE and tools you are using on a day-to-day basis to work on projects like SpinRite and SQRL.  I hope you find it interesting to share these details, and I hear my question answered on a future podcast.  Yours, Sebastiaan.  



STEVE:  So you know the...



LEO:  Do you even know what an IDE is?



STEVE:  Heard of them, yeah.



LEO:  This is the wrong guy to ask about IDEs.



STEVE:  So I think the main thing I wanted to convey is that I don't have any magic.  That is - and I'll answer Sebastiaan's question quickly.  But the point is my sense is it sort of doesn't matter.  What matters is whether it works for you.  So, for example, everyone knows I'm writing SpinRite and SQRL in Brief, which is in a DOS box in Windows, that used to run in DOS itself, where SpinRite was originally written.  And I have a colorizing add-on that gives me syntax highlighting.  So visually it works very well.  Then, if I have a problem, and I write a lot of code that worries me because it just works the first time, and it seems like I'm going to believe it more if I have to struggle to get it to work.  But it just sort of works.  So I don't really spend much time in debugging.



And also one of my approaches is iterative.  So I'll write a little, and I'll test it.  I'll write a little, and I'll test it.  I'll write a little, and I'll test it, instead of just writing for days and then seeing if everything that I wrote works.  I'm very incremental.  And I test everything I do and try all the different cases, and then I move forward.  So I'm constantly verifying that everything I've got so far works.  If I need a debugger, I use the oldest one that makes sense when I'm on Windows, which is Visual Studio 6.



LEO:  Oh, you do use an IDE.



STEVE:  Oh, yeah, yeah.  I mean, so, but I don't...



LEO:  So you're not writing in - I thought you were using MASM and Brief.



STEVE:  I am.  But I don't code in that environment.



LEO:  I get it.  But you'll fire up the IDE for debugging, yeah.  That makes sense.



STEVE:  Exactly.  And that one will show my source code, and I can...



LEO:  That understands MASM and the symbol tables and everything?



STEVE:  It doesn't, no.  So there's...



LEO:  That's some debugger you've got there.



STEVE:  ...the no-syntax highlighting.  But it does understand symbols and the old linker.



LEO:  Okay.  So it will look at a symbol table and at least say it has the variables names and everything.



STEVE:  Yes.  And I'm seeing my source.  So because the map file has line numbers and so is able to link that back to my source.  And so it's source code debugging.  But, for example, in SQRL, in order to use the libsodium library that has the Bernstein elliptic curves, I was unable to compile that - I didn't really try too hard - on the old Visual Studio 6 C compiler.  And they had it all set up for 2012 or something.  So I needed to use - so I set up a Visual Studio 2012 and then compiled the libsodium library there.  That wouldn't work with my old linker.  So then I had to use a newer linker with all of my assembler code.



The point of all this, the reason I'm telling you, is that forced me to use a newer IDE.  I'm using Visual Studio 2008 was the oldest one I could use that was still aware of the new linkage.  And as is typical, it's incredibly slow.  Visual Studio 6 snaps up and runs like crazy.  It's just beautiful.  I fire up Visual Studio 2008, and I sit around.  I can go make coffee.  And windows are coming up, and it's populating the UI, and it's just - who knows what it's doing.  But this is why I don't use new stuff.  It's all slow and piggish, and it's just in the way.  So, yes, I write in - oh, and for SpinRite what I do is that's actually still under DOS.  And so I set up a DOS network with NetWare.  I have NetWare drivers, and IPX and SPX.



LEO:  Wait.  Novell NetWare?



STEVE:  Yeah, yeah, because that runs under DOS.



LEO:  What, token ring wouldn't work for you?



STEVE:  I have a DOS machine with a network share, so that I still write everything in my Windows machine and then compile.  Then I switch over to the DOS machine and then launch SpinRite from a drive share on my Windows box, where it runs.  And then for there I have SoftICE, which is the penultimate debugger for DOS systems.



LEO:  I remember that.  Oh, I remember SoftICE, yeah.



STEVE:  ICE stood for In-Circuit Emulator.



LEO:  Yeah.



STEVE:  Once upon a time, you used in-circuit emulators.  You'd actually take the processor off the motherboard and put this plug in with cables running out to this standalone box on the side.  And that was called an ICE, an in-circuit emulator, which was the way you debugged things back then.  And so SoftICE was the software equivalent of that, where you could, again, see the source, single-step through, and figure out what the code is doing.  And so that's my debugging methodology under DOS.  And Visual Studio 6 is what I use unless, for SQRL, I've been forced into a more recent and very much slower Windows-based IDE, which I'm only in if I'm trying to track down a problem.  And the good news is I don't spend much time there.



LEO:  Do you use any version control at all?



STEVE:  No.



LEO:  No, of course not.  That would be crazy.  Why would you want to do that?  No, and I like it, Steve.  You represent the old school of programmers.  You're like a cowboy.



STEVE:  And I wrote a little code that 1.365 million people have downloaded.



LEO:  Nothing wrong with that.



STEVE:  You know?  So the stuff works.



LEO:  Do you do anything in C?  I mean, is SpinRite...



STEVE:  Oh, yeah, I forgot to mention that, for example, the libsodium library at the time did not support the GCM AES encryption.  GCM is the hybrid AEAD, the associated data encryption that does both - remember we've talked about you can't only encrypt.  You must also authenticate.  And so I was using Phillip's encryption from UC Davis.  I'm blanking on his last name [Rogaway].  But the point was made, actually by Ralph, who was the developer of that early Android client for SQRL, he said:  "You know, even if it's intellectually available, GCM AES makes a lot more sense."  I agreed with him.  I wrote a full implementation myself in C because that component needed to be portable.  I needed to be able to offer it to everyone.



So on some of the SQRL pages is a link to my C implementation.  I made it very portable.  And so that's one of the components in SQRL that I deliberately wrote in C because that part I had to make shareable.  Now the libsodium library includes it, so you don't even need that.  It's like, okay, I guess I could have waited a little bit longer.  But I needed it for myself anyway.  So, yeah.  I can write.  I have a bunch of, like, all of the newsgroup stuff is in Perl.  That crypto stuff is in C.  I did a lot of customization of the Internet news server, because it's in C, for FreeBSD.  And so, yeah, I sort of speak whatever language I need to to get the job done.



LEO:  Nice.



STEVE:  But if I have a choice, assembler.



LEO:  And that's "_get the job done," and that's what he does, and you can't knock that, I'll tell you.  Someday we'll get you using something.  No, why bother?  Why even bother?



STEVE:  Well, I'm thinking that I may do...



LEO:  I think you should learn Rust, GitHub, and Emax.



STEVE:  I'm thinking Python maybe.  I'm thinking...



LEO:  Python is good.  Python's elegant.  And, you know, one of the things that's cool, and you're seeing this, is you want to choose a language that has really good library support.



STEVE:  Yeah.



LEO:  Because those libraries are what makes it possible for you to go from zero to 60 pretty quickly; right?  You don't have to reinvent the wheel constantly.



STEVE:  Yeah.  The problem is that's where a lot of bugs come from.



LEO:  I know.  You'd have to trust these libraries.  I know.  I know. 



STEVE:  Yeah.  I'm thinking that what I want is platform transportability.



LEO:  Well, then, Python does give you that, yeah.



STEVE:  Yes.  And so, for example, it would be really - as soon as a little ARM board has a SATA interface on it, for example, then people could make a little SpinRite box that would just be like a Raspberry Pi.



LEO:  Oh, yeah.



STEVE:  That would SpinRite a drive.



LEO:  Plug it in and then take - yeah, that's a good idea.  Standalone appliance.



STEVE:  But of course that would be ARM, and so I'm not going to write it in some RISC - that's where I draw the line.  I'm not writing RISC code assembler.  That's what compilers are for.



LEO:  All the kids are doing Rust now.  Rust is the new type safe C/C++.  That's the one I would look at, if I were you.  No, no interest at all; right?  I try.  I try.  Steve Reed, Rockville, Maryland worries about HTTPS, corporate proxies, and personal passwords:  One of the job labels assigned to me is to keep the IT equipment running at our office.  One of my co-workers asked me a question; and the more I think about it, the more I question my own understanding of how the world works.  Well, not really, but at least on this one particular small point.



To wit, his wife is having issues at her workplace - new director on a rampage, firing and hiring people, et cetera, et cetera, et cetera.  She feels there are some strange things happening with her personal email and other accounts, Facebook and so on.  He, my co-worker, was wondering if it was possible that their IT person was getting their passwords for their personal accounts from the network.  I initially told him, well, no, it's HTTPS traffic.  It's all encrypted.  I guess, he said, they could be using a keylogger or something like that, but it wouldn't be from the network traffic.



Then the old discussion of HTTPS proxies came to mind.  Are the user passwords encrypted in the same method/channel as the regular traffic, or does it get an additional layer of protection?  For instance, if I installed my own root cert in our active directory domain, as many large enterprises do, filtered Gmail through the HTTPS proxy, and looked at all of the decrypted traffic as it went through the proxy, would I see the passwords?  I realize Gmail may be a bad example with cert pinning; but just as an overall issue, is that possible?



Thanks for the time you put into the podcast and all the other great products you make.  I have our company - oh, this is the guy - halfway to a site license.



STEVE:  Oh, that's the same guy, that's right.



LEO:  Expect to get the other two very soon.  So that's a good question.  Is it a second channel?



STEVE:  Would I see the passwords?  The answer, yes.  And this raises a point because - and this has not been raised, and I'm really glad he asked the question.  And that is, I've capitulated to reality from my original stance of, oh my god, the idea of filtering and intercepting and decrypting and looking at HTTPS is so wrong, yet this is what corporations are going to do because...



LEO:  They have to.



STEVE:  They have to have visibility into the traffic of their network.  And the problem is all of the authentication has traditionally been relying only on HTTPS.  Now, that could be done differently.  Browsers are smart enough now.  We were just talking about JavaScript and crypto libraries.  Those exist.  So it would be possible, for passwords and usernames, for there to be a challenge/response mechanism with passwords and usernames.  The problem is authentication.  We always come back to that.  If you've got a man in the middle, you do not have authentication.  And if you've broken authentication, there is no theoretical way to prevent that man in the middle from intercepting everything.  There's no way to know that any handshake of any kind, no Diffie-Hellman anything, that you're not actually shaking hands with the proxy instead of the other end.



So this is really sad because what this means is the corporations that are filtering their users' traffic are in fact exposing what their users, I mean, are exposing everything, including their username and password authentication, which is maybe none of the corporation's business.  Now, that said, it's the corporation's Intranet.  It's the corporation's bandwidth.  So if you don't want to do that, do it on your cell phone that's using cellular connectivity, or on a laptop that is avoiding the corporate bandwidth.  I could argue that's their bandwidth to do with as they please.



But I did want to raise this point because I thought this was really good, that yes, these proxies, I mean, this is back to Firesheep, sitting there in Starbucks and seeing all of the usernames and passwords and authentication tokens and everything.  Nothing is hidden from that proxy.  And if you have some bad apples in IT, they can see everything that is going in and out of every employee's connection.  And that needs to be said.



LEO:  And maybe you should stop using Facebook and collecting personal email on company time. 



STEVE:  Right.



LEO:  I mean, look.  That's fine, and your boss may not even care.  But you're sitting there, doing that, and you're giving them an entre.  If you didn't do that, they wouldn't be able to see into it.



STEVE:  Yup.



LEO:  Jay Clark, Boise, Idaho seeks the truth about some email security claims:  I recently received some emails from financial services companies.  There was a note in the body or subject that indicates it was "sent securely," implying that all contents are safe from prying eyes.  The actual wording is:  "Please be advised that communications with {SECURE MESSAGE} in the subject line have been sent using a secure messaging system."



This seems strange to me, as I know the email content is not inherently encrypted, and I believe when in transit the connection isn't encrypted, either.  It doesn't seem like there would be any way for me to verify, from my end, the message was sent with a "secure messaging system," whatever that actually means.



So how can a company assert so boldly that the message was sent securely with a secure messaging system?  Is that a red herring?  I still don't trust that their email service is secure, and they want me to send financial documents to them using email.  Thanks.



STEVE:  Yeah.  Jay, you are 100% right.  It's like the email that you get that says "scanned with a virus scanner, so open at will."  It's like, what?  Yeah, that's completely nonsense.  Unless you apply your own end-to-end encryption, unless you encrypt it first, like with PHP or GPG or S/MIME, one of the true client-to-client encryption solutions, there's no telling what's going on.  Now, email is a store-and-forward system where your client deposits it on an SMTP server, probably at your ISP.  Then it may connect directly to the target's SMTP server, or it could go somewhere else in the meantime and then ultimately go there.



Generally these things can be configured to be opportunistically secure.  That is, if they're late model servers, they will say EHLO, E-H-L-O, rather than H-E-L-O, HELO.  And that says, oh, I understand more advanced protocols.  They'll say, here's all the stuff I know how to do.  One of them may be STARTTLS, meaning that you can then bring up a TLS connection between the servers.  But the problem is, if somebody wanted to prevent that from happening...



[Yabba dabba do]



LEO:  You are now one step closer to a site license.



STEVE:  If somebody wanted to prevent that from happening, they could prevent that communication and downgrade to standard port 25 nonencrypted, non-TLS connections.  So that's why it's just - it's opportunistic.  The point is no one - anything that says, "oh, if this says 'secure message' in the subject line," I mean, I would worry, frankly, about any organization...



LEO:  That's so stupid.



STEVE:  ...that was trying to pull that stunt.



LEO:  It's like the email from the lawyer that says, "If you are not the intended recipient, you must immediately delete without reading this email message."



STEVE:  Yes, yes.



LEO:  Like, well, that'll work.  Yeah, mm-hmm.



STEVE:  Oh, okay.  No juicy details, yeah.  So you're completely correct.  Again, the only way to know is to encrypt it yourself and then arrange for the other person to decrypt it because still today, even today, it's more than likely going to have a link or two where it's not encrypted. 



LEO:  It does really underscore the need for some form of secure email.  And Google and others have been kind of trying to address this.  But I don't think it's an easy thing to do.



STEVE:  No.  We're trying - I've said it so often.  We're trying to shoehorn a system that was never designed to have security, and it resists it.  It fights it.  And it's winning.



LEO:  Yeah.  I'm learning how to use PGP.  It's not that hard.



STEVE:  Well, good luck having the other morons on the other end of the connection.



LEO:  These guys won't, yeah, right.  That's the problem.



STEVE:  Well, it's funny, too, because my bank, whenever I'm like doing any sort of business, they won't do anything through email.  It's all fax.  And it's like, well, okay.



LEO:  [Laughing hysterically]



STEVE:  Like somehow that's safer.



LEO:  Well, it's not like anybody could forge your signature or anything.  That...



STEVE:  No.



LEO:  That is gold.  It's the gold standard of authentication.  Tim in Orange County, California has an idea for isolating Intel ME the cheap and easy way.  This is what you were talking about lat week; right?



STEVE:  Yes.  This is one of the topics was the so-called Intel Management Engine, which lives on the motherboard, aside from the regular Intel processor that we stick into a big socket with big fans running on it.  This is a little secretive thing that's, like, monitoring your Internet connection.



LEO:  There's been a lot of conversation about this on open source boards lately because, of course, if you want to have a, quote, "free," in the sense of libre, operating system, that's great.  But your hardware isn't.  And this Intel chip could be a spy chip, in effect.



STEVE:  It's all locked down.



LEO:  Yeah, and you can't tell.  It's an obfuscated blob.  Just like me.  Hi, Steve.



STEVE:  There's very little obfuscated about you, Leo.



LEO:  I'm just a blob.  I have a relatively easy and cheap way to bypass Intel ME, or at least prevent it from connecting to the rest of your network.  Oh, you know, I've read this.  I'm really curious what you have to say to this because I've read this in other places, as well.



ME can only communicate through the built-in motherboard NIC; or, if it's a server board, sometimes there's multiple NICS.  If you have a desktop PC with vPro, well, simply install a cheap PCIe add-in NIC and cover the built-in network port with a piece of electrical tape.  For laptops, use the built-in WiFi, as ME cannot communicate over WiFi.  And if you have to plug in at a hotel or other foreign network, use a USB NIC; or, better yet, bring a portable router/firewall to insert between your laptop and the world.



On a sadder note, one of the features of the most recent Microsoft Excel app for Android is that, "Now you can open files that contain ActiveX controls."  Oh, joy.  Thanks for a great podcast.  Tim in Orange County.  I'm actually really glad Tim asked this because I wanted to ask you the same thing.



STEVE:  Yeah.  It is the case that there is no way for the integrated processor on the motherboard to have any idea how to communicate with some random Ethernet chip that's on the card.  Generally, the plugin NICs will have a BIOS.  But this doesn't operate through the BIOS.  It's direct to hardware.  So plugging in an additional outboard card will bypass the Internet Management Engine.



LEO:  Wow.  That's good to know.  Very good to know.  So really this isn't as big a hazard as it's been made out to be because...



STEVE:  Well, it's a pain, though.  If you've got built-in sockets, that's the ones you want to use.  You want to use your motherboard.



LEO:  Well, here you go.  This is a Linux laptop.  I was all thrilled because it has an Ethernet port on it.



STEVE:  Yeah.



LEO:  But I shouldn't use it.  I should use the WiFi if I want to eliminate the ME, the man in the middle.  And we should say there's no evidence that Intel's using this in any malign way, or that it has been compromised, either; right?  I mean, it's, as far as we know, still secure. 



STEVE:  Right.  What's concerned is that there's no visibility into it, and they have locked it down completely, and they do not document it.  And they're just like, it's on a need-to-know basis, and apparently we don't need to know.  



LEO:  Intel's documentation says on vPro systems.  But there's also evidence that the chip, at least, is on systems that are non-vPro, as well.



STEVE:  Yeah.



LEO:  So not getting a - this was another conversation I read on the boards, the libre boards, is, oh, well, if you just don't get a vPro computer, you're all right.  Well, but the ME chip is on other Intel motherboards, as well.  Whether it's enabled we don't know.



Patrick in New Jersey had an idea about blocking Intel's IME access.  Oh, yeah, you obviously stirred up a hornet's nest:  I was listening to last week's podcast SN-565, and I had an idea how to prevent IME from getting on your network.  I have a desktop that I'm using as a server in my house.  It's a third-generation i7 processor, one of the older ones, and it came with one of the earlier versions of vPro.  It uses the onboard NIC to get into the network, but with a different MAC address than the in-band interface the OS sees, and thus will have a different IP address on the network.  On my computer I can statically set the IP, or have it assigned via DHCP.



I would think that the new versions of IME would operate the same way so as to avoid socket collisions between IME and the OS.  That is to say, both IME and a service on the OS trying to use the same IP and port at the same time, as an example, port 80, of course, for TCP/IP.  Or HTTP, I should say.  One should be able to determine this by doing a packet capture and looking at the date in Wireshark.  If this is the case, you should be able to block traffic for that MAC address on a switch or router.  Thanks for all you do, happy SpinRite owner, et cetera, et cetera.  Will that work?



STEVE:  Okay.  So I did some digging because I was curious about this.  And it is true that the older generation - and Patrick mentions that he's got an older solution.  What I saw was v2.6, although I don't know how to relate that to time.  But 2.6 of this management engine release did display separate MAC addresses.  So it looked like two adapters to the wired network.  But with 3.0 and subsequent, it is a single MAC address.  So it is no longer obviously a second MAC.  Were it two, and you could figure out which one, well, and you could figure out which one was which.  And this is actually, this is what led me to the ARP table on pfSense was I was just curious to see on various systems whether I was seeing one MAC or two for a given system.



Now, it is the case that you can have multiple IPs per MAC.  So we know that.  It's very possible to assign several IP addresses to a single MAC address.  Essentially, all of the traffic going to the gateway is going to different IPs through the gateway's single MAC.  And we know that systems can typically be set up multiheaded with a couple IPs.  You could not have two MACs with the same IP, though.  So unfortunately, I mean, I guess if you find that you have different MAC addresses, then you could certainly filter by MAC address.



What Intel's boards, because there have been some discussions of this, what Intel's boards say is that, if you manually configure the IP, that is, you do not use dynamic host configuration protocol, DHCP, but you manually set the IP of your Windows machine, then you will not have IP sharing between your Windows or your Linux or whatever running on the motherboard, and the IME processor that is sharing that same NIC.  That is, it will get a different static IP.  And it may be, I didn't pursue this, that the Windows management tools allow you to configure the IP that that sort of shadow NIC operates under.  In which case, if you're able to give it an IP, you could then use something like pfSense or any other firewall-enabled router to simply block that address from having any access outside of your network.



So, I mean, the problem is you ought to just be able to turn this off.  The idea that you can't go into the BIOS and say "Off," I mean, that's the obscenity of this whole thing, the idea that users, owners of this machine, of this hardware, cannot just disable it.  That's wrong.



LEO:  Yeah.  You know, I wonder if there will be a market at some point for - and a lot of people are not buying Intel chips for this reason.  They're buying AMD.



STEVE:  It ought to be made much easier to say no to this.



LEO:  Yeah.  I think there's a market.  I think AMD should really look at this market and say - clearly, I mean, I understand most, you know, if you're buying a Windows machine for use in business, you're going to...



STEVE:  Yes, an enterprise environment.



LEO:  Yeah.  You're going to embrace TPM - and this is kind of like the TPM Tempest over again.  And you're going to embrace IME.  And that's fine because it gives you some stuff you need and you want.



STEVE:  So enterprise level, like inventory and asset management control.



LEO:  Right.



STEVE:  You're able to see who has everything and where these machines are.



LEO:  Right.  And you know if you work for a company, and the company owns the computer, it ain't your computer.  But what about those of us who want our own personal devices, and we don't need this? 



STEVE:  Yeah.  And it's creepy.



LEO:  And it's, well, we just don't want it.  We just want to know that our hardware is all our own, and there's no spy stuff on it, potential spy stuff on it.  And I think AMD could make - hey, if you're listening, already people doing libre stuff are often choosing AMD processors, yeah.



STEVE:  If given a choice, yes.



LEO:  Hmm.  It's very interesting, isn't it.  Well, we've come to the end of our time together, Steve.



STEVE:  Right on time.  Right on schedule.



LEO:  Love the show.  And I missed doing it last week.  But I'm glad to be back for this one.  We do it every Tuesday, 1:30 Pacific, 4:30 Eastern.  That's about 20:30 UTC.  If you want to tune in live, please do.  Join us in the chatroom, IRC.TWiT.tv.  Steve's not in the chatroom, but I am, and I keep an eye on what you're talking about and try to bring it into the conversation.



STEVE:  Yeah, that would overload me.



LEO:  That's too much.  You can ask questions of Steve, though.  He's very active on Twitter, @SGgrc.  And he has an open DM policy, so you can ask infinitely long questions via DM.



STEVE:  And, boy, that gets a lot of use, too.



LEO:  Which is exactly why I don't do it.  You can also - and don't email him.  That's not - for some reason, that's not how he wants you to contact him.  Do use Twitter DM.  That's so much better.  It's your life.  Whatever.  You also can contact him, and this is probably the official way to do it, at GRC.com/feedback.  And questions will be used in two weeks as we do a Q&A section.  But I'm sure Steve also kind of considers and thinks about it.  And if you have stuff to feed him, he'd love to get it.  You can also, while you're at GRC, take a look at the SpinRite program, the world's best hard drive maintenance and recovery utility; SQRL, if you want to know more about it, how it works, be ready for the launch.



STEVE:  Coming.



LEO:  Any day now.  Get that SQRL patch, put it on your laptop.  And of course the Healthy Sleep Formula and lots of other stuff there, GRC.com, including this show, audio versions and full transcripts, which is really useful, plus of course Steve's show notes, at GRC.com.  We have audio and video at our site, TWiT.tv/sn.  And if you want to listen every week, just subscribe.  We're on every podcast program there is.  There are even TWiT programs for every platform.  Find the program of your choosing and subscribe.  That way you won't miss a single episode.



Had a great live studio audience, who are freezing to death right now.  But thank you for being here.  I like to keep it chilly in the studio.  If you want to be in-studio live, there is limited seating for the shows I do in this studio.  There are about five or six seats.  So email tickets@twit.tv, and we'll make sure we get a chair for you.  Thanks for being here.  We'll see you next time, see you next Wednesday - Tuesday.  I'll be here on Tuesday, just in case.



STEVE:  That's good.  I will, too.



LEO:  On Security Now!.  Bye-bye, Steve.



STEVE:  Welcome back, Leo.



LEO:  Thanks.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#567

DATE:		July 5, 2016

TITLE:		Hacking Certificates

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-567.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with another packed week of security news, including an update on mobile ransomware; the successful extraction of Android's full disk encryption (FDE) master keys; Google's Tavis Ormandy finds horrific flaws in all Symantec traffic analyzing software; a Brazilian judge is at it again with WhatsApp; this week's IoT horror story; some miscellany and errata; and, finally, a look at a horribly flawed attempt to copy Let's Encrypt automation of free SSL certificate issuance.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of security news.  We'll talk about an amazing Amazon review and a response from the company, yet another IoT disaster, and how not to issue automated security certificates.  It's all coming up next on Security Now!.  



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 567, recorded Tuesday, July 5th, 2016:  Hacking Certificates.



It's time for Security Now!, the show where we cover the latest security news with this man, the security in chief guy.  I just blew your title.  I used to call you the Explainer in Chief, but that doesn't really do it.  What are we going to call you?  The man in charge of Security Now!, Steve Gibson is here.  Hi, Steve.



STEVE GIBSON:  The man who named it.



LEO:  The man who named it.



STEVE:  When you said, "How about we do a weekly security podcast?"  And I said, "A what cast?"  And you said, "You've never heard of podcasts?"  And I said, "Uh, no."



LEO:  To be fair, this was in 2005, when nobody had heard of podcasts. 



STEVE:  Now I've got awards on my shelf from podcasts.



LEO:  There you go.  And did you come up with the name Security Now!?



STEVE:  Yeah.  I suggested Security Now!.  



LEO:  I like it.



STEVE:  So we're at Episode 567 as we close in on the end of Year 11 of this weekly podcast, with a bunch of interesting news.  We've got an interesting update from Kaspersky.  It might be a little skewed because they provide some software for protecting Android phones.  But the statistics and their information about what's going on with ransomware on Android phones is interesting.  And it turns out it's growing rapidly.  We also have the news that was much tweeted this week of a security researcher successfully extracting the full disk encryption keys from his Android phone.



Our friend Tavis Ormandy at Google's Project Zero really took Symantec/Norton down by taking a look inside of a core of pretty much all of their traffic inspection applications.  They've got enterprise and consumer.  All of this stuff that will protect you from stuff on the wire, turns out they really - in fact, the mistakes were so bad in specifics that you can't really forgive them because, for example, in some cases they used open source software that has seven-year-old vulnerabilities they didn't fix.



LEO:  Oh, my god.  



STEVE:  So how do you explain that away?  Brazil is at it again with WhatsApp.  Boy, those Brazilians really have a thing for WhatsApp.  Then we raise the question, what if you forget to reregister your router's setup domain name, as TP-Link did.  We've got, of course, this week's IoT horror story.  And I have to tell you about the one from two weeks ago that I shared with Padre when you were in Newport Beach because we didn't talk about it last week.



LEO:  No, we didn't, yeah.



STEVE:  Some errata and miscellany.  And then unfortunately the company StartCom, that does the StartSSL certs, decided that they liked what Let's Encrypt had done, and they were going to do it, too.  Unfortunately, they unbelievably badly fumbled their execution.  And when you think about it, automated certificate issuance is something you have to be really careful about because certificates are powerful, and you just don't want anybody to be able to get a certificate for pretty much any domain they want.  But it turns out you could.



LEO:  Oh.



STEVE:  So lots of fun stuff for the podcast this week.



LEO:  Not good.  Not good at all.  Okay, Steve.



STEVE:  So Kaspersky took a look at what they're seeing going on in the Android world.  They have essentially instrumentation because they produce a mobile AV product that gives them some visibility into what's happening on the phones of their users.  What they have seen - and we've never talked about this before.  We've obviously talked about the Android problems with the media server module.  And later we're going to come across, in fact it's in the Symantec story, one of the points that I made some months ago was how difficult it is for an interpreter to be careful about what it's interpreting, for example, in the context of a JPEG.  And of course this is relevant to the media server module because it's trying to interpret MP4s and various forms of media.



And the way this is done is that there's sort of a meta language that is the file itself, the JPEG file, or the MP4.  It's not just pure data.  It's tags that represent pieces of things.  And essentially an interpreter reads that, block by block, and does whatever it's being told to do.  And so what we've seen, for example, over on the media server side on Android, is it's so riddled with bugs that we just keep getting more of them.



So, but what's been interesting is that people are saying, yeah, okay, but Android phones don't seem to be infected.  I mean, like, no one's taking advantage of that.  Of course, there was the concern when you could just receive an MMS message and get your phone taken over.  The potential for remote exploitation was so high there that we all jumped to fix that as quickly as possible.  But what Kaspersky is seeing is that mobile ransomware affected 136K of Android customers by April of 2016, so a few months ago, and that that was nearly quadrupled from March of 2015.  So it looks like, unfortunately, it's a growth segment.  And as I said, they have a solution potentially for this, so there's a little bit of self-promotion probably going on here.



But the statistics and details are interesting.  They said one of the things that's interesting is that the strategy is different for mobile versus desktop.  On a desktop, the ransomware favors file encryption because you typically have high-value irreplaceable files sort of inherently in a desktop setting, much more than a mobile setting.  On a mobile device, it's songs that you have somewhere else.  Also, the vendors are actively backing phones up to the cloud so that, if your phone got encrypted, it's like, okay, fine, just do a hard reset and restore from the cloud, and you're back to the point where you had your last backup.



So the point is that on mobile devices, rather than encrypting files, what they're seeing is blocking, what they call "blocker-style ransomware."  And when I saw the pictures in their blog posting about this, they sort of looked familiar, like I've run across them just sort of in passing, but didn't really give them much thought.  But they come up and pretend to be, for example, the NSA or some government agency.



Quoting from Kaspersky, they said, "Blockers are the much more popular means to infect Android devices.  On mobiles, they act simply by overlaying the user interface of every app with their own, so a victim can't use any application at all.  PC owners can get rid of a blocker with relative ease.  All they need to do is remove the hard drive, plug it into another computer" - not that that's easy for most people, but it is a workaround - "and wipe out the blocker's files."  Of course, that's sort of speaking from Kaspersky's standpoint.  But they write:  "But you can't simply remove the main storage from your phone.  It's soldered into the motherboard.  That explains why blockers hold 99% of the mobile ransomware 'market,'" in quotes, such as it is.  



In 2014 through 2015 there were four main actors in the mobile ransomware space that dominated.  There's something called S-V-P-E-N-G, P-L-E-T-O-R, Small, and Fusob.  Wonder what that's an acronym for, or an abbreviation for.



LEO:  Fusob, you know.



STEVE:  Fusob, right.  "At this time Pletor," they said, "has almost stopped its expansion.  Its creators have launched an infamous Acecard trojan and seem to be pouring their resources into developing and spreading that instead."  Oh, so their attention kind of got diverted by a different trojan they're working on.  "The developers of Svpeng have also refocused, mostly on the banking version of the trojan."



LEO:  Well, you've got to go where the money is.



STEVE:  Yeah.  "So that leaves only two big mobile ransomware families, Small and Fusob.  As a result, in the 2015 to 2016 timeframe, these two trojans represent more than 93% of the mobile ransomware space."  And what's interesting is that they have a lot in common, but their territories deliberately don't overlap, which is sort of suspicious.  Kaspersky says:  "It's noteworthy that the Fusob and Small trojan families have a lot in common.  Both display fake screens that pretend to be signed by authorities and accuse the victims of misdemeanor.  Both say that a criminal case will be opened unless the user pays the fine."  Which, you know...



LEO:  This cracks me up.



STEVE:  Yeah, it does.  A sophisticated user is like...



LEO:  If you just pay us 300 bucks, we won't have to send you to jail.



STEVE:  Yeah.  Pay $300 to the NSA, and we'll just give you a slap on the screen and let you go about your business, and don't do that again.  So they say both Fusob and Small also offer rather strange ways to pay the ransom.  This Fusob suggests payment with iTunes gift cards, which apparently provide sufficient anonymization.



LEO:  Yeah, but you don't turn those into - maybe you can turn them into cash.



STEVE:  Or maybe the guys that did Fusob just really like iTunes stuff, and they want to buy some goodies.



LEO:  Some apps, yeah.



STEVE:  Yeah.  Whereas Small offers victims the option of paying by the Kiwi payment system or the MoneyPak xpress packet vouchers.  And they write:  "Both were probably created by some Russian-speaking groups of cybercriminals, but with very different approaches."



LEO:  Oh, the viruses.  Because Kiwi and MoneyPak were not.



STEVE:  Right.



LEO:  You can get a MoneyPak at 7-Eleven.



STEVE:  And then they talk about - and remember there was - in fact it was MoneyPak at 7-Eleven ran out because in early days...



LEO:  Right, right.



STEVE:  Remember that?



LEO:  Yeah.



STEVE:  In the early days of CryptoLocker, that was the way you paid for CryptoLocker before bitcoin.  And everyone was running to 7-Eleven to buy MoneyPaks.  And the guy at 7-Eleven said, "I don't know what's going on, but the J-hooks are all empty."



LEO:  We've got a real run on these things.



STEVE:  So this Fusob detects the device's language.  And if it's one of the post-Soviet Republic languages, Fusob does nothing.  Otherwise, it shows a screen that claims to come from the NSA and demands ransom from 100 to $200.  The majority of Fusob's victims, more than 41%, live in Germany.  So that seems to be the main focus.  Then second and third are the United Kingdom and the U.S., with 14.5 and 11.4%, respectively.



LEO:  But if you live in Lithuania, they go, "Oh, never mind."  That's so strange.



STEVE:  Well, that's where - although Small - and that's what's different.  The Small family, almost 99% of Small's victims are located in the three countries that Fusob avoids - Russia, Kazakhstan, and Ukraine.  The Small ransomware shows a government-themed screen with payment instructions, threats, and a demand for, well, it's in rubles, from 700 to 3,500, which is roughly between $10 and $50 U.S., to unlock the infected device.  And then there is an English locale version Small also, but it has a different block screen, of course, and mentions the FBI, and demands a lot more money, $300, because we rich Americans with our expensive phones, we can afford more, apparently.



So anyway, I thought that was interesting.  They wrap up with a what-to-do.  And they said, and of course this is strongly good advice, install applications only from official shops such as Google Play.  To be sure that no application makes its way onto your device from an untrusted source, go to Android settings, choose security, and make sure that the unknown sources box is not checked.  And of course I'm sure it defaults to having unknown sources disabled.  And so the user would have to deliberately enable it if they wanted to get something.  I actually did that for the Zeo app when it was first made available because I just needed to get it from wherever it was, but then I turned it off afterwards because, yeah.



LEO:  Typically now, anyway, what happens is when you sideload an app it says, okay, we're going to enable this - after lots of warnings - but only for this one download.



STEVE:  Nice.



LEO:  And then it turns back on protection.  So, yeah, I think they're very aware of the risks involved.



STEVE:  And then of course the standard advice from us and also from Kaspersky:  "Regularly update your device's firmware and its installed apps.  You can choose to update apps automatically, but you still need to have the system updated manually.  And it's better to do that," they write, "as soon as an over-the-air update arrives."  And then of course Kaspersky says:  "Install a strong security solution."  And we're sort of out of the mainstream.



LEO:  Yeah, that's where it kind of bugs me because the company that makes the solution...



STEVE:  Yes, exactly.  And Leo, wait till you hear what Symantec did.  Oh.  Anyway, so yeah, it's called you have to be very careful, or you create a whole new attack surface.  Because if something is sitting there inspecting what's coming in, and it's got any problems...



LEO:  Right, right.  I don't think there's any evidence that you need antivirus on mobile platforms.  Just, you know...



STEVE:  I think you're right.  To me that seems like a stretch too far.  I mean, most people, you know, I'm running whatever that Microsoft thing is they keep changing the name of.  Sometimes it's Windows Defender, sometimes it's the little green house icon.



LEO:  But it's different because on mobile everything is kind of isolated, certainly on the iPhone.  An antivirus can't do any of the things it would do on a desktop on an iPhone.  All it could do - and in fact, as far as I know, it's the same thing on Android, all they do is scan downloads before you install it, and Google's already doing that on Android.



STEVE:  Right, right.



LEO:  So that's a little self-serving on their part, I think.



STEVE:  Yeah.  So this got a lot of forwards to me.  A guy who took a good hard long look at Android's full disk encryption, so-called FDE, successfully extracted the keys from his device.  And this was a, I don't remember now which version, but Qualcomm chipset.  And Qualcomm goes to some lengths to protect this, as you would expect.  But it turns out it's insufficient.



So let's first recall how Apple's full disk encryption works.  And that leads us to why it is so secure.  In the factory, there is a 256-bit userID, a unique ID, a UID, which is burned into the hardware.  And so it's contained.  It's write once, and it's read never.  You cannot read that.  Apple doesn't know what it is.  There's literally, from any API, no way to get the key.  Every device has one.  Every device is unique.  And there's no way to know what it is.  The only thing you can do is give it work to do, give this secure enclave a blob to encrypt or something to sign, and it'll do it, and it gives you the result.  But it does that without ever exposing the key, and it cannot be removed.  The user's password is - and here's this weird word thy invented that everyone in the security industry puts in quotes because it's like, come on, really?  And that's - remember this, Leo? - "tangled."



LEO:  Tangled, yeah.



STEVE:  They "tangle" the user's password in some undocumented way as part of this, so that the device by itself has no ability to do decryption.  The user has to provide the password.  It is then entangled - sounds like some quantum entanglement thing.  It's then entangled with the secret that's in the chip. And those two things, something that cannot be removed and cannot be exposed, but can only be used, is required, plus something that the user knows or provides is the other part of that.  And short either of those two things, nothing's happening.



And then, on top of all that, there is a hardware-enforced 80-millisecond overhead.  And this is not short-circuitable.  It's that it takes the hardware 80 milliseconds to do whatever it's doing.  So there's probably a deliberately complex password-based key derivation function, a PBKDF, which just takes 80 milliseconds. Can't make it any quicker because it's got a lot of work to do during that time.  So it's not like a software delay that's been imposed, you can just code out that delay loop.  It's actually doing work that has to be done in order to derive the proper intermediate key, given the unique ID and the user's password.



So now Android.  Starting with v5, as we talked about back then, Android devices default to protecting all of the user's information by enabling full disk encryption.  And remember that, in the beginning, there was hardware acceleration for that which paradoxically was not being used.  And as a consequence, all of the encryption as it writes and decryption as it reads was being done in software.  And unfortunately, that created enough overhead that people were turning it off because their phone was too slow with it turned on.  But ultimately the hardware that was there from the beginning to accelerate this got engaged, got implemented.  And then background full disk encryption became the default.



Now, the good news is that Android's FDE, full disk encryption, is based upon a time-tested, well-known Linux kernel subsystem called "dm-crypt."  So this is good news because it's not something that anyone, some Qualcomm engineer or somebody else jut sort of home brewed.  It's widely deployed and researched and pounded on and done right.  However, as we know, an encryption system implementation may have no weaknesses, but the vulnerability can still be in its key management.  That's the hard part.  Getting the data encrypted securely, we pretty much know how to do that.  And the algorithm's not secret.  It's a Linux kernel subsystem.  It is open source.  Everybody can go take a look at it.



But as with any good crypto, the secret is not in the algorithm, it's in the key.  And so what research has shown is that probably due to the comparative clunky keyboard of mobile devices, compared to a nice physical keyboard on a desktop, mobile users tend to choose easier-to-enter, lower entropy passwords.  So of course that comes back a little bit later, if something makes this brute-forceable.  And that's essentially what happened is Android implements, it's got this notion of a TrustZone with a secure secondary processor.



The problem is that there is an API that's documented, and "trustlets," as they are called, little trusted applets, trustlets, can be loaded into this processor's execution space.  And the code in the TrustZone can be extracted and reverse-engineered, and has been.  Consequently, several exploits have been found which break the TrustZone's trust.



Now, when this news came out, Google was quick to point out that this researcher had leveraged two known vulnerabilities, the first of which was fixed in January of this year, and the second of which was fixed just over a month ago, in May.  So still pretty fresh.  And an analysis, oh, I don't remember now who did the analysis.  But it turns out that analysis of enterprise-deployed Android devices showed that, despite the fact that both patches existed, 37%, more than a third of audited enterprise Android devices remain vulnerable, meaning that they can, right now, using this system, which has been fully disclosed, the guy's got code on GitHub, a beautiful blog posting.  If anyone's interested in the intimate details of this, it's just a very nice expos of how he pulled this off.  But basically it allows any of these devices to have their full disk encryption keys extracted.



So this researcher did pull the keys, and then wrote some software to do a simple brute-force attack.  Now, in his example the attack was - the password was simple, so it found it like on the third guess.  But the problem is we know exactly what the algorithm is.  In fact, right there, Leo, where you are, that's this week's Picture of the Week.  That is the rather complex key flow for the Android full disk encryption with the TrustZone and everything.



LEO:  This is their entanglement here.



STEVE:  Exactly.  That's their version of tangling the password and the secrets.  And essentially the secrets are stored out in the nonsecure processor in encrypted form, and then they are provided to the secure processor and decrypted when needed.  And so what's different is it is truly impossible to get the key off of an Apple device, an Apple mobile platform, onto a roomful of GPU-accelerated, special-purpose hardware to then brute-force the key.  That can be done on Android devices that have not had these two patches applied.  And the problem is it's never going to be as secure as an implementation where the hardware simply won't give it up.



And in fact in the comments at the end of that blog post, the author of Hashcat, who we've spoken of before, Jens Steube, has offered to accelerate the cracking, that is, to implement that crazy algorithm or what of it you need in order to do brute-forcing in his very fast and increasingly powerful Hashcat system.  So the moral of all...



LEO:  But let me ask you, because I read this also.



STEVE:  Yeah.



LEO:  The implication is it's because Qualcomm is not doing its enclave properly; right?



STEVE:  Right.  I was just going to say...



LEO:  If the phone didn't use Qualcomm, I mean, in other words, this isn't an Android issue, it's a Qualcomm issue.



STEVE:  Correct.  Well, yes.  And so it's not - if it didn't use  Qualcomm - okay.  So the moral I was getting to is...



LEO:  Oh, I'm sorry.



STEVE:  ...making things difficult is...  



LEO:  Is difficult.



STEVE:  Is no longer good enough.



LEO:  Yeah, right.



STEVE:  They need to be impossible.



LEO:  Right.



STEVE:  And so, I mean, Qualcomm, you look at that flowchart, and your eyes cross.  I mean, I spent some time with it.  It's like, okay, yeah, it all makes sense, and I can see why they're doing what they're doing.  But they just didn't go far enough.  The little bit of gray area got taken advantage of.  It has to be impossible.  And Apple understood that and invested in the hardware to do it.  I imagine, I mean, it's not like there's anything special or that that's hard to do.  Essentially, for example, that's what the Yubico goodies are.  They've got the key inside, and they never give it up.  It is a write-once secret, and then it just uses that.  So it's not hard to do.  Qualcomm just didn't do it.



I think they got overly complicated.  The idea of having trustlets, when I read that third parties could load trustlets into the secure processor, it's like, no, no, no.  Take that bullet point off of the data sheet and lock this sucker down so that nothing can get the key out of the hardware.  So I think it's a problem that they're storing the key in encrypted form outside.  You just don't want to do that.  You want it to be absolutely inaccessible.  Period.  And that isn't this architecture.  So this is an architectural problem with this implementation.  But I'm glad you clarified, Leo.  You're right, it's nothing to do with Android, per se.  It's this particular implementation of the security architecture.



LEO:  Now, almost all Android phones in the U.S., in fact I would guess almost all, use Qualcomm chipsets for the radios.  But interestingly, some Samsung phones do not.  They use Samsung's own Exynos chipsets.  And I'm wondering, in that case, if there's a vulnerability.



STEVE:  Good question.  Good question.  Where the secret is.



LEO:  Yeah.  Well, the idea is it's a secure enclave  la Apple; right?  Implemented by the chipset manufacturer.  Is that right?



STEVE:  Correct.



LEO:  Yeah.



STEVE:  Correct.



LEO:  So it's just not well implemented by Qualcomm.  It could be implemented better; yes?



STEVE:  Absolutely.  Next version, it's like there's no reason that they wouldn't.



LEO:  So it's not a flaw inherent in Android.  It's a flaw in, like, the vast majority of Android hardware here in the U.S.



STEVE:  It's a flaw in the hardware, basically.  They just didn't do the hardware right.  They got a little too fancy.  And for whatever reason they made the key live out, I mean, they may have a reason.  They've had no opportunity to defend themselves.  There may be, like, some, I don't know what it would be, because I'd like to have an absolutely unextractable secret that binds this to the phone.  That's the difference.  If you can get that off the phone, then you can pour a roomful of Hashcat-driven GPUs on it.  And then, if you couple that with a weak password because users tend not to do fancy passwords on their touchscreens, then you've got the double whammy.



LEO:  You've got to feel for Google a little bit.  See, unlike Apple, which controls all this, Google's at the mercy of OEMs who are making Android hardware.  And it may be one of the reasons, one of the rumors that's been strong this week is that Google is going to do their own phone.  And it maybe one of the - not a Nexus phone, which is manufactured by another company for Google, kind of with Google's suggestions, but their own phone.  And that could be one of the reasons they want to do it.  I wouldn't be surprised.



STEVE:  I think that would be good.  I mean, we know...



LEO:  Then if they blow it, well, we can blame Google.



STEVE:  Well, and I doubt they would.  We know...



LEO:  Yeah, they know what they're doing.



STEVE:  ...Google understands security.  I would argue they're at the top of the pile.  I mean, Apple and Google, I mean, they're very visible.  But I have no argument with Google understanding security, which is a perfect segue into Tavis Ormandy's latest walk through somebody else's product.  So there was a lot of coverage of this.  Oh, and I forgot to mention, I did not, just for everyone who's wondering if I'm going to talk about the Lenovo problem, there was a lot of activity just - maybe I started seeing it yesterday, but a lot this morning, about some sort of a bad problem with Lenovo.  I was going to cover it; but when I dug into it, it suddenly exploded because it's not just Lenovo, it's a whole bunch of other OEMs that made the mistake of using Intel's reference code for the system management, the SMM stuff.  So I will explain it all next week.  It got too big for me to get a grip on it today.



But anyway, this problem with Symantec, and both the Symantec label and the Norton label for consumers, Dan Goodin writing for Ars Technica said - I just love the beginning of this.  He says:  "Much of the product line from security firm Symantec contains a raft of vulnerabilities that expose millions of consumers, small businesses, and large organizations to self-replicating attacks that take complete control of their computers, a researcher warned Tuesday."



Now, I would only dial that back on "raft."  That's really not a "raft" of vulnerabilities.  It's...



LEO:  It's a dinghy.



STEVE:  It is an interpreter in...



LEO:  It's a small dinghy.



STEVE:  Okay, good, yeah.  It's an interpreter in the kernel, and you just don't want interpreters in the kernel if you can avoid it.  That's what Windows did with GDI, when they moved the graphics device interface into the kernel.  And that's why a JPEG could take over your computer.  Okay.  So Tavis is wonderful.  He, with of course Google's Project Zero, is a cross-vendor, we're just going to look at things and see if we can find problems.



So Tavis produced a detailed blog post which begins:  "Symantec" - as if we didn't know - "is a popular vendor in the enterprise security market.  Their flagship product is Symantec Endpoint Protection.  They sell various products using the same" - and here it is - "the same core engine in several markets, including a consumer version under the Norton brand.  Today," writes Tavis, "we're publishing details of multiple critical vulnerabilities that we discovered, including many wormable remote code execution flaws."  I mean, you just don't want those words to be put together next to each other.



LEO:  Wormable execution flaws.



STEVE:  Wormable remote code execution flaws.  Oh.  Tavis writes:  "These vulnerabilities are as bad as it gets.  They don't require any user interaction, they affect the default configuration, and the software runs at the highest privilege levels possible.  In certain cases on Windows, vulnerable code is even loaded into the kernel, resulting in remote kernel memory corruption."



LEO:  Oh, god.



STEVE:  "As Symantec uses the same core engine across their entire product line, all Symantec and Norton branded antivirus products are affected by these vulnerabilities."  And he enumerates just a few.  He says:  "Including Norton Security, Norton 360, and other legacy Norton products across all platforms," meaning Windows, Mac, Linux; "Symantec Endpoint Protection, all versions, all platforms; Symantec Email Security, all platforms; Symantec Protection Engine, all platforms; Symantec Protection for SharePoint Servers," and he says, "and all the rest, too."  So it's like, oh, my goodness.



"Some of these products cannot be automatically updated," he writes, "and administrators must take immediate action to protect their networks.  Symantec has published advisories for customers.  In a coordinated disclosure, shortly before Tavis's post, Symantec issued its own advisory, which listed the 17 Symantec enterprise products and eight Norton consumer and small business products affected."  And I have a link in the show notes for anyone who, like, basically, if you're using any Symantec AV, go update it, like, yesterday.



Tavis wrote:  "Because Symantec" - and here it is - "uses a filter driver to intercept all system I/O" - I'll explain what that means in a second - "just emailing a file to a victim, or sending them a link to a file which is an exploit, is enough to trigger it.  The victim does not need to open the file or interact with it in any way.  Because no interaction is necessary to exploit it, this is a wormable vulnerability with potentially devastating consequences to Norton and Symantec customers.  An attacker could easily compromise an entire enterprise fleet using a vulnerability like this.  Network administrators should keep scenarios like this in mind when deciding to deploy antivirus.  It's a significant tradeoff in terms of increasing the attack surface.



"The flaws reside in the engine the products use to reverse the compression malware developers use to conceal their malicious payloads.  The unpackers work by parsing code contained in files before they're allowed to be downloaded or executed.  Because Symantec runs the unpackers directly in the operating system kernel, errors can allow attackers to gain complete control over the vulnerable machine."  So Tavis wrote that one of the proof-of-concept exploits he devised works by exposing the unpacker to odd-sized records which cause inputs to be incorrectly rounded up, resulting in a buffer overflow.



Okay.  So a filter driver is officially sanctioned hooks in Windows which allow a third party - Microsoft uses them, too - allows a third party to essentially insert a shim.  The idea was that dealing with the intricacies of the network interface adapter, the NIC, it's incredibly detailed.  You have to really know your stuff.  And it's in a whole different API down in the kernel than it is up in the application space.  So there's interrupts flying around.  You have to be very careful not to hog too much CPU.  I mean, this is in the kernel.  This is the OS.  And efficiency really matters.



So what Microsoft did is they decided, okay, we cannot have people writing their own device drivers, like, redundantly, because that'll be a disaster.  So we'll provide those.  But then we'll allow people who have a need, essentially, to layer their code between the device driver and the rest of the system, thus a shim.  And that's what Symantec did.  And it's one piece of code, one filter driver, which installing a Symantec AV product installs into the kernel.  And what this does is inspect all of the traffic, at least inbound.  I'm not sure if it's outbound also.  But it inspects it on the fly.



And so one of the things that malware products do, actually one of the things that good products do, lots of products do it, is they compress their EXEs.  All of my EXEs are compressed.  Not because they would be huge otherwise, but because the EXE format, and I've grumbled about this in the past, the EXE format is incredibly inefficient.  Huge tracts of lands.  No, huge regions of null space.  I mean, just huge.  And it's, like, sitting there in the file.  So the point is anything, an EXE compressor could examine this executable and say, what is this 12K of zeroes?  That's dumb, so we're going to instead put a tag and say here lies, in the original file, 12K of zeroes, and then not have any.  So you just saved yourself 12K.  And so on.  It's like that.



So but the point is that means that on the front of that executable needs to be a little interpreter which itself runs when the OS loads the executable.  The interpreter gets control and reads this compressed EXE.  And so, for example, it finds this little tag saying "Here lies 12K of nulls," and it says, "Oh," and so it expands that on the fly in memory back to the original 12K of empty space.  But that means it's an interpreter.  And this comes back to what we were talking about with the danger of running interpreters in the kernel.  It's so easy to make a mistake.  And Symantec did.



[Background "Yabba dabba doo"]



STEVE:  Oh.



LEO:  That's not a mistake.  No, no.  That's a good thing.



STEVE:  One that I forgot to mute.



LEO:  Oh, don't worry, I like it.



STEVE:  I go around the house and turn off all my iOS devices.



LEO:  Steve, if I were you, I'd turn it up because you never know.



STEVE:  Well, it's little bit of a chorus, and it's sort of - because they all receive the...



LEO:  Yabba dabba do at once?



STEVE:  Yeah, exactly.



LEO:  We should mention that that sound occurs whenever somebody charges another copy of SpinRite to the old credit card.



STEVE:  I always appreciate it.  It keeps the lights on.  Even though one of these lights is flickering on and off.



LEO:  It keeps Fred employed, as well.



STEVE:  So the 10,000-foot view is Microsoft has spent painful decades, and we've lived through them - Code Red, Nimda, MS Blast.  How long, Leo, in the beginning of this podcast, were we bemoaning the fact that email was running scripts?  Remember those days?



LEO:  Yeah, ai ai ai.



STEVE:  Oh, my lord.  It's like, turn that off.  And they finally did, as we talked about last week.  But it took only 20 years.  So Microsoft has spent painful decades, carefully hardening the core Windows operating system.  Then Symantec comes along and installs a bug-ridden, traffic-intercepting filter into the OS kernel, which completely compromises hard-won security.



And so, again, this is a classic attack surface vulnerability that we've been talking about.  This is a problem where, with any add-on, we've seen them with other AVs and other vendors' add-ons, Lenovo of course is constantly in trouble for this, where an otherwise relatively secure and hardened operating system, Microsoft keeps talking about how Windows 10 is the most secure operating system ever, except, yeah, then people load a bunch of this stuff on it, and it's cheese, Swiss cheese again.  So anyway, wow.  And of course, Leo, you and I are careful and prefer to run adblockers, and we're careful about where we go and don't go on the Internet.  And knock on wood - is there any wood around here? - don't get ourselves infected.



So these judges in Brazil just keep having a problem with the fact that WhatsApp is unable, I mean, actually architecturally designed to be unable to decrypt the messages that apparently drug people are using it to communicate with.  So I don't know.  Once again Brazil...



LEO:  This is going to be a big problem.  And it's not just for Facebook.



STEVE:  You're right.  You're right.



LEO:  If countries insist, I mean, obviously what they want to do is put pressure on WhatsApp to have a backdoor. 



STEVE:  Correct.  Correct.



LEO:  But there's no response that WhatsApp can give them.  They just say we can't give you...



STEVE:  No, there isn't.  



LEO:  Take our money, but we can't - do anything you want.  Throw us in jail.  



STEVE:  As we know, WhatsApp is designed correctly so that it is impossible for them to decrypt the messages.  And twice there have been WhatsApp outages caused by judges commanding that it be taken offline.  But I'm sort of stepping on my story here.  Last Thursday a court in Brazil blocked a little over $6 million of Facebook's funds because of course Facebook owns WhatsApp.  And apparently Facebook funds is what was available to be blocked.  WhatsApp failed to turn over messages sought in a drug-related case.  And as I was writing this, I was thinking, this actually is kind of pure gold advertising that Facebook couldn't buy.



LEO:  Especially among the drug dealing public.



STEVE:  Yeah.  It's worth way more than $6 million for Facebook for WhatsApp to have this reputation of being such a problem because, we're sorry, we would love to help you, but we can't decrypt the traffic.  No matter what you do.  So:  "After repeated failure over five months to turn over this particular information for this particular drug-related case, Brazil's G1 news service reported that a judge froze the funds which are equal to WhatsApp's accumulated fines for non-compliance in the case.  Because WhatsApp has no bank accounts in Brazil, the judge froze the funds owned by its parent, Facebook."



The Brazilian court, however, did not again use provisions of Brazil's Internet law that allows courts to shut down service in some cases of noncompliance with court orders.  Of course, as we know, earlier this year a judge ordered a 72-hour shutdown of WhatsApp, which angered so many of the service's 100 million Brazilian users that the shutdown was lifted after just a day, after about 24 hours, by another court, who essentially overturned that judge's order.



So, yeah, as I was thinking about this, it's like, wow, I'm sure $6 million, to Facebook, okay, fine, take it, great story.  We're happy that people are - we're not happy that drug dealers are covering their tracks using our technology, but for people who want privacy and have a legitimate use for it, WhatsApp does the job.



So this was an interesting story.  It sounds worse than it turns out to be.  And that is that a very popular line of routers, SOHO, the consumer routers, TP-Link - and they have some small enterprise equipment also.  TP-Link once upon a time used the domain that was printed on the label on the underside of the router:  tplinklogin.net.  And also in the manual.  And at some point, for whatever reason, they switched to tplinkwifi.net.  And so their newer products use tplinkwifi.net as the configuration domain.  The older ones use tplinklogin.  So what happened in the news is that they weren't paying attention, and the tplinklogin.net, the original, technically retired, but still printed on the label and in the manuals of the older devices, expired.  And somebody grabbed it and is interested in selling it for $2.5 million.



LEO:  Oh, boy.



STEVE:  Okay.  Now the good news is our friend Michael Horowitz, who writes the Defensive Computing column for InfoWorld, he pays a lot of attention to router issues.  And I've got a couple links to share here in a minute.  But so Michael researched it further because it sounds like the end of the world, but it's not.  Because what that label on the underside of the router does is it's regarded as easier to type that than 192.168.0.1 or .254 or whatever.



LEO:  Linksys does this, Netgear does it, everybody does it.



STEVE:  Right.  So the router itself sees the browser making a request for tplinkwifi.net, has a little mini DNS server and so returns the router's current gateway IP for that particular domain.  Other ones it lets go through to real DNS servers.  It just intercepts that one.  And then that's an easy way, a shortcut of getting your browser to see the local router's configuration pages.



So what that means is anybody using it the way it was intended to be used, inside the LAN, behind the router, to get to the router, tplinklogin.net, the retired and no longer valid one, well, that router that has it printed on its label and in its manual, it's still going to take you to its own page.  The only real danger is somebody outside of the LAN.  I don't know why you would go to tplinklogin.net if you were not trying to get to your router from inside the LAN.  So it's a little sloppy that they let that go.  A company as big as TP-Link, I think this was just inadvertent.  And the problem is now maybe $2.5 million would be galling to pay some domain squatter for the right to [crosstalk].



LEO:  Yeah.  So this is interesting because I always wondered how those redirects worked.  It doesn't get to the public Internet at all.  It just goes to - the router sees it and goes, oh, you mean me?  Oh, yeah, I'm right here.  So it doesn't matter.  They don't even need the domain name.



STEVE:  No.



LEO:  That makes sense.



STEVE:  So anyway, Michael Horowitz got one, had one, verified it, verified even that when you change, if you reconfigure the router so that it's got a different, like a weird gateway, like .9.9, it still redirects it to the current gateway IP, so it always works.  It turns out that Michael operates a site, nice site called RouterSecurity.org that we've never talked about before.  And his coverage of this, which I thought was excellent, took me to RouterSecurity.org for the first time.  And I noticed that he strongly recommends that savvy users simply avoid all of the consumer - and these are my words - blue box routers.  What he recommends is something called the Pepwave Surf SOHO from Peplink.



LEO:  What?  I never heard of that.



STEVE:  I know.  And it looks very nice, too.  Take a look at it from the link in the show notes, Leo.  Michael writes:  "I maintain a long write-up of its pros and cons at RouterSecurity.org.  The Surf SOHO" - that's the name of the router - "is a business-class router."  So it's not quite - it's a little more expensive than the cheesy blue boxes, but not enterprise grade.  It's a business-class router, he writes, "that is a big step up from consumer models, yet is reasonably priced and no harder to configure than the average consumer-targeted router."  He says:  "My only relationship with Peplink is that of a customer."



But, for example, I love it when he's talking about this router, he says the router, for example, supports point-to-point VPN.



LEO:  That's cool.  



STEVE:  So you're able to link, to use the router through the public Internet to interconnect to remote networks.  And he says, "Which is a feature I have sometimes used."  He says it does not support WPS, which is another reason to like it because you don't want WPS...



LEO:  Right, right.



STEVE:  ...in your router.  So a lot of interesting features.  For example, you could also - there's a WAN USB port on the back where you could plug one of the little cellular modems, and it will seamlessly, if your main connection to the Internet goes down, it will seamlessly switch to backup using the cellular connection.  And it supports all of the various carriers and other stuff.  So anyway, I just wanted to point people at RouterSecurity.org.  I know that it would be of interest to our listeners.  And Michael, who listens to the podcast, thanks for the great coverage of this weird TP-Link story and for making it clear that it's more of a tempest in a teapot.  It's probably not going to affect people with older routers when they go back to try to navigate to their router's config page.



Okay.  Now, finally, this week's Internet of Things horror story.  Okay, Leo, first I have to say two weeks ago we covered one that was just really, like, another one of these.  Some guy bought a multicamera Internet surveillance system.  I can't remember the brand, but we talked about it two weeks ago.  I just wanted to sort of fill you in.



LEO:  It was Foscam.  Foscam?



STEVE:  Huh?



LEO:  It was Foscam; wasn't it?  Oh, well, anyway...



STEVE:  Sorry?



LEO:  Foscam?  Foscam.  No?



STEVE:  No, I don't think - I don't remember.  Anyway, so he sets it up, decides it's not what he wants, and returns it.  Then a couple months later he gets an email from the service that he registered it with, saying that one of the cameras had sensed motion.  And he goes, "What?" and clicks the link.  And now he's looking at somebody else's home.  So the short version of this is that it turns out that somebody repurchased the returned multicamera surveillance system, set it up, created an account.  And it turns out that you can, where the system is now, or it was, you could have multiple accounts all referring to the same camera system.  So, and when the camera system sensed motion, it sent messages to everyone who had an account for that camera system.



So anyway, just another example of, oh, my goodness, this was not done right.  And it was even worse, too, because then it turns out, when you look at it, the camera that you're viewing in real time, the MAC address was in - I don't remember the details now.  But something was, like, in the URL.  So you could just increment them and cruise around through all of this company's customers' homes that were under surveillance by themselves, and now by everybody else.  So anyway, that we talked about two weeks ago.



This week we have a WiFi AC plug which has been withdrawn from Amazon.  So a security researcher, Matthew Garrett, created a one-star Amazon review.  The plug was called the - shoot, I don't see it here.  AuYou, I think it was, A-U-Y-O-U.  I went looking for it this morning, and then I subsequently saw a note from The Verge saying that it had been pulled, because I couldn't find it.  And so that verified that it was gone.



So anyway, Matthew's title is "Nice hardware, infuriating setup issues, terrible insecure software."  And so I'm just going to - I'm going to share the review because it's perfectly written, and there's no fluff in it.  He said:  "There's a lot to like about this hardware, but unfortunately it's entirely overwhelmed by everything there is to hate about it.  But before we get to that, I received this product at a discount in return for writing an honest review of it.  Onwards.



"The packaging is entirely reasonable.  There's a small cardboard box, a sheet of instructions, and a piece of hardware securely wrapped in bubble wrap.  It's very small, but feels well built.  There's no creaking plastic under pressure, and no parts feel loose.  Once it's plugged in, a blue LED in the button starts blinking, waiting for you to set it up.  The app attempts to walk you through the setup, but things start going wrong here.



"The system is based on the ESP8266 module, which," Matthew writes, "is a great choice for this sort of application."  Oh, and by the way, if you google ESP8266, it is everywhere.  SparkFun offers it for, like, $7 or something.  It is a wonderful-looking little thing.  WiFi, built-in 32-bit processor, a MB of flash memory.  So it's a full system for connecting any of your IoT stuff to WiFi.  So I agree with Matthew, just it's a beautiful little thing.  Unfortunately, it wasn't very well designed from - not it, but the people who used it to build a smart plug around.



He say:  "It's cheap [meaning inexpensive], but well featured.  There's a lot of easy off-the-shelf code that vendors can incorporate into it to cut down development time and ship better products faster.  One of the features available is something called Smart Connect."  And I should mention I need to find out about this because this really sounds like the right way to go with IoT setup.



He says:  "...where an app on a phone encodes your WiFi password into network broadcasts of different lengths."  And I don't know what that means, exactly, but that's why I need to dig into it.  He says:  "It's possible to detect these even without the password, so this allows your phone" - although I have to make sure that other people can't see this broadcast.  Maybe it's not such a good idea.  Anyway:  "This allows your phone to pass the information to the socket without having to fiddle about connecting to a different network.  Simply hold down the power button to enter setup mode, and the phone does the rest.



"At least, it does in theory.  In practice, it fails for two reasons.  The first is that it'll happily try to do this on a 5GHz network, even though the socket" - that is, your phone will try to do it on a 5GHz network - "even though the socket only has 2.4GHz support.  The other is that the app doesn't have the appropriate permissions to do this on Android 6, so it doesn't work on new Android phones at all, even if you are on a 2.4GHz network.  However, it also supports a more traditional setup mode," which we've talked about before.  "By holding down the power button again, it turns into an access point.  Then the phone sees it, connect to it, and that allows the phone to then get the network setup data into the plug."



And he says:  "Again, at least in theory.  In practice, the app is looking for a network called SmartPlug.  And this version of the hardware creates a network called XW-G03, so it never finds it."  It's like, how can this possibly work?  So he says:  "I ended up reverse-engineering the app in order to find out the configuration packet format, sent it myself" - so this guy's got some serious skills - "and finally had the socket on the network.  This is, needless to say, not a reasonable thing to expect average users to do.  The alternative is to find an older Android device or use an iPhone to do the setup."



Finally:  "Once it's working, you can just hit a button on the app, and your socket turns on or off.  You can also program a timer.  If your phone is connected to the same network as the socket, then this is just done by sending a command directly; but, if not, you send a command via an intermediate server in China."  Sit down, everybody.  "The socket connects to the server when it joins the wireless network and then waits for commands."  So it has a static connection to a server in China, waiting for on/off commands.



"The command packets look like they're encrypted, but in reality there's no real cryptography at all."  So it's just some light obfuscation.  He says:  "I wrote a simple program to decode the packets and looked at them in more detail.  There's a lot of unnecessary complexity in the packet format, but in the end the relevant things are just a command and the MAC address of the socket.  On the local network this is sent directly to the socket; otherwise, it goes via the server in China.  The server looks at the address and uses that to decide which socket" - that is, which AC socket - "to pass it on to.  Other than the destination, the packets are identical.



"This is a huge problem.  If anybody knows the MAC address of one of your sockets" - which, remember, this is all essentially in-the-clear data.  Anybody, for example, sniffing traffic to that server, anywhere along the line, would be able to get the MAC addresses of all of the sockets currently in use in the world.  Anyway, so "If anybody knows the MAC address of one of your sockets, they can control it from anywhere in the world.  You cannot set a password to stop them, and a normal home router configuration won't block this."  Because of course it creates an outbound connection that the router NAT allows through, as it does all outbound connections.



"You need to explicitly firewall off the server" - and then he gives the IP address of 115.28.45.50.  And of course we don't know if that's after a domain lookup or if that's hard coded.  He says:  "...in order to protect yourself.  Again, this is completely unrealistic to expect for a home user; and, if you do this, then you'll also entirely lose the ability to control the device from outside your home.



"In summary, by default, this is stupendously insecure.  There's no reasonable way to make it secure; and, if you do make it secure, then it's much less useful than it's supposed to be."  He says:  "Don't buy it."  And, by the way, one star is the lowest you can do.  You cannot do a zero star, unfortunately, because I tried once.  Amazon doesn't recognize you're initiating a review until you select one to five stars.  You can't do zero.  So otherwise he probably would have.



Anyway, TechCrunch's Kate Conger reached out to Matthew, and she wrote in TechCrunch's coverage of this, she said:  "Garrett sent me" - it's Matthew Garrett.  "Garrett sent me a few emails he received from the company."  And here's one, quote:  "Just now my boss has blamed me, and he said if I do not remove this bad review, he will quit me.  Please help me," the representative wrote. "Could you please change your bad review into good?"



Then Kate writes:  "Garrett responded that he would update the review if the manufacturer fixed the flaw."  Entirely reasonable.  Oh, here it is, A-u-Y-o-u.  So AuYou is the company.  Maybe it's A-U-Y-o-u.  Anyway, I don't know.



LEO:  No one knows how you pronounce it.



STEVE:  "[The AuYou] representative insisted she would be fired if the review was not updated.  A week later, she followed up again, asking Garrett to take down the review.  The representative then said that she would report Garrett to Amazon if he didn't take down the review, and that other Amazon reviewers had written in to complain about it."  Well, first of all, I doubt that's true.  He has an insane number of up votes, something like 1,800 positive votes and only 10 weren't.  So everybody, the 10 employees at AuYou all said bad review, bad review.  The other 1,800 people said thank you to Matthew for this.



So again, Kate writing, said:  "Garrett says he leaves a lot of security-based reviews on Amazon, and this has never happened to him.  Of course, no one needs to lose their job over a single Amazon review."  Well, except maybe in China.  "Garrett says he's not sure if he's being manipulated or if someone's job really is on the line."  My take is, sorry, that's completely irrelevant to the fact that he's doing this service by taking a look at this.



He wrote to Kate:  "If I thought that there was a realistic chance that people were going to lose their jobs over something I was writing, that's something that would make me reconsider," he wrote.  "On the other hand, the attitude that many companies have of not giving any indication of caring about the security of the people they're selling to is horrifying in its own way.  That is important, to make people aware when choosing these devices."  And of course you couldn't - you're singing to the choir on that count.  And I just - I am so grateful that we are still in a world where this is legal.  That is, that the great threat of DMCA-ish legislation would make it dangerous for someone to do what Matthew has done, to take a look at how this stuff is working.



This is such a perfect case in point of how we desperately need to keep researchers who are not malicious, clearly, who have the intent of improving products.  Look at Tavis with Project Zero and what he, I mean, yes, egg is on Symantec's face.  And by the way, I skipped over, I just forgot, the blurb there about the fact that Symantec was using open source software that seven years ago had vulnerabilities that had been disclosed for which there is exploit code that works against the stuff that they've installed into everyone's kernels who are using this AV.  So we have to protect this ability to have people challenge otherwise-closed systems that are not open so that people can pry into them and see what's going on.  We have to.



And by the way, I did look at all of Matthew's other reviews, and he is - I think there were like 14 reviews, very much the same, I mean, not fluff at all, but really taking a close look at the way these things are working.  So I just finished by noting that the plug appears to have been taken down from Amazon, and I just saw before the podcast that The Verge had reported the same thing.  Matthew's review remains with a permalink, but I could not find the plug.



And then, looking at the other products that the same company makes, this AuYou, they have two full home security systems, which just makes me shudder.  It's like, okay, these people should not be doing Internet-based connected products of this sort.  They just don't demonstrate the ability to do it right.



Wow.  Okay.  So errata.  Two things.  First of all, last week I used a word that I didn't know the definition of, apparently.  Despite the fact that back here is the AED, or I mean the OED.



LEO:  OED, yeah, I see it.



STEVE:  The OED.  I haven't read it recently.



LEO:  Not cover to cover, anyway, I hope.



STEVE:  I said "penultimate."



LEO:  Yes.



STEVE:  When I was describing SoftICE as the "penultimate debugger for DOS."  And a number of listeners said, "Okay, so what's the ultimate?"  And then I looked it up, it's like, well, penultimate means second best.



LEO:  Yeah, it's the one before the ultimate.



STEVE:  And I'm thinking, who made up this word?  I don't want a word like that floating around for people to use wrong.  Okay.  Give me a use for that word.  What possible use is this annoying penultimate word?  Who wants that?



LEO:  All right.  I'll give you an example.  All right.  In my opinion, the best episodes of any "Game of Thrones" series is the penultimate episode.



STEVE:  See, no one knows what that means.



LEO:  Well, I know what it means.



STEVE:  You and three other people.  And they all sent me email or texts.



LEO:  You heard from everyone, all seven people who knew.  Ultimate and penultimate are not the same thing.



STEVE:  I got that.



LEO:  Yes.



STEVE:  And we could just remove penultimate completely.  It's useless.



LEO:  No, it's useful.  The penultimate episode of "Game of Thrones" is always the best show.



STEVE:  Well, in this case I have to agree with you.



LEO:  It's always the case.



STEVE:  That one is useful.  But just say second to last because then we all know what we're talking about.



LEO:  Okay.



STEVE:  Anyway, so there's that one.  Second is I have had version control in place for decades.  I didn't want to get into it because mine is my own.  And it's not GitHub.  It's not cloud-based.  But so many people who understand the value of version control generically tweeted or sent email and said, "Oh, come on.  Gibson, how can you even be, like, calling yourself a programmer?"  It's like, okay, okay, okay.  So I have absolute backtracking auditing on every piece of code that I write.  It's built into my infrastructure.  I can go back in time on a file-by-file basis, not even checkpoint-by-checkpoint, but individual tracking back the changes in all of my source code as far back as I want, with high granularity in the near term and slowly reducing granularity as the files get older because the presumption is I don't need as much back then.  So, yes.



LEO:  And you wrote that yourself.  That's cool.



STEVE:  Yes.  Sorry that I was glib about it.  But believe me.  And it's the kind of thing where you normally don't need it.  But oh, baby, when you do?  In fact, I've used it just a couple times.  I'm tracking down a weird bug in the SQRL client that I introduced - inadvertently, obviously - when I updated the identity system to maintain four previous identities.  It had deep repercussions throughout the code I'd already written.  And so several times I've gone back a few months before I did that to take a look at what I had then.



So, yes.  Rest assured, everybody who knows how important it is, I've got it, too.  And I wouldn't live without it.  There have even been times like when I've just fumbled a finger and hit delete on a source file.  And it's like, oooh.  And you sort of stare blankly for a minute, and then it's like, okay.  And good news is I have something from 10 minutes ago, so I'm fine.  Anyway, so yes. I absolutely understand the need for it and have it.



Real quick note for our sci-fi-interested media viewers.  The two shows that are, eh, they're not top drawer, but they're post Syfy reboot that we've talked about.  Their second seasons just started.  And I know that many of our listeners are watching.  And it's two shows, "Killjoys" and "Dark Matter."  I think "Dark Matter" is the better of the two.  And they're just romp 'em, shoot 'em up, space team stuff, but they're fun.  And so I wanted to make sure that people knew that they had resumed last Friday.  I've not even watched them yet.  I've been really busy.  But I will because they were fun and sort of character-driven.  I mean, they're, like, not amazing, but they're okay.



And for those of us who are interested in politics, completely off-topic, but this'll be quick.  This week's bit.ly shortcut, so bit.ly/sn-567, is the cover story of this month's Atlantic magazine, titled "How American Politics Went Insane."  On Sunday's "Meet the Press," Chuck Todd interviewed the author.  And the things he said immediately brought me to attention because it echoed a conversation I've been having with my mom, sort of about sort of processing what we're seeing in this U.S. cycle's presidential election.  And I won't go any further.  And I won't take up any more time.



So I should say that link is to a PDF I prepared.  I'm obviously a political follower, and I've been wanting to understand what's going on.  This is a great piece.  So it's a PDF that my site is hosting.  I put the cover on it so that the Atlantic would get all of the credit for it.  And it is freely available on the web also:  "How American Politics Went Insane."  And for what it's worth, if you follow politics, I recommend it without reservation.  It's long.  It's about 20 pages, although the first page is all just cover.  But worthwhile if you're interested in such things.



And I did want to make a note that, as I promised last week, the second-generation of the Healthy Sleep Formula page is updated and online.  I'm not finished with it, but all the important stuff is there, and I'll be adding to it shortly.



And finally, I got a nice note from Jeremy Leik, spelled L-E-I-K - and he wrote, "pronounced 'like,' blame my German ancestors" - in Dimondale, or Dimondale, Michigan.  Don't know.  Dimondale, maybe.  And he said:  "SpinRite mentioned on Technibble.com."  And he said:  "Hello, Steve and Leo.  I'm writing today because I'm a user of SpinRite and a believer in its capabilities.  It has saved a few drives for me, and allowed me to recover data from a RAID array that came out of a NAS with failed electronics.



"I came across an article called 'Technical Overview of Popular Software Data Recovery Procedures' over at Technibble.  They mention SpinRite on page 2 of their article.  The part where they describe SpinRite seems pretty simplistic, and lumps it in with other software tools.  I would be interested in hearing from the horse's mouth, so to speak, what your thoughts are on this subject.  Thanks so much.  Jeremy Leik."



And so I'll just say that I completely understand that.  One of the good things about SpinRite is that it is so simple to use.  I mean, its goal is to fix your drive.  And that's what you do.  That's what it does.  You run it, you point it at the drive, and it goes and fixes it.  And so it doesn't look like there's much there.  But when I was thinking about what Jeremy wrote, I was reminded of a person I hired 20 years ago by the name of Mike Toutonghi, who was an incredibly, is an incredibly brilliant person.  Which is why I hired him.



And he'd been with GRC for, I don't know, a few months, and we were having lunch together, and I started explaining to him - he said something that indicated how unimpressed he was with SpinRite.  You know, it was paying his salary at the time.  But he just didn't think there was much there.  And so I said, "Okay, Mike.  Let me tell you what's in here."  And I started to go into it, and over the course of about an hour, like what it really takes to do what SpinRite does, what SpinRite completely hides.  And he was stunned.  I mean, he said he could not believe - that had never occurred to him, what would be necessary to do what it does, and how it works.  And a lot of that was proprietary.  So there is stuff I don't talk about because it is what pays all the bills.



But Mike sort of outgrew my little company.  There wasn't room for both of us.  So I was good friends with Brad Silverberg, who was one of the executive VPs at Microsoft at the time.  And I gave Brad a call, and I said, "Hey, Brad, I've got somebody for you."  Mike did go to Microsoft.  He was the MVP, the number one most valuable employee of the year at Microsoft and became one of their 12 - they have like a special designation, like something scientist or something.  I mean, he's like - he did .NET.  He invented the whole .NET system himself.  So anyway, he knows where he's coming from, software-wise, which is why I hired him.  And he was blown away.



So for what it's worth, what I love about SpinRite, like most of my software, is it just does what you want it to.  And it deals with all of the hard stuff itself, which is what makes it fun for me to create it in the first place.  And the bottom line is you run it, and it fixes your drive.  So Jeremy, I'm not surprised that somebody trying to do a review piece sort of says, oh, yeah, and here's a bunch of other stuff, and there's something called SpinRite, and, you know, blah.  It's like, okay, except, you know, it works.



LEO:  It works.



STEVE:  For the last almost 30 years now.



LEO:  Yeah, yeah.  Well, we have enough, I think, anecdotal evidence to say...



STEVE:  Oh, my goodness.



LEO:  ...it absolutely works.



STEVE:  Yeah.  At some point it stops being anecdotal.  It becomes rigorous.



LEO:  Yeah.  All right.  Let's write a script.  Let's Encrypt.



STEVE:  Oh, let's not do one for certificates.  So where is NL, the domain?  That's Norway?



LEO:  Netherlands.



STEVE:  Netherlands, right.  Computest is a security group in The Netherlands who took a look at a newly launched service called StartEncrypt.  So it's like, okay, uh-huh.  So Let's Encrypt, StartEncrypt, at least they didn't try to steal the trademark the way Comodo did.  So the company is StartCom.  And they have the so-called StartSSL are their certificates.  And so the StartEncrypt project was launched on June 4th, so, what, a month ago.  And of course it was inspired by the success of the Let's Encrypt project.  Okay, well, I loved Computest's disclosure because it was almost comically understated.   And I don't know if it's an English language translation thing.  It was just so polite.  And it's discussing something that is so horrifying.



So they wrote:  "Recently, one of our hackers found a critical vulnerability in StartCom's new StartEncrypt tool, that allows an attacker to gain valid SSL certificates for domains he does not control."  Which is like, what?  So we have a trusted certificate authority whose entire raison d'etre is to make sure that the identity of the people they are issuing certs to has been verified.  Anyway.  So they continue with this understatement:  "While there are some restrictions on what domains the attack could be applied to, domains where the attack will work include Google.com, Facebook.com, Live.com, Dropbox.com and others."



LEO:  Oh, my god.



STEVE:  Yeah, we've heard of them.  "StartCom, known for its CA service under the name of StartSSL, has recently released the StartEncrypt tool.  Modeled after Let's Encrypt, this service allows for the easy and free installation of SSL certificates on servers.  In the current age of surveillance and cybercrime, this is a great step forward, since it enables website owners to provide their visitors with better security at small effort and no cost."  And of course we talked about what a fabulous success Let's Encrypt has been.  And you can imagine the position that StartSSL is in.  Now, they had been offering free certs, limited time.  You'd have to keep going back every year, so there would be a chance for them to upsell.  But still, the Let's Encrypt model is better than free because it's free, and it's automated.  So they think, okay.  Let's automate.



And then, continuing Computest's statement, they said:  "However, there is a lot that can go wrong with the automated issuance of SSL certificates.  Before someone is issued a certificate for their domain, say Computest.nl, the CA needs to check that the request is done by someone who is actually in control of the domain.  For Extended Validation certificates, this involves a lot of paperwork and manual checking.  But for simple, so-called Domain Validated (DV) certificates, often an automated check is used by sending an email to the domain or asking the user to upload a file.



"The CA (Certificate Authority) has a lot of freedom in how that check is performed;  but ultimately the requester is provided with a certificate that provides the same secure" - and this is the key, too.  "The requester is provided with a certificate that provides the same security, no matter which CA issued it."  Right?  Because all of the CA's private keys, which are used to verify the signing under - I'm sorry.  All of the CA's public keys are in the devices we use, which are used to verify the signing under the CA's secret private key.  So we treat all certificates identically, regardless of what CA signed it.



So they say:  "In order to make the issuance of certificates easy, this tool runs on your server (Windows or Linux), detects your web server configuration, and requests DV certificates for the domains that were found in your config."  So that's nice.  It looks into your config, sees which domains your server's configured to handle, and just asks for those certificates.  "Then the StartCom API" - meaning at the server end - "does an HTTP request" - and I just hit spacebar and changed the page, sorry - "does an HTTP request to the website at the domain you requested a certificate for."



So the far end, the StartCom server makes a request to check for the presence of a piece of proof that you have access to the website.  So the idea being that remotely it uses that domain to ask for a specific file which then verifies that you were able to put that file on that domain.  Therefore you're controlling the server at that location.  So it checks for the presence of a piece of proof that you have access to that website.  "If the proof is found, the API returns a certificate to the client, which then installs it into your config."  So very much like Let's Encrypt, it just automates the whole process.



"However," they write, "it appears that the StartEncrypt tool" - and I love this - "did not receive proper attention from security-minded people in the design and implementation phases."  Now, understand, it's not like security is an afterthought for a certificate authority.  It's a stretch to call it an afterthought for an AC wall plug.  But security is not an afterthought for a certificate authority.



LEO:  Oh, security schmecurity.  [Crosstalk].



STEVE:  I know.  Get a load of this.  So they write:  "While the client contains numerous vulnerabilities" - we do get to those at the end - "one in particular allows the attacker to trick the validation step."  So the first bug.  "The API," as we noted, "checks if a user is authorized to obtain a certificate for a domain by downloading a signature" - which is like a file - "from that domain, by default from the path '/signfile.'  However, the client," okay, at the user's end, "the client chooses that path during an HTTP POST request to that API," meaning that "a malicious client can specify a path to any file on the server for which a certificate is being requested.  This means that, for example, anyone can obtain a certificate for sites like Dropbox.com and Github.com, where users can upload their own files."  So the point here is, just to clarify...



LEO:  Ohhh.  I get it.



STEVE:  Yeah.  You don't have access to the root of Dropbox.  You have access to some screwy-looking URL with a bunch of gobbledygook in it.



LEO:  But it begins with Dropbox.com.



STEVE:  Exactly.  And so you're able to make a request of the StartCom - in your HTTP POST query to their API, the actual POST contains the path /signfile.  You simply change that to your directory on Dropbox, where you placed that /signfile on Dropbox, and StartCom sends you a completely valid HTTPS certificate for Dropbox.com.  How handy.  Now you can have your own Dropbox.



LEO:  Oh, my god.  That's ridiculous.



STEVE:  I know.  Unbelievable.



LEO:  That's ridiculous.



STEVE:  Then they say:  "That's not all.  While this is serious, most websites don't allow you to upload a file and then have it presented back to you in raw format like GitHub and Dropbox do."  So those are sort of unique in that they are file storage sites, which just make this exploit drop dead, or drop box, simple.  "Another issue in the [StartCom] API, however, allows for much wider exploitation of this issue:  The API follows redirects.  So if the URL specified in [one of these POST parameters called]  'verifyRes' parameter returns a redirect to another URL, the API will follow that until it gets to the proof [that it's looking for], even if the redirect goes off-domain."  Which is just crazy.  "Since the first redirect was to the domain that is being verified, the API considers the proof correct, even if it is redirected to a different website."



Okay.  So again, to review, that would mean that you're asking for something from, literally, and this works, Google.com.  Why does it work?  Because Google is an OAUTH provider.  And OAUTH requires URL redirection following in order for it to bounce the user's web browser around, as we've talked about in the past.  So this StartCom API is so broken that, if it goes to Google.com and receives a redirect somewhere else, it says, oh, I got a redirect from Google.com.  But that verifies the guy has control of Google.com.  Even though Google then sent it somewhere else that the user actually has control over.



So this indirection opens up a much broader range of exploitation because basically people can arrange to have a Google URL redirect wherever they want, and that is then where they put the content that this StartCom API picks up.  And these are called "open redirects."  They're pages that take a parameter that contains a URL and that redirect the user to that URL in the page's parameter.  Now, this mechanism makes people nervous.  But, for example, we often see it in login and logout pages, where you'll logout, and the logout URL will have an argument, like "returnURL=/login," so that after you log out, the web server bounces the browser over to the login page.



And it turns out that the OAUTH, as I mentioned before, requires open redirects.  It's not technically a security vulnerability, unless in this instance it's able to be leveraged into a huge vulnerability as a consequence of the fact that the thing that is following the redirections takes the first domain as the one that's being verified, rather than the last domain, where it actually gets the asset whose ownership it's trying to prove.  So, I mean, it's just like, okay.  This is a certificate authority that everybody trusts.  And they've automated this with gaping holes in their API.



So anyway, they say:  "That's still not all.  Apart from the vulnerabilities described above, we found some other vulnerabilities in the client while just doing a cursory check.  We are only publishing those that according to StartCom have been fixed or are no issue.  These include:  The client doesn't check" - okay.  The client running in the user's machine, right, in the user's server that reaches out and connects to the remote StartCom server.  The client, their own software, "doesn't check the server's certificate for validity when connecting to the API, which of course is pretty ironic for an SSL tool."



And so I added a note here:  Which of course allows for man-in-the-middle attacks against the StartEncrypt client.  Bad guys could arrange to have invalid certificates issued, thus creating a denial of service against targeted sites using StartEncrypt because it's not checking the certificate.  So it just could be any certificate that is set up on a man-in-the-middle intercepting server.  And that interceptor is not going to be a CA, so it just sends garbage back.  And that garbage gets installed into the end-user's server; and, look, HTTPS is broken.  Wow.  And who knows what else, what other kind of havoc could be created.



Second:  "The API doesn't verify the content type of the file it downloads for verification, so attackers can obtain certificates for" - and get this.  "Attackers can obtain certificates for any website where users can upload their own avatars," like a blogging a site.



LEO:  Or a forum.



STEVE:  Where you create an account with a profile, and you upload a picture.  So you would upload that signed file as your picture and then hand that URL to the StartCom API, or the StartEncrypt API, and it would give you a certificate for that site, that social site where you created an account.  Just incredible.



And finally - and you'll get this, Leo, because you've been deep into Linux recently - the private key, right, the final sacrosanct private key, which by the way is over a connection whose security is not verified, the private key on the server - now, that's on the end-user's server.  The private key on the server is saved with file mode 0666.  So it's world-readable.  Which means any local process or user on that machine can read or modify it.  And that's the secret for that server's certificate, the private key, the thing you absolutely never want to let anyone else get.  So:  "All in all, doesn't seem like a lot of attention was paid to security in the design and implementation of this piece of software," they say.  And it's like, you think?  Wow.  Yeah.



LEO:  Nice job.



STEVE:  What Let's Encrypt did is good.  The bad news is wannabe, me-too companies are going to say, oh, we're losing free business to Let's Encrypt.  So we should do it, too.  And here's an example of how badly it can go wrong.  And, boy, again, we just don't have facilities in place for policing this.  Again, I will say thank goodness that researchers are able to look at these things and are able to responsibly bring them to light, and all of us can learn lessons from them because - and hopefully all the other CAs are going, oh, no.  We were going to launch ours next month.  Let's make sure...



LEO:  Yeah, maybe we should just check it.  Maybe, you know.



STEVE:  Maybe we should.



LEO:  Maybe 0777 would be better than 0666.  Let's just go all the way, get people execute it.



STEVE:  That's right.



LEO:  Wow.  You know, it's kind of amazing.  This stuff, you know, the proof files...



STEVE:  Security is hard.



LEO:  I know, but this is a well-known thing about, you know,  proving control of the server is easy.



STEVE:  I know.  This is embarrassing.  This is embarrassing.



LEO:  Yeah.  Yeah.



STEVE:  This is just, I mean, I loved that last sentence:  "All in all," and they wrote this, "it doesn't seem like a lot of attention was paid to security..."



LEO:  It's called understatement.



STEVE:  "...in the design and implementation of this piece of software."  And again, it's not even a plug.  It's a certificate authority, issuing certificates that the world is going to trust.  Oh.



LEO:  Ugh.



STEVE:  And you can get one for Google.



LEO:  Yup.



STEVE:  Wow.



LEO:  Wow.  Well, my friend, we have concluded this fabulous episode of things done wrong, with a few things done right.  You can catch this show, we do it every Tuesday at about 1:30 Pacific, 4:30 Eastern, 20:30 UTC, if you want to watch live at TWiT.tv.  But you don't have to, of course.  We have on-demand audio and video.  Steve does a great job of not only putting the audio up there, but of written transcriptions at GRC.com.  That's his website.



STEVE:  We may be a little bit late with it this week.  Elaine was saying, "Oh, Steve, please do a shorter podcast because my schedule is really jammed up."  And she's so responsible that she's just going to take it out on herself.  So Elaine, are you listening?  Oh, actually, this is the end.  So, oh, but she does a whole proofreading phase.



LEO:  Right.



STEVE:  So Elaine, you're halfway through.  Please, you're hearing us both say take your time.



LEO:  Take your time, yeah.



STEVE:  Yes.



LEO:  No hurry.



STEVE:  I'll post it up when we get a chance because here we are at two hours and two minutes and counting.



LEO:  Not bad.



STEVE:  So it's our standard-length podcast.



LEO:  Yeah.  GRC.com.  You also find, if you want questions, I guess we'll do a question episode next week.  You can of course go to GRC.com/feedback.  That's the feedback form.  Or tweet Steve.  He's @SGgrc.  You can even DM him because he accepts DMs from all comers.



STEVE:  Yeah, don't sent tweets to @stevegibson.  That really annoys him.



LEO:  Is there a guy named @stevegibson?



STEVE:  Oh, yeah.  And he sometimes bounces tweets over to me.  He says, no, it's - and it was like, I would say hey, I'm sorry, but, you know...



LEO:  @SGgrc.  See?  Easy.  It's his initials plus his website's name.  But not .com because that - never mind.  @SGgrc.  And I have the other ones up there.  You probably don't do much with @SGpad and @SGvlc.



STEVE:  No, that was sort of an interesting idea, but it didn't really...



LEO:  I'll erase those.



STEVE:  Didn't gain enough traction.



LEO:  Yeah.  One Twitter handle is enough for any human.



STEVE:  Yeah, yeah.  And by the way, we're closing in on 1.5 million downloads of Never10.



LEO:  Wow.  Well, you've got till July 29th.



STEVE:  Oh, yeah.



LEO:  To go over the billion number.



STEVE:  I think it's, like, 15,000 a day now.  It's slowing down, but still staying strong. 



LEO:  That's great.  That's amazing.



STEVE:  Yeah.  Crazy.



LEO:  You'll find many other things at the website, including SpinRite, of course, Steve's amazing product that does work, the world's best hard drive maintenance and recovery utility.



STEVE:  There's a lot of magic under the hood that people don't appreciate.  But that's why it works.



LEO:  GRC.com again for that.  Now, if you go to TWiT.tv/sn, you'll find audio and video, so you could see Steve's giant hands.



STEVE:  Or head.  



LEO:  Or head.  It's a trick of perspective, my friends.  His hands are just normal.  They just look big.  And I guess that's about it.  I guess that wraps it up for another fabulous week.  Thanks, Steve.  We'll see you next time.



STEVE:  Thanks, Leo.  Great to be with you, as always.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#568

DATE:		July 12, 2016

TITLE:		Listener Feedback #237

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-568.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with a fun and interesting week of security happenings including Facebook Messenger's end-to-end encryption, Russia's President Putin, the fate of Russian-based VPN endpoints, Russian hackers compromising iOS devices, my promised follow-up on that Lenovo SMM hack which suddenly looked a lot more worrisome, the apparent illegality of password sharing, post-quantum crypto testing in Chrome, reconsidering antivirus add-ons, Pokemon Go woes, a possible defense against cryptomalware, news from the "of course someone had to try this" department, miscellany including the return of "Mr. Robot," Leo moves to FreeBSD, a recent pfSense facelift, Apollo assembly language source, even more - and, time permitting, five questions from Twitter.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  Boy, there is a lot of security news.  We have a topless Vladimir Putin.  Yes, we have really a shocking flaw in the BIOS of many computers, including Lenovos and Dells.  We'll talk about that.  And Steve will answer - I think we get to one question, but it's still - it's a great question.  And we'll talk about FreeBSD, so what could possibly go wrong?  It's all ahead.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 568, recorded July 12th, 2016:  Your questions, Steve's answers, #237.



It's time for Security Now!, the show where we cover the latest security information and how to protect yourself and your privacy online with this guy right here, our Explainer in Chief, Steve Gibson from the Gibson Research Corporation.  Hi, Steve.



STEVE GIBSON:  I just have to comment that our listeners are going to hear the difference, and we need to explain...



LEO:  Really, is it that apparent?



STEVE:  It's remarkably more highs that I'm hearing.  And, now, maybe we'll lose those, like in compression.  Although I'm hearing a compressed result coming from Skype.  So I don't know.  But, yeah, we should tell people that you're beginning to move to the new facility, and you've lost your curtains, which were clearly absorbing some of the high frequency.



LEO:  So that my studio office, which we're in right now - and the only shows we do here are the radio shows, Security Now!, Windows Weekly, I think that's it.  And so it doubles as my office, my office office.  And we built it, when we built this studio five years ago, with windows all the way around, so it's a fishbowl, which is fine with me, except that I also like having some privacy.  And because it's a studio we wanted some sound damping.  So we got very thick, heavy, red velvet drapes which go all the way around, and they have been all the way around all this time.  We're starting to take them - we took them down.  And John then, after he took them down, said "Uh-oh."  I said, "What?"  He said, "You know, they really made a difference in terms of sound absorption in there."



STEVE:  The acoustics of that little room, yeah.



LEO:  Because what you don't want in a studio is parallel reflective surfaces.  Nothing's more reflective than glass.



STEVE:  For the sound to bounce back and forth; right.



LEO:  Right.  Now, fortunately this wall's got a bookshelf and hats on it, so it's not - there aren't any facing reflective surfaces.  But it is much live-er, I can tell.  You know what it reminds me of, there's a sound processing device that was all the rage about 30 years ago called the Aphex Aural Exciter.  Linda Ronstadt...



STEVE:  Now, that really could go several different ways.



LEO:  I know, I know.  A-U-R-A-L.



STEVE:  Yeah, okay.



LEO:  But the Aphex was used on a lot of albums.  It was kind of the magic ingredient in some famous albums like some Linda Ronstadt albums and stuff.  I remember it was just really popular.



STEVE:  Was it a compander?  Was that what they called those things, or...



LEO:  Well, they still make them, actually.  I'm looking at it right now.  They call it an "exciter."  



STEVE:  An exciter.  That's right.  The aural exciter.



LEO:  Which has an optical big bottom.



STEVE:  Oh, if it has that many knobs on it, it must be good.



LEO:  It must be good.  It's kind of a secret sauce.  And but what I learned in those days was what it really does is some interesting phasing stuff.  And you know what, I bet you anything that we are getting the effect of the Aphex Aural Exciter...



STEVE:  For free.



LEO:  For free, by eliminating the curtains.  It's exactly that sound, which is a kind of an odd, almost a chorusing of the high end.  And it pops.  And I think that's what we're getting.



STEVE:  Well, we've now explained the audio and awakened all [crosstalk].



LEO:  For free.



STEVE:  That's right.  So this is nominally a Q&A week, although, boy, is there a lot to talk about.  Facebook Messenger gets end-to-end encryption.  We've got to talk about Russia's President Putin; the fate of Russian-based VPN endpoints; Russian hackers compromising iOS devices; my promised follow-up on that Lenovo system management mode hack, which suddenly looked like it was going to be a lot more worrisome, and it is; the apparent illegality of password sharing, although this was kind of weirdly reported in the press; post-quantum crypto testing that started for the Google Chrome browser; reconsidering the value of antivirus add-ons.  We have some Pokemon Go woes; a possible defense against cryptomalware; news from the "of course someone had to try this" department; miscellany, including the return tomorrow night, everyone, of "Mr. Robot"; Leo moving to FreeBSD.



LEO:  Oh.



STEVE:  A recent pfSense facelift.  Of course the Apollo assembly language source was the most...



LEO:  Was that awesome.



STEVE:  ...tweeted to me thing all week.  And even a little bit more.  And, time permitting, we do have some questions from our fabulous listeners.



LEO:  You are an optimist.



STEVE:  So we'll see.  And I love the Picture of the Week, only because Putin figures in the top three mentions.



LEO:  Oh, lord.



STEVE:  And I was looking at him bareback - wait, no.



LEO:  There's a lot of pictures of him topless, I've got to tell you.



STEVE:  Bu that's like a pony, isn't it?  It's not a horse.  If he was riding a horse, he would be like a little pawn.



LEO:  You're actually right.  He looks kind of big on it, doesn't he.



STEVE:  It's kind of a little Shetland or something.



LEO:  Yeah, it might be an Arabian.  They're kind of small.  That is funny.



STEVE:  Probably fancy, whatever it is.  But I don't think - I think he's not as big as he wants to look on that horse.



LEO:  If you google "topless Putin," you'll find many images of him.



STEVE:  No, actually, this was enough.  I don't know how I found this one.  But it's like, okay, I just - of course he made himself famous for taking his shirt - oh, my god, there it is, yes.



LEO:  So I think it has something to do with his desire to be seen as a strong man and a hunky - and it may be something about the Russian culture.  I just - I don't understand it.  But there are endless images of him topless.  



STEVE:  Weird.  Weird.



LEO:  Yeah, I don't quite get it.  And there's the one that...



STEVE:  And I think Chelsea Handler did a spoof on him, too.  Of course, she was topless with a whole different sort of effect.



LEO:  Easy to spoof, that's for sure.



STEVE:  Yeah.  And I guess also our ever-changing North Korean leaders always seem to sort of be a little strange this way.  Like trying to create - like having a marketing arm for themselves to create an impression in the mind of their populace.



LEO:  Yeah, yeah.



STEVE:  So anyway.  I don't know.  But, yeah, lots of Russian news and good stuff to talk about this week.



LEO:  All right.



STEVE:  So, Facebook Messenger.  We talked about WhatsApp not long ago, a few months ago.  And of course we're always talking about WhatsApp because they're getting - they're in trouble in Brazil all the time.  But Facebook has moved the Signal protocol into Messenger.  So they call it "Secret Conversations."  And it's not the default.  It is something you can engage optionally on a per-conversation basis.  Which to me I think that's exactly the right tradeoff because, as we know, the way they've implemented it, they're unable - because it is encrypted from end to end, things like their chatbot, which requires sniffing the conversation as it goes through Facebook's servers, that all gets excluded when you have end-to-end encryption.



So there will be some loss of extra fancy functionality that goes along with turning Secret Conversations on.  They used the now-available open source Signal protocol libraries.  There's one for Java and also one for C.  And they make a point that they have an entirely different backend structure.  They use a different transport protocol, a specialized on-device storage, and separate backend infrastructure.  Next week I'm going to go more in-depth into two other features - one they call "abuse reporting," and the other is this implementation of secure storage - because as I began to look at it, it was like, okay, this is too big for a bullet point.  And it looks interesting.  Looks like there actually is maybe some new technology there that I want to talk about.  And of course Messenger is a major messaging platform for the Internet, given that it's the default in Facebook.



So they have a whitepaper, 11 pages, that is available.  And mostly it is sort of just a reprinting of the Signal protocol.  And of course Signal, as we know, Moxie and his team absolutely did it right at Open Whisper Systems.  As our listeners will remember, when I first started looking at it, I was thinking, whoa, is this thing over-engineered and over-complicated.  Because, I mean, you just have stuff going in every direction at once and ratcheting protocols and key exchanges, and a lot of it seemed like overkill.



But when you look, and as we did when we covered this in detail a few months back, there's a reason for it.  And you get all kinds of extra neat things.  Like, for example, you have a non-real-time messaging protocol.  That's where, for example, OTP falls because that has to be real-time end-to-end.  With Signal they solved the problem of sending a message to somebody who isn't available at that instant in order to have a real-time interchange.  So, and a lot of the extra machinery in the Signal protocol supports that, I would argue, very valuable feature.  It's the kind of thing where somebody, if they turned on Secret Conversations, and it suddenly broke the way they're used to using Messenger, which is asynchronously, then that would seem like wrong to them.  It's like, wait, I want to have a secret conversation, not a broken conversation.



So anyway, bravo to Facebook.  And of course this ups the ante yet again on this whole controversy we're steeped in at the moment, like this whole question of encryption on the Internet.  Which takes us to Putin.  Whether his shirt is on or off, and I'm sure it was on during his press conference last Thursday, he ordered, so five days ago, the Federal Security Service Bureau - the FSB, which as I understand it, that's the renamed KGB; right?  So that's like the Russian security people.  He ordered them to produce encryption keys, is the way it's phrased, capable of decrypting all data on the Internet.  Okay.  But no one's really sure exactly what that means because of course it's impossible.  The FSB can't just suddenly do that.



So this was part of a new plan that the Russian government is implementing effective July 20th.  So this is where they have two weeks to do this.  And it's signed under law under the anti-terrorist bill.  So, for example, some highlights from this are that telecom providers and - this is broadly defined, unfortunately - "organizers of information distribution," so everyone assumes that means websites because websites are organizers of information distribution, get this, must store copies of the content of all information they transmit, including phone calls and text messages, for six months, and store the metadata for three years so that they can give the Kremlin whatever it wants, whenever it wants it.  Now, this is not just - they're not storing it in encrypted form.  It has to be in plaintext form somehow.



And then, secondly, not only do "organizers of information distribution" have to store all transmitted information, they have to turn over, quote, "any information necessary to decrypt those messages."  And so additional coding, as it says in the law, must be added to electronic messages which will function as instructions for the FSB to decode them.  So reading between the lines, this sounds like someone who was a politico, who doesn't understand crypto at all, doesn't want to use the word "backdoor," but absolutely wants the equivalent, is saying that, I mean, this, quote, this "additional coding" is code for a second key or something.



LEO:  It sounds so much like Feinstein-Burr, which said we're not going to tell you to do a backdoor, you just have to be able to give us the information.



STEVE:  Exactly.



LEO:  Whatever that takes.



STEVE:  Exactly.  Exactly.  So in pronouncing Mr. Putin's decision to sign the amendments into law Thursday, his spokesman, Dmitry Peskov, told reporters that the president instructed the government to make adjustments if the measures indeed do pose any, quote, "financial risks," unquote.  There again, it's like, okay, what does that mean?  Dmitri said, quote, "The government will keep a close eye on how this law is implemented.  And if some unpleasant consequences are discovered, the president will ask the government to take steps."  Again, murk added to more murk.  So again, I'm glad I'm in the United States of America; although, as you said, Leo, Feinstein-Burr tried to do the same thing.



LEO:  Not so very different, yeah.



STEVE:  Yeah.



LEO:  I think every government - but the real problem is this means, well, they're going to have to outlaw WhatsApp.  They're going to have to outlaw Facebook.  They're going to have, I mean, because no backdoor is possible.



STEVE:  Yes.  And that's what, when I say this is going to be really interesting, it's the reporting now downstream of this, what's going to happen.  Now, what has already happened, several of our listeners who were users of a VPN service called Privacy Internet Access sent me snapshots of a message that they received on their devices yesterday, saying:  "We Are Removing Our Russian Presence."  And so this letter reads:  "To Our Beloved Users:  The Russian government has passed a new law that mandates that every provider must log all Russian Internet traffic for up to one year.  We believe that, due to the enforcement regime surrounding this new law, some of our Russian servers were recently seized by Russian authorities without notice or any type of due process.  We think it's because we are the most outspoken and only verified no-log VPN provider."



Now, okay.  So we can see that they're spinning this into a little bit of a PR bump for themselves.  But still, they continue:  "Luckily, since we do not log any traffic or session data, period, no data has been compromised.  Our users are, and will always be, private and secure.  Upon learning of the above, we immediately discontinued our Russian gateways and will no longer be doing business in that region.  To make it clear, the privacy and security of our users is our number one priority.  For preventative reasons, we are rotating all of our certificates."



And of course if Russians or some aspect of the Russian government seized their servers, then they obtained what you want to protect most in your server, which is the private key, so that only the public key is exposed.  The private key is explicitly kept secret.  But if Russian authorities come and raid your datacenter and take your servers, you've lost control of your keys.  So they absolutely had to immediately cease all use of keys that could have been compromised.



So they said:  "We're rotating all of our certificates.  Furthermore, we're updating our client applications with improved security measures to mitigate circumstances like this in the future, on top of what is already in place.  In addition, our manual configurations..." and then they go on in this more marketing spiel.  But so the point is here is the first of, as you were saying, Leo, many probable pullouts from the Russian Federation because it may come down to essentially what Brazil has been trying to do with WhatsApp, which is either give us the content of conversations, or we're going to shut you down.  And in this case, if you do encrypted communications that we cannot decrypt, you are breaking Russian law.  And so the consequence is pull out because, I mean, now...



LEO:  That would be the economic consequence, I would think, that they're referring to, is like, if this makes us a Third World nation, maybe we won't do it.



STEVE:  Exactly.  And again, so I'm glad I'm not there.  Oh, and Snowden's not happy.  He grumbled about it's a dark day...



LEO:  It's a dark day for Russia.



STEVE:  Exactly.



LEO:  He forgot that he was living in a totalitarian state, apparently.



STEVE:  They're the only one that would have him.



LEO:  Yeah.



STEVE:  So anyway, fascinating to see what's going to happen.



LEO:  Oh, yeah.



STEVE:  And, I mean, so here we have real, like, immovable forces coming into collision, Putin saying no encryption that FSB cannot decrypt.  So what happens?  Do the services remain, but go decrypted?  I mean, you can't do usernames and passwords, I mean, even if we rolled back 10 years to when most things were HTTP, but at least logging in was secure.  Now, of course, we know that that was never actually even secure because the browser was given a cookie which, if that cookie is not marked as secure, and it can't be marked as secure, if you're then going to fall back and maintain session state over an HTTP non-encrypted connection.  As we know, that allows session hijacking, a la Firesheep, trivially.  So do services drop crypto and remain?  Or do they think, oh, wait, we can't do that because then we're going to confuse people?  Are we encrypted or not?  Where do we get encrypted?  Really, really fascinating to see what happens when a strong man says no, no Internet encryption that we can't get.



LEO:  Russia's not such a big market that these companies couldn't walk away.  Now, if China does it, hmm.  That would be interesting.



STEVE:  Well, and this may - China may be watching, too.  It's like, let's see how this goes.  Like what do companies do?  I think you're right, Leo, I think companies have to pull up stakes.  They have to say, okay, fine.  And what does that turn Russia into on the Internet?  Imagine then all of the valuable services that they have now, that they've gotten accustomed to using, that will go away.  I mean, here we've got one VPN provider saying, okay, see ya.  And it has to be everybody else.  



LEO:  Right.



STEVE:  Yeah, so, wow.



LEO:  Really interesting, yeah.



STEVE:  An interesting next few weeks.



LEO:  Yeah.



STEVE:  There was also some weird things going on with iOS devices, people stating that their iOS devices were becoming locked in so-called "lost mode," and with a Russian extortion demand appearing on the screen.  And those who have dug into it believe that what's going on is that this may be another downstream consequence of these recent mega breaches that we've talked about, the LinkedIn, for example, breach that caught Mark Zuckerberg when he wasn't paying attention to his Twitter account, where through password reuse, and then probably some phishing attacks in order to get people's Apple IDs, if you have the Apple ID and matching password, then you can put a device into lost mode, where it essentially locks it up, displays a message on the screen.



Now, typically, this is you left your phone at the airport, so you want to tell whomever finds it, "Hi there, this is my phone, you can't use it because I've locked it now, but here's how to find me, and I'd like to get it back," and so forth.  And I've never messed with this myself.  But as I understand it, it can make a sound.  You can tell it you want the sound to make noises...



LEO:  Right, right.



STEVE:  ...so that it gets seen or found, and display a message.  So these people, these scammers are asking anywhere between 30 and $50.  And so some people are paying.  And apparently Google has been finding people typing this weird Russian extortion in and asking for translations because it's like, okay, my phone is speaking Russian, and I don't know what it says.  And I guess it's a problem if it's just gibberish.  And then of course other people are just doing a factory reset because as long as you have a backup, or as recent as your backup is, a factory reset and a restore from the most recent backup will recover from lost mode.  But there isn't anything else that anyone can do.  You can't unloose it, as I understand it.  That is, if a third party has maliciously put it into lost mode, all you can do is do a full factory reset and restore.



LEO:  It's kind of weird because - hmm.



STEVE:  Yeah.  And it's not massive.  It's not widespread.



LEO:  Yeah.  I wonder how they're doing that?



STEVE:  It's people, yeah, and again, they have to have both the userID and password.  So that's where the presumption has come...



LEO:  Yeah, so they match you somehow; right?



STEVE:  Right.  Or phished you.  It may have been...



LEO:  Phished you; right.



STEVE:  ...like a fake message from Apple.  It's like, oh, it's time for you to reassert your identity.  Please enter your Apple ID and password.  And a lot of people will.



LEO:  I was, for a while - Henry had lost his phone, so it was very credible to me.  For a while I was getting text messages saying this is Apple, and we've found your lost phone.  Click this link, which of course is a phishing link, to your account and claim it.  We have it, or we know where it is, but you have to log in obviously to prove that you're you.  And it was very credible because the timing was right when Henry lost his phone.  That was just, I think, coincidental.



STEVE:  Yes.  Well, and remember, I think we talked about it on this podcast years ago, there was that weird scam where a friend who was traveling abroad would apparently send email saying that they got in trouble, and they need help.



LEO:  Yeah, that was a Yahoo! Mail hack, yeah.



STEVE:  Right.  And it was so believable that a lot of money got transferred.



LEO:  So, so silly.  Just I hope people are getting just, like, really skeptical now.



STEVE:  Well, and we'll be talking about this and Pokemon Go here in a minute because that's caused...



LEO:  I'm not going to stop playing this game.  I don't care what you say.



STEVE:  Okay.  Just be careful about the cameras that you buy on sale from China during Amazon Prime Day because, you know, wow.



LEO:  That's another thing, yeah.



STEVE:  Yeah.  So Lenovo.  This is not good.  So what exists in many ThinkPads, some Yo- is that Yoda or Yoga?



LEO:  Yoga.



STEVE:  Yoga, yeah, thought so.



LEO:  I would buy a Yoda laptop.



STEVE:  Also some other devices.  And I put a link in the show notes because there's an extensive list of, I mean, it just scrolls and scrolls, with every single model.  And, for example, even my brand new Carbon fourth-generation X1, vulnerable.



LEO:  Oh, no.  And it's a BIOS vulnerability.



STEVE:  Well, it's worse, actually.



LEO:  They say system management mode; right?



STEVE:  Right.  So it's an SMM, system management mode vulnerability.  So here's what it means.  From a malicious app running locally, so it's only local, but the app has to have admin privilege.  So if something is running on that machine and obtains or is given admin privilege, this bug allows the right protection to be removed from the firmware, safe boot mode to be bypassed, and the firmware to be altered to install a permanent malicious preboot rootkit.  So, okay.  So I got a kick out of Lenovo.  Lenovo's disclosure is a little bit butt-covering, but okay, because they're not happy about how this came down.



They said in their support article:  "Execution of code in SMM by an attacker with local administrative access."  They say:  "Lenovo's Product Security Incident Response Team is fully aware of the uncoordinated disclosure," is the way they put it, "by an independent researcher of a BIOS vulnerability located in the System Management Mode code that impacts certain Lenovo PC devices.  Shortly after the researcher stated over social media that he would disclose a BIOS-level vulnerability in Lenovo products, Lenovo PSIRT," which is their Product Security Incident Response Team, "made several unsuccessful attempts to collaborate with the researcher in advance of his publication of this information.



So we can all read between the lines.  "Since that time, Lenovo has actively undertaken its own investigation, which remains ongoing.  At this point, Lenovo knows that vulnerable SMM code was provided to Lenovo by at least one of our independent BIOS vendors."  So we have a new acronym, the IBV, the Independent BIOS Vendor.  "Independent BIOS Vendors (IBVs) are software development firms that specialize in developing the customized BIOS firmware that is loaded into the PCs of original equipment manufacturers, including Lenovo."  But not only.  We'll get to that in a second.



"Following industry standard practice, IBVs start with the common code base created by chip vendors such as Intel or AMD" - and in this case Intel, it's the Series 8 reference code - "and add additional layers of code that are specifically designed to work with a particular computer.  Lenovo currently works with the industry's three largest IBVs.



"The package of code with the SMM vulnerability was developed on top of a common code base provided to the IBV by Intel.  Importantly, because Lenovo did not develop the vulnerable SMM code and is still in the process of determining the identity of the original author, it does not know its originally intended purpose."  It's like, what?  Okay.  "But as part of the ongoing investigation, Lenovo is engaging all of its IBVs, as well as Intel, to identify or rule out any additional instances of the vulnerability's presence in the BIOS provided to Lenovo by other IBVs, as well as the original purpose of the vulnerable code."  So again...



LEO:  How many IBVs are there?  I mean, there's Phoenix.



STEVE:  Yeah, those are the guys.  And so they talked about...



LEO:  I don't think there's that many.  There are three, right.



STEVE:  So, yeah, and remember - and Award.  But there's also been some acquisitions.



LEO:  Award, AMI.



STEVE:  Yeah.  So there has been some coalescing in that industry.  But it's like probably the three are the three.  And there may be some small guys, for example, that specialize in BIOS code for specific, like low-volume subassembly stuff that not everyone's putting in all these.



Okay.  So the guy's posting is beautiful reverse-engineering.  I mean, it's - and unfortunately, as Lenovo grumbles, this was not done in the modern model of responsible disclosure.  This guy wanted the glory of just putting it out there.  And unfortunately, until firmware updates are available, a huge number of laptops are vulnerable to this.  He's got proof of concept exploit code, instructions for compiling it, including Visual Studio project files to make the whole thing just script kiddie compatible.



So there's a little bit of chronology in his posting.  On July 2nd he wrote, he added, that one of his followers confirmed that vulnerable code is present in his HP Pavilion laptop.  Alex James found vulnerable code on motherboards from Gigabyte.  And we've got one, two, three, four different model numbers listed, and they're Z68, Z77, Z87, and Z97 family motherboards.  That was on the 5th.  On the 6th, a Japanese researcher found vulnerable code in Fujitsu Lifebooks, and other Fujitsu computers probably affected.  We don't know that for sure, but certainly that one particular Lifebook model.  And Dell Latitude, the E6430, is also vulnerable.



So what's happened here is that, unfortunately, it looks like this - it's not clear that it came from Intel or that it was added by the IBV.  But what happened is there's sort of relatively universal BIOS firmware, which either Intel or the IBVs are supplying, which across the industry contain this vulnerability, which essentially was released as a zero day.  I mean, just bang, here it is, have fun.



LEO:  How do you get, I mean, how do you make it happen, though?  I mean, you have to have physical access?



STEVE:  Yes.  So it's a local vulnerability.



LEO:  Right, so it's not so bad.



STEVE:  Something malicious.  Yes, correct.  Something running locally on your laptop with admin privileges can then essentially install itself.  So you have to have malware first.  It has to be malicious.  And it's able to install itself into the BIOS in a way that you would never be able to remove it.



LEO:  So any virus could do this.



STEVE:  Yes.



LEO:  As long as it can get administrative access.



STEVE:  Right.  And of course there's lots of ways to get that these days.  That doesn't seem to slow things down very much.



LEO:  Well, that's pretty nasty.



STEVE:  So it turns out, looking at mitigations, they had a mitigation section.  And I was all, oh, great, something I can tell our listeners [buzzer sound].  It's like, don't run with admin, and don't turn your laptop on.  And it's like, okay, well.  So the good news is the industry is scrambling to figure this out.  I mean, that's the only good side of there being a high window of criticality is that it's got everybody's high-power attention to immediately patch this, rather than the stories we've heard of people waiting nine months for a response from the vendor and then finally saying, okay, fine.  So just be careful, everybody.  I mean, it's...



LEO:  Let's be careful out there, yeah.



STEVE:  The good news is they know what the vulnerability is.  The flipside of the full disclosure is it provides full documentation for fixing it also.  So there's no excuse for this taking long.  And unfortunately, what, we've got HP, we've got Fujitsu, we've got Dell, I mean, it looks like it's across the industry.  So think in terms of a firmware update coming to your machine soon.



LEO:  The problem is that they don't come to your machine.  You have to seek them out.



STEVE:  Yes, yes, yes.  And the other problem is, for example, if you're a Lenovo user, and you're smart, you turned off all of that horrible crapware that they add to do things like go check to see if there's new firmware because that's worse than the firmware problem.



LEO:  Right.



STEVE:  So anyway, that's why last week I said, okay, this thing exploded, so I need to understand what it is.  That's what it is.  It's worth checking.  And, now, I've only been talking about ThinkPads, but it's Lenovo computers.  And I don't know, the HP, well, there's a laptop.  Maybe it's only laptop chipsets.  But don't take my word for it.  These all look like Lifebooks and the 6430.



LEO:  They make servers, too.



STEVE:  Yeah.  And Lenovo does have on that page that is linked here a complete list.  A lot of it is some they know are not vulnerable.  And it's funny, too, because for the first several pages of this, as I was scrolling down, it was either "not vulnerable" or "we're still checking."  And I'm thinking, is that what you're going to say for all of the problems, "still checking"?  But I got way down...



LEO:  They say "researching."



STEVE:  That's what it was, right, researching.



LEO:  Researching.



STEVE:  It's like, okay.  But way down, when I got into the ThinkPad section, which is down deeper, most of the ThinkPads are vulnerable.  And all the ones I have are.  I mean, even the old X430 and the 220, the brand new X1 Carbon.  So it's like, yeah, it'll be nice to flash some firmware.  Haven't had [crosstalk].



LEO:  Terrible.  This is really bad.



STEVE:  Yeah, it's not good.  Yeah, well, because, I mean, it's the worst nightmare.  It potentially installs a hidden rootkit backdoor-y thing.



LEO:  That you'll never know.  You'll never know.



STEVE:  You can't...



LEO:  And you can't eradicate it.



STEVE:  Right, you can't format away, yup.



LEO:  Oh, my god.  That's as bad - I guess this is as bad as you can get.



STEVE:  Yeah.  It would be a little - the only thing worse would be if it were in the thing that's now monitoring our network interface adapters all the time, and you could do it remotely.  Then there'd just be, okay, Code Red, Nimda, MS Blast, game over.



LEO:  Right.  The mitigation is disconnect. 



STEVE:  The mitigation is, yeah, maybe, you know, keep checking for firmware update news from your various vendors.



So the press had a field day with this.  And it's like, okay, it's a little overheated.  Although we did hear some sanity from our friend Judge Reinhardt with the Ninth Circuit Court of Appeals.  We've talked about him in the past in a favorable light, as I recall.  So this is a 2012 trial where the plaintiff was found guilty.  And of course, again, in sort of clickbait mode, what we were seeing in the headlines was "Share your password, go to jail."  And it's like, what?



So, okay.  So here's the whole story:  "A recent federal court ruling from the Ninth Circuit Court of Appeals" - which is ours out here on the West Coast - "could make sharing your passwords for subscription services" - now, this is sort of the extension, and this is what Reinhardt was concerned about.  But sort of the lead-in to this says that "sharing your passwords for subscription services, covering everything from Netflix to HBO Go, a federal crime punishable by prison time, wrote a judge who opposed the decision."  And I quote him in a second.



"The ruling, pertained to a trade-secrets case, found that certain instances of sharing passwords are prosecutable under the Computer Fraud and Abuse Act (CFAA), predominantly concerned with hacking.  The case involved David Nosal, a headhunter who left his former company, Korn/Ferry, and later used the password [provided to him by a still-employed assistant] to access the company's database and use that information [for competitive purposes] at his new competing firm.  According to Fusion, the defendant was convicted of hacking charges in 2013" - the case began in 2012 - "and sentenced to one year and a day in prison.  The appeals court" - and so this is the news is that, just recently, the appeals court upheld the conviction 21.  So it wasn't unanimous.



"One of the two judges upholding the lower court decision, Margaret McKeown, wrote:  'This access' - so she's the one who was for upholding the guilty verdict - says:  'This access falls squarely within the CFAA's [Computer Fraud & Abuse Act] prohibition on access "without authorization," and thus we affirm the conviction for violations under the CFAA.'



"However, in his minority dissenting opinion, Judge Stephen Reinhardt argued that the case was not about hacking, but password sharing.  Consequently, he argued, the ruling jeopardizes password sharing for the general public.  He wrote: '[The ruling] loses sight of the anti-hacking purpose of the CFAA and, despite our warning, threatens to criminalize all sorts of innocuous conduct engaged in daily by ordinary citizens.  The majority [that is making this decision] does not provide, nor do I see,' writes Reinhardt, 'a workable line which separates the consensual password sharing in this case from the consensual password sharing of millions of legitimate account holders, which may also be contrary to the policies of system owners.  There simply is no limiting principle in the majority's world of lawful and unlawful password sharing.'"  So the concern, if Reinhardt is right, it could place users of popular streaming sites like HBO Go and Netflix who share their passwords in breach of the CFAA and open to federal prosecution.



So, now, I think it's clear that there was badness done in this case where the appellate court said, nah, this is really wrong.  An assistant still employed gave someone she knew was no longer employed the password to - which may well have been changed since this guy left, I mean, it had to have been, otherwise he could have used it, in order to remotely gain entry to their privileged, confidential data and database.  That seems clearly hacking.



Now, but also there seems to be plenty of guilt here to be spread around because I would argue that her employer certainly has grounds for being upset with her as well, I mean, if she still has a job there.  I don't know any of that background.  But anyway, so what the press has done, and you'll see this in the headlines, is oh, my god, now sharing your password...



LEO:  That's quite a jump.  I mean...



STEVE:  Yes, exactly.



LEO:  "Could" is the operative; you know?



STEVE:  Right.  But Reinhardt's position is, well, this provides post-appellate case law to affirm this concept of sharing a password is a crime under the CFAA.  And as you said, there's no way to draw a line.  There's no clear delineation that the law would like to somehow make between somebody sharing their Netflix password, I mean, that's against the law.  The license agreement says you can't.



LEO:  Yeah, but I don't think that that - judges have quite a bit of leeway.  They don't have to do - just because it could be applied in that case doesn't mean they have to do that.  There's a lot of stuff that is technically illegal, but that a court would say, well, come on, that's de minimis.



STEVE:  Well, and the whole question, too, is what will the punishment be?  Because it could just be a slap on the hand, or we're going to make you watch reruns of something horrible for the rest of your life.



So an interesting piece of news.  A lot of our listeners sent it to me because they thought this would be interesting to talk about on the podcast, and that is that, in some Chrome browsers, and because it's experimental, and it's not widely distributed yet, there's something called Chrome Canary.



LEO:  Canary's their beta.  Or actually the gamma.  So there's - or alpha, I guess it would be.  So what's even more cutting-edge than beta?  Alpha; right?



STEVE:  Right.



LEO:  It's the alpha.  Because there's Canary Developer, and then there's - I mean, Chrome Developer and then Chrome Canary.  But you can install it.  I mean, it's on the - yeah.



STEVE:  Yeah.  And users who do can dig down into some configuration dialogue somewhere and see whether this is present in their Canary build and turn it on or off.  Google is experimenting with what they're calling "post-quantum crypto."  And certainly a topic that never really leaves my Twitter feed is, oh, my god, quantum computers are coming.  Crypto is going to all just melt down.  And I actually, in the paper that is written, or maybe it was on the website, this has a website, cecpq1.com.  I'm not sure what this first "C" is for.  But the "EC" is elliptic curve.  And then the "PQ1" is post-quantum.



So what they've done is they've merged elliptic curve, and actually they're using my favorite Bernstein 25519 curve, which was the genesis of SQRL, it's because of the properties of this amazing elliptic curve that that's what made SQRL possible and when it suddenly clicked in my brain.  They're connecting that with something called "New Hope Key Agreement," which always makes me think of a Star Wars episode for some reason.  So that's this thing.



Anyway, on the site they talk about, they refer to this as "quantum nervousness," which is the general sort of background nervousness over, okay, yes, classic computing architectures are growing at a rate that we've been tracking for two decades now, and we have a sense for it.  And so we know that SHA-128 is kind of okay.  MD5 not.  SHA-256, that gives us lots of security margin.  And we're ready to go bigger as we need to, sort of scaling the existing crypto technology with processing power.



But then, of course, we've got coming out of left field is the specter of a computer that works in an entirely different way, the so-called "quantum computing," which, if everything works the way they say it would in such a computer, it completely short-circuits the fundamental nature of one type of crypto.  And this is worth pointing out.  It's only the public key crypto that is in danger.  Quantum cryptography does not endanger private key, that is, secret key, or symmetric key crypto.



So like the AES-256, the quantum computing has nothing to say about that.  And again, that's also easily scalable.  But no one expects that to collapse.  It's the so-called one-way functions which inherently exist in the public key crypto, which is a concern.  That is, we know, for example, we've talked about it through the years, it's very easy to raise an integer to an integer power in a modulus field, that is, a so-called "finite field."  That's trivial.  But we know of no way to, in a reasonable time, reverse that operation.  That is, to get a discrete logarithm of that, the reverse of exponentiation.  Similarly, we can multiply two really big primes trivially; but given that product, we have still discovered, despite lots of work, no good way to examine what we know is a product of two primes and discern what those two primes are.



So again, multiply easy, factoring hard.  Exponentiation easy, discrete logarithm hard.  And so it's that, it's the asymmetric crypto, these one-way functions.  That's where the nervousness comes from, the idea that, if you had a sufficiently capable quantum computer that as far as we know doesn't even begin to exist with the level of complexity that it needs because quantum computers, the size of problem they can handle is a function of their complexity.  And what's spooky about them is that they sort of - they change this whole concept from brute-force to checking all possible solutions at once, as unnerving as that sounds.



Anyway, so being on the leading edge, there already is a proposed spec for a key agreement protocol; that is, again, once we have the symmetric key, we're not worried about any kind of computing, quantum or not.  It's the problem that a huge leap forward in computing technology might kill asymmetric crypto.  And so it turns out there is a different way of operating, a different kind of one-way function involving lattices.  And I've not looked into it at all.  But they've named it the New Hope.  It probably actually is after Star Wars.



But so what this does is this concatenates two different technologies.  And a paper exists.  Code exists.  And it's actually running in Canary browsers.  And again, no one needs it.  But this is Google.  This is one of the advantages Google has, having a widely distributed browser of their own.  They can experiment with things, for example, as they have in the past, like the HTTP 2.0 spec, where they're experimenting with compression and header compression and tweakings of the protocols.  They're able to bring it up on their servers, and then to optionally move it out into the browsers, and then instrument this and see how it performs in the real world.



One of the problems with this technology until very recently was performance because it was agonizingly slower than what we have today.  And this technology, this New Hope key agreement approach says maybe about 1.6 times slower.  So in a world where you actually do have quantum computing, fine, I'll take it, because we really do need the technology of public key agreement to remain standing.  And so the good news is Google's playing with it.  And I imagine that, by the time we need it, we'll have it.



There was an interesting article, and it was the fact that it was in Yahoo! News that sort of came to my attention because it's just - that's sort of a more pop lay news outlet, and this article in Yahoo! News was supporting the idea that antivirus software is becoming increasingly useless and may make your computer less safe.  Now, it was a series of interviews of security people following from the rather catastrophic Symantec kernel flaw that we talked about last week where virtually the entire Symantec product line was found to have a bad vulnerability because it was filtering Internet traffic in the kernel.  It was remotely exploitable by something that - just by sending a message.  No user had to take any action because the act of this flowing through the connection could allow a system compromise.



So, and this sort of - that's an instance of what we've also, sort of the broader topic of the general attack surface problem, which is the more stuff you add - and of course Lenovo is infamous for this.  The more stuff you add, the more opportunities there are for something to break because, as we know, security is hard.  So anyway, that was just sort of the gist of this story.  There were, among the quotes there from various security experts that the author of the story quoted, someone said, yeah, antivirus software used to be 80 to 90% effective, but now it was really about 10% effective, mostly because the nature - and Leo, I've heard you talking about this a lot on The Tech Guy show.  The nature of the problem has changed.  We have polymorphic viruses.  The viruses are not static.  They're staying ahead of the virus signature updates.



But also, and you guys were talking about this on MacBreak Weekly, I think Rene was talking about the fact that the human factor has now become the weakest link in the chain, the so-called phishing problem.  Just get somebody to click on this link somewhere within Sony, and you can establish a foothold and hide yourself and then go from there.  And I did hear somebody, one of our listeners saying that he'd spent some time at his father's recently and removed whatever AV they had and just installed the Microsoft package.  It's like, okay, fine, Pops, this is all you need.



LEO:  Yeah.



STEVE:  Pokemon Go.



LEO:  By the way, they fixed this issue in iOS, anyway.



STEVE:  So, and I added "home" to the end, Pokemon Go Home.



LEO:  Oh, come on.  You're just a cranky person.



STEVE:  I am.



LEO:  You never leave your house.  It wouldn't be any use.  Actually, you go to the Starbucks.



STEVE:  Well, actually, yesterday at lunch was the first time I saw this in action.  And I guess it was...



LEO:  I guess there were a few people doing it; right?



STEVE:  Oh.  Well, so the place I eat is out on a nice patio with sort of a center court.  And there's a Verizon cellular right next door, which is really handy because they've got really good WiFi and no password, so I'm able to use the WiFi on there.  Times out after two hours, but normally I'm not there and needing to refresh.  Anyway, so I'm watching this Verizon guy in his Verizon shirt with his Verizon logo, and he's holding his phone up high.  And that seems to be somehow the sign of Pokemon.



LEO:  Yeah, and swiping up with it, yeah.



STEVE:  And so it's like up in front of his face, and he's completely transfixed and walks right into a tree.



LEO:  Oh, no.  Oh.  Oh.



STEVE:  And so I thought, uh-huh, yeah.  And then I was talking to my server, who takes care of me every early afternoon, or late - yeah, early afternoon, or late morning.  And I was telling her about what was going on.  And she came out, like an hour later, and she says, "Okay, I hate this whatever this is, this Pokemon thing."  She says, "Everyone in the restaurant is doing it."  And in fact I saw one - there was a party of eight that they were, like, shuffling along very slowly.  Every single one of them had their phone up, and they were like completely transfixed by this and like sort of - so they weren't moving at a regular pace.  And then when they got to the front door, nobody wanted to be the one who, like, arranged the table and everything because some creature might run by.



LEO:  We're busy, yes, we're busy.



STEVE:  I don't know what was going on.  Oh, my lord.  But there was in the news a concern which was that - and I guess this is what you're saying they fixed.  And is that the Google App Permissions?



LEO:  Yes, that's right.



STEVE:  Got fixed?  Good.



LEO:  They say they did that by - it was an error, and they fixed it as soon as they found out about it.



STEVE:  So for our listeners who don't know, the early installs, Pokemon - was it only Android?  Or Android and iOS?



LEO:  Android and iOS.



STEVE:  Would ask for full permissions at Google.  So that is this week's bit.ly link.  That is to say, the Google security permissions page.  So you can get to it with bit.ly/sn-568.  And so the point is, we've talked about this from time to time.  These sorts of things, whether it's Twitter permissions or Facebook app permissions or Google, it's nice to just sort of audit them.  And really nothing brings that to mind unless something brings it to mind.



So now, just think about it.  I looked at mine, and sure enough, there were a number of apps that I no longer use.  Yet they're still - they still had permissions.  And interestingly, only Chrome had full permissions into Google.  Every other one of maybe, like, 10 had much more modest permissions.  So that sort of demonstrates that the original Pokemon probably didn't need full permissions.  It was just, as they said, oops, sorry, we didn't mean to be so aggressive.  But again, bit.ly/sn-568.  Just check in.  Again, this is attack surface minimization.  Remove the things you no longer need.  There's no reason to have them sitting around.  They just represent an opportunity for exploitation.



LEO:  And while you're doing it, I mean, really what these are is the Google Connect, Facebook does it, too, and Twitter does it.  And you'll see these all over the web, where it's a quick login.  It says you can create an account, or you can log in with your Google account or your Facebook account or Twitter account.  And all three of those networks will have a page where you can go and see where you've done that, which apps you've connected.  And it's an absolute must kind of quarterly thing to go through those and delete the old apps because they still have permissions until you revoke them.



STEVE:  Right.



LEO:  And in this case, yeah, they say it was an error.  It's typical for your browser to ask for that kind of access because that way they can access Gmail without asking for additional logins, things like that.



STEVE:  Right.



LEO:  I look at mine, and it's all either a browser or an operating system that has that kind of permissions.



STEVE:  Well, and if you're not trusting Google's Chrome browser to have access to Google, then just go use Firefox.



LEO:  Right, right.  So the Pokemon Go used that quick login.  You didn't have to use it.  They also allowed you to create an account at the Pokemon Trainer site.  But it did give you that.  And normally what you'll do is you'll get a list of the requested permissions, and you can say "allow" or "deny."  In this case it didn't give you that list.  It just gave the Pokemon Go full access to everything.  So if you update your Pokemon Go, and I guess what you'll need to do is remove access, it'll ask you to log in again.  And then it will ask for those more limited permissions.  It's pretty typical for games to - for instance, here's a game that says, "I just want access to Google Play to verify your account."



STEVE:  Right.



LEO:  That's much more typical.



STEVE:  Right.  And much more well behaved.



LEO:  Yeah.  I mean, I don't think Pokemon Go is going to send email on my behalf; but it's just, you know, good...



STEVE:  So a listener of ours who left himself anonymous, and the subject line caught my eye, his subject was "Pokemon Go app spreads DroidJack malware."  So he wrote to me:  "A bunch of news sites can be found talking about the subject simply by googling.  I believe I have been a victim.  After realizing that I was infected, I factory reset my phone.  However, it seems that DroidJack remains in place after a factory reset," he says, "with an asterisk next to the item.  Why?"  And he said:  "This is poor judgment on my part, installing an app from a third party.  I should have known better.  I hope this will help anyone who listens to Security Now! in the future."



So a couple points.  DroidJack is a malicious RAT.  We've talked about RATs before, Remote Access Trojan.  Well known, and it's been talked about, you know, Symantec and Kaspersky and others have described it.  This infected version of Pokemon Go was uploaded to a malicious file repository - that is, a file repository.  I don't know if the whole thing was malicious, but it was malicious - at 09:19 UTC on July 7th.  So shortly after Pokemon was released, less than 72 hours after the game was officially released in New Zealand and Australia.  So probably because the game had not yet been officially released globally, many people wishing to access the game before it was released in their region resorted to downloading the APK, the app file, from third parties.



And get this, Leo.  Many large media outlets provided instructions on how to download the game from third-party sites.  Some even went further, providing instructions and encouragement for installing the APK download from a third party.  Quoting one of them:  "To install an APK directly, you'll first have to tell your Android device to accept side-loaded apps.  This can usually be done by visiting Settings, clicking into the Security area, and then enabling the 'unknown sources' checkbox."



And the idea of that being said on some random news program somewhere, you know, oh, if Pokemon's not available in your area, here's how you can get it from a third-party site.  It's like, no, no, no, no, no.  I mean, we were just the other day talking about making sure.  I said that I had had to do that briefly to grab a copy of the Zeo app, or the Zeo Companion, before it was up on Google Play.  But I knew who made it and who compiled it and understood the risks, and turned that back off.  And didn't you say, Leo, that there's something about it snapping back off?  Or am I confusing two different things?



LEO:  Yeah, it does.  But that's if you go somewhere, and you download an APK, and then you try to install it.  It will say, oh, you have the setting disabled.  Would you like to enable it for this one time only?



STEVE:  Perfect.



LEO:  You can go into Settings, check that box, allow third-party downloads, side loads, and basically that's the same thing as jailbreaking on an iPhone.  And it carries similar risks, which is instead of downloading it from the Google Store, you're downloading from a non-Google store.  And so there's some risk.  Although there's lots of legitimate reasons for doing this.  You've got one.  So you just use extreme caution, that's all.



STEVE:  Yeah.  And I would also argue that, for the more sophisticated user who chafes at Apple's iOS curation model...



LEO:  Right, it's an option.



STEVE:  ...this lets, you know, it's like, hey, I want to own my phone, and I want to put any software in it that I want to.  So I think this is...



LEO:  It's one of the reasons I like Android is because I can do this.



STEVE:  Yes, yes.



LEO:  But with great power comes great responsibility.



STEVE:  Yeah.  And thus my problem is that news organizations are irresponsibly telling people, go get this now, rather than waiting for the official release.  And this on the back of stories that there have been infected instances of Pokemon Go.  So, yikes.



I'm going to do deeper coverage of this also next week - I've already got it in next week's show notes - because I want to understand what they've done.  The first reporting that I saw provided no details.  When I dug into it this morning, I found the whitepaper.  And it's like, oh, now I have too many details.  So researchers from the University of Florida and Villanova University claim to have found an "obvious" solution to the encrypting malware problem, which they're dubbing "CryptoDrop."  They said, quoting from their paper:  "Our system is more of an early warning system.  It doesn't prevent the ransomware from starting.  It prevents the ransomware from completing its task, so you lose only a couple of pictures or a couple of documents, rather than everything that's on your hard drive; and it relieves you of the burden of having to pay the ransom."



So that's why I need to look at this closer because it's like, eh, this sounds a little soft and a little heuristic and a little, okay, how many files does is take before it notices?  Is it planting canaries through the file system that it's monitoring for change?  What's it doing?  And it's certainly interesting.  They gave a paper, a presentation last month at a security conference, so it seems to have some cred to it.  Again, it's in the show notes for next week.  I will have a full report.  Oh, and there is something available for Windows that grew out of this, I also saw.  So again, I'll know more next week.  I'll have read the whitepaper.



And yes, Leo, the BBC described it as sounding like the Daleks, of course because they're the BBC.



LEO:  Ah, you're talking - I know exactly what you're talking about.  We talked about it...



STEVE:  The Dr. Who robots, yes.



LEO:  Yeah.



STEVE:  But it turns out actually it was researchers from UC Berkeley and Georgetown.  They'd never expected this to be actually used.  They were just curious whether it was possible.  And that was what I was - at the top of the show, I said, "from the of course someone had to try this department."  So they asked the question, could we design some audio which we could sneak by people because it would just sound like something, but not what it is, which is audio commands a la the various voice command systems that we now have in the industry, which could, for example, convey an 'Okay, Google, call 911' sort of command.  And I was put in mind of the famous work on the MP3 compression, which as we know, the secret of that MP3 audio compression is, and it actually works in a similar way to JPEG, motion JPEG compression, is that you can...



[Indiscernible robot speak]



LEO:  It's working.  So if you didn't know what you were listening - they point out that you know what you're listening for, so you understand what it is.



STEVE:  Yes.



[Indiscernible robot speak]



LEO:  But if you just heard that kind of coming out of something like a toy...



STEVE:  Yeah, you would think something was broken, or can you hear me now, and I can walk somewhere.



LEO:  Right, right.  But it works.



STEVE:  Yeah.  So what these guys did - yeah, and they made it work.  And so our listeners can have a sense for what it sounds like.



LEO:  And it worked.  What it was saying was "Open xkcd," which is harmless, obviously.  And it did, it opened it.  If you add background noise, even less distinctive.  You're in a caf.  And then the second command:  "Turn on airplane mode."  Turn on airplane mode.  But you really, if you didn't know that that was what was going on, you probably wouldn't detect it.



STEVE:  You're right, you're right.  And so bottom line is they wanted to see whether they could do audio that was obfuscated, essentially, to people, but which the nature of the speech recognition algorithms that are in use would hear through.  And the reason this is cool, to me, is that understanding someone saying commands in a noisy caf, we humans take for granted our ability to, to an amazing degree, find the signal in the noise.  But that is incredibly difficult for software technology.  Again, we just - our brains are phenomenally complicated.



So, yeah, our brains can do it.  So in order to make speech recognition work in a practical way, it had to first ignore noise.  It had to do what we take - it had to be able to do what we take for granted, which is separate the speech from the background.  And so these guys realized that, or maybe were involved in solving that problem, and they said, okay, what if we add noise to the command?



And so for the phone, that's what it's hearing all the time.  It's hearing something that awful and managing to - because we take it for granted, but that's what the phone's hearing.  And we take it for granted.  And so when something does that, the phone, it's like, oh, yeah, I've had to be trained up, says the phone, in the ability to separate the voice from that background.  These guys put background in on purpose, added noise to it.  And the phone does its job, what it was designed to do.  Something it had to be able to do.



LEO:  Moving on.



STEVE:  So miscellany time.  I got a bunch of stuff to cover quickly.  I just wanted to make sure everyone knows that "Mr. Robot," the Golden Globe winner for Best Drama after its first season last year, returns tomorrow, July 13th.  And remember that there is the "Hacking Robot" post-show, which will premiere immediately afterwards on USA Network.



LEO:  Is that good?  Is that worth watching?



STEVE:  I don't know.  It's hosted by Andy Greenwald.



LEO:  Oh, yeah, he's good.



STEVE:  Yeah.  I know that the - I think they were doing the same thing with "Breaking Bad" because it had such a...



LEO:  Right.  Oh, a lot of shows do it.  "The Walking Dead" has "The Talking Dead."



STEVE:  Oh, my lord.



LEO:  It's just, yeah, it's kind of the - well, you know what was happening is blogs and magazines were stealing all of this.  So they said, wait a minute, we've got to put this on the show, on the network right after the show.  We don't want to lose these viewers who want to talk obsessively.



STEVE:  Well, and "Game of Thrones" has it, too; right?



LEO:  Right, yup.  They all do.



STEVE:  "After the Throne" or "Behind the Throne."



LEO:  Yeah, exactly.



STEVE:  "Under the Throne."



LEO:  And you know, they're not that, I mean, they're not great.  But, you know, there you go.



STEVE:  So if you can't wait till tomorrow night, the first episode is floating around.  It was teased and released a few days ago.  Someone shot me the news, and I tweeted out the reminder that the series was officially starting tomorrow.  And I have heard good things about the first episode.  But I can wait till Thursday.  It'll record after I'm asleep on Wednesday night, and then I'll watch it on Thursday, time-shifting as I do.  And that's fine.  But I heard, like, apparently it's off to a great second season start.  So the first episode apparently has, like, immediately reengaged people.  So that sounds great.  And I picked up the news, I think it was Saturday...



LEO:  Yeah, The New Screen Savers, yeah.



STEVE:  The New Screen Savers pre-show.  You mentioned you were moving to my non-Windows operating system, FreeBSD.



LEO:  Now, do you want - now, so there's the one that's focused on security, which is OpenBSD; right?  And then FreeBSD is kind of the base that Open and NetBSD and PC-BSD are based on.



STEVE:  So FreeBSD is faster than all of the others.



LEO:  Right, right.  It's the original, too, kind of.



STEVE:  Oh, it is.  And so what happens is, and it's not surprising, with any community of developers, especially, you're going to have a community of egos.



LEO:  Right.



STEVE:  And someone says, "Well, you know, I want to do this."  And the rest say, "Uh, no, we're going to do that later."  "I want to do it now."  And so "I want to do something with networking."  And they're like, no.  Well, that creates a fork.  And so then you get NetBSD, and OpenBSD, and so forth.  So, yeah.  So FreeBSD...



LEO:  But you like FreeBSD.



STEVE:  It was recommended to me 15 years ago, maybe, by Brett Glass.



LEO:  Well, there you go, yeah.



STEVE:  And I've never, never regretted it.  I've been running...



LEO:  What do you use it on, though?  I didn't realize you were using it.



STEVE:  Oh, yes.  I have three FreeBSD servers.



LEO:  Ah.



STEVE:  Our DNS is running real BIND.



LEO:  Oh, BIND, yeah.



STEVE:  BIND 9.  And my good old GRC newsgroups, the NNTP server, that's INN.  And so that's one server.  And then I just brought up another server for GRC's forthcoming forums, you know, standard web forums, because with the release of SQRL I have to have a readily accessible, high-visibility public place for users and testers and developers to be able to collaborate.  The NNTP newsgroup is valuable for what it is, but it's just not accessible enough.  And so that's where I was talking to you a couple weeks ago of having brought up, not quite a LAMP stack, but a FAMP stack.



LEO:  Right, right.  That's right.



STEVE:  Because I use FreeBSD, Apache, and MariaDB, which is from the originators of MySQL, but they forked it back from Oracle because they don't trust Oracle in the long run, or Larry.  And then PHP 7.  And so that one's running FreeBSD 10.7, which is the current latest.  And then the third one is also hosted on FreeBSD, and that's FreeNAS, is a FreeBSD-based...



LEO:  Yes, FreeNAS, right.



STEVE:  ...network attached storage system.  And of course I've got it, you can't see it on the shelf up there, there's something called NanoBSD.  There's also TinyBSD and PicoBSD.  NanoBSD is the host for the pfSense router/firewall that I've been talking about.



LEO:  Right, right, right.  I'd forgotten you were doing all that.  Yeah.



STEVE:  Yeah.



LEO:  Now, where do you get your hardware for your FreeBSD?  The reason I'm thinking of it, I mean, and you know what, use Linux is fine, use Windows, OS X, that's fine.  But what I want is a rock solid - what I found by using Linux is I don't need Windows or OS X.  All the stuff I want to do, with the exception of Lightroom, and there are solutions around that, can be done on an open source operating system.  And then I started looking at stability, reliability, and the difference between Linux and BSD, which is kind of that BSD is a base unit that's all created at the same time, as opposed to Linux, which is a kernel, and  then stuff is added on top of it.  Which makes BSD more reliable, I think.



STEVE:  Well, and what I like is it is Unix.  It is not...



LEO:  It is true Unix.  It's not Unix-like.



STEVE:  It is true - there is a UC Berkeley Regents of State of California, because they had the source at one point, I mean, there is that license in there.  It is actual, evolved Unix, as opposed to what Linus did, which was to create a Unix-like OS, you know, [crosstalk].



LEO:  Aiming toward POSIX compliance, as he says.



STEVE:  Right.  Right.  And so I have, in what, 15 years, it's never crashed.



LEO:  Never rebooted.  Never rebooted.



STEVE:  It's never hung.  Yeah, you don't have to reboot.



LEO:  [Crosstalk] 15-year uptime, yeah.



STEVE:  It just comes up and runs.  Now, I did hear you, and I sort of smiled at this, mentioning the difference between packages and ports.



LEO:  Right.



STEVE:  And I was a ports user.  I am now gleefully a packages user.



LEO:  It's so much faster, of course.



STEVE:  That's my point.  And when you bring a system up, you will get email from it at 3:00 a.m. every morning.  And so what you see in the security report is, oh, these three packages, which are installed, have security vulnerabilities.



LEO:  Right.



STEVE:  So you want to be able to go "PKG Upgrade," Enter.



LEO:  Right.  This is very much like the Linux experience, where you use apt-get or pacman, and it updates, because you've downloaded binaries, precompiled, ready-to-run binaries, much like you do on OS X and Windows.  Very rarely do you download source code and build the application.  And that's the port system.  But the port system's so beautiful.  I love the port system.



STEVE:  Well, and as I've said to you in the past, when you see this gibberish scrolling, like, endlessly... 



LEO:  Makes you feel like you're doing something.



STEVE:  Where one character out of place, and it wouldn't work.  You would think, okay, this can't possibly work.  And I used to build the kernel.  I rebuilt the kernel on our original server a couple times, just tweaking it here and there, just because I wanted to play with that, and that's fun.  But it's like, okay, I've done that.  Now I don't really need to.  But so, for example, I have this older piece of hardware.  It's an Intel system, multi-SCSI.  It's the SCSI 320 drives.  An Adaptec 2120, I think it is, or 2021 RAID controller.  I mean, it's just like this random machine.  Dual Xeon processors, so it's nice.



LEO:  That's what I was thinking of doing, yeah.



STEVE:  Yeah.  And...



LEO:  Lots of RAM.  BSD likes RAM.  FreeBSD likes RAM.



STEVE:  Yeah.  And in fact I'm still running 4GB on two of them; but for the FreeNAS, especially ZFS, it really wants more RAM.



LEO:  That's what I'm really excited about is ZFS.



STEVE:  And so I just got 12 because this motherboard has six slots that can take 2GB per for RAM.  So I just - I install FreeBSD from a CD, and it sees and recognizes everything in the system.  The older one, which is like 5.something, it chokes a little bit when it's booting up on the RAID controller because it's like not happy with it.  Well, they fixed that.  And so 10 just cruises right through, recognizes everything.  Everything came up and ran perfectly.  And it's like, oh.



LEO:  That was easy.



STEVE:  This is really nice.



LEO:  I know.  It's amazing, isn't it.



STEVE:  Yeah.  And so then I have, you know, I established asymmetric keys so I'm able to SSH into it and just instantly get a command prompt with crypto keys, and it just makes administration and use a joy.  So anyway, I [crosstalk].



LEO:  And I agree with you, because I've been building from ports.  I built Xorg, and I built Gnome 3.  It took all day.



STEVE:  And I was thinking, Leo...



LEO:  Even on a fast machine it takes all day.



STEVE:  It's fun to do it a few times.  But then it's like, eh, no, thank you.



LEO:  And there are some arguments for building from source because it's a little more customized to what you have [crosstalk] binary.



STEVE:  Well, actually, GRC's INN is customized.



LEO:  Right.



STEVE:  There's all kinds of things I did.  For example, for a while we were having leakage from the newsgroup out to Google or out to universities.  It turns out they were reaching in and pulling news from us.  And the people in the group said, you know, that seems wrong.  We want to keep this here.  And the other problem was people might be responding to posts that somebody had exfiltrated from our server, and no one was ever going to see their response.



LEO:  Right.



STEVE:  So it would be frustrating for them, too.  So, for example, one of the modifications I make tags the IP of the person who pulls the article in the article headers.  It adds the article on the fly on the way out.  So what's cool about that is that there's no information disclosure because everybody then is, if they look at their headers, they see their own IP.  So, okay, that - no information was disclosed.  But if an article appears out in the wild, we look at its headers, and we get the IP of the entity that pulled it originally from us.



And I think it's called X-Original-Reader is the header that I created.  And so it allows us to backtrack and find out how things are escaping.  And then I just go block them so that they can't have any more newsfeed.  And there's a bunch of other things.  Only people who post are able to delete their own posting.  Nobody can delete anybody else's.  So there's a whole curation system that I added to it.  And this was all in C.  But I was able to do it thanks to the open source, that I was able to bring the source down, figure out how it all worked, and then add some of my own code and recompile [crosstalk].



LEO:  That's why I love open source, yeah.



STEVE:  Yeah.



LEO:  You know...



STEVE:  And you're right, Leo.  It's where I will end up.



LEO:  You will end up.  But you're already there.  I keep forgetting that you're running all these FreeBSD boxes.  Do you buy - do you build and just put them together yourself?  Or do you have a...



STEVE:  Yeah.



LEO:  Yeah.  That's my real concern.  What I want to do is replace my computer at home, my iMac at home.  But I want a three-monitor solution.  And, you know, there's some - so I want to make sure it's all going to work.  And so that's the challenge.  And of course...



STEVE:  Yeah.  The coolest thing is that people are used to having, like with Windows, where we keep chasing Microsoft's eternal quest for more power, we chase it up, to the point now where we've had water-cooled chips in order to display a Pokemon running around a screen.  It's like, what has happened?  So what I wanted to tell our listeners is anyone listening to this podcast has a machine in the closet that's like, I mean, an old machine.  They couldn't, they didn't want to part with it.



LEO:  Older is better, frankly.



STEVE:  That's my point is that FreeBSD allows a machine like that to have an entire next life, essentially.  If you want to play with pfSense, put a couple of cheap network adapters in, or get a quad NIC.  Stick it in, FreeBSD will see it, recognize it, know what it is.  And then you just download the free pfSense, and you have a world-class firewall router for zero cost that you can play with.



LEO:  Yeah.  I'm looking forward to it.



STEVE:  Neat, neat.  I think it's the right [crosstalk].



LEO:  That's definitely the right thing.  And it's, you know, for a lot of the stuff I do at home, the one thing is photography, is the only one, Lightroom and photography.  And there are easy ways around that, including I still have a lot of Macs.



STEVE:  It's funny, I heard you mention that also before.  And I was put in mind of the beginning of Windows, when I was still in DOS.  DOS worked.  Brief worked.  WordStar worked.  Everything was fine.  But then there was this Micrografx Designer.  It was like, ooh, gosh, look at those.  Look at that.  And so I would fire Windows up only to run that one program which was one of the early graphics design tools under Windows.  And I would do something and then come back to DOS.



LEO:  That's one of the solutions is running Wine, and just for Lightroom.  And it works fine.  Works fine.  And for the kinds of stuff, my hobby stuff, the programming stuff I do, this is the way to go.



STEVE:  Oh, Leo.  It's, I mean, just - you just look through the...



LEO:  All the tools, the tooling is so much better, yeah.



STEVE:  I mean, it really is a - what's Paul's word?  An enthusiast's - a computing enthusiast's platform.



LEO:  For Python, for instance, you want to learn Python or use Python in your future life as a retired, reformed Windows user, there's some really interesting Python - there's, like, bpython, which lets you use a command, a REPL to type in stuff.  And if you like it, save it to Pastebin so that you can kind of code in this interesting way where you're trying stuff, seeing what happens, and it's saying, yeah, keep that.  And it's very interactive.  It's very interesting.  And all of these tools are just - they're free, widely available and, best yet, very well supported.  I mean, lot of enthusiasts out there.  That's why I like Linux, too.  And Arch Linux has an amazing wiki.



STEVE:  Oh, and, I mean, I'm not an expert in Unix.  So as I'm putting together this new system, I would hit a little roadblock, and I'd go, hmm.



LEO:  Somewhere online.



STEVE:  Just google a phrase, and okay, fine, now just press that button, and off I go.  Speaking of pfSense, for those who may be running it, it just received a very nice facelift.  I went, I didn't otherwise know about it.  And I went to the main system page, and I got a little flashing notice there saying upgrade available.  And I thought, oh.  And I had time.  And it upgrades itself in place.  So I just clicked a button, and it downloaded into its other image bank an update.  It's supposed to restart itself, and it didn't.  It may have been because it was a major change.  Once I got that, then there was a .1 update to that one.  And that one did restart and come back up.



For the major jump, it went down, and I expected it to.  But then I kind of like, okay, how long should this be taking?  And I waited for a while, and then I pulled the power and plugged it back in again, and then it came up.  So it just had a little bit of a catch.  But the new UI is way more mature.  Little flatter look, like it's modern now.  And they spent a lot of time on it.  So I just want to let people know because you wouldn't maybe otherwise know that there was a new version.  I'm on all kinds of mailing lists and things, but no one told me.  So it did.



LEO:  Yeah.



STEVE:  And I wanted to acknowledge everybody who sent me the link to the Apollo assembly language source code.



LEO:  That's fun.



STEVE:  Fun to look through.  And as you said when you were talking about it over the weekend, Leo, and you were right, well, it's for some random homegrown obscure computer.  So it's not like you can run this on anything.



LEO:  You can't assemble it and run it.



STEVE:  Although there is an emulator.



LEO:  Oh, I'm sure there is, yeah, yeah.



STEVE:  I mean, if you, like, really want to burn your engines, then you can...



LEO:  Be fun, wouldn't it?



STEVE:  Or stir the gas or stir the hydrogen or whatever it was.



LEO:  And there's the fireworks display, which is fun.  It's really fun just to look at it and just feel the history just pour through it.  It's amazing, yeah.



STEVE:  And I'm tempted to rename Peter Hamilton's novel, which he called "The Great North Road," "The Endless North Road."



LEO:  Yeah, it's kind of long, I know.  I know.  I know.



STEVE:  Oh.  However, I'm at the end.



LEO:  Did you finish it?



STEVE:  I think I'm - it feels like I'm at the - oh.  I think I finished the penultimate chapter.



LEO:  Right, yes, yes.  There you go.



STEVE:  Yes.  I concluded...



LEO:  You can tell it's kind of wrapping up.  They've solved the mystery.



STEVE:  Yes.  And so for anyone...



LEO:  By the way, not the best solution, either.  I mean, it's kind of a little bit of a...



STEVE:  I love his work.  There was lots of clever stuff.  I don't think this is his best work.  I really...



LEO:  No, I agree.



STEVE:  I think "Pandora's Star" and "Judas Unchained," that pair.  I like the Ozzie world and all that.  But I was tweeting a little bit with someone who just finished the Rho Agenda prequel trilogy about Jack and Janet, the CIA assassin people, and he really enjoyed those.  And so we were talking a little bit about - because here I was not quite where I am now.  I feel a sense of relief now, it's like, okay, that's over.  And his point was - and remember when I was sort of a little snarky towards Richard Phillips' work, that is, the Rho Agenda guy.  And then I backed off on that.  I apologized because it was wrong.  It's that Richard's stuff doesn't have fluff.  And Peter's adds decoration and sparkles to the fluff.



LEO:  Baroque, yes.



STEVE:  I mean, oh, my lord.  I know what color socks the various people are wearing and whether they like stripes or checks.  And it's like, okay.  Is this really important?  But on the other hand, you end up really knowing these people rather deeply at quite some expense.  So it was great.  I'm glad I read it.  But it was a long read.  But again, some interesting new concepts.  But I don't know.  Seemed a little bit lighter than usual for him.  And the one that we're now waiting for, due in September, the sequel to the whatever it is, "Abyss of Dreams" or "Beyond Dreams" or whatever.



LEO:  Yeah, oh, the Faller Chronicle, yeah.



STEVE:  That's probably going to be great fun again.



LEO:  Ah, yeah.  I finished that one.  That's awesome.



STEVE:  So, and I did get a nice note from a listener who asked me to please share this.  His name is Dave Jones.  This actually came as a DM, a rather lengthy DM.  He said:  "Hi, Steve.  I wanted to drop you a quick message to add yet another success story to your ever-growing pile of SpinRite testimonials.  I'm a software engineer living in Edinburgh, Scotland, though I'm originally from England, where my folks still live.  As I suspect will be the case for many of your listeners, I provide tech support for my friends and family.



"On my latest visit to my parents, my dad asked me to look at his Windows 7 laptop that, over the previous months, had slowly ground to a crashing, unresponsive halt.  Over the course of a few hours I followed your advice" - oh, this is the guy I was talking about earlier, I knew I'd heard it recently - "I followed your advice to upgrade Windows Update, install Never10, and replace third-party AV with Microsoft Windows Defender, all of this knowledge accumulated over many years listening to Security Now!, a valuable resource, not only for security, but also for staying abreast of Windows issues - not easy when you develop exclusively in OS X.



"After auditing the laptop's software, I pulled out my copy of SpinRite and set it running at Level 4" - which is the deep one - "on the laptop's hard drive."  So he wanted to give it a good scrubbing.  "SpinRite ran for almost exactly 24 hours; and, though the status screen reported no faulty sectors" - as we know, it often will - "I rebooted the system feeling quietly optimistic.  Sure enough, SpinRite had forced the hard drive to take a long, hard look at itself, and the laptop is now running like a dream.  Thank you for your brilliant suite of tools, library of podcasts, and methodical approach to problem solving.  Give my regards to Leo and his wonderful podcast network.  I'll visit that studio someday.  Kind regards, Dave Jones."



LEO:  Thank you, Dave.



STEVE:  And he said:  "P.S.:  Please feel free to share this on a future SN podcast.  In fact, I'd love it if you did."



LEO:  Well, there you go.  You got your wish.  Now, let me go and see what questions I have for you, Steve.  You said these mostly came from - yeah, I see them, I see them - mostly came from Twitter.  We start off with Hans Dekker, who asks:  If I keep an Internet-exposed web server, for instance, or a Minecraft server - that's what I'm doing - on a WiFi guest network with limited access, am I safe?  Hans Dekker.



STEVE:  So I'm a little confused, I guess, by "WiFi guest network."  So the server maybe has a wireless access point, and then it links to a wireless router?  I guess I'm more used to seeing a machine like that, an Internet-exposed web server, would be plugged into a router.  So I wasn't exactly sure what Hans meant.



LEO:  I think that's what he means.  He says what he wants to do - I understand what he wants to do because my server, which is running on a Mac Pro, my Minecraft server, SSH server, wiki web server is plugged in.  But it has WiFi.  And what he wants to do is isolate it; right?



STEVE:  Right.  And so...



LEO:  Because you have to DMZ it, or you have to port-forward.  Somehow you have to indicate that traffic coming in on 35565 is going to go to that server.  Well, what if you put it on a guest WiFi?  Would that protect the rest of the network from it?



STEVE:  The problem is there are too many unknowns in order to suggest that that would actually provide protection.  What I was put in mind of was what I did when I brought up this forthcoming forum server because, as we know, we've covered it for years, traditionally forum software...



LEO:  Oh, it's so buggy.



STEVE:  ...especially with a SQL backend, is like one of the worst places from a security standpoint.  So there was no way I would even consider bringing up a system where anonymous people could post their own content into a server unless I could absolutely isolate it from the rest of GRC.



LEO:  That's what he's asking.



STEVE:  Yes.  And so this brings up two things.  What I did was - oh, and what I needed was to know that, no matter what could possibly happen on that server, no matter what could crawl inside it from the outside through an unknown problem in the forum software or, for example, if it was a Minecraft server, some...



LEO:  Bug in the server, yeah.



STEVE:  ...buffer overflow that might exist there, no matter what could happen, no meltdown or compromise of that machine could in any way affect the rest of GRC's network.  Again, I'd just rather not have it than to have something that is a source of that kind of vulnerability.  So I used to have, essentially the hub that links all these different machines together was a very nice gigabit switch.  It is now a managed switch.  And that's not something we've ever spoken about before.  A managed switch is very much like a multiport appliance that you plug things into.  And if you don't explicitly configure it, it acts just like an unmanaged switch.  That is to say, the hub/switches that we're used to talking about, they are implicitly unmanaged, meaning there's nothing to manage.  There's nothing to do.



But managed switches give you a console interface or, more recently, a web interface.  And what I chose was a product from Cisco.  I liked that it had my initials.  It was the SG300-10, which is a cute little 10-port - thus the -10 - 10-port managed switch.  Basically it is sort of the OS side of Cisco's IOS, the Internet Operating System, and you're able to define access control lists, ACLs.  So essentially, it is an inexpensive hardware firewall.  And again, when I say "hardware," we talked about this question last week.  What's the difference between a hardware and a software firewall?  It's like, well, yes, it's running an operating system.  There's software in there.  But by hardware I mean that's all it is.



So now, rather than having all of the servers at GRC converge on this switch, where they're able to share traffic among themselves, on a port-by-port basis I'm able to impose rules on which packet traffic is allowed to ingress and egress from each port individually.  So, for example, the port that this forum's server is already running on, it is able to send email, because I have to be able to do that from the forum software.  It can access GRC's SMTP server, which is on a different piece of machine, and that's it.  It is blacked out from the rest of the network.  I make it go get DNS from outside.  It talks to the rest of FreeBSD land from outside.  So it is in my network, but it is absolutely bolted down so that, no matter what happens in there, it can't get up to any other kind of mischief.



So one option is to add to an existing network a managed switch.  And you'll want to make sure if this is the kind of thing you want to do because there are sort of - there are grades of management.  You probably want what's known as a Layer 3, as opposed to a Layer 2, managed switch because Layer 2 can do things like quality of service and traffic prioritization, but not packet filtering.  You want to make sure that the one you get can do access control lists, packet filtering.  Dell makes them.  Amazon has a bunch of them.  And they're not super cheap.  They're a few hundred dollars.



But the alternative, and this is the second part of this, is, for example, this little pfSense box I have, it's got four network interface adapters, so any little machine with multiple NICs.  The concept here is that you want port isolation so that the computer is plugged into a physical port, and there are then firewall rules.  And we call them firewall just because it's looking at the packet and deciding what to permit or to drop.  There are rules that say only this traffic is able to come in or out.



And so, for example, in the case of this forum server, it has full access to the Internet for all the things it wants to do, only to GRC's SMTP server that feels unlikely that it's able to get up to any kind of mischief.  If I weren't so careful, then I might put firewall rules in that machine.  But of course we can't trust firewall rules in that machine because it's the machine that might be compromised.  So the solution has to be outboard.  And we never really talked much about actually bringing up packet filtering to our audience.  But I have a feeling we're going to be heading in that direction in the future because this Internet of Things, and doing more sophisticated things like running a publicly facing server in your home, where you want to make sure that there isn't a crossover between any mischief it gets up to and the rest of your home network.  The way to do that is isolating the traffic.



And I know people will talk about VLANs, and that's sort of a mistake.  Virtual LAN technology is an organizational tool, not a security tool.  It can be used for security, but you have to be very careful that the switches that you use honor the VLAN tagging and that that's all done really right.  I regard it as a fragile solution.  So I think physical port isolation is the way to go.  And so it's either a multiport router where you have control over individual traffic coming in and out of the switch on an interface by interface basis - and, for example, pfSense gives you all that.  It's a full firewall also.



Or another solution is - and I expect we're going to see some downward pressure on pricing because I would like them to be cheaper for our listeners - is a managed switch that can do Layer 3 management.  They are just so fun to play with.  Oh, and you can do other cool things like port mirroring.  You're able to, for example, tell a managed switch that you want all of the traffic on the following ports to also be forwarded out of that port.  And of course that's where you put your monitor in order to, like, watch what's going on on your network.  So it's able to see all of the traffic coming and going.



LEO:  I don't know if it's horribly expensive.  Here's one from HP that's 160 bucks.



STEVE:  Wow, that looks nice.  How many ports does that have?  That has, like...



LEO:  Twenty-four ports.  I mean, you don't need that many.



STEVE:  You won't run out.



LEO:  You won't run out.  So effectively you could think of this...



STEVE:  Yeah, you're right, that's a good price. 



LEO:  Yeah, I should just buy this and put my server - now, the way I've done it is it turns out I have two Comcast networks, so I use one for the server and just my office stuff, and then the house, the whole house network is on the Comcast business class and is separate.  No, it's vice versa, exactly.  I'm on the Comcast business class because that way I have a static IP address.



STEVE:  Well, Leo, as I expected, we have filled our time.



LEO:  Oh, that's right.  And we haven't filled our question quota.



STEVE:  No.  But let's punt those to next week.  We already have some topics to discuss, following up in more depth on some of the stuff from this week.  And so, to be continued.



LEO:  Good.  HP has an 8-port Level 3 switch for only $83.  That's probably enough for me.



STEVE:  Wow.  I've got to - okay.  Where is that?



LEO:  It's on Amazon right now.  It's a prime, baby, prime.  You buy one, and I'll buy one.



STEVE:  HP 8-port managed...



LEO:  Yeah, 8-port, and it's Level 3, L3; right?  That's what you need.



STEVE:  Yeah, Layer 3.  $83.77.



LEO:  Yeah.  And eight ports is enough.  I'm not running more than eight servers.  So what you would do is you could still put this on your network and use it as a buffer, as an isolator.  Is that the idea?



STEVE:  Okay, now, I'm not seeing - this is, well, it says Layer 3.  So it says single IP management.  So that's for managing.  Traffic prioritization, rate limiting, broadcast control, secure web GUI, session logging, flash images, port mirroring.  It has all that, but I'm not seeing packet filtering.  So that's the one thing...



LEO:  Oh, okay.



STEVE:  That's the thing we absolutely want to make sure we're getting.  And the way I was solving this question was just going and finding - go to HP, pull down the PDF docs, and see if it's got packet filtering as an option in there.



LEO:  Because essentially that's what you're using to isolate it.



STEVE:  Correct, correct.  And, I mean, our listeners will have so much fun with this because you're creating rules that say "traffic bound for this range of IPs on this protocol at this port allow," and then otherwise, if it's - and so it's sort of like a stepwise, very much like a little computer program where each rule is examined for allow or deny until it matches the characteristics of the packet.  And then normally by default there's a "deny any any," meaning if it didn't match, if there wasn't an explicit "allow any any" at the last rule, then when it falls off the end it drops the packet.  So this gives you absolute control over managing who's able to do what on your system.  And if we can find one that's inexpensive and we know does packet filtering, then that would be a win because it would give our listeners something, really, it's just so fun to play with.



LEO:  Well, those rules sound familiar.  They sound like firewall rules.  So it sounds like it's very similar to that kind of.



STEVE:  Yeah, yeah.  That's exactly what it is, yeah.  I guess I would call - when you say, okay, what is a firewall, well, it's something that restricts some traffic.  And so that's what this is.  Technically it's called an "access control list," meaning an ACL.  It is a list that specifies the families or classes or types of traffic that is allowed in and out of a port, on a port-by-port basis.



LEO:  I would bet this doesn't do that packet filtering.



STEVE:  I think it probably doesn't.



LEO:  And that you'd have to get the enterprise version to do that, would be my guess.



STEVE:  Oh, but here's the one that does.  In the little chart down below, the SG300-10, the one I got.



LEO:  Oh.



STEVE:  That's $175.  So, okay.



LEO:  That's not terribly expensive.



STEVE:  It's not.  It's less expensive than I remembered.  So,  yeah, that one, it's running a version of IOS, the famous Cisco Internet Operating System that the routers run.  Very nice web interfaces, 10 ports.  And again, it's not 24, but come on, 10.  And so, I mean, most of your stuff is all going to be on one switch, feeding into that, for management in the aggregate.  But that's the one I bought, this little SG300-10.  It comes with little wings, so you can 19-inch rackmount it.  It's sitting at Level 3 in the datacenter, rackmounted, right now.  That's the one I'm using.



LEO:  I'm going to cancel that other one, and I'm going to get the SG.



STEVE:  The SG, the Steve Gibson 300. 



LEO:  Steve Gibson-approved model.  Nice.  Folks, that concludes this edition of Security Now!.  We're getting ready for TNT, so we'd better wrap it up here.  I see Jason Howell has arrived.  Don't forget you can get this show on Steve's website, along with SpinRite, the world's best hard drive maintenance and recovery utility, and all the great free stuff he does.  GRC.com.  We have also the show in audio and video at our website, TWiT.tv/sn.  And the best way to do it is subscribe.



Somebody asked me in Twitter, well, I've missed a few episodes, and your feed only has 10.  What do I do?  Well, feeds, that's the nature of feeds.  Ten is, like, generous.  It's the most recent shows.  But you go to the website, TWiT.tv/sn.  Every show ever is there.  And then I also pointed him to my blog, LeoLaporte.com, where we have user-submitted scripts for downloading any range.



STEVE:  And doesn't subscribing prevent you from missing them?  You don't have to go get them one by one.



LEO:  Right.  You subscribe.



STEVE:  You just subscribe, and then they're there.



LEO:  And that way you'll get everything going forward.  You'll always have it.  Exactly.



STEVE:  Right.



LEO:  Unless you have some rule.  Sometimes some of the podcatchers have rules like, if I don't listen to it in a month, delete it and stuff like that.  Cool.  We'll be back here every Tuesday, 1:30 p.m. Pacific, 4:30 p.m. Eastern, 20:30 UTC.  So stop by, say hi.  Join us in the chatroom.  And we'll see you next time on Security Now!.



STEVE:  And we already have a great show lined up for next week.



LEO:  We're planned.  We're all ready.  We're ready to go.



STEVE:  Just pause your life for however many hours that is.



LEO:  We'll be back soon.  Take care.



STEVE:  Bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#569

DATE:		July 19, 2016

TITLE:		Messenger, CryptoDrop, & Riffle

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-569.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with a fun and interesting week of security happenings, including a bit of daylight on the password sharing question; the trouble with self-reporting security breaches; trouble in TOR-land; what future AI assistants mean for our privacy; a terrific-looking new piece of security monitoring freeware; a startlingly worrisome 20-year-old fundamental Windows architectural design flaw; a problem with Juniper routers' OS certificate validation; some errata; a bunch of miscellany; and the promised follow-up dissection of Facebook Messenger's extra features, the anti-ransomware CryptoDrop, and MIT's "Riffle" anonymity-enforcing networking solution.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's champing at the bit, ready to go with a great show.  Lots of security news.  We'll talk a little bit about the 50th Anniversary of Star Trek and the movie to come.  And then we'll analyze some security threats and some security promises.  One's good, one's bad, and one's right in between.  You'll find out.  Details to come, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 569, recorded Tuesday, July 19th, 2016:  Messenger, CryptoDrop, and Riffle.



It's time for Security Now!, the show where we cover the latest news from the security front.  And there he is, your Commander in Chief, on the front lines every day, Steve Gibson of GRC.com.  I salute you.



STEVE GIBSON:  Yo, Leo.



LEO:  Hey, Steve.



STEVE:  Good to be with you again, as usual.  I turned my salute into the Vulcan handgrip.  And I was thinking, yes, and I'll be front row, well, not front row, but exactly the right seats on Friday.



LEO:  Oh, you're going to the show.



STEVE:  I am.



LEO:  Are you excited?  "Star Trek Beyond."	



STEVE:  I love the movies.



LEO:  I do, too.



STEVE:  That is, I mean, the Star Trek movies.  I really think...



LEO:  Is it true that one is either a Star Wars fan or a Star Trek fan?  You could be both.  I'm more of, I'll be honest, I'm a Star Trek guy.  I'm not a Star Wars guy.



STEVE:  Well, this is the 50th anniversary.



LEO:  Wow.



STEVE:  The first series began in 1966, when I was 11, and you were either nine or 10.  And it had an outsized influence on me.  The quality of the original Gene Roddenberry stories and, literally, the characters that have lived for 50 years, ever since then.  And actually, down in our miscellany, I have a little note about that because Netflix has an announcement that they just made that I will share.



But we've got a crazy bunch of news this week.  A bit of daylight on the password-sharing question that we looked at last week.  There's another result from a different three judges on the Ninth Circuit Court.  The trouble with self-reporting security breaches.  Some trouble in Tor Land.  What future AI assistants mean for our privacy.  A terrific-looking new piece of security monitoring freeware that you and I asked for, and one of our listeners delivered.  A startlingly worrisome, 20-year-old, fundamental Windows architectural design flaw.  A problem with a Juniper router's OS certificate validation.  A bunch of errata, miscellany.  And then the title of this podcast is "Messenger, CryptoDrop, and Riffle," which sounds like a law firm.



LEO:  I like it.



STEVE:  Or at least the Riffle part, I guess.  Anyway, I promised to follow up on the details of those when they exploded underneath me last week, and I thought, okay, we already have two hours.  There's no way I could spend any more time.  So Messenger has neat new features.  CryptoDrop went from, eh, I don't know to, okay, where do I get one?  And Riffle, unfortunately, which the press is saying, oh, an alternative to Tor, it's like, uh, no, unfortunately, the Internet really fights anonymity, and no one has figured out how to fix that, even these guys.  So lots of stuff to talk about.



LEO:  Can't wait.  And I don't have to wait long because the show is on the air.  And I do, at some point I'll - I ordered my FreeBSD box.  Now, not my server, my desktop FreeBSD box.  And before the show I was saying I'm now ready for you to do a show on ZFS, the file system that is not only part of BSD, but is rapidly becoming part of the Linux world.  ZFS for Linux is now kind of rapidly coming on strong.



STEVE:  Yeah, if you give it a lot of storage and a lot of RAM.  It's RAM-hungry.



LEO:  So I've got 32GB.



STEVE:  Good.



LEO:  And I think that's enough.



STEVE:  Good, yes.



LEO:  I looked at what the - because what I'm going to do is I have five drives.  I have an M.2 drive.  I don't think I'm going to put that - I think I'm going to put that in a separate pool.  I have to talk to some BSD experts, maybe.  I'll install, I'm thinking, the operating system, the ports, all of that stuff on pool one, which will be the NVMe drive, the fastest drive.  And then I have four terabyte SSDs.  And I'll make that the second pool.  And I'll make that the home directory and the data stuff.



STEVE:  Nice.



LEO:  And I'll use RAID-Z, their RAID thing for data redundancy, which will give me three gigs out of the four, or three terabytes out of four.



STEVE:  Right.  And it handles drive degradation very nicely.



LEO:  Apparently.



STEVE:  You can pull the drive out and slide another one in, and it just rebuilds it.



LEO:  Yeah, yeah.  And I don't need to have that kind of redundancy on the operating system and apps.  I need it...



STEVE:  Correct.  In fact, the architecture is very much what I described for the big box I built.  I'm booting from an M.2, the Samsung 950.  And then I have a pair of mirrored multi-terabyte drives.  And so what I do is I make a nightly image from the SSD over to the big RAID, which is just a mirror, so it's just, you know, simple redundancy because the problem with non-hardware-assisted RAID is it is a little slower.  So anyway, I'm just using mirroring, so it writes the same thing to both drives.  And that way I'm always able to back up to a previous image.  And I keep a few images rotating, and then of course offsite backup.  And we'll have a new sponsor next week that has something to say about this.



LEO:  Oh, yeah.  You're right.



STEVE:  Yeah.  And I've got - I did get the whitepaper.  And I need to dig into it because they've got, like, multiple layers of meta-ness around their RAID so that you get this sort of "it just works" sort of functionality.  So I will figure it out so we can talk about it intelligently when they become a sponsor.



LEO:  Yay.  The other thing I'm doing as kind of an experiment is creating my own cloud on another server, a Linux server, using something new called Sandstorm.



STEVE:  Heard you talking about that on MacBreak, yeah.



LEO:  I'd be very curious, your thoughts on that.  It's intended to be highly encapsulated and secure, the idea being that, well, maybe FreeBSD doesn't have all the easy GUI apps.  But if you can run a browser, I can do all the browser apps on my cloud, and then have access to it from all my other systems.  I don't know, I think this will be - you know what?  As I said, and you probably heard me say this, this is my game.  And you're the same way.  This is fun.  This is something I look forward to.  I was thinking about it last night and rubbing my hands.  We're just weird that way, aren't we.



STEVE:  So we talked last week about the press pretty much going crazy over that decision, over their interpretation of a decision to uphold a prosecution of this guy that left a headhunting firm and then got the password from someone who was still there and clearly broke the law in breaking into that company's confidential data using this password.  And so the way the majority opinion was written by those three judges in the Ninth Circuit, you could, I mean, in the best interpretation, they created some gray area where it really did seem like, if you shared your Netflix password with someone, you could be in violation of the Computer Fraud and Abuse Act, which to everyone felt like, okay, wait a minute, there's something wrong here between giving my girlfriend my Netflix password and going to prison.



So the EFF picked up a second decision made by a different set of three judges on the same Ninth Circuit Court of Appeals, which, as EFF said, backs away from dangerous password-sharing decision, but still leaves even more confusion about what the CFAA, the Computer Fraud and Abuse Act, actually means in the law.



What the EFF wrote was:  "Three judges of the Ninth Circuit Court of Appeals have taken a step back from criminalizing password sharing, limiting the dangerous rationale of a decision issued by a panel of three different judges of the same court the previous week.  That's good, but the new decision leaves so many unanswered questions that it's clear we need [what they called] 'en banc' review," which means all of the judges.



LEO:  Oh, like in the bench, by the bench.



STEVE:  Right, all 11 judges, not just three.  So that would allow the court to issue "clear and limited interpretation" of this notoriously vague federal hacking statute which is at the heart of both cases, the Computer Fraud and Abuse Act.



And then the EFF said:  "To recap, the court's language in last week's case" - that is, the week previous - "U.S. v. Nosal, was so broad that it seemed to make it a federal crime to use someone else's password, even with their knowledge and permission.  In the new decision, in a case called Facebook v. Power Ventures, a separate Ninth Circuit panel acknowledged that a computer user can provide another person with valid authorization to use their username and password."  Which that comports with how we would think this should be interpreted.  Like if someone who has authorization gives theirs to someone else for their use, then okay.  But again, still there's some gray zone.



So they said:  "That's the good news.  But the decision leaves unanswered so many other questions about how the law can be interpreted, and its rationale is so confusing, that it's an invitation for more dangerous litigation and prosecutions under the CFAA.  The CFAA makes it illegal to engage in 'unauthorized access' to any computer connected to the Internet.  But the statute doesn't say what 'authorized access' means or make clear where authorization must come from."  And we've talked about this many times.  This is the real problem when laws are left vague.



And I'm sort of now fascinated by the political process that runs this country, and so I've watched laws that can only be passed when some of the teeth is taken out of them.  And so compromise in Congress ends up taking what was originally - you can imagine the original drafters may have had very clear definitions.  But they were unable to get it to pass if it was worded that way.  And so it went through committee and went back and forth and around and around.  And it got, like, watered down so that it was finally weak enough that they could get a majority.  But then it's also, unfortunately, then, imposed upon the legal system to figure out what this language means when all of the specification was deliberately taken out of it.  So that's our system.



Anyway, speaking of our system, there was another little bit of news that just sort of put me in mind of a fundamental problem we have downstream of these high-profile hacking attacks.  And that was there was a little blurb that the FDIC, the Federal Deposit Insurance Corporation, was hacked by China, and the CIO of the FDIC covered it up.  This was in Ars Technica.  Sean Gallagher reported last Wednesday.  He wrote:  "A report published by the House Committee on Science, Space, and Technology today found that hackers purported to be from China had compromised computers at the Federal Deposit Insurance Corporation repeatedly between 2010 and 2013.  Backdoor malware was installed on 12 workstations and 10 servers by attackers - including the workstations of the chairman, chief of staff, and general counsel of the FDIC."



Now, the problem is, if that's you, you're like, oh, do we have to tell on ourselves?  So Sean continues:  "But the incidents were never reported to the U.S. Computer Emergency Response Team" - that exists to received such reports - "or any other authorities, and were only brought to light after an Inspector General investigation into another [different] serious data breach at the FDIC in October of 2015," so just last October.  And that one was - and I cut it out because it was peripheral, but it was employees.



Half the employees, apparently, have access to USB thumb drives, and they're wandering around with hundreds of thousands of people's credentials and private information on their thumb drives.  Because it's like, oh, here, stick this in, transfer this database, and I'm going to go walk across and plug it in over here.  But it stays on the thumb drive unless you explicitly remove it, and so, whoops, a little bit of an information leakage problem.  So 160,000-some-odd people have free credit reports for a year.  Like, okay, well, thank you.



LEO:  Well, there's a bright side then, yeah.



STEVE:  Anyway - huh?



LEO:  There's a bright side.



STEVE:  Yes.  So "The FDIC failed at the time of this advanced persistent threat to report the incidents."  Failed.  Whoops.  Just forgot.  It's on my to-do list.  I promised, but I must have just skipped that checkmark.  Then, the "Then-Inspector General at the FDIC, John Rymer, lambasted FDIC officials for failing to follow their own policies on breach reporting.  Further investigation into those breaches led the committee to conclude that former FDIC CIO Russ Pittman misled auditors about the extent of those breaches, and told employees not to talk about the breaches by a foreign government" - remember this is China crawling around in the Inspector General's workstation, the chief of staff and the chairman - "so as not to ruin FDIC Chairman Martin Gruenberg's chances of confirmation."



And so anyway, stepping back from this, I just thought, you know, I mean, this is a problem because we're inherently asking the higher ups to obey their own rules, and there are guidelines, and they're written down.  But, I mean, the only possible solution is to arrange, for example, not for employees who report to the people who would get in trouble to be responsible for finding this and then being told not to, but to somehow have completely disassociated auditors.  And I guess auditors were involved, but the CIO downplayed it.



Well, we need a mechanism whereby auditors aren't taking clues from the C-level executives, but going in themselves.  And again, clearly this is a function of - we saw what happened with Sony, the advanced persistent threats there, and the RSA - both companies hugely damaged, suffered major reputation damage.  And of course in the government heads will roll.  So we need some sort of mechanism where the lines of reporting are different from the lines of auditing.  Otherwise you're just going to have, I mean, what employee is going to go against his C-level boss's wish and risk being terminated?



Now, we've got two things to talk about with Tor.  The first is just some news that is a little vague, and its vagueness is a little disturbing, sort of for reasons of warrant canary concern, and involving the Tor project.  We know that early last month there was a - one of the major previous Tor personalities, Jacob Appelbaum, resigned from Tor amid some scandal, which he denied, but he left anyway.  Well, now we have Lucky Green, whom we've referred to from time to time through the years when we're talking about Tor.  He was one of the very early contributors, before it had a name even, and has been running a number of important sort of key core servers, one called a "bridge authority."  So anyway, yesterday he posted this note.  He said:  "Dear friends."



LEO:  Sounds like a [crosstalk] problem.  Sorry, I'm interrupting you.



STEVE:  "Given recent events, it is no longer appropriate for me to materially contribute to the Tor Project either financially, as I have so generously throughout the years, nor by providing computing resources.  This decision does not come lightly.  I probably ran one of the first five nodes in the system, and my involvement with Tor predates it being called 'Tor' by many years.  Nonetheless, I feel I have no reasonable choice left within the bounds of ethics but to announce the discontinuation of all Tor-related services hosted on every system under my control."  And there again it's like, okay.  "I have no reasonable choice left within the bounds of ethics but to announce the discontinuation of all Tor-related services hosted on every system under my control."  So we don't know what he knows.  We don't know what has happened.  There's no necessary linkage between the Appelbaum resignation a month and a half previous, but - so who knows.



And then his note continues:  "Most notably, this includes the Tor node 'Tonga,' the 'Bridge Authority,' which I recognize is rather pivotal to the network."  And the reason that is, by the way, is that bridge authority nodes have their IPs static and embedded in Tor applications.  They're sort of like the roots.  And so he's talking about terminating one of the first five nodes.  In this case it's a bridge authority.  So over time Tor apps need to change, unless somebody else can run a bridge authority server on the same IP, which doesn't seem to be happening.



So, he said:  "Tonga will be permanently shut down and all associated cryptographic keys destroyed on August 31st.  This should give the Tor developers ample time to stand up a substitute.  I will terminate the cron job we set up so many years ago at that time that copies over the descriptors.  In addition to Tonga, I will shut down a number of fast Tor relays.  But the directory authorities should detect that shutdown quickly, and no separate notice is needed here.  I wish the Tor Project nothing but the best moving forward through those difficult times."  And then he just signs it "Lucky."



And in his posting there were some questions following up.  One asked, like, what happened?  And it's received no answer.  So it's kind of hard to know.  This is sort of reminiscent of TrueCrypt, where, again, we're left to speculate and try to come up with a theory that makes sense.  But we have no absolute knowledge.



I read a story that I just sort of wanted to comment about a little bit.  And this was in Tech Crunch.  The title was "Why the top five tech companies are dead set on AI."  And I was a little less interested in that, I mean, well, we know because that's where growth is.  In the story they talk about how the pace of smartphone and desktop hardware innovation has slowed.  My position is it's inevitable.  That's the way the world works.  And I thought of cars.  Once we figured out that most cars should have four wheels, we're pretty much done with that question.  Yes, you could have three, and you'd call it a tricycle, or two, or more.  But most cars have four.  Four seems to be the right number.  We're kind of done with that.



And similarly, how long have we had a pretty much unchanging graphical user interface mouse and cursor model?  Since Xerox PARC showed it to Steve Jobs.  And it hasn't changed.  You move the puck, and the little pointer moves around because it's done.  And I always think of word processing and Microsoft Word, where they got it, like, a long time ago.  It was just fine.  Word 2003, Office 2003, works great.  But of course they have a new version every year or two despite that.



Well, of course, on the AI front, we've got Apple with Siri, Google with their Assistant, Amazon with Alexa, Microsoft with Cortana, and Facebook with their Chatbots, all sort of moving into this AI realm.  And as I was thinking about this, what occurred to me is that there is a privacy impact because, with AI, context is king.  And those of us who've been around sort of in the early days will remember the early speech recognition software which needed to be trained by having the user read a word list.  That was part - remember Dragon Speak was one of the very early packages.  Even back on the Apple II, I mean, it was a couple boards full of extra processing in order to get enough horsepower to do that.  And I remember that Jerry Pournelle was a big fan of speech recognition and liked dictating stuff sort of in that era, in the CPM S-100 bus days.



But the way you trained it to be reliable for you was to read a word list and to interact with it and correct it.  So it had to learn the way you spoke.  Similarly with handwriting recognition.  That's gotten a lot better.  It is smart enough now to be more generic.  But the early handwriting recognition was very similar.  It needed to adapt to and learn the unique style of its user.  And I think, because those are mechanical things, this thing wants to learn to understand me, that seems benign.  Or this thing wants to learn how to read my handwriting.  Oh, that's good, that's a convenience.  But we don't think of those in terms of privacy.



But when we stop to think about it, it was an early form of biometric parameter acquisition.  So now we move into the personal assistant space.  And so then what's the context against which our needs will be understood?  The context is everything available about us, our entire lives, as much as it has access to, because the more it knows about us, whatever the service is, the better job, the argument is - and it's a true argument, it holds up - it has to understand us in order to be able to, not only predict, but also to deobfuscate, in order to understand what we're saying or what we might mean based on our current location, for example, and based on the places we have been recently, based on what we've been doing on the Internet.



I mean, the more information, the more watching of us that can be done, the better job something, an assistant of some sort, can do of meeting our needs.  So our lives and habits and interests are going to be recorded and profiled and modeled in order for this next generation of personal digital assistants to be able to perform their jobs.  And it's happening now.  And much as with speech recognition and handwriting recognition, maybe we don't notice or care because the benefit offered is clearly, in terms of cost benefit, outweighs whatever concern an individual may have over that kind of sort of explicit "I know what you're thinking" capability may be.



But I just sort of - this all played through my mind when I was reading about this story about AI and its future.  Again, not to run around screaming with my hair on fire.  But for our audience it's just worth considering that, the way these things work, in order to be as good as they're going to get, they just need to be sucking up, vacuuming every tidbit they can get about us.  And with the justification that what we get in return is a more effective servant, a more effective assistant.  Be interesting to see how this evolves.  And I imagine there'll be some people who would rather opt out, stay off of that grid.



Okay, now, Leo, on Security Now! #551...



LEO:  Oh, I remember that.  That was a great episode.



STEVE:  And in fact I have our dialogue here.  We recorded it when I was still 60 years old, on March 17th.



LEO:  Ah, the good old days.



STEVE:  Leo says:  "It's essentially a man in the middle sitting on my own machine, much like the certs from antivirus companies.  Do you know" - it's Leo asking me - "of any tools that monitor certificate stores and report when changes are made?"  I reply:  "So, if I weren't so far behind, I would immediately whip out a utility.  I'm not going to."  And I don't know if that was before or after Never10, but it was right around that time.  So maybe I was already whipping something out.  Leo says:  "That's a great idea, yeah."  And I reply:  "It is a great idea."  Then Leo said:  "Someone should write that."



LEO:  Somebody has.



STEVE:  And I said:  "And that's why I put this in this Q&A.  Remember that Mark Russinovich just recently updated the Sysinternals tool so that, with a command line, it'll do that.  Somebody could write a little Python frontend to the Sysinternals tool that is invoked by the scheduler" - this is me talking, not what we actually got - "or maybe just runs in the background and checks every day.  If anyone does, make sure you send me a note, and I will make you famous.  I will tell everybody" - everybody, you're being told - "about it because that ought to exist."



Well, it's called CertWatch, by a guy named Beau Blaser, B-L-A-S-E-R.  And it is a beautiful-looking little piece of freeware.  Now, I gave it the bit.ly link of the week, but this time without a hyphen, so it's bit.ly/sn569.  That's a quick way of getting there because Google hasn't found it yet.  Now, if you do put a hyphen in, as I usually do, instead you get taken to a Google search for "Steve Gibson smelly old man."



LEO:  Oh, lord.



STEVE:  Because this is the Internet.



LEO:  Somebody figured out your scheme.



STEVE:  Oh, it's a diabolical scheme, yeah.  It's very difficult to anticipate...



LEO:  Unbelievable.



STEVE:  ...what next week's bit.ly link will be.  So, yes, sn-569.  And I'm not, unfortunately, or I guess fortunately, not at the top of the list.  Some other Steve Gibson gets the benefit of being the smelly old man.



LEO:  What?  Well, we've got to fix that.  Come on, folks.  We can do that.  We can make that work.  That's funny.



STEVE:  So this is exactly what we want.  It's written from scratch by a guy who's got a nice set of software of different kinds of applications.  So he says:  "Automated system certificate store checking for Windows workstation and server alerts users to the addition and removal of system certificates."  He writes:  "This new, free utility will monitor any changes made to the Windows certificate stores on your system.  Certificates can be added or removed to your system for a variety of reasons.  Windows Updates, new software packages, et cetera, can make alterations to the certificate store.  Unfortunately, some malicious software could also add an all-purpose certificate and essentially create an attack vector for SSL/TLS man-in-the-middle attacks or provide a foothold for a bad agent to usurp and exfiltrate information from your system without your knowledge.



CertWatch performs hourly scans of all system certificate stores and will report any additions or deletions from those stores when changes are made."  So, yay.  Beau, thank you.  On the page he references, that's how I was able to find SN-551 so quickly, he made a little note that he got the idea from listening to that dialogue and wrote it.  And many people - there are a couple people have come up with some sort of solutions more like what I was suggesting, a little, I don't want to call them a kludge, but not just a nice, clean little piece of freeware, purpose set, that just does an hourly check.  We have that now.  So again, thank you.  And everybody, again, it's bit.ly/sn569 with no hyphen.  And the product is called CertWatch, or the app is CertWatch.  And again, Beau, thank you for solving this problem for us.



Okay, now.  Oh, boy.  Twenty-year-old designed-in Windows behavior lets printers, or anything pretending to be a printer, install malware.



LEO:  Well, why not?



STEVE:  All the way back, starting with Windows 95.



LEO:  Oh, lord.  Which, by the way, underscores your contention that many of the pieces in this brand new modern Windows 10 are kind of old.



STEVE:  Yeah.



LEO:  What subsystem is this?



STEVE:  Get this.  Okay.  So, well,  and so we have a problem, Houston, that Microsoft made a change on Tuesday which allowed these guys, Vectra Networks, to go public with what they found.  So they wrote in their own blog:  "Security researchers with Vectra Threat Labs" - and it's VectraNetworks.com - "uncovered a critical vulnerability" - and, yeah, and it's got a CVE number, but unfortunately it's not something, well, as we'll see, that can really be fixed - "which affects all versions of Microsoft Windows all the way back to Windows 95.  The vulnerability is created by the way Windows clients interact with network printers, allowing an attacker to execute code at the system level" - so full system privileges - "either over a local network or" - are you sitting down? - "over the Internet."



LEO:  No.



STEVE:  Oh.  Twenty years ago, they write - oh, no, I guess this is me.  I'm sorry.  Twenty years ago Microsoft implemented a very dangerous feature known as Microsoft Web Point-and-Print Protocol which allows - and think about this.  I mean, we've seen this in action.



LEO:  Oh, yes.



STEVE:  Which allows a Windows machine connecting to a network-hosted printer for the first time to receive and install a printer driver delivered from the printer.  What could possibly go wrong?  And I have to say I was reminded of the very similar Windows Metafile design mistake Microsoft made during the same time period.



LEO:  Right, right.



STEVE:  Which was one of our very first podcasts.  When I looked at the Metafile code, it was immediately clear to me that this was not a mistake.  This was on purpose.  Now, it was misinterpreted.  Even my analysis was misunderstood because I never said this was malicious.  People just didn't understand that, when this was done, it didn't seem like a bad idea because nobody - it was like "The Wrath of Khan," where he didn't raise his shields, and he's approaching Kirk on the Enterprise, and Kirk is saying, well, this is mighty odd, and Khan says, "We're all one big happy Federation," you know, "no need to raise shields."  Similarly...



LEO:  It was a perfect time, Steve.  Kids played outside.



STEVE:  Precisely.



LEO:  You didn't lock the doors.



STEVE:  Dogs did their business, and everyone just walked off.



LEO:  We didn't have cell phones.



STEVE:  You avoided the landmines, yeah.



LEO:  No answering machines.



STEVE:  Right.  So back when the Metafile format was created, someone said, hey, how cool would it be if a token accepted a pointer that jumped to code in the Metafile?  Well, fast-forward 15 years.  Oh, my god, you know.  And so people thought I was crazy for thinking that Microsoft would have ever done this, except I will note that Mark Russinovich agreed with me, and we would respect his opinion, as well.  So this is similar.  This is back with Windows 95, when IPX and SPX and Novell NetWare - and Bill was still kind of thinking, you know, we've got to buy a bunch of modems at Microsoft so people can call into the Microsoft Network, and we can compete with that AOL thing and CompuServe and so forth.



And so back then, what a convenience.  You could bring in a laptop, plug it into the network.  Now, the network might have a shared printer. Well, it's going to need a driver.  But who knows what driver?  How convenient for the printer to provide it to the computer.  So it's called Plug-and-Print.  And of course we remember Plug and Play, or Plug and Pray, from the day.  Oh, I'm sorry, it's Point-and-Print.  And so what Microsoft did was design a protocol with no user interaction because that would confuse people.  You just want it to work.  So even in today's OS under 7 or 8 or 10, it bypasses UAC, no notification at all.  It installs a kernel driver, which is, like, god power, in the kernel of the OS from anything that your computer finds that looks like a network printer.  And it isn't even restrained to the LAN.



So taking it kind of calmly, more so than I am, Vectra said:  "Most organizations try to apply the principle of least privilege to the devices in their networks.  This works pretty well for things like laptops or desktops since the hardware they use doesn't change very often.  However, printers are a bit different.  While they still need drivers, printers need to support virtually any user that wants to connect to them.  As end-users move through a building, they naturally want to use the printer closest to them."  Because, you know, it spits out that paper that they have to then go get.  So they don't want the printer on the 12th floor to be printing it when they're on the third floor.



"Mobile users expect to be able to easily connect and use a printer when they come into the office.  In addition, most organizations don't standardize on a single printer, and will have multiple models and manufacturers often within a single network.  So instead of having system administrators push all possible printer drivers to all workstations in the network, the solution was to develop a way to deliver the driver to a user's device right before the printer is used.  And this is where Point-and-Print showed up."  A happy name.



"This approach stores a shared driver on the printer or print server, and only the users of that printer receive the driver that they need.  At first glance, this is a practical and simple solution to driver deployment.  The user gets access to the printer driver they need without requiring an administrator - a win-win.  The issue?  The problem is that, for this scheme to work nicely from an end-user perspective, an exception was required.  Normally, User Account Controls are in place to warn or prevent a user from installing a new driver.  To make printing easier, an exception was created to avoid" that pesky - I'm adding that, editorializing - UAC control.  "So in the end," they write, "we have a mechanism that allows downloading executables from a shared drive and run them as system privilege on a workstation without generating any warning on the user side.  From an attacker perspective..."



LEO:  It's amazing.



STEVE:  "...this is almost too good to be true, and of course..."



LEO:  Vectra calls it a watering hole attack.



STEVE:  Well, yeah, exactly.



LEO:  Which I love.  I mean, I don't love the attack, but the idea is you just - all you have to do is infect the printer.



STEVE:  Right.  And not only will your system get infected, but reinfected.



LEO:  Yeah, yeah.



STEVE:  Every time it tries to print to it.



LEO:  Put it on the printer.



STEVE:  So they said:  "This is almost too good to be true, and of course we had to give it a try.  Researchers at the security firm Vectra Networks" - they're speaking in the third person - "discovered that the Windows Print Spooler doesn't authenticate print drivers when installing them from remote locations."  Because we're all one big happy world.  "That lack of authentication makes it possible for attackers to use several different techniques" - I mean, again, this is such a gaping hole, you don't have to - it's not like worming your way through some complex incantation of four different exploits that have to interact perfectly, and only when the ASLR happens to land in the right place.  No.  This is by design from Windows 95 and has never gone away.



They said:  "The lack of authentication makes it possible for attackers to use several different techniques that deliver maliciously modified drivers instead of the legitimate one provided by the printer maker.  The exploit effectively turns printers, printer servers, or potentially any network-connected device masquerading as a printer" - and remember, that's just a protocol thing.  So, yes, a light bulb from China could pretend to be a printer.  And it's like, oh, I didn't know there was a printer there.  Let's send some documents to it.  And it takes over your machine.



LEO:  Unbelievable.



STEVE:  "Into," they write, "into an internal drive-by exploit kit that infects machines whenever they connect."



LEO:  I just want to say, when you come to this studio, if you ever want to use our printer, please, be my guest.  Just go right ahead.



STEVE:  You'll walk away with a free gift.



LEO:  A free gift.



STEVE:  And then I wrote...



LEO:  That's been in there for 20 years.



STEVE:  Yes.  But wait, there's more.



LEO:  Oh, no.  More?



STEVE:  Vectra Networks wrote - and I'm paraphrasing from what they said for a bit more emphasis.  Under "Infecting Remotely Using Internal Printing Protocol and webPointNPrint," they write:  "So far we have constrained ourselves to an internal network where a device was either inserted or infected and used to further infect devices connected to it."  I mean, so understand, they've done this.  And their blog posting has, chapter and verse, the whole - it's all laid out.  "Internet Printing Protocol (IPP) and webPointNprint allow us to extend this issue outside the Intranet to the Internet.  IPP [Internet Printing Protocol] allows for the same mechanism to load drivers from remote, in this case very remote, printers.  This can be done with the following piece of code from the MS print server."  And then their blog shows it.



Now, this was "fixed," in quotes, last Tuesday.  What did Microsoft change?  Well, they're unable to change this behavior without crucially and critically breaking 20 years' of roaming laptop and mobile computing transparent printer driver installation.  So they added a dialogue.  And we've seen how well those work with, for example, not upgrading to Windows 10.  So the good news is security-conscious people can disable Point-and-Print.  As I dug into this, I didn't have a chance to go any further.  I will probably see what it takes to do that and provide some guidance for next week because I imagine our listeners will be very interested in perhaps not having this happen to their users.  You can push it through group policy, so a corporation could do this.  And so essentially the only thing Microsoft could do is make it less transparent.  They could not break it because too much of the existing infrastructure depends on this behavior.



But this is, again, this is a classic example of something that back in 1995, with Windows 95, seemed like a good thing.  And then, now, someone did deliberately extend it to the Internet Printing Protocol.  It might have been wise to say, you know, let's not let remote printers on the Internet install kernel drivers without any user interaction.  Someone should have said no to that because that was in more recent times.  But it's probably still, who knows, maybe 15 years ago.  So, unbelievable.  Yes?



LEO:  Well, the good news is printers always auto update.  So you don't have to ever - never mind.  We continue on with the security news of the day.



STEVE:  So this is a quickie, just a note.  I don't know if this will affect any of our users.  But a startling flaw was found in a major vendor's router.  I guess arguably Cisco is the granddaddy of Internet routers.  Juniper, however, has a great reputation for high-end big-iron routers that form the backbone of the Internet.  So they released a security bulletin after somebody found a little bit of a problem with their certificate management system.  It affects every Juniper router that uses the so-called Junos OS.  That's the operating system that spans their product line.



And under "Problem" the report said:  "Junos OS runs PKId" - so that probably means Public Key Infrastructure daemon, a background service - "for certificate validation.  When a peer device presents a self-signed certificate as its end entity certificate, with its issuer name matching one of the valid CA certificates enrolled in Junos" - okay, so that means that a self-signed certificate is being looked at, not is being trusted, not based on itself, but on the name in the certificate, matching the name of a trusted certificate.  And since it's self-signed, anybody can create that certificate using whatever names they want in it because they're making their own certificate and signing it.



So they don't have to convince anybody else to trust them and look at the contents of the certificate and validate it and verify it.  No, so they're able to use a trusted name on a certificate they make, self-sign it, and across the entire spectrum of Junos devices, "The peer certificate validation is skipped, and the certificate is treated as valid."  And they say, "This may allow an attacker to generate a specially crafted self-signed certificate and bypass certificate validation."  And that's not good.



So if by any chance any of our listeners is responsible for or has Juniper routers within their organization, I'm hoping that the news of this was spread through whatever contact system Juniper has.  But this is something that could quickly be exploited, the idea being that this is how the routers are essentially peering.  And the last thing you want to do is to allow a malicious agent to peer with a major router because, as we know from all the past problems, the inadvertent mistakes with BGP routing, even if they're mistakes, horrible things can happen.  And if it's malicious, then all bets are off.  So this is something - I'm glad they found this.  There was no reported known abuse.  So this was someone detected this and said, Juniper, you might want to take a look at the way you're handling certificates.



And speaking of Juniper and Cisco, it is Errata time.  Our friend David Redekop was first, and several others corrected my mistake last week when I said that the Cisco SG300 managed switches ran IOS.  It turns out it is an IOS command line interpreter, but not actually the IOS firmware itself.  So I appreciated the correction, and I wanted to correct the record.



LEO:  You sent me a note saying that you liked this $50 EdgeRouter from Ubiquiti.



STEVE:  Yo, and that's where we're headed next.  First item in Miscellany.



LEO:  Okay.



STEVE:  So you could have three dumb routers, or one super smart router.  I wanted to put this on everybody's radar.  We talked last week about the concept of using a managed switch.  Well, a managed switch is just that.  It's like an unmanaged switch; but you're able, for example, because it has additional processing power, do things like filter packets coming in and out of specific ports on the switch.  But it's not itself a router.  And I actually stumbled on this, and then I tweeted it, and a lot of our listeners already know.  And it was a 100% rave response from existing owners who listen to this podcast or, rather, who follow me on Twitter, which is probably a subset of podcast listeners.  And I just stumbled on it.  I was looking at something on Amazon, and it was people who bought this also looked at this.  And I said, ooh, what's that?  Okay, so get this.  Well, in fact, here it is.



LEO:  I'm going to get it, yeah.



STEVE:  Oh, and Leo...



LEO:  Is this it, the six-port router?  Or is it the...



STEVE:  Look at this.  It is the cutest little thing.



LEO:  Yeah, that's it.  All right.



STEVE:  I mean, it is just itty-bitty.  And it has the highest Packet Sex Density of any little box I've seen.  A PSD, that's a technical term for what this thing does [Power Spectral Density].  So, yeah.  So for those who can't see the video, it is a cute little fanless, and I should say $49, amazingly capable smart router.  Now, what's different about this compared to any of the routers we talk about is that this has five logical interfaces, not just five physical interfaces.



So, for example, the normal kind of router that we're used to talking about, what I call the "blue box" routers, like all the Netgears and everything else that people use, architecturally that's a two-interface NAT hub, essentially, sort of a two-interface NAT box with a WAN side and a LAN side, connected to some number, typically 5- to 8-port switch, meaning that all it really is, is sort of a dumb switch with a router behind it.  What's different about this is that you actually have five logical interfaces.  So the point is, for $50 - and by the way, this is called the Ubiquiti EdgeRouter X.



LEO:  Now, is this the one with SFP or not?  And what the hell is SFP?  Do you know what that is?



STEVE:  SFP or POE?



LEO:  There's POE.  So they have two.  There's one with two POEs and three regular Ethernets; and then there's one with one POE, and the other one is SFP.  Oh, SFP is fiber, okay.



STEVE:  Yes, correct.



LEO:  So I don't need the one with fiber.



STEVE:  No.  You don't want the one with fiber.  So what is beautiful about this is, I mean, this is the answer.  What it doesn't have is wireless.  So if somebody wanted truly a single-box solution, we don't have that yet.



LEO:  But Ubiquiti does have really great WiFi routers...



STEVE:  Yes.



LEO:  ...that work with it; right?



STEVE:  Yes.  Yes.  And in fact that's probably why these routers exist.  They call them "edge routers" because then their stuff is able to plug in and use this.  So I just want to make sure that people understand that this one little cute $49, $50 box does the whole network isolation thing that we need for IoT.  Each one of those interfaces can be its own subnet, with inter-subnet isolation so that one cannot see the other, yet they have managed access to the Internet.  So you could, for example, if you wanted to use this and turn your existing WiFi router - most WiFi routers, you can reconfigure them to be just a hotspot, and so plug that into this in order to get WiFi.



Anyway, this is so much less expensive and so much more powerful than that SG300 Cisco that I was talking about last week, that I want to make sure people know about it.  It's just - it's a beautiful little box.  Now, there's one limitation, the only one I know of, and that is that it is a gigabit - it's a 5Gb interface, so 10, 100, and a gig.  But the processing power won't allow you to run, that is, between ports or move packets at a gig.  It's estimated at about 500Mb.  So as long as what you're doing, for example, your connection to the Internet is less than about 500Mb, about half a gig, then this'll do everything you want.  And you could certainly connect it to a simple gig switch as your hub of a full speed gig network, where then this manages the separation of separate subnets.



LEO:  So you could have separate WiFi subnets if you bought a couple of the Ubiquiti devices.



STEVE:  Yes, yes.



LEO:  And have them completely isolated as in the three-router solution.



STEVE:  Yes.  I mean, and so it's like either three dumb routers or one super smart router.



LEO:  Nice.



STEVE:  And so this little thing, it's just a little gem, for 50 bucks.  I just, like, on my...



LEO:  So this sets up your IoT.



STEVE:  Yes.



LEO:  If you're going to do IoT, you need to get this and a couple of WiFi access points.



STEVE:  Now, it does not support OpenVPN, but it does support both point-to-point tunneling protocol, PPTP, and IPSec.  And so that means you can also create - and it does that normally for intersite linkage.  So, for example, if you had two facilities, you could establish a static VPN link between two of these in different locations and bridge the networks together.  Or you can run this with PPTP, which is a widely supported VPN protocol, the mobile devices support, for example, and have access to your home network securely over point-to-point tunneling protocol.



So, and of course, remember, as we know, it's easy to run OpenVPN on a Raspberry Pi.  You just hook it up and give a bash script command, and bang, you've got OpenVPN installed on a little tiny Raspberry Pi.  So if you wanted OpenVPN, the Raspberry Pi could plug into one of these ports and then offer its services, OpenVPN-compatible connectivity, for you when you're roaming outside.  Anyway, we're beginning to assemble a very nice little toolkit of pieces to build solutions.  And this is the kind of thing I know our listeners are interested in, so I wanted to make sure everybody knows.



I finished Peter Hamilton's "The Endless North Road" novel ["The Great North Road"].  I really did enjoy it.  But it was quite long.  And I'm now waiting for the sequel to "Beyond the Abyss of Dreams" or whatever that was called ["Abyss Beyond Dreams"], and also for the next of the Rho Trilogy, "The Altreian Nexus" or something series.  So I'm going to go back - I never finished, actually Jack Campbell is the author of a series I've talked about before, "The Lost Fleet" series.  And I really - I love the concept, and the writing was enjoyable.



Our listeners who have been listening for a long time will remember that - real quickly, the premise is that in the far future a commander is found in a life support capsule after 100 years of battle.  And due to the aggression, the attrition rate of command officers and ships is very high.  Training standards have fallen.  And they end up reviving him, and he's sort of legendary because of the way he died.  No one could believe he's still around.



The point is he has knowledge of space combat which was common then and has been completely lost, just due to the fact that commanding officers are getting killed too quickly, and people are being promoted up the ranks.  And the people who remember me talking about it before will recall that the way he paints these battles, if you like space opera, you are just going to be so happy.  They're just clever and wonderful things he sets up, an interesting universe, and a whole bunch of books.  I think there were, like, six in the "Lost Fleet" series, and there's now four in what he calls "Beyond the Frontier."



And so I started to - I thought, okay, I'm just going to read the last couple chapters of the last book of the first series of six to kind of remind myself who the people were and so forth, to sort of bridge me in because I never took the leap into the "Beyond the Frontier."  And I did that for maybe 10 minutes, and I said, okay, I've just got to start from scratch.  So I'm starting over because they're just so enjoyable.  So if you haven't read them, you like well-written space combat, it's always been on my recommended sci-fi reading list.  And so I'm back, and I'm going to re-read the ones I read years ago and then move forward, patiently waiting for Peter F. Hamilton and Richard Phillips to both get their next books finished.



And I mentioned at the top of the show, Star Trek's 50th Anniversary year.  That is, this is 2016.  Star Trek was born in 1966.  Netflix has just announced that they, well, actually, as Popular Science's coverage put it, "Netflix users worldwide will be able to boldly binge where few have ever binged before."



LEO:  Oh, please.



STEVE:  By the end of the year, 727 episodes of all previous Star Trek series will be available worldwide on Netflix for streaming.  And CBS's much-anticipated new Star Trek series, beginning in January of next year, 2017, will make new episodes available for streaming on Netflix within 24 hours of their debut, except for viewers in the U.S.A. and Canada.  U.S. viewers will need to go through CBS and Canadian viewers through Crackle until...



LEO:  Is it Crackle?  Somebody in the chatroom says it's Crave TV.



STEVE:  Okay.  "Crackle" is what Popular Science wrote.  So I don't know.



LEO:  That's Sony's network, Crackle, yeah.



STEVE:  Ah.  So anyway, and I never - I kind of faded out on "Deep Space Nine."  I watched the first couple seasons.  Mark Thompson absolutely promises me that it got really good, that like that whole Cardassians and some dimensional creatures I never - I didn't really pay attention to it.  But every other series I watched and really enjoyed.  So, hey, and there it is.



LEO:  A special Time magazine.



STEVE:  Wow, the 50-Year Anniversary issue.



LEO:  "50 Years of the Final Frontier."  "The most influential science-fiction series ever."



STEVE:  I mean, they're just iconic, Leo.  And it was only three seasons.



LEO:  That's the thing that's amazing.  It was really a failed show.  Or not failed, but it wasn't super successful until...



STEVE:  Well, you know why, because at the time - I've told this story on the podcast before.  But I had dinner with Gene Roddenberry during a Comdex.



LEO:  Wow, that's cool.



STEVE:  And I told him, you know, I didn't want to drool all over him, but I told him that I was a serious Star Trek fan.  I don't think I mentioned that my port scanner was called ShieldsUP!.



LEO:  Wait a minute.  How long have I known you?  Duh.  ShieldsUP!.  I never put two and two together.



STEVE:  Yup.  So, but anyway, he explained that back then Nielsen had not yet implemented demographics.  And the raw count was all they were using.  And so at the end of its third year, though it had a huge fan base, the numbers weren't there.  And so it got canceled by Paramount, who said, eh, sorry, Kirk.  Maybe you can be an attorney on some comedy show in 50 years.



What happened then was that the Nielsen system began to work on - they understood that - I guess maybe they had the processing power, or they just wanted to do an upgrade.  They decided maybe who is watching matters.  So they had in their archive never-processed demographics.  And in building their statistical model, they went back and reprocessed data they had collected but never used.  And it turns out that Star Trek had the most perfect demographic profile of any show in the history of television.  You couldn't design a show that had newlyweds buying homes and cars and diapers and soap and everything that advertisers want, I mean, it was like, it was the young newlywed  yuppies, and they didn't know it.  So they canceled the series.  When in fact it was doing fabulously well with that particular demographic.  So that was directly from Roddenberry's mouth.



LEO:  I believe it, too.



STEVE:  And a great author.  So I just did want to follow up on last week's "Mr. Robot."  And I want to say I hope we soon spend less time inside of Elliot's disturbed head and get back to some fun hacking.



LEO:  Really.



STEVE:  And bring down our evil corporate overlords.



LEO:  Everybody was raving.  I haven't seen it yet.  Everybody was raving about it around here.



STEVE:  Okay.  Well, I'm - it's like, whoa.  It was a little dark and kind of sad.



LEO:  Well, everybody who works for me is dark and sad, so that's probably why.



STEVE:  I'll watch it, but, whoa.  And I got a tweet from Michael Cunningham who said, who asked me, "Did you notice the QR code in Elliot's journal actually works and goes to some goofy site?"



LEO:  Oh, there's lots of Easter eggs in this show; right?



STEVE:  Yes.  ConficturaIndustries.com.  And I put the link in the show notes, and The Verge covered it.  It has a huge blown-up QR code.



LEO:  I love this.  It's a Geocities site.



STEVE:  It's just a weird site.



LEO:  There's a guy with a jackhammer, under construction, under construction.  Warning, this site is under construction.  It's the worst.



STEVE:  One of those old-school spinning email A's from like the early days of...



LEO:  I used to have the mailbox that opened up and the...



STEVE:  Yup, I had that, too, yeah.



LEO:  Geocities Cool Page of the Day.  Link Exchange, promote your site for free.  The counter.  Pretty good counter, 61,114 visitors.  Wow.  This takes you back, doesn't it?



STEVE:  So I have a puzzle.  I know that the puzzles that I like get a lot of feedback from our listeners.



LEO:  I'm still stymied by the last one, by the way.  I'm, like stuck on Level 5 or something.



STEVE:  Of The Sequence?



LEO:  Yeah, well, not Level 5, maybe Level 10.  Yeah.  Because, well, there was one, and it's like, oh, the things can move another thing.  So then...



STEVE:  Ah, yes.



LEO:  ...that's the one I got stuck on for a while.  And then I figured that out.  Now I'm on the one after that, and I have no idea.



STEVE:  I'm at, like, 49 or something.  I think I'm on 48, two away from finishing that big board.



LEO:  "You're a better man than I am, Gunga Din."



STEVE:  And I'm like, my attention just sort of wandered.  Okay, now, everybody loved Hook. 



LEO:  Yes.



STEVE:  Remember Hook.



LEO:  Yes.



STEVE:  Which was that black-and-white puzzle where you tap little things, and it pulls these little rods back, and you have to do it in the right sequence in order to sort of unhook everything.  And we loved it, and we were uniformly disappointed when we solved the first 50 levels, and there was no second 50 levels.  And so I contacted Hook's author, and I can't pronounce - M-A-C-I-E-J.



LEO:  Yeah, it's a Polish name.



STEVE:  Can you help me out, Leo?



LEO:  I think it's pronounced Sharday.



STEVE:  No.  Really?



LEO:  I'm kidding.  I don't know.



STEVE:  Okay.  M-A-C-I-E-J - I'm sorry I don't know how to pronounce your name - Targoni.  Anyway, I wrote to him with our disappointment that Hook ran out.  And I suggested - oh, and I told him, I said:  "This is why I think the game is perfect."  And I ran through my theory of like the perfect puzzle toy thing.  And he replied, he said:  "I'm thinking constantly about expanding it, but I think I" - and we're talking about Hook now, and this is months ago - "but I think I will just go with a new game.  The main design idea was to add new game mechanics continually, to maximize a-ha moments."



LEO:  Ooh.  That's clever.  By the way, here's the pronunciation.  It's from PronounceNames.com:  "Ma-chee."



STEVE:  "Ma-chay."



LEO:  "Ma-chay."



STEVE:  Right.  "Ma-chay," good.  Thank you, Leo.  So he said:  "At this stage there is not that much interesting things to add.  And I don't want to stretch play time just for the sake of it.  Game has to be fun from the beginning to the end."



And so I replied:  "There's another way to look at it, though, which I will try to explain.  Once someone has acquired a new skill or understanding, it can be fun to simply use that new skill for at least a while, even if nothing further is being learned.  It can just be a pleasant diversion to solve the puzzle, even if nothing more is being learned about the puzzle.  Just working the machine and accomplishing is enough."



And I wrote:  "Perhaps the best example is the enduring popularity of crossword puzzles or Sudoku.  The people who enjoy them are perhaps getting a bit better at them over time, but the pleasure is just in using their brain to work out this particular solution, which always changes."  And of course we've also run across Infinite Loop, which is a lot of fun, and Infinite.  So it was that notion.  And so what I proposed to him even before Infinite Loop was discovered, I said I wondered "whether it would be possible to create a Hook level generator which is capable of endlessly creating Hook levels by itself.  That could be a Hook Pro or Hook Ultimate, which people could play and play and play, just for the pure pleasure of solving different Hook puzzles."



And finally he replied:  "It's my second 'serious' game, so I think I can do better."  He says:  "I will stay within puzzle genre and keep exploring it, looking for unique ideas.  And my design will keep on going in the direction you are calling a 'sweet spot'  slow progress, relaxing, no timers, no rush, no three-star reward system."



LEO:  Steve, you actually have people designing games for you now.  To your criteria.



STEVE:  No, but I'm trying to encourage the world to produce more puzzles that we like.  So this is a dollar.  It's 99 cents, available for iOS and Android and Steam.  Now, Leo, if something's available for Steam, what does that mean?



LEO:  It's on PCs.



STEVE:  Okay, cool.



LEO:  And actually, oftentimes, if it's Steam, it's also on Macs and Linux.  It just depends if the developer makes it portable.  But Steam is a game store on PCs, basically.



STEVE:  So let me be clear.  He has done it again.  And it is so - it's just right.



LEO:  Good.



STEVE:  There's no instructions.



LEO:  Nope.



STEVE:  He just presents you with something, and you go, okay, and you start poking at it.  And then you begin to figure out how it works and what it does.  And it's funny reading what he wrote because he described his intention, which is here, because this starts out simple, but then it evolves.  It adds new features.  And the one with the black dots threw me for a while.  I was solving them, but I didn't know why.  Now I understand what they're about.  And so, and I've not finished it.  So, and I've gone deep.  So I don't think this thing is going to exhaust itself and disappoint people too quickly.  So top recommendation, from the original author of Hook, for a dollar on iOS, Android, and Steam.  Oh, and it's called Klocki, K-L-O-C-K-I.  I've got links in the show notes.  The website is KlockiGame.com.  K-L-O-C-K-I-G-A-M-E dot com.  Klocki, K-L-O-C-K-I.  I think everyone's going to have a lot of fun with it.



I wanted to quickly mention, we've been having great success with the evolving Healthy Sleep Formula.  The number one reported side effect, aside from sleep, which is the intended goal, is exactly what you experienced the first time you tried it, Leo.



LEO:  Yeah, yeah.  I've had it happen again.



STEVE:  Headaches and groggy hangover in the morning.



LEO:  Yeah, yeah.



STEVE:  The solution is to cut the dose in half.



LEO:  Okay.



STEVE:  That big monster pill, that 1,500-milligram niacinamide, it turns out, if you just bring a sharp edge down in the center of it, it just breaks into two pieces.  And it's time-release, but it's time-release mass.  So cutting it in half doesn't destroy the time release.  I've run it at half dose.  Works perfectly.  And everybody who reported a headache and grogginess in the morning had it resolved and no more grogginess.



LEO:  Okay.



STEVE:  So it was just for some people who are more sensitive, the whole pill is too much, and the half pill - and so what I was curious about was whether half of it would relieve the side effects that are negative while preserving the function, and it does.  Now, here's the bad news.



LEO:  There's no niacinamide to be found anywhere in the United States of America now, thanks to you.



STEVE:  There isn't.



LEO:  Really?



STEVE:  There isn't. 



LEO:  You've got to start a side business.



STEVE:  I kept adding links:  Amazon, then iHerb.  Then they sold out.  Then I added Swanson.  They sold out.  I added Vitamin Shoppe.  They sold out.  I added Drugstore.com.  They sold out.  I added eVitamins.  They sold out.  So Amazon, iHerb, Swanson, Vitamin Shoppe, Drugstore.com, and eVitamins.  Nobody has it.  I was exchanging tweets last night with somebody who spoke to Source Naturals, and they said, "We don't know what has happened.  But something has happened."



LEO:  I would imagine that the demand for niacinamide has been very consistent over the last 50 years.



STEVE:  And low.



LEO:  And all of a sudden, you know, "We've been making 150 pills a day for as long as I can remember."  And then suddenly, "We sell that many a minute now."  Of course they don't.  It's like, what happened?



STEVE:  Yeah.



LEO:  But I'm actually thrilled to hear that because, if I cut it in half, then it's really not even - what is it, then, 250?  How big is that pill?  It's a horse pill.



STEVE:  It's 1,500, so it's 750.



LEO:  750.  And then one milligram, one milligram of melatonin time-release.



STEVE:  Yes.



LEO:  Good, I'll try it.  Now it's even less and more, you know.  You know.



STEVE:  And it's far away from any concern, yes.  And there isn't any.  So anyway, so when I get a chance, I'm going to talk to Source Naturals.  He said that they said they're not going to have any until the - I think he said the end of September.



LEO:  Chinese niacinamide shipments.



STEVE:  Well, and that's the other problem, is there are only two time-release niacinamides.  The other one never worked for me.  So it's probably not very delayed.  And so this is, unfortunately, this Source Naturals is the only one I know.  Now, what I would love to do would be to have them cut it to maybe a thousand milligrams and add a milligram of melatonin.  Then they would have a single beautiful little time-release happy night pill.  So anyway...



LEO:  That's the name of this show, by the way, "Steve's Happy Night Pill," available in pharmacies.



STEVE:  And Leo, 2,000 people a day now, every single day - it was at 3,500 for a while - 2,000 people a day go to that page.



LEO:  Wow.



STEVE:  And they just sort of take it for granted, "Oh, yeah, now I sleep perfectly.  You've changed my life," blah blah blah.  So I appreciate it.



LEO:  Well, I'm saving it for my trip to Paris because jet lag's a bitch.  And so I'm looking forward to having something that can help me with that.  Anything that can help me with jet lag is going to be...



STEVE:  I've found yet another way of telling our listeners about SpinRite.



LEO:  Uh-huh.



STEVE:  Not that anyone who's been listening for long doesn't know.  But yesterday at 9:26 a.m. Emett Speer sent me a tweet.  He said - and this was the second of two.  He said:  "I also wanted to add that I am an owner of SpinRite 6.  I was trying to get my company to purchase a corporate SpinRite 6 license by purchasing four, for use on the many PCs they own.  I demonstrated its abilities by using it to recover a dead RAID 6 array for a customer who was in a panic to get their data back.  The company and customer were grateful that I was able to recover the full system with no data lost, but they didn't get SpinRite for our PCs."



To which I say, well, win some, you lose some.  I'm happy to have performed a service.  They now know that it works.  In some neuron in their head they've stored that information.  So next time the CEO's machine dies, just after pulling all of his financial data together, and he doesn't have a backup of it yet, Emett can say, you know, go over here and buy a copy.  So Emett, I appreciate you exposing them.  And, boy, for a RAID 6 array to need SpinRite, that's negligence because in a RAID 6 you have two drives of full redundancy.  Any two drives can fail, and you're still okay.



LEO:  And apparently they did.



STEVE:  So three drives had to fail in order for this to be a problem.  So the flipside is that makes SpinRite's job much easier because it only needs to recover one of the three drives.



LEO:  Right, right.



STEVE:  In order to bring the RAID back.  And then you can do a rebuild of any that it can't recover.  So SpinRite in the era of RAID still makes sense.  And again, Emett, thank you for providing that news.



LEO:  And actually SpinRite would still work on a ZFS disk on FreeBSD.  You just have to boot it in FreeDOS.



STEVE:  Yup.



LEO:  Because it doesn't care what the file system is.  It's not looking at that.



STEVE:  Yup, exactly.  So we talked last week about Facebook's addition of secure end-to-end encryption as an optional feature to Facebook Messenger.  And they call that Secure Conversations.  So you're able to essentially promote an interaction with Messenger to a Secure Conversation, sacrificing Facebook's server monitoring of the dialogue, which means that some features you may use for standard messaging would no longer be available.  But that's the tradeoff with essentially putting your communications in a secure tunnel.  And last week I mentioned that the whitepaper explained some additional features that we ran out of time - we had a full two-hour podcast last week.  And so I thought, okay, let's - I want to get into this and look at it and understand it.



So abuse reporting and secure storage management they detailed.  And those of our listeners who enjoy crypto puzzles will like this.  Facebook has layered on top of the Signal protocol what they call "franking."  So the idea is they're concerned about abuse of service, that is, abuse of their terms of service, in encrypted conversations, because if it's encrypted end-to-end, they can't see them.  They're not able to perform any kind of filtering, for example.  So they had to come up with a way, without violating privacy, to allow the recipient of a message which they found objectionable to be able to report it in a fashion that was cryptographically sound.  Which would mean, of course, first of all, they wouldn't see the communication until and unless it was reported.  And if it was reported, then they needed the property of nonrepudiation, that is, they needed a system whereby the sender was unable to say, "I never sent that.  The person receiving it made that up.  That didn't happen."



So, "Any participant in a secret conversation may voluntarily notify Facebook of abuse of content they receive."  Technically they could notify Facebook of abuse of content they send, but I don't think that seems likely.  "Facebook uses such reports to identify users who violate," writes Facebook, their "terms of service.  The ability to report abuse does not relax the privacy guarantees inherent in the endtoend encryption of Secret Conversations.  Facebook will never have access to plaintext messages unless one participant in a secret conversation voluntarily reports the conversation."



Okay.  So here's how this works.  So we have the sender of any message must incorporate what they call a "franking tag," which is appended to and then encrypted with the message.  And the franking tag actually is just a cryptographic signature that we've talked about often.  In this case, the sender on a per-message-sent basis creates a nonce, a 256-bit one-time random number.  They use that as the key to an HMAC.  Remember that an HMAC is a hashed message authentication function, in this case an HMAC 256.  So they have their conversation.  I'm sorry, they have their message.  They make a random number, and they first stick it on the end of the message.  Then they use that random number as the key to hash the message, which generates a signature.  That signature is the franking tag.  And then, after getting the franking tag, they destroy that random 256-bit nonce.  Don't need it anymore.  So it's at the end of the message, and it is the key to the keyed hash that generates the signature, which is the franking tag.



So the sender of any message must incorporate that franking tag into the message and send it along - oh, and then they use their own keying, their existing cryptographic key in order to encrypt both the message and the franking tag as one.  They then send to Facebook, because it's going to go to Facebook and then on to its destination, they send to Facebook the encrypted message and the franking tag.  Now, no recipient of a message will display any message without a valid franking tag, which is validated upon receipt.  So that essentially - so if someone received a message where the franking tag did not validate, the app doesn't show it.  So there's no way to spoof or change the message in a way that the franking tag would not detect.



So the recipient would decrypt the message using, again, the same secret key that they had previously negotiated.  Then at the end of the message would be the nonce that the recipient generated.  So they would take that and validate the franking tag by using that to key the same HMAC function feeding the same plaintext plus that nonce through the HMAC to get the franking tag.  So that's at the far end.  Now, in the middle, Facebook receives from the sender that message plus the franking tag.  Facebook then uses their own secret key, which they keep secret, private, to key another HMAC where they concatenate the franking tag with what they call the "conversation context," which is the sender and recipient identifiers and the timestamp.  And this creates the reporting tag.



So Facebook then sends that reporting tag, the franking tag, and the encrypted message blob that they could not see into, all to the recipient.  The recipient, as I said, verifies the franking tag and, if it's verified, will display the message.  Now, if the recipient finds the message objectionable, they're able to, and Facebook said they're still working on the UI for this phase, and so they don't have it yet.  But the recipient can push a button to report the sender as having sent this.  So what that button will do is return the reporting tag, the franking tag, and the plaintext which the recipient has seen and found objectionable, all to Facebook.



What that then allows is for Facebook to perform all the verification, because it will have the plaintext of the message.  That'll contain the nonce that it never saw before, and the franking tag.  And the franking tag was bound into the reporting tag, which is HMAC'd under Facebook's own private key.  So Facebook again uses their private key to validate that nothing has changed, and that allows them to absolutely cryptographically verify that the sender sent what the recipient claims because their identities are bound in; also that the sender sent it when the recipient said because there's a timestamp bound in.  And you can't change a bit anywhere, or the whole thing refuses to go.



So there is the abuse reporting mechanism which Facebook added to the secure communications in a way that doesn't violate security, but creates non-reputability of a message received that somebody finds objectionable.  And only if a message is reported does Facebook ever see the plaintext.  And that comes from the decrypted recipient who says, I don't like what this person just sent me.  So they nailed the crypto.



LEO:  That's good.



STEVE:  It looks like they got it exactly right.



LEO:  That's really - and so significant that they're effectively bringing this to a billion and a half people.



STEVE:  Yes.



LEO:  That's just incredible.



STEVE:  Yes.  I should note that WhatsApp is dark again.



LEO:  In Brazil, yeah.



STEVE:  In Brazil.



LEO:  Just in time for the Olympics.



STEVE:  Yeah.  And this, apparently, I don't know how long this will last, but a judge has ordered the service suspended until further notice.  Essentially, until WhatsApp complies with a court order.  Which is impossible.



LEO:  What's awesome is Telegraph and Facebook Messenger and all sorts of other messenger programs, I hope Secret and Threema, too, are getting a lot of traction because of it.  This is one of the programs that almost everybody in Brazil uses.



STEVE:  Yeah.  Another aspect of Messenger is called Secret Conversation Secure Storage.  So, okay.  So now we have Messenger, and we're interacting with a user, and we're wanting secret conversations.  But clearly we need them protected on our mobile device, whatever that is.  That is, they need to be encrypted.  Yet Facebook also wants the expected features to work.



So Secret Conversations, the plaintext messages, after decryption are stored permanently only on the device that participates in each conversation.  And of course it does Facebook no good to store a blob in their server because they can't decrypt it.  So it moves through.  So it's decrypted at the receiving end.  And of course there's also, in order to have a two-sided conversation log, you're storing what you sent and then what you received in response in a chain.  Plaintext messages are protected using on-device symmetric key encryption.  And there's an optional disappearing messages functionality which, okay, those are always kind of flaky because it's technically impossible to enforce that, as we know.  But it's there because people want it.  It's kind of, I guess, they think it's a cool feature.



On-device encryption ensures that messages stored permanently on a particular device are only accessible while a user is authenticated to Facebook.  So in the design of this, Facebook's operational requirements were that Messenger would allow users to switch Facebook accounts.  While a second user is logged into a particular device, messages of the first user are not accessible.  But when the first user returns to the same device, they will find their messages reconstituted and available.



So to achieve those requirements, the clients on the endpoints employ two encryption keys, a local key and a remote key.  And both of those keys are used for AES-GCM encryption.  That's the right way to do encryption.  It's what SQRL uses for its identity encryption because it is a simultaneous encryption and authentication.  And if you don't authenticate, you don't get any results out of decryption.  So it's a nice hybrid.  We talked about do you encrypt, then authenticate, or authenticate, then encrypt?  Because if you need to do both, the GCM cipher does both at the same time.



So the local key is generated on the device and never leaves the device it was generated on.  It is used to encrypt the plaintext messages before they're stored permanently on the device.  So that local key, as messages, as the conversation chain is being stored in nonvolatile memory, it runs through this local key in order to perform AES-GCM, which is a symmetric cipher.  The remote key is a long-term, per-user specific key held at Facebook and delivered on the fly to the device when a user authenticates.  Which is really interesting.  That means that, if you're not logged into Facebook, if you're not authenticated to Facebook, those secret conversations are encrypted, and they're not visible.  You get access to them by logging onto Facebook.



Facebook then sends your specific per-user remote key to the device.  It's used to decrypt the local key, which you are then able to use to access your conversations.  And of course when you log out the remote key is removed, and the local key is wiped, that is, the plaintext version.  So you only have your encrypted copy, the local key, ready to be decrypted by the remote key the next time your particular Facebook account is logged into on the device.  So, again, clean, simple, not lots of bells and whistles, and as good a secure storage solution as you could ask for.



Where there are additional hooks available in the platform, for example, iOS has a bunch of goodies, Messenger on iOS absolutely uses the various - I can't remember, there's a whole series of tags, basically property tags that you're able to give things.  So you're able to say, like, tag that database as never decrypt when the user's not logged on tag.  And that's enforced by the operating system in addition to the Facebook app.  So it's taking advantage of the platform's features when they're there, and doing a useful job of protecting the user so that their secret conversations are not available when they're not logged into Facebook.



And then lastly, the disappearing messages is nothing fancy.  It just adds a timestamp to the messages; and, when the timestamp expires, the message will no longer display.  And as I said, eh, it's like, okay, I guess it's kind of a fun feature; but again, not cryptographically secure by any means because it's just checking to see if it should display it or not based on a timestamp.  There's no actual way that we have yet of robustly, proactively, retroactively, I guess, removing a message that was transferred and decrypted onto a device.  You just can't make it go away unless it's going to remove it itself.



Oh, and after the time limit expires, there's a grace period for reporting abuse.  Then it is actually deleted.  So first it's hidden.  And then, to give you a little bit of time to report abuse if you choose to, it remains.  And then it disappears from the storage completely.



CryptoDrop.  I sounded a little negative about it last week.  And based on the results they report, where do I get my copy?  This is the heuristic system watcher which attempts to see ransomware scrambling files on the fly and stop it.  And it performs much better, when I read the whitepaper and got into the details, it performs much better than I would have guessed.  They first analyzed hundreds, literally hundreds of cryptoware samples.  They looked at exactly how the files are handled.  Is it a copy to a spare location and then encrypt and overwrite?  Is it encryption in place?  Is it a secure delete after a file move?  I mean, because there are different ways you could achieve this.



So they looked at exactly what was going on.  Then they found what they called three primary indicators which were suited to detect malicious file changes.  One they call "file type changes."  And as we know, anyone who's looked, for example, at a hex display of a file, like a DOC file or a ZIP file or an executable, there is some clearly identifiable stuff, typically at the beginning of a file, that sort of tells the operating system about what the file contains.



Now, a simple text file doesn't have that.  It's just text.  But anything that's sort of higher level, like a ZIP or an EXE or a DOC, that has some structure to it, that you can always see.  And there's a well-known utility called "file" which determines the file type without looking, for example, at the file extension.  Not all operating systems support extensions.  And extensions are sometimes deliberately changed in order to confuse things.  So it's got, essentially, a magic database containing hundreds of file type signatures ranging from specific programs like Microsoft Word 2007, or just unicode text, and everything in between.  Certainly you could detect zip files and EXEs and DOCs and so forth.  So the looking at the header, the beginning of a file, is one way to determine what kind it is.



And of course something that's going to encrypt it is going to turn that into pseudorandom noise.  So suddenly the file changes its type.  And that's not something you would expect to happen normally.  Then they have something called the "similarity measurement," which uses something called a "similarity-preserving hash function," called "sdhash."  There's a page on the 'Net that describes it, and a lot of work has been done.  It kind of put me in mind a little bit of my longest repeated string concept, although this is used to do sort of fuzzy matching, whereas mine is exact matching.



This is used with overlapping hashes to do fuzzy matching of files and to preserve a set of hashes from a file in one state, or a file at one time.  And then you can use that digest, those hashes, against the sdhash function in the future and get actually a number from zero to 100 of how similar the original file and the current file is.  So clearly that's useful because, again, anything that's going to encrypt a file is going to turn it from something structured into noise, pseudorandom noise.



And, not surprisingly, the third indicator is the Shannon entropy, which is the mathematical description of how random the data is.  As we know, text files have relatively low entropy.  But two things you can do change that.  If you compress it, compression inherently removes entropy from the file because, if there is any entropy left, then there's something more you can compress there.  And the other thing is encryption.  Encryption turns a file into noise, which is super high entropy.



So determining the mathematical, analyzing a piece of the file for its Shannon entropy would give them a quick sense of whether this looks like it's encrypted gibberish or something that has lower entropy and is probably information that something can understand.  So armed with that, they did a bunch of lab testing.  They obtained 2,663 malware samples from VirusTotal, using ransomware-related search terms and known ransomware virus variant names, and essentially ran through - there were many that had tiny variations among them.  So there weren't, like, 2,663 completely different types of ransomware.  We know that's not the case.  But it's versions of TeslaCrypt and CryptoLocker and so forth.  And so they separated that out.  And they ended up settling down to 492 widely differing samples.



CryptoDrop, the application they wrote, detected the behavior of all 492 widely differing samples, quickly protecting the majority of the victims' data with as few as zero files encrypted before detection.  Not always zero, but in some cases the behavior of the tool was something they were specifically looking for, like the copy and wipe the other thing and so forth.  And so they were able to intercept before that happened.  So they said:  "This result highlights the required actions of ransomware and the effectiveness of our indicators at detecting this type of malware."



In terms of descending attack frequency, PDF files were the most often attacked.  Then ODT, DOCX, PPTX [PowerPoint], TXT, then MOV, then ZIP, then MD.  And they of course had to look at false positives because if this thing, you know, this is inherently heuristic.  It's looking at behavior.  And as we know, that can sometimes go off the rails.  So they wrote:  "While CryptoDrop is effective at quickly detecting ransomware, we note that any evaluation of its real-world utility must also include a discussion on incorrect detection of benign activity.  False positive analysis for a system such as CryptoDrop is challenging since its analysis requires changes to be made to a user's protected documents.  Techniques used in static malware analysis works, for example, providing a set of known good binaries along with bad ones, but that will not work since CryptoDrop does not analyze binaries for malicious traits, but rather behavior."



Anyway, so they explain their basis for detecting false positives.  And so they said: "We evaluated 30 common Windows applications" - and in their document they run through them, and they're things we all know - "on the same virtual machine configuration used to test malware samples and found only one false positive.  That false positive was 7-Zip, which was expected, as it reads a large number of files and generates high-entropy output, exactly similar to ransomware."



So these guys have a system which runs in Windows.  I saw that somewhere, and I could not find where this thing was available.  I'm not sure that it is.  But I went from thinking, eh, to thinking, well, okay.  This seems like a good thing to have running in the background, just to, like, stop something before it gets loose, especially if they're able to stop it in its tracks as quickly as they allege they're able to based on their analysis.



So I was very impressed.  So it is heuristic, looking at behavior.  But what ransomware does is enough different from the way we are normally using our computer, with the exception of mass zipping a bunch of files with something like 7-Zip.  And if I were running 7-Zip, and this popped up, I'd be glad because it'd be like, oh, cool, this thing's working.  Because I know what this is.  This is not cryptomalware.  And, yes, thank you very much, I'm going to continue my zip operation.  Don't interfere.  But, boy, if you weren't doing something like this, and it popped up, it would deserve your attention.



So I'm hopeful that, if not now, in the future, we're going to get something like this in an application because that would be great.  And then of course, and they address this on their paper, we're back in the cat-and-mouse game because, if this became widespread and popular, the cryptomalware people would start working on ways around it in the same fashion.  But this looks like a strong tool because it's essentially going after the behavior that is exactly what we want to stop, instead of, for example, looking for byte patterns of a virus, and as a consequence having lots of false positives.



And I'll close the podcast by saying that, unfortunately, this Riffle, which I think was the master's thesis of someone at MIT that generated a lot of news a couple weeks ago, looks like a disappointment.  We talked at length about how Tor works, the idea being that you choose a path through a number of routers.  You get each router's public key.  You then encrypt the data you want to send, first for the last router's key.  Then you encrypt it for the second to the last.  And then you encrypt it for the third of the last, which may be the first.



Anyway, these encryptions form shells of encryption.  You then launch it into the Tor network.  The first router uses its private key to strip off the outer shell, which exposes the IP of the next router in the hop and so forth, the idea being that no one router is able to see where it's going or get in there.  The big problem is, I mean, the fundamental meta problem is the Internet was never designed to provide the kind of anonymity that the Tor network is trying to add after the fact.



So obviously this has been given a lot of attention, and we know that the greatest weakness is a state actor that has visibility into many Tor servers, is able to perform traffic analysis, and essentially catch the traffic going in and associate it with the traffic going out.  And as we've talked about this before, what you're best able to do is validate an assumption.  So you assume this guy's traffic is coming out over here.  That's much easier to verify, that is, to prove the assumption, than to just look at the whole network at once and try to figure out who goes where.



So Riffle said, okay, we're going to do something different.  We're going to come up with a system whose traffic cannot be analyzed.  The unfortunate consequence of that is it makes it completely impractical.  So this has been considered before.  This person's master's thesis made it somewhat less horribly inefficient.  But essentially, everybody in the network has to always send the same amount of traffic into the network at the same time and receive the same amount of traffic at the same time, specifically to defeat traffic analysis.



And then the stuff you send is mixed in - "shuffled" is the term - with other data, and it moves around the network and comes out.  But the idea is that, if all messages are the same length, and everybody is sending the same amount, then you can't do traffic analysis.  It also means you have to send a lot more than you want to and receive a lot more than you want to, essentially to cover for everybody else's use of traffic.  So, yeah, it would work.  But, boy, if people thought Tor was slow, this brings that to a whole new level of pain.



So nothing that we're going to see that we can download and install anytime soon, just an interesting exercise.  Maybe something will come from this.  This moved the state of the art a little bit further forward than it had been before.  But it's got a long way to go before it provides anonymity.  And I would argue that, I mean, that's the kind of solution that unfortunately is required, which demonstrates how impractical it is.  It's just, wow, more effort probably than it's actually worth.



LEO:  And Tor works pretty well.  The only issue is of course a government, a state observer with tentacles all over the place might be able to figure out what's going on.



STEVE:  Yeah, yeah.



LEO:  For the rest of us, I'm not too worried.  It's pretty good anonymity.  Not perfect.  Steve Gibson's at GRC.com.  That's where he hangs his hat and where this show originates, from the magic of GRC.com.  You'll also find SpinRite, the world's finest hard drive maintenance and recovery utility; all of Steve's stuff, including SQRL, which must be close to coming out; right?



STEVE:  Yeah.  If I had more time, I would tell our listeners about some recent improvements.  We made a couple of really very cool things.  So next week.



LEO:  Cool.  All right.



STEVE:  Because we're out of time.



LEO:  More than the mic flag?  I mean, like substantive improvements.  The mic flag's pretty good, though.  I'm not knocking the mic flag.  You only know that if you see the video.  Steve's got his little logo up there.  He also, let's see, has audio and human written transcriptions of the show on his website, GRC.com.



I guess we'll a Q&A next week.  So if you have a question, GRC.com/feedback, or tweet the man.  He accepts the twits, the tweets.  @SGgrc is his Twitter handle, @SGgrc.  He even accepts DMs because he's a madman.  We have audio and video of this show available at our site, TWiT.tv/sn, or subscribe.  That way you'll get every episode.  Every podcatcher has it.  Eleven years and still going strong.  Steve, always a pleasure.  Have a great week.



STEVE:  Indeed it is.  Talk to you next week, my fried.  Bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#570

DATE:		July 26, 2016

TITLE:		Listener Feedback #238

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-570.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I first catch up with the past week's security happenings, including Apple getting Stagefright and speculation as to whether Russia is trying to influence the U.S. presidential election.  Microsoft battles and wins against U.S. privacy overreach.  Grace Hopper, who coined the term "software bug," brilliantly demonstrates a nanosecond.  We've got a bug-fix update to pfSense, a "doing it weird" look at the CUJO security appliance, a bunch of errata, a bit of miscellany, and a dozen notes and questions from our terrific listeners.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and we're going to talk about the latest security news, some good court decisions, some bad court decisions, and of course it's question-and-answer time.  And we've got not one, not two, not 10, but 12 question from you, our audience.  Steve will answer them in an amazing display of intelligence, acumen, and perspicacity, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 570, recorded July 26, 2016:  Your questions, Steve's answers, #238.



It's time for Security Now!, the show where we cover the security of your stuff.  And this is the guy who does it, Mr. Steve Gibson from GRC.com.  Great to see you again.  Happy Tuesday, Steve.



STEVE GIBSON:  Great to be back, Leo.  We've got a bunch of interesting stuff.  Not a ton of security news, so I did a dozen Q&A questions from our listeners, rather than our usual 10, sort of judging how long this is going to go.  But we have the news of Apple getting Stagefright, essentially.  The question of whether Russia is trying to influence the U.S. presidential election.  Microsoft's battles and wins against U.S. privacy overreach.



Something so cool, and I thank one of my Twitter followers, or one of our podcast followers sent me a link to Grace Hopper, who of course famously coined the term "bug," that's where "bug" came from, brilliantly demonstrates a nanosecond, shows us a nanosecond, and also relates it to a microsecond, I think it is.  Maybe it's millisecond.  I think it's microsecond.



There's a bug fix update to pfSense.  I don't really have a "doing it wrong," I have a "doing it weird."  Which is a bizarre look at what a consumer security appliance known as CUJO does, the way it connects to a network.  Just kind of unnerving.  We have a bunch of errata, a sort of an embarrassing quantity, frankly, of errata.  A little bit of miscellany, and then a dozen notes from our listeners.



LEO:  Don't you be embarrassed, Steve.  Everybody makes mistakes.  The only measure is...



STEVE:  Well, these are good ones, so....



LEO:  ...how quickly you correct them.  



STEVE:  These are good ones.  I won't step on it by giving it away.  Our Picture of the Week is a snapshot from "Star Trek Beyond."



LEO:  Oh, did you see it?



STEVE:  Oh, yeah, of course.



LEO:  Of course.



STEVE:  On opening day.  That's really important.



LEO:  You are serious.



STEVE:  So I called it "an engaging action film set in our J.J. Abrams rebooted Star Trek universe."



LEO:  Right.



STEVE:  And I think that's the way to frame it.  I mean, it's an action film.  I know that there are diehards that want more Roddenberry-esque meaning of the Federation, I mean, and there was homage to that.  But mostly it was a lot of fighting, more than I needed.  But I liked the movie, I mean, it was Star Trek.  And lots of beautiful...



LEO:  Aliens.



STEVE:  ...consoles, and I like the new crew.



LEO:  You were going to say consoles.  I said aliens.  But they were both beautiful, yeah.



STEVE:  Yeah.



LEO:  Good blinkin' lights, in other words.



STEVE:  And she really can't act very well, that blonde.  It's like, oh, goodness.  But, you know.



LEO:  It's hard to act when you're wearing whatever that is on her head.



STEVE:  And actually, some of the lines they have to say, like, "Where is your home planet?"  There's no way you can say "Where is your home planet" with, it's like...



LEO:  Yeah, where are you looking in your inner life, your prior experience, to give that some depth?  And who knows, I mean, yeah.  Let's move on.



STEVE:  So Cisco's Talos security group we've talked about actually more and more recently.  These guys are doing a great job, sort of in the same way that Google's team is, looking at, just in general, at things in the industry and giving them a onceover.  And in this case, Tyler Bohan of Cisco Talos discovered five remote execution code vulnerabilities in various pieces of image-rendering code in OS X and also iOS, that is, in the latest versions before this very recent update.  So he of course did responsible disclosure, informed Apple.  They fixed it.  And so once the patches were out and available, we got the news of that.



And so I called this a Stagefright bug because it's very reminiscent of Stagefright.  As we know, of course, the Stagefright was dogging, or actually still, really, is a module dogging Android because it handles a lot of the media processing.  And in the case of Android, when we first saw Stagefright happen, it was just receiving a multimedia SMS, an MMS message, that the image in the multimedia event would automatically be processed by the Stagefright module and, because there was a mistake there in the parsing of the image, it would allow a bad guy to essentially put their own code in with the image and get it to execute.



Well, Apple got hit by the same thing, and in a very similar way.  One of the things we've been talking about the last few months is the difficulty of not making a mistake when you're coding an interpreter because an interpreter, the person coding an interpreter sort of assumes that what it's interpreting will be sane, that it's going to interpret valid input because why wouldn't it?  Well, it turns out bad guys have exactly the opposite approach.  They look for subtle mistakes in the interpretation path that they can take advantage of.



So in this case, and there was an interesting lesson here we'll get to at the end, the big mistake was in Apple's handling of, believe it or not, TIFF files, the Tagged Image File Format, which I'm having to tell people what TIFF stands for because unlike PNG, JPEG, and GIF or GIF, however you pronounce it, few people these days even see a TIFF file.  But in case one comes along, the code is still there for handling it.



So what Talos wrote I thought was just so good, I couldn't even paraphrase it without changing anything, so they said:  "The Tagged Image File Format is a file format that's popular with graphic artists, photographers, and the publishing industry because of its ability to store images in a lossless format.  TIFF was created to try to establish a common scanned image file format in the mid '80s.  Cisco Talos has discovered a vulnerability in the way in which the Image I/O API parses and handles tiled TIFF image files.  When rendered by applications that use the Image I/O API, a specially crafted TIFF image file can be used to create a heap-based buffer overflow and ultimately achieve remote code execution on vulnerable systems and devices.



"This vulnerability is especially concerning as it can be triggered in any application that makes use of the Apple Image I/O API when rendering tiled TIFF images.  This means that an attacker could deliver a payload that successfully exploits this vulnerability using a wide range of potential attack vectors including iMessages, malicious web pages, MMS messages, or other malicious file attachments opened by any application that makes use of the Apple Image I/O API for rendering these types of files.



"Further, depending on the delivery method chosen by an attacker, this vulnerability is potentially exploitable through methods that do not require explicit user interaction since many applications, i.e., iMessage, automatically attempt to render images when they are received in their default configurations.  As this vulnerability affects both OS X 10.11.5 and iOS 9.3.2 and is believed to be present in all previous versions" - again, this is old code - "the number of affected devices is significant."



So I sent out a note, I think it was just yesterday, as I was digging into this more because I was aware of 9.3.3, that is, iOS 9.3.3.  But I think maybe only one of about, I don't know, I have, like, 12 iOS devices I manually updated, not a single one of them did that by itself.  And so I wanted to alert everyone, you know, this would be a good time to go just check to see if there's an update available, and probably it'll say yes, we've got one.  And it's like 50MB and requires the regular reboot and restart and so forth.



But for what it's worth, and for whatever reason, not one of my devices did this on its own.  And for something like this, this doesn't want to hang out there for too long because, as we know, once bad guys realize there is an exploitable flaw, especially in iOS, where these generally are rare, and these guys didn't talk about what privilege the execution code would have, but it may very well be highly privileged execution, this could be bad.



So that's one of four.  I won't go into the same detail with the other three, or at least the middle two.  One was a similar problem, and again, a remote code execution in the OpenEXR file format.  And actually there were two vulnerabilities there.  And the TIFF only had one vulnerability.  They also found a problem with the Digital Asset Exchange File Format, one vulnerability.  And then also in the BMP, old standard Bitmap File Format.



And they wrote, they had a little short write-up for that.  They said:  "The BMP file format is both longstanding and has a fairly straightforward structure.  The BMP file header contains information about the size, layout, and type of image.  A vulnerability exists within the way that the height property of an image is handled.  This can be exploited when a specially crafted BMP image file is saved, then opened, and part of the size information is manipulated."



LEO:  Yeah, let me guess, it's more than 65,635 pixels tall or something; right?



STEVE:  Yeah.  "The exploit leads to an out-of-bounds write, resulting in remote code execution when opened in any application using Apple Core Graphics API."  So then, to paraphrase a little bit, they said:  "Image files are an excellent vector for attacks since they can be easily distributed over web or email traffic without raising the suspicion of the recipient.  These vulnerabilities are all the more dangerous because Apple Core Graphics API, Scene Kit, and Image I/O are used widely by software on the Apple OS X platform."



Then they said:  "Organizations should patch software to the latest release in order to resolve these vulnerabilities.  Additionally, organizations may wish to consider blocking" - and this is what I wanted to get to - "should consider blocking files at network gateways if the file is of a type that is never, or very rarely, going to be encountered within the legitimate business of the organization."  For example, TIFF files.  And that's significant because most companies could completely sail along with no TIFF files crossing their Internet to Intranet boundary.  It just, you know, you just don't run across the file format any longer.  Yet it's still supported for legacy reasons.



So sort of in the same way that we've switched our firewall concept from block what's bad and allow everything else, we've switched it around to drop everything, that is, block everything, and then selectively open the traffic that we know we want.  It really does make some sense to consider where you have the ability to do content filtering to look at all the file formats that are around.  And if you don't recognize them, you probably don't need that.  And just say, eh, no.



I mean, the worst that could happen is an exception would have to be made in a specific instance.  But, for example, anyone who had that kind of firewall up, who was blocking TIFF files because when's the last time you saw one go by, even if this were exploited in a zero-day fashion - and as far as anyone knows it has never been exploited, that is, Apple fixed this before this got out because Cisco Talos reported it responsibly.  But the point would be that this is the kind of thing that, if you were preemptive, your corporation would be protected, even if it were found.  And it generally is this legacy code that tends to bite people.  And happily, things like Flash are becoming legacy as we move to HTML5.



So you want iOS 9.3.3 or OS X 10.11.6 or later because those releases have these things fixed.  And again, I had to do it manually.  So I would suggest iOS users who are concerned about this, just make sure that your devices are running the latest.  Do you know, Leo, what the schedule is for this, like the updates?



LEO:  So because Talos told Apple before they revealed it, Apple was able to update last week iOS, El Capitan, tvOS because it's in the Apple TV, and watchOS because it's in the Apple Watch.  So those are all fixed.  One of the four vulnerabilities is not patched on Mavericks and Yosemite, older versions of OS X.  So that would be the only place you'd have to worry.  But of course you want to make sure everybody updates.  And not everybody does updates.



STEVE:  So is it an iOS user's responsibility...



LEO:  Yes.



STEVE:  ...to go get the update?  Apple doesn't notify you?



LEO:  Yeah, you'll get a notification.  But you may not get it right away.  You may get - or you may just see the icon, the settings icon badged, that kind of thing.  So everybody should do it.



STEVE:  I sometimes do run across my devices that have a fingerprint scanner, it'll say, oh, you have to enter your passcode after a restart.  And I think, well, it worked yesterday.  So apparently the device restarted itself at night for some reason, maybe to perform a silent upgrade like that.  



LEO:  I'm sure Apple has the capability.  I don't think it does that.  I don't think it did it with 9.3.3 on iOS, but maybe.



STEVE:  Yeah, it didn't on any of mine.



LEO:  No, yeah.



STEVE:  So, okay, this is weird.  And I have to cover it because we're Security Now!, and we're now in the second week of the two-week election conventions.  And there's all this in the news about the claims that Russia may have been involved in hacking a Democratic National Convention staffer's email account and actively involving itself by selectively releasing some emails in the U.S. election outcome.  Now, of course, I don't know whether that's true or not, so I can't comment on that.  That's what's in the news.



Multiple analysts have confirmed that Russian state actors did penetrate the DNC email system, and also apparently some personal email accounts of DNC staffers, which, I guess because they were consultants, they were also using to conduct DNC business.  The leaks came through WikiLeaks, yet Julian Assange is refusing to provide any attribution of the source either way.  So he's saying, you know, the people who give us tips require and ask for anonymity.  That's what we're providing.  So there's no confirmation there.  But Michael Isikof, who's a respected reporter, did report on this.  And I have a picture in the show notes of the pop-up that this DNC staffer was apparently receiving for days.



LEO:  And ignoring.



STEVE:  And ignoring, ignoring.  So Michael writes in his coverage:  "Just weeks after she started preparing opposition research files on Donald Trump's campaign chairman Paul Manafort last spring..."



LEO:  By the way, I'm glad to see she's using Yahoo! as her home page.



STEVE:  I was going to say, you know.  I have a hard time taking Yahoo! seriously.  I don't know what it is.  I just - I never have.  It just always seemed like maybe a step above AOL, but as Mom calls it, AWOL.



LEO:  But she obviously took a picture of this, so she must have wanted - she must have thought about it.



STEVE:  Well, okay.  So Michael reports:  "Democratic National Committee consultant Alexandra" - I guess this is Chulapa.



LEO:  Chalupa, just like at Taco Bell, yeah.



STEVE:  And I was thinking, isn't that a hot sauce?  But I think that's Cholula.



LEO:  Yeah.  But there is a Chalupa which is a Taco Bell treat, yeah.



STEVE:  Okay.  So Alexandra Chalupa got an alarming message when she logged into her personal Yahoo! email account, and it reads "Important action required" as the headline in bold.  Michael says:  "...read a popup box from a Yahoo! security team that is informally known as 'the Paranoids.'"  In this case, not so much.  Or as they say, even if you're paranoid, it doesn't mean that they're not trying to get you.  Then it continues in this dialogue:  "We strongly suspect that your account has been the target of state-sponsored actors."  Now, maybe she thought that meant...



LEO:  A mime troupe.



STEVE:  ...Alan Alda, you know, or Clint Eastwood.  I mean, I don't know, like she didn't understand...



LEO:  We've got a Chinese mime troupe in here.  We've got...



STEVE:  Yeah.  So then...



LEO:  But she did take - somebody took a picture of it.  I mean, she must have taken a picture of it; right?



STEVE:  Well, she reported it.  So get this, though:  "Chalupa,  who had been drafting memos and writing emails about Manafort's connection to pro-Russian political leaders in Ukraine, quickly" - and I put in my notes, quickly? - "quickly alerted top DNC officials, saying, and I guess this was her interview by Michaels:  'Since I started digging into Manafort' - get this - 'these messages have been a daily occurrence on my...'"



LEO:  Oh.



STEVE:  How pesky.  These pesky pop-ups warning me of state actors "have been a daily occurrence on my Yahoo! account despite changing my password often."  And, I mean, I'm just gobsmacked.  It's like, okay.  Didn't go to Gmail.  Didn't decide to get a DNC account.  Just thought, well, I'll change my password.  Oh, look, another one of these pesky "important action required" messages.  Wow.  And then "A Yahoo! spokesman said the pop-up warning to Chalupa 'appears to be one of our notifications' and said it was consistent with a policy announced by Yahoo! on its Tumblr page last December to notify customers when it has strong evidence of 'state-sponsored' cyberattacks.  Bob Lord, the company's Chief Information Security Officer, wrote in that Tumblr post:  'Rest assured, we only send these notifications of suspected attacks by state-sponsored actors when we have a high degree of confidence.'"



LEO:  I think Google does this, too.  These are not - this is not just Yahoo! doing this.



STEVE:  Yeah.  I mean, what you'd like is your account is locked forever.  Go find a real email system.  Anyway, who knows how they got in or how they managed not to get shaken off by her frequent password changes.  But the idea that she was getting these daily and continued writing emails and memos in the face of notifications indicating that state-sponsored actors were hacking her account, again, we...



LEO:  What should she have done?  I mean, you know, what should she have done?  Called the FBI?



STEVE:  I would say, I mean, okay.  So she should have immediately reported it to the DNC, and they should have said, okay, stop using Yahoo! Mail.  We'll set up an account for you at the DNC to use for DNC-related business.



LEO:  But the DNC was hacked, too.



STEVE:  Yeah, that's not good.



LEO:  So it doesn't - I wouldn't blame her too much.  I mean, normal people, when faced with something like this, I mean, I don't think...



STEVE:  And it did, Leo, it had a very clear little X in the upper right-hand corner.  Just like that...



LEO:  Close this because it could be wrong.



STEVE:  ...that pesky notice goes away.



LEO:  Right, could be wrong.  I mean, it doesn't - it's not definitive.



STEVE:  So we didn't mention here, although you did cover it over the weekend, Microsoft's successful outcome with the New York-based or located Second Circuit Court of Appeals in this issue of our U.S. domestic law enforcement back in 2014 issuing a subpoena or a warrant for them to provide information that was stored out of the U.S. in Ireland.  So this is the Second Circuit Court of Appeals sided with Microsoft in this case over whether the U.S. government could force the tech giant, Microsoft, and other companies to hand over customer emails stored overseas.  So this appellate decision "reverses the original 2014 court order requiring Microsoft to turn over email which was stored in a server in Ireland."



So that decision happened two years ago.  Microsoft said, "We're going to appeal it," and they did, and they won on appeal.  And this was a narcotics case that these emails were believed to be connected to.  A judge, Susan Carney, with the Second Court of Appeals, "found that the federal Stored Communications Act only applies to data stored in the United States, and thus cannot be used to force a company to produce information from servers outside the country."



So now, with their original warrant invalidated, the government must proceed through a much lengthier process to set up something called a "mutual legal assistance treaty" with the Irish government to obtain the data.  However, Ireland filed a brief supporting Microsoft in this case, and they were joined by a bunch of other tech companies including Apple and Cisco.  So it's not clear how cooperative Ireland is going to be in this.  I mean, again, we're in this new place where we have strong crypto.  We have a well-connected global Internet and pesky things like national boundaries, that never used to be a problem, we now have to deal with as this information flows freely across borders.



LEO:  You don't, I don't think, in your show notes mention another court decision using the Computer Fraud and Abuse Act.  It was against a company that was scraping Facebook information at the request of Facebook users.  Oh, my gosh, this is a good one.  Basically it says that, if you use somebody's website against their permission, you're violating the CFAA, and it's a felony.



STEVE:  Oh.



LEO:  So if I put a big sign on here that says, "Hey, Steve Gibson, you may not use this website," and you do, you could have some serious consequences.



STEVE:  Wow.



LEO:  Yeah.  This is the California Court of Appeals.



STEVE:  Ninth Circuit, probably.



LEO:  Yeah.  I don't - yeah.  So the issue was Power Ventures invited Facebook users to sign up.  And then, as usual, give us access to your contacts, whatever.  And they did that.  And then Facebook sent them a cease-and-desist letter saying stop.  And they continued doing it, and then of course the court battle ensued, and the judges say, no, no, once you got that cease-and-desist, you're violating the CFAA if you log in again.



STEVE:  Ooh.



LEO:  Even if the user asks you to.



STEVE:  And so that got overturned?



LEO:  No, no.  That's the decision.



STEVE:  Oh, no.



LEO:  It's a felony.



STEVE:  So it hasn't gone to appeal yet.



LEO:  Well, it would have to go to the Supreme Court.  The Ninth Circuit...



STEVE:  Oh, the Ninth Circuit upheld the CFAA?



LEO:  Upheld.



STEVE:  Oh.



LEO:  They sided with Facebook.



STEVE:  Wow.  The courts...



LEO:  They taketh, and then they giveth away.



STEVE:  That's the end of life as we know it.



LEO:  Well, it could be.  I mean, it just depends.  I still think a judge can decide not to do it.  But...



STEVE:  Yeah, this is bad precedent, though.



LEO:  Oh, yeah.  If Twitter says, hey, Nero, if you log into our site, you are now violating a federal law, and you could go to jail for a long, long time.  The CFAA really is a blunt weapon and is often misused, as we know.



STEVE:  And in fact we were talking about it last week, that one of the problems - and I kind of got a little carried away talking about it, that some of these things start off being sharp; but in order to pass, they're deliberately blunted.



LEO:  Right.



STEVE:  In order to not hurt various factions' feelings and in order to essentially buy their votes by weakening the law.  And, wow.  Ooh, boy.



LEO:  You know, that's one of the things, unfortunately, I mean, we're going to have to operate on the, come November, on the state level and the local level because it's something neither presidential candidate knows anything, has any information at all about.  But the President's not the person who's going to decide, it's Congress.  So just keep these things in mind when it comes around November time, and vote for someone who does know.



STEVE:  Okay, now, the audio for this video is low, so you'll need to turn the audio up a little bit, Leo.  And it's only two minutes.  I think we should just play it into the podcast.



LEO:  Absolutely.



STEVE:  And then I'll give everybody an easy way to find the link.  This is Grace Hopper.



LEO:  Admiral Hopper.



STEVE:  Who was - she was Navy; right?  I think she was Navy.



LEO:  Yeah, she was an admiral.



STEVE:  Yes, and an early programmer of the early mainframes, who coined the term "bug," who is explaining, brilliantly, the concept of a nanosecond, and then relating it to a microsecond.



[CLIP]



GRACE HOPPER:  They started talking about circuits that acted in nanoseconds, billionths of a second.  I didn't know what a billion was.  I don't think most of those men downtown know what a billion is, either.  And if you don't know what a billion is, how on earth do you know what a billionth is?  I fussed and fumed.  Finally, one morning, in total desperation, I called over to the engineering building, and I said, "Please cut off a nanosecond and send it over to me."  And I've brought you some today.



Now, what I wanted, when I asked for a nanosecond, was I wanted a piece of wire which would represent the maximum distance that electricity could travel in a billionth of a second.  And of course it wouldn't really be through wire.  Be out in space, velocity of light.  So if you start with the velocity of light and use your friendly computer, you'll discover that a nanosecond is 11.8 inches long, the maximum limiting distance that electricity can travel in a billionth of a second.  Finally, at the end of about a week, I called back and said, "I need something to compare this to.  Could I please have a microsecond?  I've only got one microsecond, so I can't give you each one.  Here's a microsecond.



LEO:  She's pulling it out of a paper bag.



GRACE HOPPER:  Nine hundred and eighty-four feet.



LEO:  Wow.



GRACE HOPPER:  I sometimes think we ought to hang one over every programmer's desk, or around their neck, so they know what they're throwing away when they throw away microseconds.  Now, I hope you'll all get your nanoseconds.  They're absolutely marvelous for explaining to wives and husbands and children and admirals and generals and people like that.  An admiral wanted to know why it took so damn long to send a message via satellite.  And I had to point out that between here and the satellite there were a very large number of nanoseconds.  You see, you can explain these things.  It's really very helpful.  So be sure to get your nanoseconds.



[END CLIP]



LEO:  I love it.  She was handing them out.



STEVE:  Wasn't that great?



LEO:  Oh.  I wonder if that was a class or a - that's awesome.  It looked like a bunch of...



STEVE:  So, and for those who couldn't see it, when she was talking about the distance to the satellite, she was taking this 11.8-inch wire and sort of moving it in steps, like putting it end to end to end to end, all the way up to where the satellite would be.  And I also loved her explanation, I mean, that of course speed of light, as we know, nothing can move faster than, that it's the maximum limiting factor.  That is, so here's this beautiful, straight, 11.8-inch piece of wire which she calls a nanosecond because it's a physical representation of a nanosecond of propagation distance.



Anyway, I didn't know I was going to have time to do this, so there's actually a Q&A note later where someone tweeted to me and said:  "Steve, people are now messing with your bit.ly link formula.  How hard is it to create a web page with links on it?"  And it's like, oh, yeah.  I have a web server.  I could do that.



LEO:  You can even do your own bit.ly.



STEVE:  Well, actually I have GRC.sc for shortcuts.



LEO:  Yeah, there you go.



STEVE:  And it has always been my plan to do that.  But we all know I'm a rather busy boy.  So, and I don't want to do like a cheesy one.  I want to do a, like, I want to do it once and forever solve the problem.  So it would have a database on the backend and a nice UI that allows me to set things up and so forth.



LEO:  Bit.ly has a white label version that you can do for free, by the way, if you want [crosstalk].



STEVE:  Well, I never got around to it.



LEO:  Yeah.



STEVE:  So what I did was - and there are other advantages to have something browsable because, for example, people have asked, what about that, you know, where is your sci-fi reader guide?  What was that site that you talked about for privacy information and so forth?  And so I thought, okay.  Years ago, in the newsgroups, people were posting links in, like, sort of just everywhere.  And it was annoying people.  So I created a group just for that purpose, which I called Link Farm.  I don't know why.  I just - I thought it was kind of funny.  And so we now have a Link Farm page at GRC, GRC.com/linkfarm.  And that will be the place from now on where I will just post links.  I mean, the show notes always have them, but not everybody gets the show notes.



LEO:  I like the little barn, the little red barn and silo you have there.



STEVE:  It's the Link Farm.



LEO:  You should get an animated GIF with a little cow coming out of the door.



STEVE:  And there will be - links will be harvested, grown and harvested here.  And again, I did have time this morning, I didn't expect I was going to, but I didn't have time to do anything other than that one link.  But I will, as I can, populate this with some other often-requested things, and our listeners will know that at any time they can just go to GRC.com/linkfarm, and it'll be in most-recent-at-the-top easy format.  And the other thing that allows, of course, is browsability.  You can browse backwards in time.  Now, I'm not going to go and repost all of the previous podcast links.  But moving forward, we now have a place for those to go.



So whoever that was who suggested, "Uh, Steve" - and actually there was a little back and forth in Twitter, and he was saying, you know, just set up a 301 redirect or a bit of JavaScript or something.  It's like, no, no, no.  If I'm going to do it, I want to do it right.  But as a consequence, nothing's happening.  So now we have a simple page where I can put links.  So no more bit.lys.



I did want to quickly note that pfSense has been updated to - now, I wrote 2.3.2.  But I thought it was 2.3.3.  Now I've confused myself.  But it did just get an update.  So anyone using pfSense, you can actually, if you just go to your main admin page, in the upper left-hand corner you'll see it checking for any updates to itself.  And it will now say, yes, got one.  And they fixed about 60 bugs, added eight features, and two to-do list items completed.  I have a link in the show notes to everything that they changed.  And this is what you want in a border router.  This is what you want in a router whose security you're depending upon, people who actively care, who are fielding reports of any odd behavior and fixing it and then making it available.  This is not what we have in our existing turnkey consumer blue box routers.  That's why pfSense and I are getting along so well.  So I just wanted to let people know there's an update.



And I mentioned this CUJO.  This is a consumer appliance thing.  And I'm sure you've seen it, Leo, or a picture of it.  It's kind of an inverted bowl shape with a flat head, but then it's got two LED things that kind of look like eyes.  And so it's supposed to be sort of a little friendly consumer appliance thing of some sort.  And I'm not a fan of technologies that sort of try to - that claim to be able to do more than they probably can.



But someone sent me a note some time ago saying how can this intercept my network traffic if you just plug it into your router?  And that's what you do.  This little thing is an appliance.  And the other thing I'm not a fan of is $9 a month for the privilege of this probably not being able to do that much for you.  So there's that.  But I was curious.  How can it do anything?



LEO:  You're not in between the person and the Internet.



STEVE:  Correct.



LEO:  You're just sitting there as a peer.



STEVE:  Correct.  Correct.  And believe it or not...



LEO:  Maybe the lights light up or something, eyes light up or something.



STEVE:  This is a consumer ARP attack.



LEO:  Oh, nice.  It's a man in the middle.  Cujo in the middle.  Oh, lord.



STEVE:  Completely breaks all the rules of how the network should work.  So I found - I dug around, and I found their explanation.  And our listeners will be able to read between the lines.  They said - so the question.  A knowledgeable person writes:  "I have a highly customized router based on WRT, so I'm curious how it is going to get access to all the packets on my switched network without me having to make changes to my router settings."



Answer, they write:  "The CUJO" - and that's, by the way, C-U-J-O - "appliance works in one of two modes."  So they do have what they call their gateway mode.  "Our Gateway mode, where you plug it into your router with a" - oh, I'm sorry, yeah, the gateways.  "Our Gateway mode, where you plug it into your router with a single Ethernet cable; or our Bridge mode, where it sits between your modem/router and switch."  For those who have those functions separate.  Many people don't, especially if your router, for example, has WiFi.  Then it can't get in between.



Get this.  "Our Gateway mode works by intercepting packets via an ARP mechanism.  This is how we achieve our 'simple plug and play' goal for the average Joe.  Our Bridge mode works as you would expect.  Because it sits in the middle of a modem/router and a switch, it's physically in the middle."  Then they said:  "Once the CUJO is logically or physically in the middle, we sample metadata from your network's connections," they said, "using NetFlow.  The metadata is strictly src/dest IPs and ports, bandwidth, packet count and connection states."



They said:  "We do NOT perform deep packet inspection as it is too intrusive and has a pretty big performance penalty for us."  Actually, we know they don't perform deep packet inspection because they can't, because everything is encrypted these days, and there's no visibility into the packets going by.  "These samples," they say, "are hashed and sent to the CUJO cloud over an encrypted channel.  In the cloud is where we do the heavy lifting."



So essentially we have a deliberate ARP spoofing attack, meaning that when any device on your network sends a query out to get the MAC address of the router, that is, of the gateway, what's supposed to happen is that's a broadcast.  Since the device on your network, a light bulb or an IOT device or whatever, has no idea where you are, it broadcasts it.  Anybody can reply.  This CUJO replies first, before your router is able to, claiming to be...



LEO:  We have a video dramatization from the Stephen King movie of the same name.



STEVE:  Oh, "Cujo," right.



LEO:  How you describe it, I think you'll see it's quite apt.



STEVE:  Oh, boy.  So anyway, I'm not putting something on my network which is going to commandeer, by breaking the fundamental architecture of - oh, and, I mean, well, I've just stepped on myself - by breaking the fundamental architecture of the way networking works and the way, you know, ARP stands for Address Resolution Protocol.  And imagine if you then add something else to your network that wants to do the same thing.  Now they're, like, now you have three devices fighting for supremacy, and one of them is going to win, and not necessarily the same one every time.  I mean, it's just an incredible kludge.  So as I said, maybe, I mean...



LEO:  [Crosstalk] going to win.  Cujo.  He's here.  Scary St. Bernard.  All right.



STEVE:  Was that an actress that we recognize?



LEO:  Yes, from "E.T."



STEVE:  I thought so.



LEO:  Yeah.  By the way, that was an Indiegogo project originally, CUJO was.  It was one of those crowd-sourced...



STEVE:  That's where I saw it.  That's how it came on my radar was, yeah.  Well, and again, maybe for a nave user - first of all, I'm not sure what monitoring hashed aggregate packet stream is doing.



LEO:  They might see malware floating by or something like that.



STEVE:  Yeah.  I guess, you know, for $9 a month...



LEO:  Bitmap, yeah.  Get one of those Ubiquiti EdgeRouter X's.



STEVE:  Oh.  This little...



LEO:  You're going to have to explain - I got mine.  But you've got to explain, what do I do with it?



STEVE:  Okay.  Actually, we have a beautiful application note from John Baxter in our Q&A.  So we will be covering that.



LEO:  Okay.



STEVE:  However, first errata, first piece of errata - funny you should mention the Ubiquiti.  Many people who are in love with theirs and know them well corrected me when I said last week that it supported PPTP and IPSec, but not OpenVPN.  It does support OpenVPN, but only from the command line.  And I'm still a bit mystified because I got the information that I was repeating from the latest documentation, where under VPNs it lists two, PPTP and IPSec tunnels.  However, many people corrected me, and so I'm sure it's correct.  In fact, I have in the show notes a link to the step-by-step instructions for establishing an OpenVPN server with TLS encryption using this just beautiful little $49 router.  So thank you, everyone.  Oh, and someone did report also that it's just Debian Linux in there.  So this is also a real little Debian Linux box.



LEO:  That makes sense.



STEVE:  With five interfaces, five physical interfaces, five physical, separate, not just switched interfaces, but logical interfaces that allow you to set up separate LANs, as our application note we get to later will mention.



Second tail-between-the-legs errata is I glibly and incorrectly said last week that, if somebody was using RAID 6, and that failed, that would require three drives to have failed, since RAID 5 allows one to fail, and you continue.  RAID 6 allows two to fail, and you continue, meaning that not until three fail are you in trouble.  And I said, oh, and that gives SpinRite a great opportunity or great chance of repairing the RAID - and this actually was in response to a testimonial, where someone did this - because it would only have to fix one of the three.



Well, many people who were paying better attention than I was said, uh, wait a minute.  It would have to fix the most recently failed one because the other two that had died earlier would have obsolete data.  And of course that's correct.  So thank you for the correction.  And just to clarify, as drives fail, then the RAID goes on without them, and their data is no longer relevant.  So two drives fail, your RAID is, like, running now with no redundancy.  So when that third drive fails, that's - but maybe it went for a year or six months.  I mean, it could have gone for a long time.  So that final drive to fail is the one that you would have to use SpinRite to bring back in order to recover the whole RAID.  So thank you for paying more attention than I was.



And speaking of paying more attention, I got a correction, believe it or not, that Daleks are not robots.



LEO:  What the hell are they?  They look like robots.



STEVE:  I know.  They look like stupid robots, frankly, and I hope I haven't offended half of our listeners.  I just - I never got into the whole "Dr. Who" thing.  I know it's [crosstalk].



LEO:  I didn't, either.  It started as a kids' show, so...



STEVE:  Fly around in a phone booth or something.



LEO:  Yeah.



STEVE:  I don't know what's - and now I'm sure that's not really a phone booth.  Okay.  But it turns out, from someone who knows - oh, and of course you have one on your desk, Leo, a Dalek.



LEO:  Yes, it's a 3D-printed Dalek.



STEVE:  They're supposed to have some weird - they're supposed to have some snorkel thing, too, coming out of the front.



LEO:  Yeah, they've got a thing coming - that fell off, yeah.



STEVE:  Oh, okay, good.  Anyway...



LEO:  It's retracted.



STEVE:  Martin tweeted me:  "The Daleks are not robots, but malevolent aliens that use a machine to live and travel in."



LEO:  That's their spaceship.



STEVE:  But there's some weird gelatinous thing inside, I guess.



LEO:  Yeah, yeah.



STEVE:  And so it's sort of armor and transportation.  So on that one I'm happy to stand corrected.  And this is not really errata, but I didn't have anywhere else to put it.  A frequent and valued contributor in the newsgroups, Gary Marriott, who is @ramriot in Twitter and in the newsgroups, he just made a comment following up on my discussion of the Facebook abuse protection stuff.  He just noted, he said:  "Hi, Steve.  Facebook Messenger.  Because Facebook is the custodian of the remote key that recovers the local decryption key for message logs, this opens them up to being compelled by deception or court order to release that key to expose a person's local message logs, even if the message logs include end-to-end encrypted messages."



And so while that isn't - it doesn't contradict anything I said, it's worth noting that I was pleased by the security model, where when you log your device into Facebook, Facebook provides your key to the device that then decrypts the device's key, which then allows your message log to be decrypted.  And so yes, actually, it's one of the things that Gary has really been handy for over on the SQRL side is he's one of the many people who check my work and often finds edge cases which are absolutely worth looking at.



LEO:  So it's in the logs.  It's encrypted end-to-end.  But because it's stored unencrypted in the logs, or no, because they have the key to the logs.



STEVE:  Yes.  So if...



LEO:  But that means it's unencrypted and then reencrypted or something; right?  



STEVE:  It's stored encrypted, and the key is destroyed when you log out from Facebook on your device.



LEO:  Which no one ever does, of course.



STEVE:  Yeah.  So his point was, if law enforcement - okay.  So here's the scenario.  Law enforcement obtains someone's smartphone, and they want to know what the secret conversation - this is the point.  This is the secret conversation log where you've been using the secret conversation of the new Facebook Messenger.  So they obtain someone's smartphone.  Now they go to Facebook and compel Facebook to release the key for that user's account.  With that key and the phone, they can then decrypt the previous message log.  So that's worth paying attention to.



That's, for example, something that Apple has made much more difficult for themselves than Facebook has been able to make, mostly because Facebook just doesn't - isn't positioned in the same privileged "we wrote the software and designed the hardware" position that Apple is.  So it's not clear that there's anything better Facebook could do.  But as we know, it's hard to completely lock these things down against every scenario.



Talking about SQRL briefly, as a consequence of a note in the SQRL newsgroup, you know, I'm getting near the end of this.  And there was a feature that I had designed in the beginning that no longer made any sense.  And so before I took it out, I wanted to make sure there was no valid use case for it.  And one of the responses reminded me of something that had never - something that I never talked about that I take for granted, but it's worth making clear.



So this person - and this is the end of this person's note - said:  "All right.  Sounds good.  It could get annoying to have to enter the entire," and he wrote, "super long complicated password every time my wife and I switch active SQRL user X times a day."  And what I was hit by was that the model of password is very different with SQRL than we're used to.  So what I wrote to him, what I wrote back in the newsgroup I'll read here.



I said:  "Remember that the classic super long complicated password logic requirement is significantly changed with SQRL.  In the traditional non-SQRL model" - that we're all operating under today - "your remote web account is inherently exposed to the entire public Internet.  So it's only the secret of your username and password that prevents anyone in the world from obtaining free rein to your online account.  So that is what sets the requirement for strong password protection."  Meaning that the password has to be strong because the only way we have of authenticating is typically some piece of information like our username or email and a password.



Now, yes, there have been moves to tighten that down, like Google will, if you log in from somewhere that you haven't logged in before, you can require a one-time passcode or that kind of thing.  So there are ways that this inherent vulnerability is mitigated, but that's still the fundamental problem.  And of course we also have the concern that, if that secret escapes from websites, which is happening now with increasing frequency, then we're in trouble.



"None of that remains true with SQRL.  With SQRL, physical access" - this is what I wrote - "to your SQRL cryptographic identity is the first requirement which cannot be bypassed."  Physical access to your SQRL cryptographic identity.  "Nothing other than a distant derivative of your SQRL identity ever transits the wire.  So unlike with passwords, your SQRL identity cannot be obtained from monitoring your login traffic.  This is an underappreciated aspect of SQRL.  The fact that we are authenticating locally to our encrypted identity by briefly decrypting it, rather than globally to a publicly accessible service, represents a huge difference in threat models."



And I finish, saying:  "Consequently, our SQRL passwords only need to prevent the use of our local SQRL identity by someone who can first obtain access to it."  So I wanted to make that point, that is, we're - and I've said it often.  SQRL becomes a proxy for our identity, able to identify us to websites.  And so what we still have is just so that someone walking by doesn't use that or abuse that, we need to authenticate ourselves to SQRL.  But what that really also means, then, is that the password can be, now, I don't want to encourage reckless use because maybe somebody would get a hold of your identity.  But you know what your own use case is.  Does it never leave your house, et cetera.  In which case you can make it easier with no decrease in security, understanding that you simply want to prevent anyone from using your SQRL identity which your password decrypts as needed.



Also, speaking of SQRL, I ordered one.  There's something called Sticker Mule.  I never heard of Sticker Mule before, Leo.



LEO:  I haven't either.  What is it?



STEVE:  It's a site where people make stickers.



LEO:  Oh.



STEVE:  And somebody made a two-inch by two-inch beautiful-looking SQRL sticker.  I have a link in the show notes.  And in fact, if you click on the link in the show notes, it'll take you directly to the SQRL sticker page.  Maybe you can just search Sticker Mule for SQRL.  Anyway, I ordered one.  It's $2.70 in singles.  Price goes way down if you order many.  But I have on the SQRL pages, long ago, as soon as I got this logo nailed down...



LEO:  I like that [crosstalk].



STEVE:  ...I posted high-resolution line art for the final logo.  And that's it.  So that would be 2x2.  And somebody is saying, hey, you know, spread the word, SQRL.  So if anyone wants a SQRL sticker for whatever purpose...



LEO:  Sticker Mule.



STEVE:  Sticker Mule has them.



LEO:  Yeah, $2.70.



STEVE:  Couple of bits of miscellany.  Someone sent me a brilliant observation.  I was speaking last week about how the new two-part Healthy Sleep Formula component, the key component, niacinamide, has sold out, like in six different online - the major six different online retailers.  Someone said search by UPC.  And it's like, oh, it's brilliant.  So I gave the people in the newsgroup a chance to get any if they needed it first.  We gave them a day and then added it the Healthy Sleep Formula web page.  So if you're somebody who has not been able to find niacinamide, on the Healthy Sleep Formula page at the top is the UPC for that correct Source Naturals time-release 1,500-milligram niacinamide.  And it's all over the place.  Not at major suppliers, but you can find it by UPC.  So Bob in Santa Barbara, thank you for that tip.  That will be really handy.



I already mentioned "Star Trek Beyond" at the top of the show, so I won't - I had that here, a reminder in case I didn't talk about it before.  And Eric Ebert tweeted me, he said:  "@SGgrc How do you feel about Season 2 of 'Mr. Robot' so far?"  And I thought about it for a minute or two, how to best describe my feelings.  And I said:  "Put it this way.  I'm only still watching because Season 1 was so amazing."  So...



LEO:  There you have it.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Be interesting, when you catch up, Leo, to see what you think.  It would be interesting to see what you think.  It's, you know, as I said last week, we're spending an awful lot of time rummaging around inside of Elliot's head.  And it's like, eh, okay, it's just depressing in there.



LEO:  I kind of lost interest early in the first season, to be - not early, but about...



STEVE:  Oh, you did.



LEO:  ...halfway through the first season.  I haven't - that's why I haven't caught up.  I'm kind of interested, but not that interested.



STEVE:  Yeah, in that case there's other things to watch.



LEO:  You know what you should watch that you might not have seen?  It's a Netflix original featuring Winona Ryder called...



STEVE:  Like her.



LEO:  Yeah, who doesn't - "Stranger Things."



STEVE:  Ooh.



LEO:  I think you will like it.  It's a little bit X-Files-y kind of creep show.



STEVE:  Nice.



LEO:  But what's really interesting, it's about the '80s.  And it takes place in the '80s.  And it really is, in a way, a call back to '80s movies.  So there's kind of three groups that you follow.  There's kids, and they're great.  It's kind of like "The Goonies," or maybe a little E.T.-ish.  There's Winona and her peer - there's teenagers, and they have their own story.  It's all related about the same story, but their own perspective on it.  And then there's the adults.  Winona is the adult, and there's a great sheriff.  And it's got this - it's actually very multilayered and fascinating.



STEVE:  A good vibe?



LEO:  Yeah, and it's well written.  It's good.  I think you'll enjoy it.  Try it.  You can binge it.  It's on Netflix.



STEVE:  Nice.



LEO:  Yeah, it's "Goonies," "Stand by Me," "E.T."  It's got a very '80s - there's '80s music, '80s hair, '80s outfits.  And then it's creepy as hell.  The only bad thing is the monster is like kind of not - it's like...



STEVE:  Oh, no, no, no, no, no...



LEO:  Never mind.  Never mind.



STEVE:  No spoilers.



LEO:  No spoilers.



STEVE:  No spoilers.



LEO:  Just a little tip.



STEVE:  And this will not come as a spoiler to many people.  I got actually a long tweet, looks like, from Ralph Griesenbeck, whose handle is @RandomGravy on Twitter.  And he asked me a question.  He said:  "In a recent Security Now! episode you recommended looking at the SMART screen in SpinRite.  However, that only works if it's supported in BIOS.  In my experience the systems supporting SMART in BIOS are not that common.  Even if SMART data is available, interpretation is a bit of an art as each drive maker has different implementations.  Am I missing something?"



And so I replied to Ralph.  I said:  "Hey, Ralph.  Some BIOSes can and do support SMART probing.  But SpinRite does its own directly to the hardware, continuously during operation.  So it does have access to the drive's SMART data, even when the BIOS is 'not so SMART.'  SpinRite also performs some SMART interpretation for the user and succeeds in eliminating some of the drive-to-drive variations, though you're right that differences between drives can be confusing."  And then I sent him some links.



I have two links from the SpinRite pages:  GRC.com/sr/smart.htm, and then also sr/smart-studymode.htm.  And if users haven't seen those, I really commend it to their attention.  I broke that SMART monitoring page down with bullets and callouts showing what every little section does and what they mean so that it really clarifies that because there's a lot of information.  It's a very information-dense page.  And I would argue it's one of the key features of SpinRite.  As I mentioned before, if a drive is just idling, doing nothing, the SMART system doesn't really report anything because it reports on struggles, essentially.



Well, SpinRite makes the drive struggle like nothing ever has.  And so watching what SpinRite causes the SMART data to do is extremely illuminating.  You can see it generating correctable errors and uncorrectable errors.  And SpinRite calculates the error rate that is the number of errors per megabyte of data read from the drive to give you a numerical sense for that.  It also captures the minimum and the maximum which have occurred within megabyte samples.  And they shouldn't vary too much.  If the maximum is really high, that means there's an area in your drive where it had to work much harder than the average for that drive.  And there's all kinds of other things, all of the health parameters.  SpinRite captures the starting health parameter and then shows you any decrease in that health parameter that is created by the work SpinRite is doing with the drive.



So again, I know we've got a lot of fans.  If we have any SpinRite fans who didn't really know what was going on there, next time you're running SpinRite, page over through the UI to that SMART page.  And maybe compare that or look at the /sr/smart.htm page to see what's going on there because a lot of good info there.  And it was funny, when I was doing the work on SpinRite 6, there was some concern about whether drives would balk at being probed while they were busy working.  I saw nothing in the spec to indicate that it would be a problem.  But nobody else does that.  It turns out it's never caused a problem.  And believe me, we've got a lot of experience now with SpinRite 6 doing this.  So that's become a solid part of SpinRite's core technology moving forward, as well.



LEO:  I like your TWiT IPTV T-shirt, Steve Gibson.



STEVE:  I like it, too.  It is sheer.



LEO:  Sheer.



STEVE:  So it's nice on a hot day like this.



LEO:  Is it hot down there?



STEVE:  Oh, boy, yeah.  We've had the heat wave through here.  It's better, but boy, is it humid.  It is so - it's like muggy.



LEO:  Well, go for a - you're near the ocean.  I didn't even know this.  You're near the ocean.  Go for a dip after the show.



STEVE:  Yeah.  Hold on a second, I'll be right back.



LEO:  Do you ever go for a dip?  When's the last time you've been in the ocean?  Was it in this decade?



STEVE:  No.  Unfortunately, the ocean's pretty screwed up now.



LEO:  Is it?  You don't want to go in now, huh?



STEVE:  You don't want to go in there, no.  It's a little scary.



LEO:  That's too bad.  We're going to be in San Diego in a week.  Is it going to be...



STEVE:  San Diego's got nice beaches.



LEO:  Yes.  I can't wait.  We're going down next Wednesday.



STEVE:  The problem is there's a lot of sand.



LEO:  All right.  Just stay inside and finish SQRL.  That's all we ask, Steve Gibson.



STEVE:  That's what I'm doing.



LEO:  That's all we want from you.  Just keep working.  Keep a-working.



STEVE:  I hear you.



LEO:  Question #1, Tod Sage, field support technician.  He says the real world may differ a little from our ivory towers in cryptomath:  I've been a field service technician since 1988.  I've worked for many companies, as well as myself, in a very wide range of disciplines.  Now, these settings raise concerns about the level of access I have been given.  My biggest concern is when one large company contracts with another, that then contracts with another, and so on, until I'm looking at job postings on Craigslist from some company in India who sends me a packet containing usernames, passwords, and an ID badge stating I am a contractor for Company #2, with instructions not to tell the end customer the full details of who's cutting my paycheck.



For someone replying to a Craigslist solicitation for a one-time job, there is very little to deter any active engagement in cybercrime, and very little in the way of verification even that I am who I say I am.  And thanks to the way the hiring chain works, no one involved even knows who I am, and no one really cares.  That's somebody else's problem.  Having been involved in this firsthand, and having seen this occur often, I have seen no sign of any enforced standards in IT security.  Is it any surprise, then, that the many corporations who outsource their IT service needs suffer so many problems and have such poor security track records?



Let's not forget the most famous contractor of all, Edward Snowden, who was a contractor at the NSA.  Here, Edward, have access to everything.



STEVE:  Yeah.  You're a smart guy.  You've proven yourself.



LEO:  What could possible go wrong?



STEVE:  Yeah. 



LEO:  And of course we were talking about this yesterday.  The Target infiltration went through their HVAC company, that Target gave access to the network to the HVAC contractor.  And who knows who they gave it to?



STEVE:  Right, right.  And I just - I loved this story from the real world because we do get caught up in minutiae, like, well, you're never going to be able to factor that prime.  But if some guy in India sends you the password, you don't need to.



LEO:  Wipro is the company in India that hires a lot of contractors, tech contractors.  W-I-P-R-O.  They've massive.



STEVE:  Yeah.  And I'm sure that their contract says we're just making our best effort. 



LEO:  Yes.  Do your best.



STEVE:  And if anything happens, well, you know, it's not our fault.



LEO:  Kyle Day tweeted - well, I don't know, maybe this is a DM.  Hi, Steve.  Love your SN podcast.  Highlight of my week.  I have a question about corporate spying via inserting a certificate into a Windows user's root certificate store.  I understand that IE and Chrome use Windows' built-in certificate store, but Mozilla's Firefox uses its own.  If I install Firefox on my work machine and use it for personal browsing, does that mean that it's impossible for my employer to decrypt that traffic because they don't have a certificate to MITM my Firefox traffic?  Is that a workaround for corporate spying?



STEVE:  So a couple things there, sort of some that we've talked about, some that we haven't.  So first of all, Kyle's understanding is correct.  Firefox maintains its own certificate store.  He would have to verify that whatever mechanism the corporation had for getting the certificate into Windows would also not work for Firefox.  But it's likely that it wouldn't.  That is, the active directory group policy stuff leverages Windows specifically.  So using a browser that brings along its own store would work, that is, would prevent anyone like an employer at the border doing a man-in-the-middle.



The problem is that browser may not be able to get out on the Internet at all.  That is, it is very likely that anyone setting the system up - and this kind of comes back a little bit to the story we'll be getting to about the EdgeRouter configuration, the application note.  That's the word I was trying to come up with, the application note that we have, because a corporation could block HTTPS traffic, requiring, for example, the use of a corporate proxy.  And the proxy would absolutely require the presence of a certificate.



So essentially the answer is, it might work.  And if it does work, then it should be secure.  But if the corporation is really serious about filtering all traffic on their Intranet, then it will not be possible to not go through their proxy, which is also decrypting and inspecting the traffic as it happens.  So while the concept is right, it's very common that it would also be blocked, unfortunately.



LEO:  Scott Ericsson, Milwaukee, Wisconsin with a SQRL question:  Steve, SQRL sounds amazing, but I think there's a problem.  How many emails a day do you get with that, that begin like that?



STEVE:  Yeah.



LEO:  I have found a problem.  As I understand it, SQRL auto-magically creates a unique identity for each of its users for each website they visit.  But what if I want to appear as a different user at the same website?  Under the Internet's present insecure email and password scheme, I can use a Gmail alias, or use a secondary email account to create a second independent identity at any site I wish.  SQRL would appear to lock us into our SQRL identity for each site.  Is that not a problem?



STEVE:  So, great question, one that we've had before, and one that we have an answer to.  There are many ways to solve a couple problems, depending upon what makes the most sense for the user.  You could certainly create another SQRL identity.  And so, for example, in a household, each of the kids and Mom and Dad would have their own SQRL identities.  And nothing prevents you from creating an additional identity for use at a certain site.  The problem with that, I mean, and that's absolutely - you can do that.



The problem is there's some overhead that comes with a SQRL identity, like that rescue code that I talked about, where you have to store that somewhere.  Essentially, you're doubling up the stuff.  When you set up a new device, you would need to import or to export your identities and then import them into the new device and so forth.



There's a better way.  Built into the protocol we have a mechanism known as "alt ID," alternate identities.  And any time you are authenticating yourself to your client, to SQRL, there is an option button that allows you to do a couple extra things.  One of them is to change your SQRL identity, sort of in a sticky fashion, if you wanted to switch to somebody else's identity.



But the other option is to use an alternate identity.  The way SQRL creates the identity, remember, is it hashes the domain you're visiting through a keyed HMAC, where the key is your super secret master identity.  The alternate ID is simply appended to the end of the website's domain name.  So it can be anything you want.  It could be the numeral zero.  It could be HiMom.  It could be anything.  And we simply add that string to the end of the domain name, which creates an absolutely separate, unique, non-linkable, non-trackable, it's a completely separate identity for that site.  And so it's built into the protocol, it's defined in the spec, and it exists in the client now.  So Scott, we've got you covered.



LEO:  Oh, I dropped my headphones, hold on.  Whatever you're saying, I - okay.  Now I'm working all right. 



STEVE:  I ought to also mention, I mentioned last week that there was something else I wanted to talk about, but we ran out of time.  We were right up at, like, two-plus hours.



LEO:  We've got lots of time today.  Go ahead.



STEVE:  One other thing that I added about a month ago was there was some discussion about a feature in v2 to produce a static secret.  But it was so simple to do, and so useful to have, that I said, no, it's going in right now.  And the next iteration of the client that everyone got had support for that, and it's in.  The idea is, think of things like LastPass.  In the LastPass model, they have data they're storing on our behalf, yet they cannot decrypt it.  They need something from us in order to decrypt the blob that they're storing.  That's a really useful model, the idea that a website could have any amount of anything.  I don't mean just a password database, but user data.  And they don't want to be able to decrypt it.  And if they can't decrypt it, they're not vulnerable to any kind of attack.



Well, right now the SQRL spec that I've discussed had no such provision.  We give the site our public key to use to identify us, which does double-duty to not only identify, but also to authenticate because we sign a challenge, and that verifies the signature.  But there isn't a secret that we're providing that could be used as the master decryption key for something server-side, until now.  It's there.



And so if the site wishes to obtain a static secret from SQRL, in the first exchange it sends what's called a "secret index."  And again, that can be any information the site wants - just the numbers, just a numeric zero, or a wave of the hand, it doesn't matter.  The SQRL client generates essentially a subsidiary static secret from hashing what the site provides off of the master identity and returns it.  So, and that's, like, it's the output of another - it's another 256-bit output of a rather complex hashing process to make sure that there's absolutely no way to go upstream.  And it's a little overkill, but it doesn't take up any time, so we go for overkill where we can.  And that allows a website to obtain from someone authenticating with SQRL a secret which will never change.  Every time they come back, just as their identity is the same, the secret is the same.  And the system also handles previous identities and previous secrets in the same fashion.  So it's possible for the site to ratchet itself forward.



Basically, we have it all covered.  It's one of the things that's taken a while.  But you know me, I want to get it right so that I never have to look at it or think about it again, and I can get back to SpinRite 6.1, and SQRL will be able to launch and solve the world's problems.  So anyway, it's very cool that it's able, that the site cannot decrypt something it's storing on your behalf.  But the SQRL technology, this little addition, simple, took minutes for me to add it, will then allow the website to request a static secret, which then it can use to decrypt data it's storing for us for as long as it needs it.  So, very cool.



LEO:  From Docop, @docop29.



STEVE:  Who knows.



LEO:  Who knows.  Twitter handles, what can you do?  Worse than license plates.  Steve.  I have to figure out what my license plate for my Tesla should be.  People do a lot of thing with electrical, you know, WattUp.  Amped.  Stuff like that.



STEVE:  Those are probably taken, unfortunately.



LEO:  Yeah.  All the good ones, I'm sure, especially in California.  Anyway:  I have a guest WiFi network at work that I use with my iPad for doing mostly work tasks.  I have an iPhone that I never connect to the network so my private information is not going through corporate servers.  The WiFi password changes every two weeks, so I have to reconnect my iPad.  I've noticed recently, though, that my iPhone also connects to the network.  It seems that iOS is automatically updating the password across iCloud.  Oy gevalt.  Given your recent discussions about corporate appliances breaking SSL and being able to access all your traffic, is this going to open up private traffic on my phone to my corporate overlords?



STEVE:  So, first of all, it is absolutely true that this is one of the things that Apple has decided will be a convenience.  So, and for example, for me it's a convenience.  As I mentioned, I have about 12 iOS devices.  And when I was setting up my new, that Soekris Engineering box running pfSense, I changed my WiFi around.  I was setting it up.  I came up with a crazy, unhackable password, and I only had to put it into one device.  And it was a convenience that all of the other iOS devices that I had suddenly knew how to get onto my new WiFi network.  So that was cool.  But this guy brings up a very good use case where it's not what you want.  That is, where in this case a device that shares an iCloud account is syncing itself through that to obtain information he would like that device not to have.



Now, the good news is there's a switch in the WiFi options of iOS where you can turn off automatically logging into WiFi networks that you recognize.  And while having it off the rest of the time might be a little inconvenient because it just won't seamlessly automatically be on WiFi, you would want it off while you were in this corporate setting so that it would get the password, but at least it wouldn't use it without your explicit permission.  And I'm thinking, why, who would change a WiFi password every two weeks?  First of all, that really argues against it being a big complex password because, I mean, that would just be onerous.  And the only reason I could imagine is that they're trying to stay ahead of people giving the WiFi password out.  So if people give it to other people, then - or maybe this IT department has run...



LEO:  That's probably what it is.



STEVE:  It's just run wild.



LEO:  We're in charge here.



STEVE:  Exactly.



LEO:  We'll just show you.  We'll change the password every other week.



STEVE:  Oh, my god, and everybody hates those guys.



LEO:  Well, and we've talked about that.  It doesn't necessarily improve security to change passwords.



STEVE:  No, no, no.  I mean, for example, as I said, it's probably - probably have to be weak passwords if you're changing them every two weeks.



LEO:  It just encourages people to put post-it notes on their screen.



STEVE:  Yes. 



LEO:  But I think with a WiFi password, you nailed it, it's probably people are being - well, he says they have a guest network, though.  So I don't know.  But it's probably being given out.  That's the guest network; right?  So people...



STEVE:  I think, right, "I have a WiFi guest network at work."  Yeah.



LEO:  Right, yeah, right?  So it's the guest password.  But we haven't changed our guest password in five years.  You know, and I'll tell you what it is:  brickguest.  It's like, so what?  You'd have to be physically here...



STEVE:  Right.



LEO:  ...to use it.  I think I'd notice you sitting on the street playing Pokemon Go with my WiFi.  Jared is next, @nucleareye.  I love the Twitter handles.  Security Now! question:  What's the big push behind cloud computing and storage, hey?  Moving these services offsite makes us more dependent on Internet connectivity and puts our data at a greater security risk, so it seems.  I don't like the idea of depending on someone else to access my data, securing it and having access to it.  I get it's a nice thing to be able to access from anywhere in the world, but sometimes that isn't necessary.  So why put stuff in the cloud?  Thanks for SpinRite.  I love it.  Listen to the podcast every week and love that, too.



STEVE:  And Jared, I understand your feeling.  The good news is, unless you absolutely have to use a service which is cloud-based, no one's making you put anything in the cloud.  Drobo is a sponsor now.  Drobo is a cloud sitting next to you quietly humming.



LEO:  Cloud-free, yeah.



STEVE:  And with all the redundancy and safety and convenience that you want in just sort of moving something out of the way.  However, you're not everyone.  And, for example, Jenny is having her laptop backed up by Carbonite, which is a cloud-based service, and thank goodness because she's not - she just wants the problem solved.  She doesn't want to get all involved in the details.  So from my standpoint, we're living in this rich environment now where there are...



LEO:  We have a lot of choices.



STEVE:  Where there are amazing open, free, low-cost solutions.  Cloud is an option.  Now, if your backup storage is with you, then there's tremendous advantages to that.  But if some catastrophe happens, then you don't have the advantage of physical offsite.  So as we've talked about with backup, there's some advantages to physical offsite, and some consequences in terms of performance, just bandwidth access to something physically remote, and security.  So it gets more difficult, but it's also very convenient.  I just think we're like in this land of riches right now, with mass storage being so inexpensive that everybody's got some. 



LEO:  You know, I've mentioned this before, but I got my little Linux NUC.  It's an Intel NUC.  Got it from System 76.  It's running, like, stripped down Debian, because I don't need a GUI or anything.  It's a server.  It's got nothing on it.  It's Debian stable, so it's rock solid.  And then I put this thing called Sandstorm on top of it.  This is my cloud.  This is running out of my house.  It's HTTPS.  They provide that and DynDNS for free.



They have all these apps in the App Store that you can use.  These are all cloud apps, and this is all stored on my server in my house.  By the way, so much encrypted that you see the grains of the data files.  These individual grains are encrypted and stored separately from everything else.  So they're completely kind of secure little packets that can easily be transferred.  And I'm using BitTorrent Sync to keep this backed up to here.  So that's my cloud backup.  It's backed up to my work server, or actually work desktop.  Actually, I'm backing it up to several different desktops.  And even if somebody got any of those backups, those are encrypted and unusable.  It's totally, I think, possible to do this.



STEVE:  Yup.



LEO:  And this is free stuff.  Sandstorm.io, I'm really impressed by it.  I've got a music player, photo sharing.  I've got Dropbox-type filesharing.  It was an experiment;, but, yeah, you've got the choices.  That's the point.  But Jared - and you're right.  I mean, do you put anything in the cloud?



STEVE:  Do I?



LEO:  Yeah.



STEVE:  Yeah.  I use Amazon S3, and I've got...



LEO:  And you encrypt, I'm sure.



STEVE:  ...all the podcasts and images for various systems are up there.  I had the advantage of sort of having my own cloud because I've got the GRC servers in a physical location at Level 3.  And so each of my locations backs up to the other.  So I sort of have the equivalent.



LEO:  Yeah.  I mean, I understand most people, most individuals' homes aren't going to have a cloud of their own because, you know.  And that's why I got that Ubiquiti EdgeRouter.                                                                                                                                                                                    



STEVE:  But Drobo is a cloud of your own, essentially.



LEO:  Exactly, right, yeah.  Torleif Hensvold.



STEVE:  And this is the one we are going to skip because he's suggesting that why don't I set up a web page rather than have my bit.ly links hijacked.



LEO:  Done.  Done.



STEVE:  Good idea.  So Torleif, thank you.



LEO:  Well done, thank you.



STEVE:  Done.  Link Farm.



LEO:  Link Farm.  GRC.com/linkfarm.  You know that is what Google calls those spammy sites with lots of links on them.  But you don't care.



STEVE:  Oh, really?



LEO:  Yeah.



STEVE:  Didn't know that.  Well, mine's going to be lot of links, but it's not spammy.



LEO:  It's good links, good links.  @scruffydan on the Twitter, Dan Moutal.  FYI - oh, this is the answer that you - the errata, the Ubiquiti EdgeRouters... 



STEVE:  Ah, no, the next one is.



LEO:  ...do support OpenVPN.



STEVE:  Oh, right, right, right.



LEO:  Need to use the CLI to configure.  Speeds not great, 10 to 15Mb.  I'm using the POE model EdgeMAX EdgeRouter, which can route at 1Gb.  And I tested it, and it works like a charm, he says.  Plus, if you really want to geek out, it's just Debian under the hood, and you get full root access.  Keep up the good work.  That's a different thing than the EdgeRouter X; right?



STEVE:  Yes.  And so I wanted to make sure people knew that they did have a higher performance router that can run at a full gigabit per second.  Because I had mentioned that the X will run about half a gig.  And so you're getting an incredible lot of functionality for 50 bucks in the X.  But they do have a more powerful one that can run faster.



LEO:  And now we get to - by the way, I know you're not watching the Democratic National Convention, but I have it on in the background.  They're doing the roll call.  And in just a few minutes it will be completed.  It's close.  Hillary Clinton has 2315 votes, Bernie Sanders 1502.  It's like neck and neck.  It's a horse race.



STEVE:  I'm glad they're doing it because the Bernie Sanders voters need to just have that done.



LEO:  Well, no, absolutely.  You know what, and he got a lot of planks on the platform, as they say.  I just - it reminds me of my youth, watching these.  "The great state of Montana, home to the cowboy hat." 



STEVE:  With their signs.



LEO:  I just love that.  I don't know why.  It just - to me, that's American democracy in action.  Or something.  John W. Baxter, Port Ludlow, Washington, provides a terrific real world application example for the $60 EdgeRouter X we've been talking about from Ubiquiti:  Steve, it was interesting to see you discuss the Ubiquiti EdgeRouter on Security Now!.  The box does indeed have the ability to create the desired isolated network for IOT devices.  We're using it similarly to isolate a guest network from staff networks, as follows:



We're using the machine to load balance between two WAN connections.  At home I'd prefer to use my DSL in failover mode only, but I haven't convinced the boss.  I weight the cable connection at 95% instead.  So he's got DSL and cable, and he's using both.  Instead of using DSL's failover, they're bonded, but he's doing most of the bandwidth from cable.



STEVE:  Yeah, and how cool that you can commit two ports to the WAN side so that if either one goes down, the other one just picks up the slack.



LEO:  I could do that with that little Ubiquiti EdgeRouter X?



STEVE:  Yes.



LEO:  Wow.



STEVE:  Yes.



LEO:  Very sophisticated.



STEVE:  Yes.



LEO:  Before you get too far into working with the machine, you should be sure to update and install the latest firmware, which is version 1.8.5, as there are several advances in that version of the EdgeOS software.  Until recently, TLS connections to the GUI presented an expired self-signed certificate - a little scary and seems to upset current versions of Firefox.  I checked just now:  Version 1.8.5 uses a self-signed certificate which expires in 2024.



The built-in DHCP server works well.  Each LAN gets effectively its own, as can each virtual interface if you create them.  We haven't experimented there.  The DNS forwarding and management also works well and can be quite powerful.  We're using OpenDNS, paid, to gain the filtering of "unfortunate," as they say, IP addresses, and we don't allow the staff LANs to use any other DNS.  Just yesterday I configured the company site EdgeRouter - these are bigger routers than the one we're talking about.



STEVE:  No, this is the little thing.



LEO:  Really.



STEVE:  This is this little cute box.



LEO:  Wow.



STEVE:  Yeah, the little EdgeRouter.



LEO:  To permit explicit configuration of the OpenDNS server's IPs, rather than insisting on the 192.168.X.1 forwarding server.  For the guest network, we provide Google name servers via DHCP, but allow overrides for any other DNS server the client desires - that's nice, guests, use whatever you want - and we allow the guest network clients to use the OpenDNS servers as an exception to "the guest network can't touch the ER-X" firewall rules.



I do most configuration work in the GUI, using Safari, but I'm getting better with the command line interface.  User passwords for the web interface must be installed using the CLI.  Perhaps that's been fixed in 1.8.5.  OpenSSH works well with key files.  We've disabled password login on SSH.  I always do that, too.



STEVE:  Yup.



LEO:  I also do some configuration by editing the downloaded config.boot file and installing the result.  Terminology:  Ubiquiti can't decide whether these things are EdgeMAX or EdgeRouter.  Also note that the Ubiquiti community forums have many articles whose details have been obsoleted by newer versions of the software, but they're not dated, so that's hard to detect.  Enjoy your explorations of this machine, but first please finish SpinRite 6.1, okay?  Come on.



STEVE:  Okay.  So a couple things.  First of all, everyone should know I'm not using that.  I've solved my problem with the Soekris Engineering hardware and pfSense.  And that does everything that this little Ubiquiti router does, and way more.  Although that's probably arguable, given that it's running Debian, and you can probably install whatever you want to on it.  I mean, it's an amazing piece of hardware for $50 with five physical ports.  So anyway, I'm not wasting any time or spending any time.  That's why I don't know it better than I do, and I'm just reciting what other people have told me and what the manual says, even when it's wrong.  But I wanted to bring it to our listeners' attention because, for 99.9% of the people, it's amazing.



And so just to summarize what John said, as an example of the control that this gives you, he's got two separate networks with completely separate DNS management.  The corporate LAN is hardwired to use OpenDNS's paid servers and blocks any attempt not to.  So not only do you say here's the DNS you'll need to use, it won't let you make any changes.  Whereas he deliberately configured the guest LAN in a more lax fashion.  OpenDNS is presented through DHCP.  So in that "obtain IP address automatically" mode, you're also getting the OpenDNS DNS servers.  But he deliberately said, but if you want to manually configure your own DNS, you can do that, too.



So, I mean, there's so much power in this little box for $50.  Anybody who wants to mess around with this kind of next-generation professional-level packet networking - and, as I said, yes, we solved the isolation problem with three dumb routers.  But you could also just use one smart one, just this, for $50.  And, boy, you'll just - you could play with this thing forever.  So John, thanks for sharing the details of the way you set this up.



LEO:  One of our chatters, Neo, has mentioned that Dan Gillmor, who's a friend of TWiT and a journalist, has raised issues about the terms of service, the End User License Agreement, for Ubiquiti.  They say they can't - I'll tell you what it says, and then I'll say why I don't think it's an issue.  But he said they can collect information about you.  And that's often the case in terms of service because there's information that you give them when you log into a Ubiquiti account or whatever.



STEVE:  Right, right.



LEO:  But so just to be aware of, some people might find this cause for concern.  Read the license agreement.



STEVE:  Yeah.  There's no indication that this thing is sending anything home.



LEO:  I don't know how they would collect information from this, anyway.



STEVE:  No.



LEO:  Because it's just a router; right?  It's not phoning home. 



STEVE:  No, it's not phoning home.



LEO:  So, now, my question is, the problem is I have this Eero.  And the Eero really wants to talk to the Eero servers.  This is this new WiFi thing.  So I don't think I want to put the Ubiquiti in between the Eero and the outside world.  But I could put it between - I could put the Eero directly connected to the cable modem, and then off the Eero go to the Ubiquiti and have the server connected to the Ubiquiti, and use the Ubiquiti rules then; right?



STEVE:  So what's this Eero?



LEO:  Eero is a - okay, this is another thing.  Someday you want to look at this.  This is a new category of WiFi routers that's very interesting, very expensive.



STEVE:  Is this the mesh system?



LEO:  Well, I don't know if it's mesh or not.  I think it's mesh, but I'm not sure.  Yeah.  There's three of them, if you get all three.  You distribute them, and it distributes - it does a great job of really boosting my WiFi signal, and there's no dead spots anymore.  And they do something else which is you have to establish an Eero account, either with your phone number or your email.  And the router is logged into the Eero servers.  They update the firmware, like all the time, which I think is a good thing.  They also claim that they are doing some tuning.  They see what devices you're using, and they're tuning the router based on what the device is.  All I can imagine is maybe doing some QoS stuff for video streaming [crosstalk].



STEVE:  I'll bet your household is keeping it busy.



LEO:  There's a lot of stuff on it.  It's not nearly as...



STEVE:  How many light bulbs does he have?



LEO:  Yeah.  It's not early as configurable as the Asus I use, or this EdgeRouter.  I mean, you do it all with an iPhone or Android app, and it's just - you know what I should do is have...



STEVE:  More turnkey.



LEO:  Yes, very turn - it's great for somebody who can afford - I think it's 500 bucks - needs really good WiFi, and doesn't want to geek around with it.  No idea what their security model is or anything, although they seem like - the guy comes from Google.



STEVE:  So two things.  The problem with doing a Y connection is that they would each have to have their own public IP.  So you would have to have two IPs. 



LEO:  Ah.  So you really do want it to be the first thing on the connection.



STEVE:  I think so.  And the beauty of this router, it might require a little bit of tinkering, but I'm sure you could get it to pass right through so it didn't even know that there was a router.



LEO:  That's what I would do, yeah.  Pass through to the Eero.



STEVE:  Yes.



LEO:  And let the Eero do its DH - sounds like, from this guy's email, that the Eero can say, oh, you do DHCP.  Oh, no, I'm not going to do it for this one.  You can really control it that way very granularly.  All right.  I'll figure it out.  There's so much new technology in my house now that I have...



STEVE:  Arriving daily.



LEO:  I have, yeah, kind of have to slowly work my way through it.  Tonight's the FreeBSD box.  Let's move on.  Fred, I'm sorry, Tom Zitzelsberger.  Steve, I just - that's his name.  Don't laugh at the guy's name.  I just listened to SN-569, and I have a question.  You said that the new Facebook secure message system was crypto done right.  But it seems like it might be simple for Facebook, having received a National Security Letter, to simply add a single character to the secure message to trip the recipient's report feature and have the now-decrypted message returned right to Facebook without notifying either sender or receiver.



Also, since the message needs to go through the Facebook servers, it would be simple for Facebook to append that single byte to all incoming traffic to the person named in the National Security Letter, and the target's own system would return all their incoming private messages, as well.  It seems like this new system would fit perfectly with Vladimir Putin's new law about companies providing the FSB - the Russian secret service - with means to decrypt messages.  Let me know if I'm mistaken here.  I'm a huge fan.  Thanks for all you do for us.



STEVE:  So, yeah.  There's a little bit of misconception here that I wanted to clear up, and it's important to understand the way this abuse reporting works.  If the recipient's device found that signatures don't match, that is, if as Tom suggests a character were added anywhere, that would bust the hashes and signatures, and the incoming message would be discarded.  It would not be echoed back to Facebook.  It would just be thrown away.  It would be a communications error.  The system would assume, oh, there was a transfer error, so this is gibberish.  Just don't display it.



The decryption is only - and when I say "only," I mean Tom's suggestion and anything else anyone can come up with, only if the recipient sees the message and is offended by it, it feels that it's in some way abusive and against Facebook's terms of service, then the recipient of the decrypted message can themselves voluntarily choose to bounce it back to Facebook in the clear, along with the various other tokens that we described in detail last week that allows Facebook to validate that that is unchanged from what the sender originally sent because it did go through Facebook encrypted on the way.



And this technology we discussed last week allows Facebook to say, yes, you know, essentially they reencrypt the message that was sent in the clear and are able to verify it's the same thing they originally got from the recipient, who has created this offensive message.  But I wanted to make sure that everyone understands, messages will never be seen by anyone but the recipient unless that recipient chooses to break cover and send a message back to Facebook.



LEO:  Which could happen, too.



STEVE:  Yeah.



LEO:  Scott Surbrook.  I've been watching Security Now! since the 200s, but I don't remember any episodes in which you apply your ability to simplify complex topics with regards to why 256-bit symmetric key encryption like AES is as strong or stronger than 4096-bit public key encryption like RSA, especially since there are approximately 2^1200 primes in a 4096-bit RSA key space.  What would be the equivalent - he says RSA, but I think he means AES key size.  Thanks.



STEVE:  So I think we covered this in Episode 199.



LEO:  Oh, we've mentioned it.  You missed it.  You just missed it by one.



STEVE:  Yeah, he started at Episode 200.



LEO:  Just missed it by that much.



STEVE:  So Scott, and anybody else who's wondering, the idea is these are approximations.  And so there is no fixed equivalence, per se.  The idea here is that cryptographers use everything they know - and this is the other reason.  It's based on assumptions.  So cryptographers assume that there is no way of short-circuiting AES.  And if that's true, then they know how many keys are available in a 256-bit key space and, with current technology, how long it would take to crack that by brute force, assuming no other solution.  Similarly, in the case of RSA, we know how long the public key is and how many primes are available and the rate at which we can try, the rate at which we can guess.



And the reason public keys are generally a lot larger than private keys is that we're trying to, with a public key system, we have a weaker problem that we are trying to prevent the cracker from solving.  So the problem itself is not as hard.  For example, what, a prime is three and seven, okay, so there's 21.  What's the prime factorization of 21?  Well, that's easy.  The point is that the problem itself is not intractable.  It's just difficult.  And so public keys are much bigger, typically, that is, asymmetric keys, because the way the asymmetric key systems we've designed so far are difficult, but not sort of the same, like, absolute, there's no way to short-circuit this other than brute-forcing that we do have with symmetric keys.  And, famously, Bruce Schneier a long time ago did a chart predicting the rate at which CPU processing power would be increasing and what that meant for minimum key length over time.  And there is a chart that shows one column for symmetric and another column for asymmetric.



And so the point is, this is all just seat of the pants, sort of just rule of thumb.  So we're in a place today where a 128-bit symmetric key of high quality is good, as is a 2048-bit public key that is properly derived with high-quality entropy.  For the foreseeable future, 256 bits, remember, it's only twice as many bits for symmetric, but it's ridiculously more combinations.  And 4096-bit, doubling the public key, provides again just a huge amount of protection.  And the reason you just don't have really big keys is there is some computational burden.



So, like, every time you use the key, you've got to do this work.  And that does go up quickly as the key size increases in the case of public key crypto.  So the argument is it's just waste to use a ridiculously large key, when a key that's a lot smaller still provides enough security margin.  And this margin is this notion of, well, here's what we know we can do, and we have a margin between that, it's like our safety margin, for how long we want the key to be able to survive an attack.  So again, just sort of rule of thumb.



LEO:  Number 11 from @grymoire, another Twitter, Bruce Barnett.  CryptoDrop sounds great.  However, as far as I know, it's not available.  Anyone know how or when it'll be available?  Free?  Commercial?



STEVE:  I just wanted to make a note, a number of people were excited by my positive review, I mean, surprisingly positive.  It's like, okay, I want one of these.  The lead author of the whitepaper shot me a note thanking me for the coverage of CryptoDrop last week.  And I wrote back and congratulated him and his three co-authors and said, as soon as there's something that our listeners can take action on, like something they can download, please let me know.  So as soon as that happens, I will let everyone know.



LEO:  Very nice.  And last and least, Ryan Young.  [Indiscernible] not least.  No, no.  If you're last, you're least.  Ryan Young.  Steve...



STEVE:  At least you're not penultimate.



LEO:  Yes.  That was this other guy, Bruce.



STEVE:  That's right.



LEO:  Steve, do I need a Level 3 packet switch to segregate my network?  Or can a virtual network in DD-WRT accomplish the same thing?  I would like to set up a segregated open network with limited bandwidth on my router, but I don't want anything, anything to get into my home network.  I love the show and can't wait until Tuesday for a new one every week.  Thanks for all the expertise.  Well, thank you, Ryan Young.



STEVE:  Yes, thanks, Ryan.  And I want to say again, this is a big problem with virtual LANs, VLANs.  It is easy to confuse it with security.  It is not.  Virtual LANs are useful for administrating a huge, sprawling network and sort of Ethernet because Ethernet doesn't - there's a point at which Ethernet stops scaling well.  Because of the nature of packet collisions, if a single Ethernet gets too large, it starts to fail.  So virtual LANs can be used to logically segregate Ethernets, but the physical enforcement has to be performed by a VLAN-aware switch, that is, a switch which sees packets tagged for specific virtual LANs and then only sends the packet out of that port of the switch.



The thing to understand is that the VLAN tag is just data.  It's nothing magic.  It's a slightly extended couple fields in the Ethernet frame which allows this management of the frames.  But confusing that with security, that is, isolation, gets you in trouble because if something else can see packets on another VLAN, well, it just ignores the tag.  Even if it's not for its VLAN, it's for a different VLAN, it can still see it.  So you're gaining nothing for security.  And it can spoof packets for the other VLAN simply by changing that tag in the Ethernet frame.



And he mentions DD-WRT, so it's probably in one of the, as I call them, the blue box routers, which are a router coupled to a four, typically, four-port switch.  But that's just a switch.  That's not four separate interfaces like the Ubiquiti routers that we've been talking about have.  It's just a switch.  So there is no isolation available between those ports.  You need something more.



LEO:  You did it again, Steve.  Twelve questions, a new world record.



STEVE:  And right on schedule. 



LEO:  Right on time.  We do Security Now! by GRC's Steve Gibson every Tuesday, about 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  If you want to join us live, love it if you do.  But if you can't, no problem.  No problem because we have on-demand of every show.  Steve's got a copy of the audio at his site, GRC.com.  He's also got a lovely written transcript so you can read along as you listen.  You can watch and listen at our site, TWiT.tv/SN.  And you can also subscribe because there's a million ways to get podcasts, whether it's iTunes or Google or Stitcher, I mean, it just goes on and on.  And of course all the great TWiT apps on every platform.



When you visit GRC.com, don't forget to pick up a copy of SpinRite, the world's finest hard drive maintenance and recovery utility.  He also has lots of free stuff there.  SQRL, find out more about that, where they sit in development.  If you have questions for Steve, you can ask him here, but you can also ask him on his Twitter handle, @SGgrc.  He is open to DMs, to Direct Messages, so you've got several places you can talk to him.  GRC.com is the website, @SGgrc on Twitter, and here every Tuesday.  Which doesn't seem like enough.  But, you know, I don't want to take any more time away from your very important projects.  So thank you, Steve.



STEVE:  My pleasure, my friend.  Talk to you soon.  Well, talk to you next week.



LEO:  Next week.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#571

DATE:		August 2, 2016

TITLE:		Phishing & Filtering

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-571.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up with the past week's security happenings, including LastPass vulnerabilities, new wireless keyboard headaches, deprecating SMS as a second authentication factor, obtaining Windows 10 for free after July, and a bit of errata and miscellany.  Then we discuss RAID storage redundancy, the pervasive problem with website spoofing, and the power and application of multi-interface packet filtering.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here to explain all.  We've got a bunch of security news as we head into DEF CON and Black Hat, the big hacker conferences coming up this week.  He'll talk a little bit about that, answer some questions from the Twitter audience.  We will also talk about phishing scams and filtering, particularly the Ubiquiti EdgeRouter X.  And we were going to talk about RAID 5 and BeyondRAID, Drobo's RAID 5 interpretation, but I think we'll defer that for another day.  So phishing and filtering, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 571, recorded Tuesday, August 2nd, 2016:  Phishing & Filtering.



It's time for Security Now!, the show where we cover all the latest security news and help keep you safe and help you understand what all this stuff means.  And thank goodness we have the Explainer in Chief here.  I noted, by the way, that at the Democratic Convention they stole your title, Explainer in Chief.  Did you note that when that happened?



STEVE GIBSON:  And I'm wondering, was that a title that Clinton, that Bill always had?



LEO:  No.  George W. Bush called himself the Decider in Chief.  The Explainer in Chief, as far as I know, is you and no one else.  So was it Hillary, or was it Chelsea who called Bill their Explainer in Chief?



STEVE:  Yeah.



LEO:  I think referring mostly to his garrulous nature, more than his deep understanding of technical topics.



STEVE:  Yeah, yeah.  He certainly wasn't giving his wife very good technical consult about how to handle her email.



LEO:  No.  Anyway, so here he is, the real Explainer in Chief, not Bill Clinton, but in fact Steve Gibson.



STEVE:  Indeed.



LEO:  Hi, Steve.



STEVE:  So I titled this podcast RAID, Phishing, & Filtering for a couple reasons.  There's just sort of three big topics I want to talk about.  I'm thinking maybe I'll wait till we have another Drobo sponsorship before I go into RAID stuff because this was sort of relative to that.  But there was some news about QR code hijacking, which is really about phishing.  And we haven't talked about the phishing problem, but it's interestingly intractable.  And so I wanted to spend some time talking about that.



And we've been talking a lot about this notion of multiport routing and packet filtering.  But I realize I've also just sort of glossed over some of the details which I think a lot of our listeners would find really interesting.  It is, it's down at that packet plumbing level.



So we have some interesting news this week.  But then I thought I'd spend some time covering some just sort of relevant technology.  Also, this is the calm before the storm.  This happens every year around this time.  It gets kind of quiet.



LEO:  Yeah, yeah.



STEVE:  Now, we're also going to talk about LastPass vulnerabilities that happened last week.  There are some new wireless keyboard headaches.  SMS as used for second authentication factor is being formally deprecated because of the vulnerabilities that actually we anticipated months ago.  Some news about obtaining Windows 10 for free after July.  We have a little bit of miscellany and errata, and then our main topics.



But one of the reasons - this wireless keyboard content is interesting because it was a sneak peak into one of the presentations that will be happening at the end of this week.  We are approaching - Thursday, Friday, Saturday, and Sunday - DEF CON 24.  And so it was in, what, 1992, I think, was the first one, so 24 years ago.  And it's been going strong ever since.  And of course it's always at this time, in the late summer, we just are buried with really interesting new fun hacks to talk about which arise from that.  So things kind of get quiet beforehand because all the hackers were saving up their goodies for presentation during DEF CON.  And so we've got that.



The Picture of the Week someone sent me.  I got a kick out of it. It's someone named Robb Stark, R-O-B-B Stark, and he tweeted it, @5stringplayer.



LEO:  You think that's his real name?



STEVE:  Maybe.  I mean, on the Internet you never know.



LEO:  You never really know.



STEVE:  But what we do know is that this guy is crazy mad for SpinRite.  And I don't know, like, what the setting is.  You can kind of see behind, maybe it's an office facility.  But he's got - this picture on the show notes is four separate screens, each running a copy of SpinRite on four different machines down below.  And he's brought the power and SATA connections out the front so that four different drives are hanging, dangling from the SATA power and data connections.  And if you look, you can see there's two little cartons over between the first and second and the second and third.  The first one says "Awaiting SpinRite," and the second one, on a green big Post-it note, says "SpinRite Complete."  So it's whole...



LEO:  This is really amazing.



STEVE:  It's a SpinRite production system, essentially.



LEO:  Wow, good for him.



STEVE:  I don't know any of the back story behind this, but I just got a kick out it.



LEO:  He's got four PCs, and he's SpinRiting everything, man.



STEVE:  And he says, "Now, this is how you SpinRite."  And I said, yeah, that's definitely the case.



LEO:  That's great.



STEVE:  Kind of spooky.  Kind of spooky.



LEO:  That's really awesome.  Yeah.



STEVE:  It's spooky, too, because if you look in the upper right corner of the screen, that's actually - see that larger rectangle in the upper half on the right side on each of those screens, that's the actual data in the drive.  And it goes flashing by as you're watching it.  And it's a little disheartening sometimes to see what is happening because it's the actual data on the drive as SpinRite is reading it.



LEO:  Wow.  Well, I hope this isn't an NSA facility because, if it is, he's probably leaked some critical passwords or something.



STEVE:  It's definitely a nice little setup.



LEO:  That's cool.  That's really cool.  



STEVE:  So after the podcast last week came the news of some problems with LastPass.  And it was a little muddied because there were two different researchers.  Tavis got involved, our friend Tavis Ormandy, who took a look at LastPass.  And he  tweeted that he had found something and was in communication with LastPass, and they were working on it.



Then separately, for an unknown reason, I don't know if it was just to get some click traffic or what, but another researcher who had reported something a year ago, that has long since been resolved, chose to freshly post the URL.  And so that got everybody in a concern, thinking that this was a new problem.  And it wasn't a new problem.  And in fact we talked about it a year ago.



So, but there was one thing that was interesting and new.  What LastPass wrote in their blog in two parts, the first part said:  "We want to share a quick update with the LastPass community about important fixes that we have made in response to two recent security reports."  Now, that's a little odd because they said "...in response to two recent security reports.  Our team worked directly with the security researchers to verify the reports made and issue a fix to LastPass users.



"The recent report only affects Firefox users.  If you are a Firefox user running LastPass 4.0 or later, an update will be pushed via your browser with the fix in version 4.1.21a.  If you would like to update your client proactively, you can update with our download link here."  And then it's lastpass.com/lastpassffx.  I'm not sure why.  Oh, Firefox fix, I guess.  Or just Firefox, ffx, Firefox.  "You can check which version you are running in your LastPass browser add-on, under the More Options menu in About LastPass.  If you're running LastPass 3.0, you are not impacted and do not need to update."



Well, now, okay.  So a little more information here.  The 3.0 series is what Mozilla has available from download LastPass add-on.  I was running v3.3.1.  So this never - and of course, as we all know, I'm still an avid Firefox user.  But no one using LastPass v3 point anything was ever in danger.  So something that they did only for the Firefox version, when they went to v4, caused this problem that Tavis found.  And they continue:  "Other browsers are not impacted by this report, and users do not need to take action for other browsers.  As always, we appreciate the work of the security community to challenge" and so forth.



And they said, in their second portion:  "Security is fundamental to what we do here at LastPass.  Our first priority is always responding to and fixing reports as quickly as possible.  In follow-up to recent news, we want to address in more detail two security reports that have been disclosed to our team.  One report was disclosed yesterday, while the other report was responsibly reported and fixed over a year ago."  So their initial statement was incorrect, that this was in any way something new that needed some attention.  Apparently, as they said, that was long since fixed.



And then they said:  "Notably, both exploits do require tricking a user via a phishing attack into going to a malicious website."  And my interest in talking about phishing is, I mean, this is an interesting coincidence, but not my main focus.  They said:  "The first report was responsibly disclosed to our team over a year ago by security researcher Mathias Karlsson and fixed at that time.  Karlsson recently posted his findings on the URL parsing bug," which he had found.  "All browser clients were updated, and Karlsson confirmed our fix at that time, requiring no action from our users."  So this was just old news that sort of recycled because he posted it, even though it had been fixed a long time ago.



"The second report," they write, "was made yesterday by security team researcher Tavis Ormandy, who contacted our team to report a message-hijacking bug that affected the LastPass Firefox add-on.  First, an attacker would need to successfully lure a LastPass user to a malicious website.  Once there, Ormandy demonstrated that the website could then execute LastPass actions in the background without the user's knowledge, such as deleting items.  As noted below, the issue has been fully addressed, and an update with a fix was pushed to all Firefox users using LastPass 4.0."



So this is, as we know, this is the model, in fact this is almost better than the model.  One of the things that - I have Tavis's disclosure, which he withheld.  And this is all part of Project Zero that we've talked about often, where Google's Project Zero is looking for bugs, not only in Google's stuff, but elsewhere in the industry.  He commented on and actually remarked about the speed with which LastPass responded, virtually immediately.



And it was funny because in their standard boilerplate they talk about, I don't remember now if it's 60 or 90 days.  But they start a clock, as we've often talked about.  And when that clock expires, this thing goes public, whether it's been fixed or not.  And so Tavis commented that the clock is irrelevant in this case because it's already fixed.  Before he got his posting done it had been resolved.



So anyway, what he found was a way of malicious script interacting with the JavaScript which LastPass injects into a page in order to function under Firefox.  We don't yet have a standard for browser add-ons, so every browser exposes a different means for automating its functions.  And whatever they did in v4 created this opportunity which Tavis found where a window was being created which was used to pass messages to the add-on.  And if malicious script from a malicious website was targeting LastPass Firefox users while this was not fixed, then it would be able to essentially execute LastPass commands in the background.



Again, it's really difficult, especially in JavaScript land.  It's why there have been postings on the 'Net saying JavaScript is harmful to security, just because it's very tough, due to the nature of the JavaScript language, which was designed a long time ago.  They're trying to increase the security, adding technology to create more containment.  But it's just difficult.  And we have the problem that, when you go to a website, browsers download script from that website.  It's hard to find something that is more problematical.



Anyway, so this got fixed in as good a way as you can imagine.  And for what it's worth, anybody like me who stayed on v3 was never in danger.  This was a bug that got introduced for Firefox only, whatever they did to change it to v4.  I did update to v4.  The UI has changed.  It sort of seems like it's running a little bit better for me.  So I'm glad for that.  And bravo for LastPass continuing to do good by us.



Somebody, there was a lot of - when Tavis posted this, there were a lot of people who said, hey, what about 1Password, which was like, I just saw several tweets to that effect.  And he actually, Tavis actually posted a kind of a joke picture of some guy, kind of bug-eyed, looking at the screen and saying "My first reaction to what I've seen in 1Password."  So we don't know what that is yet.  But again, this is hard to do.  It is very challenging to do this correctly.



So the best we can hope for is that the fundamental architecture is solid, that is, the concepts are solid; and that people like Tavis will look, pry it open and look closely at the specific implementation details because that's what this was.  It was an implementation flaw that apparently, I mean, didn't require any rearchitecting or anything, they just fixed it instantly.  So it was like, ooh, crap, sorry about that, and everybody gets a new one.  So, okay.  



So, wireless keyboards.  This was in the news last week because there was a sort of a little snapshot, actually a big snapshot.  You can go to KeySniffer.net, which is a site that was created to host some of the documents and presentation which will be shown later this week at DEF CON 24.  So the short version is the only way to use a keyboard safely is with wire or Bluetooth.  And the problem is that Bluetooth is a little expensive.  I mean, it's not prohibitively expensive.  There are plenty of Bluetooth keyboards around.  But what companies try to do, because they're trying to produce very low-cost keyboards, is they think, we don't need all that Bluetooth overhead.  It's complicated.  You need a processor, I mean, you need a lot of technology.  So they just - they try to take a shortcut.



These guys, Bastille Research, looked at eight different keyboards.  And these are not obscure, so these are non-Bluetooth wireless keyboards.  That's the phrase of death:  "non-Bluetooth wireless."  You don't want those words all put together in one phrase to describe the keyboard you're using.  Anchor, EagleTec, General Electric - I didn't know they made keyboards.  Hewlett-Packard, Insignia, Kensington, Radio Shack - I don't think they're making keyboards any longer - and Toshiba.



LEO:  Not Logitech.



STEVE:  Not Logitech.



LEO:  Because they're easily the largest wireless keyboard maker.



STEVE:  Yeah, although they do have their own little dongle gizmo.  



LEO:  They do, yeah.



STEVE:  And so I don't know if these guys didn't look at it, or if they didn't find a problem.  But here's the story.  It turns out that all these keyboards are using the 2.4 GHz band.  And they're simply depending upon obscurity.  That is, they've developed their own little protocol.  There's no encryption.  They're just figuring, eh, you know, nobody's going to notice.  So last Tuesday...



LEO:  Last time we talked about that, weren't they using, like, ROT13 or something to...



STEVE:  Worse.  It was XOR.



LEO:  Oh, they were XORing.



STEVE:  It was a Microsoft keyboard.  And as we know, ASCII is eight bits.  And so there was the secret was a byte.  And so...



LEO:  Just XOR it with a byte.



STEVE:  And it was a static byte.  And so what that would do is it would flip, it would invert some of the bits.  That was the encryption.  And so that technically allowed them to say "encrypted keyboard" and make everyone feel all warm and fuzzy.  But encryption like, oh, goodness.  And it would be a perfect, like a perfect test question on a final exam in Crypto 101.  Here's a series of bytes coming from the Microsoft encrypted keyboard, received over the air.  What does this say?



And what you would do is you would look for a byte that was repeating like where a space would probably be.  And then you'd check your assumption, if that makes sense.  Then you would know that that was a 20 hex, which is a space.  But it wouldn't be a space, it would be something different.  But the bits that were different from 20 hex would be what was known as the "syndrome," that is, that thing that you XOR.  That would then allow you to immediately determine how to flip all the other bits in the message, turning it into ASCII, and then you could read it.  So that, you're right, that's what we talked about back then.



LEO:  I now understand why Bastille didn't mention the Logitech, because in February they published a report saying the Logitech, Dell, and Lenovo keyboards that use dongles have a design flaw that makes it easy for hackers from as far as 90 meters away to pair with your dongle.



STEVE:  Oh.



LEO:  So they do use 128-bit encryption.  They use transceivers made by Nordic Semiconductor.  But not all of the keyboards and mice apply it, or [crosstalk] apply it.



STEVE:  Ah.  Okay, so to give people a sense for this, what they're going to be demonstrating in a couple days allows a hacker with a $12 radio device - actually there's a microcopter, you know, like a microdrone?  There's a microdrone transmitter which is a USB dongle that you can find for $12.  And so it's just a little - it's got the USB connector on one end and one of those cute little mini RF connectors on the other to hook an antenna to.  And that's all you need.  So $12 to intercept the communication between any of these eight wireless keyboards and a computer from up to 250 feet away.  So it gives the hacker the ability to both type keystrokes on the victim's machine, so injecting keystrokes, and record all of the target's typing.  So this is - we would call this "no security through obscurity."  No encryption used.  It's just, I mean, just no thought given to security.



So in their write-up they note that:  "Each of the vulnerable keyboards is susceptible to both keystroke sniffing and keystroke injection attacks, keystroke sniffing enabling an attacker to eavesdrop on every keystroke a victim types on their computer from several hundred feet away.  The attacker can recover," of course, "email addresses, usernames, passwords, credit card information, mailing addresses" - anything that the user types.



The keyboards are vulnerable to this product of theirs, this KeySniffer software they wrote, using USB dongles at the computer end, because the USB dongle sends out a ping.  At regular intervals it's broadcasting, which allows attackers who are aware of this to quickly survey an environment such as within a room, a building, or a public space, for any vulnerable devices, whether anybody is using the computer, typing on the keyboard or not.  So all of these also broadcast the fact that this is a target-rich environment.  As long as the computer is turned on, and this USB keyboard dongle is powered up, it's sending out a beacon saying "Hack me, hack me, hack me," which their software is able to pick up.



So anyway, bottom line is Bluetooth, as we've discussed years ago, is a well-designed, very secure protocol.  You either want a Bluetooth keyboard or a keyboard with a wire in order to be safe.



LEO:  Good to know.  Good to know.



STEVE:  Yeah.  And I'm glad you followed up because I knew that they had been involved, like nine months ago, that they were doing something else, but I didn't pursue that.



LEO:  Yeah.  Just use a wire.  They don't mention Apple in either of these, but I'm guessing Apple probably is aware of these issues.



STEVE:  Apple's all Bluetooth.



LEO:  Yeah, it's all Bluetooth.  So that's safe.



STEVE:  Yeah.



LEO:  Yeah, okay.



STEVE:  NIST, our National Security government group that generates standards, essentially, for interoperability and use, just posted on the 26th of last month, so last week, an update to their guidelines, among other things dealing with authentication.  And they said - they made some changes from what they had said to what they're now saying.  And it's a big long document, but there's two relevant paragraphs.  The first says:  "If the out-of-band verification" - so that's of course what this is.  The idea of anything out of band is some other channel than the one you're using.  So if you're sitting in front of your browser, talking to a remote server, and it wants to authenticate you, then your phone is out of band.  It's not part of that channel between you and the server.



"If the out-of-band verification is to be made using an SMS message on a public mobile telephone network, the verifier shall verify that the preregistered telephone number being used is actually associated with a mobile network and not with a VoIP or other software-based service.  It then sends the SMS message to the preregistered telephone number.  Changing the preregistered telephone number shall not be possible without two-factor authentication at the time of the change."  So they're just sort of formalizing that, but then they deprecate the whole thing.  They then say:  "OOB, out-of-band verification, using SMS is deprecated and will no longer be allowed in future releases of this guidance."



So this is sort of interim, if you have to use it, if you're using it, at least use it wisely.  But we're now formally saying this is not safe.  And of course we talked about this weeks ago.  And I don't remember now, I was setting up - oh, it was with Hover.  When I was establishing my account at Hover, they offered multifactor authentication, and I had a choice of using the temporal-based key or SMS messaging.  And I mentioned on the podcast at the time, no way am I using SMS messaging.  Not only is it a problem, but you're sending something important every single time you want to authenticate.



The beauty of using a key-based, time-synced cryptography is that you establish that once, and you never need, you know, nothing goes over any wires anymore.  It's just the fact that each endpoint knows the same secret that allows them, based on the current time of day, to generate the same six-digit code in order to verify.  And of course that changes, due to the secret key, in an unpredictable fashion.  So that's the right solution for that kind of additional factor not sending SMS messages.  SMS messages, of course, were used because people who have a smartphone can receive them without any - it's just sort of easier.  What's the message we just sent you?  Unfortunately, as we've seen, the inter-service provider messaging, that SS7 is just...



LEO:  Broken.  Broken.



STEVE:  Just never was built with strong authentication, and it's just too easily hacked.  The movies that show it being hacked are a little less fiction than we would like them to be.



And then I got a kick out of this.  Just on the Windows 10 front, there's a page that I linked to in the show notes.  You might get a kick out of it, Leo, if you click on that and bring it up.  It's the assistive technologies backdoor into free Windows 10 upgrades.  As we know, Windows 10 upgrades ended on July 31st.  So they're no more.  Yet, if you tell Microsoft that you need to take advantage of assistive technologies, then you press that button down below, and you immediately get a download option for the Windows 10 update.  It's a little 5.5MB thing.  Probably - I don't know what happens if you're not in Windows.  Probably either it won't...



LEO:  It downloads an EXE, and I can't use it.



STEVE:  Ah, right, okay.  Yeah, so it's a little 5.5MB EXE that runs the Windows 10 upgrade for you.  So Microsoft says on that page:  "For the general public, the free upgrade offer for Windows 10 ends on July 29.  However, if you use assistive technologies" - I guess, for example, someone tweeted, well, does that mean if I've ever used a screen magnifier, then I qualify?  It's like, well, yes, that would be an assistive technology - "you can still get the free upgrade offer, even after the general public deadline expires, as Microsoft continues our efforts to improve the Windows 10 experience for people who use these technologies.  With the Windows 10 Anniversary Update, we've taken a number of steps to improve the accessibility of Windows 10 accessibility.  To learn more" - I fact, we've made it very accessible.  Just press the button, and you can access it.



LEO:  It'd be sad to take advantage of that.  I mean, they're trying to be good to people who use JAWS and other screen readers that aren't compatible.



STEVE:  Well, come on.  After a year of having this force-fed down the throats of...



LEO:  No, I disagree.  I think that's taking advantage of Microsoft doing the right thing.



STEVE:  Ah.



LEO:  I would not do that if I were - I think that'd be unethical to push that button if you weren't using assistive technology.



STEVE:  Well, the FAQ says:  "When does the free upgrade offer extension end?"  Oh, you mean because it's bypassing buying a copy of Windows 10?



LEO:  Exactly.



STEVE:  Oh.  Anyway, so in the FAQ they said, "When does the free upgrade offer extension end?"  And then they say:  "We have not announced the end date of the free upgrade offer for customers using assistive technology.  We will make a public announcement prior to the end of this offer."



LEO:  They're probably waiting till the major assistive programs all work with Windows 10.



STEVE:  And I posted in the newsgroup the question this morning, GRC's Security Now! newsgroup, wondering what experience anybody has had so far since July 31st.  Of course relative to, for example, Never10 and the need for any GWX management.  And one person, by the time I put the show notes together, Dave DeBruce, responded.  He said:  "I never installed KB3035583, which installs the Get Windows 10 installer.  It has been sitting in my Recommended Updates for quite some time.  Yesterday I noticed" - that is to say Monday, so August 1st - "that after an update check, it is gone.  So Microsoft has at least pulled this update out.  I know that's not what you asked, but it does look as if they are pulling this stuff out."



LEO:  I did get an email from somebody who didn't try to take advantage of the upgrade offer till the 31st.  And it ran and worked, and he got authenticated.



STEVE:  On the last day.



LEO:  No.  The last day was the 29th.  So he waited a couple of days after the last day.



STEVE:  Oh, on the 31st.



LEO:  Yeah.



STEVE:  Ah.



LEO:  So I'm not recommending this as a policy.  We also have a number of people I know, and one of them works for me, who got stuck at 99%.  This is a fairly common upgrade problem.  And it's still stuck.  And Microsoft's advice is to go to the Microsoft Store, and they'll help you get through it.  And I would imagine at that point they'd arrange for authentication.  So they're not - I don't know how cranky they're being about it.  Apparently there are some people still doing it.



STEVE:  Well, I mean, I'm sure you'll talk to Paul and Mary Jo about it tomorrow and see, like, is it, I mean, it's always been a question.  I've heard you and Paul and Mary Jo talking...



LEO:  They don't - it's not the, yeah, I mean, Microsoft's very clear that it is not free anymore.  But if their software lets you do it, I guess it's okay.



STEVE:  Well, and also remember, too, that everyone knows, and we've talked about it on the show, and you and Paul and Mary Jo talk about, if you upgrade to Windows 10 and make sure that you're authenticated, I think I've heard you talk about it in fact on The Tech Guy.



LEO:  Yeah.



STEVE:  Make sure that you are registered and - what's the term?



LEO:  Entitlement.



STEVE:  Entitlement, right.



LEO:  Your machine will get an entitlement to Windows 10.  And that entitlement is good forever for that machine.



STEVE:  Right.



LEO:  So you could opt to go to Windows 10 later.  But you have activated on that machine, that's the key.



STEVE:  Right.  A couple little bits of errata.  Bruce Wilson, who's an enterprise architect with Oak Ridge National Laboratory, he tweeted a note.  His Twitter handle is @usethedata.  So he confirmed my concern, which we discussed last week, over Firefox not being immune to certificate tampering.



Remember that we had, in our Q&A last week, one of our listeners said that his corporation does have an encrypting or decrypting proxy, and has pushed a certificate onto their machines.  But Firefox uses its own certificate store.  Does that mean that he's safe?  And I wasn't able to definitively say one way or the other.  I said, well, yeah, it is true that it has its own store, but I don't know that it's not possible for that to be affected also.  And even if it weren't affected, that is, if you could maintain security, it might very well be that a tightly locked-down corporation would prevent Firefox from getting an HTTPS connection out to the Internet unless it went through their proxy.  So you might not be able to use Firefox either way.



Anyway, but Bruce confirmed, from his experience, he said, regarding using Firefox to avoid corporate spying:  "If a Windows box is joined to an Active Directory domain, the corporation can run any arbitrary script on the box, including scripts to push a certificate into the Firefox certificate store.  Fundamentally, if it's a corporately managed system, tools like" - and he writes SCCM, which is the System Center Configuration Manager, formerly known as SMS, which is the Systems Management Server - "allow the admins to do pretty much anything."



So I wanted to close that loop, that, yeah, I mean, so the next solution is certainly more overhead, but that would be to use a VM.  Get like a little virtual box or as small a little VM environment as you can and put Firefox in there.  The corporation and its scripts will not be able to get in and alter Firefox's certificate store running in a virtual machine, yet the virtual machine would still be able to have access to that workstation's networking, and then you could see whether you're able to serve privately, whether you are able to establish a connection out to the Internet without going through the decrypting proxy.



And second, a bunch of people - I sort of anticipated this, but it was fun to see the response - took some exception to my comments about how TIFF format was dead and saying, no, no, no, no, no.  Apparently library sciences and archiving are big on TIFF images.  And due to its age, that's sort of the default format for fax scanning.  And that's all true.



LEO:  Yeah.  A lot of scanner software still scans to TIFF, as well.



STEVE:  Yeah.  And I should have noted also that, in fact, file formats never die.  I mean, in the same way that old software doesn't, it's still around, file formats, eh, no.



LEO:  TIFF has a good place because bitmap is uncompressed.  JPEG is lossy compression.  TIFF has lossless compression built in.



STEVE:  Like PNG.  PNG is sort of the inheritor of the lossless compression format.



LEO:  PNG is lossless?  It's not lossy?



STEVE:  Yeah, lossless.



LEO:  Oh, all right, cool.



STEVE:  Yeah.  And actually very good compression technology, too.



LEO:  Yeah, much better than TIFF, I'm sure.  TIFF uses Lempel-Ziv.  



STEVE:  If you ever want proof that old formats never die, look at any graphics program under the Save As menu.  It's like, I mean, it's just - and it's not like anyone would implement a driver for some of those.  It's just that v1 of Corel Draw or Photo Paint had support for it, so v25 does, too.  So, I mean, really obscure things that no one has ever seen.  And, yes, TIFF, as well.



LEO:  TIFF is - somebody in the chatroom is saying it's also multipage, which is why it's still used for faxes.  Like PDF, you can have multiple pages in a TIFF.  You can't do that in a PNG or a JPEG.



STEVE:  Right.



LEO:  So, see?  There's still some good.  There's still some life left in her.  



STEVE:  I got a note - no, I didn't get a note.  I stumbled on this last week, and I tweeted it.  Peter Hamilton has written a short book, believe it or not.  He calls it a novella.  And he's actually written several others before.  So this short form is something that he likes.  Anyway, it was apparently just released last week.  I just wanted to give our listeners a heads-up.  It's called "A Window into Time."  Four dollars, so not very expensive.  Not very long, though, 95 pages.  So, yes, an actually short book.



The back cover gives us a little clue into what it is, saying:  "Whip-smart 13-year-old Julian Costello Proctor, better known as Jules, has an eidetic memory.  For as long as he can remember, he has remembered everything.  'My mind is always on,' he explains.  But when an unexpected death throws his life into turmoil, Jules begins to experience something strange.  For the first time, there are holes in his memory.  But that's not the strangest part.  What's really weird isn't what he's forgotten, it's what he remembers.  Memories of another life, not his own.  And not from some distant past.  No, these memories belong to a man who's alive right now.



"With bravery, ingenuity, and quirky good humor, Jules devises a theory to explain this baffling phenomenon.  While tracking down the identity of his mysterious doppelganger, he finds himself enmeshed in the hopes and dreams of a stranger - and caught in the coils of a madman's deadly plot."  So it sounds fun.  And I don't think I've read a bad Hamilton book.  I've read some really laboriously long ones, notably "The Great North Road."



LEO:  Short might be good.  Yeah.



STEVE:  "The Great North Road."



LEO:  Short might be an advantage.



STEVE:  Yeah.  Yeah.  And I just trust Peter.  I remember thinking, you know, "The Dreaming Void," that just really sounded like not something I want.  I don't want - and it turned out to be fabulous, a wonderful trilogy.



LEO:  That wasn't the Al Capone one.



STEVE:  No.



LEO:  That was not so good.



STEVE:  That was the reality dysfunction one.



LEO:  Yeah.



STEVE:  And I agree with you, Leo, that kind of went a little bit off the deep end.



LEO:  Yeah, yeah.



STEVE:  But a lot of people loved it.  And by the way, somebody has already finished it from my tweet, someone named Steverino, of all names, says:  "Thanks for this fun little read, Steve.  'A Window in Time' was thoroughly enjoyable and short."



LEO:  Yeah, nice.



STEVE:  And I did have a fun story.  I thought that maybe we would be talking about Drobo, so I had a SpinRite Drobo adventure to share.  Istvan Burbank, maybe Istvan Burbank.  Anyway, he said, "Ah.  I had used a Drobo for years before my own NAS, and have only good things to say about it, especially about being able to put different sized drives in."  We'll see why in a second here.  He says:  "I ran SpinRite on friends' broken drives, recovered the drive, and copied their data to a new drive.  And if the fixed drive was bigger than one of the drives in my Drobo, I would hot swap it in without much worry about the drive failing again due to the Drobo's redundancy, and my Drobo's capacity would automagically increase."



So I thought that was kind of clever.  He's helping his friends.  He's using SpinRite, recovering their data, then cloning that to a new drive.  And he's now got a drive that's like, eh, well, we're not quite as sure about it as if it had never failed, so we'll stick it into a place where, if it has any trouble, we'll be protected.  So kind of clever.



LEO:  That's cool.  That's a good idea, actually.  And that would be a good place to put it, a Drobo would be, actually, because if it fails, no big deal, just put another one in.  Yeah.



STEVE:  Yeah.  So phishing and filtering.  [Sigh]



LEO:  [Sigh]  I like that.  [Sigh]  Where do I begin?



STEVE:  Where do we start?  So here's, okay, so here's the problem.  And phishing is sort of the way you stumble into the larger problem, which is website spoofing.  It's something that I've spent a lot of time over the last three years looking at because of course I'm actively involved with SQRL and this authentication solution, where this has really dogged me.



And in fact the whole project, essentially, I wouldn't say it came to a stop last summer, but I took it on a diversion because I didn't feel like I clearly understood exactly what the nature of the problem was in the context of SQRL.  And I absolutely wanted to make sure there wasn't a solution, there wasn't something we had missed.  And as it turns out, I found a solution and implemented it and made it go, and it works.  And then we decided, eh, we would alter the spec to support it.  But as I'll explain later, we ended up not - I ended up removing it from the client.



Okay.  So here's the problem.  And to varying degrees, every authentication technology is vulnerable to it today.  Some modes of SQRL are very resistant, but there are still edge cases.  And it is just a problem that the industry as a whole doesn't have a good solution to.  And that is, if the user of a web browser is fooled about where they are, that is, you believe you're on a website that looks exactly like your bank - and we've talked about this through the years but never really looked at the exploitation side, which is what I wanted to talk about today.  If you miss the fact that the domain name is not correct, it's not BofA.com, and there have been, of course, all kinds of, I mean, this problem has been around for so long that there's a long history of exploits of this problem, that is, how do we fool the user into believing they're at one site, when they're actually at another?



LEO:  Oh, I got a phishing scam I almost - I came this close to falling to.  It wasn't from Twitter.com, it was from Tvvitter.



STEVE:  Perfect example.



LEO:  The two V's looked just like a W.  You could barely tell the difference.



STEVE:  Perfect example.



LEO:  Yeah.  It's just a spelling difference; right?



STEVE:  And so here's why this is a problem.  Well, first of all, obviously you don't want to be at a site that, you know, the only person, the only reason someone is going to have you at T-V-V-I-T-T-E-R dotcom is they want to get up to some mischief.  And what should typically - what typically happens is you're presented with, oh, please enter your username and password.  So in the simplest case, you land on a spoofed website asking you to authenticate.  And most users will say, oh, okay, and enter their username and password.  Now, the bad news is, obviously, you've just sent your username and password to this malicious site that now has access to your actual account on the actual site.



Now, one mitigation is password managers because they're not fooled.  LastPass, for example, it's not going to get a string match on T-V-V-I-T-E-R dotcom.  It'll just come, I mean, it won't show anything.  It won't populate the fields.  It'll think you're at somewhere that you've never been before.  So that would be, like, a solution except that, in my experience with LastPass and password managers in general, and I know many others, sometimes what website do confuses the password manager.  So that even on a site that you know LastPass has an entry for, it's not populating the fields.



And so I know LastPass users do what I have done in such cases is you open the vault, and you manually copy your username and password over into the fields because for whatever reason the script on this page is fighting with the add-on.  And so what would have been a protection, unfortunately, through sort of social engineering, it's been defeated.



Now, this article that appeared that sort of put this on my radar and brought it to the fore was in the Hacker News last week.  There was an article talking about how the QR code logins can be trivially defeated with this approach.  And so in looking at it, it's like, yes, all logins can be defeated with this approach because, unfortunately, this spoofing is that powerful that we're still looking for some way to protect the user from fraudulent websites.  And unfortunately, as we've talked about in different contexts, even using multifactor authentication isn't a solution.



And so here's where it gets a little bit trickier at the plumbing end.  Because, for example, so you go to the spoofing site.  And the fake site presents you with a page asking you to authenticate.  What happens behind the scenes is that it, that is, the server running the site accesses - the server running the fraudulent site accesses the real site as if it were you.  That is, for example, maybe you fill in username and password and hit Enter.  That goes to the malicious server.  The malicious server essentially does the same thing you've just done, pretending to be you.  So it brings up a web page on the real site, provides it with your username and password.



It then notices that that site is requesting some additional authentication.  That is, even if you have established second-factor authentication, an out-of-band authentication, that site that it is impersonating you to challenges it for your second factor.  And it doesn't matter what the challenge is.  It could show a QR code and say, here's a QR code you need to scan.  Well, what does it do?  That malicious server grabs that QR code that is the second-factor authentication challenge and does, again, does the same thing to you on the malicious site.  It says, oh, you're using second-factor authentication.  Please scan this QR code.



So it has essentially inserted itself as a classic man in the middle.  And it has not done so by hacking into HTTPS or not having security and using an HTTP connection or anything.  It's simply done it because you're not actually at the site you think you are.  And that allows it to interpose itself into the communication chain.  And so this is what I spent so much time last summer brainstorming, was is there nothing we can do to prevent this from happening?  That is, for example, if you had a time-based second-factor, it would say please enter - the real site would challenge the malicious site for the six-digit code.  Seeing that, the malicious site challenges the user for the six-digit code.  The user says, oh, right, gets their phone or wherever they're running their authenticator, even one of the old-style PayPal footballs, you know, whatever, and enters the six-digit code into the site, which the malicious server then forwards to the real server, having succeeded and defeated the second factor.  Same thing for SMS.



I mean, whatever the challenge is, once this malicious actor has imposed itself between the user and the real site, anything - essentially, it's able to, even with HTTPS over SSL connections, because you're making a secure connection to T-V-V-I-T-E-R dotcom.  And it could even be an EV cert.  I mean, it could look authentic, although I'm not sure what it would say for the, well, I guess the issuer of the certificate would have had to have been willing to issue a certificate which was suspiciously like Twitter, and maybe you couldn't pass that.



But as we know, things like Let's Encrypt doesn't have any kind of human intervention there.  So certainly getting SSL certs no longer requires human interaction, making it even easier to pull off this kind of spoofing.  So once there is a malicious server in the chain, anything the real site provides, would be providing to the user, it provides to the malicious server, which then provides it to the user.  And it's able to maintain its position.



So the first thing I wanted to note is that this is a problem today that, to some degree, automated password managers can help because they're not going to see a string match.  They're going to say, wait a minute, this is not T-WI-T-T-E-R.  And so they won't automatically populate the field.  In my experience, the password managers tend to run across sites where they don't function as smoothly as they might often enough that an unwitting user would think, oh, well, okay, it's one of those, and then go manually populate it.



So again, it's not, doesn't give us the kind of strength we would like to have.  And any kind of additional logon information that anyone has been able to think of succumbs to this, whether it's an optical QR code, it's a time-based code, it's an SMS message.  For example, for a while we were talking about, like, choose which is the proper picture.  And then so you'd be shown a grid of pictures.  Well, again, the valid site challenges the user, which in this case unfortunately is the malicious server, with this group of pictures, which the malicious server forwards to the actual user as, oh, look, you've got to choose, find the kitty cat that you have chosen as yours and click on it.  So the malicious server sees you do that, it simply sends your response through it back to the valid site in order to defeat authentication.



So I wanted to explain first how this plumbing works, and why this is such an intractable problem.  It is very simple to get into this situation.  And phishing is normally the way you fall into spoofing because no one is going to themselves type in T-V-V-I-T-E-R dotcom.  We're all going to type in Twitter.com.  But links in email, links in social media postings, links in Twitter messages, anywhere where the process of going to URL has been automated, you just - you are expecting to go to Twitter.  And what comes up looks like Twitter.  And unless you are really good about looking at the URL, like making sure - and I have to say, as the co-host of a Security Now! podcast, when I'm doing something that is really important, I will, you know, I do make sure that, if this is something crucial, I go look at it.  But I know that most people don't.



And so this is the way we fall into this problem so much.  So the only mitigation that I've been able to come up with, working with the gang in the SQRL newsgroup, was a proposal that I presented to them last summer and then implemented.  And the idea was that the problem arises because of this man in the middle.  And what is somehow necessary is to short-circuit that man in the middle.  That is, to somehow get a direct connection between the authenticator and the user.  And this is something I've understood from day one was a problem.



The very first working spec for SQRL, for example, had this notion of it's a bit in what the server sends back to the SQRL client called "same IP" because that's one of the first giveaways which SQRL is able to capture.  And that is that, when in the SQRL implementation of this problem with phishing, the bad guy, that is, this malicious server, would ask the good server for the QR code.  And embedded in the SQRL QR code is the IP that made the request.  And when the SQRL client then scans the QR code, or if you have the client built into the computer, you just click on the QR code because it's a standard clickable href link.  The client running in the computer performs the authentication query with the server.



Well, we would expect the IP addresses to match in that case because the IP address of the user which requested the QR code should be the same IP as performed the authentication, if the SQRL client is in the same machine as what the user is using.  But that's not necessarily the case in a mobile login, unless your smartphone is also on the same network, on the same LAN, in which case you would have the same public IP.  But if it's on a wireless LAN, it's going to have a different IP.  So we've handled that in the specification, that is, this concept of whether the same IP is expected or not.



So in the case of somebody using SQRL to login where they have the client running in the same machine, or if they're logging into a mobile site with their mobile device, same thing.  You are protected because the IP that requested the QR code is the same IP as performs the authentication.  And that completely shuts out this man in the middle that's inherently at some other IP, somewhere on the Internet.



Now, it's true, if there was an evil person somehow operating in your same network, then you'd both have the same IP.  So we recognize that comparing the IP that requested the QR code to the IP address that's performing the authentication is not a guarantee of no spoofing, but it is very strong protection that doesn't exist anywhere else.



For SQRL, when the authenticator, the authenticating device, whether it's the same computer or a mobile device on the same network, is on the same network as the computer that you're using.  But we were able to do something one step more clever.  And this is what we implemented last summer, and that is, when the user logging into a site clicks on the link to authenticate, the web browser would generate a query to the client itself, to the local SQRL client.  There's a longstanding tradition in Unix of using so-called localhost servers.  You run servers on 127.0.0.1 is the localhost IP.  Basically it's the machine's own IP.  And I just got a pop-up here.  I'm sorry, it distracted me.



LEO:  What does it want?  Is it from some guy in Nigeria offering you $14 million?



STEVE:  Just microphone settings.  It's complaining about my microphone volume.



LEO:  You know, Skype has been laboring a little bit.  Your picture was kind of wonky for a while.  The sound's been fine, so I haven't said anything.



STEVE:  Good.



LEO:  They did, by the way, arrest Mike, the Nigerian prince.  He's been arrested.  He scammed...



STEVE:  No kidding.



LEO:  Yeah.  Well, he's one of them, I'm sure.



STEVE:  [Crosstalk] one Nigerian prince?



LEO:  They got one.  Apparently it scammed one person out of $11 million.  But many others, as well.  And, yeah, just arrested him.



STEVE:  Even now.



LEO:  Even now people fall for that.  You know what, probably lonely people who, you know, maybe just want to make a friend.



STEVE:  Maybe he's a nice prince.



LEO:  He's a nice prince.



STEVE:  Yeah, a nice prince.  So in this model, the SQRL client running in your machine sets up a localhost server on a well-known port that we reserve for SQRL so that the client itself, running in your computer, is able to receive queries from the browser.  And again, this is commonly done.  Unix, I don't think, could operate without localhost.  If you ever, I mean, and Windows is using it like crazy, as well.  It's just a very convenient way for different processes within a single machine to talk to each other through the sockets interface.



So the beauty of this is that, when SQRL is running in that mode, and you authenticate with SQRL, what we call it is we have an abbreviation, CPS, Client Provided Session.  What happens is the SQRL client sets a flag in the query to the SQRL authentication server saying "Client-provided session is in use."  So the server, instead of authenticating the browser's session, it sends the authentication token back to the client, which then it's able to set in the browser in responding to the browser's query because, as we know, when a server responds, it's able to set cookies.



So essentially this is a means where using SQRL with this feature, the remote server is sending the authenticated session back to the SQRL client, which it then gives to the local browser.  And the point is there's no way for any man in the middle to obtain that.  A man in the middle is wanting the session that it has established with the server to become authenticated.  The idea is that the malicious server initiates this login and then is forwarding everything to the user, to essentially perform the authentication on its behalf.



But the point is that by then forwarding everything to the server, the malicious server's session with the real server that gets authenticated, using this client-provided session feature, the real server sends that final authentication to the SQRL client, which then, in the same machine, provides it to the browser, to the user's browser.  So the user's browser is what gets the login session, not the man in the middle.



Now, we implemented this.  It was up and running.  Everybody was happy.  And then we found out that Microsoft was making noises about shutting down this whole localhost feature.  There was somebody who was participating in the newsgroup who was following developments at Microsoft, sort of the way Paul and Mary Jo do, you know, very much into what's going on.  And in Windows 10 it was not going to be allowed.  That is, this next version, the one that's now a year old, was going to be - and so imagine, this is just happening.  It was last summer around the same time.  We'd, like, solved this major problem, absolute bulletproof site-spoofing protection for SQRL.



And then the news that we cannot - we will soon not, like Windows apps will not be able to establish servers that other apps can access.  I assume this is just Microsoft looking for more ways to tighten things down.  At the last minute there was such an outcry from the developer community, because this was going to break so much, that Microsoft backed up, and the default setting was changed from default disallow to default allow.  But it's still there, and they're telegraphing their intentions.  And apparently there's - I don't remember now the term.  I'm sure you'll know it, Leo.  There's some class of apps that, like, Microsoft-approved apps or there's like somewhere you get them or something.



LEO:  Yeah, they're called UWP, Universal Windows Platform.  They're in the Microsoft Store.



STEVE:  Ah, exactly.



LEO:  It's like the Apple Store or the iOS stuff, yeah.



STEVE:  Right.  And those will not be permitted to use localhost communications.  Now, I don't know if I care about that for my own Windows client.  But it just seemed like, oh, shoot.  I mean, here was this perfect solution for this problem.  But it looks like we're not going to be able to count on it in the future.



So what we did was I ripped all that plumbing out of SQRL.  We backed out, went back to the previous design, but kept the client-provided session feature in the spec because what I think is foreseeable is that my Windows client, and even Jeff's running on iOS, and a bunch of people are working on them for Android, these are separate clients running on the platform.  It is entirely foreseeable that this will move into a browser add-on.  That is, it'll be maybe ultimately, if SQRL were to succeed, built into browsers natively.  So it's not even an add-on, it's just this browser is able to authenticate you with SQRL.



And if that happens, then the beauty is we no longer have this communication problem where the browser and an external client are trying to talk because the client will no longer be external.  It will be in the browser, in which case SQRL will be able to use this client-provided session, and it will be impossible to fool SQRL and for any man in the middle to obtain a login session when you're using SQRL that is either an add-on or natively built in the browser.



So we have strong protection today.  The only way of defeating it is strong protection with the same IP, which will catch any instance where we would expect the IP to be the same.  That is, you're using a mobile phone on the same network, or you're using a client on the same computer, in which case the public IP should be the same.  If they're not, we don't proceed.  And that would protect SQRL users from all of the typical man in the middle where there's another IP.  That malicious server IP would be detected and prevent any authentication.



But in general, this site spoofing is a big problem.  And so I wanted to create some context for that article that the Hacker News reported from someone who said, oh, look, you know, it's easy to fool these multifactor authenticators.  It's like - my screen keeps blanking out.  It's like, yes, it's actually - it's easy to fool everything.  This is a problem that has not been solved.  And the good news is SQRL provides strong but not perfect protection now, but the promise of perfect protection as soon as it actually moves natively into, well, either as an add-on or natively into browsers.



But, yeah, this phishing and website spoofing is a problem.  There's just no way around it.  It's been around forever.  We've talked through the years about all the ways of, like, obscuring a URL so that it's like www.amazon.co.uk - well, that's actually a valid domain.  But, I mean, www.amazon.info, you know, who knows who has that.  Maybe Amazon preemptively registered it.  But there are a lot of people who would see Amazon.info and think, oh, okay, that just - I guess that's okay.  I mean, this whole URL domain name thing was never designed for primetime.  It just sort of happened, and now we're stuck with it.  So anyway, I wanted to sort of go into more detail into the nature of the site spoof and why none of today's authentication systems provide perfect protection.  But happily there's some perfect protection on the way, courtesy of that little guy.



LEO:  Woohoo, SQRL.



STEVE:  Okay.  Second topic.  Packet filtering.  We've been talking a lot in the last couple weeks about these various routers.  This sort of began months ago when I switched from those two old T1 lines that I had to a cable modem.  And at that time I decided it was time to sort of dust things off and upgrade.  So I went with that little Soekris Engineering PC platform running pfSense.  And I'm so happy with pfSense.  It's also, as our listeners know, it is a great solution if you have an old PC, or maybe even like a little fanless, diskless PC.  It doesn't need much.  It just needs a couple interfaces because pfSense is freely downloadable, and you install it in a machine and set up a very capable router.



Then, in the context of Internet of Things, we've been talking, of course, for quite a while about the need for isolating networks.  And that's really what I want to talk about here.  And it's germane because not only could pfSense do that, if you had multiple interfaces, but then we found the little Ubiquiti EdgeRouter, which has five separate interfaces, each that can be configured to be a separate set of IP addresses, that is, separate subnets operating within your domain as individual Intranets.  And I haven't really gone into detail about what you do with these multiple interfaces.  And so I wanted to talk a little bit about packet filtering in the context of how any of these different multi-interface switches or firewalls would function.



And we also talked, for one week, I was talking about the Cisco SG300 device, which was the first thing I had found and liked.  That wasn't a router.  That was a multiport switch.  And there's a little, well, there are definite distinctions in what switches offer, what features switches offer versus routers.  But then of course we went from the SG300 to the Ubiquiti, which for $49 arguably provides the most bang for the buck I've ever seen.  The previous simple, low-configuration approach we've referred to often as the "three dumb routers," where you create - you take just three generic routers in a "Y" configuration in order to provide just plug-it-in, bulletproof network isolation.  However, if you begin to want to have some cross-network communications, things get a little trickier.



And I would argue, now that there is the Ubiquiti $49 router on everyone's radar, that just makes way more sense.  First of all, you've got much more flexibility and all kinds of cool features.  I don't think I've mentioned that the various rules which you use for configuring the router can, for example, have time-of-day enable and disable.  So, for example, the kids' network could shut down at 9:00 p.m. and just not work anymore until morning.  Or whatever you wanted to do.  So all kinds of flexibility.



So the way to think of these, any of these multi-interface devices is that plugged into each one of the physical ports is a network segment, which is, I mean, it could be just one IP.  But normally it's a block of IPs.  And I know that everyone who's been playing with home networking has seen 192.168.0.x, typically, or some routers are .1.x.  And in fact the spec, the IETF spec sets aside 192.168 dot anything dot anything.  So the last two bytes are completely available.  So that means you've got 64,000, well, minus some overhead per network, IPs available.



So, for example, one thing you could do, one way you could configure things is to number - you'll have one port that is the WAN, that is the Wide Area Network side, connected one way or the other, DSL modem or cable modem or whatever.  And as we know, it is possible to load-balance the WAN side, that is, you could have two WAN links, maybe of different types, so that if one goes down, the other one picks up the slack automatically.  That's the kind of power that we have with these late-model router devices like the Ubiquiti Edge Router.



But say that you just had one port for WAN going to a DSL modem or cable modem.  Now you've got four more ports.  And you could label them 0, 1, 2, and 3, and assign to each one of them one of those 192.168 networks.  So port 0 would be 192.168.0.x.  Port 1 would be .1.x.  Port 2, 2.x, and Port 3, .3.x.  So now you have four disjoint networks where they're able to be treated individually and independently.  And that's the key.  That's what's different between these routers, as I've said before, where you actually have not only physically separate ports, but logically separate ports, so that they can have their own networks assigned to them.  Well, more than that, they can have their own filters assigned to them.



So what's a filter?  The way to picture this is that on each of the ports, there is something inspecting the packets coming up the wire into the router.  Some access control systems allow you to specify filtering inbound separately from outbound.  But in general, most systems are inbound.  That is, so it's data coming into the port runs through, is like inspected with the so-called filters.  And once the data is past them, sort of in the inside of this device, it's free then to go wherever it wants to based on the address.



So what this essentially allows is the individual traffic to be differently filtered on different networks.  So, for example, imagine that .0.1 is your main, normal, non-IoT, your PCs, maybe your entertainment systems.  You might want them to be on their own network, just to keep them separate.  The point is this gives you complete control.  Years ago, we spent a lot of time talking more about the plumbing of the Internet and the fact that packets have both, well, essentially the design is hierarchical.  So you have Internet packets that have a source IP and a destination IP.  And some of the protocols that are carried within that IP packet, like TCP or UDP, have this notion of ports, a source port and a destination port.  All those are, are 16-bit values carried in the packet.



When the packet arrives at its destination, the device is able to aim, to sort of route that packet to the proper destination within the device.  So, for example, say that you had a server, you had server hardware running a web server and a mail server.  Well, packets with a destination port of 80 or 443, for HTTP and HTTPS respectively, they would be given to the web server because when it started up its service it said to the operating system, I'm listening on ports 80 and 443, which is sort of an abstraction.



I mean, there aren't physical ports anywhere that it's actually listening to.  What it says is it just sort of registers itself in a table inside the operating system, saying any inbound packets with a destination port of 80 or 443, I get them.  And similarly, the email server, for example, an SMTP server wants to listen for packets coming in on port 25, which is the agreed-upon port for email.



So all of the packets moving through this switch are coming from the devices outside.  Their traffic is coming into the switch.  And at entry to the switch, we have the opportunity to decide what we want to do.  We can perform matching on any of these fields - on the source IP, on the destination IP, on the source port, on the destination port - and also some additional characteristics I'll talk about in a second.  But that's a very powerful facility because, for example, we could say, if traffic was coming in, we could allow traffic in as long as it was going to be going out to the Internet and not to any of the other networks on the switch.  That is, traffic is allowed through that port into this little switch router so long as it's not going to 192.168 dot anything dot anything.  So that it can come in, but it won't be allowed in if it's going to try to go out of one of the other connections.



And so you can see that that's an immediate simple way of creating isolation so that, for example, your IoT devices you might have configured that way so that they're able to have access to the Internet, but no traffic from them is able to go to any of your other networks, so there's no way for them to scan or probe or get up to any mischief because you've said only allow their packets in if they're not destined for any 192.168 addresses.  And so that's an example of the kind of rule.



Now, that's just IP-based filtering.  But because we also have ports, we have a lot more power.  So, for example, we might say only allow them if they're going to remote web services, that is, if the destination port is port 80 or 443.  In which case suddenly now we've also essentially blocked anything from any external connection other than remote web servers.  Or maybe we want to allow or block remote email servers at port 25.



The point is that, by inspecting every packet that enters this little router switch and performing a series of tests that match specific fields, we're able to either just say drop the packet, just discard it, pretend we never received it.  Or in some cases we can log it, if we think that would be interesting, if we want to see that it happened.  We can reject it, which sends back a message saying, sorry, that packet is undeliverable.  Or it can be accepted and allowed to pass through.  And once we create disjoint, that is, completely separate subnetworks for the various ports, then because they're in separate address spaces, we can use the same rules to control inter-port access.



So, for example, some traffic would be permitted, and others would not be.  There's also this notion, we've all heard the term "stateful packet inspection" or "stateful firewall."  Well, for example, the Ubiquiti EdgeRouter and many of the good routers are more than stateless filters.  They're stateful, meaning that actions that packets take can alter the rules dynamically.  So, for example, in the Ubiquiti EdgeRouter, you're able to allow - you're able to set a rule to allow a new connection to move through the filter, or an established connection to move through.



In TCP, we have famously the SYN packet, the synchronized packet, which is absolutely required to establish a new TCP connection.  So although the UI, for example, and the Ubiquiti doesn't specify SYN packets, it broadens the term to a new connection.  That's what it means.  It's allow a connection to be created through this filter.  And then this notion of an established connection can also apply to UDP packets that don't have SYNs.



But, for example, sort of in the way a NAT router works, we've talked about how good NAT router protection is because nothing unexpected from the outside is able to get through.  It's only outbound traffic that creates a table entry that allows the reciprocal packet, that is, a packet coming back from the IP and port that the outbound packet was going to and coming back to the IP and port that that outbound packet came from is allowed to enter.  That is, the router remembers that there was traffic that was initiated outwards, and so the reflection, the reply traffic is able to come back.



The Ubiquiti does the same thing with this notion of an established connection.  So it would be possible to have this isolated network segment of IoT that has no connectivity into your network, that is, like into the highest security zero network.  No unexpected packets are able to get in.  In exactly an analogous fashion to the way NAT protects us from the hostile exterior Internet, we can create a NAT, that is, the equivalent, it's not really doing translation, but it is doing stateful firewall filtering such that the low security IoT network has no access into any of the other networks.



But those networks do have access into the IoT network.  That is, by configuring the rules correctly, new connections would be allowed to be made into the low security network, and then its reply traffic, only as long as it was coming back to the same IP and port as originated it, would be allowed to flow.



So think about that.  I mean, first of all, it means you can get yourself easily tangled up in how all this works.  But it's all just sort of try things and experiment with them, see if they work the way they don't, and you'll learn a lot in the process.  So what this essentially means is we're used to thinking in terms of routers as WAN and LAN.  That is, outside hostile, inside safe.  And it's because that boundary has filtering and the equivalent of a stateful firewall.



Well, now what we have is within our own network we've got, instead of just sort of two sides, an outside and an inside, now in the case of, for example, a five-port Ubiquiti router, we have five networks, each with separate ranges of addresses, each where we can put inspection filters on the traffic trying to enter the common router from the network and decide what we want to do with them.



The last thing I'll say is that the way these rules function is very clever.  It was established a long time ago, and it's so powerful and flexible that it's the way things are today.  And that is, the rules are ordered so that when a packet comes in - they're typically called ACLs, Access Control Lists.  You have an ordered list of rules.  So, for example, if a packet has this or that, and it's whatever you want to have matching, IP address or source and destination port, whatever, it will be accepted, rejected, or dropped.  Or maybe it won't match that rule at all, in which case the next rule is processed.



But the first rule in this ordered list, which is where the selection criteria for the rule match, ends the processing of the list.  And that packet is then thrown away, or accepted and allowed to proceed and enter, or perhaps a logging entry is made or whatever.  As soon as the rule matches, we're done.  And in terms of high performance what that says is, if you really want the most performance, you want the highest bandwidth rules to occur earlier in the list because it means you have less rule processing necessary per packet.  You wouldn't want to, if you had a choice, to put a high bandwidth rule that is, like, doing a whole lot of work, like streaming media or something, at the bottom of the list because you'd have to check every single packet through the entire list until you finally got the permission that you were looking for.  If it doesn't break your security model, you'd like to put the most often executed rules at the top of the list.



So anyway, we've sort of glossed over the power, that is, the application of the power of these multi-logical interface routers and switches.  I mean, it's just another whole world of fun that people can have with networking.  And, boy, when you take this concept of rules, the fact that you can put time locks and clocks on them, you can log things, you can drop the packets, you can selectively decide what you allow in and what you don't, you can come up with a really locked-down, very secure, powerful network architecture for $49.  And then a lot of hours' worth of your time fiddling with it.  But it's fun fiddling.



LEO:  Well, as long as it's fun fiddling, I'll take it.  I will be doing that exact fiddling soon.



STEVE:  It's just neat.



LEO:  Yeah.



STEVE:  It's just it's fun to see this stuff work.



LEO:  Yeah.  And you use, somebody said, Neo's saying in the chatroom, well, he likes pfSense.  You use pfSense for other purposes.



STEVE:  Yeah.



LEO:  But you use pfSense, yeah.



STEVE:  Yeah.  pfSense is a router on the top of the bookshelf behind me.  And as I was mentioning before, for example, one of the last things on my to-do list for SQRL - I'm starting into the final list of to-do stuff.  I posted a pre-podcast update to the SQRL gang last night as I switched over to start pulling the podcast together with a rejiggering of some of the user interface terminology because we came up with this concept of rekeying an identity, and that wasn't the way I was thinking of.  I was considering it a new identity originally, and the UI still represented that.  So that's all been changed.



But, for example, one of the things that I need to do is to add proxy support because in corporations, as we've said, the web browsers are configured through a proxy, and you can only get to the outside world through the proxy.  So I needed to make SQRL proxy aware.  Well, I'm not a corporation.  I'm just me.  But in order to test this I need to create a proxy.  And what do you know, pfSense has the world's most popular proxy, called Squid.  And so...



LEO:  That's great, yeah. 



STEVE:  ...with a couple button presses, I now can set up a corporate emulating environment in order to verify the proxy support.



LEO:  Oh, nice.  Yeah, that's a great idea, yeah.



STEVE:  So, yeah.



LEO:  Yeah.  So in honor, I think, of DEF CON or Black Hat, somebody dropped this off for you.  And I gather he tweeted you or let you know that he was coming?



STEVE:  Yeah.



LEO:  He said:  "Steve will know what this is."  But I think there are some clues on it.  It's a big PC board, I mean big, like 15x15 inches.  And it has slots for surface-mounted chips.  There's only one on here right now.  But the chip, I think, might be a clue to this:  AWT-4500 Deep Crack.



STEVE:  Yup.



LEO:  So I guess you could put 1, 2, 3, 4, 5, 6 by 1, 2, 3, 4, 5, 30 Deep Crack chips on here, and it looks like this row would be controllers.  It is from Cryptography Research Advanced Wireless Technologies and the Electronic Frontier Foundation.  What is this?



STEVE:  This was, and we've talked about this in the past, this was a prototype of the Deep Crack DES cracker.  When the EFF wanted to prove that DES was not secure - and that was, you remember, DES is a 56-bit cipher.



LEO:  Right.



STEVE:  So it's only 3DES where you have the individual 56-bit, three separate 56-bit keys that you get security, or reasonable security.  So this was 56-bit DES cipher.  And they said, you know, we're going to crack this.  And this was a long time ago . So this was early LSI integration to produce essentially a hardware GPU-style-ish accelerator in order to brute-force crack DES.  And so this board wasn't used because they only got one, they got that one chip populated, and then they ended up obsoleting that one and doing a second-generation board.  But so you're holding a piece of history in your hand there, my friend.



LEO:  Well, and it's autographed.  I can't quite read the autograph.  It says "Carl."  I guess it's Carl that gave you this.  I don't know.  "Thanks for your long-term friendship."  And then it's signed by somebody with the last name J-O - Johnson, I think, maybe?



STEVE:  My guess is that that was a gift to him, and then he's re-gifting it to us.



LEO:  Ah.  Well, to somebody named Carl.  Anyway, yeah.  So do you know the Twitter handle of the person who tweeted you?



STEVE:  I do.  I'll be happy to send it to you.



LEO:  Yeah, because I'd like to thank him.  I think what we'll do is we have some framed - we have a framed core memory, and a framed motherboard from a Macintosh IIfx, which stood for "too freaking expensive," as I remember.  And then I'd love to add this because that's great history.  That's great history.



STEVE:  Yes, yes.



LEO:  I will definitely frame this and put this in our wall of memories.  Which is getting smaller because we're moving to a smaller place.  But I like the providence of this.  It's very interesting.



STEVE:  Yeah.



LEO:  That's fascinating, yeah.  Well, we've done it again, Steve, killed a couple hours talking about security and technology and networking.  And we'll save the RAID for another day.



STEVE:  We will.  And presumably, given that DEF CON is as full a basket of goodies as it always has been, we'll have some really fun things to talk about next week.



LEO:  Can't wait.  Father Robert is there on our behalf, risking his life and limb, or at least his data.



STEVE:  Just keep your WiFi turned off.  It's deadly.



LEO:  Bring a burner phone.



STEVE:  You do not turn WiFi on in that place.



LEO:  In fact, don't bring a smartphone at all.  You don't want to end up on the wall of sheep, that's for sure.  But we'll have a report on The New Screen Savers on Saturday from Father Robert.  Someday you should go.  Have you ever been?



STEVE:  Nope, never have.



LEO:  Be fun, I think, for you.  And you'd certainly be lauded as you walked in the door.  You could play Spot the Fed, always fun.  And, you know, try to decipher the name badge.  They always do a kind of arcane name badge that has an encrypted code on it.



STEVE:  It's got [crosstalk] great spirit.



LEO:  You know, it's got great traditions.  It really is cool.  I've never been, either.  Maybe you and I can go next year.  Be kind of a fun field trip.



STEVE:  Some year.



LEO:  Some year.  I'll bring my BSD box.



STEVE:  There's always too much to do.



LEO:  That's the problem, isn't it.



STEVE:  And the problem is, you know, I'm able to get four days' worth of work done here and then look at the summary and talk about it.



LEO:  Right.  And that's true of all conferences nowadays, thanks to the Internet.  You don't really need to go to a conference.  You can get all the information.



STEVE:  Yeah, I think the social interaction...



LEO:  It's what it's all about, yeah.



STEVE:  ...is what it's for.



LEO:  Yeah.  Absolutely.  Agree 100%.  You'll find Steve at GRC.com.  Again, don't know if we'll be doing a Q&A next week.  But if you have questions, you can go to GRC.com/feedback or tweet him.  He is @SGgrc on Twitter and even accepts DMs, long DMs from - well, don't make it too long.  He's got other things to do.  If you want SpinRite 6.1 to come out, make it short.  You also can go there and get this podcast, this very show.  Audio and written transcriptions of the show are available at GRC.com.  Don't forget SpinRite, the world's best hard drive maintenance and recovery utility.  You know, set up four machines.  Buy four copies.  Really, go all out.  Create a SpinRite factory.



STEVE:  And then SpinRite all the drives within sight.  Someone sent me a tweet this morning saying, hey, "Is it all right if I run SpinRite on multiple VMs?"  And I said, "Of course."



LEO:  Would it work?



STEVE:  Absolutely.  Run it on every drive that you own.  By all means.



LEO:  That's good to know.  And that's where SQRL is; the Healthy Sleep Formula, the revised, more economical, easier to swallow Healthy Sleep Formula.



STEVE:  Unfortunately, still completely sold out at the moment.



LEO:  Out of stock.  I'm hoarding mine.  I'm hoarding my niacinamide.  I'm not letting that time-release niacinamide out of my sight.  Let's see.  Oh, just all sorts of stuff.  It's a great site to browse because Steve is fairly eclectic in his interests, and you'll find all sorts of tidbits in there.  We also have copies of the podcast, audio and video, at our website, TWiT.tv/sn for Security Now!.  Or you can always subscribe, and every podcatcher has it.



People sometimes are baffled by the fact that we only have the last 10 shows in the podcast feed.  But that's kind of the nature of a podcast feed.  If we had all 571 shows, the feed would be hundreds of megabytes, and you really wouldn't want to download hundreds of megabytes every 15 minutes, just to see if there's a new one.  So we only put 10 there.



But all 571 episodes are on the website.  And I even have some scripts in PowerShell and various other languages for downloading every episode on my blog, LeoLaporte.com/blog.  If you want to use some scripting, you can get them all.  Or you can go one by one, download them by hand from TWiT.tv/sn.  Episode 572 next week.  So get listening.  Get cracking.  And we'll see you next time.



STEVE:  DEF CON, probably DEF CON follow-up, would be my guess.



LEO:  I'm guessing.



STEVE:  Thanks, Leo.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#572

DATE:		August 9, 2016

TITLE:		DEF CON & Black Hat, Part 1

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-572.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, following the DEF CON and Black Hat conferences, Leo and I catch up with the past week's crazy news, including a distressing quantity of distressing Win10 news, Apple's changing bug bounty policy, newly disclosed Android takeover flaws, yet another way to track web visitors, hackers spoofing Tesla auto sensors, Firefox and LastPass news, and some miscellany.  Then a 19-year-old stubborn decision by Microsoft comes home to roost, and a handful of new problems are found with HTTP.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's been reading all the releases from DEF CON and Black Hat, all the new security exploits.  We'll cover those and a whole lot more.  This is going to be a jam-packed great episode.  You stick around.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 572, recorded Tuesday, August 9th, 2016:  DEF CON and Black Hat, Part 1.



It's time for Security Now!, the show where we talk about your privacy and security online with this fellow right here.  His name happens to be the illustrious Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Leo, this is...



LEO:  Peace in our times.



STEVE:  ...the penultimate episode of Year 11.



LEO:  You used the word correctly in a sentence.  You have grasped the meaning.



STEVE:  I forced myself to because I have clearly put on record it's a useless word that no one has a need for.



LEO:  You know what else?  This is also the penultimate show in this old studio.  Next week will be our last show in the Brick House.  And the week following we'll be in the Eastside Studios.



STEVE:  And from what you've said, our listeners are not going to notice any big difference, like looking at you there, where it's like, oh.



LEO:  It should look the same.  The desk will be cleaner.  But everything you see here - and most people, by the way, it's a tiny percentage that actually watch the show.  But most people who watch the show, everything you see here you will see in the new - it'll look the same.  There may be some subtle differences, but it will look the same.  Actually, one of the differences is right now I'm in a fishbowl.  We used to have curtains all the way around and so that nobody could see.  But they took the curtains down, and now I'm in a fishbowl.



STEVE:  And we've commented about how much brighter the sound was.



LEO:  Yeah, looks different, yeah.  The new studio will be...



STEVE:  No, I mean...



LEO:  It sounds different, yeah.  But the new studio will be drywall around three walls of it, but there will be windows to the outside world in my new studio, so that's cool.  Unlike this studio.  So anyway, it's just different.  But we're going to take all these pieces with us.  Which is, I think, okay, because I don't think the people who are building a brewery in here want them.



STEVE:  Oh, so you're going to actually move your office installation.



LEO:  Yeah.



STEVE:  Into the other building.



LEO:  Yeah, exactly.



STEVE:  Nice.



LEO:  All the stuff that's here, going.



STEVE:  Nice.  Except apparently some of the books you're leaving behind.



LEO:  Well, I don't have room for as many bookshelves, so I have to go through them.  But, you know, programming books from the year 2008 aren't that useful.



STEVE:  You know?  And...



LEO:  You have worse.



STEVE:  I have, you know...



LEO:  You have a worse situation.



STEVE:  ...DOS internals books.  And actually I did, I did need them when I did SpinRite 6 because I was doing new things with the VGA adapter that I had not done before.  And you can't find anything on programming the VGA adapter any longer.  So, I mean, even online it was scarce.  So I was glad that I have sort of an archeological environment here.  So for me, yes, a little bit different.



LEO:  And you're never moving.  How long have you lived in that apartment?



STEVE:  Since, well, this condo since 1984.



LEO:  Okay.  So, yeah.  And there's no reason to think that you will be at any time required to pack those books up again.



STEVE:  No.  That'll be somebody else's problem.



LEO:  So if I were in that situation, I would not ever get rid of a book.  I love books.  I hate to get rid of books.



STEVE:  I do, too.  Although, Leo, they're just not practical anymore.



LEO:  Not at all.



STEVE:  I mean, like, when was the last time I actually went to a book, rather than just typing a phrase into Google?  And there's, like, everything I could possibly want to know, and much more current, and even some commentary.  I mean, just it's all changed.



LEO:  I can only imagine, though, the look on the guy's face who wanders over to our used bookstore and finds the best collection of old Python books ever.



STEVE:  Well, for the right person...



LEO:  Web 2.0.  For the right person, it's a treasure trove.  And these were expensive books.  There's probably $10,000 worth of books behind me.



STEVE:  Remember how expensive technical resources used to be?



LEO:  Yeah.  They really were expensive.  Now it's all online.



STEVE:  I'm seeing that actually a lot in medical stuff that I'm having to buy sometimes.  I have some $300 textbooks that I've purchased.  And it's like, ooh, do I really need this?  It's like, well, apparently I do.



LEO:  Or how do they get away with this?  You know?



STEVE:  Yeah.  So we are post-DEF CON and Black Hat, with an overflowing cornucopia of new horrors to share.  So many, in fact, that I called this Part 1.  Even as I was sort of putting this one to bed, I looked up in my Twitter feed, and I found a whole bunch of other things that it's like, oh, no, okay.  We're not done yet.  So all kinds of fun things.  I do have - I do not want this to be the "pound on Microsoft for Windows 10" podcast.  That's not what this is going to become.  I've said my piece about Windows 10.  I've implemented my piece with Never10.  By the way, it just crossed 1.8 million downloads.  Naturally, it's slacked off a lot since they stopped pushing Windows 10 on everybody, but still 5,000 people a day for some reason think they need it.



LEO:  Why are they downloading it now?



STEVE:  I have no idea.  No idea.  Although we still get downloads of the Click of Death podcast and things.  So it's like, I think, for some people, they're like you and I with books.  They're like, oh, I might need this someday.



So we do have a distressing quantity of distressing Windows 10 news.  I heard you mention on MacBreak Weekly, and we'll cover it here, Apple's changing bug bounty policy, which is nice.  Some newly disclosed Android takeover flaws, some that have been patched.  Some won't get around to being patched till next month because they happened more recently.  Yet another clever and sad and distressing way to track web visitors around the Internet.  At DEF CON, some hackers spoofed Tesla's automobile sensors, which I kind of think is a nonstory, but I want to explain why.



LEO:  God, I hope so.



STEVE:  We have some Firefox news, some LastPass news, some miscellany.  Then three more things I stuck afterwards:  a 19-year-old stubborn decision by Microsoft which has come home to roost, and then two different groups have found new problems with HTTP and HTTP/2.  And most of this is courtesy, but not all, courtesy of DEF CON and Black Hat.  And as I said, I was looking up at my feed, and there's, like, even some more interesting-looking things.  So, and one of these, in the case of this 19-year-old stubborn decision by Microsoft, this one I'm going to have to take a look at.  I think we're going to have some horrified listeners.



LEO:  Uh-oh.



STEVE:  Not that we don't usually.  But extra horrified.  So a great podcast, our penultimate Year 11 podcast.



LEO:  So when you say "penultimate Year 11," you mean we'll be beginning Year 12 of the show in two...



STEVE:  In two weeks.



LEO:  Wow.



STEVE:  Yes.



LEO:  Wow.  And it'll be easy to keep track of, now, how long we've been in the new studio, because it's coincident with the move to the new studio.  That's good.  We begin our 12th year in our third studio.  Wow.



STEVE:  And each one's lasting much longer than the one before.



LEO:  This one should last me, like you, for the rest of my life.  I am not moving ever again.  We signed a 10-year lease with a five-year option.



STEVE:  Nice.



LEO:  So that, let's see, that'll take me to 74.  And maybe I'll retire in the next 15 years.



STEVE:  You and I will be like Jerry Pournelle.



LEO:  I know.  But you know what, Jerry still has a lot of things, good things to say, so...



STEVE:  [indiscernible] Windows 10 [indiscernible] Windows 10 [indiscernible].



LEO:  [Indiscernible].  That will be fun.



STEVE:  So Woody Leonard...



LEO:  Oh, yeah.



STEVE:  ...who writes the Woody on Windows column for InfoWorld...



LEO:  Talk about old-timers.



STEVE:  Yeah.



LEO:  He's been doing that forever.



STEVE:  Yup.  His title of his most recent posting was "Windows 10 Anniversary Update Woes Continue."  And I just thought I'd run through these quickly for listeners who at least will have a feeling, if they've had some of these problems, to know that they're not alone.  His little posting starts out, before I paraphrase, he said:  "Problems with last week's Anniversary Update keep piling up, and solutions remain elusive."  And then he says:  "Late last week I recommended that you actively block the Windows 10 Anniversary Update.  The past few days have brought yet another wave of complaints.  Here's a sample," he writes.



So apparently Windows 10 is freezing on a number of systems.  And I actually think that later on I'll get to at least some of the causes of these things because, in digging into other stories, I realized, ooh, this is what's causing that problem and so forth.  So there was, on Reddit, Woody was following some dialogue that had 680 comments about post-Anniversary Update freezing of all the systems.  And apparently some of this involves some incompatible AV software that Microsoft, as it's explained actually by McAfee - not himself, McAfee now owned by Intel, the corporation - that Microsoft did not have time to incorporate the checks for compatibility of specific McAfee AV versions.  And so it'll update over and be incompatible and thus cause a lot of problems.



But in any event, Woody notes that nobody yet has found a complete solution for these.  And he notes from his own experience that Edge, the new browser, which is in many ways a good thing, we've talked about how Microsoft did, they bit the bullet and just said, okay, we cannot keep pushing IE's code base forward any longer.  We just need to start again.  And when you do that, you have the advantage of all the experience that you've gained.  And so instead of cobbling things together, or in many cases not being able to do what you would like to do from an old code base, you can make it the way you want it.  And we know that Edge has a very good, strong security model and is very fast and has a state-of-the-art scripting interpreting system.  So in many ways it's good.



However, Woody notes that Edge still has plenty of problems.  He says:   "I've hit situations where Edge will not close by clicking on the red X.  Also, I can X out of the last open tab and Edge keeps running, when closing the only open tab should shut down the program as a whole.  The problems seem to appear after visiting sites with lots of ads, like the ones," he says, "linked to from MSN.com, for example.  Once the problems start, they don't go away."  The only solution, he writes, that he's found is to reboot.



And then two different antivirus companies have reported problems.  As I mentioned before, McAfee warns, actually with emphasis in their note:  "DO NOT upgrade to the Windows 10 Anniversary Update without first verifying whether your McAfee product is compatible.  This caution affects the products listed in the section above," of their notice.  Then they said:  "Microsoft intended to implement an upgrade and installation check to ensure that no incompatible McAfee product versions could be installed or were present.  Due to time constraints, Microsoft could not implement the intended version check in the Windows 10 Anniversary Update."



So, unfortunately, that leaves people with this update, the big Anniversary Update, and this apparently causes real problems because, as we know, we've been talking about this recently, one of the things that AV tools have started doing is digging themselves very deep down into the kernel.  This has been causing problems, as we know, because it can increase the attack surface of the machine.  If you have a third party's code inspecting everything that comes through the network, well, it has to be flawlessly implemented, which is something that Microsoft has carefully been doing over a long period of time.  If there are things like buffer overruns in that add-on code, that creates vulnerabilities.  And we've covered those in the not-too-distant past on the podcast.



But as a consequence, it means that, if there are some changes that Microsoft made in the kernel, where they normally would have the right to make such changes, the idea being that it's the API layer, this Application Programming Interface, that's supposed to be the boundary, the formal boundary between applications and the OS.  And the idea being that, as long as the API stays the same, the OS vendor is free to do anything it wants to behind the API because it's that layer, that way that the applications have of talking to the operating system, that needs to remain uniform.  But then who cares how the job gets done? 



Well, what's happened is, by essentially putting kernel drivers in the OS - and in many cases Microsoft doesn't sort of officially support the kind of things that these vendors want to do.  So then they have to even break the kernel API.  There is another API, for example, for device drivers, which is completely different from the application programming interface.  And that API, as any, assumes certain things that driver developers would want to do and makes those OS services available.



Well, the problem is, if these vendors need to do something outside the API, they will have to hook functions in the kernel, which then makes the whole system far less stable.  So reading between the lines, our advice for a while has been, unless you really have to have these things down, added to the operating system, unless there's some overriding reason, it's really becoming better not to use these.  And as we've also talked about, many of these are now also putting certificates in your system and then not managing them as responsibly as we would like, which then allows for third parties to come along and create spoofed website attacks.



And then, finally, he says:  "I'm still unclear" - that is, Woody says.  "I'm still unclear about the ability to block [what he calls] crapware tiles."  He says:  "I wrote about the problem a couple of weeks ago."  And actually I do know what causes this now, and we'll get to that in a second.  "Admins cannot keep Microsoft from pushing crapware Live tiles onto Win10 Pro PCs because certain Group Policies don't work in the Anniversary Update."



And believe it or not, and I'm just - I'm stunned by this news - Microsoft has removed a bunch of very useful mitigations against many of the things that people found objectionable about Windows 10.  They took them out of the Anniversary Update for the Pro version, not the Educational version and not the Enterprise version.  I think Enterprise they left them in because Enterprise wants control.  Education they left them in because they didn't want to force educational usage to have that if they didn't want it.  And that left, like, all of the rest of us, non-Enterprise and non-Educational, that is, the Windows 10 Professional people, without the same level of control over this that the other, like the very high-end to very low-end both have - which, if I were using Windows 10, would annoy me a lot.



And he writes:  "My current Win10 Pro AU [Anniversary Update] machine has tiles for Solitaire, Candy Crush Soda Saga" - this is just so sad - "Pandora, Asphalt 8, Age of Empires Castle Siege, FarmVille 2, Minecraft, Twitter, and Get Office - in other words, about half of my Start Menu tiles are unabashed, Microsoft-installed crapware, all on a machine that's been through the official 'start fresh' regimen."  He doesn't want those, and he can no longer turn them off.



LEO:  Not true.  You just right-click and you remove them.  They're stubs for installing.  They are not the app.  That's not true.



STEVE:  Okay.  Well, I have the registry edits...



LEO:  I don't have them.  Here, you want to see?  You don't have to, please don't edit the registry.  You right-click them and delete them.  Oh, my god.  You want to see my startup after Windows 10 Anniversary?  None of that.  None of that stuff.



STEVE:  Okay.



LEO:  You just right-click, and you say "remove."  And they're not the apps, by the way.  They are ads, I admit.  They're stubs that you click them, it'll take you to the store, and you download it.  Also I should point out that you're not allowed to, if you took the free upgrade, deny updates.  That's part, that was part of the deal.  You've agreed to all updates.  You can delay them.  But ultimately you'll have to take the Anniversary Update.  You can't not do it.



STEVE:  So others are reporting that the Anniversary Update is not respecting unknown partition types.  They're finding that installing the Anniversary Update, for example, in dual boot environments, where they have Linux and Windows, that they lose access to Linux.  And so it's common practice to install Windows first and Linux afterwards because Microsoft does have a habit of overriding the boot sector, which would cause you to lose your multiboot behavior.  But this has gone further.  And there's a lot of report of this on the 'Net, that Microsoft is just blowing away non-Windows partitions as part of the Anniversary Update.  And the term I'm seeing is "borking" dual-boot partitions.  So be advised that that could happen.  You might want to make an image of the whole drive before you move, if you haven't already.



Okay.  So the reason that what Woody said made sense to me was that there is extensive and pretty clear coverage of the Group Policies and registry entries which Microsoft is documenting they have changed.  And they're saying, when you go to Group Policy Edit and look at these keys, they're specifically saying that these are no longer available for Windows 10 Pro, one being turning off the Microsoft consumer experience, which controls, among other things, installation of third-party apps and extra links on Windows 10.  Now, so maybe, Leo, what you're saying is that Windows will, or Microsoft will push these, and then the user is free to delete them.



LEO:  That's right.



STEVE:  And so that means...



LEO:  It's part of the default install.  And so there's two things you can do.  One, there's a setting that turns off advertising, if you call it that, in the Start Menu.  I of course immediately did that.  And then you can right-click and unpin it.  And if you want to, you can uninstall it.  I just did, in fact, I just checked because I had - it was hard to find something, but I found a solitaire entry.  It wasn't on my tiles, but it was in the menu still, and I uninstalled it.  And it's just like that, and it's gone.  So, you know, Woody may not be really a fan of Windows 10.  There is some disinformation that gets spread.  I don't think Windows 10, I don't think Microsoft is as bad as, I mean, look, I only have one machine left with Windows 10 on it, so I can answer questions like this.  I far prefer Linux.  But it's not that bad.  You can remove those.



STEVE:  Okay.  So for what it's worth, for people who are using Windows 10 and are technically sophisticated, I have here in the show notes a number of, I mean, a detailed itemization of the Group Policies which have been removed from Windows 10 Pro.  They still exist in the educational version, and they exist in the Enterprise version.  They are gone from Windows 10 Pro.  They used to be there.  They've just been taken out.



So you're no longer allowed to turn off the Microsoft consumer experience.  You cannot turn off showing Windows tips.  You have less control over the lock screen.  And you're no longer able to prevent changing the log screen and the logon image, nor can you disable all apps from the Windows Store, which are features that the other versions of Windows don't support.  So if anyone is curious and wants more details, I've got it all laid out here in the show notes.



And then Mary Jo finally, you know, we talked last week about the whole assistive upgrade backdoor.  Mary Jo reported that - and so I wanted to share this information with our listeners who might find it useful, that Windows 7 and 8 unused product keys can still be used to install Windows 10.



LEO:  Yeah.  I saw that.  That's cool.



STEVE:  Yeah.  So she asked Microsoft, like, okay, do you guys know about this?  And they said, uh, no comment.  And she said, well, okay, is it going to go away?  Uh, no comment.  And so for what it's worth.  She said, and this is last week, she said:  "In spite of the official end of the free Windows 10 update offer on July 29, it seems that any valid Windows 7/8.x retail product key still installs Windows 10 for now."  And again, this, obviously, this is sort of off-the-books behavior, not what anyone is expecting.  And so no idea how long that will last.  And so she has, you know, she's verified with Microsoft that this is happening, and users are able to install Windows 10 using Windows 7 and 8.  And I said "unused product keys." But it looks like even valid product keys.  So anyway, so that, again, also.



Apple has changed their - and they announced this just last week, on Thursday, at Black Hat.  This is Ivan Krstic.  Is that how you pronounce his name, Leo, do you know?  K-R-S-T-I-C?  Krstic?



LEO:  It's either Krstic or Krstic.  I don't know.



STEVE:  Okay.  He announced a reversal of Apple's longstanding "we don't pay bug bounties" policy, with the news that Apple will begin offering cash bounties of up to $200,000 to researchers who discover vulnerabilities in its products.  And I know you guys just talked about this on MacBreak.



LEO:  I like the rationalization.  Keep going.



STEVE:  Yeah.  Well, and to me it makes sense because - so what Apple was saying previously was that they weren't going to be in a bidding war with government institutions, for example.  I mean, for example, we know that the FBI reportedly, or it's a rumor, but it's generally agreed that they paid something near a million dollars for that hack which allowed them to get into Syed Farook's work-related iPhone after the San Bernardino shootings.



So a CEO of Securosis, Rich Mogull, he said:  "A bug bounty program is unlikely to tempt any hackers who are only interested in getting a massive payout.  For those who only care about cash, Apple could probably never pay enough," meaning they wouldn't be able to outbid somebody who had a nefarious application for a breach.  "But for those who care about making an impact, getting a check from Apple could make all the difference by incentivizing good work."  And to me that makes sense.



And so I paraphrased it.  I said:  "Put another way, if you have no interest in allowing your work to be used for evil, but you would like your important security findings to be rewarded and supported, that can now happen on Apple platforms."  So from my standpoint I think it makes absolute sense for Apple to say we'll pay a reasonable amount of money because - and as I understand it, part of this is a whole change in their approach to security researchers; right, Leo?  They're, like, saying we're going to - we'd like to work with people to find problems.



LEO:  Good idea.



STEVE:  What a concept.



LEO:  I like the -I don't know if this is in the release you're reading, and I didn't read this, Rene reported it.  They said, well, it's getting so hard to find problems in Apple software now that we want to reward you for doing that.



STEVE:  Yeah, [crosstalk].



LEO:  They think it was easy before, so we didn't want to reward you?  I'm not sure that they're saying.



STEVE:  Well, and we keep seeing...



LEO:  There's plenty.



STEVE:  ...rootkit hacks.  I mean, no matter what Apple does.  In fact, we just had that 9.3.3 went to 9.3.4 to remove another way of getting into the phone.  So it's like, good luck.  I mean, again, we know these things are just too complicated.  The harder you press, the more problems you can find.  I think this is great.



LEO:  Yes.



STEVE:  I'm glad that Apple is saying, yeah.  White hat hackers, I mean, this stuff does take time.  I look at this kind of stuff, and I think, wow, that would be fun to do.  But I don't have a couple months to, like, just find a big problem and then say, here, Apple, and have them fix it.  It's like, okay.  If it were a profit center, and I didn't have a lot of other things to do, then I think that would be a really fun way to hack.  So I think it's great.



LEO:  Yeah.  And after all, don't you want, I mean, as users, don't we want Apple to incent people to try to find bugs?



STEVE:  Yeah.  I mean, the whole Pwn2Own competition [crosstalk] happens, which is finding all these problems.  And they're all responsibly disclosed, and they're fixed by the time we find them.  But until we found them, they were potential zero days that nobody knew about.



So there are - an Adam Donenfeld of Check Point presented at DEF CON.  His presentation was titled "Stumping the Mobile Chipset."  And the little synopsis of his presentation read:  "Following recent security issues discovered in Android, Google made a number of changes to tighten security across its fragmented landscape.  However, Google is not alone in the struggle to keep Android safe.  Qualcomm, a supplier of 80% of the chipsets in the Android ecosystem, has almost as much effect on Android's security as Google.



"With this in mind, we decided to closely examine Qualcomm's code in Android devices.  During our research, we found multiple privilege escalation vulnerabilities in multiple subsystems introduced by Qualcomm to all its Android devices in multiple" - and this is a little redundant - "multiple different subsystems.  In this presentation," they write, "we will review not only the privilege escalation vulnerabilities we found, but also demonstrate and present a detailed exploitation, overcoming all the existing mitigations in Android's Linux kernel to run kernel-code, elevating privileges and thus gaining root privileges and completely bypassing SELinux," which of course is the Security Enhanced Linux.



So they gave that presentation.  All versions of Android were vulnerable to these newly revealed flaws.  However, they had been trickling the news out responsibly since April and from April through last month.  And so most of them have been fixed.  In the supply chain, Google fixed all but one, which was unable to make it into the August updates.  So it'll be in the September updates.  So, but these flaws affect Android phones and tablets that ship with Qualcomm chips, which could let a hacker take full control of an affected device.



And I had a list of the phones somewhere.  Oh, there.  Google's Nexus 5X, Nexus 6, 6P; HTC's One M9 and HTC 10; and Samsung's Galaxy S7 and just the S7.  Oh, and I love this, too.  And the recently announced BlackBerry DTEK50, which of course BlackBerry touts as the most secure Android smartphone.  And as we've often said, that's just marketing speak.  No one can declare something the most secure anything.  They can declare their intent.  But as we have learned, because security are mistakes, you don't deliberately make mistakes.  That's why it's a mistake.  And those mistakes create vulnerabilities that can then be exploited.  Which sort of tautologically says you can't say it's the most secure phone because it's not a statement that contains any sense.



So anyway, so these are malicious software install exploits, meaning that somebody, a malicious actor would need to sneak an app either past Google's scrutiny, or the user would have to be incented.  And unfortunately we've just seen this, we were talking about this with Pokemon Go, that people were installing it sideways into their phone by deliberately turning off the only install apps from the Google Play Store, turning that off in order to install something that wasn't available.  So we know that that's being done.



But anyway, so this is not something like Stagefright, where just someone sending you an MMS can take over your phone.  This requires you to install some software.  However, that software, that Android application needs no special privileges at all.  It doesn't need to ask for anything.  It can look completely benign.  Yet using these exploits it's able to essentially get root on your phone and then have the run of the kingdom, do anything it wants to.  A lot of them are in the process of being fixed and will be fixed, the final one from Google in the next month's batch of patches.



Okay.  We've talked often about just the tracking technology.  Whether you're concerned about tracking and being tracked or not, it is in my mind separable from just the technology, which is often fascinating.  And I do find myself jarred when I go to a site whose ads are shockingly relevant.  I mean, there's a substance that I'm exploring for the Healthy Sleep Formula known as oleamide, and it's looking very good.  I haven't said anything about it or written anything about it yet, but it looks like it's another major step forward.  It already exists in us.  And so I have been purchasing some in order to experiment with it, as have a bunch of other people that are in a small group.  And I'm finding the ads for it like in random places that I visit.  And it's like, okay.  That's just too weird.



I mean, so I'm sure everyone has this experience, unless you are really crazy about blocking cookies and private browsing and flushing everything.  Actually, this exploit still affects you even in private browsing and can be used to track you through a VPN and across a private browsing session.  What happened is that some time ago the W3C ratified - you're not going to believe this - a battery status API for HTML5.  It's now in - it's been in Firefox since v16, and it's in Chrome and Opera, not in Safari or IE.  So this is not an issue for them.



But, for example, Chrome browsers on Android, that would be a place where you would have a battery.  The battery API allows a website to determine whether the phone is currently charging or not; the current battery level as a floating point value between zero and 1.0, obviously for empty to full; if it's charging, the number of seconds remaining until it's expected to reach full charge; and, if it's discharging, the number of seconds remaining until it's expected to fully discharge.



Now, sure, you could see how that could be handy.  A website could, if you were, like, going to start playing a video, it might check to see whether your phone is on a charger or not.  And, if it's not, is there a remaining charge in the battery to watch the movie?  And if not, it could say, hey, by the way, if you're going to watch this uninterrupted, you ought to plug the phone in.  Now, that would be a little unnerving to us privacy-related people who would think, wait a minute, how does this website know that my phone is not plugged in, or how much charge my battery has?  Maybe that's not a concern.



However, think about it.  It's yet another thing which is not changing rapidly, or you could argue is changing in a predictable fashion, like, even whether it's charging or discharging, if it's not either fully charged - well, I guess it can't be fully discharged or you wouldn't be using it on the web.  But if it's not fully charged, then it's going to be, this time in seconds is going to be ticking down as it charges, or up, or down, or, well, anyway, you know what I mean.



So it turns out that some researchers, two Princeton University researchers were just curious whether anyone had decided to leverage this for tracking.  And of course we know the answer to that:  Yes.  They found, in the wild, ads which are running JavaScript, which are querying the battery status API and using it and, like, merging it with other tracking-related material in order to enhance the integrity of their tracking.  And we talked a long ago about the Panopticlick site, where a whole bunch of browser headers are munged together, and you're sort of ranked, like, whether you're unique with your browser, or how many other people who are probably not you have been seen with the same fingerprint.  It basically is a way of fingerprinting you without using explicit tracking technology like a cookie that was never really designed for tracking, but makes it drop-dead simple to do.  Instead, they're using these sort of side channel approaches for locking onto us.



So now we have the battery status API as one more thing.  And I think it's kind of cool that a website could help you out, maybe show your phone's battery gauge or use it in some clever fashion or remind you that it's really not the way lithium-ion cells want to be handled to be discharged fully.  We see that you only have 5% charge left.  If that's your habit, you should consider plugging your phone in more often, and the battery that is not interchangeable will last longer.  So, but, yes, again, another example of something for good not necessarily being used the way its designers intended.



Okay.  So fooling the Tesla's sensors.  To me, this is, okay, interesting.  Sort of maybe stick a pin in the map.  But I don't think this is a big deal.  Some Chinese researchers working with some people from the University of South Carolina demonstrated at DEF CON, using off-the-shelf radio sound, meaning ultrasonic, and light-emitting tools, the technology to both spoof the presence of nonexistent obstacles and mask the presence of real objects in the car's path.  And so they're saying, you know, well, we're just demonstrating this academically.  But imagine how bad guys could use it.  And it's like, yeah, okay.  To me, no one ever imagined that this technology was unspoofable.  The car is doing the best it can.  I'm still amazed that anyone is taking their eyes off the road or their hands off the wheel.  I know you're not supposed to.  But I'm amazed that this technology has just sort of exploded onto the scene as quickly as it has.



LEO:  You have cruise control in your car; right?



STEVE:  Yeah.



LEO:  Actually, I don't know what you have in your car.  I don't even know what kind of car you drive.



STEVE:  I'm able to push a button, and it holds the speed that I'm currently going.



LEO:  You wouldn't take your hands off the wheel if you had cruise control turned on.  You'd keep your eye on the road.



STEVE:  Yes.



LEO:  So it's three things.  It's a smarter cruise control that adapts to maintain a good stopping distance, and you can set the stopping distance.



STEVE:  Nice.



LEO:  So if the car in front of you slows down, you slow down.  If it comes to a stop, you come to a stop.



STEVE:  To create a buffer zone.



LEO:  Yeah.  It's called "adaptive cruise control."  My Audi did that.  The second thing is it will stay in its lane.  So if it can see lane markings, which it can't always, but most of the time on the highway it can, it will - and we talked about this a couple weeks ago.  It stays right in the middle of that lane.



STEVE:  Right, right.



LEO:  And so both of those, I think, are minor.  My Audi didn't maintain, didn't steer, but it would warn you.  It would pretension the seatbelts and vibrate the wheel.  So that's not new.  The one thing that's a little weird is you can turn on the blinker, and the car will change lanes for you.



STEVE:  That's nice.



LEO:  But if you think about it, self-parking is similar; right?



STEVE:  Yup.  And you know, when you mentioned the blinker, it's a pet peeve of mine that I'm a crazy blinker user, and I'm, like, alone.



LEO:  You're the only one, I know, especially in Southern California.



STEVE:  No one, they just don't bother.



LEO:  No.  I was taught as a - because I learned how to drive when public schools still taught you how to drive.  They don't anymore, by the way.  There's no drivers training.  But the drivers training teacher, and it stayed in my head my whole life, still does, said even if you're signaling as a convenience to the person behind you, give them some warning, even if it's obvious you're going to turn, or there's nobody behind you, just get in the habit.



STEVE:  Yes.



LEO:  And I did.  And I still have that habit.  But a lot of people apparently weren't taught.



STEVE:  I think it's a courtesy.



LEO:  Yeah.  That's what he said, it's a courtesy.  Let them know.  And so, yeah, you can't change lanes without doing that on the Tesla, I guess.



STEVE:  It would be nice if we knew that the person blinking was going to do what they said they were going to do.



LEO:  Right.



STEVE:  Because of course you still have to make sure that they're not going to keep on...



LEO:  Well, as I get older, I realize, I'm just going to leave the blinker on.  I feel like, why turn it off?  You know what I'm saying?



STEVE:  No, Leo, you can use that emergency flasher button, and everything blinks.



LEO:  I'm turning eventually.



STEVE:  Then you're covered.



LEO:  I'm going to be turning.  Just a little early.



STEVE:  You haven't decided which direction.  Just flash them both.



LEO:  I don't know.  I'm not sure, yeah, mm-hmm.



STEVE:  That'll keep everybody confused.  And they'll give you lots of margin, too, plenty of leeway.



LEO:  I have that left turn signal going the whole time.  The whole time.  Just in, you know, you never know.  No, actually the Tesla...



STEVE:  Let's take a break.  I want to catch my breath.



LEO:  Okay, yeah, we'll do that.  I'll just, you know, the Tesla, I think you'd have to really be kind of strange and cocky and maybe overestimating what's going on.  It's pretty apparent it's not really driving itself.  And, man, I mean, every time I use it, and I do use it a lot, I'm paying just as much attention to what's going on.  I'm just letting it help me.



STEVE:  I think not everyone is us.



LEO:  Right.



STEVE:  And that's a problem.



LEO:  We use blinkers.  Right there we've established.



STEVE:  Right, yeah.



LEO:  We're weird.



STEVE:  So Let's Encrypt.  Everybody knows what a fan I am of the idea of automating the least verified class of certificates - which, while being least verified, still makes them incredibly useful - the so-called DV, the Domain Validation certificate for a web server, where the only thing it's claiming is that I am the server for this domain.  There's no corporate association, no company reputation, nothing more than I'm a server on this domain.  I mean, it's sort of obvious, when you think about it.



And so the beauty of what Let's Encrypt does is it allows those certificates to be made available in an automated fashion at no cost, thus moving the whole web from HTTP to HTTPS, to encrypt all of what was plaintext.  So all kinds of problems.  Like, I mean, looking back on it now, it's hard to, like, it's hard to believe that we were in a period during this podcast where you would log onto Facebook with a secure connection, and then it would then drop you back to a nonsecure connection, that is, a non-private, non-encrypted connection, where your Facebook session was maintained by a cookie being sent in the clear.



LEO:  Firesheep.



STEVE:  Yeah.  It's like, did we ever actually do that?



LEO:  Kind of amazing, isn't it.



STEVE:  Yes, the whole industry did that.  So anyway, this is neat.



LEO:  We've come a long way.  We've learned. 



STEVE:  We really have.  We really have.  And in fact, didn't we just hear that, what was it, it was like last week was the 25th anniversary of the first web page that was delivered probably at CERN by what's his name.



LEO:  Tim Berners-Lee.



STEVE:  Yes, Tim Berners-Lee.



LEO:  Sir Tim Berners-Lee.



STEVE:  Yeah, 25 years.



LEO:  Can you believe that's the first web page.  Wow.



STEVE:  And here we are closing in on 11 years of the podcast.  So we've been around for a chunk of that time.



LEO:  Wasn't it the 35th anniversary of the IBM PC, as well?



STEVE:  Yes.  And by the way, I heard you ask who had a 5150.



LEO:  Did you?



STEVE:  I had a [crosstalk]...



LEO:  The original?  Did you have the cassette port and the cassette adapter?



STEVE:  No.  I came along, well, because I was in...



LEO:  Because originally it did not have a hard drive or a - it had a cassette adapter; right?



STEVE:  It had dual floppies.



LEO:  Dual floppies and a cassette adapter.



STEVE:  There was, yes, there was an audio, a microphone and earphone plug in the back so that you could store your 12-line BASIC program.  I don't know who they thought was going to buy this thing with a cassette player.  But, yeah.  And so it had a choice of either a color or a monochrome display.  The color display was - I don't know who designed it, but it flickered like crazy because, while the CRT is scanning, it's having to, in order to scan the screen, it's reading out of the memory for the video.  And there wasn't enough bandwidth to the memory for the video to read from the refresh memory at the same time that the computer, the 4.77 MHz 8088 - or was it 8086?  I don't remember on the very first one - when it was updating the video.



So you had a choice.  You could either not give the video screen access to the video memory when the processor needed it, which would cause a little blerch to appear.  And what you got was a screen full of static while the page was being updated.  It would just sort of snow.  And then IBM said, oh, no, no, it looks broken.  We can't ship it that way.  So some bright engineer said, oh, we'll turn off the video.  We just won't let them see the snow.



So they blanked the video while the system is updating, like when it scrolls.  In order to scroll the screen, you have to copy all of the data.  You had an ASCII byte and then a color byte, so 16 bits per character.  You'd have to copy them up by, in this case, 160 bytes, which is two times an 80-character line.  So you'd have to copy this 4K buffer up by 160 characters, so basically move the entire buffer in order to scroll.  Well, it looked like a blizzard.  So they'd turn the video off, copy everything up, then turn it back on.  Then what you got, if you did like a directory listing, it would just flash as it was scrolling upwards.  So of course my first product for the IBM PC was called Flicker Free.



LEO:  Ah.



STEVE:  It redesigned...



LEO:  Vertical blank; right?  



STEVE:  Yes, well, it did a nonblanking flicker.  It turns out that something that apparently the IBM engineers hadn't noticed is that in the - it was a Motorola video display chip, so it was a 68 something or other.  There was a register that contained the starting address of the video memory.  Well, they left it at zero.  But it turns out, if you changed the starting address to 160, suddenly, with no flicker at all, the entire video buffer has just moved up, with no flicker.



LEO:  Just you're jumping the buffer.



STEVE:  Well, instead of moving the buffer, I was moving...



LEO:  The pointer, yeah.



STEVE:  ...the region that was being refreshed.  And it got a little tricky at the end because the video memory wrapped around, yet it wasn't a multiple of the page size.  So I had to do a bunch of other things.  And, you know, nothing is ever as easy as the top-level description.  But bottom line was not only did it eliminate the flicker; but, because you weren't having to copy the memory it scrolled instantly.  And so people who were used to seeing their display go [vocalization], it just shot by.  Anyway, so we sold a lot of Flicker Free.  And that's what allowed me to then have time to write SpinRite.



LEO:  That's very cool.  I didn't know that, actually.



STEVE:  Yeah.



LEO:  I thought I knew everything about you.



STEVE:  So, yeah, I had one of the big steel IBM boxes in the beginning.  So anyway, Let's Encrypt is taking off like crazy.  We've talked about what a success it has been.  The problem initially has been who's going to trust their cert because they're needing to issue certificates on the fly using this confirmable API that allows a web server to automate the process of interacting with the automated certificate authority to issue its own certificates.



So what was done initially, and we discussed this at the time, was cross-signing the certificate, meaning that they did create, the Let's Encrypt people created their own root certificate, which upon launch no browsers knew about.  So it didn't do them any good.  But they also had their certificate - so the certificates they were issuing were all being signed by their own root cert that, again, nobody recognized, and also by an old-school major certificate authority that everybody knew, a process called cross-signing.  So it was double-signed.



The news is that Firefox has just recently pushed the ISRG X1.  ISRG - what is that, Internet Security Research Group, I think - X1 root cert is now in the - it's, like, through debugging.  And I've got, if anyone's curious for details, links in the show notes to the dialogue where it's been accepted.  Everything is called a bug even when it's not a bug.  They just use the bug system to move updates through and manage it.  So it's been managed.  And I expect before long we will have a production version of Firefox that natively recognizes this ISRG X1 root cert.



And at some point - there's nothing wrong with cross-signing.  At some point, after all the browsers have come up to speed and have that root cert in all of their stores, then Let's Encrypt can drop the signing by the other certificate authority and have it only signed by their own because theirs will be recognized.  So another nice milestone for this terrific project.  And LastPass I had to mention because a lot of our listeners sent me the news that they have produced an authenticator app.  And so this is like...



LEO:  Ugh.  Ugh.  Ugh.  I'm sorry.



STEVE:  What?



LEO:  You touched a button.  First of all, they came out with that a while ago.  But just this week they decided to pester the hell out of us about it.  That's why everybody's sending you notes.  Is it driving you crazy, too?



STEVE:  So, well, what's clever about it - so I should mention that it's the time-based one-time password that we...



LEO:  Yeah.  It's like Google Authenticator or Authy.



STEVE:  Just like Google Authenticator, like the old football that we talked about years ago.  What's a little different, though, is that it knows about the LastPass browser extension, so that you don't have to type anything.  When you use their Authenticator, and you're a LastPass user, which is probably the only reason you'd have the LastPass Authenticator, and your LastPass extension is logged into your browser, that is, when everything's, like, set up to go, and you visit a site that wants a six-digit code, the extension will see that.  It will push a request to the phone.  The Authenticator pops up, showing you the six-digits, but you don't have to enter anything.  You simply say, yes, I want to use it to authenticate.  And the six-digits are sent back to the browser app, which then populates the field on the site that you're visiting, and you're logged in.



LEO:  And this, by the way, is exactly why I didn't use it.  I don't want a single source for the authentication and the password manager.  Because if one is compromised, then I'm giving them both; right?  I didn't want to use the authenticator...



STEVE:  They're coming from a single manufacturer.



LEO:  Well, if LastPass is compromised, then they get the password and the second factor.  So that's why I don't use LastPass Authenticator.  And I wish they'd stop bugging me about it.  Because every time it pops up, saying, oh, you know, if you were using LastPass Authenticator.  And there isn't even a close box on the popup.  You have to go into a menu to close it.  It's incredibly annoying.  And I think it's less secure.  I mean, maybe I'm wrong.  But I don't think having a single provider do both is the right way to do it.  I understand what you're saying.  I'd still have to be authenticated and logged in as LastPass.  But let's say I've been compromised.



STEVE:  Well, okay.  The reason I'm hesitating is I'm just sort of running through the logic because you still have an app running on a mobile device.  And so that gives you...



LEO:  No, it's not on your - it's in your browser.



STEVE:  No.  The Authenticator is on your phone.



LEO:  Oh, I misunderstood.  Okay.  So I did install this, by the way.  Like a couple of months ago I installed the LastPass Authenticator.  But the problem is you're setting up the Authenticator with your LastPass credentials; are you not?  Maybe I misunderstood it.  I just like the idea of using a separate company with a separate database for my second factor.



STEVE:  You're completely right, if the way it worked was that LastPass browser extension was the authenticating agent so that it populated the six digits.  Then I'm 100% with you.  But that's not what this is.



LEO:  Okay, good.  Because I use the Google, the new Google authentication, which sends a notification to your phone, and then you accept it.



STEVE:  This is that.



LEO:  Okay.



STEVE:  That's all that they've done.  They've done exactly the same thing.



LEO:  Then I'll turn that on.  You know what, maybe this is new because they did something a little different.  When they first did it, it looked like another - it looked like basically another Google Authenticator, and it didn't have that wiring.



STEVE:  And you know, Leo, just to be honest, what you're reporting in terms of being bugged?



LEO:  That bugs me.



STEVE:  That's not something Joe would have done.



LEO:  It's a bad sign, no, unh-unh.



STEVE:  We never had that before.



LEO:  An ad for another product popping up whenever I use LastPass?  Unh-unh.  That's a very LogMeIn kind of thing to do.



STEVE:  That's exactly my...



LEO:  No, I'm not happy about that.



STEVE:  It does support time-based six-digit codes, what they're calling "one-tap push notification."



LEO:  That's the thing I like.  That must be neat, yes.



STEVE:  Yes.



LEO:  I do like that because I use that with Google, and it really is convenient, much more convenient than entering the six-digit code.  All right.  Good.



STEVE:  We're getting so spoiled.  I have to type those pesky six digits.  I can only remember five.  I have to keep going back and...



LEO:  That's kind of part of my argument is it shouldn't be easy; right?  It should be hard.



STEVE:  Oh, I've got something coming that's easy.



LEO:  Okay.  I guess SQRL.  SQRL.



STEVE:  I've got something.  So I wanted to tell our listeners that GRC's DNS Spoofability Test is back up.  I didn't realize until I inadvertently killed it a couple months ago how many people used it.  And it is very cool.  And there's nothing else like it on the planet.  And I'm proud of it.  And it was a huge investment of time.  And after I was done, I thought, well, it's beautiful, but why did I spend all this time?  And I'm really hoping I don't feel that way about SQRL.  So we'll see.  But this thing, it died.  And the reason I'm bringing it up, first of all, I just wanted to let everyone know it's back.



What happened is I use DNS in a very clever way for GRC's version checking.  And the other thing, the DNS Benchmark, people who've used the DNS Benchmark all the time started complaining.  He says, "Hey, it says it can't tell if there's a new version."  What happens is I have what I call a "pseudo DNS server" that I wrote at GRC.  And so domain names can be special.  For example, DNSbench.ver.grc.com looks like a domain name, and it returns an IP address which is actually the least significant two pieces of the most recent version of the application's version number.  And what's nice about that is that it's not TCP.  It's super low overhead.  Anything lets you do DNS, even behind a portal or something.  So it tends to get out.  And all it's doing is apparently making a single DNS request.  So it's just a beautiful lightweight way of checking versioning.



Well, I had to add that to SQRL, the GRC SQRL client.  I mean, we're at that point now where I'm in the final details of this stuff.  And so I knew that the DNS system had broken a few months ago because we were getting complaints about it.  But it's like, yeah, I'm busy.  Yeah, I'll get to it.  But the complaints kept coming in.  So I'm gratified that people are finding the DNS Spoofability Tests to be as useful as they are, and if it's getting use, that's neat.  What happened was weird.  And it put me in mind of that CUJO appliance we talked about a couple weeks ago because I inadvertently CUJO'd myself when I brought up the new FreeBSD Unix server, for a reason I don't yet know, even now.  I know what the problem is.  I don't know what's causing it.  And it's bizarre.  But it's claiming an IP that it doesn't own, which happens to be an IP that gets mapped internally to the incoming DNS responses, or the incoming DNS queries.



So DNS comes into a nameserver at GRC.  And that Unix machine continues sending out what's called a gratuitous ARP.  Now, normally the way address resolution protocol works is that, when something on an Ethernet needs to know what network adapter to send a packet to based on its IP - remember, Ethernet is the numbering, the labeling, the addressing is the word I'm looking for, the addressing on Ethernet is MAC addresses, these 48-bit MAC addresses, where the most significant 24 bits is a manufacturer number, and the least significant 24 is a serial number of that manufacturer, the idea being that you don't need to have jumpers or switches or anything.  There will never be more than that many Ethernet adapters on the same network, certainly.  But the idea is never in the world.  So you just plug them onto an Ethernet, and you don't ever have to worry about address collision.



So ARP says - it's a broadcast message that says, "Who has IP X?"  And so all the adapters on the so-called broadcast domain, which is typically the whole Ethernet, but that's something that VLANs are able to segment, all of the adapters that hear that, they check their little list of IPs.  And you know how adapters can have more than one IP.  This is how.  This is how you can have multiple IPs on a single computer or adapter is they just have a list.  And if somebody is asking who has this IP, the adapter that has been configured with that IP says, "I do."  And so it responds.  So there's an ARP request, and an ARP reply.



Well, the other thing that can happen is what is happening in this case, and that is a gratuitous ARP.  As the name sort of implies, it's a statement that, like, nobody asked for, but the owner is just sort of saying it.  And that's handy.  So, like, when an interface comes up, when you're booting a system for the first time, and the networking system comes up, that NIC, the Network Interface Controller, can send gratuitous ARPs for all the IPs that it owns.  And so what happens is any switches which are on the network will receive those gratuitous ARPs and go, oh, nice to know.  So you save them the overhead of asking, when something wants to come in, that it sets up their ARP table automatically.



So what was happening was this UNIX machine is every second or two sending out a gratuitous ARP for an IP completely unassociated with it.  I'm tempted to think this is a bug.  And what's interesting is I have three Unix machines.  The oldest one is behaving itself and is not doing this.  Both the one I set up recently to handle GRC's forthcoming web forums and the FreeNAS server, they're both doing it.  The FreeNAS server wasn't causing problems.  Even though it's also doing it, it's claiming an IP on the same switch port, so it doesn't cause the switch to send the traffic out the wrong port.  So it's bad, but it's not disruptive.  Which is why I'm thinking maybe there's a bug that nobody has, I mean, because you wouldn't notice it unless you were in this weird situation where the machine was claiming an IP on a different switch port, thus disrupting traffic that should have gone out that switch port, sending it over to its.



And the point is this is how the CUJO works.  Remember we talked about it, this thing that you just plug into your network, and somehow it's able to take over, it's able to do a man-in-the-middle attack, essentially, benignly.  But the idea is it sends out gratuitous ARPs in order to claim to be the gateway for the network.  So all the devices send their traffic to it, rather than to the actual gateway.  Anyway, so I thought that was a little interesting back story, and just wanted to let everybody know that the DNS Spoofability Test, GRC's DNS Spoofability Test, is back online.  Oh, and the DNS Benchmark is happy again.  It's able to see what its version is.  And now I can write the code to add it to the SQRL client so it'll be able to let people know if I've got a new version of the SQRL client.



And one last, or actually two last bits.  A follower, Justin Garrison, he has been following our conversation about, from a Q&A a couple weeks ago, the listener who was wondering about using Firefox as a noncorporate-intercepted proxied web browser.  And he reminded me that the portable version of Firefox maintains its cert store on its portable medium.  So if you install the portable version of Firefox, for example, on a USB drive, and if your corporation allows a nonproxied browser to have access, that's another way of avoiding anyone messing around with its certificate store because it's off on its own and is only present when you're using the browser.



So thank you, Justin, for the tip.  And for anyone else who might find that useful, it's nice to have the option of something like that, a fully self-contained little portable Firefox instead of, for example, I was suggesting a VM as a means of creating containment.  But this is probably even cleaner.  And it's not something you probably need to have all the time and wouldn't take up any space on your system.  And Leo.



LEO:  Steve.



STEVE:  "Stranger Things."



LEO:  Oh, you watched it?  Did I tell you to watch it?



STEVE:  Yes.



LEO:  Okay.



STEVE:  You mentioned it, well, you mentioned it kind of diffidently.  And I just had to say...



LEO:  Well, I don't like to tell you about shows if you don't like them.  I don't know.



STEVE:  It's the best thing I've ever seen in my life.



LEO:  Oh, my gosh.  You liked it.



STEVE:  Which maybe is a little hyperbolic.  So I will say - I was rehearsing this, and I just - it is one of the best things I have ever seen.



LEO:  Good.



STEVE:  I absolutely loved it.  It's a fabulous miniseries.  I call it that because it's eight episodes.  They're like an hour and 15 minutes each.  I mean, Netflix has done it again.  I just bit my tongue until halfway through Episode 7.  I kept waiting to see if it was going to disappoint me, if it was going to fail.  And finally I said, okay, I can't wait any longer.  So I tweeted out an absolute, unreserved recommendation.  I mean, it's worth joining Netflix for - and they've raised the price now to $10 - joining them for a month just to get this, and then quit your subscription if there's nothing else that you find interesting.  It is really good. 



LEO:  It's interesting because it's had a slow start.  It's like they didn't promote it or something.  But the word of mouth has been spectacular.



STEVE:  Well, and you were onto it pretty quickly.  It was July 15th that it was released, so only the middle of last month.



LEO:  People are discovering it now, though.



STEVE:  Well, it's a 9.2, which I don't think I've ever seen on IMDB.  It's a 90-something, maybe 92 or something in Rotten Tomatoes.



LEO:  Good.



STEVE:  I consider it, when I was trying to, like, characterize it, I called it a cross between "Goonies," "Super 8," and "Close Encounters."



LEO:  Exactly.  It's self-consciously so because it's a very - it's an '80s homage.



STEVE:  Right.  But also it starts out as sort of a mystery.  It opens with a star field, and you slowly pan down to this dark, mysterious-looking laboratory with some satellite dishes and some red lights upon poles.  And, you know, the music is well done.



LEO:  Music's really well done.  I love the music. 



STEVE:  It's fabulous.  But then the way it successively reveals what's going on.  Also, there is always a problem that it's not going to hold together, that is, like the writers cheated or something impossible happens.  That doesn't happen.  So the whole, once you really understand what's going on, and you don't until very near the end, then you realize how everything fits exactly right.  So it has integrity, internal integrity, as well.  And a fabulous ending.  So anyway, I don't know if there will be another one.



LEO:  I think they did get renewed for a second season.  I don't know what they'll do with it.  I guess there are a lot of unresolved questions that they could address.



STEVE:  We did have a little tease at the very, very last scene.  So they could do more.  Anyway, I loved it.  And I know that not everybody follows me on Twitter.  So Leo, thank you for mentioning it.



LEO:  Good.



STEVE:  I did, I got around to it, and I stretched it out over two nights.



LEO:  Yeah, I think we did - we did a few more.  Because that's a lot.  



STEVE:  Yeah.



LEO:  It's like six or eight episodes, and they're...



STEVE:  It's eight, yeah.



LEO:  Yeah.  But it's hard to stop watching.



STEVE:  And I will say, the responses to the tweet were people who were already ahead of me said they absolutely agreed.  And then others whom my tweet incented came back a few days later and said, wow.  So for what it's worth.



LEO:  Great cast.  And there's kids, teenagers, and adults.  And they each have their own threads.  But the kids are the best.  They're so good.



STEVE:  Oh, like, it's just, it's perfect.



LEO:  So good, I know.



STEVE:  The dialogue, I kept backing up and, like, watching scenes over a couple times because - and I sound like Andy going off on something [crosstalk].



LEO:  If you like Dungeons and Dragons, the Dungeons and Dragons scene, but beware the Gorgon.  That was my only negative was the Gorgon.  Little rubbery.  Little rubbery.



STEVE:  Yeah, I agree, I agree.



LEO:  I'm trying to do this without spoiling anything.



STEVE:  Also the dumb adults versus the smart kids, you know, the parents are kind of clueless.



LEO:  Yeah.  Yeah, poor Winona Ryder didn't really, I mean, all she could do was act freaked out for eight episodes.



STEVE:  And I wouldn't have even recognized her.



LEO:  I know.  I know.



STEVE:  I was very surprised.  And I knew from the credits. But it's like, wow, that's Winona?



LEO:  "Stranger Things."  It's a Netflix exclusive.  You have to have a Netflix account.  I think there's enough good stuff on Netflix that it's worth the subscription, 10 bucks a month.  And by the way, because I have now, I bought a UHD HDR 4K TV, that's the other good thing about Netflix is they have a significant amount of 4K content, and even some HDR content.  And you can find it by searching HDR on Netflix.  And so even though "Marco Polo" was the worst series ever, it sure looks good.  It's beautiful.  Anyway, "Stranger Things," Netflix.



STEVE:  Yup.



LEO:  Thank you.  Thank you, yeah.



STEVE:  I don't think anybody could be disappointed.  I mean, yeah, there are curmudgeons.  But still, if you're not a curmudgeon, if you like the idea of something fun...



LEO:  Well, it's funny, you know, I don't want to recommend something to you that you hate.  So I'm always, like, a little ginger in, you know...



STEVE:  I can certainly hit pause or stop.



LEO:  [Crosstalk] something that you kind of like.



STEVE:  But anyway, I'm delighted.



LEO:  All right, Steve.



STEVE:  So I wanted to mention that I did bring myself up to speed on what this BeyondRAID is.



LEO:  Ah, I was very interested to hear about this, yeah.



STEVE:  And also what they mean when they say "thin provisioning."  First of all, the thin provisioning is a - essentially it means, when you create multiple volumes, you don't need to pre-declare the size of each volume.  In the old days we had hard drives with, well, we still have hard drives, fortunately, and partitions.  So you can think of a partition by the actual name it's been given, a partition of the hard drive.  And you would set things up with C, D, E, and F partitions.  That's like the reverse of thin provisioning because the point is that you have to decide ahead of time how much space to give to C, how much to give to D, and so forth.



Now, things have gotten better.  Windows, for example, is able to shrink and move partitions, which allows you to make some changes.  But what the Drobo does is allows you to - and what they call "thin partitioning" is to create multiple accounts which are able to grow at whatever rate they want to grow and not need to preassign any specific amount of space to any one, but essentially allow them to all pull as they need to from that space.  So that's their thin partitioning thing.



But the technology that was most interesting to me, that I wanted to understand, was what they called BeyondRAID.  And what I like about this is that what RAID itself, the abbreviation, Redundant Array of Inexpensive Drives, RAID, the concept is that you are protected against the failure, either a spot can't read or the whole drive can't read, but you're protected against failures by redundantly having information on the drive.



So let's take the three drive case.  You have two drives that contain different data.  So say that you had a 10MB drive and another - okay, I really am old school, forget about that - 10GB drive, another 10GB drive, and they've got different data.  They have different data, so it's not - the data is not in any way related.  Now you take a third drive, and what's really cool about the XOR function is you XOR the data, sector for sector, byte for byte, from those two drives, and you store the XOR of them in the third drive.



So what this allows - so now you have a three-drive RAID.  Now, its still only stores 20GB, right, because we have two drives, 10GB each.  And then we added another drive.  But what it's doing is storing the XOR of the first two.  So that doesn't give you - that doesn't buy you or deliver any more storage space.  It still, the total storage is still the two drive sizes, this 20GB.  But any one of them can fail, and you lose nothing.  Obviously, that third one, that checksum drive that we added, the XOR drive, that can go away, and no one cares.



What's cool is, since it stores, essentially, the difference, that's what an XOR is, the difference between the bits in the first and the second drive - and I'm not going to take that drive away, I'll take that drive away - if the first drive goes away, we can infer the contents of the first drive by XORing, again, the second drive against the XOR drive.  And that returns the data that was originally stored in the first drive.  And what's elegant is that, from a computer science standpoint, XOR is very fast.  It's incredibly, well, not incredibly, but it's sufficiently fast that you're not losing a huge amount of speed in essentially arranging to - so that whenever you write data to either drive, you update this XOR sort of extra copy that represents the difference.



Now, what's really cool is that it works with more than just two drives.  You can take three drives as your main, or four drives as your main, or five, and then have one XOR of all the others.  And if any one of the others fail, you can reconstruct what it originally had from using the remaining drives.  You'd need, I mean, it's going to be slower because you have to read all of them in order to recompute the missing drive's contents, but it works.  Now, in an extension to that is RAID 6.  And I can't do that with my fingers, unfortunately, because it uses some fancier math.  But essentially it's an additional drive of redundancy which also does not buy you more storage.  But now it means any two drives can fail, and you still can read the whole thing.



And RAID 6 is coming into its own because drives are now - drive arrays are getting so big that, if a drive dies, in RAID 5 if a drive dies, you have lost all redundancy.  It's okay, as long as no other drive fails.  But the concern now is sometimes it takes days to rebuild a failed RAID when one drive dies because, as I said, it is intensive.  You have to read the data on all the other drives in order to reconstruct the one missing drive in a RAID 5.



And so if you've got 12 drives, for example, and those are multi-terabyte drives, as I've mentioned before, nobody ever formats a drive any longer.  I mean, if you actually gave a format command where it was going to go out and read every sector, you might as well just, I don't know, come up with some way of needing less space because this thing will just never happen.  It'll never finish.  That's the burden that SpinRite has because it's all about actually reading all of the physical surface.  Nothing does that any longer except SpinRite.  But that's also what makes it unique and valuable.



The point, though, is if you have 12 drives, one of the problems with increasing the drive count is if each drive has a certain probability of failure.  The more of those you have, the more likely one of them will fail, statistically.  So the problem with RAID 5 is that what happens if another drive fails during the rebuild of the first drive that failed?  That's why RAID 6 is gaining popularity.  Drives are cheap, and technology is cheap.  So let's add one more drive.  It won't give us any more space, but it will mean that, while rebuilding from a failed drive, if anything else fails, we're still okay.



So that's sort of the RAID background.  When you think about it, all that's really necessary is that we arrange for redundancy across drives.  And what I was curious about from just the overview of what Drobo did is it made it sound like you could remove a drive, and say that you had it populated with five, as I do mine, you remove a drive.  And as we know, if that was just RAID 5, standard RAID, I remove a drive, and I have now lost all my redundancy because I'm now requiring all of the drives I have to compute the data in the missing drive.  And so that's a problem.



What Drobo has done is they said, okay, so we're down X terabytes from the drive that's failed.  So now we've got four.  But rather than saying, so we have no redundancy, they say, we're going to restore redundancy as quickly as possible.  And when you think about it, nothing actually prevents you, theoretically, from re-RAIDing on the fly, that is, saying to yourself, okay, we only have four drives.  We want to restore redundancy.  So let's turn this into a four-drive RAID.  And they do that.  Which is, like, very cool.



So what they do is, when they see a drive is gone, they start rebuilding to restore redundancy.  Now, the requirement is free space because what we've seen is that the way this works is you are consuming a whole drive's worth of space for redundancy.  And the other thing to note, in a three-drive RAID, you've got two drives of data and one of overhead.  So that's not very efficient.  One third of your total capacity is wasted in this RAID checksum, you know, the XOR drive.



So what is nice with a simple RAID 5 is the more drives you have, the lower the overhead becomes of the redundancy.  Because, as I said, if you had like 11 drives - and I don't have that many fingers - 11 drives, and then one of checksum, then it's now much lower percentage of the total storage.  On the other hand, as we saw, with that many drives the chances of any of them having a problem goes up.  So then you begin to want to have additional redundancy.



Anyway, so all I wanted to really say was that I'm impressed.  The way they pull off this, you know, and we mentioned it before - in fact, last week I talked about a guy who was using SpinRite to recover friends' drives and then copy them to brand new drives.  And then he would take that recovered drive home with him.  And if it was bigger than the smallest of the drives in his Drobo, he'd pull out the small drive and put in the bigger drive.



And again, what Drobo does is it has the technology, first of all, unlike other RAIDs, the drives contain metadata that tell Drobo which drive is which.  So you're free to rearrange them in the box anytime you want.  If I did that on my hardware RAID at Level 3, everything would fall apart.  It would not recognize the RAID, and it would say it was broken, and alarms would go off.  Drobo doesn't do that because it tags the drives and tracks them as they move around within the case.  But in this case, so you pull out the smaller one, the smallest one, put in one that's larger than that.  Drobo recognizes what has happened and then sets about rebuilding itself to optimize the storage that it contains.



And you do have a choice of one or two drives of redundancy, that is, sort of a drive's worth of redundancy.  So you can run where, for example, in a five-drive box, where you get the storage of four of the drives, if you use a single-drive redundancy, or you can do dual-drive redundancy and be protected if any two die and then have the storage equivalent of three of those drives.  So anyway, I just - I did want to dig into it.  I hadn't seen this technology before.  They did it right.  And I'm very impressed.  So, nice piece of work.  SpinRite.



LEO:  Speaking of nice pieces of work, yes.



STEVE:  I found a nice question from somebody who was wondering about ZFS, the Z File System.  Trevor Harrison in Vancouver, British Columbia, the subject was "With ZFS Scrub, is SpinRite still needed on ZFS volumes?"  He says:  "Hi, Steve.  I'm building my first FreeNAS box.  Hanging out in the FreeNAS IRC channel, I've been told that the ZFS Scrub is a block-by-block scrub of the drive to find bad blocks.  I know SpinRite works at the sector level below the file system."  He says, parens, "(At the metal level?).  So can you explain to us, and even do a ZFS in-depth podcast, as to why ZFS Scrub replaces SpinRite or doesn't?  I personally think it doesn't, but running SpinRite on a live server with lots of drives, well, you get the idea.  I'd like to know for sure and understand the differences."  And he says:  "Do you ever SpinRite your GRC servers?"  And then he says, "Also, I'll be buying SpinRite as soon as I can hear my 'Yabba Dabba Doo' live.  Kind regards, Trevor."



LEO:  I told you you should have that live.  I told you.



STEVE:  Yeah.  I've had a lot of requests for that.  So I think in the future I'm not going to mute all of the Yabba Dabbas.



LEO:  Oh, that's fun.  Mute it when it gets out of control.  And let's hope it does.



STEVE:  Because that would be fine, too.  So it's not very disruptive.  Okay.  So here's the deal.  ZFS Scrub is not what it sounds like.  It's a nice term, and it wouldn't confuse you unless you were thinking, wondering whether it does what SpinRite does.  It doesn't.  What the Z File System contains that other file systems lack, and which is where it gets its reputation, its deserved reputation for robustness, is it goes checksum crazy.  It checksums everything.  And other file systems don't do that.  There are ways to rebuild them, but they don't tolerate the overhead of checksums.  ZFS was designed with this from the beginning.



So what a scrub is - and a scrub is not something that the file system does automatically, it's a command you can invoke.  It can run in the background while the file system is live.  But it's tying up a lot of resources, as we'll see in a second.  So you may notice degraded file system performance during the scrub, and it can take a long time.  I saw just - I saw like a 28-hour scrub report when I was poking around, learning more about ZFS a couple weeks ago.  So, I mean, it's a multi-day sort of process, again, because file systems tend to be big now.  And what the scrub does is it is a manually invoked checksum verify.  So there's no reason to believe that the checksums would be wrong.



But the system doesn't just go through and scrub them all, which is the term ZFS uses for going through, without any reason to believe there's a problem, just to do - it's like a high-end verify pass.  I want to verify that my file system is pristine, that no bit rot, as it's called, has crept in, because that can happen, as we've seen.  And so this does that.  This reads every block, computes the checksum of that block, and then verifies it against the stored checksum for the block, basically doing a checksum of the entire file system.  So as you can see, that's not what SpinRite does.



SpinRite, of course, is about - oh, and it doesn't, obviously, mess with non-file system space.  So it's not concerning itself with preserving or checking the integrity of any sectors not in the file system, that is, they're not in use.  SpinRite is about the lower level, as Trevor says, the "metal level," of going through and absolutely verifying and/or repairing the data that the drives store.  And to answer his final question, yes.  Everybody who's ever worked at GRC, as far as I know, and I know I've checked in with several of them years afterwards, we all run SpinRite on any system we're setting up.  I ran SpinRite on all of the drives in my new Win7 box.  I run SpinRite on the drives at GRC.  I know that Greg is running it all the time on any systems that he's setting up for others and for himself.



So those of us at GRC are believers.  And I just want to verify the drive because, without running SpinRite, you just don't know what condition the drive is in.  And sometimes you're surprised.  I've returned brand new drives where I've run SpinRite on them fresh out of the box, and it has pushed down the relocated sector count, or the seek count has gone way higher than it should.  Both are things that SpinRite shows you while it's running.  And that just means this is a sick drive.  I mean, it's sick right from the box.  And so I send it back, and I get another one.  I'll run SpinRite on it, and it'll behave itself perfectly.  And so I'm glad I didn't use that drive that was sooner or later, and probably sooner, going to give me a problem  So, yeah, we absolutely use it for preventative maintenance.



And again, I plan at some point to talk about ZFS in detail because it is a fascinating, beautiful piece of work.  And I'm seeing it more and more.  In fact, I configured that most recently built Unix box - not the FreeNAS server.  That is running ZFS just because that's the way it came, and it was easy to set up a ZFS "pool," as they're called.  But the forum server is using UFS and a hardware RAID.  I just - I want the experience of using ZFS with JBOD, Just a Bunch of Disks.  And so it's the last thing I need to do before I bring that server public because I'll have to take it down in order to convert the file system over.  But I want to do that because, everywhere I look, ZFS is taking over.



LEO:  Good, because I'm ready to run it.  I'm actually going to - I'm thinking about converting my home cloud, which is right now running Sandstorm - FreeNAS supports Docker; right?  So I could run Sandstorm in a Docker on FreeNAS.  And then I have ZFS.  I'm thinking about doing that.  It would be crazy to do that, but I'm thinking...



STEVE:  Well, you're having fun, and that's what...



LEO:  That's all that counts.



STEVE:  That's all that counts.



LEO:  I crave ZFS.



STEVE:  So, okay.  HTTP protocol flaws.



LEO:  And we're ready.  This is now the Black Hat/DEF CON segment.



STEVE:  Yes.  We're back to Black Hat and DEF CON.  We talked - I'll do HTTP first because this is interesting.  This is a new attack that's been called HEIST, H-E-I-S-T, which is an acronym or an abbreviation for HTTP Encrypted Information can be - we're skipping the "can be" - Stolen through TCP windows.  There are some details of TCP protocol that I've never bothered to get into because it's really down in the weeds.  Oh, I guess I did actually talk about it, years back.



The TCP window is something which is an evolution of TCP which is a agreement by the endpoints about how much received buffer each one has, which gives the sender permission to send unacknowledged data ahead.  So each end is essentially, as the ACK packets are being sent to the other end to affirmatively acknowledge how much of the TCP stream has been received so far, and it's now possible to be a lazy ACKer, where you only acknowledge every while, as long as you do it often enough that you're not worried about freaking out the sender and causing it to start retransmitting packets that you've already received.  So you want to acknowledge frequently enough that you keep everything flowing.



But the idea is that, especially when we have what's called a large bandwidth delay product, that is, we're at distant points of the Earth, and the bandwidth is low so that the delay is high.  And what that means is the roundtrip time is extremely long.  So TCP works by the sender sending something, and the receiver acknowledging its receipt.  Well, since the acknowledgment can take a long time to get back, we want the sender to be able to send ahead.  And so what happens is the acknowledgment packet contains permission, a 16-bit permission.  And in later versions of TCP that's scalable.  So you can not do it by bytes, but you can do it by larger increments because these days the bandwidth delay products are much bigger, or can be.



That permits the sender to - essentially that so-called "window," which is called an "advertisement," the window advertisement that the recipient is sending with its acknowledgment says, "At this time you are free to send this many bytes unacknowledged," meaning that the receiver can confirm its ability to provide the buffer space necessary.  So the sender just can blast away without requiring incremental receipts.



So it turns out that what these researchers found was - and this is what's unique about this - a browser-based way of sensing the actual size of data at the packet level.  Which sounds like, okay, who cares?  Except that we've seen places, CRIME was one, BEAST was one, there have been a number of attacks on HTTP where, as we'll remember, where the compression was reverse-engineered.  That is, it was possible by guessing a whole bunch of times to determine what some unseen compressed data was by putting your own data in, which would be combined with the compressed data.  Remember that the way the compression works is that you get more compression if you have more redundancy.  And so if you put in data which turns out to be redundant, the total size increases less than if you put in data that was not redundant.



So that's a really roundabout, indirect way of figuring out, painfully, but you know hackers, they're clever and patient, figuring out what data you can't see by seeing how large the compressed result of what you can't see, plus what you can see because you put it in, ends up being.  These guys figured out a way for JavaScript to determine the size of data being sent.  Which moves these previous man-in-the-middle attacks, because you had to be typically a man in the middle to make this practical, that's moved those attacks into the browser.  It's still fringe, and not something you need to really run around worrying about, I think.  But an interesting hack, and no doubt a great presentation for, I don't know, I didn't note here whether it was Black Hat or - oh, yeah, it's a Black Hat presentation.  So that's HTTP, the HEIST attack.



The other presentation at Black Hat last week was four new, what I would call a "protocol implementation flaw," not necessarily a flaw in the protocol, but side effects of first Version 1 implementations in HTTP/2.  HTTP/2, we did a podcast on it, I don't know, about a year ago, looking at what features it offered.  There's a bunch of cool things it does.  And this was originally driven by Google's efforts to improve the efficiency of the whole Internet.



An observation, for example, was that web browsers are almost always sending non-varying headers.  The same, you know, if a web page is queried, all these requests go out for all the assets that populate the HTML page, and they've all got all these query headers, this metadata that's not part of the actual data goes out, you know, things like I have a copy that expires on this date.  Do you, server, have something newer?  I'm this user agent, I'm this language, I'm this quality of service and so forth, a whole bunch of stuff per query.  Which typically does not change.



So it's been observed that this is a lot of redundant junk, especially if the little objects you're getting back are small.  All of this header information can be a substantial percentage of the total payload.  So reducing header redundancy, compressing headers.  There's also this notion of streaming, where normally a browser is only allowed to have two connections to a remote server, to a given remote server IP, in order just to keep this under control.  The problem is that a page which is loading a whole bunch of things, like maybe that page has a whole bunch of little things and a few big blobs.  If the requests are made for the blobs, then all the little things have to wait in line behind the blobs, waiting for those to finally get sent by the server in order for the page to then be able to show all the little things that may actually be more interesting, or more immediately useful than the big blobs.



So what HTTP/2 does is it multiplexes that single connection.  In fact, we do, we drop to one connection now, which is multiplexed, so that multiple queries can be sent, and multiple pieces of responses can be received in any order that the server wants to send them.  And so that's potentially a huge win for just the feel of web pages.



Well, security researchers being what they are, they said, huh.  I wonder what mischief we can get up to with this stuff?  There is a famous old attack that we talked about a long time ago called a compression layer attack.  It's also been known as a "zip bomb."  The idea is, we've talked a lot about interpretation recently, about how, for example, the TIFF image and JPEGs and all kinds of file formats are sort of a meta description of their contents, so that the thing that is reading them is reading the file metadata, which then tells it what the following data is.



Well, compression is very much like that.  When you have a compressed file, you have control information mixed in with data.  And the presumption made by the decompressor is that a friendly compressor generated the compressed data.  But that's not necessarily so.  And it turns out that you can horribly crash HTTP/2 servers if you deliberately mess around with the header compression.  It is possible for a single connection to tie up as much as a gig of server RAM.  And you can do that as many times as you want to until the server crashes.  So in their presentation of what they called the "HPACK Bomb," the attacker crafts small and apparently innocent messages which decompress into significant amounts of data, as in gigabytes, on the server, bloating the server's memory footprint and often crashing the server.



And so, for example, just to give you an example, one of the ways you might compress a block of null space, a block of all zeroes, say that you had 16K of zeroes.  And in fact EXE files, one of the things that's so annoying about the Microsoft EXE format is that it's incredibly inefficient.  And there are huge regions, huge tracts of land of null space in the middle of these files.  So instead, an intelligent compressor recognizes, it sees all this null space and goes, wait a minute.  And so it puts in a special marker that says, here's a zero.  Duplicate that 16,000 times.  Well, what if you said 16 billion times?  Oops.  So clearly we need sanity checking on the decompression to make sure that this compressed meta representation of the headers is sane, that it makes sense, that it's not totally crazy.  We don't have that today.  So that's an example.



Another is something known as the Slow Read attack, where a malicious client deliberately reads responses very slowly.  And we did talk about this also, a long time ago.  It was called the Slowloris attack.  it was an early form of DDoS where you would establish connections with the server, and you just would not acknowledge the receipt of data very quickly, which forced the server to keep the connection up.  And that allowed you plenty of bandwidth and time to initiate many, many, many, many, many, many, many more connections, all which would also be slow.  And eventually they would pile up.



Well, it turns out that - this was done by Imperva Research, and they tested variants of essentially this Slow Read attack on Apache, IIS, Jetty, Nginx, and Nghttp2, all able to bring the server to a standstill at this point.  Again, just something that the protocol doesn't yet handle, but needs to, in sort of version 0.9.



There's also some details in the way the HTTP/2 protocol is implemented, something known as the Dependency Cycle Attack, which takes advantage of some flow control mechanisms which are new in HTTP/2, which support network optimization.  And in this case, again, a malicious client is able to craft requests that induce sort of an interflow dependency which puts the server into an infinite loop, essentially, as it tries to resolve these deliberately intertwined dependencies for which there's no resolution, sort of the Kobayashi Maru attack on HTTP/2.  And then they've also come up with a way of abusing the stream multiplexing that I had mentioned before.



So these are not showstoppers.  It doesn't mean that there's, like, we need to fix HTTP/2.  That's why I call these "implementation errors."  And we do need to fix the implementation.  And I'm sure, after this presentation at Black Hat, all of the server implementations are in the process of playing with these attacks themselves and coming up with mitigations for them.  So they all look like things like, oh, you know, we just didn't consider that a client would be evil.  So with a new protocol you are inherently opening new opportunities for clients to misbehave.  And that's why we have Black Hat and DEF CON.



LEO:  Your mention of sanity check reminded me, if you don't mind a little interruption.



STEVE:  Yeah.  Yeah, yeah.



LEO:  I got an email from Patrick, our engineer over here.  He runs the API and so forth.  And there's somebody in Australia who loves this show because he has run a script to download every episode.  A lot of people do that.  But he neglected one minor detail.  He forgot to put an end number in it for the last episode.  So he has been downloading since July, the end of July, just downloaded, or tried to, Episode 306,003.  Which I'm sorry to say we won't actually be recording until the year, according to Patrick's calculation, 7889.



STEVE:  Yeah.  Your lease will have long since expired.



LEO:  So just a little tip.  If you're going to write a script to download, you might, A, want to keep an eye on it; B, have an upper limit.  You know?  In fact, Patrick suggests using our API because there are shows with weird numbers like 85A or 103SE.



STEVE:  Yeah, actually Security Now! has a couple of those.



LEO:  Well, that's, yes, this guy's doing Security Now!.  And the API will deliver you, not only all of the numbers, but not just a simple numeric succession, but in fact every show episode.  And you can ask the API.  And then you won't be downloading episodes in the high hundred thousands.



STEVE:  Which demonstrates a lot of hope.



LEO:  There's a lot of hope.  He doesn't want to miss any of them.  You've just got to keep running that till you get there.  Anyway, I'm sorry.  I didn't mean to interrupt.  But you reminded me.



STEVE:  No, it's okay.  I've got one last item.  And I was going to follow up on it anyway next week.  So I'll just tease everybody with it.  I need - this is bad enough that I need to understand it more than I do.  And so I'm going to have to do a bit of research.  But here's the deal.  Back in 1997, 19 years ago, hackers found that Windows 95 and Win NT could be induced to send the username and password out of the system.



LEO:  I know where you're going with this one.  I know where you're going here.



STEVE:  And the way that was done is the web browser could be given, by a malicious web page, be given a resource on what looks like a Windows file share, a so-called SMB, Server Message Block, also known as CIFS.  And that's the standard Windows file and printer sharing protocol.  In the same way that most resources or assets that a browser queries are HTTP:// or sometimes even FTP or other things, you can do SMB.  You can actually tell a Microsoft browser to get something over SMB that's not local.  And so 19 years ago this was brought to Microsoft's attention.  They know about it, knew about it, and said, yeah.  Okay.  We're not going to, you know, that's by design.  We don't think it's a problem.



Now, the argument at the time was that somebody in Russia gets your PC's username and password.  What are they going to do?  Presumably, there's no way to log in remotely into that machine.  So the fact that - oh, I should mention they don't get the password.  Oh, and I forgot to say they get what is - oh, I completely missed the whole punchline.  And that is that part of this SMB protocol provides your current logged-in credentials with the query.  So with the query that goes out over the Internet from your Microsoft web browser, now, that's one of the mitigators here is that Chrome and Firefox don't do this.  Only IE and Edge do.  But Edge does, and why this suddenly got important is, as we know, Microsoft started using your Windows 10 authentication for much more than just Windows.



So whereas 19 years ago this may not have been a problem or, I mean, still would never make anyone comfortable who knew about it, suddenly it's a huge exploit vector.  Any Windows 10 user who was using Edge - and I imagine that's what most Windows 10 users are using, unless you're a higher-end user, you're a listener of the podcast, and you've chosen to use Chrome or Firefox.  But if you're using Edge, and you haven't done anything different, and you go to a web page that wants to get up to some mischief, that server will send your browser a request for something that it apparently has, that is, the server, remote server has, over the SMB protocol.  Your browser will send your currently logged-in username and a hash of your password - you heard that right, your password hash - to whomever asked for it, wherever they may be.



There are currently two test sites that I'm afraid to go to.  One of them is in Russia, and I'm sorry, but I'm not going there.  But there are two.  And people who have written about this have gone there and have had their password cracked in four seconds.  So their username and their password for their Microsoft Windows Live account, cracked and known by an external party in a matter of seconds, just by visiting a web page.



Now, there are probably other mitigators here, and I just want to verify that.  So I'll come back to this next week.  For example, as I've mentioned, many people are now behind ISPs that filter ports 137 through 139 and 445.  Those are the Windows file and printer sharing ports.  So I'm assuming ISP blocking of Windows shares would solve this problem.  And I, of course, with ShieldsUP, back in the beginning, I used to greet people by their name.  I'd say, "Hi, Leo."  In fact, that's what happened the first time Kate showed you ShieldsUP.  I don't know if you [crosstalk].



LEO:  It said my name, I did, and I was shocked.



STEVE:  So this kind of information leakage is old news, but it never went away.  And I think Microsoft, it didn't occur to Microsoft that reusing your single sign-on credentials for all these other services might create a new opportunity for exploitation.  There are some registry - and unfortunately that's where they are, in the registry.  It's NT LAN Manager, NTLM keys in the registry that can be changed to turn off sending your credentials to remote sites.  So the switch is there, but they're all on by default.  And I loved it because I went, I dug back in, and I found the original report at Insecure.org.  They were calling them "sploits," as they once did. 



LEO:  Sploit.



STEVE:  Yeah, sploits.  And this was WinNT/Win95 Automatic Authentication Vulnerability.  Here's what I love.  It says, parens:  "(IE Bug #4)."



LEO:  Wow.



STEVE:  There was a actually a single-digit bug count at one point.



LEO:  Wow, the fourth bug.



STEVE:  Bug #4.  Leo, that's the fourth bug.



LEO:  That must have been before it was released.



STEVE:  It turns out it's not a bug.  Microsoft says, quote...



LEO:  They did it on purpose.



STEVE:  "We're aware of this information-gathering technique, which was previously described in a paper in 2015."  That is, it came back around again last year.  And they say:  "Microsoft released guidance to help protect customers; and, if needed, we'll take additional steps."  Otherwise, eh.  Basically they're saying, eh, we don't think it's a problem.  So various sites are reporting on this.  Our friend Lawrence Abrams at BleepingComputer has a very nice extensive write-up.  He's one of the people who took a sacrificial machine and poked Russia, and they hacked his password.  I mean, they decrypted his hash in four seconds.



And so if anyone is concerned about this, again, only IE and Edge.  So, for example, as a Firefox user, I've never been in danger.  As a Chrome user, nobody would be.  But as we know, there are occasions where a link will explicitly bring up an IE or an Edge, or sometimes where something requires you to.  Or you could even imagine somebody who was malicious putting up a web page that said this valuable content you want can only be viewed under a Microsoft browser.  Please come back under IE and Edge.  And maybe, if you wanted whatever you thought was there badly enough, you would.  And then they could snag your username and your password hash.  So that seems really bad.  I'll have all the details next week.



LEO:  Yeah, it's been getting a lot of attention.



STEVE:  Yeah.



LEO:  I would guess that's probably the biggest story to come out of DEF CON or Black Hat.



STEVE:  Well, and 19 years old.



LEO:  Pretty impressive, yeah.



STEVE:  And Microsoft, yeah, yeah, we don't think that's a problem.  Uh, maybe it is.



LEO:  Well, I mean, what are they going to say?  Oh, yeah, it's been there for 19 years, and we didn't fix it?  I think they're going to say, well, we didn't fix it because it's supposed to be there.



STEVE:  Yeah, I haven't...  



LEO:  So don't use IE or Edge.  That's the key.



STEVE:  Correct.  Correct.



LEO:  You shouldn't be anyway.



STEVE:  Or Windows.



LEO:  Or Windows, for that matter.  I think Microsoft makes you use either Edge or IE for downloads.  There are certain things you [crosstalk].



STEVE:  Oh, yeah, yeah, that's a very good point.  That's a very good point.  I run across that snarky text.  "You must use Internet Explorer to obtain this."  It's like, okay.



LEO:  And I have installed, while you were talking, LastPass Authenticator.  So we'll see.  I'm not using it as my authenticator program, just for that one tap authentication.  I don't know how that works, though.  And we'll find out.  Does it work with everything?  Or just some things?  Or I don't know.



STEVE:  LastPass needs to understand the site.  So it needs to...



LEO:  Right, know that it's asking for a code.



STEVE:  Correct.  It needs to see that there's a query.



LEO:  And it would then also need all the authenticator codes; right?  You'd have to set up all the...



STEVE:  No.



LEO:  No, you don't.  Okay.



STEVE:  Those are in your phone.  And so that's the key.



LEO:  They are.  Well, I'm saying you need to set that up in the phone, though; right?



STEVE:  Correct.



LEO:  Yeah, yeah.



STEVE:  Yeah, and you know, I've been disappointed that the various authenticators do not have a universal export format.



LEO:  Well, that's why I use Authy.  Authy does, but the problem is it stores it on its Authy servers, which is...



STEVE:  Yeah, yeah.



LEO:  It's encrypted.  It seems to be Trust No One because I use my own encryption passphrase.  But nevertheless.  I don't know.  Security's hard.  That's why I listen to this show.



STEVE:  "Security is hard."  Ooh, that'd be a good title, yeah.  I think actually we've used that title several times.



LEO:  "You're doing it wrong" is my favorite.  Steve Gibson's doing it right, every week, right here, every Tuesday at 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  You can watch it live if you want at TWiT.tv, or you can download an episode after the fact.  Steve's got them all at GRC.com.  He also has transcripts, if you like to read along while you listen.  Sometimes that helps with comprehension.  Or it's just a great way to search.  He's got lots of stuff at the site, while you're there.  The sleep formula, all the stuff.



And SpinRite, the world's best hard drive maintenance and recovery utility.  You could keep up on SQRL as we edge closer to the release day.  And you can send him a little yabba dabba doo, while you're at it.  Buy a copy of SpinRite.  We have audio and video at our site, TWiT.tv/sn.  So again, you don't have to be here live.  You can always listen after the fact, or watch even.  And every podcatch, I mean, 11 years, Steve, 11 years.  That's a long time.



STEVE:  I thought doing the column for InfoWorld for eight years was a long time.  But, yeah.  I've passed it by three now.



LEO:  It's remarkable.  Well done.  You can listen to every one of them.  They're all there.  Every one of them, if you really wish, 572 episodes, soon 573.  We'll see you next time.



STEVE:  Thank you, my friend.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#573

DATE:		August 16, 2016

TITLE:		News & Memory

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-573.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, Leo and I catch up with the past week's news.  Did Microsoft lose control of its secure boot Golden Key?  We discuss AdBlock, unblock, counter-unblock, and that counter-counter-unblock is well underway.  Leo tells a story from the field about Avast A/V.  A "security is hard to do" mistake is found in an update to the Internet's TCP protocol.  We talk about Microsoft's evolving Windows Update policies, an ber-cool way for developers to decrypt and inspect their Firefox and Chrome local TLS traffic, a nice write-up of our "three dumb routers" solution, trouble with Windows Identity leak mitigation, yet another way of exfiltrating data from an air-gapped PC, and some fun miscellany.  We wrap up with a discussion of Intel's forthcoming memory breakthrough.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  A big clarification:  We've all been reporting the story about Microsoft and the magic golden key being released.  It turns out it ain't that way at all.  We'll have a clarification from the one guy who understands what's actually going on.  He'll also take a look at a very exciting new kind of memory.  Intel has just announced it.  It's going to change everything.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 573, recorded Tuesday, August 16th, 2016:  Memory and micro kernels.



It's time for Security Now!, the show where we cover your security and privacy online with this guy right here.  This here is Steve Gibson of the GRC, Gibson Research Corporation, at GRC.com.  He joins us every week after extensive research on the scene, and he lets us know what's going on.



STEVE GIBSON:  Frantic, panting, pull everything together research.



LEO:  You're not a last-minute guy, though.  I don't think so.  You're very thorough.



STEVE:  Well, I start worrying about it, I mean, I'm collecting all week, and then what often happens is I'll make a final posting to the SQRL newsgroup in the, like, middle of the afternoon on Monday, saying, okay, here's an update to the client.  It does, you know, these things are added.  Now I've got to switch my attention over to the podcast.  So it's a full, focused 24 hours that I put in for the podcast, with then sort of a background collection of things that I see.



LEO:  Wow.



STEVE:  No, well, I mean, it shows, and I'm glad.



LEO:  It does show.  It does show.  We're very grateful for it.  You work hard.



STEVE:  And, boy, this is an example.  A really interesting question we answer about whether Microsoft lost control of their so-called "secure boot golden key."  We have the Adblock unblock, counter-unblock, and counter-counter-unblock being well underway.  I want you to share, Leo, your story from The Tech Guy this weekend.



LEO:  Oh, did you hear that?



STEVE:  About the woman who had the Avast AV problem.



LEO:  Yeah.



STEVE:  We've got really a classic "security is hard to do" mistake in a core update to the Internet's TCP protocol, which ended up inadvertently creating an exploit, which again, it's like, security is hard, as we often say.  We've got - I want to cover Microsoft's evolving Windows Update policies, which is all good news for everybody.



I stumbled upon, actually, thanks to a Twitter follower who sent me a link, an ber-cool way for developers to decrypt and inspect their Firefox and Chrome local TLS traffic, which, like, is one of the reasons that HTTPS is sort of a pain for developers is your browser encrypts things.  And so you can't see it if you're just doing a packet capture.  It turns out there's a way, without needing to set up, like, a Fiddler/man-in-the-middle sort of deal of any kind.



Also I found a really nice write-up of the "three dumb routers" solution that was done.  We've got some trouble with, as I mentioned last week, the Windows identity leak mitigation causing all kinds of problems.  And so that's not the way to do it.  I'll talk about the way to do it.  Yet another way in the never-ending stream of ways of exfiltrating data from an air-gapped PC.  We've got a bunch of fun miscellany.  And then, actually coming from two topics you covered on TWiT, one about micro kernels and the other about Intel's forthcoming memory breakthrough.  I was listening to TWiT, and I had some things, sort of a little more deep dive into those two topics that I thought all of our listeners would find interesting.



So a catch-up on the news and some fun miscellany.  I figured out, by the way, what was CUJO'ing my system at Level 3, so I'll talk about that and a whole bunch more.



LEO:  Wow.  Jam-packed.  And I can't wait.  I'm actually really intrigued with - we had a fascinating TWiT on Sunday.  Greg Ferro from the Packet Pushers Network, obviously a geek of high water, brought up some very interesting things.  So we'll talk about that in just a second.



STEVE:  And you had Allyn on the show also.



LEO:  Had Allyn Malventano.  It was a great show.  It was fun.  Devindra Hardawar.  It was just jam-packed.  Alex Wilhelm.  I hear a magic sound.



STEVE:  Well, as I promised, I did not mute all of my devices.



LEO:  But that was not a "yabba dabba doo."  What was that?



STEVE:  No, that is exactly 2:00 o'clock.  We have an hourly chime.



LEO:  Oh, okay.



STEVE:  You know, there are many things that Mark Thompson and I are aligned on.  When we first met each other actually is when you were present at the first Gnomedex.



LEO:  I never forget it.  So much fun.



STEVE:  Where I was the keynote speaker for the first Gnomedex.  He and I met for the first time.  We had both chosen the same speakers for our stereo systems, both the same make and model of projector for our projection TV.  And as we went through, we had independently chosen, made all the same decisions.  One way that we're very different, though, he's also a big anime person.  And just no, thank you.  I just never got into anime.  He can't stand anything making a noise.  And I use sound as another input channel.



And so when Amazon is, you know, I get a notice for delivery, I get some monkeys that are jumping around.  I have an hourly chime.  Of course, famously, yabba dabba doo when a copy of SpinRite sells.  And so I just, you know, I have a lot of sounds.  And my PC also, that's the other thing, things like, for example, you can associate a process starting and a process stopping with sounds.  And so, like, things are going click click click click and bing bing bing boink.  But it's useful for me to know when something is going on because it's like, okay, wait a minute.  What is that?  I didn't do anything.  Whereas Mark has no sound.  And actually...



LEO:  Yeah, I'm kind of with him.  That would drive me crazy.



STEVE:  ...a tremendous investment in a big PC enclosure that manages to cool some serious heat-generating machines absolutely silently.  So that when he's working, you know, he's surrounded by screens the way I am.  But there's just no sound.  Whereas it's a little bit of a carnival over here.  So, you know, I always turn all of that off so as not to have the podcast disrupted.  But many people have said, "I would really just love to hear my own purchase of SpinRite."  So as I mentioned last week, okay.  We'll see how that goes.  So for what it's worth, every hour we'll get a chime, and maybe - I already heard the monkeys before this, so Amazon's done its delivery.  So I don't think we'll hear them again.



Okay.  So the big news is the massive misreporting across the entire industry of this Microsoft secure boot golden key.  That did not happen, not in any way, shape, or form.



LEO:  Oh.  What?



STEVE:  It was complete, completely wrongly reported.  Threatpost said, "Microsoft mistakenly leaks secure boot key."  9to5Mac says, "Proof Apple was right to fight the FBI."  Ars Technica, "Microsoft secure boot firmware snafu leaks golden key."  None of that is true.  Complete misreporting.  In my notes I said...



LEO:  What?



STEVE:  The report on this has been 1,000%, meaning very, very inflammatory and incorrect.



LEO:  Okay.  So just to - because I've been reporting it that way.  We don't have the sophistication to know this is wrong.  My understanding was there is secure boot.  In most cases, by the way, you could turn it off.  Otherwise I wouldn't be able to put Linux on all these machines that I put Linux on.  You just disable it in the startup BIOS.  But on some Microsoft machines, like the Windows RT tablet, you can't disable it.  And apparently there's...



STEVE:  And phones.



LEO:  And phones, that's right.  But so as is often the case, like with the CSS, the DVD encryption and the Blu-ray encryption, there's a key, a master key; right?  And Microsoft, it's said, please correct us, published this master key inadvertently in a source code posting on GitHub.  All of that's not true?



STEVE:  No.



LEO:  Oh, my god.



STEVE:  So, okay.  So the hackers who figured this out are absolutely talented, and they did a terrific job of cleverly uncovering an exploit.



LEO:  Not to mention publishing that exploit with fine synthesizer MIDI music and an animated golden key.



STEVE:  And, now, see, this is an example of what does drive me crazy, is like...



LEO:  It's hard to read this.  You have to cut and paste it, frankly, is the only way to read it.



STEVE:  The good news is you can do a Ctrl-A, and it will mark the entire thing, copy, and then drop it in Notepad.  Immediately then close that page.  Lord knows what it's doing to your processor.  And then at length - so those are actually hashes.  That's not the key.  Those are hashes...



LEO:  Ah, okay.



STEVE:  ...of individual bits of secure boot.



LEO:  SHA 256-bit hash.



STEVE:  So here's what happened.  What they did was uncover a mistake.  And again, I want to make it clear.  These guys are good.  They did a great job.  Unfortunately, they mixed a little of their own personal agenda in with reality, trying to draw a conclusion that was unwarranted.  So, but again, great reverse-engineering and cleverness.  Just not what - essentially, they used the term "golden key."  And because their write-up was itself very confusing and dense, I had to just, like, go back and forth and make notes and leave a trail of crumbs and, like, okay, wait a minute now, and, like, basically decode what they published because it was really, I mean, these guys are not technical authors.  They're hackers.



So what this actually was, was an implementation design error in the handling of boot permission policies which can be used to trick older version of the UEFI secure boot manager using some components of an update.  So the so-called Redstone version of Windows 10, which is 1607, version 1607...



LEO:  The anniversary update, the current, yeah.



STEVE:  We know it as the "anniversary update."  It added some new technology, the concept of supplemental secure boot policies, which can, for example, be used for test signing development code.  And of course that could also be malicious rootkits and so forth.  So there is, there's a fundamental problem with secure boot.  You just referred to it earlier, and that is, what if I want to run Linux?



And we did a whole podcast on the UEFI secure boot technology and how it starts from a known unmodifiable piece of integrity on the motherboard which cannot be changed, and carefully brings the system up by verifying the signature of everything that it loads before turning control over to it.  And if you do that perfectly, what you end up with is a system in a known state.  What you also end up with is a system that you can't change.  So there's a tension in this approach with people who, for whatever reason, want to change; and for non-malicious purposes, like developers needing to develop kernel drivers, boot-time drivers, and developers.



So with this anniversary update, Microsoft created an extension to the boot policies known as supplemental policies, which have weakened verification, but which that same new boot manager understands.  So there was no problem with that.  These guys realized that what that did, though, was create a vulnerability because these new supplemental policies with a lower degree of verification could be used to fool older boot managers which didn't know to specifically check for them.  So they looked like regular policies.  The updated boot manager is aware of them.



And so this is a little bit sort of like that weird problem we have, like with people doing fresh installs of Windows 7, where Windows Update has changed so that you can't use Windows Update to add the updates to Windows 7 until you manually update Windows Update so that it then knows how to read the data from Microsoft's changed Windows Update servers.  Similarly, Microsoft enhanced the flexibility of secure boot in a way that, if you're using sort of synchronized pieces, everything's fine.  But they just missed the fact, and these guys caught it, that you could take the new policy parts from the update and use it to fool the pre-update boot manager.  That's all that is.  There's no key involved.



So what they wrote, you can see where the press got this, they wrote:  "You can see the irony.  Also the irony in that MS themselves provided us several nice 'golden keys,' as the FBI would say, for us to use for that purpose."



LEO:  Ah.



STEVE:  So they were using the term referring to the FBI's use or request for some way of unlocking the system.  But the press picked it up incorrectly.



LEO:  Like there was a key, right.



STEVE:  Thinking that it was actually a key.



LEO:  Of course that rotating floating golden key in the demo scene might have had something to do with it.



STEVE:  Oh, I mean, yes.  And so, well, and here's a little bit of their own agenda.  So they said:  "About the FBI:  Are you reading this?  If you are, then this is a perfect real-world example about why your idea of backdooring cryptosystems with a 'secure golden key' is very bad."  Well, no, that's not what this is at all.  But then they continue:



"Smarter people than me have been telling this to you for so long, it seems you have your fingers in your ears.  You seriously don't understand still?  Microsoft implemented a 'secure golden key' system."  No, they didn't.  "And the golden keys got released from MS own stupidity."  Well, no, they didn't.  "Now, what happens if you tell everyone to make a 'secure golden key' system?  Hopefully you can add two plus two.  Anyway, enough about that little rant, wanted to add that to a write-up ever since this stuff was found."



So, you know, these guys have an agenda, and this was a platform for allowing them to express themselves.  Unfortunately...



LEO:  Yeah, I mean, we share their agenda, but it doesn't have anything to do with this.



STEVE:  No.  Not at all.



LEO:  Now everybody, including me, including everybody I ever talked to, misunderstood this.  Thank you for setting the record straight.  I wish you would call everybody and tell them.  Because I haven't seen one article saying, "No, no, that's not it."  I guess it is kind of hard to understand, frankly.



STEVE:  Well, think of how fabulous this would be if it were true.



LEO:  I know.  I know. 



STEVE:  And, I mean, it's not true.  So, and now the problem is I don't know how Microsoft mitigates this.  I mean, this is - I don't mean to downplay this.  This is a big mistake because this does allow non-updated boot managers, pre-anniversary update, to be fooled with some pieces that are from the anniversary update.  So this was, I mean, this is absolutely a mistake.  But what it wasn't was the disclosure of a golden key.  So anyway, and believe me, I don't blame the press for not digging in because it was hard to determine that that's what this was.  And then when I thought I understood it, then I read it again several times to make sure I was right.  It's like, okay, yeah, that's what these guys did.  Which is nice work.  But the whole golden key is an absolute red herring, referring to the notion of backdoor systems.  But this isn't that.  This was a mistake.



LEO:  Right.  Microsoft has put out some fixes, the ROS and Slipstream.  The hackers who discovered it said those don't do anything.  They say in their write-up - now, I'd like to get some clarification on this, too - that Microsoft really can't fix it because it would break these older systems.  Is that the case?



STEVE:  My point.  That's my point.  It's like, I mean, we have an enduring problem.



LEO:  Right.



STEVE:  What this would - the only thing you could do, or Microsoft could do, would be to release, securely release an update to the boot manager.  That they could do.  If they brought, that is, for people who didn't, for whatever reason, didn't want to update to the anniversary edition of Windows 10, Microsoft should at least, and I imagine they will, I think we can foresee this, there will be an update to all Windows systems that support secure boot.  They could be updated for awareness of this new supplemental policy system, and that would then shut everything down.  But that of course requires action from the entire industry of users.  So it's a big problem, but it can be fixed.  But it does require that the existing boot managers be taught about these changes.  And it just slipped by, it just slipped underneath Microsoft's radar.



LEO:  And it doesn't affect, like, main line of business stuff for Microsoft, either.  So there's not a huge incentive to fix it.  You point out, correctly, it's not about installing Linux on it, it's that a rootkit or something else could use it to modify the operating system.



STEVE:  Right.  Well, and in - oh.



LEO:  What?  A yabba dabba do?



[Yabba dabba doo]



LEO:  Wait a minute.  Did you have a precognition that you were going to get a yabba dabba doo?



STEVE:  No.  What happens is...



LEO:  Does the hard drive make a unique eh-eh right before it plays yabba dabba doo?



STEVE:  I have a real-time monitor to GRC's servers.  So that gave me the first indication.



LEO:  Oh, my.



STEVE:  Then GRC's servers sends a text message to my phone, which is tied with iMessage to all the other devices.



LEO:  That's so funny.  That's so funny.



STEVE:  So I did hear it first.  And actually that was a corporate purchase.



LEO:  Nice.



STEVE:  That was four yabba dabba doos.  So whoever that was, thank you very much.  If you're listening, I appreciate it.



LEO:  Probably somebody listening to this, saying Steve Gibson's the only guy that got this whole story right in the whole world.  And thank you, Steve.  Here, I'm going to buy a corporate license.  That is awesome.  So I just want to clarify, because I'm going to, I mean, I now have the obligation to, in every place where we said this, including Windows Weekly tomorrow and on TWiT on Sunday, to say we got it wrong.  This doesn't do that.  This isn't a golden key.  This just involves using bits and pieces of the Redstone update to modify the secure boot in older versions of Windows, like Windows RT and Windows Phone.



STEVE:  Correct.  So, yes, the supplemental policy pieces that were added, that technology added to Redstone is a means of permitting developers to install test code.



LEO:  Ah, right, right.



STEVE:  Essentially to allow secure boot to believe that their test code is valid.



LEO:  For development purposes, yeah, yeah, okay.



STEVE:  But there are things missing, some device ID pieces and other pieces, that just aren't necessary there.  But the updated secure boot knows about that, which is what makes that safe.  Yet what these guys discovered is you could take those supplemental policies, and they would work on older versions of secure boot across the board, allowing anybody to use that to install their code, basically to completely subvert any pre-anniversary update secure boot technology.



LEO:  Got it.  Okay.  Well, I will fix that.  And I did get - it's not that I didn't try to read the original post.  And I did.  But I don't have the skills you do to parse it, and I didn't understand a word.  So, not that it was very well written.



STEVE:  And it even jumps around, you know.  They had a lot of fun doing it.  But, like, the text jumps around.  So it's like, okay, wait a minute, wait a minute.  What?  What?



LEO:  Yeah.



STEVE:  And so I copied it to a text file.



LEO:  Well, lesson learned.  When it comes to highly technical subjects, even the tech press often gets it wrong.



STEVE:  Again, you couldn't have dangled a bigger golden carrot in front of the press.



LEO:  Right.  We all wanted to believe it.  Right.



STEVE:  Oh, yes.  I mean, it's a fantastic story.  It's just not true, unfortunately.



LEO:  Yeah, yeah.



STEVE:  So, anyway, that's why we have the podcast.



LEO:  Thank you.



STEVE:  I got a kick out of you talking about this on TWiT and needed to talk about the foreseeable ad blocking-unblocking wars which are now underway.  And I appreciated you noting that it was easy to block third-party ads.  We should back up a little bit.  This is Adblock Plus versus Facebook.  And as we know, Facebook's revenue model is advertising.  And so Facebook is not happy at the idea that users would be empowered to block ads on their devices.  And the response on Sunday's TWiT show was universal about ads on phones.  I mean, it's just such a problem there on mobile devices that the ad blocking has been a major win.



So Facebook has worked around Adblock Plus's blocking, and the news is that Adblock Plus has now worked around Facebook's unblocking of their blocking, and back and forth.  And what you properly noted was that blocking third-party sources is trivial because most ads have traditionally been pulled from a domain other than the page's domain, the site from which the page was pulled.  But it is the case that one of the ways - and we always knew this was possible is that, if advertising came from the same domain, that would make it more difficult.  But of course developers are going to just naturally have different URLs.  Maybe there'll be a subdomain, you know, ads.facebook.com, for example.  So it's from the same primary domain, but a different subdomain.



Well, clearly, by default, something just blocking third-party ads would permit those.  And so ads appear.  Then the adblocker says, oh, well, we're going to block ads.star stuff.  And in fact there are some rules of various sorts that do that.  And so then Facebook says, oh, okay, fine.  So then they stop using domains, and they put something down in the URL path, but probably still looking different than non-ad content.  It'll have a different URL pattern.  And so, again, I mean, the problem is Facebook is fundamentally trying to do something probably impossible.  And that is, they are trying to force what the browser client shows its user.  And that really isn't a level of control that this system was designed to offer.



The only way I could imagine it could be done, and it would kill so many other things, and that would be just to turn a page delivery into a scrollable PNG image.  So basically you go to a page, and what you get is one pre-rendered PNG image that you then scroll down.  And then there's no way to block it without taking it all apart and masking it and things, which would be another level.  But fundamentally, as we know, the HTML goes to the browser.  It parses it and finds lots of references to images and things and then requests those.  But that's at its choice.



And so what the ad blocking does is put a filter in that action, that secondary fetching, to say, eh, let's not get things that look like this.  And so this back-and-forth continues to proceed.  And, I mean, you could even imagine it going as far as, you know, if ads had fixed sizes, then an adblocker could say, oh, we're going to block images of those sizes.  And so then the ads start having fudgy sizes, and back and forth.  Problem is I just don't think that Facebook is going to be able to win this one.  It'll be interesting to see how this goes.  But this was entirely foreseeable, and it's happening just like one would imagine.



LEO:  Yeah, and I don't know how you end this; right?  It's just round after round of escalation.



STEVE:  Yup.  This is one where...



LEO:  I like the idea of a solid PNG.  I hope they don't do that.  But that would work; right?  That would - there's nothing you can do about that.



STEVE:  Yeah, although you'd lose all of the dynamic functionality.



LEO:  You have no interactivity, yeah.



STEVE:  Yeah.  And so unless you did some sort of an interactive overlay on top of that - and actually, I mean, the document object model, the DOM in today's browsers is powerful enough that you could do that.  You could pre-render the page with the ads in place and then overlay hotspots and control some things on top of it.



LEO:  You wouldn't have AJAX-y stuff, but...



STEVE:  Yeah.  Maybe it'll happen.  So tell us about, Leo, the woman that called with her Avast problem.



LEO:  Yeah.  I wanted to run this by you.  And I've talked to some people since who confirmed my theory, although it's never...



STEVE:  I listened to you, and I thought you were dead-on.



LEO:  Yeah.  Rose was a community manager for a local synagogue and used Facebook to post information about events and so forth.  And at some point her Facebook stream was hijacked, and Turkish, spammy links in Turkish to porn sites started to fill her feed.  Of course immediately most of her friends unfollowed her.  They didn't want to see that.  And the synagogue probably did the same.  And she went - she did everything I thought she should do.  We went - it took me half an hour with her.  I did 15 minutes on the air and then I stuck around during the news break to talk some more about it.  Took me a while to figure out what was going on, or at least a theory about what was going on.



And she did all the right things.  She went through her Facebook connected apps and disconnected everything.  She changed her Facebook login.  She did everything she could - she brought it to a, she said, Israeli security guy, and he cleaned it, ran Malwarebytes and stuff.  And I was very puzzled because the thing that really triggered a warning bell for me is she said every time I go to Facebook, it says you have to change your password.  And she would not - I said, well, did it then email you or call or send you a link?  She said, no, it was right there, it just says "change your password" on the Facebook page.  And I thought, that is not normal behavior.  That's not what I would expect from Facebook.



So finally, after quite some time, I should have done this right away, I said, well, you're on - look at the browser bar.  You're on https://facebook.com.  Yes.  Is it green?  Yes.  Click the padlock.  Okay.  Does it say you're on a secure site?  Yes.  Who's the certificate by?



STEVE:  Nice work, Leo.



LEO:  Avast.



STEVE:  Yup.



LEO:  Avast, which is of course an antivirus company.  And I dimly remembered us talking about a flaw.



STEVE:  Yes.



LEO:  First of all, Avast, and this is not unusual, I think other antivirus companies do this, and other security companies, put a man-in-the-middle certificate in so they can scan all the traffic, SSL traffic.



STEVE:  They have to now.



LEO:  Yeah.



STEVE:  If they want to look into your secure connections, that's the way to do it.



LEO:  Right.  Not the way you want them to do it.  And that's what Superfish from Lenovo did, and others.  So that was a man in the middle.  But we had talked about the fact that that particular - I believe the Avast root certificates had leaked.



STEVE:  They lost their private key, yes.



LEO:  That's what I thought.



STEVE:  They published it by mistake.



LEO:  So what I assumed - and I never got confirmation from Rose.  But what I told Rose is, well, first of all, get Avast off of there.  And you don't want to go to any site that doesn't say the certificate comes from that site.  But what I in the back of my head was assuming is that some Turkish actor had figured this out and was doing a man in the middle to her using the Avast certificate and hijacking her Facebook traffic.



STEVE:  And the moral of the story for our audience is this is the problem with a third-party interception.  I would argue that, in a corporate setting, the border proxy which is intercepting secure connections is on balance a good thing because the corporation has a need to protect their networks and their users from all incoming traffic.  And the only way to do that is to look inside those connections.  And in a corporate setting you're using corporate facilities, corporate bandwidth, and so forth.  So employees need to understand they have no expectation of privacy when they're using the corporate equipment.  And IT has an obligation, I think, ethically, to make it clear, you know, to print that in a little notice that's stuck on the top of the monitor to remind people that communications with this computer are being screened for security purposes.



In that setting, though, we've got hopefully professional-grade IT running real well-designed, hopefully well-designed hardware screening this.  The problem with changing that model to everybody's PC is pretty obvious.  And that is, suddenly that same technology which is very powerful is operating in your computer.  And we've talked about how the unfortunate side effect of this next generation of very intrusive antivirus is it increases the attack surface.  So it could very well be, you know, who knows.  Maybe every email she sends out has a little tagline added, "Scanned by Avast AV," and somebody, I mean, what you're basically doing is you're broadcasting the fact that there's this, like, what your technology is...



LEO:  I'm using Avast, yeah, yeah.



STEVE:  ...in your machine.  And if any flaw is then found, somebody sends you back a piece of email, knowing that Avast is going to scan it.  And if there's any problem with what they've got running in the kernel, that's all it takes.  And we've seen this.  This is not theoretical.  This happens.  You receive email, and it takes over your machine.



LEO:  What is the, for a less sophisticated user like Rose, what's the remediation that you would recommend?  I mean, she could remove the Avast certificate from her authorities, but that's maybe an advanced thing.  Uninstall Avast?  Would that be sufficient?



STEVE:  I would uninstall Avast.  Although the problem is, if that cert is there...



LEO:  That cert's now in the accepted cert authorities.



STEVE:  In the root.  It's in her root list of trusted certs.  So you absolutely, I mean, and you're right, Leo, this is a problem.  It's because, as you said, she's doing what she can, but...



LEO:  She got a so-called "security expert" to look at it.  Why he didn't notice this is another matter.



STEVE:  Yeah.



LEO:  So, yeah, this is a tough one to fix because she has to know enough to go into the root certificates and purge Avast.



STEVE:  And that's my point is that this is high-power technology...



LEO:  That shouldn't be used.



STEVE:  ...that you could argue should not be occurring on systems.  The AV people have been forced to do this by us all switching to encrypted connections.  I just think staying with Microsoft's solution is probably the right move.



LEO:  Yeah.  Wow.  Anyway, yeah.  She was using Chrome.  She turned off all browser extensions.  She did, I mean, she did everything I would have said.  But, I mean, my god, that's such a deep hook into her system.



STEVE:  Yeah, and Chrome does use Windows - Chrome doesn't have its own security suite.  It leverages the security platform of the machine it's on.  And in Windows it is using Windows CA root trust store.  So that all tracks.



LEO:  Well, I'm glad you were listening, and I didn't say anything really stupid.



STEVE:  No, you did a great job.



LEO:  Whoo.



STEVE:  And it's nice, too, that she's able to click the padlock, dig in, figure out who the cert came from.  And you immediately recognized, whoops, that HTTPS cert should not be signed by Avast.  They should be signed by wherever you're visiting.



LEO:  And as you know, I then took the next segment as a chance to kind of explain the certs and how to check the certs.  And I wish everybody knew that.  If you're a geek listening to this, and you haven't shown your parents and your friends how to check to make sure the cert is what it says it is, you know, it's more than just looking at the address bar.  It's going one step farther, yeah.



STEVE:  Yeah.  So there was an interesting, another news item that I wanted to clarify.  Again, it made headlines because it seems to affect so many devices.  But what's actually behind it is a much more interesting story.  And so, for example, ZDNet had coverage saying "Linux traffic hijack flaw affects most Android phones and tablets."  And then they explain a difficult-to-exploit flaw affects all Android phones and tablets that are running Android 4.4 KitKat and later, which comes with the affected Linux kernel 3.6 or newer.  That's 1.4 billion devices, including the developer previews that are out now of Nougat.



So what's behind this is really interesting.  That Linux kernel 3.6 was released in September of 2012, so just about four years ago, coming up on four years ago.  And the developers deliberately added support for a very recent, relatively, update to the core TCP protocol, in order to tighten it up against some known attacks.  Unfortunately, in doing so, these researchers who published a paper at last week's 25th USENIX security conference demonstrated a way for what's known as a blinded attacker, that is, an attacker that isn't a man in the middle, has no visibility, but does know the IP addresses of two communicating endpoints.



It turns out that, as a side effect of a change in TCP, and it's like RFC 5912 or something, I mean, it's a high-numbered, late-model, request-for-comment document that has part of the TCP spec.  As a side effect, there's a way of an attacker to shut down communications, but without being in the middle, just knowing that two endpoints are communicating, and their IP addresses.  And if it's non-secured, that is, if it's, for example, an email exchange, then it's even possible for the attacker to inject their own data into the flow.



And so what was interesting is that, well, first of all, it ends up being - these guys did a beautiful job and leveraged their insight into something quite powerful.  In the abstract for the paper they said:  "In this paper we report a subtle, yet serious, side-channel vulnerability, introduced in a recent TCP specification.  The specification is faithfully implemented in Linux kernel version 3.6 and beyond, and affects a wide range of devices and hosts.



In a nutshell, the vulnerability allows a blind off-path" - that's the term I was looking for - "off-path attacker to infer if any two arbitrary hosts on the Internet are communicating using a TCP connection.  Further, if the connection is present, such an off-path attacker can also infer the TCP sequence numbers in use, from both sides of the connection.  This in turn allows the attacker to cause connection termination and perform data injection attacks.  We illustrate how the attack can be leveraged to disrupt and degrade the privacy guarantees of an anonymity network such as Tor and perform web connection hijacking.  Through extensive experiments, we show that the attack is fast and reliable.  On average, it takes about 40 to 60 seconds to finish, and the success rate is 88% to 97%."  Which is, as our listeners of the podcast for a long time know, that's way up there in terms of attack reliability.



"Finally," they say, "we propose changes to both the TCP specification and implementation to eliminate the root cause of the problem."  So essentially this is another "security is hard."  The brightest minds in the industry, you know, we don't have college interns changing the TCP specification.  The guys that are changing TCP are, I mean, really know their stuff.  Yet, even so, mistakes get made.



And the real problem is - we've talked extensively about TCP in the past, I mean, because it's just a lovely protocol.  But the problem is we come back to the original concept of the Internet, where security was an afterthought, or actually it wasn't a thought at all.  It was, oh, my god, this works?  Just the idea that it worked was a miracle back then, that you could use these autonomously routed packets, where it's just a packet of information that has a destination IP address, and then a grid of loosely connected and not even reliably connected routers are able to forward packets toward their destination.  And if you do that enough times, you get there.  And the packets contain the IP of where they came from, which allows the recipient to respond.  And that's the Internet.



Yet it's like, unfortunately, it also permits all kinds of mischief.  And notice that, as I mentioned, you could do data injection if it wasn't encrypted.  But even encrypted payloads are still carried in an IP and TCP wrapper, which fundamentally have this problem.  And so, for example, I'm not going to go back in and do a tutorial on TCP.  We've done that already.  And if anyone's interested, it's there in our archives.  But the data being sent in both directions, the bytes are numbered in a monotonically increasing sequence, which wraps around, it's a 32-bit count, so it wraps around after 4.3 billion.  But it doesn't start at zero.  It starts at a hopefully random place.



So once upon a time the starting points weren't random enough.  And so knowing where the sequence number was, was enough to allow somebody to spoof.  Essentially, that's what this is.  It's a way of spoofing.  And when you think about it, you've got a worldwide network of loosely connected nodes.  The only thing that identifies a packet is, like, while it's being routed, is the IP that sent it and the IP that it's going towards, its destination.  But anybody else can drop a packet on the Internet that spoofs its source IP.  Which means that the recipient has absolutely no verifiable means to know where it came from.  That's the crux of the problem, when you've got this loose confederation of routers that are simply - they don't care what's in the packet.  They just send it on its way.



What that means is that, if somebody else can - well, essentially it means that anybody in the world can drop a packet onto the Internet with made-up information, and it will arrive at the destination, and there is no way, none, for the recipient to know that it didn't come from the source.  Now, one of the ways that spoofing has been mitigated is with the so-called "sequence numbers," that is, it's known as a TCP window, which identifies the allowable range for packets coming in.  And packets that fall outside that narrow range relative to 4.3 billion, that whole 32-bit sequence number space, they're just discarded.



And so what these guys did was they figured out a way to, blindly and off the path, to be able to send, leveraging some features that were meant to increase the security of TCP, they could leverage those against security in order to obtain information from the endpoints, enough to allow them to get port numbers and sequence numbers.  And if you know the IP address, the port number, and the sequence number, that's the only disambiguating information that the packet contains, you can then fool TCP.  So here we are, what, decades from the time this was created, and the smartest people we have are saying, ooh, let's update TCP in order to fix some problems.  And they ended up doing just the reverse by mistake.



LEO:  Oopsies.



STEVE:  So, yes.  So they conclude in their paper, they say:  "The contributions of the paper are the following:  We discover and report a serious vulnerability unintentionally introduced in the latest TCP specification, which is subsequently implemented in the latest Linux kernel.  We design and implement a powerful attack exploiting the vulnerability to infer, first, whether two hosts are communicating using a TCP connection? and, second, the TCP sequence number currently associated with both sides of the connection.  We provide a thorough analysis and evaluation of the proposed attack.  We present case studies to illustrate the attack impact.  We identify the root cause of the subtle vulnerability and discuss how it can be prevented in the future.  We propose changes to the kernel implementation to eliminate or mitigate the side channel."



Oh, and patches do exist.  They were released on the 11th of July, so more than a month ago, but they won't be pushed out into Android, it's expected that they'll be part of the September updates for at least the Nexus 7 phones, along with the other batch of problems that are going to be fixed next month.  So, really interesting.



LEO:  They said in the article, one of the articles I read, that Google was not treating it as a major security flaw.  It's hard to do.  It's a flaw, but it's not - it's a nontrivial thing to do; right?



STEVE:  Correct.  And virtually all of our communications is over TLS now.  So you can't...



LEO:  Right, anyway, right.  This is why you want - you've now convinced me that everyone should HTTPS everywhere; right?  That's another reason why.



STEVE:  Yeah.  We have the processing power to handle the encryption.  We've got certificates thanks to Let's Encrypt.  There's just no reason not to do it.  And so it's not even just for privacy.  It's like for this kind of little edge case issues that you would never expect.  Something I don't have in the show notes but was sort of on my mind last week, there was a report in the U.K. about surveillance vans that were going to be driving around and were able to reportedly determine if somebody was pirating some subscription content from a service.  It's not in the notes.  And there was a lot of speculation about how that could possibly be done.



So I just wanted to mention that - oh, and apparently they would be using WiFi, that is, like sniffing on the WiFi.  That caused a ruckus because the presumption was, very much like Google Maps famously did by mistake where they were capturing packets, and they said no, no, no, we're not doing any data interception.  And so there was a lot of conversation about, well, how is this possible?  How could that be done?  Well, and so I just wanted to comment that, if this surveillance van is from the company that is offering the service, then they're watching the recipient and wanting verification that they're receiving subscription content.



And this is very much like the Tor deanonymizing.  Remember that, as we've talked about with Tor, while it's difficult to obtain an identification of endpoints outside the network which are communicating, it is trivial to confirm it.  So if you have a suspicion, then it's trivial.  All you have to do is, for example, block the traffic for a while and see if your suspicion is borne out because the other end suddenly dries up, and then you let the traffic go.  And, oh, the traffic comes back again.  So you can't absolutely know in that instance.  But you can have a pretty good idea.



So, for example, if some - if this van wanted to catch people who were pirating this content, they would have the ability to know the IP address of where the van is parked in front of, passively receiving encrypted WiFi.  They could do something, for example, like for that IP at the sending end, change the packet size.  Or change, you know, make every 10th packet half size.  And that pattern would emerge at the receiving end and confirm that the data stream was coming from that source.  So again, in trying to have a level of privacy that the Internet absolutely was never designed to provide, you can't have it.  You can want it, but you can't get it because the technology will work against you.  It just - it wasn't built to offer that.



LEO:  All right.  Back to filling our brains with Steve's knowledge.



STEVE:  Some nice news for people using, staying, who have chosen to stay with Windows 7 and 8.1.  Microsoft last week, I think it was, announced that they were going to basically learn from the success of the Windows 10 patching and updating model and begin adopting that starting with the October updates of, in this year, 2016, for Windows 7 and 8.1.  So what that means is instead of what has traditionally been, what we've been talking about since the beginning of the podcast, is every second Tuesday of the month from the point they began, I guess it used to just be at random times, then they went to the second Tuesday because IT departments were going crazy with unplanned, unscheduled patch releases.  They, as we know, it would be many individual patches.  You would run Windows Update.  You'd see a list of 13 things.  If you were curious you might poke around and look at them.



That's going away.  So instead of essentially what are a handful of individual incremental updates, all updates will be merged into a single monthly, one monthly update blob.  And from starting in October, each successive month will add to that existing new patch base, offering one single update.  Meaning that, if you missed a couple months, all you ever need is the latest one because it will automatically back-incorporate, starting in October, back to October, anything that has happened since.



And then, over time, Microsoft will also move this blob's updates backward in time.  They're probably just doing it carefully to make sure that they don't break anything.  But the point is that that will incorporate earlier and earlier patches until eventually, and we don't know when, but eventually the monthly update will be able to take an original last edition of Windows 7 or 8.1 - in the case of Window 7 it would be Service Pack 1, the last official image, and bring it current.



Now, of course, as we know, Windows Update itself has changed in such a fashion that, as I mentioned before, if you install a new version, a new build, or the last build of Windows 7 SP1, it can't find any updates because the update server has changed.  So you still need to do the Windows Update update, to update Update.  And then it will be able to grab one blob and bring your system current.  Now, that's all good, except that - and it sort of gives us a rolling mega update rollup.  But we should note that it is removing some user control.  I know that a lot of people, like the type of people who listen to the podcast, like to see - oh, 3:00 o'clock.  Like to see - now you know why I normally mute these things.



LEO:  That's actually kind of pretty.  I wouldn't mind that.  It's not, you know, it's just like a...



STEVE:  Yeah, I like it very much.  So we like to see what's going on, and in some case choose not to do something.  And of course the famous instance is the 3035583, which is the infamous Get Windows 10 update.  Although I never endorsed the idea of avoiding it, because avoiding Windows Updates is just difficult to do, I know that many people kept, you know, every single month Microsoft would offer 3035583 for their machine, and they would turn that off, saying, no, I don't want that.  And so that was, while burdensome, we did have control.  So this will - we will lose that.  It'll end up being monolithic.  You either stay current, or you choose not to.



On balance, I think it's probably a good thing.  And just from a pure technology standpoint, when I've dug into individual updates' contents, and I look at all the various DLLs and .sys files that they make tiny tweaks to, and then you imagine all of that overlapping, and all of that overlapping all the way back through time to the beginning, I have no idea how they ever made any of this work.  It's like, I mean, how can you say I don't want the 3035583 update, yet other things I do want later?  Yet the functionality that that update brought somehow isn't put in by anything that happens afterwards.  I have no idea how that happens.  It just - it's amazing to me.



So this probably represents a huge improvement.  I think it probably improves the stability of these systems going forward, again, at the expense of some control from control freaks who like to be able to say, I don't think I want that one.  So, still, I think that's progress.  And the other nice piece of news is that - we all know that I frantically built my - I can't think of the name, the Intel chipset with an H, Haswell.  I built my Haswell-based Windows 7 machine immediately upon learning that Microsoft was not going to be supporting Windows 7 and 8.1 on the Skylake chipsets.  And so it's like, oh, shoot, I need to protect myself from that.  Well, then of course we've covered the news that they changed their mind.



Well, they have just changed their mind again, relative to security patches.  It was going to be, they originally said in January of this year, that the Skylake-based PCs would not be getting security patches for non-Windows 10 platforms after the summer of 2017, so a year from now.  Then they got some pushback, putting it mildly.  So they changed it to 2018, the summer of 2018.  Still pushback on that.  So they finally said, okay, fine, we will support Skylake through the natural end of support for the platforms.  So that's, of course, January 2020 for Windows 7 and 2023 for Windows 8.1.  So anyway, anybody who is installing Windows 7 and 8.1 on newer hardware will have it supported, thanks to this change in policy all the way through the end of life of updates.  So that's good news.



Okay.  This is just the coolest hack.  As a developer myself who is often needing to look at packet traffic, I have to infer the contents of TLS connections which Wireshark captures for me and displays.  I can see IPs and ports.  I can see where things are going.  I can see the initial identified handshaking packets.  But I can't see any contents.  And contents is often valuable.  In the old days, I would simply, for example, if I was working with GRC's servers, I would use HTTP so that, even if we would normally use HTTPS, I'd just use HTTP for testing because I could see into it.



That's all gone because it's no longer safe, as we were just saying, to use HTTP.  And all of the browsers now know that GRC is always secure because we have the HSTS headers, the HTTP Strict Transport Security, which informs browsers to autonomously change any non-secure to a secure connection.  So HTTP is silently promoted to HTTPS.  The server sends that header with every reply to train every browser that touches GRC, and of course many other sites, too, that are now supporting HSTS, that secure is the only way we want to connect.  That means, though, that I'm no longer able to see, for diagnostic and development purposes, what's going on.



Turns out there is a way, and I didn't write down the person who tweeted the link to me.  But I have in the show notes the link to the write-up, a detailed write-up of the way to decrypt TLS browser traffic with Wireshark.  It turns out that developers can place an environment variable in their system, SSLKEYLOGFILE.  So you set the SSL key log file to a specific filename.  And Firefox and Chrome, only those two, but who needs anything else, will honor that environment variable.  And here's the key.  Every TLS connection the browser establishes, it logs the cryptographic keys for the connection.



So again, we've covered this extensively in the past, where the way TLS happens and the way the negotiation occurs with the server providing some information, the client providing its random information, and a pre-master secret and then the master secret.  If you had that information, you could then take an encrypted stream and decrypt it.  Basically, that's the information the endpoints each have that allows them to encrypt and decrypt the communications for their own purposes.  And Wireshark knows how to read that file.



So what this allows you to do is capture traffic with Wireshark with this environment variable in place, and then use the keys that were captured, and Wireshark is now smart enough to decrypt it and allow you to see the plaintext inside.  There was some - this was sort of fascinating, some back-and-forth with this most recent release of Firefox.  We're at Firefox 48.  They almost took it out because there was concern that there was some - that logging the cryptographic keys to a file was a security vulnerability.



The argument, which I concurred with, was wait a minute.  Yes, you're exporting it from the browser.  But if there's somebody - if your system is already compromised to the level required to leverage that, then all bets are off anyway because there are, you know, you can just simply drop a filter into the TCP stack.  There's, at least in Windows, I'm very familiar with the layers of that.  And there are all kinds of - remember LSPs, Layered Service Providers, Leo?  We used to have a problem with those.



LEO:  Don't remember that.



STEVE:  That kind of went away.  But it still exists.  So it's easy to stick shims in and intercept traffic.  It's just sort of a mess, but you could do it.  And so that argument won out.  And Firefox, they did not move it to a compile time definition, a def that you would have had to set to build your own custom Firefox that had that capability.  They left it in the main production release.  So anyway, just a very cool hack.  Again, I've got the links in the show notes for anyone who's interested.



And I should mention that the link farm page, for anyone who hasn't looked, it's where I'm continuing to put things:  GRC.com/linkfarm.  And it's growing.  I've got a bunch of static things and a list of the puzzles and toys that this community has been exposed to and loves.  And then based on various podcast numbering, I pull a bunch of relevant links out for each podcast.  So don't forget to check GRC.com/linkfarm.  And the show notes also have specific links to this.



Also I wanted to point out that we've been talking about the Ubiquiti EdgeRouter, and before that the Cisco SG300, and also pfSense.  PC Perspective dotcom, PCPer.com, P-C-P-E-R dotcom, put together a very nice write-up with very nice diagrams explaining all of the evolution of the three-router network isolation approach, the so-called Three Dumb Routers solution.  And even the comments after that posting were useful.  So I've got a link also in the show notes, and also in the link farm, on the link farm page, because I think for some people that makes sense.  That is, you may not want to get all into the sophistication required to set up individual subnetworks on interfaces on something like the Ubiquiti EdgeRouter X, or deal with a system with multiple interfaces running pfSense.  You just want the solution.  Or you may have a few old and retired blue box consumer-grade routers sitting in a closet, where you can just plug them together and get the equivalent strength.



So I really appreciated the write-up.  And I also note that we need the same thing for the Ubiquiti EdgeRouter X and for pfSense.  So if anyone is interested in detailing their IOT network segregation solutions, write it up and bring it to my attention, and I will share it with our community because I know that people here would appreciate a bit of a how-to guide.



LEO:  And that PC Perspective piece was probably written by Allyn Malventano; right? 



STEVE:  Isn't he Perspectives Plural?



LEO:  No, no, that's him, PC Perspective.  And it's PCPer, they host This Week in Computer - Brian Shrout, the publisher and editor-in-chief, hosts our This Week in Computer Hardware.



STEVE:  Yes,  It wasn't written by Allyn.  It was written by somebody else there because I did look [crosstalk].



LEO:  Okay.  You and Allyn had corresponded, I know, over that.



STEVE:  Yeah.



LEO:  Okay.  Yeah, that's the same site.



STEVE:  Cool.  Anyway, very nice piece of work.



LEO:  Good, good, good, good.



STEVE:  So it turns out we talked last week about this very worrisome Windows SMB - the so-called Server Message Block - credential leakage, which allows, if you are using a Microsoft browser, IE or Edge, allows a malicious party to put an SMB Windows filesharing-style resource on a browser page.  Or I forgot to mention also Outlook.  You can receive - that's also supported there.  So if they send you email that has a blob, and you're using Outlook to open it, it will do the same thing.  These Microsoft clients will initiate an outbound connection across the Internet,, and part of that is your username and the hash of your password.  So if that's not - if the password is not super strong, I mean, and I mean super strong, then that can be a problem.



And of course LAN Manager passwords, as they're called, have notoriously been weak, sort of fundamentally weak.  And ages ago we dealt with lots of problems with those.  And this is a concern because people are now using their Windows credentials to log onto Microsoft properties, so it's not just your own machine that you'd be logging onto.  I think this is why Microsoft didn't worry about this traditionally is that there wasn't really anything somebody remotely could do.  Now there is.



The point is that I got a tweet from someone, Donn Edwards, who noted that he'd been playing around with this mitigation, and it has got showstopping side effects.  His tweet said:  "Hi Steve.  The 'fix' [in quotes] for IE usernames mentioned here" - and he refers to the BleepingComputer.com page that I referred to last week - "causes more problems than it solves."  And there's a registry setting change which I referred to last week, "RestrictSendingNTLM" - that's NT LAN Manager - "Traffic," and you set that to two.



And he says:  "This effectively isolates the PC on the LAN" - so not even the WAN, but the LAN - "so that it cannot see or connect to any other PC or fileshare on the LAN."  Yeah, that would be a deal-breaker for me because my Drobo would go offline and become inaccessible.  "You have to enable connecting with every other PC or server as an exception" to that policy.  He says:  "It also interferes with Remote Desktop connections.  So even if you connect with Remote Desktop and use saved credentials, you still have to input the credentials again.  Please could you alert users to this issue, since the article itself is not particularly clear or explicit.  Keep up the good Security Now! work."



Okay.  So I wanted, yes, to let everybody know, but also to note that, first of all, if your ISP is blocking access to those ports, certainly Cox does, and a lot of ISPs do because of the traditional problems with Windows.  On the other hand, I would argue that those have largely been solved with firewalls which are now running since XP SP2.  Or was it SP3?  It's been a while.  I forgot.  Might have been 3.  Oh, no, SP2.  Yes, because I just recently upgraded to SP3.



LEO:  Oh, yes, I see.



STEVE:  Ah, yes.  In order to get SHA-256 signature awareness.  So, yes, SP2 with XP brought the firewall on by default.  Of course everybody's now behind a router, which is providing protection.  So the fact that the problem no longer exists means ISPs could be forgiven for dropping those port filters.  The right solution is for us to filter them.  And so this is another perfect application for a smarter router.  That is, if you were using the Ubiquiti EdgeRouter or pfSense, you could absolutely firmly block ports 137 through 139 and 445.  That range of three, 137 to 139 - so 137, 138, 139 - and 445, those are the ones where all of this server message block NT LANMAN stuff happens.  If those are blocked at your own interface between your network and the Internet, then you're protected, and all of your goodies inside can function, and any query that any Microsoft browser or client in your network attempts to make, it'll absolutely fail at the border.  So, and then if you had some need for specific outreach, you could permit that.



And so digging into this a little bit more, that led me to an interesting page because I was kind of curious about where pfSense stood with this.  And of course Universal Plug and Play is a constant concern from a security standpoint.  So I got a kick out of what they said.  They said - this is the documentation for pfSense at pfSense.org - "UPnP is short for Universal Plug and Play and is commonly found on Windows, BSD, and Linux systems.  NATPMP is short for NAT Port Mapping Protocol and is similar to Universal Plug and Play, but found more commonly on Apple devices and programs.  A growing number of programs support both methods.  pfSense supports both, and the service may be configured at Services > UPnP & NATPMP."  So that's all available for pfSense users.



"UPnP and NATPMP both allow devices and programs that support them to automatically add dynamic port forwards and firewall entries.  The most common uses are in gaming systems (Xbox, PlayStation, et cetera) and BitTorrent programs like uTorrent, which both rely on allowing inbound connections to a local service."



And then they have a bar and warning flashing.  And they said:  "WARNING!  Potential Security Risk!  If UPnP or NATPMP are enabled, use only devices and programs which are trusted.  These mechanisms will allow these entities to bypass the firewall to allow incoming connections with no additional control or authorization."  And I love it, they said:  "Do not be surprised when this happens.  Access permissions for the service may be crafted in the options on pfSense.  The format of these is shown in the GUI at Services [and again] UPnP & NATPMP in the user-specified permissions boxes.  Using these, access could be restricted to a specific workstation or device."



And so that's an advantage, an example of the kind of power that one of these more capable routers gives you is you could enable UPnP specifically for your Xbox, just because you want to do it that way, that is, use UPnP and have it configure the network itself, but still have it not generally available.  And in this world of Internet of Things, this is something I'll be very surprised if the IoT devices aren't just saying, oh, I'm going to open myself a port so that China can access the light bulb whenever it wants to.  It's like, okay.  Bad idea.



And one last link here.  There was specific information about UPnP with the Xbox, and I've got a link in the show notes which, for people who don't want to use Universal Plug and Play, but want to statically map some ports, that provides some guidance for doing that with pfSense.



And finally, before we get into a little bit of miscellany, yet another way of exfiltrating data from a computer.  Yes, the hard drive's head movement sounds.  It turns out that the same guys we covered a couple months ago, who were extracting data through a wall, remember they had like an antenna on one side of a wall and a laptop sitting on a table on the other side.  And they were able to get the data.  They were able to extract a key in use from that machine.  It turns out that we now have DiskFiltration, which of course is hard drive information exfiltration.  They call it that because it uses acoustic signals which are emitted from the hard drive, which is also known as sound to non-geeks.



LEO:  Acoustic signals, yes.



STEVE:  Yes, an acoustic signal...



LEO:  That's what we've been doing [crosstalk].



STEVE:  ...from the hard drive.  Make sure I heard - I'm sure I heard something.  And so what they're doing is they've got software in the machine which is manipulating the hard drive head actuator to generate sounds that can transfer passwords, cryptographic keys, and other sensitive data stored on the computer to a nearby microphone.  So in practical terms, it's worked at six feet distant to a phone sitting on the desk.  They were able to achieve 180 bits per minute, which, yes, you're not going to be sending any large texts or exfiltrating a database.  But that's generally not necessary these days because we've become increasingly dependent upon encryption.  And all you need is the key.  And 128 bits per minute would allow you to exfiltrate a very strong 4,096-bit key in about 25 minutes.



So again, not super practical.  But you could imagine a situation where, in a super secure environment, if there were some way to infect a computer that was believed to be safe because it was air-gapped, no WiFi, no network connection, it's sitting there, and only it knows what it has, if there were some advantage to be gained from surreptitiously obtaining 4K bits of data - and again, these days 4K can be enough.  If it's a cryptographic key whose secrecy absolutely must be protected, this potentially allows you to break that wide open.  So just, what have we got?  We've got fan noise.  We've got of course the speaker.  We've got the hard drive.  Basically anything that you can do on a computer to in any way affect the environment, through any means, can be used to send data.  Really not a big surprise.  But it's sort of fun to see this stuff applied in practice.



Now, okay.  I have in the show notes a picture of this thing, which is the most beautiful piece of engineering I've seen in a long while.  It is a Kickstarter that someone pointed me to.  And unfortunately, it was instantly sold out because of its popularity and the fact that they're just unable to mass produce them.  It's a five-page wooden book where each page is an intricate, beautiful wooden puzzle.  And you have to solve each page successively in order to open that page of the book, to unlock that page to get to the next page of the book.



And anyway, it's just - I just wanted to show it to people, just for - I know we have a large following of puzzle lovers.  None of us can get it, unfortunately, because every single version, the build-it-yourself, the buy a bag of toothpicks and make one yourself, every one of the Kickstarter variants is completely sold out.  And I would have immediately grabbed one because they  just look beautiful.  And in their notes they note that, if it weren't for laser cutting, this would never be possible.



LEO:  Oh, yeah.  Can you imagine?



STEVE:  But it's the reproducibility.  And it's just - it's beautifully, I mean, beautiful wood, it's just a wonderful-looking thing.  So for what it's worth, all we can do is lust after it.



Turns out the mysterious ARP generator which was CUJO'ing my system, actually two of my three machines at Level 3, was the Intelligent Platform Management Interface.



LEO:  Of course it was.



STEVE:  Of course.  Unbelievable.  This is that baseband processor that we talked about a few months back.  I think actually it was the week that you were in Newport Beach, Leo, and I discussed it with Father Robert, but then we talked about it the following week, as well, essentially the backdoor that exists in all of these machines.  And fortunately, those servers, they're beautiful Intel 2U servers with six hot-pluggable drives each, and dual Xeons and dual redundant power supplies, I mean, it's a beautiful box, and I have three of them.  They have dual NICs.  And this is the takeaway.  Only the primary NIC is hooked up to the platform management.  I verified there is no way to shut it down.  Nothing in the BIOS lets me do it.



Those are all running FreeBSD.  FreeBSD has an IPMI driver and something called IPMI Tool.  So I was able to dynamically load the kernel driver and then use IPMI Tool to probe the IPMI, look at the status, see the fan spinning, you know, all the kind of things that this technology allows you to do in terms of managing the underlying hardware.  And then I got a clue because there was an option to use a secondary NIC as a failover from the primary.  But there was no option to use the secondary instead.  And I thought, oh.  I wonder if that means that it's not being hooked by this.  So I went into RC config and changed the interface to the secondary one, moved the plug, and all is quiet.  Problem is solved.  It was just that one NIC of the two.  So that's another tip.



There was a lot of dialogue after we were talking about this, about just plugging in a third-party interface, which you can certainly do, into the motherboard if you wanted a network connection that would not be risking having this platform management as a potential backdoor if there were any vulnerabilities found in it.  And we know how difficult it is to make this stuff perfect.  But if your motherboard has multiple NICs natively, it may just be as easy as switching to the secondary or tertiary and so forth.  The newer servers I have have five NICs.



LEO:  Wow, wow.



STEVE:  So I don't know why.



LEO:  All my new computers have dual NICs on the motherboard.  It's interesting, yeah.



STEVE:  Yeah.  So, and it's weird because one of them, the one that's running the oldest version of Free - oh, I verified it wasn't FreeBSD.  I stopped it at the little devil screen before BSD was running, before it had booted, before it had loaded the kernel, before the network was up.  And sure enough, that ARP noise was occurring there, and it was stealing from another IP in the system for itself, even without FreeBSD running.  And so I thought, okay, well, it's not the OS.  Which is nice because I didn't want it to be the OS, although it would have been fixable if it were.  But I don't need two interfaces there, and now I'm only going to use the secondary one.



I got an interesting tweet that I thought I would pose as a puzzle for our clever listeners.  Jimmy G., tweeting as @TheRedTech, he sent actually a tweet both to @Naked Security and @SGgrc.  He said:  "I just bought a USB" - and he means a thumb drive - "from a friend, but he's a hacker of sorts.  How would you safely format it, in case of a joke or worse?"  And so I thought about that.  I mean, because that could be deadly.



LEO:  There's always BadUSB, too; right?  I mean, he could have firmware stuff on there.



STEVE:  Yeah.  So a Chromebook could probably do it safely, and Chromebooks will format USB thumb drives natively.  They don't need anything added to them.  And you could then power wash the Chromebook to, like, flush it from anything that might happen.



LEO: Just in case, right, right.



STEVE:  Yeah.  And I would think that Unix would probably be a safe choice since it doesn't have any of that autorun nonsense that mainstream OSes have.



LEO:  You can format it without mounting it on a Linux system using DD, which is just...



STEVE:  Ah, that's exactly right.



LEO:  Yeah, or your format.  But you still wouldn't fix, if there's a firmware bug, I mean, if the guy's a mean hacker and put BadUSB on it...



STEVE:  Yeah, but it wouldn't be able to do anything.  It would...



LEO:  Well, yeah, but you couldn't use it anywhere else.  You'd format it...



STEVE:  Oh, I see what you mean.  Ah, very good point.



LEO:  Doesn't make it clean.



STEVE:  Very good point.  That's very true, Leo, because it is a little computer, as we know, that could get up to some mischief, yeah.



LEO: Right, yeah.  To fix that I guess you'd need a EPROM program or something. 



STEVE:  And I also ran across, just, again, miscellany, an excellent USB explainer.  You were just talking about USB on MacBreak Weekly.  And of course we know you're a fan of the Type C connector.



LEO:  Love it. 



STEVE:  LogicSupply.com is a nice site that actually is one of Mark Thompson's favorite sources of well-built, sort of above-consumer-grade, industrial-grade PC hardware of various sorts.  They did a really nice explainer for the USB standard, taking us from USB 1 all the way through, not only 3.0, but 3.1, first and second generation.  And talk about the differences in the physical connectors, the power delivery capabilities.  I didn't realize that USB 3 could go 20 volts, which allows it to deliver as much as 100 watts of power.  So that's substantial.  And also the various data rates and so forth.



So again, link in the show notes, and I think on the link farm page.  I think I put a copy of the link there for anyone who just wants to sort of just, if you haven't had a chance to focus on that, and you're interested, it's a bunch of good stuff.  And then finally a tweet from John Adams.  I was interested because his Twitter handle was @netik.  And that's sort of a good Twitter handle.  Turns out he's one of the early Twitter employees.  And in a short bio he said, "I helped build this thing."



LEO:  Wow. 



STEVE:  Anyway, someone retweeted a tweet of his that I got a kick out of, and I knew our listeners would appreciate.  He said - and my point is he's got some cred.  He said:  "There is no Internet of Things.  There are only many unpatched, vulnerable, small computers on the Internet."



LEO:  Yeah, that'll give you chills.



STEVE:  And that's exactly, I mean, that's really what it is.  It's just like, we're in a wild wilderness at this point.  And I got a nice note from a young student, David L. in Omaha, Nebraska.  The subject was "SpinRite saved me once again - and our high school yearbook."  I guess he's getting an early start on the yearbook.  Or maybe it's photos from the summer or something.



He said:  "Hello, Steve.  I'm a high school student who really enjoys listening to you and Leo on Security Now! every" - well, he wrote Wednesday.  Oh, I guess he listens on Wednesday because we record on Tuesday.



LEO:  Yeah, yeah, that's when he gets it.



STEVE:  He said:  "Love the depth you go into in your topics.  Anyway, I was working on a paper due the next day on my desktop, and everything on my computer had been running very smoothly, as if nothing was wrong.  I noticed that some updates were waiting for me to install.  I didn't have time to install them right away" - probably because he was working on that paper - "so I decided that I would let them install when I head off to school.  The next morning it boots up just fine, but when I come home" - or he says:  "In the morning it boots up just fine.  But when I come home, I'm greeted by a screen that read 'No active partition found.'"  Ooh.



"Normally," he says, "I need to confirm to restart the computer, as it was sitting on the Windows Update screen when I left.  I began to panic, as most of my schoolwork had resided on that computer, along with some photos that I needed to copy to a flash drive for the high school yearbook.  Trying to figure out what to do, I was googling the error message.  It turns out that others have fixed it through the Windows 7 install DVD.  I didn't want to do that as I was afraid it might corrupt the drive even more.  So I ran SpinRite.  I selected my drive and ran it on Level 2.  I let it run.  About an hour or two later, I was greeted that SpinRite found no errors.  I was prepared for the worst then, as I did not back up this computer," he said, parens, "(even though I should) as we do not have the best Internet speed."  He's in Omaha, Nebraska.



Anyway, "I was afraid I was going to lose everything and let our yearbook staff down.  I rebooted the computer, only to find it prompting me to select 'Last Known Good Configuration or Profile 1.'  I selected Profile 1, and the computer started right up into Windows.  I am in the process of backing up my data to a safe place and giving the important photos to our yearbook staff like nothing ever happened.  Thank you, Steve, for your amazing work. David L., Omaha, Nebraska."  And, David, thank you for sharing your experience.



And for what it's worth, this is one of those ounce of prevention issues.  It's difficult to sell something that no one needs.  But the other thing I routinely hear is from people who listen to the podcast, who purchased SpinRite and use it preventatively, you know, for preventative maintenance, just running it on their system to prevent it from getting to a point where it's in real trouble.  And one thing I've never mentioned in all the time I've been talking about SpinRite, believe it or not, is that there's absolutely no need to run it in that mode all at once.



One of the things that I added in SpinRite 6 is a percentage complete that is accurate to four decimal places.  And I did that specifically so that it would be, no matter how big the drive, it would be sufficiently sensitive to represent where it was.  So, for example, if you have a drive that's so large that SpinRite's going to take a long time to run, and it's just inconvenient, it's completely feasible to start it at the beginning at the end of the day, let it run overnight or until you need it.  Then you just hit Escape, and up pops a screen saying, like, "Pausing SpinRite," and showing you, it'll say SpinRite is 37.39246 percent in.  You make a note of that and terminate SpinRite and then use your computer for the day.  And then you are completely able to pick up exactly where you left off.



And that's one of the options when you're starting is by default it starts at the beginning, but you can also enter the exact percentage where you want to begin.  So you'd put right back in 37 point whatever I said, and whatever you wrote down.  And you know me, I'm a perfectionist, so I always - I round forward when I'm reporting where we are, and I round backward when you're restarting, so that you're always guaranteed of an overlap between where you ended and where you restart, no matter what happens with the math.  So you're absolutely guaranteed, then, to start from where you were and be moving forward.  And you could run SpinRite over the course of as many individual sessions as you want it to in order to get the whole job done.  And doing that gives you full SpinRite preventative maintenance protection.



So in all this time I had never mentioned the fact that it doesn't have to be all done at once because there is a very nice suspend and resume capability built into it.



LEO:  If you don't mind, let's take a break for one last commercial before we get into memory and micro kernels.



STEVE:  Yes.



LEO:  Some topics that we brought up Sunday on TWiT.



STEVE:  That's what triggered both of them.



LEO:  Steve wants to weigh in.  You know you could always just call.  I can put you on any time.  But it's nice.  Do it on your show.  Yeah, it's nice.  All right, Steve.



STEVE:  Okay.  So there is a new memory technology on the horizon. 



LEO:  Yes.



STEVE:  And it is a true breakthrough.



LEO:  Allyn Malventano had just come back from the FMS, the Flash Memory Summit, I guess it was, and was talking about this.



STEVE:  Right.



LEO:  Yeah.



STEVE:  And this is not flash memory.  This is something different.  This is the result of years of work from a joint venture between Intel and Micron, working on this technology together.



LEO:  Both known for their solid-state drives, by the way, and flash memory.



STEVE:  Yes.



LEO:  Yeah.



STEVE:  Yes.  This blows flash away.  I mean, completely.  It is one thousand times faster than flash memory, than so-called NAND, as it's called.  It's got a thousand times more endurance, so it doesn't have that - we've talked about the fatigue problem with NAND often because essentially we're stranding electrons on a little island floating with an insulator underneath it.  And the way you write is you create enough of a electrostatic field that you overcome the insulation and drive the electrons, you tunnel the electrons through the insulator.



The problem is that fatigues the actual physical properties of the insulator.  That's why writing is hard on flash memory.  That's why writing causes damage - tiny, incremental, but still something, for example, that hard drives don't suffer from.  This, no sign of that kind of an endurance problem.  And it is 10 times the density of dynamic RAM, of DRAM.  And I have a picture here in the show notes that's called 3D XPoint Technology.  And it's almost impossible to imagine a more simple solution.



In static RAM, static ram is so-called SRAM.  That's like the registers in a processor.  And essentially static RAM are cross-coupled inverters, inverters that are coupled to each other.  And if you think about it, we've talked about this in the past.  If you pull an input low, the output of that inverter will be high.  And that goes into the input of the second inverter.  That'll mean its output is low.  So that continues to put a low into the input of the first one.  So two inverters connected to each other are stable.  And if you yank one of those lines in the other direction briefly, it'll flip.  And that's why it's called a flip-flop.



And the problem is that requires a bunch of transistors.  And transistors take up space.  And they also take up energy.  And they produce heat.  So, and by "a bunch," it's like six or so transistors.  The advantage is it's super fast.  The problems are it's volatile, that is, it's only the fact that you keep those inverters powered up that has them knowing what way they were last set, that is, their memory is a function of this dynamic process.  So that's why static RAM is volatile.  Dynamic RAM was a major innovation where all of that complexity was reduced to one transistor and a capacitor.  And there the concept is you store the state in the charge of the capacitor.  And the downside is the capacitors have to be itty-bitty in order to get a lot of them in a small space.



Well, itty-bitty capacitors tend to leak and can't store much charge.  That means you need to read them periodically, before they've had a chance to discharge, in order to top them up again.  And that's what refreshing is.  Dynamic RAM, DRAM, needs to be constantly refreshed, meaning that there's a highest priority of all down in the hardware which is going through the entire DRAM of the system, reading it and then rewriting, basically checking the fill state of every one of the little capacitors, and topping it off before it has a chance to discharge down into the - enough that you can't tell whether it was a one or a zero.  So, again, one transistor, one capacitor, much smaller because it's so few components.  But with it comes the obligation of needing to refresh it.  And of course it's also volatile.



Now we come to this so-called 3D XPoint technology.  It uses essentially a phase-change technology.  HP and SanDisk partnered up on something called memristors years ago.  And it looks like that effort is failing.  It doesn't look like that's going to happen.  This one is similar.  It is happening.  Here, imagine a horizontal set of conductors, and you put little dots of stuff on these conductors horizontally.  And then you lay on top of it a vertical grid of conductors such that you've got the horizontal array of conductors intersecting with the vertical array of conductors in XPoint, thus the name.



And at every intersection, what separates those is this physical substance.  And what they have found a way to do is to run a current through this special substance which changes its resistance property permanently.  So you send a pulse of current through it in one direction, and its resistance drops.  You send a pulse of current in the other direction, and its resistance rises.  And it's known as a bulk change, that is, the whole thing changes property.  So it is very stable.  So it is nonvolatile.  And, as you can imagine, all it is is a grid, an overlapping grid of conductors.



And you can see why it's called 3D, because I just showed one layer, but then you put dots on top of that one and put a grid in the other, perpendicular to the grid, and dots on top of that, and another set of connectors perpendicular to it, and you can stack these things up so your efficiency goes up very high.  What you end up with is - and it's just, it's hard to get your mind - it's hard for us to get our mind around this and what it means because it's such a change from the way we're used to thinking.



We have always been thinking in terms of bulk storage, mass storage being blocks, or being sequential.  Or being slow access.  The idea being that the registers in the processor are static RAM, superfast.  The L1, L2, and L3 caches are superfast memory.  Then we go outside the motherboard to DRAM, which is much larger, but much slower.  Which is why we have a hierarchy of increasingly fast, but also smaller caches.  And then connected to this whole system is comparatively much slower memory.  Fast as it is, hard drives or SSDs, it's still dramatically slower.  And we're used to thinking in terms of fetching a block.  You know, go ask for this sector, or read this block of sector into memory, transfer it into memory, and only then can we use it.



What's mind-blowing about this technology is that it is random access, high density, and nonvolatile.  I mean, it's like core.  It's like the return of core memory, where we started in the early days, where you could turn the computer off - I did this when I was 14.  You turned the computer off, and then you come back in the morning, you turn it on, and it's still there.  I mean, it doesn't have to boot.  It doesn't have to do anything.  It's just - because the memory itself was nonvolatile.



So their first chip, and they're thinking later this year, I mean, it's working.  I have some links in the show notes for anyone who wants to see.  There are a couple of very nice YouTube videos and a lengthy 45-minute Intel, joint Intel-Micron presentation that I watched a couple years ago, whenever it was that it happened, because I was fascinated by this.  And this is actually - this is not blue sky.  This is not, oh, yeah, like supercapacitors, let's hope someday that they figure out how to do it.  This year, they're saying 2016, and we don't have a lot of months left in 2016, we're going to get this.



Their first delivered product is a 128Gb die which is 16GB on a chip.  So it's 16GB of mind-blowing, random access, nonvolatile memory.  I mean, and again, we're so used to the concept of essentially storage being sort of semi-offline.  I mean, you just can't randomly address it.  Now for the first time I'm glad for 64 bits.  Until now it's like, eh, who needs 64 bits; 32 is fine.  Except it's a little bit like the Internet, okay, 32 turned out not to be enough bits for the Internet.  With 64 bits, imagine that you just - all of the mass storage, all of the memory in the system is just there.  And you can access any byte of it that you want to like it was DRAM, except 10 times faster than DRAM and nonvolatile.  So also it is your storage.  It's just, it's weird to, like, to think...



LEO:  Wait a minute.  It's faster than DRAM?  I thought it was faster than NAND but slower than DRAM.



STEVE:  I'm sorry, 10 times more dense than DRAM, you're right, you're right.



LEO:  And faster than NAND memory.



STEVE:  Right.



LEO:  Like a thousand times faster than NAND.  But it's not quite as fast as DRAM. 



STEVE:  Correct.



LEO:  Yeah.  But, I mean, Allyn hypothesized machines that didn't even have DRAM, that this would, you know, you could live with slower DRAM if you didn't have to transfer stuff from storage into RAM.



STEVE:  Correct.  It changes, I mean, what's so weird is that we are just so used to thinking about there being a delay and needing to, like, go access something in a block.  Here it's like 21st-century core.  It's just you can access any of it that you want to.  And it's fast and nonvolatile and just goes.



LEO:  So you imagine machines that, you know, you no longer say, "I have 8GB of RAM."  You just say, "I have 20TB of..."



STEVE:  Of storage.



LEO:  "...of XPoint storage."  And it's all available, and at near RAM speeds.  Wow.



STEVE:  Even an iPad, you know, there we see a single device where we know it's got flash memory and RAM.  But that division dissolves in this case.  So it's just, to me, it's just so cool.  Over time we've developed abstractions for the way we access memory.  Back, I mean, a long time ago, I mean, memory was a challenge in the early days of computing.  There were actually data and programs stored acoustically in a mercury delay line because it took time for acoustic waves to propagate through a tube full of mercury.  So there were transducers at each end and an amplifier, and this thing would recirculate.  And the pattern of acoustic waves moving through this column of mercury was the storage.  I mean, that's how clever people were becoming.



And then of course there was drum memory, where you had a spinning drum, and it was kind of random access.  But it turns out that there was an art to writing programs that were inherently synchronized with the rotation of the drum so that, when the program needed to fetch its next instruction, that had been placed on the drum the proper distance upstream for how long the previous instruction took to execute so that it would be there, available to be read in.  I mean, you think about the pioneers of computing and what they went through with the tools they had at the time.



And then of course all the sci-fi movies showing the spinning mag tape, where magnetic tape was the way you did bulk storage.  Think about the challenge of sorting files on mag type.  An incredible thousands of hours of programmer time went into designing algorithms to, efficiently as possible, sort and extract data from multiple mag tapes.  You'd have scratch tapes and sort of mount them on machines and then run a deck of cards through the card reader in order to load that up into core.  And then that would run a program that would do your data processing, if you were a big insurance company, where all of your customer records were on mag tape, where you can barely get to them.  But somehow they made this work.



And so of course we've moved slowly forward with storage getting much faster and much less expensive, but always fundamentally remaining kind of inaccessible, block accessible, where you would address a block.  And this represents such a big change in thinking that it's just sort of hard to get your mind around.  So I just, to Intel, I say, and Micron, bravo.  I don't think we can guess yet where this is going to go.  I imagine it'll be very expensive in the beginning.  I don't think it's going to threaten hard drives just in terms of cost per bit.



But again, if we've seen anything, it's that these are exponential curves.  And I think there's no doubt that a decade from now this will have replaced SSDs easily, well, probably sooner than that, I think, given the pressure for, especially in enterprise and big cloud storage facilities, to access data more quickly.  It's just fabulous.  And I'm done.



LEO:  You don't want to do micro kernels?  



STEVE:  Let's talk about it next week.



LEO:  Yeah.  Okay, good, yeah.  We're out of time, so that's fair enough.  I'm excited about this memory thing.  This is the kind of breakthrough technology that doesn't happen every [crosstalk].



STEVE:  And it's just, it's elegant.  It's just elegant.  I mean, you look at it, it's like, okay.  How do we simplify this?  You can't.  It's just, you know, it's intersecting addressing lines in a little blob of goo that somehow remembers...



LEO:  They're resistors.



STEVE:  ...the last pulse it received.



LEO:  They're resistors; right?



STEVE:  Yeah.



LEO:  That's what's kind of interesting to me, yeah.  Fascinating.



STEVE:  Yeah.  They're resistors whose resistance can be changed.



LEO:  Variable, yeah.



STEVE:  Yes, based on the history of the current that flowed through it.



LEO:  It's awesome.



STEVE:  It's just so cool.  It's just, it's like, you know, that's why I sort of painted the picture of static RAM with complexity.  Dynamic RAM, way simpler.  And now this, this is it.  This is just cut to the bone.



LEO:  I guess you'd still have some sort of high-speed cache RAM lying around.



STEVE:  Yes, yes.



LEO:  To keep the pipeline full.



STEVE:  I think you still need that.  Even with DRAM, although DRAM has its limitations because it wants to be read out.  I mean, this, well, I was going to say, the organization, the physical organization of DRAM requires some constraints.  The reason, you know, DRAM has a natural size at which it can be read, and it's called a cache line.  And so a line is read into the Level 3 cache.  And then the DRAM typically needs to get refreshed.  Because in order to read it, you need to transfer the charge of that line into a buffer.  And once you've done that, you've discharged that line, so you need to rewrite that line.



So there is overhead associated with DRAM that we just don't have with this technology.  This is just, I mean, the only thing I can imagine is some other sort of like holographic crystal, where we're able to zap it with lasers to, like, flip molecules around inside.  That's, again, and probably a slower access mass storage.  I think this is going to be sitting here as the king of high-speed, nonvolatile storage for quite a while.



LEO:  Well, you told us about ZIP disks.  You told us about flash memory.  Now you're telling us about Optane.  Optane.



STEVE:  Nice.



LEO:  Steve Gibson.  This is the show to listen to if you want to keep up on what is going on for real in the world because this is our most sophisticated show, I think.  You've got to tune in every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  Or Wednesday on demand, after the fact.  We'll get the show out in a couple of hours.  Steve also a little later will get written transcripts of the show.  He's going to have an audio version and the transcripts at his site, GRC.com slash, well, whatever.  Just go to GRC.com.  It's in the menu.  He'll also have show notes there.  He always does, so if you want links and so forth.



We have the audio and the video at our site, TWiT.tv/sn.  And you can also subscribe, and that way you won't miss an episode, you know, whatever podcatcher you prefer.  While you're at GRC.com, though, consider making a yabba dabba doo sound in Steve's lair by buying a copy of SpinRite, world's best hard drive maintenance and recovery utility.



STEVE:  And you don't have to run it all at once.  You can run it over the course of as many little sessions as you want.



LEO:  Once in a while.  A little bit at a time.



STEVE:  Yup.



LEO:  You can also find out more about SQRL, the Healthy Sleep Formula, and all of that.  It's all at GRC.com.  Steve, we'll see you next week.  This is our last episode in this studio, by the way.



STEVE:  Yay.  And we're going to see what you come up with for your studio next week.



LEO:  Well, eventually it's going to look exactly the same.



STEVE:  But probably not by next week.



LEO:  Not by next week.  Next week we'll be sitting at the roundtable, in all likelihood.  But the week following, I'm guessing it'll only take a couple of weeks to get this recreated.



STEVE:  I think it'll be good.



LEO:  And you won't notice the difference except I won't be alternatively freezing and sweltering.



STEVE:  Are you guys going to take photos of your current setup so everything can be placed in the same location?



LEO:  Oh, that's a good question.  Where does everything go?  You know, it's a shame we don't have any video of what it looks like or...



STEVE:  Yeah, no record.



LEO:  No record of how it's changed over the years.  We tried when we built this to make it look like The Cottage.  And I think we came pretty close.  But this time we're taking everything with us.  There's nothing to build.  We're going to keep all of this, including my desk and everything.  So it shouldn't change at all.



STEVE:  Cool.



LEO:  I think we'll have a better monitor for you.  Don't have to adjust it every time.  Thanks, Steve.  We'll see you next week in the new studio, in the Eastside Studio, for Security Now!.



STEVE:  Thanks, Leo.  



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#574

DATE:		August 23, 2016

TITLE:		Routers & Micro Kernels

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-574.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, Leo and I catch up with the past week's news.  Did the Shadow Brokers hack the NSA's Equation Group?  Apple's Bug Bounty gets quickly outbid.  A critical flaw is discovered in the RNG of GnuPG.  The EFF weighs in on Windows 10.  The Chrome browser is frightening people unnecessarily.  A Johns Hopkins team of cryptographers, including Matthew Green, disclose a weakness in Apple's iMessage technology.  We discuss surprisingly and sadly unused router hardware capabilities and then answer the question:  "What's a microkernel?"



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He'll talk about that leak of the NSA hack tools from the Equation Group.  What does it mean?  What does it mean?  What could they be?  He'll also give us a little insight into the microkernel, how it works, what it is.  And a look at a very interesting router operating system.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 574, recorded Tuesday, August 23rd, 2016:  Routers & Micro Kernels.



It's time for Security Now!, the show where we cover the latest security, keep you safe and sound online with this guy right here.  I feel like I'm sitting next to you.  This is nice.  Steve Gibson.



STEVE GIBSON:  So normally that screen used to be much further behind you.



LEO:  Yeah.



STEVE:  So you sort of couldn't catch me out of the corner of your eye.



LEO:  No, I had to kind of turn completely.  And I did a TV turn, which was cheat and look over there.  It would look like I was looking at you, but I'm really looking over there.



STEVE:  Ah.



LEO:  We are temporarily discombobulated because we're going to be moving back into my office next time.  But for now we're in the main studio because, as you know, I bet you can imagine, moving a whole studio...	



STEVE:  I don't know how you did it, basically on the fly.



LEO:  On the fly.  And so I made completely impossible constraints on these guys, and I feel so bad for it, and I'm sorry, John.  Because first of all they said, "Well, it's going to take us five days."  I said, "I can't miss five days of shows."  "Three days?"  I said, "I'm not going to miss any shows.  I'm not going to miss any shows."  And they said, oh, okay, okay, okay.  And then to add to the horror I said, "And we're not going to buy" - and they said, "Well, we can buy duplicate gear; right?  Or rent it or something?"  I said no.



STEVE:  Long cables.



LEO:  No.  You get one of everything.  And then, not my fault, but the tenant improvements by the owner, well, first of all the building got sold in between, during the tenant improvements.  So we leased it from one guy, and now it's a different guy owning it.  So the tenant improvements dragged on.  We were supposed to get this six weeks ago.  We got it one week ago, basically.  So there was little we could do ahead of time.  And then most of that would have been studio building.  Right?  And like the bricks that are supposed to be there and all that stuff.  So we could only do a barebones studio.  But I said, no, don't worry.  A, everybody's going to understand that for the first two weeks in a new place we're going to be, you know, it's going to be like in a new house.  You're still finishing up the stuff, painting.  And, B...



STEVE:  Stuff in boxes still.



LEO:  Oh, lots.  Lots.  And then, but secondarily, most people just listen.  And as long as - so what I said is, if we can do a show, if we do audio shows that look okay, I'll be happy.  And they don't have to be - we can do everything at the round table, which we are, until the other studios are ready.  And the last studio to go is mine because that was the last studio used in the Brick House.  Actually, it's surprisingly complete.  The desk is over, the backdrop is over, the lights are in.  We just have to wire the sound.  That'll be ready on Saturday for the radio show.  And then after that I'll be doing this show and Windows Weekly from my office again.



STEVE:  So not only is this the first Security Now! in the new studio...



LEO:  Yes?



STEVE:  This is the first Security Now! of Year 12.



LEO:  So we'll always know when we moved.  We moved in Year 12.



STEVE:  That's right.



LEO:  Year 11, Year 12.  Wow.



STEVE:  That's right.  



LEO:  Year 12.



STEVE:  Ten years from now...



LEO:  This show's going to be a teenager next year.  Junior high school.  Wow.



STEVE:  So lots of stuff to talk about.  Our main topics that we will get to is I discovered something very surprising in the hardware of all consumer routers, almost without exception, which is, I mean, it's distressingly unused capability that just isn't - it's physically there in the hardware, but isn't surfaced to a user interface.  DD-WRT is beginning to make some inroads into it.  So I want to talk about that a little bit.  And I wanted also to do a little bit of just a little sidestep into the topic of microkernels because we're all living on top of operating systems, and there's been a lot of microkernel discussion in the news.  So I want to, toward the end of the podcast, talk about those things.



But there was a lot of news of the week, of course.  The question, we'll answer the question, or look at it at least, about whether the so-called Shadow Broker Group hacked the NSA's Equation Group.  Note that Apple's bug bounty was quickly outbid.  A critical flaw has been discovered in the random number generator of GnuPG.  The EFF has weighed in on Windows 10.  Chrome browser is frightening people unnecessarily, and I've had a bunch of reports about that.



Then a Johns Hopkins team of cryptographers led by Matthew Green presented a paper at the 25th Annual USENIX Conference a couple weeks ago, disclosing a series of weaknesses in Apple's iMessage technology, which, for example, just to give you a little tease, allows for retrospective decryption of encrypted iMessages.  So there's that.



And then somebody posed a question actually this morning through Twitter that I really liked.  And I thought, this is a perfect puzzler of the week for our listeners.  So we will finish the podcast with the question this guy asked because - and it's just something for our listeners to think about for a week, and then we'll talk about it next week.  So I think lots of fun stuff.



LEO:  All right, Steve.  I'm listening with all ears.



STEVE:  So our Picture of the Week, which is in the show notes, is just a fun T-shirt which our listeners will appreciate and which would confuse pretty much any normal people who would think, what?  How does that make any sense?  And of course we all remember the "Hundred Bottles of Beer on the Wall"...



LEO:  I just saw it.  I love it.



STEVE:  Isn't that great?  So we all remember the "Hundred Bottles of Beer on the Wall" song, where you take one down and pass it around and then there's 99.  So this T-shirt reads:  "99 little bugs in the code, 99 little bugs.  Take one down, patch it around, 117 little bugs in the code."



LEO:  Oh, lord.



STEVE:  And so it's like, yes, that's the lesson we learn.  You have to be so careful when you think you're fixing something.



LEO:  Oh, so easy.



STEVE:  It's just as likely that you're going to add some more problems.



LEO:  'Tis indeed.



STEVE:  So, okay.  Probably the top story of the week was this whole NSA hacker group Shadow Brokers deal.  I've read in as much as I can from what's available publicly.  And attribution is famously difficult.  You'll remember that I was reluctant for the longest time on the topic of Stuxnet to ascribe this to the U.S. and Israel, who we now - it's sort of, again, no absolute proof, but the consensus has sort of been, yeah, I mean, we're as sure as we could be that that's, you know, that it was state sponsored and probably the U.S. and Israeli intelligence groups, the cyber groups.



So what happened here in this case is that a group calling themselves the Shadow Brokers posted a bunch of data, but only a taste of what they have, 256MB of compressed stuff, predominantly batch scripts and what was regarded as unimpressively coded Python.  So the people looking at it were unimpressed by it.  And in fact I saw one massive compound IF statement, checking the version of the Cisco ASA software that was running.  And I have to say it's not the way I would have written the code.  So who's to know?  But they posted this with the claim that they had hacked into the NSA's Equation Group.



Now, one of the things that immediately sort of caught my attention was that, if you actually read the posting, and I'm going to let everyone see what you think because I'm going to read the introduction paragraph exactly as it's written.  Tell me if you think it's actually somebody who can't speak English, or somebody who does, who's doing a bad pretend, a bad emulation of a non-English speaker.



So they said:  "How much you pay for enemies cyber weapons?  Not malware you find in networks.  Both sides, RAT and LP, full state sponsor tool set?  We find cyber weapons made by creators of Stuxnet, Duqu, Flame.  Kaspersky calls Equation Group.  We follow Equation Group traffic.  We find Equation Group source range.  We hack Equation Group.  We find many, many Equation Group cyber weapons.  You see pictures.  We give you some Equation Group files, you see.  This is good proof, no?  You enjoy?  You break many things.  You find many intrusions.  You write many words.  But not all.  We are auction the best files."  Now...



LEO:  That's Chinese, by the way.  That is almost certainly Chinese syntax.  



STEVE:  Okay.  To me it reads as fake.



LEO:  Or if you were faking Chinese syntax.



STEVE:  Oh, exactly.  But, for example...



LEO:  For instance, when you say "good," you often say "hau hau."  Which is too good.



STEVE:  Well, but, see, "We find cyber weapons made by creators of."  That, to me, like...



LEO:  Is Russian.



STEVE:  ...some correct English slipped in there when they were trying to make it seem sort of jilted and stilted.  So I don't know.



LEO:  You know, I was a Chinese major.  My Chinese isn't great.  But I do kind of recognize a Chinese-style syntax.  There's not a lot of, for instance, Chinese doesn't have tenses.  It feels to me a little bit like it would be either Chinese or somebody pretending, you're right.  And hackers obviously want to obfuscate who they are. 



STEVE:  I've read a lot of English by non-English speakers, and it feels different than that does.



LEO:  Right, right.  Feels like a fake, yeah.



STEVE:  It really does.  And, you know, you could understand that that may be what they're [crosstalk].



LEO:  It's the equivalent of a ransom note.



STEVE:  Okay.  So the files that have been made available are dated no more recently than 2013.  So the most recent are three years old.  So that's, you know, it makes people think that this has been held for a while after it was grabbed.  No one understands what that means or why.  I think I heard somebody on TWiT suggest that it was like a field tool set, like an archive that may have been lost or left somewhere.  That is to say, there are other feasible ways that these tools could have been obtained other than this rather romantic, "We found their IP range and hacked them."  Okay, maybe.



But if in fact these are field tools, and they have sort of a feel to them of that, then it's very often the case that NSA people have to leave the Puzzle Palace and venture out in order to go to specific locations on the Internet in order to get the position on the network that they need.  And if they're physically roaming around, you know, thumb drives get lost, or laptops get stolen from airports.  You know, that kind of thing.  So there are other ways this set of tools could have escaped.



Now, all of that notwithstanding, there is some - this was eyebrow-raising for the security industry.  There was a whole bunch of previously unknown things that were contained here.  So even though they were three years old, everyone on this podcast knows how lumberously - lumberously?  Anyway, how slowly...



LEO:  That's a good word you made up.



STEVE:  ...we move forward with security standards.  So 2013 is - especially problems that have been persistent for a long time.  For example, we'll be talking a little bit later about this flaw in the random number generator of GPG.  It's been there, I think, since the late 1990s.  So for decades.  Because if it's sort of following the logic or the wisdom of that T-shirt, if you don't know it's broken, you're really better off not messing with it because leave it well enough alone.



So, similarly, for example, the news just today is that one of these cyberweapons which was specifically aimed at the Cisco firewall, the ASA line of firewalls, and that's actually where this crazy compound IF statement was located, it was individually stepping through individual IF-THEN clauses, looking at version numbers that it had retrieved from the SNMP protocol.  And it's a flaw in the SNMP protocol, Simple Network Management Protocol, which we've talked about before.  It's a UDP, typically UDP-based protocol that allows you to query network gear for its status.  And so things like the number of bytes received on interfaces and transmitted and, I mean, you can - if you have write privileges, you can reconfigure SNMP devices over that protocol.  So it's very powerful, you know, as it sounds, Network Management Protocol.



Anyway, the point is that the code stopped checking versions at 8.something, and I didn't bother to remember to write it down, it wasn't important, which was some years ago.  And if it didn't match any of the known versions, it returned an error saying "unsupported."  Well, some researchers said, huh.  ASA is now at 9.something.  What happens if we tell it that it's compatible with that?  And sure enough, it works.  So, and I'm wondering, and I didn't have a chance to look, when it was that that version of the firmware was published, and if that corresponds with the date of this tool.



Because the point is they may have - that tool may have been current when it was last edited, which was when that 8.something was the most current version of the Cisco software.  Because this compound IF statement does nothing except turn an SNMP short version string into a full English statement, saying this is version zum zum zum of the Cisco something-or-other firewall.  Then the next line checks a different SNMP version and then says the same thing with a slightly different bit of text.



So again, this is part of what made people feel like, wow, this is - whoever was writing this was being paid by the character rather than to create inefficient code.  So anyway, what were found were implants, exploits, and other tools for controlling routers and firewalls, including those from Cisco Systems, Juniper, FortiGate, and a Chinese manufacturer named TopSec.  And a whole bunch of other stuff.  Again, batch scripts and Python-written tools.  



The Shadow Brokers imagined that they were going to - I guess they imagined they were going to make a windfall from this because they were asking for as much as a million bitcoins.  Okay, but a bitcoin this morning was $582 US.  So that would be $582 million.  And nobody expects that that's going to happen.  In fact, I saw a posting...



LEO:  So it's just theater, in other words, that they're doing this.  It has nothing - yeah.



STEVE:  Yeah.  And I saw posting somewhere that said the highest bid we're aware of so far, and they're only 999,999 bitcoins shy of their one million goal.



LEO:  Well.



STEVE:  So I think someone said, "Yeah, I'll give you a bitcoin for that."  So they're saying they're holding back, like, way more, the bulk of this.  And for what it's worth, it would be valuable to certain entities.  I think the price has to come way down for it to be sufficiently, I mean, for the benefit to match the cost.  But still, if these guys didn't give us just the good parts, if there was a lot more of similar quality, despite the fact that it's kind of unimpressively written, somebody somewhere knows stuff that is not public.



Cisco immediately put out a notice and quickly came up with a short-term block for this patch.  They have not yet updated their firmware.  But this is an example.  Wherever this flaw was in the SNMP protocol, sending that to the most recent version of firmware after you removed that check to see whether it was a known version, it crashed the firewall.  And as we know, the crash is where you begin the development of an exploit.



So the problem is still there in some form in the most recent firmware.  So Cisco's got a job to do because SNMP, it's not a super secure protocol.  You're able to put a username and password on it.  But it's much better to filter the port so that - it's port 161, I think, as I recall.  You're much better off not letting anybody see your SNMP ports because that's just generally a good thing.  And many ports need to be public:  port 80, port 443 for the web have to be.  But SNMP, you just don't want everybody to see that.  You're asking for trouble.



So with any luck, most organizations that are properly configured won't have their SNMP protocol exposed.  On the other hand, maybe they do internally.  And so this would create the ability for a hacker who was able to get in through somewhere else to then access the firewall and get up to some mischief in order, for example, to open the front door after coming in through the backdoor.  So, wow.  And again, if there really is an equal or much greater amount of similar quality, that's kind of frightening that somewhere there is a group that knows, at this level of exploitation into who knows what devices.



We talked a couple weeks ago about how at the recent, it was either Black Hat or DEF CON, Apple gave a presentation where, among other things, they unveiled their bug bounty program.  We talked about how they're going to be offering security researchers up to $200,000 if they privately disclose serious critical holes in Apple's software, rather than taking such vulnerabilities and exploits elsewhere.  However, there is an existing commercial exploit broker named Exodus Intelligence.  And they immediately upped the ante, raising Apple's bid to as much as half a million dollars for valid Apple software bugs.  And so, first of all, as I read this, I'm thinking, half a million dollars.  How can they possibly afford that?



Well, get this.  Their business model is that corporations that want early preview or access for whatever reason can subscribe for $200,000 a year to receive comprehensive reports, proof of concepts, demos and packet captures of these exploits which this Exodus Intelligence Group are basically purchasing from hackers who find them, pulling them all together, and then they've set up this subscription model.  And it's, I mean, it's hard to imagine that there won't be some U.S. front company that says, yeah, we need exploits for only the best purposes for our intelligence services.  So $200,000, eh, chicken feed.  And I guess that's the model that these guys are using.



So, you know, as I said when we talked about this before, I like the idea of Apple offering this official bounty program because it allowed researchers to dig into Apple's code, which is about as closed as it could be, and actually when we talk about what Matt Green and his group at Johns Hopkins found, the real lesson there is about this notion of having closed protocols and the danger of it.  But I like the idea that a true white hat hacker could support themselves, if they were sufficiently skilled, by finding problems and having Apple pay them a fair price for their find.  The problem is half a million dollars is a lot more than 200,000.  And you'd have to have your ethics screwed on real tight in order to say, you know, I'm going to stay with Apple.



So it certainly is competition for exploits.  And not just Apple, by the way.  Exodus is looking for - I wrote it down.  Oh, so iOS, Google Chrome, Microsoft Edge, and Adobe Flash are their official sort of platforms.  So of course Chrome, now the majority browser on the web; Edge, the browser that Windows 10 people are using by default; Flash, that refuses to go away and is probably a ripe territory.  I don't imagine you get so much money for those Flash exploits because they're not that hard to...



LEO:  A dime a dozen, literally.



STEVE:  Unfortunately.  So GPG.  One of the other things we've often talked about is the critical need for - I want to say all,  I think it might be all - crypto software to have a source of high-quality random numbers.  There are probably some modes where you don't need them.  But for most things you do.  So, for example, back when I was talking about SQRL, we did a podcast on the Entropy Harvester, which is, like, the first thing I wrote for SQRL because I wanted to get that right.



And what mine is doing, the code that I wrote for SQRL, is it's sucking, continuously sucking in all kinds of noise that the system produces - exact packet counts, exact packet arrivals, hard disk transfer rates, bytes transferred, I mean, like, when anything happens, keystroke timing, mouse moves, everything that's going on in the background, it's just sucking them in, pouring them into a big hash.  And the idea is that - oh, and all kinds of, at the nano level, the individual things going on in the processor, the branch mispredictions, the cache hits and misses.  You know, our current processors maintain an incredible repertoire of their own internal analysis and management platform.  And it's available to the programmer.  And it's completely unknowable outside.  So, I mean, and highly unpredictable.



So the point is, because there's no lack of true entropy in everything going on in the system - oh, also how much memory every process is using and so forth.  I mean, there's just all this, I'm just scraping all of this, dumping it into a hash, and that churns until SQRL needs a random number.  And many crypto systems are very, very hungry for randomness.  SQRL actually isn't.  It doesn't need much.  So that also helps to increase its integrity because the more you need, the more difficult it can be to provide it.  What typically happens is that - and that's the case here in GPG, is that a hybrid is created of something that harvests real entropy, which is then used to seed an algorithmic pseudorandom number generator.  And the problem is that it's easy to make these work wrong.  It is very difficult to make them work right.



And so the problem with a pseudorandom number generator is, once you're able to determine its state, if you're ever able to get a snapshot of, like, of its pool of entropy, and if it algorithmically generates output by churning that pool, then you're able to predict the future of outputs.  And that's exactly what this does.  So some security researcher discovered what they call a "critical vulnerability."  And we'll back off of that a little bit here when I explain what it is because it isn't the end of the world, and it's been fixed, in the random number generator inside GnuPG, and also Libgcrypt.  And those apps have been around since 1998.  And so essentially it's just been patched.  But any version of GPG earlier than August 17th, that is, last week, is vulnerable.  This has always been there.  They're all vulnerable.  But again, they're calling it critical because it is a flaw in the random number generator.



Turns out it's very difficult to exploit.  So that's why it's not the end of the world.  The vulnerability allows an attacker who can arrange to obtain 4,640 bits of entropy from the random number generator, to then trivially predict the next 160 bits of output.  So this is, as I said, if you can - in this case they're not getting a snapshot of the internal state.  But it turns out that, due to a flaw in the mixing functions of the pseudorandom number generator part of this, if you were to get a little over 4K bits out, you can then compute the next 160.  And that's not something that anybody wants.  That's just, by definition, it's cryptographically broken, if you're able to do that.  So GPG 2.1.15 is fully patched as of the middle of last week.  And all platforms were affected because this was in the common core code of that product.



Now, the researchers indicated that, although the vulnerability is critical, users should not immediately start revoking private keys created with vulnerable versions.  And I wrote down exactly what the researchers said.  They said:  "A first analysis on the impact of this bug in GnuPG shows that existing RSA keys are not weakened.  For DSA and ElGamal keys it is also unlikely that the private key can be predicted from other public information."  They wrote:  "This needs more research."  But they suggested do not be overly hasty in revoking keys.  Of course, you know, revoking your GPG key would cause some upheaval for everyone who would then need to update themselves in order to communicate with you.  And so they found a problem.



The good news - and it is a true design flaw that's always been there.  But it's more of an internal issue.  It's fixed.  And even they say, eh, they call it "critical" because, again, these things tend to, you know, clever people look at this longer and find some unseen way of extracting the earlier entropy and then can compute backwards.  So it's a little bit of a flaw in randomness, which, as we said, crypto absolutely needs a good supply of.



I tweeted this last week, and there was one piece of new information here that I wasn't aware of.  The EFF has weighed in on Windows 10.  And their headline was "With Windows 10, Microsoft Blatantly Disregards User Choice and Privacy."  Now, I took a softer tone in my tweet.  I just said "Win10 holdouts, not to mention corporations, would likely appreciate the EFF's take on choice and privacy tradeoffs."  Meaning that, if you're on the fence, or if it's for some reason painful for you not to have moved to Windows 10, or if you just want additional justification, the EFF basically, I mean, they rant for a while.  They're not being gentle.



The first part is user choice, which they were really unhappy about.  And there's no news there.  That's everything we were talking about for the last year, things like what seemed like deliberately confusing dialogues leading up to click the red X to close it, and that essentially doesn't deschedule the upgrade and everything.  So of course the EFF thinks all of that is a bad idea.



But then of course the second side is what Windows 10 itself does.  And here was something I didn't realize, that is, something that was news to me.  They wrote, under "Disregarding User Privacy," they said:  "The trouble with Windows 10 doesn't end with forcing users to download the operating system.  Windows 10 sends an unprecedented amount of usage data back to Microsoft, particularly if users opt in to 'personalize' the software using the OS assistant called Cortana.  Here's a non-exhaustive list of data sent back:  location data, text input, voice input, touch input, web pages you visit, and telemetry data regarding your general usage of the computer, including which programs you run and for how long."  Then they go into talking about the ways it's possible to use options to reduce that level of reporting, that of course we've covered previously, extensively.



But here was what I didn't know:  "Unless you're an enterprise user, no matter what settings you choose, you have to share at least some of this telemetry data with Microsoft, and there's no way to opt out of it.  Microsoft has tried to explain this lack of choice by saying that Windows Update won't function properly on copies of the operating system with telemetry reporting turned to its lowest level.  In other words, Microsoft is claiming," writes the EFF, "that giving ordinary users more privacy by letting them turn telemetry reporting down to its lowest level would risk their security, since they would no longer get security updates."  And then they said, in parens, "(Notably, this is not something many articles about Windows 10 have touched on.)"  And I never remembered encountering that before.



So anyway, they conclude, saying:  "There's no doubt that Windows 10 has some great security improvements over previous versions of the operating system.  But it's a shame that Microsoft made users choose between having privacy and security."  And that's no surprise from the EFF.



I got a tweet that reminded me of several of these that I've received that I just sort of wanted to talk about sort of a checkpoint here:  In August of 2016, after the January 1st, midnight, New Year's Eve sunset of SHA-1 signed certificates.  And so the tweet that I got said:  "Steve, I work for a hospital, and we have an online bill pay system in place using a third-party site.  When visiting the payment site in Chrome and looking at the certificate information, Chrome is telling me that the security on the site is weak."  And he says, "See attached image.  What are your thoughts on this?"  And in fact the image that he attached has Chrome saying that this may not be a private connection.  Now, what it's doing is warning that that site that he was going to was signed with SHA-1 cert, claiming that the connection might not be secure.  Which we know is utter nonsense.



LEO:  It's just scaring people.



STEVE:  Yes, exactly.  And Google's security engineers know it, as well.  On the other hand we know, it's one of the underlying topics of the podcast is how reluctant and difficult it is to move the industry forward, and that SHA-1, it was time for it to die.  But it has died.  For example, you can't get an SHA-1 cert any longer.  But the ones that were issued still exist.  I tweeted back to him, and I said, well, for what it's worth, there isn't any known actual problem with SHA-1.  Everyone's just being cautious and moving away from it before it becomes a problem because everything we've learned about the way security progresses says that someday that may not be strong enough.  And I also said, but look at the expiration date.  When that cert expires, that company will have no choice but to move to SHA-256 because, as of midnight of last year, of New Year's, no CA will synthesize and sign an SHA-1 certificate anymore.



So I'm of two minds.  The problem is, Google is doing this - and this is not the only person I've heard this from.  I get this constantly.  It's like, what does this mean?  And it's like, well, you know, Google knows that companies using SHA-1 certs will get some blowback from their users, their web server visitors, who are worried by the certificate that the company is using.  And so Google knows that will incent the company to move off of SHA-1.  To me, that seems like overkill.  Unless a problem were known, just let them expire.  No one can get them anymore, so within a couple years they'll all be gone.  So anyway, I guess this is the tension you're going to have when it is so difficult to change things that aren't broken.  SHA-1 actually isn't a problem.  We just think it's a good idea to move away from it.  And Google's pushing, as we know.



So this USENIX paper from our friend Matthew Green, who is the professor of cryptography at Johns Hopkins, along with four, I assume they're postdocs or grad students - and you can get a lot of work done if you have enough smart grad students that are interested in a project.  The paper was titled "Dancing on the Lip of the Volcano:  Chosen Ciphertext Attacks on Apple iMessage."  And I'm just going to quote from the abstract because this gives you a sense for what Matthew Green and his group found.



Their paper, which is, I think, 19 pages long, it opens:  "Apple's iMessage is one of the most widely deployed endtoend encrypted messaging protocols.  Despite its broad deployment, the encryption protocols used by iMessage have never been subjected to rigorous cryptanalysis."  Why?  Because they're secret, and we'll be talking about that once we catch up on this news.  "In this paper, we conduct a thorough analysis of iMessage to determine the security of the protocol against a variety of attacks."  Now, of course, this could have been done easily, if Apple had published the protocol for verification by experts.  But they didn't.



"Our analysis," the abstract continues, "shows that iMessage has significant vulnerabilities that can be exploited by a sophisticated attacker.  In particular, we outline a novel chosen ciphertext attack on Huffman compressed data, which allows retrospective decryption of some iMessage payloads in less than 218 queries." Which is nothing.  "The practical implication of these attacks is that any party who gains access to iMessage ciphertexts may potentially decrypt them remotely and after the fact.  We additionally describe mitigations that will prevent these attacks on the protocol, without breaking backwards compatibility.  Apple has deployed our mitigations in the latest iOS and OS X releases."



Okay.  So these guys, this work was done last year.  And in November of last year, 2015, they responsibly disclosed, privately to Apple, what they found.  So Apple then revised their protocols in, as they said, in a backward-compatible fashion.  And we got those in March of this year in iOS 9.3 and Mac OS X 10.11.4.  So the problem is solved.  So by the time this got any light, everyone should have been updated, and this wouldn't be a problem.  But I want to just now go over what they described as their high-level protocol analysis because it's interesting what they found.



Under the "Key server and registration," and our listeners will - this will sound very familiar to people because it's what I've been complaining about from the beginning:  "iMessage key management uses a centralized directory server [they call] IDS which is operated by Apple.  This server represents a single point of compromise for the iMessage system.  Apple, and any attacker capable of compromising the server, can use this server to perform a man-in-the-middle attack and obtain complete decryption of iMessages.  The current generation of iMessage clients do not provide any means for users to compare or verify the authenticity of keys received from the server."



Just to pause for a second, remember, this is why, for example, I'm so bullish about Threema, or even Signal.  Both of those give you explicit key management.  Now, on the one hand, most users don't want that.  But if you actually care about the security of your communications, I mean, if, for you, security is more than just, oh, yeah, it's secure, then iMessage doesn't provide that because, as I've always said, they're managing the keys.  And if a third party manages the keys, and the third party can be subject to any kind of coercion, or bad employees, then you don't actually have security.  You have the feeling of security.



Then they continue:  "Of more concern, Apple's 'new device registration' mechanism does not include a robust mechanism for notifying users when new devices are registered on their account.  This mechanism is triggered by an Apple push message, which in turn triggers a query to the Apple-operated server.  Our analysis shows that these protections are fragile."  Then they have an Appendix A where they implement attacks against both the key server and the new device registration process successfully.  That is, they demonstrate its exploitability.



Further, "Lack of forward secrecy," which is a property that we know is important because what that does is it means that the symmetric key being used to encrypt messages is constantly changing so that, if you capture the key in the future, and you had stored ciphertext in the past, you cannot use a key captured in the future to decrypt old messages, which is otherwise a problem.  Until recently, SSL, the pre-TLS protocol itself was not - did not offer forward secrecy.  iMessage doesn't either.  "iMessage does not," they write, "provide any forward secrecy mechanism for transmitted messages.  This is due to the fact that iMessage encryption keys are long-lived and are not replaced automatically through any form of automated process."  Where, for example, as we know, Signal has the key ratchet mechanism that is constantly moving keys forward.



"This exposes users to the risk that a stolen device may be used to decrypt captured past traffic.  Moreover, the use of long-term keys for encryption can increase the impact of other vulnerabilities in the system. For example, in Section 5, we demonstrate an active attack on iMessage encryption that exposes current iMessage users to decryption of past traffic.  The risk of such attacks would be greatly mitigated if iMessage clients periodically generated fresh encryption keys.  See Section 7 for proposed mitigations."



I'll skip over their discussion of the fact that there is no prevention for replay and reflection attacks, and finally just get down to Apple's use of nonstandard encryption.  They write:  "iMessage encryption does not conform to best cryptographic practices and generally seems ad hoc.  The protocol" - which they diagram earlier in the paper - "insecurely composes a collection of secure primitives, including RSA, AES, and Elliptic Curve DSA.  Most critically, iMessage does not use a proper authenticated symmetric encryption algorithm and instead relies on a digital signature to prevent tampering.  Unfortunately, it is well known that, in the multiuser setting, this approach may not be sound.  In the following sections, we show that an on-path attacker can replace the signature on a given message with that of another party.  This vulnerability gives rise to a practical chosen ciphertext attack that recovers the full contents of some messages."



And I had in my notes here some additional detail.  But everyone gets the idea.  Essentially, what Apple did was, unfortunately, they rolled their own.  They invented something they did not need to invent.  Now, I want to back off from that a little bit, saying I'm not sure when iMessage's protocol was put together.  So some of these things may not have been around.  Some of these primitives may not have been available.  But we've covered on this podcast in the past the danger of using a signature rather than a MAC, a Message Authentication Code, the danger of using a signature to authenticate a message because, if there's some way for you to use a valid signature, even if it's not the original person's valid signature, but if the signature will still validate, then you can make any changes you want and then sign the message with, for example, your own signature.  So long as it's part of the system, it'll be accepted at the other end.  And attacks like that have existed, and iMessage is vulnerable to that attack.



So the takeaway is, once again, the clear and present danger of closed protocol security design.  In my opinion, it's not necessary to see the source, that is, Apple's source code.  But documentation of the protocol would have allowed anyone who understands crypto to glance at it, and this problem would have been fixed a long time ago.  Because Apple is as closed as they are for, I guess, corporate commercial proprietary reasons, they didn't disclose the protocol.  So what that does is it hugely raises the bar of difficulty beyond the expertise of just being an expert in crypto.  You also then have to reverse-engineer an undocumented protocol from scratch.



Now, there were a couple previous attempts, partial reverse-engineerings of iMessage.  So Matt Green and his group used those, but they were incomplete.  So they had to do packet captures, watch this thing work, use what little was known publicly, and basically reverse-engineer all of how it works in order to then look at it.  And then what they realized was what Apple had done had a lot of problems.  So I can't think of a more perfect example of the danger of a protocol being closed, different than the source being closed because, as we know, being able to look at the source code in theory would let you find bugs.



But in practice, lots of open source code has bugs hiding in plain sight.  You just can't see them when you look at the code.  That's not the way code works today.  But the protocol, that is, what the code was trying to implement, I would call that the policy, as opposed to the implementation.  The policy should be able to withstand scrutiny.  And that's, for example, that's exactly my position with SQRL, is that the SQRL protocol is absolutely open.  I talked about it on the first day that I mentioned SQRL.  And other people are implementing compatible clients and servers using their understanding of the protocol because it's, first of all, very straightforward and very simple, but nothing hidden.



And I think, even if we're going to have proprietary closed source solutions, there's just - this is a classic example of why the protocol that that closed solution implements should be public.  And that is actually the rule with the rest of the Internet.  The Internet is based on open protocol.  That's what has allowed it to be as robust as it has been.  Well, that and the fact that it was an inspired design from the beginning.  It's got problems, things that it wasn't designed to do that we're trying to make it do, that it's having problems with.  But that's not its fault, the fact that all these RFCs are written, the documents, how everything glues together.



Look at all the companies, like the router manufacturers, like Cisco and others, that are making a great living writing, creating hardware and software solutions that implement that open protocol.  I really think that's the future that we're going to see, that this kind of, oh, no, we're better than everybody else, we know how to do this right.  I wanted to believe that.  But this is an expos of even Apple's good crypto people didn't understand as well as true experts who do this, like, for their living.



LEO:  It's a classic case, isn't it.



STEVE:  Yeah, it's perfect.



LEO:  Yeah.  Is it good enough?  Remember we talked about Telegram, and you said it was good enough?  This is good enough.  It's just not strong.



STEVE:  Yeah.  Oh, it's going to keep, you know, it's going to keep anybody in the neighborhood...



LEO:  Everybody but a state actor, probably, out of your pants.



STEVE:  Right.  And, again, even if it were public, if you use centralized key management, you can't trust it.  You cannot trust it.  I mean, we trust Apple.  But Apple could be compelled, as we often said, to add another key to a conversation that would allow a non-Apple actor to have access to that messaging traffic.  And in the paper - I didn't have this in my notes, but I read the whole thing - Apple maintains in their database 30 days' worth of everyone's message traffic.  And my god, it's an amazing amount of message traffic.  It's 200,000 messages per second, 200,000 iMessages per second Apple is currently transiting through their network.  So they're maintaining 30 days of back traffic so that devices that are turned off, when you turn them on, they're able to resynchronize themselves.  We've all seen that.  When you bring a new device online, sync it into your Apple account for the first time, it's able to get all of the back messaging traffic that's available for 30 days.



So Matthew and his group's point was that, with the exploits they found, it would be due to the fact, for example, that keys are not being rotated, and that in fact their chosen ciphertext attack that leverages the fact that Apple did not authenticate messages properly, that would allow an attacker to subpoena the encrypted data from all of the most recent 30 days for a given person, and then do an offline decryption with no other information.  So the fact that Apple says, oh, well, yes, we're storing it, but it's encrypted, and we don't have the keys, that's okay.  Johns Hopkins does because it wasn't [crosstalk].



LEO:  It's okay.  Johns Hopkins has it.



STEVE:  So you shot me a note over the weekend, and I received a bunch of tweets about this.  There was a very nice posting, a blog posting in CodersNotes.com, about the "Elegance of Deflate."



LEO:  Wasn't that a great - wasn't that interesting?  Yeah.



STEVE:  Really was.  And I have a - I just love encryption.  I mean, sorry, I do love encryption, but I love compression.  I've always been fascinated by compression.  It's just been one of the fun puzzles that engages me because it's a closed system.  It's very much like the mobile security or the mobile app puzzles that I find and share with our listeners, thanks to them sharing them with me, which are themselves closed systems.  Everything that you need is in front of you to work with, and what can you do?  And compression is like that.



So I wanted to point our listeners back to our podcast that was titled "Lempel & Ziv."  It was Podcast 205 on July 16th of 2009.  So, and there's show notes.  The audio is there.  I'm sure we were doing video by then.  So you can get it from TWiT, or you can get it from GRC.  Again, Podcast 205, July 16th, 2009.  I explained, in Explainer-in-Chief mode.  We had a lot of fun visually explaining the way this very clever buffer-based Lempel & Ziv compression works.  And I've talked about it through the years.  And it was an invention.  I think it was 1973 a patent was issued...



LEO:  Long time ago, yeah.



STEVE:  ...to these guys.  And I think they were at IBM at the time.



LEO:  Or, no, Unisys. 



STEVE:  Oh, you're exactly right, Unisys.  And the idea was to compress data over a communications channel.  And that's sort of a - it's weird because we don't think of like compressing a file as being over a communications channel.  But the idea is that the recipient who is going to decompress it has no advance knowledge of the contents.  So the sender is able to look into the future, sort of like upstream of what it's going to be sending, if that helps them; or also look downstream, that is, remember what has been sent, but then chooses to send stuff to the recipient.



And the idea is that the way the algorithm works is they each create state in the form of some buffers, which is kept synchronized, so that each end does the same thing to their state.  And so the sender knows what the recipient has in their table, their state table, and that knowledge allows the sender to use shortcuts, essentially, to represent much longer runs of data which happened to appear in the recent past of the data that was sent because that will be represented in this table.  And the way this applies to file compression is that we think of the act of compressing the file as sending it.  That is, we're sending it to a small file.  And the act of decompressing it is we're receiving it.  We're receiving the small file into a big file.



And so, anyway, I go into it in great detail.  I think our listeners would find it interesting.  I know, you know, we have so many of these things that we talked about years ago that are still relevant today.  So again, Podcast 205, Lempel & Ziv.



LEO:  But you don't cover Deflate there.  Deflate is kind of interesting because it's Lempel-Ziv plus; right?



STEVE:  Well, yeah.  Deflate, I did actually talk about...



LEO:  That's Phil Katz came up with that, with PKZIP.



STEVE:  I did talk about Huffman coding of the tokens.



LEO:  Oh, okay.



STEVE:  And so Lempel & Ziv is the core algorithm.  And then the idea is that, because not all things will happen with the same frequency, once you have this set of things that you want to send, you're able to represent the ones that occur most often with fewer bits, and the ones that occur less often with more bits.  So you get Huffman compression, which is what that's called, variable bit-length compression, on top of the really cool buffer compression.  So, yeah, neat stuff.  And that's Deflate, you know, Gzip that's been around forever.



LEO:  Yeah, PKZIP.



STEVE:  I just wanted to mention about SpinRite that I got some nice feedback from people who were really glad that I mentioned as I did last week something I had never mentioned before, and that was that it's not necessary to run SpinRite all at once; that, because of the fact that I made the percentage complete, accurate to four decimal places, 37.1234, you're able to run it for a few hours when you don't need your computer, like overnight, and then stop it.  It shows you where it was.  And then next time you have some time, you're going out, or you're going to sleep again, you start it up where you left off.



And so a lot of people appreciated knowing that.  That's just - it's not something that's really apparent.  In fact, I did see a little confusion, some people who didn't even know where it was in the user interface.  There's one place where you, I mean, and this is one of the things that I look forward to changing in the future is updating the UI.  Because at the time it was state-of-the-art.  But that was 25 years ago, and the state has changed a little bit.



LEO:  We had Alan Cooper on yesterday, on Triangulation, old, good old friend, and kind of king of the UI.  And he had written, in the early days, he was working at DOS.  And then Windows 1 had come out, or actually he said 0.98 or whatever.  And he was writing a project manager, which ended up becoming Super Project, that CA bought.  And he said it was graphical.  I said, "Graphical."  He said yeah.  I said, "Were you using like the ASCII art, like..."



STEVE:  Like the line drawing.



LEO:  "...the line drawing in ASCII?"  He said, "Oh, yeah, that's how it was graphical."  That's how Windows was graphical originally.



STEVE:  Yeah.



LEO:  So that's how you did it, by the way, in SpinRite.



STEVE:  I think it's no coincidence that we just sold a couple copies.



LEO:  Oh.



STEVE:  It must be that we have some live viewers who are waiting for me to talk about SpinRite to...



LEO:  Yabba-dabba doo.



STEVE:  ...push the button.  So thank you.  I didn't have the loud one on next to me.  But I did hear yabba-dabba doos in the background.



LEO:  That's awesome.



STEVE:  So it's appreciated.  It's what keeps me here. 



LEO:  Yeah.  I ought to do something like that in the studio, where we have, like, little sounds go off every once in a while telling us [indiscernible].



STEVE:  It's funny, I also got feedback about that.  Someone asked, by the way, if I was - and I never had a chance to respond, so I will here - whether I was using some program to generate those.  I talked about how, when a process launches and a process stops, that I have various little, just little click-y bonk sounds and things.  No.  It turns out that's built into Windows.  You are able to associate sounds with all kinds of Windows events, like process start, process stop, logging on, logging off, screen blanking, and all kinds of things.  So it's all built in.  If you just go into the sounds applet and poke around in there, you will see the ability to bind sounds to Windows events, like switching users and logging on and so forth.  All kinds of things.  And so I have a standard set of sounds that have moved with me through the years.  And that's just sort of part of my operating environment.



LEO:  All right, Steve.  Let's get into it.  Routers and microkernels.



STEVE:  Yeah.  So I was astounded a couple weeks ago by what I found in the hardware of most of our dumb, dumb routers.  And it was just a trail that I was set onto because a number of our listeners like a different type of router.  We've of course been talking about the Ubiquiti EdgeRouter X and the power that it offers.  A number of people said, what about the - and no matter how much I practiced saying this, I cannot say it - the MikroTik.  Mik-rot-ik.  M-I-K... 



LEO:  I think it's Mi-krot-ik.



STEVE:  MikroTik?



LEO:  Yeah.



STEVE:  That's a lot easier.  Oh, you're right, MikroTik.  MikroTik.  Okay.  Anyway...



LEO:  It could be Mikro-Tik.  I don't know.



STEVE:  Could be.  Yeah.



LEO:  MikroTik.  What does that mean?  I don't know what that means.  You've got a word I've never heard of.



STEVE:  It is a bizarre word.



LEO:  I know "necrotic," which is dying.



STEVE:  Well, and I was trying to say, okay, "erotic" but with a "mik."  So erotic, MikroTik.



LEO:  MikroTik.



STEVE:  But apparently it...



LEO:  Actually, the way it's spelled with the inner cap, I think it's MikroTik.



STEVE:  Okay.



LEO:  See the inner cap?



STEVE:  Oh, look.  Oh, Mikro...



LEO:  I think it's MikroTik.



STEVE:  Somehow I missed that.  I don't think I saw that page.  Nice.



LEO:  Yeah, that's on wiki, Wikipedia.



STEVE:  But actually, okay.  So what I have in the show notes, I'm not going to go into this in detail.  I just want to put it on people's radar.  Basically the show notes are one, two, three, four, five, six, seven, eight, nine interesting links of surprising stuff.  It turns out that the heart of, I want to say all, but at least all that I looked at, certainly many, of our rather dumb routers, the ones where we've got a WAN port and four LAN ports, and it's blue and plastic, it turns out in there is an extremely capable chip, the same chip as in the Ubiquiti EdgeRouter that does all of that extra stuff.



Because it turns out that Qualcomm, I would argue, really overdesigned a beautiful chip, and then no one took advantage of it.  They used a minimal set of features.  But in this Qualcomm chip is not only the ability to individually configure the subnets of individual LAN ports, but a complete hardware-based, packet-processing engine and rule-based filter system.  So, I mean, it's a firewall multiport router on a chip.  And it's in the dumbest of the routers.  They just don't use it because it's not what they were selling.  And so when I - first of all, I was trying to understand what features this MikroTik - thank goodness that's the way you pronounce it.  Now I can say it.  This MikroTik...



LEO:  Well, wait a minute, because they're from Latvia.  So it's probably MikroTik.



STEVE:  Oh, MikroTik.



LEO:  Isn't that where Andy Kaufman's character Latka came from, Latvia?  I don't know.  Say it like Andy Kaufman would say it, MikroTik.



STEVE:  So I was trying to figure out what capabilities these routers had.  And I ran across this chip.  And the documentation on this MikroTik site is really bad.  And I should say, for what it's worth, this is not my favorite router.  I looked at it.  It's funky.  If you have one, fine.  But if you don't, get a Ubiquiti EdgeRouter X.



LEO:  I have never, never heard of them.



STEVE:  So, but our listeners do or have.  The documentation is very confusing about, like, which router.  They make, like, 50 of them, different models, and also antennas and things.  But even among the routers it's very unclear what they can do and what they can't.  So that forced me to dig down.  And what I found when I dug was this Qualcomm chip.  And it turns out everybody's using it because it's amazing.  But they're not using it for its amazing stuff.  And so, for example, DD-WRT, that we've talked about often, which is the alternative, open source, very nice firmware which can be used on many of these routers, it is creeping into this chip further.



There is a page, one of the links that I've got in my show notes, at the DD-WRT wiki.  The page is "Switched Ports Separate LAN Ports Into Another Subnet," or "Separate LAN Ports Into Another Subnet."  So that says that on this DD-WRT page, they explain it.  The web UI, the normal browser-based UI, it doesn't go there.  You can't do that there.  But at the command level that you're able to get to,  you can give commands that DD-WRT will interpret to program these advanced capabilities that are in the cheapest router around, or older router.



I mean, really, the Ubiquiti EdgeRouter at 49 bucks is hard to beat.  And it brings all of those features to the surface so that you can use the standard browser UI in order to create separate LAN ports or separate subnets on different LAN ports.  But anyway, the point I wanted to make was that, to my amazement, it isn't a dumb switch or a hub that is doing nothing, even in the cheapest router.  It is typically this Qualcomm part.



Now, the other thing is that Qualcomm's got all this locked down in NDA.  And the only documentation I could find had some poor guy's name plastered across every single page in light gray, branding him as the person who let this loose on the Internet.  On the other hand, it's the complete documentation for this chip, which is otherwise not public.  You have to go under NDA in order to get documentation for it.  Intel made me do that once when I wanted to write some code for their gigabit chip.  I was like, come on, it's just a gigabit chip.  I mean, it's supported under FreeBSD.  I can go get their driver.  But I'd rather have the official documentation.  But companies are like that.



So anyway, I wanted just to let everybody know that this exists, that that capability exists.  I don't know what you could do with it except I know we've got tinkerers.  And if you've got older hardware that isn't a MikroTik router, and isn't a Ubiquiti, for example, but it will run DD-WRT, you may be able to unlock unsuspected capabilities there, which would be kind of fun.  I think that'd be cool.



So I was amazed that there's, like, an incredible packet processing computer.  And you can tag individual packets for processor-level handling or local handling.  So, for example, that chip itself can be a hardware firewall, which in hardware follows a hierarchical ACL, you know, sequential match rule set.  All that's built into the hardware.  And if, then, more intelligence is needed, there's a rule that says "Forward me to the CPU," in which case - and, for example, the chip itself is called a 7-port switch because five of them are Ethernet ports, and two of them are processor ports.  So it's not seven Ethernet ports.  But it's technically a seven-ported chunk of silicon.



Anyway, I'm just - I was just amazed that that was in there.  And, boy, you know, if I had any free time, that'd be fun to play with.  But I know that our listeners may have some fun with it.  So I wanted to let everybody know that's there, hiding.



So operating system and microkernels.  This comes from a conversation, Leo, you were having a few weeks ago about - was it an alternative OS for Android phones?  That's been one of the things that has been happening.  And it might have been something that Google was doing.  I don't remember now what the genesis was.  But I wanted to remind people that, sort of a little bit of history here, the way, like, where we came from with computing.



Because once upon a time there were no operating systems.  Those old-school computers with the raised air-conditioned floors flowing cold air up through large boxes of electronics, with the big reels of mag tape going back and forth, and the big huge printer chug-chug-chugging out, line printer, lines of text.  Back in those days, when a program ran on the computer, that's all that was running.  So, and they were called "jobs," typically.  And at the very beginning you would run one program at a time.  And so this job would run on the machine.  And in general the operators, these things had their own operators who often wore white coats to look official.



LEO:  No, I thought that was to keep things clean.



STEVE:  Well, to make sure that their salary was clearly justified.  Because, well, and the other thing is these computer systems were ungodly expensive.  I mean, like an insurance company, a huge insurance company, would have one in their main headquarters.  And it would process all of their stuff.  And it would run, typically, it would never stop.  It was 24 hours a day because they wanted to get as much work out of this thing as they possibly could.  The operators ended up after a while knowing how long which jobs took.  So, like, the East Coast payroll job would take five hours to run.  The West Coast payroll would take four hours to run because there were not as many people on the West Coast back then, and like that.



And so the different things they were doing would - they'd, like, run the deck of cards in that would get this thing programmed.  And then they'd mount the reels of tape that the job required.  And basically they were just sort of trained monkeys.  They weren't programmers.  They knew which button to press to start.  And then they basically sort of sat around and watched, literally, the wheels spin for a few hours.  And they could - also you developed some expertise after a while.  When the lights dimmed a certain way, they could kind of tell, oh...



LEO:  You've got to listen to yesterday's Triangulation because this is exactly what Alan Cooper did with his System 360 or 370.  It's exactly what he was talking about, the disk packs and taking them out.  And, you know, he said - I said, "Man, you must - you were like the priesthood."  He said, "I was getting $3.25 an hour.  It wasn't exactly high-end stuff," as you said.



STEVE:  That's exactly that era.



LEO:  Yeah.



STEVE:  And so the idea was that, when a job was running, it owned the machine.  And the problem was that some jobs needed lots of tape drives, just because they had lots of data that needed to be shuffled around in many more places.  Other jobs only needed three.  But if a system had 10, then when a job was running that needed only three drives, it sort of bothered the boss that those - he would, like, knock on the glass and ask those technicians why are those seven tape drives not busy?  Because he knew what he was paying for those, and he wanted to keep everything busy.  And they just sort of shrugged, and they said, you know, go talk to the programmers.  All we do is put decks of cards in and press Go.



So what evolved then was, first, was the automated queuing of jobs in order to minimize, to squeeze out the time that nothing was going on because that really upset the boss.  But then, because this thing was so expensive, there was such tremendous pressure on keeping this busy all the time, it occurred to people that maybe this thing, this machine could do more than one thing at once.  There could be a supervisor that would arrange to have multiple jobs coexisting, and each using the machine when it was available.  For example, oftentimes, especially back in the mag tape days, it took a long time to rewind one of those tapes.  And so while a tape was rewinding, the other tapes could come alive doing a different job on their drives, using the computer, while the other one was getting ready for its next phase.



And so we sort of - we moved forward little by little.  Basically, because these things were so expensive, there was tremendous pressure to just keep it busy.  And then the next change was so-called "timesharing," where we sort of backed off from this notion of having jobs, to this notion of having users on terminals.  And a bunch of people would all be connected to this.  And it was, you know, these machines were not fast in terms that we're used to thinking of today.  I don't have any stats on-hand.



But, for example, when I was at Berkeley, we had two different mainframes.  We had a CDC 6600 and a CDC 7600.  And, for example, as computer science students we would punch up our cards, a deck of cards of our Fortran program, and pass them to a student assistant through a little cubbyhole, and then later come back in the day, and our card deck with the printout that that deck generated would be in a cubbyhole.  And so we would pick up the results.  I mean, that's literally the way this worked back then.



But then we added, we developed this notion of timesharing, where many users would be doing things at the same time.  Now, not all users had the same priority.  And one of the things that you got to know, for example, and this was again at Berkeley, if you really wanted to get access to the system, you would wake up at about 2:00 a.m. and trudge over to the lab where there were terminals and run your project.  And it would run in about one one-hundredth the time that it would take during the middle of the day because during the middle of the day the university basically had priority, and/or the chem lab is doing x-ray crystallographic computations or something, and the lowly comp-sci students had low priority.



So you'd hit Enter on the Hazeltine terminal.  The cursor would be blinking, and you'd just wait for it to acknowledge that, you know, and you'd think, I did press Enter, didn't I, and hoped that it wasn't waiting for you, that you were waiting for it.  And in fact, when I worked in summers while I was in high school at Stanford's Artificial Intelligence Lab, I begged the director, Les Earnest, who was the administrative liaison with the powers that be at the campus, for access to the PDP-10 and the PDP-16 machines they had.  And he agreed.  But I could only use them in the evenings and weekends because, again, the system was loaded down during the day and was slow, and they didn't want any excess random stuff going on that wasn't for their main purpose.



So back then you were sharing a machine.  But consider what that meant.  If you had much more pressure on the system, many more people waiting for it, then it was never waiting for anyone.  And that meant it was busy all the time.  And so that was the thinking at the time.  So now coming forward to present-day, we're sitting in front of computers that are ridiculously inexpensive.  We've got them in our pocket, and we have them on our wrist.  We own multiples of them ourselves, all of them ridiculously more powerful than those huge things on elevated air-conditioned floors that many people were desperately trying to share back in the 1970s.



So the concept of an operating system became important when programs needed to share the same hardware.  It was originally, as I mentioned, called a "supervisor."  We now call it an OS, an operating system.  And the need for an operating system reflects the fact that there are a couple of things that cannot be done by the applications that are running, sort of by definition.  For example, the application cannot load itself because it is itself.  Even when I was toggling in the bootstrap loader through the switches of those PDP-8s behind me, you had to put in that loader in order to read the paper tape into core memory and then run the core.



But the app itself - and in fact there were some fancy tapes that had a loader on the front.  So you would toggle in a low-capability small loader because it was practical to key it in.  It was like the minimum number of instructions, just to suck in the leader of the paper tape.  And once that was done, what that leader was, was a much more efficient loader, which the pre-loader would load.  And then it would take over and read the rest of the tape in a much more efficient fashion, using a much larger loader that wasn't feasible to key in by hand.  But the point is that programs need help to get going.



The other thing that, I was going to say no program could do, but it wouldn't be practical, at least, is scheduling.  That is, there are many different resources on a computer system that the programs running on it need to share.  And time is one of the key resources.  And so every operating system has this - it's called a scheduler, something that schedules the execution of programs.  And there may not be anything that has received as much attention over the years as scheduling.  There's an art and a science to it.  Papers have been written, doctoral theses have been written over how to best - because it's a complex problem.  Scheduling in general is a complex problem, how to maximize the amount of runtime given very complex competing requests.  And ultimately these days we just throw more cycles at it, or more memory, or more juice, or more cores, and worry about it a little bit less.  But it is a big issue.



And then another resource which is inherently global and shared is memory.  And once again, you can't leave that up to the program.  The program can't load itself, it can't schedule itself, and it can't manage the system's memory by itself.  That all has to be done by a third party.  It has to be done by the operating system.  That is, the program can ask for memory.  And then the operating system decides if it can grant that request or not.  Based on rules like processes could, in the old days when there was very limited memory, you would have limits, quotas on how much memory a process could ask for.  So a request could be denied by the operating system.  I says, I'm sorry, but I can't give you as large a buffer as you would like to have.



So the concept of a microkernel, best stated, is the minimum set of services that must be provided, that cannot be provided by the programs running or other services running.  And so the loading of them, the scheduling of their use of time, and the managing of the sharing of the system's global pool of memory, something needs to stand back, separate from the workers, and manage them.



Now, of course, there is much more to an operating system than just loading scheduling and memory management.  And this is where in my notes I said, "No battle plan survives contact with the enemy," to remind myself that all microkernels start out being perfect, pure, pristine, oh, look, we finally got a beautiful little microkernel.  And now the question is, how long will it stay that way?  How long will it be before it becomes adulterated?



And of course we've talked many times about the decision Microsoft made when they moved GDI, the Graphics Device Interface, API support from outside the kernel to inside the kernel.  They did it because crossing back and forth across the kernel boundary was expensive on the Intel architecture.  There was a switching overhead that they wanted to minimize because systems were becoming so graphics intensive.  So then there are a number of kind of gray areas.  For example, there are many other API services beyond loading the program, scheduling the programs, and managing memory, like what time of day is it, for example.  Where there are things that many programs would want to share, then it makes sense not to have every program have to write the same thing, to rewrite the same code.



Now, and there's another thing that the OS has to manage, and that's the file system.  Somehow a file system is an abstraction of the physical storage device such that the programs refer to entities, files, without regard for how they're stored.  It's open this file that's named this and give me its data.  And so notice that that doesn't change, if it's a FAT file system or an NTFS or a ZFS or whatever.  Basically you're asking for a file.  You're insulated from the details of how the file system does that.



So the question is where should this go?  Or where should these things go?  We have all of the additional API services.  And then of course device drivers.  Device drivers is an example of another shared resource.  Does that go in the kernel?  Or is that a service that runs outside the kernel that applications may be able to get to directly, or may need to run through the kernel to get to?  And then, of course, higher level functions.  When we were talking about a couple weeks ago, Leo, you were talking about, I think it was the little kernel?



LEO:  Yeah.



STEVE:  Was it LT?



LEO:  LK, yeah.



STEVE:  Yeah.



LEO:  This is what Google's Fuchsia is based on, yeah.



STEVE:  Correct.  And it all sounded fine.  And then I heard that somebody said, oh, yeah, and it'll have GPU support in the microkernel.



LEO:  No, it's not a microkernel.



STEVE:  Ah.



LEO:  That ain't no microkernel.



STEVE:  And so this is the problem, is that everyone keeps trying to have a microkernel.  And for the first week you do.  And but then it's just so tempting to put more stuff in there; to just say, oh, you know, let's just add this feature and that feature and another feature.  And it takes some real discipline to say no because, as we know, it is very hard to make this stuff work perfectly.  And you want that kernel, you want your microkernel to not be buggy, to not have memory management flaws, not have vulnerabilities in the program loader or the scheduler.  Or all the other things you add.  For example, the GPU, the idea of having - calling a microkernel something that also supports a GPU?  It's like, uh, well, they must have had a reason.  Clearly it's because the GPU is a widely used resource.  Every app that's running on this thing will be using graphics.



LEO:  It's probably more efficient, too; right?  I would think, if it's in the kernel, it'd be more efficient.



STEVE:  Well, yes.  But it's a tradeoff because look at all the...



LEO:  It's also more complex; right.



STEVE:  ...all the trouble that Microsoft has suffered from the fact that a JPEG can take over Windows.



LEO:  Right.



STEVE:  That's just ridiculous.  And if it were outside of the kernel, it couldn't do that.  But the actual code that's interpreting the JPEG has root privileges.  It's kernel code.  So it can do anything it wants to.  So, anyway, I just sort of wanted to create some context.  There is not a formal definition.  A microkernel mostly represents a wish that sort of the ivory tower academicians have this notion of a microkernel, where - and in a strict microkernel, all that other crap is outside the kernel.  You apply the test.  Can this be done outside?  That's the test.  Can the loader be done outside?  No, probably.  Can the scheduler be done?  Well, by definition, no.  The scheduler has to be in the kernel.  Can memory management be done outside?  No, that has to be in the kernel.



So the test is does it have to be in the kernel?  If the answer is no, and the decision is therefore it is not in the kernel, then somehow you've managed to maintain a microkernel.  But if the decision is, oh, it'd be nice to have it in the kernel, wouldn't it?  It's like, yeah, it would, but then it's not a microkernel.  It's starting to be, not a maxi kernel, but still, not micro.



LEO:  A kernel kernel, because most kernels... 



STEVE:  Okay, so...



LEO:  The Mac is still based on a microkernel.



STEVE:  Mach.



LEO:  It was originally Mach.  I think it's now XNC or something.



STEVE:  Well, everything's based on a microkernel.



LEO:  Yeah.  It all started with a...



STEVE:  That's right.



LEO:  Linux has never been a microkernel.  Linux is always a monolithic kernel.  That's, by the way, the opposite of micro is monolithic, which is everything's in it, everything but the kitchen sink.



STEVE:  Yeah, it's kernel bloat.



LEO:  Yeah.



STEVE:  So, okay. We will wrap up with the puzzler for next week.  I don't want people to tweet the answer.  You can talk among yourselves.  If you have some fellow geeks, this might be fun to talk about.  But don't send it to me.  Don't tweet it.  Keep it to yourselves, and we will discuss this next week.  And because what's fun about this is there are some subtleties to it.  So challenge yourself, not only to get, like, the right answer, but the full answer.  So here's the question.  And this was a tweet I received this morning:  "I've often heard you talk about cryptography and prime numbers.  But why can't non-prime numbers be used?"  So think about that.  We talk about...



LEO:  Why can't non - I know why.  Go ahead.  I think I know why.



STEVE:  Don't tell us.



LEO:  I'm not going to tweet it.  I'm not going to Facebook it.  I'm not going to semaphore it.



STEVE:  Just for yourself, it's a self-test.  Why can't we use non-prime numbers?



LEO:  Why can't we use - oh.  I'm going to put my answer in a sealed envelope to prove that I, well, if I'm wrong, then I prove nothing.  But if I'm right, to prove that I knew ahead of time.



STEVE:  Yes.  Now, will this be the Schrdinger cat envelope, where...



LEO:  Yeah, that's right.



STEVE:  Where we don't know what it contains.



LEO:  It's always right, no matter what happens.  No, I think there's a pretty good answer to that question, actually.  That's a good question.  Why does it have to be prime numbers?  Why does it have to be prime numbers?



STEVE:  Yup.



LEO:  Steve Gibson is at GRC.com.  You know that.  That's where you'll find SpinRite.  Make a yabba-dabba doo in his office, anytime of the day or night.



STEVE:  And again, thank you.  There were two, actually, that occurred when I began talking about SpinRite.  I'm sure it was live listeners who were waiting to push the button.



LEO:  Yeah, that's nice.



STEVE:  So thank you very much.



LEO:  That's really great.  Don't wait.  Do it right now.  SpinRite.  You'll also find - that's his bread and butter.  It's the only thing he charges for.  Everything else is free there, including the latest crypto stuff, information on SQRL, the perfect sleep formula, healthful sleep formula.



STEVE:  Never10 is down to 4,200 downloads a day.



LEO:  Yeah.  Well, there's no need for it; right?



STEVE:  I don't know why.  I know.  It's like, I still have LeakTest there, and people get it every day.



LEO:  Yeah.  Hey, well, it's free.  I'm going to take it.  Let's get some more stuff.  Free stuff.  GRC.com.  You can also go to GRC.com/feedback to ask questions.  But probably the best way to do it is go to Steve's Twitter, @SGgrc.  And you can tweet him.  He takes private tweets, if you want to give him a lead, if you work for the Equation Group, whatever, @SGgrc.  You'll also find the audio and human written transcripts of the show at GRC.com.  Steve does that every week out of his own pocket, and I appreciate that, Steve.  And, yeah, SpinRite's there.  We have audio and video at our website, TWiT.tv/sn.  You can also subscribe.



By the way, we've got an update.  Remember Patrick Delahanty told us that there was a script running out of Australia that was attempting to download every Security Now! episode ever?



STEVE:  And going into the future, where no one has gone before.



LEO:  Yeah.  It's still running.  He is looking for Episode 577,043 today.  Not kidding.  This morning...



STEVE:  It's in somebody's closet somewhere.



LEO:  He just ran it and forgot it.



STEVE:  Too bad because it's not going to get #574, this one.  It's shot right past.



LEO:  Oh, that's true, it's gone right past it.  That's the disadvantage of doing that.  That's right.  Because you can't retroactively - oh, I found it.  That one you were looking for.  I found it.  Unless he's written some very good code.  And I hope he hasn't because his memory's overflowed by now.  What else?  I think that's about it.  We'll be back in our regular studio next week.  Although this really worked well, I think.  It's, yeah, looks great, and it was very comfortable for me.  If you want to join us live, you do that every Tuesday at 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  And we'll see you back here next week for Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#575

DATE:		August 30, 2016

TITLE:		Pegasus & Trident

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-575.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, Leo and I catch up with the past week's news including the Dropbox and Opera incidents; a Chinese certificate authority who could not have been more irresponsible; the changing Facebook and WhatsApp information sharing arrangement; the FBI's disclosure of election site hacking; Tavis Ormandy's Dashlane and 1Password vulnerability disclosures, the threat of autonomous weapon systems; WiFi router radio wave spying; and the details behind Pegasus and Trident, the emergency Apple iOS v9.3.5 patch.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  And we are going to talk about the latest security news, including spend some time with that big iOS security flaw, the one that's been around for years.  How does it work?  It's pretty amazing.  Coming up next, as always, on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 575, recorded on August 30th, 2016:  Pegasus & Trident.



It's time for Security Now!, the show where we cover your security and privacy online with the Explainer in Chief himself, Mr. Steven "Tiberius" Gibson.  And today, oh, I'm excited.  I'm really excited for Security Now!.  You notice, by the way, those of you who watch on video - and I know that's a scant percentage of the total.  Most people just listen, and rightly so, since Steve and I are not exactly beauty queens.



STEVE GIBSON:  Talking heads, yes.



LEO:  At best talking heads - that we decided not to move.  We're in exactly the same studio.  Nothing has changed.  I thought, why move?  When you've got perfection...



STEVE:  False alarm.  False alarm.



LEO:  No.  This is the new studio, and it looks pretty much indistinguishable.



STEVE:  Yeah.  In fact, clearly, if this had just changed, and everyone was used to seeing where you had been for the last five years...



LEO:  If I hadn't said anything, yeah.	



STEVE:  ...nobody would pick up on it.



LEO:  All they'd say is, oh, I like the new clock.  That's it.  I'll tell you some things I like that you can't see.  But first of all, the air conditioning works in here.  Very nice.



STEVE:  And was it Lisa who was hot in her office because her AC was...



LEO:  Lisa is so hot, even when she's cold.  She's hot.  No, yes, she couldn't get it right.  It would either be too hot or too - the building we were in was 120 years old, and it was funky.  And the landlord, the previous owner had not maintained it at all.  So it was just falling apart.  We now have a parking lot.  We now have AC that works.  We have - it's just functional in so many more ways, and it's half the rent, so we're saving lots every month.  The downside is it doesn't have that quirky charm.



STEVE:  Quirky charm.



LEO:  If you've ever lived in an old house...



STEVE:  No, I agree. 



LEO:  ...it's the same thing.



STEVE:  In fact, your first studio, frankly, I preferred it.  I mean, it was really wonderful.  This one looks like a studio.  It looks much more like a TV studio which is, like, you know, instead of an environment you had a really - you just sort of had an environment.



LEO:  And that was always my philosophy, both at The Cottage and The Brick House, was a real sense of place, of a clubhouse.  And this is just a TV studio.  But that's fine.  And frankly, all it really needs to be is a radio studio.  And by the way, get ready, because the next incarnation will be me on a boat, and there'll be no video at all.  It'll just be me and you, and we'll be talking on a boat, and we'll be in our 70s, and we can go - it'll be great.  It'll be so much fun.  I'll be, "I'm out here in the middle of the Atlantic, talking to Steve."  Now, this has been a good week, I think, for a security professional.



STEVE:  Oh, yes.



LEO:  What are we talking about this week?



STEVE:  So we have lots of news.  I was going to try to do a Q&A this week, but on Thursday afternoon I tweeted to all of my Twitter followers that Apple had just released an emergency iOS update, bringing iOS to 9.3.5.  And of course like a week before we had gone from 3.3 to 3.4.  Now we were at 3.5.  And so I just wanted to let everybody know that that was there.  My own, I have, I don't know, maybe seven or eight iOS devices, only today have they begun to offer me, proactively offer me an update.  So it's interesting that this, as I had mentioned before, I'm not seeing these devices suggesting that they be upgraded.  If you go into...



LEO:  You can check and see it.



STEVE:  Yes, and then it immediately knows it.



LEO:  Yeah, but it doesn't tell you.  Yeah, that's how Apple does it, which is weird.  They don't bug you.



STEVE:  Yeah.  And, I mean, it's certainly a tradeoff.  Now they are saying, oh, an update is available.  Or there's the little red "1" on the badge of the control panel app.  And it's like, huh?  And then you go in there, and it's like, oh, yeah, okay, fine.  And it does its upgrade.



Anyway, so we're going to talk - the main topic after we catch up with news is the podcast is titled "Pegasus & Trident."  Trident is sort of a play on words because there were three, this "tri," vulnerabilities which were patched after they were found being used in the wild.  And we have a lot to talk about that.  We have, from the Lookout Security guys who did the technical analysis, what they found is really fascinating.



But what is chilling is that they found evidence in the code that this works all the way back to the iPhone 4s.  So it has been probably - and these vulnerabilities only last week got fixed.  And only due to really a coincidence of the fact that somebody who was already on the lookout was prepared for this eventuality and didn't act on basically a phishing attempt to get him to click a link.  Instead, he forwarded the links to Citizen Lab, who looked at it for a couple days, and then they got the Lookout Security guys involved.



Anyway, it's a really interesting story.  And, for example, the links are set to only function once, and that's specifically to prevent the exploit from being easily reverse-engineered.  So it's something, you have to suspect it and capture it the one and only time it will be primed in order to make it work.  So really interesting.



But we had a ton more news.  Dropbox and Opera both handled security incidents responsibly, while a Chinese certificate authority could not have been more irresponsible.  And we have to talk about whether it's not time to start pulling back from this trust everyone, or trust all CAs, philosophy which we have at the moment.  And I know that some of our listeners have experimented with removing questionable-looking root certificates from their certificate root store on their various devices, specifically for this reason.



Then of course we have the news of WhatsApp and Facebook changing their information-sharing agreement, and a little quick something that people can do if they want to prevent that from happening to them.  The FBI discloses two election sites, federal election sites hacked through SQL vulnerabilities.  Tavis, our friend at Google, tweets about Dashlane and 1Password upcoming disclosures.



And then we've got two crazy things from the fringe that were just so, well, kind of fun.  One is an AI professor at UC Berkeley who writes about autonomous, the forthcoming, the upcoming, the soon-to-be-seen autonomous weapons systems that are on the way.  And then a loony-tune, like we need a reality check on this one, the concept of using WiFi radio waves to spy on you, literally because you absorb and reflect radio.  So what can that tell you about moving around the room?  And, I mean, anyway, that appeared in The Atlantic.



We've got one erratum, a little bit of miscellany, and then we'll do our deep dive into Pegasus, which is, by the way, the name of the exploit kit which is offered, essentially under license, from this Israeli "security firm," unquote, security firm, insecurity firm.  And of course Trident with the three exploits.



LEO:  Excellent.  Okay, Steve.  Let's dig in.



STEVE:  So Dropbox sent its long-time customers...



LEO:  Yeah, I got that, yeah.



STEVE:  Yup.  My email said:  "Hi, Steve.  We're reaching out to let you know that if you haven't updated your Dropbox password since mid-2012, you'll be prompted to update it the next time you sign in."  And as it happens, I had, so I guess they didn't tie their mail to last password update.  Maybe they didn't have that metadata in their database.  Of course because I have messed with LastPass, and my Dropbox password is something that no human could remember.



So they said:  "This is purely a preventative measure, and we're sorry for the inconvenience."  And I dug in a little bit deeper and found what they were sharing.  They said:  "If you signed up for a Dropbox prior to mid-2012 and haven't changed your password since, you'll be prompted to update it the next time you sign in.  We're doing this purely as a preventative measure, and there is no indication that your account has been improperly accessed.  We're sorry for the inconvenience.  Our security teams are always watching out for new threats to our users.



"As part of these ongoing efforts, we learned about an old set of Dropbox user credentials" - and then they have in parens - "(email addresses plus hashed and salted passwords) that we believe was obtained in 2012.  Our analysis suggests that the credentials relate on an incident we disclosed around that time.  Based on our threat reporting and monitoring and the way we secure passwords, we don't believe that any accounts have been improperly accessed.  Still, as one of many precautions, we're requiring anyone who hasn't changed their password since 2012 to update it the next time they sign in."



Okay, so now, actually, I'm correcting myself.  This sounds like they do know when the password was changed because there is a requirement upon sign-in, if it predates this, that you'll be forced to make a change.  And I was curious, so I did sign in last week and got no requirement to change my password.  So it looks like they're handling it automatically.  Be nice to know, to be able to read between the lines a little bit more and know, like, where they found what.



LEO:  Yeah, they're not telling us what's going on.  But I understand that because sometimes you'd prefer not to.  Yeah, I didn't get - I just logged in, just to see, because I did get that email.  But like you, I didn't get a prompt to change the password because I've changed it in the last year.



STEVE:  Right.



LEO:  Right.



STEVE:  So anyway, they did everything you could ask someone to do.



LEO:  That's the right way to do it.



STEVE:  Yes, exactly.  Opera had a similar handling, although I sort of got a kick out of the way they disclosed it.  First of all, there's Opera users.  Opera has about 350 million users.  And of that 350 million, they have about 1.7 million who use the Opera Sync, which is a cross-browser synchronization feature.  So a very, very small, like less than half a percent of or around half a percent of users are taking advantage of Opera Sync.



So they wrote:  "Earlier this week, we detected signs of an attack where access was gained to the Opera Sync system.  This attack was quickly blocked.  Our investigations are ongoing, but we believe some data, including some of our Sync users' passwords and account information, such as login names, may have been compromised.  Although we only store encrypted (for synchronized passwords) or hashed and salted (for authentication) passwords in this system, we have reset all the Opera Sync account passwords as a precaution.  We have also sent emails to all Opera Sync users to inform them about the incident and ask them to change the password for their Opera Sync accounts.  In an abundance of caution, we have encouraged users to also reset any passwords to third-party sites they may have synchronized with the service."



So that's nice.  The only glitch here is that they say "We detected signs of an attack where access was gained."  Well, okay.  What they're not saying is that "attackers exploited a vulnerability in our system that allowed them to gain access," which would be more correct.  So, I mean, it's not like you just use enough force in the attack, and it cracks into the database.  As we know, packets are not pointy.  They're all kind of, you know, you look at the pictures, they're kind of square, and they move along.  And so the packets themselves are not dangerous.  It's what they contain.



But the flipside of this is a Chinese certificate authority named WoSign.  And, boy, they're properly named.  Okay.  So get a load of this one.  From some of the commentary I sort of pulled things together.  One of the largest Chinese root certificate authorities, WoSign, issued many fake certificates due to a vulnerability.  WoSign's free certificate service allowed its users - are you sitting down on your ball, Leo?



LEO:  I am.



STEVE:  You're going to want to make sure you're centered for this.  WoSign's free certificate service allowed its users to get a certificate for the base domain if they were able to prove control of a subdomain.  Whoopsie.



LEO:  That's not good.



STEVE:  This means that, if you can control a subdomain of a major website...



LEO:  Leolaporte.squarespace.com, for instance.



STEVE:  Exactly.  Then you can get a certificate from WoSign...



LEO:  For Squarespace.



STEVE:  For Squarespace.com



LEO:  That's not good.  And a lot of blogging services do that.  Blogspot.



STEVE:  Well, GitHub.



LEO:  GitHub, right.



STEVE:  GitHub.io.  And in fact what they found was many certificates for GitHub, Alibaba - which of course is the largest retailer, online retailer - and Microsoft, which of course now has gotten fancy with their logon stuff.



So here's the problem.  After the vulnerability was disclosed to WoSign, they never reported this misuse to the root program as required.  And their audit report didn't include any mention of this, either.  So this has caused some outrage in the community of people who care about the integrity of the CA system.  And so commentators have stated that WoSign lacks the security knowledge needed for operating a CA.  I would argue maybe they just lack the care required to responsibly operate a CA.



In an online thread discussing potential sanctions against WoSign, WoSign as quoted as saying:  "For incident 1, misissued certificate with unvalidated subdomain, total 33 certificates.  We have posted to CT log server and listed in crt.sh.  Here is the URL.  Some certificates are revoked after getting report from subscriber, but some still valid,.  If any subscriber think it must be revoked and replaced new one, please contact us in the system.  Thanks."



So in my own notes here I said I really think we need to start rethinking our default "trust everyone" policy because, as we've talked about often on this podcast, the number of root certificates in our systems has exploded.  Just during the course of this podcast, I remember at the beginning it was 11.  And I hesitate to look.  Last time I looked it was more than 400 individual certificates, any of which our browsers will trust unless they're instructed not to.



So I think what we're going to see, because there is really no sign yet of any replacement for this system, this is the system we have - and in fact at the end of the podcast we will be answering last week's Puzzler of the Week.  And I have a new Puzzler for this week...



LEO:  Oh, good.



STEVE:  ...which involves some unintended consequences of the CA system, to see if anybody - just to sort of give people another little self-test.



LEO:  It's fun to do this.  Every week, I wouldn't mind doing a little bit of this.  It'd be fun.



STEVE:  Well, I'll look for them.



LEO:  If you come up with them, yeah.



STEVE:  Yeah.  So, you know, right now it's like it was with EXEs.  It's like, oh, yeah, download it, run it.  Now everyone's got multiple layers of filters, and we're scanning stuff.  Our precaution level is way up.  Now, executables are tricky because anyone can make them.  Signed certificates are much, you know, maliciously signed certificates, or erroneously signed certificates are rarer, but not nonexistent because we've covered this problem of mistakes being made.  Sometimes they're made by a company that's otherwise responsible.



Anyway, I'll be very surprised if Google, for example, being one of the major enforcers of these sorts of problems, doesn't immediately yank WoSign out of Chrome and suggest that other browser vendors follow because they've violated the terms of their agreement with the industry implicitly and contractually explicitly by not stepping up and behaving in a responsible fashion.  And I would argue that that's a good thing to require, but I don't think it's sufficient.  I think - I know that some of our listeners have experimented with removing or disabling huge numbers of certificates and having no problem.  I mean, I think if I went to a site that required me to be authenticated or required the server I was visiting to be authenticated by a WoSign certificate, I probably clicked a bad link because I don't speak Chinese.  So I probably don't need that.



And the problem is, if they get a certificate for GitHub.io, then that is a place that I would be going.  And I would look at my browser, and it would say, yes, you have a secure connection, when in fact I'm not at GitHub.  So I will predict that downstream we're going to have to see, something's going to happen.  I mean, we could easily - browsers could implement a conditional whitelisting system, much like we have with ads, with like uBlock Origin and so forth, where you selectively say, yes, I want to allow this.



So, for example, you could, if such a thing existed, you could put it in an auditing mode for a couple months where it looks at and, like, counts the use of any root certificates that it ever needs to use during a 60-day period, and you decide that sort of sets your usage profile, then lock that down and say, now require notification, proactive notification, if you encounter a certificate that hasn't already been whitelisted during this learning phase, and decide if that's one that you need to add.  Maybe do it a one-time permission, but don't keep it in your validated cert pool.



So as far as I know, nothing like that exists, even as an add-on, because it does require access to some deep plumbing in the browser.  So it would have to be something that the browser itself would either provide an API for, which they don't currently, or a feature offered by a more security-conscious browser.  But I think we're at the point now where, for some users, that would be a worthwhile tradeoff.



And I know you've talked about it, I think probably on the Sunday show, Facebook and WhatsApp have announced that they're going to get together.  And essentially WhatsApp is going to share its data with Facebook.  This is a turnaround from everything that WhatsApp said because, at the time that this acquisition by Facebook was announced, WhatsApp was very aware of their users' privacy concerns because that's why people were using WhatsApp beforehand.  And so the founder of WhatsApp said, at the time, "Respect for your privacy is coded into our DNA, and we built WhatsApp around the goal of knowing as little about you as possible."  Until...



LEO:  Until Mark Zuckerberg came along, yeah.



STEVE:  Until money.  So, unfortunately, this appears to be no longer so clear.  As I said, they recently announced that they'll be making a change in those policies.  Now, when anyone runs WhatsApp, you should be prompted to acknowledge these terms of service change.  You can decline.  So there's two ways to fix this.  If you haven't been in WhatsApp recently, maybe you already did and say, oh, yeah, yeah, fine, just clicked right through, that's okay.  You can still fix it.



But if you do get prompted because you haven't used WhatsApp since they added this, you can, instead of clicking on Agree, you click on Read More.  And that takes you to a dialogue where you are able to uncheck a checkbox that is labeled "Share my WhatsApp account information with Facebook."  So you can turn that off in a subdialog of the agreement to the new terms and conditions.  Or, if you've already done that without worrying about it, but now you think, okay, I don't want that, in WhatsApp you can go into the settings menu under the account tab, and you'll find the same thing.  It says "Share my account info," which you can disable.  Turn that off.



Oh, and I should mention there's a 30-day grace period.  So they made the announcement saying 30 days from now the floodgates open, but you have to accept the new terms and conditions and at that time have those options set to, which are set by default, of course, because they want everyone to do it, unless they explicitly opt out.  So any of our listeners who don't want that leakage - and I guess one of the big concerns is that WhatsApp has explicitly said that they will be sharing the user's phone number with Facebook.  So, and who knows what else.  But the good news is you can turn that off, if you think, uh, no thank you.



So we had a case of good old SQL vulnerability attack.  The FBI sent out an announcement to all of the states' federal election sites after discovering that Illinois and Arizona had breaches.  So the FBI uncovered evidence that foreign hackers had penetrated, in the announcement it said two state election databases recently.  I think, like, late July was one of them.  And - I lost my train of thought, sorry.  But that bulletin did not indicate which states were affected.



Other people who were familiar with this confirmed that it was Illinois and Arizona.  In the Illinois case, officials were forced to shut down the state's voter registration system for 10 days in late July after the hackers managed to download personal data on up to 200,000 state voters.  So they confirmed that there was a big exfiltration of their voter registration database through the site.



The Arizona attack was more limited.  There was some malicious software that was introduced into the voter registration system, but no exfiltration of data resulted.  So the FBI put out a bulletin which actually had a surprising amount of really good technical information.  I was very impressed that they laid it out.  And what they - I guess what I liked best was that it contained some explicit action items for other IT managers in other states, like specifically what to do, instead of just waving their hands and saying, oh, no, attacks are underway, keep an eye out, they really drilled down.



The bulletin said in late June 2016 an unknown attacker, well, now, or it said an unknown actor, actually it's a little less than unknown because they have the eight IP addresses that the queries came in through, which were logged by the weblog of the system that was attacked.  So they said:  "An unknown actor scanned" - I guess maybe an unknown individual - "scanned a state's Board of Election website for vulnerabilities using Acunetix" - which was the scanning tool - "and after identifying a Structured Query Language (SQL) injection vulnerability, used SQLMap to target the state's website.  The majority of the data exfiltration occurred in mid-July.  There were seven suspicious IPs and penetration testing tools Acunetix, SQLMap, and DirBuster used by the actor, detailed in the indicators section below."



Anyway, so their announcement contained lots of very nice technical detail and, as I mentioned, including the explicit IP addresses that these things came from, probably so that, if somebody wanted to, they could just block them at the border, stick them into a firewall rule and say, you know, under no circumstances do we want to allow any pointy packets from these people coming into our network.  Anyway, I was impressed with the nature of the bulletin.



Last Friday evening, actually at 9:31, I was included in a tweet, or I guess maybe it was a retweet, where Tavis Ormandy, Google's famous bug hunter, who we know a couple months ago worked with LastPass to tighten up the minor problem that was found there, he was - Tavis was responding to @SwiftOnSecurity.  And Tavis wrote:  "I hadn't even heard of True Key.  I have upcoming Dashlane and 1Password vulnerabilities."  Last sentence:  "There's a lot of scary garbage," as he put it.



So we don't have any details.  I'm sure if Tavis has found something like that, he's already in touch with Dashlane and 1Password.  So we won't know until patches are available, assuming that they're able to do it within 90 days.  And of course as we know, LastPass did it, like, that day, within hours.  And so the whole notion of any kind of a timeline of them fixing it and maybe a forced disclosure was short-circuited.  So the takeaway here, for any of our listeners using Dashlane and 1Password, is keep an eye out for any forthcoming updates because you're going to want to jump on that in order to get the benefit of Tavis's findings.



And this, I have two things, I labeled them "From the Fringe," just because, okay, well, you'll see.  And the first, I mean, they're serious.  And, I mean, they're seriously written.  The first one is written by Stuart Russell, who is a UC Berkeley computer science professor known for his contributions to AI.  And I went through the page, and he's got a thing for what he calls "lethal autonomous weapons systems," which he's very concerned about.



So he writes:  "A very, very small quadcopter, one inch in diameter, can carry a one- or two-gram shaped charge.  You can order them from a drone manufacturer in China.  You can program the code to say:  'Here are thousands of photographs of the kinds of things I want to target.'  A one-gram shaped charge can punch a hole in nine millimeters of steel, so presumably you can also punch a hole in someone's head," he writes.  "You can fit about three million of those in a semi-tractor-trailer. You can drive up the I95 with three trucks and have 10 million weapons attacking New York City."  He's a cheery fellow.  "They don't have to be very effective.  Only 5 or 10% of them have to find a target."



He writes:  "There will be manufacturers producing millions of these weapons that people will be able to buy just like you can buy guns now, except millions of guns don't matter unless you have a million soldiers.  You only need three guys to write the program and launch them.  So you can just imagine that, in many parts of the world, humans will be hunted.  They will be cowering underground in shelters and devising techniques so that they don't get detected.  This is the ever-present cloud of lethal autonomous weapons.  They could be here in two to three years."



LEO:  What?  I wish I knew that earlier.  I would have fortified the studio a little more.



STEVE:  Well, yeah.  Wow.  Now, first of all, we know, for example, we've seen pictures of drones trying to fire a gun.  And the problem is that, as Newton explained to us a long time ago, that for every action there is an equal and opposite reaction.  So in order to push anything out the gun muzzle in one direction, the drone is going to get shot back based on the relative mass of these two things substantially, which lowers the muzzle velocity and...



LEO:  Recoil is a bitch, yeah.



STEVE:  Exactly.  And so I don't know about this one-gram shaped charge.  I mean, you'd have to allow this little mosquito thing to land on you and then go off in order to do damage.  But the problem is - it's interesting.  One of the things I meant to talk to you about, and I forgot to, when I was reading the most recent Peter Hamilton book, "The Great North Road," there was a whole bunch of, like, the notion of grid systems, like they sprayed sensor goo, which formed an autonomous intercommunicating grid, in order to link up to something.  And of course was it Daniel Suarez who did the amazing books about like the...



LEO:  "Daemon" and "Freedom."  Oh, and then "Influx," yeah, yeah, yeah, yeah.



STEVE:  The drone hordes.  



LEO:  Yeah.



STEVE:  And, I mean, these are chilling things.  And technically he's not wrong.  So, I mean, there are some technical hurdles to overcome.  You'd need to have a camera on this little thing.  It's got to have smarts.  But, you know, neural networks, and I'm hearing you on many of the podcasts, Leo, talking about AI.  Many of your guests talk about AI being an area of huge expected growth in the future.  We're all hoping that Siri gets smarter somehow.  Maybe Apple could make search work, which would be really wonderful for the App Store, apply some AI there.  But still, you know, these are - this guy's obviously painting a very gloomy forecast.  But there's nothing technically impossible about it.



LEO:  He's counting on the hockey stick.  That's what he's counting on when he says two years.  And that's what, you know, all these AI researchers kind of, when you project that kind of thing, you project an exponential growth at some point which just takes off.  And the AI start building better and better stuff, faster than a human could.



STEVE:  Skynet.



LEO:  Yeah, Skynet.  And then you're left behind in the dust, with the silicon dust.



STEVE:  Well, and it is the case, I mean, I was privileged to be at Stanford's AI Lab in the early '70s, sort of at the birth of that first very optimistic AI effort.  And we had robot arms, and we had vision systems.  And when you turned right to go up this windy road, there was a sign there that said, "Caution:  Robot Vehicle in Operation." 



LEO:  Wow.  And this was the '70s.



STEVE:  Yeah, in '72, '71, '72.  And we all were like, it just sort of seemed, okay, we're going to solve these problems.  And it turns out it's really hard.



LEO:  Yeah.



STEVE:  I mean, it's - now, of course, we've got ridiculous computing power, compared to what we had back then.  But still these are hard problems.



LEO:  It feels like it's going to happen. Just we don't know when.



STEVE:  Speaking of a hard problem, this is now - this is tinfoil hat time.



LEO:  Oh, boy.



STEVE:  The Atlantic had a story that a number of our listeners were worried about and wanted to make sure I was aware of.  It's a little fanciful.  But, well, because extrapolating is dangerous for nontechnical writers, is I think probably the best way to put this.  The story was titled "All the Ways Your WiFi Router Can Spy on You."  Now, we're used to thinking of WiFi routers in terms of packets and firewalls and subnets that are separated and port-forwarding and so forth.  That's not what they're talking about here.



This article says:  "City dwellers spend nearly every moment of every day awash in WiFi signals."  Which we know is true because you take out your phone and look at what's available, and you never don't see any WiFi.  "Homes, streets, businesses, and office buildings are constantly blasting wireless signals every which way for the benefit of nearby phones, tablets, laptops, wearables, and other connected paraphernalia.  When those devices connect to a router, they send requests for information - a weather forecast, the latest sports scores, a news article - and in turn receive that data, all over the air."



And I'm going to skip some of this because we get down to the meat here:  "But it can be used to monitor humans, and in surprisingly detailed ways.  As people move through a space with a WiFi signal, their bodies affect it, absorbing some waves and reflecting others in various directions.  By analyzing the exact ways that a WiFi signal is altered when a human moves through it, researchers can 'see' what someone writes with their finger in the air" - okay - "identify a particular person by the way they walk, and even read a person's lips with startling accuracy."  [Crosstalk].



LEO:  We know about gate analysis; right?  That can be very unique.



STEVE:  That was the one I was going to agree with, yes.  Because there you're talking about very large signals.  But again, in a presumably otherwise sort of prefabricated and established environment, and that's one of the problems.



So this article says:  "Several recent experiments have focused on using WiFi signals to identify people, either based on their body shape or the specific way they tend to move.  Earlier this month, a group of computer-science researchers at Northwestern Polytechnical University in China posted a paper to an online archive of scientific research, detailing a system that can accurately identify humans as they walk through a door nine times out of ten."



So again, they've purpose-built a system that irradiated a region and had sensors capable of detecting that.  The problem is then extending that to a router, which has, like, no imaging capability whatsoever.  It'd be like comparing the imaging array of a camera to a single photo cell.  Well, yeah, so the photo cell can tell you what the ambient room light is.  But you can't point it at the numeral "5," no matter how big it is, and have it tell you what it is.  On the other hand, someone could argue, yes, but "5" has a different amount of black in it than "1."  And so it could, without even knowing what the shape is, if it understood what the limited nature of what it was seeing was, it could still make a guess.  And so that's probably a good analogy for this.



So this writer continues:  "The system must first be trained.  It has to learn individuals' body shapes so that it can identify them later.  After memorizing body shapes, the system, which the researchers named FreeSense, watches for people walking across its line of sight."  And so that's, again, that's a giveaway that this is more than just a router stuck on a shelf somewhere.  "If it's told that the next passerby will be one of two people" - and get that, if it's told that the next passerby will be one of two people - "the system can correctly identify which it is 95 percent of the time."  So it's better than a coin toss.  But it's not able to do this for, like, out of any large population.  There just isn't enough information there.



They write:  "If it's choosing between six people, it identifies the right one 89 percent of the time.  The researchers proposed using their technology in a smart-home setting:  If the router senses one person's entry into a room" - now, see again, they used the term "router," which is the problem.  They write:  "It could communicate with other connected devices - lights, appliances, window shades - to customize the room to that person's preferences."  Okay.  Except that what if the room had a few other people in it, and they were moving around, too?  That is, everything in the room is subject to this WiFi signal.



So again, this isn't vision.  This is one parameter.  You get some doppler shift in the reflected signal so you can tell, like, the speed with which something's moving.  But you can't even reliably tell if it's going towards you or away from you because you could be getting a reflected doppler signal from a far wall, and the person is moving away.  So lots of problems with this.  And I'm going to skip down here to another little bit of interest.



"A pair of MIT researchers wrote in 2013 that they could use a router to detect the number of humans in a room and identify some basic arm gestures, even through a wall.  They could tell how many people were in a room from behind a solid wooden door, a six-inch hollow wall supported by steel beams, or an eight-inch concrete wall" - all of which are transparent to varying degrees to the proper radio - "and detect messages drawn in the air from a distance of five meters, but still in another room."



So anyway, this article goes on, talks about some researchers in 2014 who were able to use WiFi signals to do lip reading by, again, detecting the motions of someone's mouth and doing that within very narrow parameters.  Our listeners will remember that I really liked a technology, I can't remember the name of it now, where it was a radio technology - I think Google was an investor - where you could do things like make a clicking motion with your fingers...



LEO:  Oh, yeah.



STEVE:  ...above it, or like roll an imaginary toothpick between two fingers as a dial.



LEO:  Yeah, Google showed it at Google I/O, yeah.



STEVE:  Yeah, it's very cool.  And I can see the logo, but I don't remember the name.  Anyway, what's so neat about this is that it uses a antenna array to be able to do that.  And so you need what I would call imaging more than - yeah, there it is.



LEO:  Project Soli, S-O-L-I.



STEVE:  Ah, yes.



LEO:  Cool.



STEVE:  Just love it.



LEO:  And never saw anything again.  That was like...



STEVE:  Well, and in fact we're going to be talking about that because I have some update on XPoint and of course supercapacitors and next-generation batteries and so forth.



LEO:  Oh, yeah, that.



STEVE:  Yeah.



LEO:  Oh, yeah, that.



STEVE:  But anyway, I wanted to sort of give a little reality check.  It is absolutely the case that you could stage an environment.  But this article suggests that consumer routers are going to be spying, I mean, it says consumer routers are going to be spying on people.  They're not going to be.  The router is dirt cheap.  The router, for example, there's no way it can get doppler information from the radio signal.  That would blow its mind.  And you absolutely need doppler in order, you know, not just intensity, but motion, in order to pull all this together.  So it's like, yeah, one more thing to worry about, kind of.



But I guess one interesting notion is we've seen, for example, in some spy movies, where a laser interferometer is bounced off a window, and the speech in the room vibrates the window just minutely, but that's enough for the laser interferometer to detect the vibrations and turn it back into sound from a great distance away.  So you could certainly do something like that, where you're using radio rather than this multistage acoustic process.  But again, boy, interpreting any useful signal out of what you would get would be really difficult.



So, one piece of errata.  Last week many of our sharp-eared listeners caught a mistake I made when I was reading verbatim from the technical document about the iMessage attack.  And I remember looking at the number and thinking, what?  But, I mean, I knew it wasn't right, but it's what it said.  I said that that attack could be performed in as little as 218 samples.  Well, the problem is that, when I copied and pasted from the PDF format into the text format, the caret between the two and the 18 was lost.



LEO:  Oh, that's a minor detail.



STEVE:  Yes, 2^18.



LEO:  Yeah, somebody in the chatroom said it, too, and I just didn't want to interrupt.



STEVE:  Yeah, well...



LEO:  I figured people knew.  They knew what...



STEVE:  I would have gone, "Oh, yeah."  It does say here 218 in my notes, but I know that's not right.  And it's funny, too, because, I mean, I read it earlier, and it said 2^18.  And I thought, okay, well, now, that's, what is that, that's 256,000, approximately, because 2^16 we all know is 65,536; 2^17 will be 131,072; and 2^18 will be 262,144.  So again...



LEO:  But you know what?



STEVE:  That's not many.



LEO:  Exactly.  What's the diff?  You're getting a lot, you're going to get that many packets pretty quick; right?



STEVE:  Yeah, it's still - and that was the point.  It is a practical attack.  It's not like it's 2^426.  So anyway, a number of people sent me a tweet saying, "I don't think that's 218."  I said, oh, of course it's not.  So thank you for the correction.  I certainly happily stand corrected here.



A couple pieces of miscellany.  Another terrific dumb router write-up has surfaced, a dumb router configuration guide, this one with lots of information and pictures also.  We talked about the one from - and I'm blanking on it.  I did put - I added the link to the Link Farm page, GRC.com/linkfarm.  This one is at nerdcave.littlebytesofpi.com.



LEO:  Okay, I really like that URL.  Wow.



STEVE:  That's P-I, by the way, LittleBytesofPi.com.



LEO:  Well, of course, yeah.



STEVE:  And that page details both the two-dumb-router and the three-dumb-router configuration.  So the three, of course, is our Y configuration that we have talked about and that has been often used.  And again, as time goes on, in some cases these go under the Security Now! episode number.  In some cases, like in this case, this is sort of for the ages, so it's at the top of the page in its own little Dumb Router Configuration section of links so people can always find it at GRC.com/linkfarm.



Also I got a tweet from a Willie Howe, who said:  "One of your other subscribers wanted me to share my YouTube channel for Ubiquiti products with you."  So, and this guy has a cool Ubiquiti EdgeRouter configuration YouTube channel.  It's YouTube.com/williehowe, W-I-L-L-I-E-H-O-W-E.  And I believe that one is in the show notes under SN-575.  So again, YouTube.com/williehowe, Willie Howe.  And so, for example, he's got - they're, like, 10- or 11-minute videos.  Public WiFi Security, that's actually five different videos, one through five, that ends at "Putting It All Together," so it explains the whole thing.



He did one on a new release of the EdgeOS v1.9, and he notes in there that he was just about to do one on 1.8 when they came out with 1.9.  So he goes through the new features there.  He's got one on blocking traffic at the EdgeRouter, local traffic blocking, and configuring the EdgeRouter for multiple WAN, that is, Internet-side IP addresses, and more.  So I knew that some of our listeners would get a kick out of looking at someone do some walkthroughs for what is actually the replacement for the three-dumb-router paradigm because it's $49, and it's an incredibly powerful little five-port router.



And finally - or actually not, sorry.  The penultimate bit of miscellany, Intel just had their 2016 Developer Forum, and many people there were surprised that there were no announcements about the much-anticipated 3D XPoint status.  It was a year ago that they and Micron jumped up and down and went crazy.  We talked about it just recently, the idea of something that was much faster than flash and much denser than DRAM, so it sort of had a place in between.



And I found really some interesting analysis by someone, Jim Handy, who has a site called TheMemoryGuy.com.  And I liked what he had, the way he phrased it, and he raised an interesting point.  First of all, he characterized the whole system as layered memory.  And we really know, I would say maybe hierarchically organized memory, we know that you have registers in the chip that the processor has instant access to.



Then there's a very complex hierarchy of increasingly slower and larger memory in a series of caches.  So there's an L1 cache, the Level or Layer 1 cache, which, for example, all of the cores in the chip can have simultaneous access to also very quickly, although it's not like a register.  It's not like working 1+1=2, perform the math.  The abstraction is that it is RAM.  So the processor sees everything outside of it as just a huge block of RAM.  The reality is that there's a series of layers.



Typically now we have three layers of cache - Layer 1, Layer 2, and Layer 3; or Level 1, Level 2, Level 3.  And then we have DRAM.  And then you could argue outside, you know, the next layer down is flash, and the layer below that is traditional spinning hard drive.  And what I liked was that Jim suggested that the proper way to think about this 3D XPoint is another layer in between the DRAM and flash because it is much, much denser than DRAM and much faster than flash.  So that fits the requirement of something that would qualify as an additional, as a useful additional layer in the system.



But he wrote, and I really liked this, he said:  "Intel really needs for 3D XPoint Memory to work.  Without it, the performance of future computing platforms won't scale with processor upgrades.  In other words, when a higher performance processor is plugged into the system, that system's performance won't improve because the rest of the system will bog the processor down," meaning its access to memory.  "The new 3D XPoint Memory is the key to preventing this from happening.  Without it, Intel will be unable to migrate customers to increasingly powerful processors that sell for higher prices and reap higher margins for Intel."



He says:  "This is a tough spot for both companies" - meaning Intel and Micron because they've cross-licensed this and jointly developed it - "and there are no indications of any pending breakthrough that will improve the situation.  About all we can do is watch from the sidelines with the hopes that Intel and Micron will overcome their technical problems and get back on track."



So essentially what's happened is, and this is very typical, they're having process problems.  They have prototypes.  They did show prototypes.  They are hundreds of times faster than flash in some cases.  Well, not quite a hundred.  I think it was 1.75 microseconds versus 85 microseconds.  But still, you know, way faster.  The problem is it's very different to make one than to, like, get a whole fab line running; and also not only have one out of every thousand actually work, but have a very high level of good parts out of a wafer of these things.



And the problem is this is new material.  So everyone's really good about working with silicon.  We know how to do that now.  But this is some goo that is in between cross points.  And you've got to lay the goo down and keep it where you want it, and not have it where you don't want it, and figure out how to actually produce this at volume.  So I think there's every reason to believe in the long term it's going to be a good thing that's just not there yet.  And they were optimistic a year ago.  They weren't actually saying much this time.  So, I mean, not even making anymore forecasts.



And against that background I wanted just to note, because I heard you talking about batteries - and I don't remember who you were talking with.  I think it was off...



LEO:  It wasn't on a show.



STEVE:  It was off-camera, but after the show.



LEO:  Yeah, he was a battery researcher.  He was really an interesting guy.  He was from Hawaii.



STEVE:  He knew his stuff, Leo.



LEO:  Yeah, yeah.  It was fascinating.  He was doing really basically empirical battery research.  They were testing stuff.  And of course it took, you know, it's a time-consuming process.



STEVE:  Oh, like how are you going determine cycle life unless you cycle?



LEO:  Right.



STEVE:  And so it's going to take some time.



LEO:  And it really underscored why it's so difficult to get good information about batteries because even this guy, who is as immersed in it as you could be, was unwilling to give me a unequivocal answer about anything.



STEVE:  And you know me, I was very impressed.  I thought, good, you know, he was telling you when he did not know something.



LEO:  Right, right.



STEVE:  Because that's the correct answer.



LEO:  Right.



STEVE:  Is we don't know.  I wanted to mention to you, ever since this is - and I kept forgetting to.  I was very impressed when that third-generation Lenovo X1 Carbon that I got, back when I was worried about Windows 7.1 moving past me, after it had been plugged in for maybe two weeks, it popped up a notice.  And it said, "This thing seems to be living on the AC line.  If this is the way you intend to use it, let's bring the battery down to half."



LEO:  Ooh, interesting.



STEVE:  "Because that will extend its life."  And I was so impressed because that is absolutely true. 



LEO:  Yeah.



STEVE:  There's a thing called NiCad fast charging.  And like those crazy high-performance model cars that zoom around, that are NiCad based, the battery gets hot because the engine, the motor draws so much current that it's essentially one or two ohm dead short.  In fact, I remember them actually winding a motor with coat hanger.  It was, I mean, it's that...



LEO:  Wow.



STEVE:  You know, they want so much torque out of this motor that it's literally a short for the battery.  So, but when the battery runs dead, as it will in 10 minutes, or like after one race it's dead, these guys want to recharge it fast.  So they stick them on a fast charger which just pumps the battery with juice.  And there's a little trick in NiCad battery chemistry where the terminal voltage on the battery will increase until it's charged and then begin to drop.  And so what the fast charger does is sitting there staring at the battery voltage, looking for the first instant that it plateaus, and then it disconnects it, and the battery is charged.



The problem is lithium-ion, that we're all now using because it's got much higher energy density - it doesn't have the NiCad memory problem.  You know, for these guys who were draining their NiCad down to the ground and then boosting it back up to full for the next race, there's no memory problem.  But most of our devices are being used intermittently.  Lithium-ion doesn't have a robust end-of-charge indication.  And all of those, everyone's talked about, remember, the hoverboards catching fire and exploding.  And people's laptops have done that.  That's what happens when you overcharge a lithium-ion battery.



And so there's sort of this devil's bargain being made with everyone who's wanting as much life out of their lithium-ion as possible because the temptation is to get it as close to fully charged as possible, but not more.  If you have a flaky charging circuit, and you overcharge, that's when the lithium-ion melts down - and, I mean, destructively so.  But it is the case that, if you want to store a battery, the way to do it is to, after fully charging it, bring it down about a third, between a third and a half.  The two-thirds full is what I have most reliably seen.  And that's where you want to let it sit.



You don't want to store it fully charged.  They're just not as happy as they are with a partial charge.  And he was right, Leo, relative to, for example, managing the batteries in your Tesla.  Technically, it would be better, because you don't need the maximum mileage, it's easier on the batteries if you don't tax them by giving them a full charge.



LEO:  Right.



STEVE:  Tesla wants to push it full so that you can get as much mileage...



LEO:  Well, they recommend, they actually - on the Tesla app you have a setting.



STEVE:  Nice.



LEO:  Yeah, that says daily charge or range charge.  And they recommend don't fully charge it every - I did it once, and I got a lot of tweets from people saying - posted on Instagram.  They said, oh, no, don't do that.  And so I have it set at something like 80 percent.  But he also suggested charge it every day.  You should keep it charged.  And so I started doing that.



STEVE:  Yeah, there have been people who say, oh, don't leave your devices plugged in.



LEO:  I asked him about that, and he was very clear, that's fine.



STEVE:  Yes.  Don't leave a flaky device plugged in.  But, for example, Apple has figured this out, and Apple stops charging, and then that's not a problem.



LEO:  Don't use a flaky device is probably a better idea.



STEVE:  Yes.



LEO:  Get a device that manages power best.



STEVE:  You and Ian were talking, or I guess Ian mostly, was talking on Sunday about "Halt and Catch Fire."  And I did want to note to our listeners who had watched the first two seasons that, if they had missed it, Season 3 did start last week.



LEO:  Harry McCracken was actually on the set and did a long piece about it.  That's who we were talking with is Harry McCracken. 



STEVE:  Okay, right, right, right.



LEO:  Yeah.  He thought it was amazing.  I mean, he was - I don't know if he saw the shows, but he was really impressed by the verisimilitude of the set.



STEVE:  Yeah.  It's tough for me to make time for it.  What it has turned out to be is, and I wrote in my notes where I said:  "Predominantly character-driven, set in a nominally historical but fictional techie setting, but not particularly compelling characters."



LEO:  Yeah.



STEVE:  That is, it's like, eh, you know, I really don't care about these people.  And a good...



LEO:  That's important.



STEVE:  A good show, they really do want you to care about them.



LEO:  Funnily enough, the thing that bothers me besides that - and I did try to watch it, and I stopped, I haven't seen the third season - the thing that bothers me is the kind of close to but not actually.



STEVE:  Yes, exactly.



LEO:  And it's like, no, that's not what happened.



STEVE:  Historical fiction.  So it's not actual history.



LEO:  Yeah.  And we lived it, so we know what happened.  And so it's kind of - it bugs me in that sense.  It's like a bizarro universe.



STEVE:  Right, right.



LEO:  By the way, good show, just a side note here, I don't know if you've watched it on HBO yet, is "The Night Of."



STEVE:  It just finished, didn't it.



LEO:  Yeah.  And I avoided it when I first saw it because I thought, that's too grim.  And it is grim.  But the acting and the writing is superb.



STEVE:  I had a number of my followers recommend it, and so I immediately - I think I missed the first two.  So I told TiVo - oh, I just did want to mention, I heard you also talking about TiVo.  I do not regret my lifetime...



LEO:  No.  I have two.



STEVE:  My lifetime subscription.



LEO:  I have two.  Just bought them.



STEVE:  I have three.  I have three because I have two minis.  And they all have them.  It is such a good device.  I mean, it's just...



LEO:  Yeah, it really is.  It is the best.  There's no doubt.



STEVE:  It is the one.  And so even if it went belly-up a year from now, I'd think, well, okay.  It would have been wiser not to go lifetime.  But, boy, it's just [crosstalk].



LEO:  It's worth it, yeah.



STEVE:  And I loved your story about Lisa seeing yours and going, "Why do I have this crappy one?"



LEO:  "Why didn't you buy me one?  Why are you making me use the X1?  That's not right."  But it's because it's so expensive.  I mean, once you buy the TiVo and the lifetime subscription, you've spent 700 bucks.



STEVE:  Oh, you're biting a bullet, all right.



LEO:  Yeah, yeah.



STEVE:  But, boy, you know, I watch a lot of cable news stuff, especially during this political season.  And if I couldn't fast-forward through the commercials, I swear, they're just - it's there as an excuse for advertising.



LEO:  Oh, yeah.  They don't even make any bones about it.  That's clearly what's going on.



STEVE:  You can't watch it, like give it your attention.  So you have to have that.  And, boy, that new skip feature does work nicely that it supports.



LEO:  Oh, is that nice, yeah.



STEVE:  I got a nice tweet from someone about something that, believe it or not, I still haven't ever talked about.  The guy's Twitter name is PGP ID 0x01086FDA.  Looks like his name might be Cristian Rasch.  Anyway, he said...



LEO:  Oh, that's a good idea.  Use your PGP ID as your Twitter handle.  What a great idea.  I might change my NIC right now.



STEVE:  That's kind of cool.



LEO:  Yeah.



STEVE:  Yeah, PGP ID.



LEO:  That way people know how to privately reach you.



STEVE:  Yeah.



LEO:  As long as you publish your key somewhere.



STEVE:  "@SGgrc Thank you for supporting Wine as a valid SpinRite platform.  Just purchased my copy, which is currently hard at work."  And I never really talked about how, when you buy SpinRite, you get an executable.  Just one.  Just an EXE.  And what's fun is that, when you run it under Windows, or as Cristian notes, Wine, so Linux or Wine on a Mac, it shows you a graphical user interface.  It says, "Hello, this is SpinRite."  And you then use that to produce boot medium.  You're able to burn a CD, to format a thumb drive and then boot the thumb drive.  So that's sort of the installer, the creator of the bootable media.  But there's only one EXE.



And so after SpinRite creates the boot environment, it copies itself, that same EXE itself, to the device, to the thumb drive or into the CD image.  And when you run that same SpinRite EXE from DOS, you get SpinRite.  So there aren't two things.  There's just one.  And the way I did it is kind of cool because, once upon a time in the early days, when Windows was just beginning to happen, and there was a lot of DOS still being run, Microsoft said, okay, wait a minute.  What happens if somebody runs - we're going to use the .exe.  We're not going to use, like, .win or some other extension for Windows apps.  We're going to use EXE, which is, you know, and DOS had .com for command-style image files up to 64K, which was SpinRite until it outgrew the 64K.



So they were going to use an EXE.  But Microsoft thought, what if somebody attempts to run a Windows EXE from DOS?  Because DOS is where most people, that's where everyone was initially.  So what they did was they actually, they designed the Windows executable so that it had a DOS stub.  That is, it had a DOS program.  And it was a fixed stub.  And when you ran that app under DOS, this little one-liner, it would say, "This program requires Microsoft Windows" to run.  That's all it did.  And it dropped out and came back to the command prompt.  And you'd go, oh, right.  And then you'd launch Windows and run that same EXE in Windows.



Well, what I did was I wrote a Windows app which does the install, and SpinRite itself is the DOS stub.  So when you run that EXE, which is technically a Windows application, in DOS, DOS runs the DOS stub which is SpinRite, and SpinRite runs.  When you run it under Windows, you get the UI that builds SpinRite.  So I've never talked about it.  It's just kind of a fun little hack.



LEO:  That's a nice way to do it, yeah.



STEVE:  It works beautifully, yeah.



LEO:  All right.  Let's continue on, Steve Gibson, and we're going to talk about Trident and Pegasus.



STEVE:  Yeah.  So last Thursday at 3:00 in the afternoon I tweeted to my followers:  "Apple recently pushed an emergency update for all iOS devices.  It has been used against 'targeted victims,' but could see wider use now."  So the message was go get yourself updated.  And as we've seen, it's five days later, and I'm finally seeing iOS devices that are acknowledging that there's an update to be downloaded.  So again, I'm not clear why this wasn't immediately delivered, but it wasn't.  So this is a textbook case of a bad exploit and very responsible handling and management of its discovery.



This begins on August 10th, so what is that, 20 days ago.  Ahmed Mansoor, who is an internationally recognized human rights defender - he blogs; he's a member of the Human Rights Watch's advisory committee; and he's also received some award, sort of like the equivalent of the Nobel Prize of human rights activists.  But he's been harassed for the last five years with various technical attacks on him.



So, as I mentioned at the top of the show, he was already ready to be suspicious, which unfortunately distinguishes him from most people who might be victims of this.  And as we'll see, and as I mentioned at the top of the show, this has been apparently in place for quite a while.  In the reverse-engineered code, they found references that are three and four years old.  So somebody's not happy.  Well, in fact, unfortunately we probably know, we're very sure we know who, that this thing got foreclosed on.



The problem is everything we know would have to suggest that there are other unknown vulnerabilities, and that this company that is making a huge amount of money making these available to governments and law enforcement, they say on ethical basis, since they're making this much money, they're highly motivated to continue finding ways in.



What we have in this case is a really good snapshot of the details that I know our listeners are going to find interesting.  So he receives an SMS text message which immediately made him suspicious.  He did not click on the link.  The next day he received a second similar text.  The messages promised him new secrets about detainees tortured in UAE prisons.  So that's, like, right up his alley.  This was targeted for him.  Obviously they had his phone number, whoever it was, and they were sending him something they believed he would want to know.  And it contained a hyperlink, these messages did, each of them, to an unfamiliar website.



Well, it was unfamiliar to him, but not to the guys at Citizen Lab.  And these arrived on his stock iPhone 6, which was running 9.3.3.  Now, as I mentioned also before, and we talked about a couple weeks ago, we just went to 9.3.4, and now we're at 9.3.5 as a consequence of this.



So rather than clicking on either of those messages' links, he forwarded both messages to Citizen Lab for their investigation.  Two days later - so that was on August 10th and 11th.  Two days later, on the 12th, Citizen Lab brought Lookout Security into the loop for their reverse-engineering and technical analysis, which is very impressive.  I don't - in my raw notes I had a link to their PDF.  It's a 35-page paper.  I will stick it on Link Farm after we're through so that anyone who's interested can go to GRC.com/linkfarm and get the link to the PDF, if anyone's interested, because it was rich in details.



So Citizen Lab brought Lookout Security in for reverse-engineering.  Three days afterwards, on August 15th, Apple was brought in and brought up to speed.  So these guys figured out what was going on, realized how bad this was, and on the 15th brought Apple in.  And then 10 days later, on August 25th, Apple released iOS v9.3.5 to patch and close three previously unknown zero-day vulnerabilities, all of which were used - thus the term "trident" because it was three vulnerabilities in this cyberweapon.



So what do we know?  The malware's been in operation for more than a year - probably, like I saw in some notes, at least there were some 2012 and 2013, so as much as four years - which has enabled it, they wrote, to develop a high degree of maturity.  As a result, the software is capable of exploiting multiple iOS versions, essentially every version of iOS from 7 - there is a test in the software for iOS 7 - all the way up through 9.3.3.  So it would have infected Mansoor's phone.  It would not have infected 3.4, only because the software hadn't quite been updated for the two-week-old version.  But when they removed that test, it then did infect 9.3.4.  So it was just a matter of checking.



It was very much like we were talking about the Cisco PIX firewall the other day, where that malware wouldn't have infected more recent devices, only because it was from 2013.  The versions had moved on, but that compound if-then clause hadn't been updated to handle, just wasn't aware of any versions after it had been minted.



So an excerpt that they found in what they called a "magic table" contained in the kernel exploit portion, which maps addresses in the kernel, shows that the exploit supports versions of the phone from the iPhone 4s all the way up through the iPhone 6s Plus.  So what they produced was an in-depth technical analysis of what they called a "targeted espionage attack," which is being actively leveraged.  And I appreciated what they wrote because they said "leveraged against an undetermined number of mobile users around the world."



That's what we have to realize is that this has been around for years.  This guy, just because essentially they targeted - someone targeted someone they shouldn't have, probably the UAE because he's a problem for them.  He's been jailed, and when he was released from jail $140,000 were stolen from his bank account and so forth.  So he's been subject to a lot of harassment over the years.  So - and I lost my train of thought.



LEO:  You know, what's interesting, I mean, given that this is going on for three or four years...



STEVE:  Oh, right, right, right.  What I wanted to say was that - thank you.  We know of him receiving it.  But it is, as I'll cover in a second, extremely stealthy.  It is beautifully written.  And I hate to use that term for something that is so malicious.  But, I mean, it is professional-grade cyberweapon.  And we know that it comes from an Israeli company.  Is it NFO?



LEO:  NSO.



STEVE:  NSO.



LEO:  Yeah.



STEVE:  NSO Group.  And you mentioned on MacBreak Weekly an Israeli company, apparently owned by a San Francisco-based venture capital firm that are now trying to sell their ownership of NSO Group for a billion dollars.



LEO:  Well, now is a good time.



STEVE:  Okay.  So what this does is when - if he had clicked either of those links, that would have taken him to a web page that - and I'll get into details in a second - that exploited an unknown, very complex, compound flaw in WebKit that gave the exploit a foothold.  And that's one of the three vulnerabilities.  Then the other two were used for the second phase, which was obtaining additional pieces through web queries from the remote server and then installing itself in a persistent fashion.



The problem is nobody - it does jailbreak the phone.  It dynamically, remotely jailbreaks the phone, giving this tool complete carte blanche access across the phone in a way that chilled these guys.  And I'll explain in a second.  But it's also completely stealthful so that nobody would know that this had happened.  Oh, and if something happens such that the exploit cannot function, a different web page is displayed so the user doesn't know that they just dodged a bullet.  And so in no way does it make obvious what has happened.  So, I mean, it is absolutely stealthful.



So nobody, since this has worked on iPhone since 4s, and we know that it's been around for years, and it installs itself persistently and survives reboots and upgrades, there is no way of knowing how many people today are currently under monitoring, being monitored by this.  Well, until updating to 9.3.5.  That sweeps it away and prevents it from happening.  But so I love that they said "an undetermined number of mobile users around the world" because we need to remember it's not just this one guy.  He's the one, he was the last person to be infected, rather than the first person to be infected.



So they write that "Pegasus is professionally developed and highly advanced in its use of zero-day vulnerabilities, code obfuscation, and encryption.  It uses sophisticated function hooking to subvert OS- and application-layer security in voice/audio calls and apps including remotely accessing text messages, iMessages, calls, emails, logs, and more from apps including Gmail, Facebook, Skype, WhatsApp, Viber, FaceTime, Calendar, Line, Mail.ru, WeChat, Surespot, Tango, Telegram, and others."



LEO:  Wow.



STEVE:  And they know this because embedded in this are individual, per app, essentially DLLs.  They're not called DLLs over in Mac land.  But they are dynamically loaded libraries.  This thing uses the phone's jailbroken status to turn off code sign checking, and then it injects these individual modules per app.  So it's got a WeChat hooking module.  It's got a Telegram hooking module, a WhatsApp hooking module.  And, they note, as we've talked about, it hooks it pre-encryption.  So the user is using WhatsApp or Telegram with encryption, or iMessage.  It doesn't matter because what's coming out in the clear at their end and what's going in from the keyboard in the clear is captured before the encryption stage because this thing has inserted little stubs, little hooking stubs, custom-written for each of these different apps.



They said:  "The attack is very simple in its delivery and silent in delivering its payload.  The attack starts when the attacker sends a website URL through SMS, email, social media, or any other message" - and remember, that's another point.  This uses WebKit.  And so that's the general purpose HTML display engine used not only by Safari, but other web browsers.  And it's what gets invoked when an HTTP link is accessed.  So through whatever source, whether someone tweets it to you or sends it to you in email, it ends up acting in the same way.



"Once the user clicks the link, the software silently carries out a series of exploits against the victim's device to remotely jailbreak it so that the espionage software packages can be installed.  The user's only..."



LEO:  Oh, it's not the website they're going to.  So there's WebKit.  WebKit modified renders then a malicious website in that link?



STEVE:  No.  Yeah.  The link itself is innocuous.



LEO:  Oh, interesting.



STEVE:  It was SMS dot and it was web.avs.co or something.  Now, that didn't mean anything to Mansoor, but the Citizen Lab guys instantly recognized this as a domain where they had seen spyware tools operating before.  So they immediately knew this was probably malicious.  So there's a remote server somewhere - oh, and then it had - it was slash and then like a six- or seven-digit serial number.  And the two messages contained different serial numbers.  And these are one-time-use links.



LEO:  Right.



STEVE:  And that's in order to prevent any kind of an analysis post-infection.  So you can get it once, and in clicking it, it disables it at the sending end.  So the remote server sends you the exploit.  In fact, Leo, this is the licensing model.  When someone...



LEO:  They have a licensing model.



STEVE:  Yes.  When some government says "We want to use this," in their documentation, I think it might have been Citizen Lab's write-up, they indicated that someone purchased 900 or some hundred number of infections for X amount of dollars.



LEO:  Oh, my god.



STEVE:  And so you receive a Pegasus workstation which connects you into this infrastructure.  But NSO runs the infrastructure.  They source the exploit from their servers.  So if your check bounces, you don't get any of the information.  So, I mean, so they're an active...



LEO:  This NSO Group really is like a criminal organization, frankly.  I mean, this is just appalling.



STEVE:  Well, yeah, under the guise of political expedience, I guess.  So they say:  "To accomplish [what it does], after jailbreaking the user's phone, the spyware does not download malicious versions of these apps to the victim's device, but rather compromises the original apps already installed on the device.  This includes preinstalled apps such as FaceTime and Calendar" and blah blah blah, the ones I already mentioned, by installing spying hooks into those.



So a user infected with this spyware is under complete surveillance by the attacker because, in addition to the apps that it has specific hooks for, it also spies on all phone calls, call logs, SMS messages the victim sends or receives, and audio and video communications.  And in fact, and in the words of one of the founders of the NSO Group, it turns the phone into a walkie-talkie.



LEO:  Jesus.  How can this be legal?



STEVE:  It's amazing to me.



LEO:  It's amazing.



STEVE:  And again, so get a load of this.  So Stage 1 is the delivery and the WebKit vulnerability.  This stage comes down over the initial URL in the form of an HTML file that exploits a vulnerability.  And so there were three vulnerabilities given:  the CVE-2016, because that's the year we're in, and so these are vulnerabilities 4655, 4656, and 4657.  So Stage 1 is click the link, and it uses a WebKit vulnerability.



Then the jailbreak is Stage 2.  This stage is downloaded from the first stage code based on the device type.  So the user agent in the web query tells the remote server what it is, who it is, what device and technology is making the query.  So it then sends a customized attack package for that device.  So Stage 2 is downloaded as an obfuscated and encrypted package.  Each package is encrypted with unique keys at each download, making traditional network-based controls ineffective.  As we know, if you encrypt the same file with a different key, you get a completely different result.  That's what encryption does.  And so by always encrypting under a new key, you're never able to get any pattern match, and every single instance of the same thing looks completely different.



"Stage 3, espionage software.  This stage is downloaded by Stage 2 and is also based on the device type, 32-bit, 64, et cetera.  Stage 3 contains the espionage software, daemons, and other processes that are used after the device has been jailbroken by Stage 2.  Stage 3 installs the hooks into the applications the attacker wishes to spy on.  Additionally, Stage 3 detects if the device was previously jailbroken through another method; and, if so, removes any access to the device that the previous jailbreak provided, such as SSH."  So it's also jealous.  It says, no, anybody else who's in here, we're kicking you out.  We're taking over.  It's ours; this phone is ours now.



"The software also contains a failsafe to remove itself if certain conditions are present."  And what I loved is the third stage deploys a number of files, and it enumerates them.  The one that caught my eye was ca.crt.  It brings along its own root TLS certificate, which it adds to the keystore.  So on top of everything else, they've installed their own key so that they can get up to other mischief in the future, if they choose.  Now this phone will trust any certificates, signed by them, spoofing any other sites.



So they write:  "The attack works on iOS up to 9.3.4, and the developers maintain a large table in their code that attacks all iOS versions from 7.0 up to and including 9.3.3.  While the code investigated did not contain the appropriate values to initially work on iOS 9.3.4, the exploits we investigated do still work, and it is trivial for the attackers to update the table so that the attack will work on 9.3.4."  As I mentioned before, it's just a function of Apple's been revving iOS at a pace that this malware has, like, stayed just a few weeks behind.



They said:  "One other unique property of this attack is that standard jailbreak detections fail to report that the device has been exploited.  The attack and installation of the spying software is designed to be as silent as possible to the target."  They write:  "Pegasus is well designed in terms of its modularity and efficiency.  For example, the kernel exploits call upon magic tables for each of the platforms that map out kernel memory for each version and phone model.  The code is extremely modular, relative to other malware our researchers have encountered."  And this is Lookout Security talking.



"We found common libraries and common formats with similar naming conventions.  Unlike most malware authors, the code in Pegasus is clean and efficient, with evidence of professional and careful design.  We see evidence of a robust quality assurance process for the development.  Even their first-stage exploit contains both debugging and QA-specific functions of the type one would expect from an enterprise-class software development organization."



And so I just had a couple little notes about these three exploits.  The first one, 4655, is the memory corruption in Safari via WebKit.  They write:  "A memory corruption vulnerability exists in Safari WebKit that allows an attacker to execute arbitrary code.  Pegasus exploits this vulnerability to obtain initial code execution privileges within the context of the Safari web browser.  This vulnerability is complex, and Lookout continues to work on analyzing this vulnerability and will publish additional findings as they become available."



And I thought of you, Leo, because this is address space layout randomization defeat.  4656, kernel information leak circumvents KASLR, the "K" in this case for kernel.  "Before Pegasus can execute its jailbreak, it must determine where the kernel is located in memory.  Kernel Address Space Layout Randomization (KASLR) makes this task difficult by mapping the kernel into different and unpredictable locations in memory.  In short, before attacking the kernel, Pegasus has to find it.  The attacker has found a way to locate the kernel by using a function call that leaks a non-obfuscated kernel memory address in the return value, allowing the kernel's actual memory location to be mapped."



So that's a beautiful example of, as we've said on the podcast, yes, address space layout randomization makes it more difficult.  Everybody has that now.  And they're still getting defeated because, unfortunately, it ups the ante, but it doesn't prevent the problem.  And in this case there was a function whose return value allowed the inference of where the kernel was, and that completely defeated that.



LEO:  Wow.  So much for ASLR.



STEVE:  Yeah.  And finally, 4657, memory corruption in kernel leads to jailbreak.  "The third vulnerability in Pegasus's Trident is the one that is used to jailbreak the phone.  A memory corruption vulnerability in the kernel is used to corrupt memory in both the 32 and 64-bit versions.  The exploits are performed differently on each version."



So again, that's why different packages are downloaded, depending upon the bitness of the target device.  So these guys, it's really four, when you think about it, or more, exploits because there have - so they needed, for the jailbreak, they needed individual ways of jailbreaking differently for the 32- versus the 64-bit code.  So they have both, and they choose the one that they need, depending upon what phone the person is holding when they click the link.  "The vulnerability is complex, and Lookout continues to work on analyzing this vulnerability and will publish additional findings as they become available."



So, and then I conclude by talking about the jailbreak persistence.  They said:  "Once the kernel has been exploited, both exploits perform similar tasks" - that is, either 32- or 64-bit - "to prepare the system to be jailbroken.  They disable kernel security protections, including code signing.  They remount the system partition.  They clear the Safari browser caches to help cover their tracks and then write the jailbreak files, which then give them persistence across reboots and future version iOS updates."  Wow.  So a look into the real world of, I mean, as these guys said, it's enterprise-class, enterprise-grade remote attack on the most secure mobile platform that man has developed so far.



LEO:  Well, I mean, how secure is "most secure"?  I mean, it's kind of meaningless; right?



STEVE:  And that's the problem, exactly.



LEO:  "Most secure" is probably not much more secure than less secure.



STEVE:  Well, as we know, there's policy, and there's implementation.  And so sloppy policy there's no excuse for.  Implementation errors, well, unfortunately, we all want these things to do a lot.  And that makes them complicated.  And, as we know, complexity is the enemy of security.  So, wow.



LEO:  Amazing.



STEVE:  And so I think the takeaway from this is anyone who is a high-value target would need to avoid the use of everything.



LEO:  [Laughing] Ta-da.



STEVE:  Put on a bathing suit and walk into the middle of Central Park and meet somebody who is also in a bathing suit and whisper to each other and cover up your mouth moving so that lip readers can't get you.  I mean, it's the reality.  I'm not worried that much because I don't do anything that anyone wants.  And I exercise all prudent cautions, but I don't stay awake at night.



LEO:  Wow.  Well...



STEVE:  Wow.  Okay, so...



LEO:  Yes.  Now there's Pegasus, the flying horse.



STEVE:  And the problem is I'm sure this was an expensive thing to have happen.  I don't believe these were the only unknown problems.  And I would imagine this company has such strong incentives and such a demand for these tools that the moment this happened they brought their next generation vulnerabilities online, and they're offering something, they didn't have to reprint the brochure.  It still says we'll do the same thing we did before.  Technically they're doing it in a different way.  But I'll bet you that there is still a link that somebody is going to receive next month, or tomorrow, and it'll still take over their phone, still install all this stuff, same modules get installed in Stage 3, all that work's been done.  That's going to be protected because there's going to be some other way in.



LEO:  Okay.  That's good.  You know, it's a lesson to be learned; right?  



STEVE:  I think...



LEO:  What's frustrating to me is that they know about these vulnerabilities for four years, don't say a word to Apple to fix them because of course not, they're selling them.  But who's to stop somebody else from coming along and discovering it and weaponizing it?  Right?  I mean, these guys can't be the only people with the skill set.



STEVE:  No, no.  That's absolutely right.  And so certainly, hats off to Apple.  A 10-day turnaround, I mean, it's not like this is a huge thing to fix.  I appreciate what Rene said, talking about this on MacBreak Weekly.  Certainly they need to be careful.  We've had some disasters where updates have caused phones to stop functioning correctly and that, you know, back in the early days.  We haven't had that happen for a long time.  But so you always have to be careful.  But Apple was, I think, very responsive to this.  In order to go from first notification to pushing a patch out in 10 days across their entire iOS platform, hats off.  The problem is there's probably other problems.



LEO:  Oh, probably.  Almost certainly.



STEVE:  Yeah, yeah.  So last week we left our listeners with a puzzler.  Why do we use primes?  And I said there's a little subtlety to it.  So the best way to explain it is that the security of prime number-based, or prime number factoring dependent public-key encryption, depends upon a one-way function.  The guys who invented this came up with the term "trapdoor," which never really seemed that clear to me, but it's called a "trapdoor function" in cryptography ever since they invented the term in the '70s.  So but it's a one-way function, meaning that it is easy to do, but intractable to undo in the other direction.



And I ran across a nice analogy the other day.  When you're describing this to your non-techie friends, use the analogy of a padlock.  It's easy to close the padlock.  But opening it requires a key.  So a padlock is a one-way function, easy to do in one direction, hard to undo in the other direction.  In the case of math, two very large - and that's the key.  Remember that it's very large prime numbers satisfy this requirement because multiplying numbers of any size is easy.  We've got algorithms that just multiply, and they can be arbitrarily long numbers.  We know how to multiply them.  But then the security entirely depends upon not being able to unmultiply them, which we call "factoring."



So if the numbers multiplied were not prime, that would mean that one or the other or both of these nonprime numbers themselves would have smaller factors.  And what could happen is that it's much easier to find a smaller factor than a larger factor.  It's the size of the factors that is intractable because, despite decades now of very clever mathematicians speaking bizarre languages of math, we have made very little progress on speeding up prime factorization.  It has turned out that is really resistant to any kind of, I mean, and you can imagine it's a huge pot of gold if someone could figure out how to crack a big number into the two numbers that multiplied to get it.  Nobody has figured that out.



LEO:  How big do the primes need to be to be effective?



STEVE:  They're thousands of bits.



LEO:  Yeah.  Is that what we say when we say 4,096 bits?  That's the size of the prime factor?  Or the size of the total, the number?  The number they're factors of?



STEVE:  It's the modulus.  So it's multiplied, and then essentially the division by 4,096 or 2,048 or whatever is what is kept behind.



LEO:  Oh, interesting.



STEVE:  The residue from the modulus.



LEO:  Got it, okay.



STEVE:  So anyway, so the point is, it is the fact that the individual factors cannot be decomposed; that what the cryptographer has to do is decompose the entire thing into two primes.  If they were not primes, if they had other - if those numbers being multiplied themselves had factors, then you could chip away at it.  You could find a smaller factor and then remove that, find the next factor and remove it, and whittle this thing down.



LEO:  The obvious example would be is, if this big number is even, you'd go, oh, well, there's a two in there.



STEVE:  Perfect, yes.  Now it's half as long as it was before.



LEO:  Right, right.  So you multiply two primes together, you've got to get the primes.  There's nothing smaller you can go for. 



STEVE:  Right.



LEO:  That's what I thought.  I'm glad I got that right.



STEVE:  You got it right.  The puzzler for this week...



LEO:  Good.  These are fun.  I want you to do this every week.  Folks, tweet Steve with puzzlers.  I want more of these.



STEVE:  Okay.  So, and this one came yesterday in a tweet from the owner of a company who had a tricky problem.  He listens to the podcast.  He said:  "We're in trouble.  What do you think?"  So a family of network-connected, embedded-style devices having unalterable firmware is hardwired to make TLS connections to a server at this company's publicly available, fully qualified domain name.  So there's a device, there are devices...



LEO:  They sold these devices; right?



STEVE:  ...a family of devices out in the world.



LEO:  And they sold them; right?  And they hardwired the address into the device.



STEVE:  Yes.  And the firmware cannot be altered.



LEO:  Right.



STEVE:  But the firmware only understands how to satisfy and verify SHA-1 hash certificate signatures.



LEO:  Uh-oh.  Oh, crap.



STEVE:  The server these devices are connecting to at the domain name burned into the device's memory is currently serving an SHA-1 cert.  But as we know, when it expires, it will be impossible, and it happens to be a Symantec VeriSign cert, it will be impossible to get Symantec or any other CA to sign an SHA-1 for a standard public fully qualified domain name.



LEO:  Because we're all going SHA-2.



STEVE:  Exactly, SHA-256.



LEO:  256.



STEVE:  Those are the only certs, as of midnight of last year, or January 1st of this year.  So no CA will issue an SHA-1 signed cert in 2016 or after.  Is there anything this company can do, any trick that can be played externally to satisfy the needs of this unmodifiable hardware to allow it to continue to function?



LEO:  And kids, this is why you don't lock down the firmware on your IoT device, and you provide an update mechanism.



STEVE:  Exactly.  It's a classic example of whoops.



LEO:  Wow.



STEVE:  Yeah.  So there is no update for this.



LEO:  So you need to somehow spoof - the address is written in stone.  And of course your cert...



STEVE:  Oh, you want to do this now, Leo?



LEO:  No, no, no, I'm just thinking.  I just want to clarify the problem.  I'm not going to solve...



STEVE:  Okay.



LEO:  Believe me, I ain't solving this one.  You'd have to somehow still function with a nonfunctional cert, basically.  Your cert's going to expire.



STEVE:  Yes.



LEO:  And I presume that the device requires a secure connection to operate, right, it's going to balk.



STEVE:  Correct.



LEO:  It's going to say, well, you're not secure.  Okay, stupid question.  Can you set the time on the device?  Okay.  I'm not going to ask you more questions.  Let's presume not.  The answer obviously is not setting the device into - putting the device in 2009.  Hmm.  Interesting.  You can't modify the device.  You can't modify the URL.  It needs be a secure connection.



STEVE:  It's burned into this thing that does not have it firmware updated.



LEO:  But sometime soon they're not going to be able to go back to VeriSign and say I need a new cert.  It'll have to be - it won't be an SHA-1 cert.  That's a good one.



STEVE:  So think about it for a week.  We will discuss it.



LEO:  Oh, I know.  You go to Wo.co.  



STEVE:  Yes.



LEO:  They'll give you an SHA-1 cert.  Steve Gibson's at GRC.com.  That's his home on the Internet, the Gibson Research Corporation.  If you go there, just do us a favor, make a yabba-dabba doo happen.  Buy a copy of SpinRite, the world's best hard drive maintenance and recovery utility.  That's Steve's bread and butter.  And while you're there do take advantage of all the freebies.  Find out about SQRL; get some Perfect Paper Passwords; check your shields, are they up or down; all of that.  Including this show.  He's got audio of the show.  And of course transcripts.  Give it a couple of days.  Elaine has to write these, so it takes a couple of days after the show.



STEVE:  Yeah.



LEO:  You can find 64Kb audio at his site.  You can find that and video at our site, TWiT.tv/sn.  Otherwise they're identical.  They're the same files.  And we also make sure that they're available on all your favorite podcatch apps, including the TWiT apps, which are on every platform - Windows and Mac and iOS and Android and Roku and everywhere you want to be.  There's even five different Apple TV apps.  And you just go to Security Now!, you could sit there and watch it in the comfort of your own home.  Don't miss an episode.  This is a good show.  Now, we might do questions next week.



STEVE:  Let's hope.



LEO:  Let's hope.



STEVE:  Because otherwise a catastrophe, only a catastrophe will keep us from doing a Q&A.



LEO:  Right, that's a good point.  That's a good point.  Security willing.  So go to - he's on Twitter, @SGgrc.  You can always tweet him there.  You can also go to GRC.com/feedback and ask your questions, and we'll take the best ones, the most commonly asked, and answer them next week.



Steve, lots of fun.  And I love the stumper.  And I have no idea at all.  The last week one I thought was - that was easy.  This one, I don't know.  There's a clever way, though, huh?  All right.



STEVE:  Could be the Kobayashi Maru.



LEO:  Ooh.  Mmm.



STEVE:  Could be.



LEO:  Could be.



STEVE:  Could be.



LEO:  No.  You wouldn't do that to us.



STEVE:  We'll see.  Stay tuned.



LEO:  Steven "Tiberius" Pike.  By the way, anniversary; right?  Next week the 50th anniversary of the launch of "Star Trek," I believe, 1966.  Is it September?  I think it's in September.  I'm not sure exactly when.  Denise Howell tweeted it.  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#576

DATE:		September 6, 2016

TITLE:		Flip Feng Shui

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-576.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the continuing woes of WoSign.  Autonomous micro-recon drones turn out to be real.  A new crypto attack on short block ciphers prompts immediate changes in OpenVPN and OpenSSL.  We introduce a new Security Now! Abbreviation, "YAWTTY," Yet Another Way To Track You.  We continue with discouraging social engineering experiment, another clever USB attack, a bunch of fun miscellany, and a look at the weaponizing of Rowhammer with "Flip Feng Shui," the most incredibly righteous and sublime hack ever, ending with our  follow-up to last week's Security Now! Puzzler.



SHOW TEASE:  It's time for Security Now!.  More troubles at WoSign.  Mozilla's thinking about what they're going to do next.  A microdrone reconnaissance tool.  And how your smartphone's light sensor could help track you.  Plus we'll take a look at something, that Rowhammer attack they're calling "Flip Feng Shui."  How it all works, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 576, recorded Tuesday, September 6, 2016:  Flip Feng Shui.



It's time for Security Now!, the show where we cover the privacy and security of your systems online.  It is a dangerous world out there; but, boy, thank goodness we have this guy on our side, Steve Gibson of GRC.com.  Hey, good morning, or good afternoon, Steve.  How are you?



STEVE GIBSON:  Hey, Leo.  Great to be with you again as you get yourself prepared for a trip.  Do we have you next week, but then not for a couple weeks after that?



LEO:  Yeah, let's see.  Next week would be the 13th, but not - yeah.  So one week.  And then I think Father Robert, I'm not sure if - Father Robert, I think, or maybe - I'm not sure.  We have to figure out which host.  It's either Jason, Megan, or Robert.  I'm not sure.  I'm taking two weeks.



STEVE:  [Crosstalk].



LEO:  Yeah, well, it has to be somebody who can read ads, frankly.  They have to be approved for doing the ads because we don't ever want to make you do that.  So on the 13th I'll be here.  The 20th and the 27th I will not.  And nor will I be back on October 4th because that's the day we're flying home.



STEVE:  Okay.



LEO:  So I'll miss three episodes of this show.	



STEVE:  Okay.  And I am recording one of them with Father Robert.  We've already arranged.



LEO:  That's right, because he's not here for one of those weeks.



STEVE:  Right, right.  



LEO:  Okay.  Yeah.  Sorry.  And then I'm thinking about doing something nutty.  I don't know if you heard Windows Weekly earlier, but Mary Jo Foley convinced me maybe not to bring any technology with me on the trip.



STEVE:  Yeah, uh-huh.



LEO:  You sound skeptical.  Why ever so?  Well, I have to bring a camera.  I'm going to bring a digital camera.



STEVE:  You'll certainly have a camera.



LEO:  So I don't mean that.  But, I mean, not bring a laptop.  Not bring a tablet.



STEVE:  But, I mean, even before the show you were talking about, well, maybe I'll need this phone as a backup for my main phone in case...



LEO:  I have to have a phone.



STEVE:  ...that main phone does, you know.  So it's like, okay, there's an escalation already beginning.



LEO:  I'm already - I'm bargaining.  It's called bargaining.



STEVE:  Right.  Isn't that one of the stages of acceptance?



LEO:  Yes, bargaining.  But maybe if I just bring - no, I have to bring a phone for safety purposes.  I'm going to bring a Google 5 phone because they have international calling.



STEVE:  Oh, that is a fabulous rationalization.  It hadn't occurred to me before.



LEO:  Well, yes.



STEVE:  You need it for safety.



LEO:  Safety.  But I don't plan to turn it on.



STEVE:  So you could hit somebody over the head with it?  Because it'll bend, you know.



LEO:  You know, actually I've used it.  In Venice we got lost because it's a maze, and all the canals look the same.  So then you fire up the phone, you fire up Google Maps, and you get your way, you make your way home.  So for that, or if I'm, you know, I've fallen and I can't get up, I can call 911.



STEVE:  You could do that on your watch, though, couldn't you?



LEO:  I'm not going to bring a smart watch, either.



STEVE:  Wow.



LEO:  Bring one phone.  The only reason the backup...



STEVE:  Now, are you a watch wearer?  Will you bring a dumb watch or no watch?



LEO:  No, I - oh, actually, boy, if I don't have a phone, how am I going to know what time it is?  I might have to wear a watch.



STEVE:  The point of being on a vacation is it doesn't matter what time it is.



LEO:  Well, it matters a little bit because there's excursions, and there's massages.  You've got to keep track of the massages, dude.



STEVE:  You're highly scheduled on your vacations.



LEO:  You know, the worst thing was reading materials.  But I could bring a Kindle, or I can bring a - actually, I'm thinking of bringing a book, a physical book.



STEVE:  Love my Kindle.  The Kindle is just...



LEO:  Kindle's nice because it's small and light.



STEVE:  Yeah.



LEO:  But what if I bought a really thick book?



STEVE:  Well, that you could hit people over the head with for security.



LEO:  And then I was thinking, well, maybe I'll bring an iPod.  You know, an old iPod doesn't have any - what I'm more worried about is, like, checking social media, sending pictures on Instagram, stuff like that.  What if I didn't do any of that for two and a half, three weeks?  Whew.  I might not ever do it again.



STEVE:  Wow.  



LEO:  Just a thought.



STEVE:  Well, you know, there have been people, I mean, I don't understand this because I look around, and I see people who, with their family...



LEO:  Live on their phone.



STEVE:  A family at dinner, all four of them have phones.  And this is even post-Pokemon Go.



LEO:  No, it's more common than not.



STEVE:  Yeah, it is.  And it's just like, they're not having a conversation.  They're all into their feeds of one sort or another, or [crosstalk] they're doing.



LEO:  I thought it would be good for my marriage, good for my peace of mind.  I could see the sights.  I don't know.  It's crazy talk, isn't it.  What is Flip Feng Shui, and why are we talking about it today?



STEVE:  Well, yes.  "Flip Feng Shui" is the title of today's podcast.  This is without...



LEO:  People are, by the way, timing their SpinRite purchases to hit on Tuesday afternoon.



STEVE:  I always appreciate it.



LEO:  Yeah, that's nice.



STEVE:  This is, without a doubt, the most righteous, sublime hack we have ever covered.  It is multilayered, incredibly clever.  And I wanted to do a Q&A this week, but this came along, and it's like, okay, stop the presses.  This is just - this is too fun.  And it's complicated.  But I know that our listeners are going to get a kick out of it.  Basically it is the weaponizing of Rowhammer, which we talked about, it was March 2015, so about a year and a half ago we covered Rowhammer.  I will review what Rowhammer is and then explain how a group of researchers managed to use Rowhammer to exfiltrate the private key from other processes sharing the same cloud server as them.  It's just amazing.



But we have a lot of other stuff to talk about.  We've got the continuing woes of WoSign.  It turns out that autonomous micro recon drones are real.  A new crypto attack on short block ciphers has prompted an immediate change in OpenVPN and OpenSSL.  We have a new Security Now! abbreviation.  We're officially unveiling YAWTTY.  



LEO:  Carefully.  What the hell?



STEVE:  Well, that's how you would pronounce it:  Y-A-W-T-T-Y.  YAWTTY.  That's Yet Another Way To Track You.



LEO:  Okay.



STEVE:  So we have the first officially designated YAWTTY.  Then we have the results of a discouraging, or just the discouraging results of a social engineering experiment.  Another clever way for USB to attack our systems.  A bunch of fun miscellany.  And I did get a couple questions that I had stumbled upon answered there.  And then we're going to do the serious deep dive into Rowhammer.



And I almost forgot, of course we have the follow-up to last week's puzzler of what to do if an Internet appliance that does not allow itself to be modified in any way and only knows how to verify and approve certificates signed with SHA-1, what do you do in the future, or even soon, when any server certificate that it needs to access cannot be renewed as an SHA-1?  So we will give some ideas about that, too.  So, yes, all kinds of fun stuff.



LEO:  It could be pronounced YAWTTY.



STEVE:  But that's not nearly as much fun.



LEO:  Okay.  Okay.



STEVE:  YAWTTY.  Yeah, I guess it could, yeah.



LEO:  YAWTTY.



STEVE:  Except that TTY is the official abbreviation for teletype.  And we used to call those "titties."



LEO:  Really?



STEVE:  Yeah, TTY, that was the official term.



LEO:  I was hanging around with the wrong people.  I had no idea, TTYs.  I just call them TTYs because that's pretty much as quick as the other one.



STEVE:  Well, you know, we've got JIF and GIF, and so now we've got TTY.



LEO:  YAWTTY.  Oh, lord.  Flip Feng Shui.



STEVE:  So we need to look a little bit, I think this will be interesting to people, at the sort of behind the scenes of the process that browser vendors go through in dealing with problems with certificate authorities.  After, and we talked about this last week, the revelations that this Chinese CA WoSign had woefully poor signing security policies, a thread was created in the Mozilla Dev Security Policy group which had 155 posts from 34 people, many of them notable in the industry.  And the initial posting by Mozilla, I think, really helps to clarify sort of where they stand.



And I know that I've had some feedback from our listeners since we talked about it who are taking the issue of having certificates trusted from authorities that they probably just have no need for.  And that's the problem is we have this, as we've said, this blanket "trust everyone," well in excess of who we actually need to trust.  And everyone knows that's the wrong way to do things.  That's like having, in the old days, where you had a firewall that was open, except you would block the ports that people were using to attack you.  It's like, no.  Flip that around.  Block everything, and then open the ports for the traffic that you know you need.  That's the way to do it.



So we're now sort of still limping along with the reverse of that, sort of the equivalent of a trust everybody, respond to problems approach.  And it'll be interesting to see when that changes.  I think it probably has to because there is a delicate line that a browser vendor is walking because certificate authority systems and solutions, companies, are commercial entities that are typically for-profit, Let's Encrypt being a notable exception.  And Let's Encrypt has put pressure on other CAs to create, to arrange somehow their own free certificate solutions.  So basically that lowest level of validation, the domain validation, where all you're doing is proving ownership of a domain, that's now no longer something that a certificate authority can expect to profit from.



But of course there are reasons to have much better validation.  And I think that's only going to get stronger, that is, these reasons for that are going to get stronger in the future.  So what that means is that a browser vendor has a great deal of power because, as we move from HTTP to HTTPS, having a certificate for a website is no longer optional, and the website needs to get it signed from a certificate authority that can vouch for the identity of the website.



So what that means is that it's no longer, well, the site works except you can't do something without a certificate that is recognized.  Increasingly, it's nothing works if a server isn't issuing a certificate that is trusted.  So what this means is that the web browsers have a huge amount of power.  And they recognize they have an amazing amount of power essentially over the economic well-being of CAs because, if a browser decides it's going to pull its trust from a certificate authority for that browser, in a world where HTTPS is now de rigueur, that CA is in serious trouble.



So Mozilla wrote to sort of create a foundation for and to explicitly ask for comments.  And what I liked about this was this is more information than we've had before.  They wrote:  "Several incidents have come to our attention involving the CA WoSign.  Mozilla is considering what action it should take in response to these incidents."  And notice it's plural.  We actually have three, not just one.



"This email sets out our understanding of the situation.  Before we begin, we should note that Section 1 of the Mozilla CA Certificate Enforcement Policy says:  'When a serious security concern is noticed, such as a major root compromise, it should be treated as a security-sensitive bug, and the Mozilla Policy for Handling Security Bugs should be followed.'  It is clear to us," they write, "and appears to be clear to other CAs based on their actions, that misissuances where domain control checks have failed fall into the category of 'serious security concern.'"



So the first incident.  And unfortunately they decided to number them from zero, which is just confusing.  It's like, sometimes it's fun.  Sometimes it's appropriate.  Not here.  So, okay.  For example, we should have had a zero with the podcast.  But at least now our podcast number is actually the podcast number.



LEO:  We didn't really think about that, did we.



STEVE:  No.  Anyway, so incident zero, which I wrote as "first incident" in my notes because that's annoying, said:  "On or around April 23rd of 2015" - okay, so a year and a half ago - "WoSign's certificate issuance system for their free certificates allowed the applicant to choose any port for validation."  Meaning, like, 8080 or 8090, that is, not forcing 443 for validation.  "Once validation had been completed, WoSign would issue certificates for that domain.  A researcher was able to obtain a certificate for a university by opening a high-numbered port" - in this case greater than 50,000 - "and getting WoSign to use that port for validation control.  This problem was reported to Google, and thence" - and thence?  Thence.  Okay.  Maybe they should number from zero after all - "to WoSign and resolved.  Mozilla only became aware of it recently."



So they said:  "Before the recent passage" - and this gets into the CAB Forum proceedings - "passage of Ballot 169 in the CAB Forum, which limits the ports and paths which can be used, the Baseline Requirements said that one acceptable method of domain validation was 'having the applicant demonstrate practical control over the fully qualified domain name (FQDN) by making an agreed-upon change to information found on an online web page identified by a uniform resource identifier (URL) containing the fully qualified domain name."  Which is to say, for example, I want to get a certificate from DigiCert, and so they give me something to put at GRC.com.  Then I say, "What you gave me is there."  Then they go fetch it from GRC.com and go, okay, yes, you're validated.  And that is the protocol, for example, that Let's Encrypt uses for their automated system.



So they continue:  "This method, therefore, did not violate the letter of the baseline requirements," that is, that WoSign was not doing any port restriction and allowed a high-numbered port to be used.  "However, Mozilla considers the basic security knowledge that ports over 1024 are unprivileged" - remember that only processes running as root are able to open ports below 1024.  Users can open ports above.  So just any unprivileged app running on a server can set itself up as a web server on that machine, and that's what this university student did in order to demonstrate this problem.



So, however, "Mozilla considers the basic security knowledge that ports over 1024 are unprivileged should have led all CAs not to accept validations for domain control on such ports, even when not documented in the baseline requirements."  So they're sort of saying, yeah, they should have known.  But, okay, technically maybe not.



Second point:  "The misissuance incident was not reported to Mozilla by WoSign as it should have been, and the misissuance incident did not turn up on WoSign's subsequent baseline requirement's audit," also as it should have.  That's the first problem.



Second problem:  In June of 2015, so a couple months after that, "an applicant found a problem with WoSign's free certificate service, which allowed them to get a certificate for the base domain if they were able to prove control of a subdomain."  And that's what we talked about last week.  "The reporter proved the problem in two ways.  They accidentally discovered it when trying to get a certificate for med.ucf.edu and mistakenly also applied for www.ucf.edu, which was approved.  They then confirmed the problem by using their control of  theiraccount.github.com to get a cert for github.com, github.io, and www.github.io.



They reported this to WoSign, giving only the GitHub certificate as an example.  That cert was revoked, and the vulnerability was fixed.  However, recently they got in touch with Google" - and this is why this became in the news just a couple weeks ago - "to note that the ucf.edu cert still had not been revoked almost a year later."



So Mozilla notes three things:  "The lack of revocation of the ucf.edu certificate, still unrevoked at time of writing, although it may have been by the time of this posting, strongly suggests that WoSign either did not or could not search their issuant databases for other occurrences of the same problem."  Meaning that they should have been - a responsible CA in realizing they had a problem would have retroactively or retrospectively examined their entire past for other possible exploits of that vulnerability and then revoked those certificates.



LEO:  Which means there may be many, many, many, many; right?



STEVE:  Yes, yes.  "Mozilla considers such a search a basic part of the response to the disclosure of a vulnerability which causes misissuance, and expects CAs to keep records detailed enough to make it possible."  I mean, that seems like a clear requirement for having as much responsibility as a CA does.



Second point:  "This misissuance incident was not reported to Mozilla by WoSign as it should have been."  And, finally, "This misissuance incident did not turn up on WoSign's subsequent baseline requirements audit."



And, finally, the third incident:  In July of 2016, so last month, "it became clear that there was some problem with the StartEncrypt automatic issuance service recently deployed by the CA StartCom.  As well as other problems it had" - and actually we discussed those about a month ago - "which are outside the scope of this discussion, changing a simple API parameter in the POST request" - oh, this is what we discussed - "in the POST request on the submission page changed the root certificate to which the resulting certificate chained up."  Okay.  This is different than what we talked about, but this is obviously related.



LEO:  Geez.



STEVE:  But basically they were trusting any parameters that the page returned to them, which meant it was trivial for someone to generate fraudulent posts with parameters they specified, rather than that they had received in a page from the remote server, from the CA's server, and get up to all kinds of mischief.  In this case, you could change the root certificate, which the resulting certificate was chained up to.



"The value '2' made a certificate signed by StartCom Class 1 DV [domain validation] Server CA, but a '1' selected WoSign CA Free SSL Certificate G2, and '0' selected CA [as the name], another root certificate owned by WoSign and trusted by Firefox."  So, and what we now know as a result of additional information, is that WoSign quietly acquired StartCom some time ago, which explains this comingling.



LEO:  Oh.



STEVE:  And so StartCom apparently, in some sort of merger of technology or who knows what, added these features.  Or maybe it's WoSign's code which StartCom added their, you know, WoSign had zero and one, and StartCom now has two.  So they may actually all be issuing, after this acquisition, through WoSign, yet having the surface on the face of StartCom, unless you change a parameter in the POST, in which case you can have your cert signed by, you know, name...



LEO:  Anybody you want.  Anybody.



STEVE:  I wonder what number three does.  Anyway:  "Using the value '1' [Mozilla writes] led to a certificate which had a notBefore date" - which is the usage start date - "of the 20th of December 2015."  Okay, so December 20th, 2015.  That's, what, 11 days before the end of SHA-1 could be generated.  And, okay.  Oh, and it was signed using SHA-1.



So Mozilla says:  "The issuance of certificates using SHA-1 has been banned by the baseline requirements since January 1st, 2016.  Browsers, including Firefox, planned to enforce this by not trusting certs with a notBefore date after that date."  Now, see, because a notBefore date is the issuing date.  And so the point is that, even now in 2016, if you fudged that POST parameter to a "1," so that you've got WoSign CA free SSL certificate, you would get a notBefore of December 20th, 2015, and SHA-1, clearly designed in order to fudge the system, that is, to allow, I mean, the only reason you would set a notBefore date like that is to allow for some calendar flop.  So you don't want it to be like December 31st.  You want to push it back a little further, just so that calendars and clocks and things being a little bit off don't cause a problem, but specifically so that you can issue valid SHA-1s in 2016, which is clearly what they were doing.



So Mozilla continues, saying:  "But in the case of Firefox, the fix had to be backed out."  Oh, Firefox planned to enforce this by not trusting certs with a notBefore date after January 1st, 2016, meaning any certs issued in 2016 or after.  "But in the case of Firefox, the fix had to be backed out due to web compatibility issues."  Which is interesting in itself.  "However, we are considering how/when to reintroduce it, and CAs presumably know this."



Another point:  "The issuance of backdated certificates is not forbidden, but is listed in Mozilla's list of problematic practices.  It says, 'Minor tweaking for technical compatibility reasons is acceptable, but backdating certificates in order to avoid some deadline or code-enforced restriction is not.'  WoSign deny that their code backdated the certificates in order to avoid browser-based restrictions.  They say:  'This date is the day we stop to use this code.'  If that is true," writes Mozilla, "it is not clear to us how StartCom came to deploy WoSign code that WoSign itself claims to have abandoned."



Then they say:  "It seems clear from publicly available information that StartCom's issuance systems are linked to WoSign's issuance systems in some way.  Nevertheless, it should not have been possible for an application for a cert from StartCom to produce a cert signed by WoSign."  So this whole notion of cross-domain CAs makes everybody a little uncomfortable.



And, finally:  "This misissuance incident was not reported to Mozilla by WoSign as it should have been.  Taking into account," they conclude, "all these incidents and the actions of this CA, Mozilla is considering what action to take.  Your input is welcomed."



LEO:  Cut them the heck off.



STEVE:  Yeah, exactly.



LEO:  I mean...



STEVE:  And so the reason I gave that rather elaborate introduction is that this, you know, is Mozilla doesn't want to hurt this company, yet they want to protect their users.  And so it's a balance; you know?  WoSign is in business.  And so what I think this really means is that this has to be done responsibly.  So clearly, so you can see what they're doing here is laying out their case to the public, saying here are all the problems.  What do people think?  And again, 155 posts from 34 different authors responding to what they think, so...



LEO:  Does anybody say, "Oh, don't worry, just forget it?"  Probably not, yeah.



STEVE:  So I got a kick out of this.  We were talking about the autonomous drone horror scenario of millions of drones in a semi-tractor-trailer, or three of them, actually, being opened up on the shores of New York somewhere, and then flying into the city and wreaking havoc.  It turns out that they actually exist.  Not weaponized, but this was interesting.  There's a company, a San Diego, California-based company called Shield AI - they're a tech firm specializing in mini reconnaissance quadcopters - which has just been awarded a million-dollar contract to provide drones that scour urban battlefields and beam back critical information to the U.S. Army.  And I put in parentheses here in my notes, "Hopefully not U.S. domestic urban battlefields."  Presumably they mean war zones, urban war zones in the Middle East.



LEO:  I don't think they're making a distinction, really. 



STEVE:  Yeah, I know, and that's of course a concern because these little things - well, so anyway, Shield AI's mission statement suggests their flying machines can "help solve the intelligence deficit..."



LEO:  Oh, yeah.



STEVE:  Uh-huh, "that can often mean the difference between life and death for military personnel dropped into densely populated war zones.  A notice on the U.S. business procurement website, FedBizOpps, reveals the company has recently been contracted by the U.S. Army and Naval Special Warfare Command to work on autonomous tactical airborne drones.  There is little detail in the $1 million contract awarded by the Defense Innovation Unit Experimental" - so that's DIUx - "the new tech-focused outfit tasked with gaining the technological jump on America's enemies."  This DIU is a new government group, sort of the equivalent of a DARPA back in the day, but one that seems a little more defense focused, even though the "D" in DARPA was defense.  Anyway, so this is a "nine-month prototype project in the area of autonomous tactical airborne drones."



And so on the site there's a video which shows this thing buzzing around.  And it sort of gives a sneak peek into what Shield AI has done and demonstrated in order to be awarded this contract.  It shows a microdrone which is launched simply by someone tapping on the screen of a smartphone, which takes off and, with no remote control, no piloting, and full autonomy, maps the narrow corridors of a building.  And to me it looked like, I'm sure it was, a storage rental facility because it was those long corridors of the rollup steel doors, you know, inside.  And it produces a full map of the facility without any human assistance.



LEO:  I mean, this is great.  If you're, I mean, geez, if you're getting landed in an urban combat situation...



STEVE:  Yes, yes.



LEO:  It would be - the fog of war is dangerous.  It'd be great to have.



STEVE:  Yes.  And imagine just like turning a bunch of these loose and having them fly out in different directions, especially if they're a grid, and they're able to talk to each other so that they're not bunched up.



LEO:  It's an inevitable technology.



STEVE:  Yeah.



LEO:  But the problem is, of course, then you contemplate, well, how might it be used domestically?  And if you say, "Oh, they'd never," the city of Baltimore just got busted for secretly surveilling the entire city, but with Cessnas, not drones.  But flying Cessnas and surveilling the entire city without disclosure.  And, you know, this is going to happen.



STEVE:  Well, and we have covered stories, or, yes, the press has covered stories of our military industrial complex actively marketing that technology to municipalities.  You know, drone technology, for example, in order for civilian law enforcement purposes, but still it has wandered off away from the battlefield, where it was presumably originally targeted.



So this is a good one.  And this is an example of why we have to keep security researchers protected from retaliation for what they find.  Given that the reality is, we were talking about at the top of the show, that security is not absolute, but to varying degrees our devices are resistant to attack, we need good attackers to poke at all of this technology so that problems could be identified.  What's really interesting here is that this is not a bug that was found, but it was time to retire some tried and true crypto which is just no longer sufficiently secure, as a consequence of its fundamental design.  And that's the block size.



New ciphers have a block size.  For example, the Rijndael cipher, which was chosen as the AES cipher, is 128-bit block.  And back on the podcast where we talked about how symmetric ciphers worked, I explained that you could think of a cipher, encryption, as a one-to-one reversible mapping of every combination - in the case of Rijndael, 128 bits into a different 128 bits.  And since it's reversible, that means that every time you put the same 128 bits in, you get the same different 128 bits out under the influence of a key.  And that's what makes this whole thing so elegant.



So think of the cipher as a black box:  128 bits go in, a different 128 bits, probably different, I mean, in theory, one of them could go right through.  But maybe not.  A different 128 bits comes out.  And you can reverse it.  That would be encryption.  Decryption is just the reverse of that.  And the point is that the key you use uniquely determines the mapping between the input 128 and the output 128.



Well, so clearly one of the important facets of the cipher is how big, how many bits, how long is the key, which tells us how many keys there are.  And Rijndael can have 128-, 196-, or 256-bit keys.  So its key size is scalable.  The block size is fixed.  Older ciphers have smaller block size.  And I should say block size is that 128 bits because it's considered a block because, if this was data, a block of 128 bits of data would be encrypted as a whole, at once, into a different 128 bits.



So in older ciphers like DES, which was 56 bits, or Blowfish that was 64, those used 56- or 64-bit blocks.  Now, they're still secure, but there is a problem.  And they can succumb to the so-called "birthday attack."  And this is an insidious problem.  We've talked about sort of the whole - the birthday paradox in the past.  You get a bunch of people together, and everyone tells the group their date of birth - not the year, the month and day.  And there will be an unintuitively high probability that two people in a relatively small group have the same month and day of birthday because - and again, this is one of the places where people are just bad with probability.  Our brains don't work in probabilities very well.



So the math holds.  And the trick is that it's not - we're not asking does one person have the same, you know, does any person have this specific birthday.  It's does any person have anyone else's birthday.  And that's the trick behind the birthday attack.  So it turns out that it is no longer considered safe, and has been proven to use these small block ciphers.  There will be a paper presented at the end of next month, on October 23rd, at the ACM Conference on Computer and Communications.  I don't even know which annual, like what number that is, but that's been going on forever.



So these guys in their abstract explain.  They said:  "Cryptographic protocols like TLS, SSH, IPSec, and OpenVPN commonly use block cipher algorithms such as AES, 3DES, and Blowfish to encrypt" - wait a minute.  Maybe the key was, yes, I'm sorry, I'm just remembering that DES's key was 56, I think it's 56 bits because that's why you use 3DES.  So I think DES is itself a 64-bit block, but it uses a short key.  And that was the problem was that that key became too short, too soon.  So 3DES serializes three DESes in a row, each with its own piece of whatever that key length is.  I want to say 56 because I remember 112.  I think it's 56 times three is the total key length in 3DES.  But the problem is the block size, the fundamental block size is still 64 bits, which is a problem.



So these guys continue:  "...to encrypt data between clients and servers.  To use such algorithms, the data is broken into fixed-length chunks called 'blocks,' and each block is encrypted separately according to a mode of operation," which we've talked about extensively in the past, you know, CBC (cipher block chaining), codebook and so forth.  "Older block ciphers, such as 3DES and Blowfish, use a block size of 64 bits; whereas AES uses a block size of 128 bits.  It is well-known in the cryptographic community that a short block size makes a block cipher vulnerable to birthday attacks, even if there are no cryptographic attacks against the block cipher itself."  In other words, nothing wrong with either of those ciphers.  They've withstood the tests of time.  The problem is they just don't have enough combinations of bits-in to bits-out in today's computational environment.



"We observe," they write, "that such attacks have now become practical" - well, and we'll see what that means.  That's, you know, but again, stretching the word "practical," and we have to because we want to take these out of service before they become really a problem - "for the common usage of 64-bit block ciphers in popular protocols like TLS and OpenVPN.  Still, such ciphers are widely enabled on the Internet.  Blowfish is currently the default cipher in OpenVPN, and 3DES is supported by nearly all HTTPS web servers, and currently used for roughly 12% of HTTPS connections between mainstream browsers and web servers.



"We show," they write, "that a network attacker" - now, here's where we get to the questionable practicality; but, still, something we need to understand.  "We show that a network attacker who can monitor a long-lived 3DES HTTPS connection between a web browser and a web server can recover secure HTTP cookies by capturing around" - okay, sit down - "785GB of traffic."  So, yes, three quarters of a terabyte.



So, "In our proof-of-concept demo," they write, "this attack currently takes less than two days" - actually, it's like 38 hours - "using malicious JavaScript to generate traffic.  Keeping a web connection alive for two days may not seem very practical, but it worked easily in the lab.  In terms of computational complexity, this attack is comparable to the recent attacks on RC4.  We also demonstrate a similar attack on VPNs that use 64-bit ciphers, such as OpenVPN, where long-lived Blowfish-encrypted connections are the norm.  Countermeasures," they write, "are currently being implemented by browser vendors, OpenSSL, and the OpenVPN team; and we advise users to update to the latest available versions."



So the attack requires that the attacker has the ability to monitor traffic passing between the end-user and a vulnerable website, "vulnerable" in this case only meaning that it is offering 3DES as an HTTPS TLS handshake available protocol; and that the attacker has managed to inject some exploit code, JavaScript exploit code, into a web page that the user is using because then that JavaScript is what burns up the wires generating the 785GB of traffic over a day and a half in order to, essentially, looking for this collision, this birthday attack collision.  And that allows it, when it succeeds, allows it to decrypt the session cookie.  So, yeah, 38 hours I had here in my notes that JavaScript spends generating 785GB worth of data to decrypt a cookie.  OpenVPN required eight hours and, oh, a mere 705GB of data to recover a 16-byte authentication token.



So anyway, the good news is the industry's response to the news of this was immediate.  OpenVPN just released an update which actively discourages the use of 64-bit ciphers.  The v2.3.12, which was just released, they write in their release notes, this release includes many small improvements and fixes.  This is the first release that actively discourages the use of 64-bit block ciphers for security reasons.  And OpenSSL maintainers plan to disable 3DES in their next release, v1.1.0; but they are deprecating the claimed security level of 3DES, which had been high.  They're now deprecating it to medium, which will bias the crypto selection logic against choosing it.  So it will tend to be less readily chosen over ciphers that have larger block lengths.



So this is a classic example of - there was a theoretical understanding of this potential problem, yet nobody moved until some researchers went to the trouble of demonstrating the viability of an attack against small bit block ciphers.  And then, immediately, whoops, everybody fixes it.  The good news is we've got large block ciphers.  AES is fabulous.  And so it was just compatibility and inertia.  You know, I mean, the fact that 1-2% of existing HTTPS connections are using 3DES means that somebody with presumably a really old browser - because any server will have more recent ciphers.  I mean, I'm trying to imagine a scenario where, as we understand the way SSL connections or TLS connections are negotiated, the browser offers the list of ciphers and suites, cryptographic suites that it understands.  From those, the server chooses, like, the best one, whatever "best" means.  And so that way they agree on a strong one.



There are various downgrade attacks that we've talked about in the past where an attacker gets in and, for example, trims the list of the ciphers that the browser says it knows, and the server sort of shrugs and goes, okay, and then uses a weak one, which then allows the attacker to attack the connection.  But still it's odd to me that 3DES, I mean, for example, GRC supports it, but it's like at the bottom of the list because it's old.  But again, I wouldn't want to refuse service to somebody because the only way to get to GRC is over an SSL connection.



So again, this is the way it should work is not bad guys exploiting this, but researchers having a great deal of fun writing a paper, presenting a paper, getting an advanced degree probably by doing this work, and then improving the security for everybody as we march forward.  And this is something that, you know, you couldn't have done this 10 years ago.  We didn't have the infrastructure, and so 64-bit ciphers made sense then.  They really no longer do.  And so it's worth noting that that's no longer the case.



Now, YAWTTY, Y-A-W-T-T-Y, Yet Another Way To Track You.  Believe it or not, the color and amount of ambient light striking your phone.



LEO:  Well, that's probably unique to the location; right?



STEVE:  Yeah, that's exactly the problem.  And the web guys, they're just having so much fun adding new APIs.  So this is the Ambient Light Sensor extension of the Generic Sensor API.  First of all, there is a Generic Sensor API.  Okay.  Before long it'll be like if your hand that you're holding the phone has a tremor, it'll, oh, look, it'll pick that up on the accelerometer and then track you or maybe send you to the - nah, I don't want to say anything that's ageist.



But anyway, so everyone already understands what this means; right?  It is now possible for a web page to determine the exact color and amount of light measured in red, green, and blue lux levels which your phone is exposed to.  So if that's code running in an ad, and you then go from one site to another, although it cannot be used to uniquely identify you, it can be used to disambiguate you.  That is, if that - and as we know, the Panopticlick site worked by aggregating a whole bunch of individually weak signals into something that was shockingly unique.  When you took all of the aggregation of weakness, you ended up with something that actually did identify an individual.



And so, yes, light is subject to change.  You change your position.  You put your phone down.  Anything happens, you're going to get a different amount of light.  But in the interval between switching pages, the light level probably doesn't change.  And so that's one more thing, one more parameter that someone could use to note that, oh, you know, we weren't sure if this was the same guy.  But look, exactly the same amount of red, green, and blue?  Probably is.  So YAWTTY.



LEO:  Interesting.



STEVE:  Yet Another Way To Track You.



LEO:  Yeah.



STEVE:  Wow.  You know?  And this is the problem is that I'm not sure how useful this is for a website to know how much light is striking your phone.  Maybe, what, it enlarges the font size in dim light because it knows that our human eyes have to iris open wider, which lowers our resolution, so we need a larger font and dimmer light?  I mean, you know, you can make up use cases for this.  But it just seems like now they're, like, they run out of really important things to do.  And so they're like, well, let's...



LEO:  We do it because we can.



STEVE:  That's right.  Let's just, boy, what haven't we put in there yet?  Let's see, how about the dripping water API?  Because we need a kitchen sink somehow, so it's got to have the dripping water API.



LEO:  The iPad Pro has this, too, and actually modifies the screen temperature based on ambient light to balance it.  And the rumor is strong that so will the new iPhone announced tomorrow.  So I don't...



STEVE:  Boy.  They're not going to get - I don't think they're going to get any money from me.



LEO:  For ambient light sensing?  No.  For the headphone jack.



STEVE:  No.  I mean for the new phone.  I think we've really hit that point where the phone I have is absolutely fine.



LEO:  Yeah, there's nothing wrong with this one.



STEVE:  No.  Great phone.



LEO:  And it has a headphone jack, which is pretty awesome, yeah.



STEVE:  Yeah, it does everything I want.  And maybe in another few years, when the battery gets tired, if that's a problem.  But I don't - I'm never, like, off of a plug for more than a few hours, the way I operate.  So anyway.



Okay.  So some German researchers did a social engineering experiment.  1,700 university students, who all claimed to be aware of the risks of unknown links, were actually tested - without their knowledge, of course, because otherwise it wouldn't be a valid social engineering test.  Email and Facebook accounts were set up with the 10 most common names among that group of targets.  So contemporary university student names, 10 of them.



It was funny because I was talking to my sister Nancy.  We both watch "Stranger Things."  And of course two main characters in "Stranger Things" were Steve and Nancy.  And I thought, you know, I mean, it's interesting that names do have an era associated with them.  Like now we've got Derek and Tiffany these days.  But back in the '70s and '80s, young adults were named Steve and Nancy.  Not so much anymore.  Anyway - I don't know a lot of other Nancys.



Anyway, so Facebook profiles were created having varying levels of publicly accessible profile and timeline data, some with public photos and profiles, others with minimal.  Then these email messages were sent claiming the links were to photos taken at a New Year's Eve party held a week before the study, so high relevance.



Two sets of messages were sent out.  In the first, the targets were addressed by their first name? in the second, they were not addressed by name, but with just more general information about the event which was allegedly photographed.  The links that were sent resolved to a webpage with the message "access denied," but the site logged the clicks by each student.  So they were unique links tagged in the email to identify who clicked the link, or who was the recipient of that particular email and link, thus who went there.



The messages that addressed the targets by name scored clicks from 56% of email targets and 37% of Facebook message recipients.  The less well targeted messages that did not address their target victim by name yielded only 20% results for email, so down from 56 if it said who they were, but scored higher on Facebook.  42% clicked via Facebook messages, probably because email feels like and our experience is it's a more personal medium, where we expect to be, you know, we expect people who know us to send us email.  And our spam, our own human spam filters are on the lookout for nonsense not addressed to us.  So it's like, okay, no.  So I'm not going to click on something that doesn't know who I am, at least; whereas Facebook message traffic is much less so, less personally tied like that, the idea being it's just not email.



So the German security researchers who conducted the study said:  "The overall results surprised us, as 78% of participants stated in the questionnaire that they were aware of the risks of unknown links, and only 20% from the first study and 16% from the second study confessed that they had clicked on the link."  So that was interesting, too.  They caught them clicking on the link.  They logged it.  But then in this questionnaire that followed up, there was a high level of denial of having done so, even though the evidence was there in the server log.  And finally, among those claiming that they were security-savvy, they found that 45 and 25%, respectively, had clicked on the links.



So this is a problem.  We've talked about it a lot.  We think this is now the way targeted attacks occur.  There are certainly, we were discussing last week, technologically targeted attacks where something is, like for example in the case of Pegasus & Trident, where the user didn't even have to know that their phone was attacked.  In this case, the guy was smart enough not to click on a link that looked suspicious because he was aware of the risks.



But there's also the social engineering side.  And what we've seen, for example, we believe that the whole Sony disaster was precipitated from one administrative assistant who - it only took one to click on a link.  And that allowed this persistent threat to get inside of Sony and then have its way with the entire company's network.



LEO:  Kind of amazing.  Half of everybody.  Half.



STEVE:  Yeah, yeah.



LEO:  It's amazing.



STEVE:  You know, I think it's like we were saying last week.  People will give away their passwords.  They just don't actually care that much about security.  Everyone says, "Oh, yeah, I'm security-conscious.  But, wow, I want to see any pictures that occurred.  Who knows what happened?"



LEO:  Yeah.  Well, to be fair, I mean, these guys are pretty good at pulling your strings and pushing your buttons.  They always put some text in there that makes it very hard not to click; right?



STEVE:  Well, and that's the problem.  And of course we've talked about at length the "Hi, I'm away on a trip, and I've lost my wallet.  Can you please wire me some money?"  And that was, until that got very widespread coverage, it was phenomenally successful in situations where people actually were away on a trip.



LEO:  Well, and - excuse me.  Don't look to me, I'm having a coughing fit.



STEVE:  I'll stop clapping behind you.



LEO:  Alert, alert the media.  I've been phished.  I've clicked on a link.  And the link that got me, I mean, I've only done it maybe twice in the last five years.  But the one that most recently got me, Henry had just lost his phone.  He was in Barcelona.  And he just lost his phone.  And I got a link that said, "This is Apple.  We found your iPhone.  Click this link to go to iCloud and run 'Find Your iPhone.'"  And I clicked the link because that's kind of credible; right?  It tallied in with events that had actually happened.



STEVE:  Yup.



LEO:  In hindsight, of course, Apple's never going to send you that text.  But I didn't know that.  And then I got a site that looked just like iCloud and started logging in.  Fortunately, my fingers froze about halfway through that, and I immediately went and changed my password anyway.  But that was an eye-opener.  I mean, you're right.  We know better.  But they manage to find things that are going to push your buttons.



STEVE:  Yeah.  I think it's a weakness that any sober person needs to acknowledge.  And we also often have bad days.



LEO:  Right.



STEVE:  I mean, you're just - you're distracted.  You're not...



LEO:  You're not always alert, yeah.



STEVE:  Exactly.  You're not focused on something.  You're trying to listen to something on the radio at the same time.  So you just go ahead and click something, trying to multitask, and pow.



LEO:  And I don't think it's a bad thing.  I think humans are trusting.  I think that's a good thing.  I think we generally think the best.



STEVE:  Right.  It is an abuse of an inherent trust in our fellow man.



LEO:  Good thing, yeah.  We were watching CNN today, a really dramatic documentary on an L.A.-based cult.  And I was watching it with Lisa.  And we're both thinking, how could these people fall for this?  But it's because you want to, you know, you have to be pushed pretty far to go, "Oh, wow, I'm being suckered now, aren't I."  We want to believe the best.  I don't think that's a bad thing about humans.  But it does make us vulnerable.



STEVE:  Or we want to believe what we want to believe.  Sometimes it's not the best.



LEO:  Yeah, that's true, too, yeah.



STEVE:  So there is once again another USB problem.  You know, we've discussed these for years.  Turns out that this is another plug-and-play mechanism.  As we know, there are USB network adapters.  It turns out, if you stick a USB network adapter into any standard default configured machine, PC or Mac, the OS will go, ooh, here's a NIC, and immediately put it into the system and query it for its information.  So if instead this is a hacking device, that is, if there's a little computer behind that USB faade, it pretends to be, it can pretend to be a server offering DHCP - I'm sorry.  Yeah, it is DHCP.  But in the notes it says DCHP.  So I think I just copied and pasted, so there was a typo in the source material.  But anyway, provides DHCP services.



One of the things that DHCP can do, because remember that it's not just here's your IP address.  We know that DHCP can also say here's the DNS servers you could use.  And then there's a whole bunch of other stuff that you can do, time and, you know, just pretty much everything.  Well, one of the things you can do is you can say "This connection uses proxy auto-config," which is it offers a URL to what's called a WPAD, W-P-A-D, which is the proxy auto-config discovery file, which tells browsers what proxy to use in order to get out onto the Internet.



Well, it turns out DHCP overrides DNS.  That is, it is used preferentially when both are available, has a higher priority.  So some guys at SpiderLabs have created a tool in Python they call Responder, which pretends to be a NetBIOS, DNS, SMB, MySQL, FTP, LDAP, HTTP rogue authentication server supporting all those protocols.  And so you stick this thing into a machine.  It works even if it's locked because, again, hey, it's a network adapter.  We're all friends here.



So that network adapter gets bound into the system, and a query is sent out for the connection details.  If it's this malicious server, it's then able to take over the connections and cause traffic to be proxied through it, all without touching the keyboard, and all while the machine is locked, not even actively in use.  Because all of our computers today could have all kinds of traffic trickling in and out of them pretty much all the time.  And so it's able to piggyback and leverage that traffic in order to capture credentials, which is what they end up doing, and then run that through any of the well-known LAN manager credential hacks in order to obtain the password.  And then you've got the user's credentials on the network.



So again, a classic instance of convenience trumping security.  A very nice feature.  You plug this in.  But, boy, you know, you ought to have to be logged in.  You ought to have to acknowledge with a pop-up that a new network interface is being added to the system.  Please confirm that you want to do that.  But that would be so much work.  And maybe users aren't going to click the right button, so we'll just make it automatic.



LEO:  Wow.



STEVE:  Wow.  Yeah.  So now some fun miscellaneous stuff.  That catches us up on the news of the week.  Spaces or tabs?  That's the question.



LEO:  What do you use?  You're an assembly language programmer.



STEVE:  Oh, I'm strict tabs, of course.



LEO:  Yeah.  But nobody else reads your code.  I mean, I think one of the reasons people use spaces is because tabs can be defined to be different on different platforms.  So if other people were using your code...



STEVE:  Correct.  And it is the case that, you know, my code, as I move it from one browser or from one editor to another, sometimes the tabs won't work right.



LEO:  Are eight; sometimes they're four.  Right.



STEVE:  Yeah.  And some editors do tab expansion, converting them to spaces, but they don't deconvert them, and blah blah blah.  I mean, so I wouldn't argue that there are some advantages to spaces.  But I like tabs.  And I'm not changing.



LEO:  No.



STEVE:  At this point.



LEO:  And I like spaces, and I'm not changing.



STEVE:  So what we know is that a Googler analyzed - now, the headline said a billion, but it's only 400 million, so come on.



LEO:  Oh, please.



STEVE:  Analyzed 400 million files to settle the programming dispute made famous by HBO's "Silicon Valley" on that "tabs versus spaces" question.  And in the show notes here, I have the chart which resulted, which was from the top 400,000 GitHub repos, showing Java, H, JavaScript, C, PHP, HTML, CS, JSON, C++ Python, XML, Ruby, CC, and Go.  It turned out...



LEO:  No Python, which is odd because whitespace is very important in Python.



STEVE:  Yeah.  P-Y, Python is there.



LEO:  Oh, it is there, okay.



STEVE:  Fifth from the bottom.



LEO:  Missed it.



STEVE:  And much stronger in spaces than in tabs.



LEO:  Yeah, since whitespace is everything in Python.



STEVE:  So what we learn is spaces dominated except for C and Go.  So in C the blue bar showing tabs outsizes the red bar showing spaces.  But not hugely.  But still it's more.  And in Go, look at that, it's like no spaces.



LEO:  I don't understand why Go, yeah.



STEVE:  Nobody ever hit the spacebar in Go.



LEO:  My editor does it for me.  So that's the thing.  I mean, if you're using a good editor, indentation is handled by the editor.  It's only when you create a new block.  And then I use tabs, but I think I have it set so the tabs - so I get the best of both worlds - so the tabs are spaces.



STEVE:  I just like tabs [crosstalk].



LEO:  What I don't want, and I don't think you should use, is a tab character.  I don't mind you hitting the tab key.



STEVE:  Oh, no, I don't want all that cruft in my...



LEO:  So you use spaces, in effect, because you have the tab key mapped to four spaces.



STEVE:  No, no.  I have an actual tab character.



LEO:  Oh, you put a tab character in there.



STEVE:  I thought you meant showing the tab character.



LEO:  Well, you wouldn't want to show it.



STEVE:  No.



LEO:  But, yeah, see, I don't - I will use the tab key, but it inserts four spaces.



STEVE:  Ah, yeah.  And I use the tab character.



LEO:  That's the best of both worlds.



STEVE:  Right.  Okay.  So get this.  We all know John Carmack.



LEO:  Yes.



STEVE:  John Carmack has entered all of our lives, I would imagine, all of the listeners of this podcast at one point.  I was fascinated by Doom back in the day.  Back then it stood out as an astonishing tour de force in essentially 3D environmental rendering.  I just used to stare at the walls as I would, like, move around and watch the texture mapping occur.  It was just - it was phenomenal.



So John Carmack of course is still around.  He's the CTO of Oculus.  But Wikipedia says:  "John D. Carmack is an American game programmer, aerospace and virtual reality engineer.  He cofounded ID Software.  Carmack was the lead programmer of the ID videogames Commander Keen, Wolfenstein 3D, Doom, Quake, Rage, and their sequels."  And then of course a couple years ago he became CTO of Oculus.  I was talking to Mark Thompson, just I think yesterday or maybe Sunday, and somehow Carmack came up in our conversation because John is just, like, crazy about frame rate.  And Mark explained that he really didn't get the whole frame rate thing until he experienced low frame rate VR.



LEO:  Oh, yeah.



STEVE:  And then immediately had to sit down because it's such a disorienting problem.  Carmack was willing to trade off resolution for frame rate, saying that matters more than resolution.  And I have to say, you know, anyway, the guy, I mean, he's my kind of programmer.  All of that stuff was written in assembly language because you couldn't even get the machine off the ground with the kind of performance it needed to do Doom if it wasn't in assembler.  So, I mean, he is a programmer's programmer.



The point of all this is that someone sent me a tweet, knowing that John had just tweeted, and knowing me, John just a couple days ago tweeted, "Create and run an empty activity project in Android studio, and I get a 38MB folder with 1,175 files."  Then he finishes, "We've just given up on elegance."



LEO:  Oh, typical old-timer, complaining.



STEVE:  Yay, John.



LEO:  That's just libraries.  It's loading - it's a framework.  You're loading a framework.



STEVE:  I'm working on this...



LEO:  By the way, if you're writing in Java, yes, you've given up.



STEVE:  I'm working on SQRL's installer and remover because people, you know, it doesn't need one.  It just runs.  But unfortunately, it's not for us.  It's for our nontechnical friends.  And the browsers download it to the download directory.  Okay, then what?  Anyway, so the problem is I don't know if anyone has seen any of these commercial installers, but they would take my cute little 238K piece of art and turn it into a 3MB blob that basically does nothing.  So essentially I'm binding installation and removal technology into SQRL so that you just run it, and it will notice that it hasn't been "installed," and then say, "Hi.  I'm not installed right now.  Do you want to install me?"  And then, if you say no, it'll just let you run it without making any modifications to your machine.



If you say yes, then it will copy itself under the program files directory and register itself to pick up URLs and so forth.  And register with the add/remove programs so that, similarly, if someone wants to remove it, they can, blah blah blah.  And it's taking up no space.  So it's like, yeah, there is a right way to do it.  Nobody does.  But that doesn't mean the right way doesn't exist.  I'm happy to do it that way.  Actually, I have no choice.



LEO:  There's an excellent book, if you're interested in the Carmack and Romero story and the story about Doom and...



STEVE:  Oh, neat.



LEO:  And it's called "Masters of Doom:  How Two Guys Created an Empire and Transformed Pop Culture."  Not a lot of coding in there.  But the story behind it is fascinating.



STEVE:  No, that sounds really interesting.



LEO:  Will Wheaton reads the audiobook, and right now it's on sale at Audible for four bucks, so it's a good little acquisition, "Masters of Doom."



STEVE:  Yeah.  I like history, as we know.  I've got PDP-8s blinking behind me.



LEO:  Well, and Doom really was history, wasn't it?  I mean...



STEVE:  Oh, Leo.



LEO:  Yeah, it changed everything.



STEVE:  It stunned us.



LEO:  It was the first premium product, too; right?  First three levels were free, so it was a great way to get you into that.  I mean, he revolutionized gaming.



STEVE:  Yeah.  And, see, back then you had to be good to do it.  He did it because he was, I mean, that was some serious code, very much like the early Mac programmers, who managed to get a 68000 to do things no one thought it was powerful enough to do.  But they did.



LEO:  Pretty cool.



STEVE:  I miss those days.  Anyway...



LEO:  Because back then they used tabs.  No frameworks.



STEVE:  That's right.



LEO:  Did it by hand.



STEVE:  There you had file size problems.  Tabs were going to save you some space.



LEO:  That's true.



STEVE:  That's right, baby.



LEO:  That's true.



STEVE:  Andrew Hutcheson tweeted something.  I don't know where he got it.  Actually, he tweeted both you and me.  And I just love this.  Somebody, maybe he, originally wrote:  "I'm not scared of a computer passing the Turing test.  I'm terrified of one that intentionally fails it."



LEO:  That's good.  I like that.  Yikes.



STEVE:  Love that.  Thank you, Andrew.



LEO:  Yikes, yikes, yikes.



STEVE:  Okay.  And a couple little quickies.  Adam Stearn, but may others have asked, he said:  "What was that mail archiving application you mentioned weeks ago?"  And I guess maybe I re-mentioned it weeks ago, but I initially mentioned it years ago.  I just wanted to refresh everybody because I'm still using it, and it rocks.  It's called MailStore Home.  So MailStore is the company and the product, and I use the Home edition, which is free for personal use.  I'm using v8, of course, but they're now at 9, which I noticed when I went to go check them out when someone asked me a few weeks ago.



Anyway, it's a great tool.  I use it continually.  Basically I have it set up so that mail that I receive is copied into an archive, and then it pulls from the archive and deletes the archive.  So essentially I have - it's just the way it was convenient for me to set it up that way.  So I have, it's now 2.7GB of indexed, instantly searchable, everything I've received from the beginning of time email.  And it comes in handy all the time.



LEO:  Does that require Outlook, or what is...



STEVE:  No, it doesn't.  It supports about seven or eight different formats.



LEO:  pgMail is supported.



STEVE:  It does support Outlook and PST files.  It supports MBX files.  It had no problem sucking in Eudora's - I had all of my stuff in Eudora, which is just a flat...



LEO:  That's MBX; right?



STEVE:  A flat text file.



LEO:  Nice.



STEVE:  Anyway, it really - it does the job.  I'm so impressed.  And again, free for personal use.  Free for home users.



LEO:  Nice.



STEVE:  Oh, look, it's at 9.8 now.  I might want to wait till it goes to 10.  Actually, my v8's working just fine.  Anyway, I do recommend it.



LEO:  That's good.



STEVE:  And someone said, given that Apple refuses to allow outside security audits, what's the basis for saying iOS is the most secure mobile platform?  And so I thought about that, and I wrote back to this person.  I said:  "As we know, Apple exercises extreme control over their closed iDevice ecosystem.  Google currently has much less control.  This gives Android users more freedom, but at a cost in device security.  Though Google is much better with their own devices, the vast majority of Android smartphones worldwide are either never patched or are patched partially and/or very late."



So we covered just last week Apple's immediate response to the zero-day that was found, and that within 10 days everybody had updates available, although I'm still puzzled by the fact that it seems to take Apple a while to get them pushed out.  I just now, as we were doing the podcast, one of my iPads said, oh, there's an update.  It's like, yeah.  And so it's taking care of itself.  But still, it's very quick.



And so, again, given that our model, the proper model is systems that are resistant to attack, clearly being able to respond to known attacks in a timely fashion is required because it's the known attacks that then get you.  And that's a glaring weakness.  We know Google is working because they're certainly concerned about security.  They're working to fix that.  But the way Android got started and the way it got picked up and sort of diversified into so many different products, many where it's just get the consumer's money and then good luck to you.  Unfortunately, it's a computer with lots of known problems that aren't getting fixed.



And then, finally, Tim Stewart tweeted a question, something we had not discussed.  He said:  "Is loading a form over HTTP, but posting to HTTPS, a security risk?"  And in the past, in like the olden days, back in the early 21st Century, I would have probably said yes, we've talked about this, that it's disconcerting to see a form delivered over HTTP.  But technically the secure information, like if it's your credit card information and so forth that you're filling out, when you submit it, if it's an HTTPS GET or POST, then that's going to be protected.  The server will be authenticated over TLS, and you'll get privacy from encryption. Everything should be good; right?  Well, no.



The problem is, if you got the form over HTTP, anything could have been done to it.  Any modifications could have been made.  So, for example, a little bit of JavaScript added to it could, upon you clicking the Submit button, not only submit it to where you think, but bundle up all those parameters in a query tail to a GET, which the browser is able to issue to a different domain and thus exfiltrate your form, your private confidential form data to some other domain without raising any alarms or concerns.  So it is actually the case that you need the form delivered to you over HTTP, and it's submitted over, I'm sorry, over HTTPS - I was reading my notes where I said HTTP - over HTTPS and posted as HTTPS.  Otherwise, there's just too much mischief that a bad guy can get up to.



And, finally, I didn't really have any - I didn't have time, actually, to go searching through my notes for a fun SpinRite anecdote.  But something came up from my discussion last week that I didn't know.  Mark Thompson didn't know it.  Nobody I know knows this, or nobody I know who I would expect to has ever heard of this before.  Which, I mean, it's right in the middle of my bailiwick.  I was talking last week about how SpinRite is itself the DOS stub of a Windows app.  And that way, when you run it under Windows, you get the little UI, the Windows UI that then allows you to install it, which mostly just means formatting a boot device for bootability.  And then it copies itself to that.  And when you run it, the same EXE, from the device, then it runs SpinRite, the DOS stub.



Someone tweeted me, @sjh_canada.  I never knew what EXE and COM stood for.  I just, you know, I sort of took them for granted.  And I mentioned last week how a COM program is like, remember command.com or msdos, well, actually that was msdos.sys.  But frequently the kernels, certainly in FreeDOS, it's kernel dot - maybe it is kernel.sys.  But anyway, even though it has a SYS extension, it is actually a COM file.  It's just a memory image, that is, and so it's limited to 64K, that is, one so-called segment of memory, because without anything fancy, that's all you're able to write in an 8086 class machine because the maximum size of addressing was 64K blocks.



Anyway, COM is short for "compile time binding," and EXE is short for "execution time binding."  I never heard that before.  Never knew it.  And that exactly fits what's going on because by "binding" they mean essentially establishing the running image, in this instance of the use of binding.  So when producing a COM file, the compiler binds the result into the memory image, and you just drop that image into memory, and you run it.  Nothing has to be done.  And the reason you used those back then is you didn't have to have a sophisticated loader.  All of that work was done by the compiler, that is, the compile time binding.  And so you just drop it into memory and just jump to it.  The executable format is much more sophisticated and has to have a much more complex, thus bigger, loader.



So in a classic case of bootstrapping, where you're actually using the term "bootstrapping" as in one stage being used to get the next stage in, the COM loads easily with just a simple copy of the file into memory, and then runs.  It contains the sophisticated loader that is then able to load the EXE, which is the execution time binding, where the binding into the RAM image occurs at execution time, as it's being loaded into memory, rather than by the compiler.  So very cool.  Never knew that.  Thank you for sharing that.



LEO:  I didn't either.  I mean, I knew COM files were small, but I didn't know why.



STEVE:  I know.  Nobody I know ever knew what EXE and COM stood for.



LEO:  Yeah.  



STEVE:  Turns out they do stand for something.



LEO:  Yeah.  Hey, a couple of little things.  First of all, don't forget your mind teaser, your brain teaser from last week.



STEVE:  Nope.  And that's at the end of our notes.



LEO:  Okay.  Don't want you to forget that.



STEVE:  Yup.



LEO:  And somebody's asking in the chatroom, and I think this is very cool, Jonathan Zdziarski, who is, of course, we talk about him all the time, the Mac security guy, has written a little utility that he's giving away called Little Flocker.  It stands for F-Lock.  It's the old F-Lock.  And it's a program for Macs that restricts file access.  You have to give permission for an application to access your files.  And, now, that could be annoying.  It's kind of like Little Snitch, which is blocking outbound network connections, which is another program, very useful in preventing malware, also very annoying.



STEVE:  Yeah.  All of these things are [crosstalk].



LEO:  Pretty convenient.



STEVE:  Ask for permission, it's like, well, yeah.



LEO:  But I think it's kind of intriguing.  It's a kernel extension, which is always a nerve-wracking thing because that modifies the operating system at a very low level.  But Zdziarski, on the other hand, seems to be a very benign fellow.  Anyway...



STEVE:  And he's been doing a lot of pen testing.  I've been following his tweets as he's been developing this, and it's been moving along now for a few weeks.



LEO:  So at some point, just curious.  I know you don't use Macs particularly.  But this seems like a good idea.  I'll run it and let you know how horrible it is, yeah.



STEVE:  Do.  Because we know, if you can tolerate it, Leo...



LEO:  Well, Little Snitch is one of those things where you make rule sets a you go.  So every time...



STEVE:  Yeah.  But so was NoScript, and NoScript drove you out of your mind.



LEO:  I couldn't do it, yeah.  So this will be like that.  Every time you want to save a file, the first time you do it with a program it's going to say, now, "Microsoft Word wants to save a file.  Is that okay?"  And you'll say yes, from now on you let Word do whatever it wants or whatever.  But security and convenience.



STEVE:  And the fact is, that's a perfect example of the firewall rules being set correctly.



LEO:  Right.



STEVE:  That it's block by default, and then allow, you know, permit selectively.



LEO:  Right.  Not always fun.  But really safe.



STEVE:  No, I would say never fun.



LEO:  Never fun.  But always safe.



STEVE:  It's a problem, but we don't have any better technology today.



LEO:  Yeah.  Time for Flip Feng Shui, Steve.



STEVE:  Which is their name for this.  I take no credit for it.  It's a great name.  Okay.  So a year and a half ago it came to light that DRAM, which is where the bulk of the data in use by the computer is of course resident in DRAM, was subject to deliberate manipulation, a so-called "bit-flipping attack."  And what was discovered was that pounding, that is to say hammering, on one row of DRAM was shown to have the ability to influence one or more bits in the adjacent row.  And the stat I remember, I don't have it in my notes, but I remember it from bringing myself back up to speed, is one out of 1,700 bits is flippable.  So one in 1,700, that's a lot of bits when you consider how many bits there are.  So a relatively good chance of Rowhammer attack working.



And then the double Rowhammer is hammering the rows on both sides of the target row.  And essentially what's happening is we're inducing noise.  The DRAM is another instance, just like hard drives and SD, where the commercial pressures to increase density have forced the engineers, who are super clever, to cut the margins, cut the signal-to-noise ratio down so that it works, but you just don't have as much margin as you'd like to.  And that's the whole, you know, that's one of the keys of SpinRite is that things have always been that way.  The technology keeps advancing, so the amount of data we can squeeze is always more.  But it's still always pushing the limit.  And so that creates a gray zone.  And as I mentioned in the past, SpinRite goes into the gray area and pulls your data out of it.



So, okay.  So we had a year and a half ago a problem, a recognized problem.  This was bad, that something could hammer on DRAM and cause an error.  Well, okay.  That's not good.  But at this point it sort of - it shows the computer is not working the way it should, but it's not clear how you exploit it.  Well, in the last year and a half, the last 18 months, there have been some special case exploits, where for example there was a privilege escalation exploit that had some probability of flipping a bit that was critical to maintaining and managing the privilege of a process, and that it could change its privilege.  Basically you're doing something out of band.  If you tried to write what you wanted to that memory, the system would slap you and say, that's a memory violation.  You have no access there.  But if you pound right next to it, and the bit that you wanted to flip flips anyway, then, hey, you didn't do it.  Actually you did, but you did it in a way that the system didn't see.



So that's Rowhammer.  And since then there has been effort to tighten up the hardware.  One of the things that could be done is that the RAM can be refreshed more often.  Typical RAM refresh is about every 64 milliseconds.  And so what's happening is, as we know, DRAM uses the fewest parts possible per bit in order to get as many bits as possible per unit area.  So the capacitor where the charge is stored is made as small as possible, and that's a problem because, well, the good news is it lowers the power consumption because you're having to force less, you're having to fill less in order to get a voltage change on a smaller capacitor.  But it also means that it's the signal in the capacitor is increasingly small relative to the noise in the environment.  And Rowhammering is about environmental noise.



So if you revisit the RAM more often, the whole refreshing process is one of reading a row of RAM before any of the bits have had a chance to change.  They want to because the electrons are leaking away.  And so, if you come back within every 64 thousandths of a second, read what's there, and then, like, reinforce it, just write back what you just read, then that's what DRAM refreshing is.  So by doing it twice as often, by shortening the refresh interval to 32 milliseconds, that's been shown to provide very, you know, much stronger protection from Rowhammer. 



And DDR3 memory was the first place this became prevalent because of the density of the cells.  It was just so aggressive.  DDR4 is even higher density.  It would tend to be more susceptible, except it was developed with a Rowhammer awareness.  And there's actually on the DRAM controller is something counting the row accesses so that it's able to catch, it may not be a deliberate Rowhammer attack.  It could just be - it could be serendipitous, although the reason that would be suspicious is that the other thing Rowhammer has to do in order to work is to flush the cache because remember, as we talked about last week, our systems have multiple layers of caching, typically three - Layer 1, Layer 2, and Layer 3 - before you get to the DRAM.  So the processor has to read the data that occupies one of the rows and then explicitly flush the cache.  Otherwise, if it tries to read it again, the cache will do its job and provide the data.



So Rowhammer functions by - I'm sorry.  So DDR4 memory has been strengthened by having a controller that looks for high-frequency usage of specific rows and then goes right to them, and their neighbors, and refreshes the memory on a spot basis, in addition to the ongoing background refresh.  And that looks like it's gotten better.  The problem is there's still lots of DDR3 memory, and it's only recently that chipsets have increased their refresh rate.  There are apparently some microcode updates available for motherboards to increase the refresh frequency and decrease the interval from 64 to 32 milliseconds.  And there's about a 1-2% overhead that results from doing that.



Okay.  So we have a technology, a potential exploit technology, which unfortunately today works.  That is, one in 1,700 bits of DRAM on servers in the world can be flipped.  And these are called "memory disturbance errors," technically.  Okay.  Now we've got to step back and look at how memory is managed.  And I was trying to think of an analogy for memory management that would make sense.  So imagine a deck of cards.  Everyone knows about a card deck that has 52 cards.  Imagine that being well shuffled, so it's completely randomized, and those 52 cards are dealt out to four players around the table so that each player gets 13 cards, facedown.  Now, imagine that that memory, that is, the original deck of cards is all of the memory in the system.



Now, what the four players have been dealt is essentially their view of memory.  So each player has 13 cards.  Say that each card represents a meg of memory.  So they each get 13 megs of memory.  Each player sees the memory as one through 13 megs.  But the fact is those have been randomly assigned out of the pool, out of the actual physical pool.  That's hardware mapping.  That's hardware memory management.  The idea being that what the process sees is an abstraction.  It sees a linear range of memory like those one through 13 cards, but the actual physical location could be anywhere in the system.  But one of the keys is, notice, no player has the card of somebody else.  That is, the way they were dealt out, everyone has disjoint cards, that is, their own separate 13.  No one is sharing cards.  That way they all have their own memory.  And I'll explain, and you'll see in a second how this becomes relevant to this interesting hack.



But the virtual memory manager and/or the operating system manages the pool of physical memory using memory mapping hardware, which imposes itself, interposes itself, between the program running and the hardware in the machine.  And so that when - so the program sees a region of memory which is maybe not the actual physical memory.  Almost never is the actual physical memory location.  That's abstracted for it.  Which allows each program to sort of operate independently and with no collision.



Okay.  Now.  People running cloud servers, they noticed something.  They noticed that, in a big cloud server, there might be a hundred virtual machines operating.  And they're probably running the same version of something, some OS, whether it's Windows or Linux or a Unix.  And if that's the case, they share a lot of memory.  That is to say, the same operating system in two separate virtual machines is going to have the same data stored in a lot of its pages.  And so there's something known as Kernel Same-Page Merging, KSM, Kernel Same-Page Merging.  To optimize a large system's memory, the virtual machine manager is continuously scanning memory, searching for identical pages.  And it turns out that is such an effective strategy for conserving memory that it's now the way it's done.



So think about it.  Separate virtual machines loaded with the same stuff, whatever it is, maybe the same version of OpenSSL, or the same OS, they're going to have a lot of code similar.  And these things always load starting at a page boundary.  So the memory page alignment will be the same.  There will be many identical pages.  So when the virtual machine manager notices two pages that are the same, which are typically occurring in different virtual machines, it merges them.  What it does is it marks them as read-only so that any attempt to change them will be brought to its attention.  And it then points one of the virtual machines to the other virtual machine's memory.  That is, it breaks that one-to-one relationship between apparent memory and physical memory, creating a many-to-one relationship.  So that suddenly many of these virtual machines will have a mapping table that maps all of what looks like private and separate memory to a single page of memory.



So you can kind of see where this is going.  This starts to get a little dicey here because now we've got, I mean, technically it's brilliant, I mean, and it's gutsy.  And it works.  And it's what everyone is doing.  If any machine attempts to change a byte of memory which it is sharing with others without its knowledge, the virtual machine manager steps in, copies that to its own page, makes the change, and gives that process back its own private copy because it's no longer identical to the others.  So it works.  It hugely reduces the memory footprint and allows the same hardware to simultaneously hold vastly more virtual memory or virtual machines because there is this high incidence of memory collision among individual virtual machines.



Now, what these guys figured out how to do is how to weaponize this.  And they've written the code.  They're presenting the paper.  Did they present it?  Or are they?  I had it in my notes here.  I don't see it.  Oh, yeah.  At the USENIX security symposium a few weeks ago they presented this.  So, first of all, they scanned their own memory, they Rowhammered themselves, looking for an identifying flip, all of the flippable bits in their own memory area.  And they need a bit at a certain range of offsets within a block because of the strategy, which I'll explain next.



So they first audit - they do a self-Rowhammer audit to find vulnerable bits in their own space, which they're able to do.  The operating system says, "What the hell's going on here?"  But it just lets them.  So then, once they have found a bit with the proper offset in the page, they know that one of the other processes in the system is running OpenSSH.  And the way OpenSSH is configured, there'll be an authorized keys file which is the public key that matches the remote user's private key.  So the public key is in the server, as we would want.  The user maintains their private key.  And when you connect, when you attempt to connect with OpenSSH into the server, the server's authorized key is used to verify the incoming connection's private key.  So that all makes sense.



But because this is open source software, because it's known where it's going to be, they're able to - oh, and the key is public.  What they're able to do is duplicate a page which they know resides in a different machine, and where the offset of the bit in the page is in the private key where it's being stored in RAM in OpenSSH.  As soon as they explicitly deliberately duplicate a page that exists in the other virtual machine, they wait a bit.  The virtual machine manager scans around, sees, oh, look, here's a page that's the same as it is over there.  I'm going to merge those.  Now they merge them.



Okay.  Once that's happened, these guys have already verified that they can flip the bit where they want to.  So they hammer on their own copy, which is actually now a shared copy.  They reflip the bit that they verified they could flip, which flips the bit in the RAM instance of the other virtual machine.  Now, this also factors in, if you'll pardon the pun, to the whole issue of primes.  We were discussing last week that what it is that is hard about prime factorization is the factoring of two really large primes.  The public key has this merge, you know, is the multiplied primes, is in the public key.  It turns out, if you flip one bit of a public key, you make it incredibly easier to factor because it's no longer the multiplication of primes.



LEO:  Ah.



STEVE:  It's just like we were saying last week.  So that flipped bit in the public key then allows them to perform a factorization.  That allows them to obtain the private key, and they can then remotely log in over SSH into the machine that they have compromised.  Unbelievable.



LEO:  Wow.



STEVE:  And it works.  It works.  This is like, oh, wow.



LEO:  That's amazing.



STEVE:  Isn't that incredible?  Yes.



LEO:  So the puzzler from last week helps us understand that, yeah.



STEVE:  Yeah, yeah.  And how you can take something which is, oh, look, we found a problem with DRAM.  If you pound on this row, something flips next door.  It's like, oh, that's bad because then the program will crash.  Yes.  But also, if you're really, really good, you can turn that into an exploit.



LEO:  Mm-hmm.  Crashes are good.  Yup.



STEVE:  I mean, yes, it's just a perfect example of the way virtually any kind of defect can be leveraged.



LEO:  Nice.  Very nice.



STEVE:  So, wow.  Sublime and righteous hack.



LEO:  And well named, I might add.



STEVE:  Yes.  The Flip Feng Shui.



LEO:  Feng shui.



STEVE:  Okay.  And we'll wrap up with a discussion of last week's puzzler.  Everyone will remember that someone tweeted me with a problem.  And in fact I haven't had a chance yet to get back to him my probably favored solution to it, which is really pretty cool, and something we even talked about some time ago.  And that is, imagine you have an appliance whose firmware is old and only knows about SHA-1.  Very much like XP before SP3.  XP up through SP2 didn't know about SHA-256 at all.  So it couldn't verify that cert or any cert in the chain or - and, see, the roots are still signed with SHA-1 because they don't have the problem of, well, because they're self-signed, essentially.  So I just lost my train of thought.



Okay.  So we have this device whose firmware could absolutely not be changed.  The problem is, as we all know, SHA-1 certs, unless you go to WoSign and change the POST parameter to a "1," in which case, although maybe they fixed it by now, you could get yourself a cert good for a couple years.  The problem is any reputable CA will not, after January 1st of 2016, on and after, will not give you an SHA-1 cert.  So one of the hacks, the first one was one you did mention last week, Leo, that I think you probably saw Bill in Michigan note, or maybe you guys came up with it independently.



LEO:  No, that just was off the top of my head.  In fact, I'm shocked that it was a good idea.



STEVE:  Very good.  And that is to use the clock.  The only reason that appliance would balk at the SHA-1 certificate, at an old SHA-1 certificate, is if it thought it was expired.  So if it's using it own internal clock, set it back a year.  Now, remember, certificates do have a not-valid-before date, so you can't go back a decade and get 10 years of life.  You have to go back a year.  And basically, for the rest of time, or until these devices die or get retired or finally get updated, you'll have to annually move it back to the same year to keep it within that period of time.  So the remote server would be deliberately issuing an expired certificate.  Servers don't care.  We see it happen all the time.  Sites are being protected with expired certificates.  Our browsers are the ones that say, hey you're trying to pawn off a bad cert on me.  And alarms go off, or if you're Google your system melts down.



But anyway, in this case the first possibility is simply not let the device know what day it is.  Keep it within the valid date.  Servers don't care if they're issuing an invalid cert.  You'd have to arrange not to have anybody else obtain that cert.  So hopefully the fully qualified domain name of the device, or maybe the port it's connecting to, hopefully there's something that distinguishes incoming connections from it that would allow the server to have on that domain and/or that port, have that bound to this increasingly creaky and old, but still useful, SHA-1 cert.  And then you would get it, you would arrange to make it okay by keeping the device's clock there.



Now, if it's not an internal clock, it might be that the device is a little bit smarter, and it's making NTP, Network Time Protocol queries to the National Bureau of Standards or the Navy or wherever.  There's a whole bunch of different NTP servers around.  In fact, Microsoft has time.windows.com.  So if that's the case, you would want to, first of all, learn about what the device is doing to obtain time by capturing its traffic.  NTP is not a secured, encrypted protocol, so you can see - and it's typically UDP.  So you can see those easily go out and come back.  And you'll see it doing a domain name lookup at wherever it's using for NTP.  So then you arrange for its DNS server, whatever it is that's serving DNS, to serve it a spoofed IP.  That is, you change the IP of the fully qualified domain name it's looking up to your own NTP server, where you keep that date within the sweet range, with typically two or three years for an SHA-1 cert, so that the devices are all happy.



So once again, it's a network time protocol-based approach of fooling the appliance into what day it is.  And, if for some reason, neither of those two approaches work, there is another one which is very cool.  And that is leveraging CloudFlare's so-called "No Browser Left Behind" solution.  It is the Picture of the Week that I deliberately didn't point out at the beginning of the podcast because I didn't want to give this away.  But that picture on the first page of the show notes shows the - it's a flowchart of CloudFlare's logic for their dynamic certificate issuance.  And we've talked about how they work before, and we did talk about no browser left behind quite a while ago.



Their concern was that, okay, yeah, SHA-1 is something that doesn't provide the security we want, and it's not necessarily future-proof.  But there are devices, there are browsers that are not able to do SHA-256.  That is to say, we don't want to leave any browsers behind.  Anybody on XP with SP2 - and in fact CloudFlare has stats on the number of queries they service that are happening right now from systems that cannot do SHA-256.



So what they do is, and this is the brilliance of their solution, because you don't have to statically issue the same cert to everyone.  The TLS handshake gives you clues about how advanced the TLS cryptographic stack is in the client that is requesting the connection.  And if it's TLS 1.2, then you're able to check whether it understands elliptic curve or not.  If so, you give it that.  If it's TLS 1.1, then it probably knows SHA-256.  You give it that.  If it's TLS 1.0, which was SSL 3.0, which, for example, these appliances certainly would be, you give it - and CloudFlare does - an SHA-1 cert.  So all you would have to do would be to have CloudFlare handle that domain which these appliances are connecting to, CloudFlare essentially being the TLS or HTTP or connection proxy for those devices.  And they would keep working as long as CloudFlare continues to offer the "No Browser Left Behind" service.



LEO:  Clever.



STEVE:  Very, very cool solution.



LEO:  That's a good way to do it.  And we've mentioned CloudFlare before.  And the reason you don't use it to protect yourself against DDoS attacks is this cert replacement thing.



STEVE:  Yeah, because, well, yes, correct.  I don't like the idea of anybody else having GRC.com certificates.



LEO:  Right, right.



STEVE:  That's just like - that goes against my...



LEO:  Not worth it.



STEVE:  ...grain, you know, [crosstalk].



LEO:  But there are a lot of people wouldn't care about that.



STEVE:  Correct.  Oh, yeah, yeah.  I mean, and a lot of major people use them.  But they're not GRC.  And but the other problem is that all of the extra goodies that GRC offers, I didn't realize how many people were using the DNS spoofability test until it was down because I broke it.  And it's fixed since then.  But I got all these complaints from people.  It's like, god, I really want to use that.  And, like, so all - and, like, ShieldsUP, spoofability, there's a whole bunch of the fancy network stuff that I've done that cannot be behind a proxy.  It just won't work behind a proxy.  It has to be able to accept unsolicited incoming packets.  And if it can do that, then it is open to attack.



LEO:  Steve Gibson, he's at GRC.com.  Is it up?



STEVE:  Yeah.  We're back.



LEO:  All you've got to do is visit GRC.com and revel, revel in the freebies, all the great stuff that he does for us, like SQRL, ShieldsUP, the DNS tool, which is actually...



STEVE:  I have several big announcements coming, too.



LEO:  And good stuff coming.  I use the DNS Benchmark all the time.  That's really useful.  Download that.  And then there's the one thing, the one and only thing he asks you to pay for.  It's his bread and butter.  It's his daily living.  It is, of course, SpinRite, the world's best hard drive maintenance and recovery utility, and well worth every penny.  And if you go to GRC.com, make sure you pick up a copy.  You can also pick up a copy of this show.  And not only the audio, the MP3, but a written transcript of it, as well, GRC.com.  You can leave your questions there, GRC.com/feedback.  Or tweet him.  He's @SGgrc and accepts direct messages as well as tweets.  So it's a great place to go to ask a question.  And maybe we'll do a question-and-answer version next week.



STEVE:  I hope so.  Although this was fun.



LEO:  Really great.  Really.  Always a pleasure.  You're fabulous.  We love doing this show.  And I know there are almost 100,000 people every week who devotedly listen.  So many people tell me either that they use it in curricula at colleges for computer science and security, or that they use it to get jobs or get A's.  One guy told me, because he'd listened growing up his whole life to Security Now!, he was able just to take and pass a number of computer science classes without even going to the class because he already had taken those classes right here.  So thank you for the - you really do something pretty amazing here.  And we'll do it again next Tuesday, about 1:30 Pacific, that's 4:30 Eastern time, 20:30 UTC.  I will be here one last time next week.



STEVE:  And I was feeling so glad, Leo, that the podcast is not on Monday.



LEO:  Why is that?



STEVE:  I'm glad it's on Tuesday.



LEO:  Oh.



STEVE:  Well, because Monday is too often a three-day weekend.



LEO:  Well, that's true.  That's true.



STEVE:  And I don't want those days off.



LEO:  You'd miss a show.  And you never miss a show.



STEVE:  Oh, that would not be good.



LEO:  Now in its 11th year of serving the masses fabulous information about security.



STEVE:  Twelfth year, actually.



LEO:  Twelfth.  Finished its 11th.  Now in its 12th.



STEVE:  Yes.  In year 12.



LEO:  Thank you, Steve.  We'll see you next time.



STEVE:  Okay, my friend.  Talk to you next week.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#577

DATE:		September 13, 2016

TITLE:		Listener Feedback #239

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-577.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss a bit of Flip Feng Shui follow-up; Apple's announcements; Android's rough week; wireless device privacy leakages; some fun miscellany; and 10 questions, comments, and observations from our terrific listeners.



SHOW TEASE:  It's time for Security Now!.  Steve's got the latest security news for you.  And, finally, it's a Q&A session.  So we've got a lot of questions from our audience.  Steve has a lot of answers for you.  Coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 577, recorded Tuesday, September 13th, 2016:  Your questions, Steve's answers, #239.



It's time for Security Now!.  I'm going to get my Temperfect mug and put in my Bragi headphones and listen to this guy right here, Mr. Explainer in Chief himself, Steven Gibson.  Hi, Steve.



STEVE GIBSON:  Say, you know, I have had some people ask why I'm drinking, you know, those who see the video see me holding up a white ceramic cup.



LEO:  Yeah, a Lavazza cup.



STEVE:  As opposed to the - yeah, Lavazza, as opposed to the Temperfect mug.  And it's just that, if I were out and about, I would probably use the Temperfect.  But for my mode of operation, it's just easier for me.



LEO:  Folks, no cup of coffee lasts more than a few minutes with Steve Gibson around.  There's no issue of it cooling or chilling.  We have a...



STEVE:  Yeah.  So there's no need for it to - and the cup is also sitting on a hotplate, you know, a traditional old school cup warmer.  So it keeps the cup warm.



LEO:  Oh, well, who needs a Temperfect mug if you've got a cup warmer?



STEVE:  Exactly. 



LEO:  You keep it on a hotplate, really?



STEVE:  Yeah.



LEO:  Wow.  You don't like cold coffee.



STEVE:  Don't think I can show it to the camera.  Yeah, there.  A little hotplate.



LEO:  Oh.  Is it one of the USB-powered hotplates?



STEVE:  Oh, no, no. 



LEO:  That's the real deal.



STEVE:  That whole idea, there's something that should not be USB powered.



LEO:  110-volt hotplate.  



STEVE:  Oh, god.



LEO:  Yeah, those things...



STEVE:  But there's like a USB fan, where you stick it into your laptop and then...



LEO:  Those are all right because you don't need a whole lot of wattage for a fan.



STEVE:  That doesn't need a lot of power.



LEO:  No, a hotplate, yeah, maybe not.



STEVE:  Well, so - did we start?



LEO:  Yes.  Yeah, we started, yeah, yup.



STEVE:  This is Security Now! 577.  Finally we have a Q&A.



LEO:  Woohoo.



STEVE:  The industry has been sufficiently quiet, and the pressure to do a Q&A has been growing.  I have, Leo, I have so many questions that we could just, like, we could cruise for another couple of decades just doing Q&As because so many people write.  And between only really having time to do 10 and giving them useful coverage, plus whatever news has happened in the week, and the fact that sometimes we just can't get to a Q&A because of other really cool stuff that we have to talk about, I have a massive backlog.



LEO:  Well, the truth is, every show you do stimulates more questions than you can answer.



STEVE:  Yeah.



LEO:  I mean, I know myself, as I'm listening, I'm thinking of questions.  But, okay.  So you - and then what - and so I can understand why there's...



STEVE:  So we're going to - I have a quick little fun Flip Feng Shui follow-up from the authors.  Apple's announcement I wanted to talk to you about just briefly.  Android had a rough week.  There's also some more wireless device privacy leakage in the news.  We have some fun miscellaneous stuff; and, of course, being a Q&A, 10 questions, comments, and observations from our terrific listeners.  So a great show.



LEO:  Excellent.  And a great Image of the Week, which we'll do in a moment.  I love it.



STEVE:  So our Picture of the Week is just fun.



LEO:  I love it.



STEVE:  A lot of people have had fun over the years spoofing various O'Reilly covers.  I don't know why...



LEO:  The animal covers, yeah.



STEVE:  Yes.  Yeah, they're just notorious within the IT, computer, and programming community.  They're generally great references. I have, you know, not a complete set.  You can't have a complete set.  There are just too many.



LEO:  I have a ton of them.  I'm looking at a bunch right now.  And the animals have become so much their trademark that many of their books are known by the animal on it.



STEVE:  Yeah, what's the Perl?



LEO:  So the Perl book is the Camel Book.



STEVE:  That's right.



LEO:  Yeah, Larry Wall's Perl book is the Camel Book.



STEVE:  Yup.



LEO:  That's how successful they are.  I've never seen a giraffe book.



STEVE:  Well, yes.  And so this was well done.  Anyway, it's just fun.  It's a fun cover:  "Regex by Trial and Error."



LEO:  Which is how I do it.  I don't know about you pros, but...



STEVE:  But I think, no, I retweeted - I guess I shared it with a couple friends who are also programmers because I think everyone does.  And that's the point of this, is that the regular expression language is formally defined.  There unfortunately is not a single one.  All the different implementations, authors couldn't resist changing this or that.  So, for example, the Regex bible talks about the individual, has individual chapters for different languages' implementations of regular expressions, Perl of course being probably the preeminent one.  But it's really - what's the term?  It's not procedural, it's declarative.  And I would hate to have to code the interpreter for regular expressions.  I have sometimes marveled at what the regular expression interpreter is able to do.



But the idea is you're able to describe the way you want typically a string to be transformed with very complex pattern matching and substitution phrases in this crazy thing.  And it often doesn't work right the first time.  So you do it.  Then you give it some test cases.  And then you say, oh, whoops.  And in fact I'm sure the world is full of bugs that have not yet been found in regex statements which were not quite what the programmer intended for them to do.  So anyway, just - so "Regex by Trial and Error."



LEO:  By O RLY books.  I love that; right?



STEVE:  There are a couple of typos on the cover that were no doubt a consequence of a misapplied regular expression.



LEO:  "Combining slashes and dots until a thing happens."  Love it.



STEVE:  So I was surprised and really pleased.  I received a tweet from one of the security research team at VU Amsterdam's group that's run by Professor Herbert Bos, who we talked about.  They're the guys who did the Flip Feng Shui work which was so impressive.  Ben Gras wrote, he said:  "As one of the authors" - he tweeted to me - "one of the authors, thank you for your knowledgeable and detailed exposition.  We're honored by it and your kind words."  And I replied, I said:  "Oh, wow, thanks."  And so in email he followed up, saying:  "Thank you again for your Flip Feng Shui coverage.  Because of more recent coverage, I am a bit of an expert on how well our work is understood; and I don't hesitate to rate your coverage at a 95th percentile rating for expertise and quality of exposition."



LEO:  Wow, that's excellent, wow.



STEVE:  "We also loved your appreciative words, of course.  So full marks, thank you so much."  And then he concluded with:  "I'm also a big fan of the show, so it's just joy all around here."



LEO:  Oh, that's great.  High praise,  yeah.



STEVE:  So neat to know that these guys are following the podcast.  And thanks, Ben, for the note.



LEO:  You get used to, I'm sure, if you're in a project like that, of kind of incorrect or, I mean, mainstream media just - mainstream.  The tech media just mangles stuff.



STEVE:  Well, how often do I talk on the podcast about something that's just like, okay, this is not a problem; or, oh, this is much bigger than expected.  And typically the press tends to overheat these things, as we've seen, because...



LEO:  It's good for ratings.



STEVE:  ...they're looking for clickbait, yeah.



LEO:  Yeah.



STEVE:  So I did want to just mention briefly about the Apple announcement last week, last Wednesday.  I slept soundly through Thursday night into Friday morning for the first time in quite a while, not bothering to set an alarm.



LEO:  You did not get up at midnight?



STEVE:  No, honey.



LEO:  I did.



STEVE:  Now, and I also...



LEO:  I did.



STEVE:  I know you did.



LEO:  I had to.



STEVE:  And I guess I would have been frustrated because, if I was going to get up at midnight, I would have wanted to get the product I wanted.



LEO:  Yeah, no.



STEVE:  And you did, and you were unable to get what you wanted.



LEO:  Not until next - not until I get back from vacation, let's put it that way.



STEVE:  No, but I didn't think you were able even to order the phone that you wanted.



LEO:  No, I did.  The reason I ordered two, I ordered a jet black, which will get here when I get home from vacation.



STEVE:  I see.



LEO:  October 4th.



STEVE:  And then one to take with you.



LEO:  But I wanted, well, not just to take with me, just so I could review it this weekend on the radio show.



STEVE:  And this is for the trip where you're not taking any technology along.



LEO:  Yeah, by the way, that didn't last.



STEVE:  Okay, good.



LEO:  Now I'm bringing more technology than ever.



STEVE:  So I just wanted to observe.  I mean, you've had some great things to say about the nature of what happens as companies and products age.  And this makes me think of Windows.  And that is, I'm staying with my 6 because, you know, I have a 6s Plus.  I followed them until I got everything I wanted.  I now have everything I want.  Just like, yes, a faster processor would be nice.  A better camera would be nice.  More memory might be nice, although I've got the biggest one at the time, which I haven't had a problem with.  But I don't need that stuff.



And I did sort of think it was interesting last year when Apple said, oh, sign up for the new phone every year plan.  And it's like, uh, no.  So maybe I'll go to the 7s.  Or maybe I'll wait to see what the 8 is.  My point is that this is what happens at some point when things are good enough.  And Windows has been good enough for many generations now, which is why many people are choosing to stay on 7.



LEO:  Right.



STEVE:  That is, Windows 7.  And it's very difficult, then, for companies to move people forward.  And so, in my opinion, the iPhone has achieved that same status.  And that is, it's like Word years ago was done.  But "done" doesn't make them continuing profit.  So they had to keep cranking out new versions and try to upsell us.  Except, sorry, this just does everything I want.  And I understand that.  So I just think that Apple's at the same place.  And it'll be fun to see how the whole lack of a headphone jack thing shakes out.  I did hear some corroboration of the argument that space inside the case is at such a premium that the amount of space required for the interior management of that little hole, that little penetration through the case is surprising.  And that the designers of the mechanics would love to have that back.  And I did note one of your guests noted that Bluetooth consumed energy, but failed to note that so do headphones.  And so that's probably a wash.



LEO:  Oh, yeah.  We don't really think about that.  But of course you've got to drive those speakers.



STEVE:  Correct.



LEO:  Think it's equal?  That's an equal amount?



STEVE:  And in fact I believe that the battery voltage is so low that it needs to be stepped up and provide enough pressure to drive the impedance of the headphones.



LEO:  Oh, that's interesting.



STEVE:  So that's lossy also.  So the headphones actually are a problem.  And you get so there are a lot of benefits associated with just saying, eh, we'd rather just use radio because we already have radio.  It's already there.  It already works.  We're just going to send the audio out that way.  I mean, I'm not discounting the controversial nature of it.  I'm glad I still have my headphone jack.  But I just use - I haven't had a conversation on my phone for years.



LEO:  I know.



STEVE:  I shave much more often than I talk on the phone.



LEO:  But, see, you probably don't listen to audio in your headphones, I mean your phone, that much.



STEVE:  No.  I just - I don't [crosstalk].



LEO:  Yeah.  So many, many, many, many people, it's their iPod.  I listen to audiobooks, as well.



STEVE:  Yes, yes.



LEO:  I listen on - and I have - and also to the point where I've purchased much higher quality headphones for my phone.  So it makes a big difference to me.



STEVE:  Traveling, if I'm flying...



LEO:  Same thing, yeah.



STEVE:  I use Bose sound-canceling headphones and my phone to...



LEO:  Can you use Bluetooth on a plane?  No, that's a radio.



STEVE:  Oh, yeah.  No, you're right, I plug it in.



LEO:  So that's another argument against the thing.



STEVE:  Of course, those arbitrary restrictions are getting relaxed because people are saying, you know, we're not going to fly on your plane unless we can use our stuff.



LEO:  Right.



STEVE:  And the airlines go, oh, gee, I guess it's not such a security problem after all.  So speaking of security problems, Android has had a rough week.  Google just released patches for their Nexus devices for two serious problems, the worst of which was a - and we've talked about this class of problem before - a parsing problem in JPEG images, in this case in the - do you pronounce it EXIF?



LEO:  Yeah, that's right, E-X-I-F.



STEVE:  EXIF, E-X-I-F.  That's the metadata for the JPEG.  And we've talked about how any image is sort of a compiled thing, and you need an interpreter in order to display it.  And so, and that code is tricky to get right.  There's probably regular expressions in there somewhere.  And so vulnerabilities were found.  And then what's worse is that applications were discovered in the Google Play Store, downloaded as many as 2.5 times - 2.5 times - 2.5 million times.



LEO:  Yeah, that was a shocker, wasn't it?  Wow.



STEVE:  Yeah.  So it's like a whole bunch of people have apps that have this malicious stuff in them already.  So Google's fixed it.  And of course this is the problem with this really long tale of upgrading on Android is that Google has made the patches available to their OEM partners, but no one knows how long it's going to take for those to get pushed out.  We watched, because everyone could see with Stagefright, how long it took the various manufacturers, even though Stagefright was a code red level emergency.  We had tools that allowed us to check our Android devices, and it took weeks and in some cases months for Stagefright to get fixed, when it was fixed at all.



And so of course the bigger problem is many people are using older Android devices that just won't ever get patched.  It's a computer.  And as we've argued on the podcast, there has to be some sort of responsibility that goes along with offering connectivity services to a computer like that.  As long as you're profiting from its connectivity, I would argue you have an obligation to provide patches when they're created.  But the Android ecosystem is in the process, I think, of improving.  But it's had a rough time.



There was an interesting article, I think you might have talked about it on TWiT on Sunday, about the Bluetooth Low Energy leaking information.  Or maybe it was you were talking about WiFi.  But actually this sort of pulls it all together.  There was an interesting article.  And I did have to chuckle because of a little bit of an anecdote in here.  Sean Gallagher, writing for Ars Technica, I'll just read - I'll share the beginning of his story.  He wrote:  "My new neighbor was using AirDrop to move some files from his phone to his iMac.  I hadn't introduced myself yet, but I already knew his name.  Meanwhile, someone with a Pebble watch was walking past, and someone named 'Johnny B' was idling at the stoplight at the corner in their Volkswagen Beetle, following directions from their Garmin Nuvi.  Another person was using an Apple Pencil and their iPad at a nearby shop.  And someone just turned on their Samsung smart television.



"I knew all this because each person advertised their presence wirelessly, either over 'classic' Bluetooth or the newer Bluetooth Low Energy (BTLE) protocol.  And I," writes Sean, "was running an open source tool called Blue Hydra, a project from the team at Pwnie Express," P-W-N-I-E.  "Blue Hydra is intended to give security professionals a way of tracking the presence of traditional Bluetooth, BTLE devices, and BTLE iBeacon proximity sensors.  But it can also be connected to other tools to provide alerts on the presence of particular devices.



"Despite their 'Low Energy' moniker, BTLE devices," he's writing, "are constantly polling the world even while in sleep mode.  And while they use randomized media access control (MAC addresses), they advertise other data that is unique to each device, including a universally unique identifier," the so-called UUID.  "As a result, if you can tie a specific UUID to a device by other means, you can track the device and its owner.  By using the Received Signal Strength Indication" - that's RSSI - "you can get a sense of how far away they are.  That information," he writes, "can be used for good or ill, to generate movement data about the people who carry those devices, and to watch for devices that appear when they shouldn't.  Pwnie's Rick Farina told Ars, as he gave us a walkthrough of the tool:  'I have an alert set up for when my mother-in-law's car pulls into range.  It gives me about a 30-second warning.'"  So it does have some beneficial applications.



Anyway, so I just wanted to note that what we're seeing, this is another instance of the tradeoff between absolute privacy and features, which is a problem with all of our wireless technologies.  As we've covered in the past, WiFi similarly blabs about who it is, where it's been, and who it knows.  And we very much want the convenience of having everything just work.  And I've noted that, when things just pair instantly and easily, everyone cheers.  Oh, look how easy that was.  And it's like, yeah, but what we forget is that the nature of the underlying interchange which participates in making that so easy in many cases is doing things like using beacons to broadcast their presence and, often inadvertently, the identity of their owner.



So I don't think I see this trend reversing.  It seems that we're seeing more of this, even in a privacy- and security-conscious environment now.  But people want the convenience.  And look at the explosion.  A perfect example is of IoT devices and the coverage we've been giving this year with the appalling lack of security because features trump security, for a long time.  And we're learning lessons first from the desktop and now from smartphones about how important it is to maybe rein in features, or at least really focus on security because, if you don't, you're just not going to have any.



Many people tweeted me this story because, of course, my interest in hard drives.  You may have seen this story, Leo, about the datacenter at ING, or maybe it's just NG Banks.  I think it was ING.  I just wrote NG in my notes.



LEO:  I want to say ING, but I can't remember.



STEVE:  Yeah, I think it's ING, yeah.  Their main datacenter in Bucharest, which is in Romania, was down for 10 hours, brought down by a seemingly unrelated test of their high-pressure fire suppression gas discharge system.  So everyone, everything was fine.  No fires.  But they said, "Let's test to make sure that the fire suppression system works."  So they opened the valves.  And the sound made as the gas was pushed through huge numbers of tiny holes, first of all, it pinned the meters, the sound level meters, which only went to 130dB.  It pinned them.  So we don't know how loud it was, but it was more than 130dB.



And as we've discussed before, hard drives have become so sensitive to mechanical vibration.  Remember years ago we showed the funny YouTube video of some guy shouting at his hard drive RAID array and making it go wonky.  I think we were seeing a graph of the data transfer rate.  And when he screamed at it really loudly, the transfer rate dropped because what was happening was he had, essentially, the tracks were so close together, IBM researchers say one one-millionth of an inch offset will now, in contemporary drives, will cause the drive to be unable to read its data.  One one-millionth.  What's that, a micron?  



LEO:  Well, that's a millionth of a meter.  So, but yeah.



STEVE:  That's right.  Right.  So way more than that.  One-millionth of a inch.



LEO:  Right.



STEVE:  So the sound pressure of this fire suppression gas released caused these drives to go off track when they were writing.  And that's the critical thing.  That's what did the damage because, if you're reading from the drive, what typically happens is that the drive can't find its sector, or it gets a read error which is uncorrectable because the head's too far off track.  So it goes around again and just does a retry and may be able to succeed.  But if you've got a busy datacenter where you are recording information in real time, and you force those heads off track, then you're in trouble because you catch the head while it's writing.  And it is then not writing in the right place.  And so you can't read it again, and it may well have overwritten its adjacent neighboring track.  So that's a big problem.



I think I've mentioned a couple times probably through the years that the very first version of SpinRite, it's like pre-SpinRite, because SpinRite was really born to adjust sector interleave.  But doing it correctly meant I had to also make it do really robust data recovery because I was going to low level format the track and forever lose the opportunity of recovering data.  So it absolutely had to be able to perform data recovery as part of the task of basically doing a true low level reformat of the drive.  But the predecessor to it was a utility that I wrote, just a one-off, to fix a girlfriend's hard drive.



She had, I think it was a 10MB Seagate that all of her company's financial data was on, that it could no longer read.  And it turns out that just lifting one end of the drive up, it was a voice coil-actuated drive.  And just lifting one end up allowed gravity to bias where the heads settled so that they were back over the data tracks, and it would then read.  And so what I did was I wrote a simpleminded version of SpinRite that essentially read and rewrote the data.  And I ran it several times while gradually returning the drive to horizontal and essentially migrated the actual physical tracks back to where they should have been.



LEO:  Oh, you crack me up.



STEVE:  Back in alignment.  It worked.



LEO:  Oh, my goodness.  Wow.



STEVE:  Yeah, it worked.



LEO:  That's crazy.



STEVE:  So anyway, another friend of mine had noted that he'd had problems with servers that were seeing too much vibration.  And they found, that just putting their thumb on the server damped the vibration enough that things worked better.  So this is something that everyone's going to have to pay some attention to, those who continue to use spinning hard drives, is that, with this crazy density comes some responsibility.  The drives really have to be treated carefully, especially when they're writing, because that's what had this datacenter down for 10 hours.  They had to recover because that sound did lasting damage to their drives.



LEO:  Amazing, yeah.



STEVE:  Yeah.  And also in a little bit of miscellany - I have two more.  I just thought to note, and you guys have been talking about it on many podcasts, you know you're in trouble when the headlines read:  "How to tell an explosive Galaxy Note 7 from a non-explosive one."



LEO:  How, pray tell?



STEVE:  Yes.  Or worse, when the headline reads:  "Samsung Galaxy Note 7 explodes in New York, burns a six-year-old boy."



LEO:  Wow.



STEVE:  So, and actually later in our Q&A we have a little discussion about - because there's some confusion about proper handling of lithium-ion batteries.  It's something that we've talked about here several times.  But I agree with you, Leo, that Samsung has done everything they can, which is to essentially recall a huge number of those very nice phones and take responsibility for them.



LEO:  Yeah, yeah.



STEVE:  And the fact that these things are able to do that reminds us that there's a lot of energy, a lot of chemical energy stored in those cells.  I mean, the best minds in the energy storage business, in the battery design business, their whole goal has been, for many years, how can we possibly cram as much energy as possible into the smallest size with the lowest weight?  And what we have today in lithium polymer, lithium-ion batteries, is the result of our best engineering, storing energy in that medium.  And unfortunately, when it comes out all at once in any form, that's not good.  So we want to bleed it back out gently and use it, rather than in any way have it suddenly present itself all at once, as happens when the battery structure breaks down and basically just it uses itself, it uses that energy against itself and raises the temperature.  Gas is released; you get an explosion, and a big recall of, I mean, a big, expensive recall.



And one last thing.  At TechCrunch, I think it was TechCrunch Disrupt, there was a super high-performance database that was announced.  And I loved that they used GPUs to accelerate their SQL-compatible database.  All we ever see is GPUs used for cracking things, pretty much.  They're, like, they make massive hashing engines.  And of course before custom silicon was available for our various crypto currencies, GPUs were used in order to perform hashing.  And then those got replaced by custom silicon.



But this is called the BlazingDB.  If anyone's interested, it's at BlazingDB.com.  And I also got a kick out of the fact, first of all, they tout the fact that it's between five and 140 times faster working on enterprise-class and enterprise-scale databases.  And then they boast that it's written in C/C++, calling it "a low level language with very granular control of hardware - memory, processors, et cetera."  And then they say:  "C/C++ is our dedication to delivering massive scale and hyper speed for our customers."



And I sort of thought, okay.  I guess that's probably, when you compare C, as we've talked about over the last couple weeks, to various higher level languages which represent much greater levels of abstraction from the low level, you know, C was designed to be an OS implementation language, just far enough away from the actual hardware of the machine to give you machine independence, yet without much cost in performance.  So anyway, I thought it was cool to see our ubiquitous GPUs being put to a nice non-crypto and non-graphics accelerating task.



And speaking of C, I needed to correct the record.  I said incorrectly last week that Doom was written in assembler.  Turns out only a tiny bit was written in assembler.  Most of it is written in C.  I got a note from James Boer in Kirkland, Washington, under the subject "Doom Trivia."  And he wrote:  "Just FYI, Doom was written in C, with some small portions of rendering code in assembly."  Which is exactly right.  I went and looked.



He said:  "Even so, you're correct that it was masterfully coded.  Doom was partially what convinced me," he writes, "to become a professional videogame programmer.  Doom was not the first pseudo-3D rendered game, nor was it the first shareware game.  What made it unique, among a few other details, was that it was one of the first games that could render reasonably complex world geometry using the entire screen on a 486-class machine - and, of course, for the stunningly visceral game play.  In case you're wondering why I call it 'pseudo-3D,' that's because it's not true 3D rendering like Quake" - which of course came after - "and is sometimes referred to as '2.5D.'"



And then I didn't realize, but GitHub has id Software's source.  And I have the link in the show notes, if anyone is interested.  It's at github.com/idSoftware/DOOM.  John Carmack posted the entire source of Doom up there.  And in fact, as is often the case, there is a chunk of assembly in the most time-critical portion because nothing beats hand-designing code for speed.  But I was very impressed that as much of it was in C as is.  I mean, virtually all of it is in C, with just like a page and a half of assembly code down in the actual texture mapping and rendering portion of the code.  So, James, thank you for the correction.  I'm glad for that.



LEO:  This is great, to have the source code.



STEVE:  Isn't that neat, to have the source of Doom?



LEO:  Yeah.



STEVE:  Yeah, I mean, anyone who was a budding game programmer, there are, represented in that code, a huge number of really great ideas.  And I was curious.  I have a - Michael Abrash was one of the great low level coders of yesteryear.  And I checked because I was curious.  I have his - he did the "Zen of Assembly Language Programming."  I have all of his original books, and also the "Graphics Programming Black Book Special Edition," with a foreword written by John Carmack, where John talks about having tried many times without success to lure Michael away from whatever he was doing during the time that Doom and then Quake were being put together because these guys are masters of the low level arts.  Great coders.



LEO:  Yeah.  Yeah.  Really  neat.



STEVE:  And I have a nice note from Paul in Worthington, U.K.  I just loved how he put it together.  He shares his recent SpinRite success with SSDs, which he wasn't aware of.  He said:  "Steve, I cannot remember," he writes, "how I came across SpinRite.  Think it may have been back at v5 then.  I assumed when I switched my system drives to SSD that I would be using SpinRite a lot less.  I used to have the habit of running SpinRite regularly on my system drives every few months, or if the system started to slow.  It always was great, and I have recovered drives that blue screened or failed to start completely.



"I built a new machine last year using a SanDisk SSD.  I chose an enterprise version with a 10-year guarantee" - this is last year - "because, as a commercial photographer, I need speed, but value reliability even above speed.  It was great.  SanDisk dedicated software allowed me to monitor it and run a TRIM command.  I had a big project running," he says in parens, "(layered Photoshop files sized between 3 and 7GB on disk), and the system slowed, particularly on startup.  But some days it was fine, fast and no problems.  SanDisk emailed to tell me I should update the firmware, but backup everything on the disk first, and also update the dedicated SanDisk SSD Dashboard software.



"First, I updated the SanDisk SSD Dashboard software, and it FAILED COMPLETELY," he has in all caps.  "It just destroyed the existing working version.  No worries, just roll back the system."  And he says, "I use FarStone recovery software.  No good.  Install the old version of SSD Dashboard, another no.  Okay, I should have downloaded and copied it like I always used to, but these days you don't need to, do you?" he writes.  By this time I'm tearing what is left of my hair out.  So of course I start thinking, 'What I need is SpinRite for SSD.'



"To cut a long story short, I dug around the Internet and discovered that SpinRite can help SSDs.  OF COURSE IT DID," he writes in all caps.  "It found one defective and unrecoverable sector close to the beginning of the drive, and two further ones that it recovered.  Rebooted the machine, and since then it's been running like lightning again.  I, for one, know that SpinRite is one of the most cost-effective software purchases I have ever made.  I look forward to its future fixing both my spinning and my non-spinning mass storage.  Thanks for your great software and the Security Now! show."  And, Paul, thanks for sharing your experience.



LEO:  Awesome, awesome.  All right.  You want to do some questions?



STEVE:  Let's do it.



LEO:  I've got them right in front of my little eyes right here.  Let's start with JK in LV.  Las Vegas?  Probably.



STEVE:  That's what I was wondering.



LEO:  I'm thinking.  Could be Little Village.  I don't know.  Wants to know about the need to wipe an encrypted drive.  Is there ever a reason to do a secure delete on a hard drive that's been using whole disk encryption?  I think it's dumb, no matter if an SSD or spinning drive.  My friend says, "Oh, no, you're wrong."  I'd be happy to be told otherwise, if the Security Yoda disagrees.  Thanks for everything you do.  Love Security Now! and SpinRite.  All right, Security Yoda.  [Yoda voice]  What drive must we delete?



STEVE:  So there's two different ways today that we have whole drive encryption.  One is if it's built into the hardware of the drive, and the other is if we add whole drive encryption afterwards, that is, on top of an unencrypted drive.  And I think the second, from reading the question, I think the second is what he was referring to.  And the advantage of the second is that we know exactly how the system works.  Where the encryption is built into the drive hardware, you just can't know.  And everybody who listens to the podcast knows how I am about details.  That's where the devil is.  It matters how they implemented it, whether it is truly secure when you change or lose the password or delete it or do a secure wipe or something.



The advantage of adding our own is that we know how it works.  And it is absolutely true.  So JK is right.  His skeptical friend, I would argue, is incorrect in that, if you have encrypted, you've added your own whole drive encryption to a hard drive before you have started using it.  That's kind of important because, if you're really super concerned, because if bad sectors were spared out, that is, removed from service, and while - I'm sorry.  If they were removed from service while the drive was unencrypted, they would forever remain inaccessible to the encryption and unencrypted.  There's not going to be much data there.  There's going to be 512 bytes, typically, of data because we typically spare out on a sector granularity basis.  But still it's not encrypted.



So if you know you want security, encrypt the drive immediately, then start putting your data in.  If you then delete the key, maybe overwrite the header, I don't remember now if TrueCrypt has an explicit "expunge the header."  Because that's - it's in the header, which actually is stored redundantly because it's so important.  You want to absolutely securely delete that because that's where the master key is which your password is used to decrypt, which then allows the drive to access itself, essentially.  But with that gone, and proper encryption, it's just pseudorandom noise.  We understand how to do that now.  We've got that technology nailed.  Without the key and contemporary encryption, there's no way to reverse that data.



LEO:  You don't have to worry about the swap drive or anything like that?



STEVE:  Well, all of the good technologies now do that.



LEO:  They encrypt the swap, as well.



STEVE:  They will encrypt the swap drive and encrypt the whole boot process and everything.  The hibernation file and the swap file, also.  So that said, the data is still there.  It's encrypted.  It's inaccessible.  If you really are a belt-and-suspenders kind of person, yeah, run DBAN, Darik's Boot and Nuke, over the drive.  But don't do it 15 times.  Just write zeroes.  That'll be plenty.



LEO:  [Yoda voice]  Encrypt or do not encrypt.  There is no [indiscernible].  That was terrible.  I'm sorry.  I apologize.  Brian in New Haven, Connecticut has our next question, wonders:  How can I have told the difference between the Ubiquiti EdgeRouter X and a managed switch?



I have appreciated your discussion of the Ubiquiti EdgeRouter X, our little $60 miracle worker, over the last several episodes of Security Now!.  I can understand now how that device provides five separate logical interfaces that allow for network isolation in a way that the other blue box routers containing a simple switch cannot.



But if I had just been browsing Amazon, and the EdgeRouter X appeared among several managed switches, I doubt I could have discerned the difference on my own.  Is there anything in the listing that could have made it more evident?  The mention of 5GB RJ45 ports?  Seeing the ports labeled "eth0" through "eth4"? I'm trying to figure out if there was something obvious I missed, or if the Amazon listing obscures this capability?



Thanks for the excellent podcast.  Been a listener for at least seven years and owned my copy of SpinRite for nearly that long.  Wish I had an anecdote to submit, but maybe I don't because I run it regularly on all my drives.



STEVE:  And you know, I forgot that I should have noted - the guy that's provided the nice testimonial about SpinRite on his SSD, if you're listening, do run SpinRite, now that you know it works, on that SSD.  Just use Level 2, which is the read-only pass.  And that'll still help the drive to keep itself in good shape.  So definitely worth doing from time to time.



Brian's question was a good one, and it made me think of the time I spent digging into - what was that other, it's not MikroTik. 



LEO:  You liked the MikroTik.  That was a good solution.



STEVE:  MikroTik?  I don't remember now what the right way to say that was.



LEO:  No, I think it's like MikroTik.



STEVE:  Anyway, it just - it was so unclear from all the descriptions - they had, like, 75 different routers in the first place.  It's like, okay, really, do we need this many?  But it just wasn't clear.  So I had to dig into the chip in order to see what these things actually did.  And that's when I discovered that the chips that even incapable routers were using were capable of doing this.  But they just hadn't bothered to.  So the answer, Brian, is, and to our listeners, no, it's not obvious.  And it would be nice if manufacturers understood that this is a feature we care about.  I mean, they talk about things like power over Ethernet and that MDIX where it doesn't matter, you don't have to have crossover cables anymore.  The jack is able to flip the connections around when you're jumping between ports that have the same sense, whereas we used to have crossover cables.  All that's kind of gone away.  They talk about those things.



But the problem is there are managed switches which give you, for example, filtering on ports, but not the ability to define disjoint subnets.  And they're not routers because, if you have multiple networks, that's a classic definition of a router.  So maybe the distinction, although I don't know that you could hold them to this, is that the Ubiquiti EdgeRouter, the key is the word "router."  A managed switch might have that capability.  For example, that Cisco, that SG300 series, it's technically called a "managed switch."  It's not called a "router," but it does allow you to set up different subnets on that box.



So, unfortunately, Brian's identified a gray area.  And the only thing I know you could do would be not to look at the bullet points, unfortunately, because they're just not going to be clear.  Go track down the manufacturer's site.  Maybe they say more.  Maybe look through any social media postings that are hung onto reviews to see what other people are saying, whether they were able to use that or get that working.  And check out the manual.  Grab the PDF of the manual and see if it gives you that feature.  Unfortunately, there doesn't seem to be an easy way to do this.  We do know that the Ubiquiti EdgeRouter X does the job.  And I just haven't found a reason, unless you needed more than five ports, for choosing a different piece of hardware.  At 50 bucks, it's a real bargain.



LEO:  Some concern has been expressed about Ubiquiti's privacy policies and so forth.  I haven't really - I haven't looked into it.



STEVE:  I saw that go by.  And I don't remember why I dismissed it now.  But I sort of thought, oh, okay, that's interesting.



LEO:  The problem is all terms of service will have these overly broad, for legal reasons, overly broad things like we could use this information in a variety of ways.  And they're just protecting themselves against [crosstalk].



STEVE:  And often it's the corporate attorney who insists on putting this language in there.  I remember, I've always had this policy that someone could use SpinRite on all the drives they owned.  But my printed manual did not say that.  And I argued with my marketing and sales department, back when I had them.  Now I don't, so the problem went away.



LEO:  End of argument.  End of argument.



STEVE:  It's like, no, I'm not going to ask someone, I mean, you're crazy to think anyone is going to buy it four times if they have four drives.  That's nuts.



LEO:  Right, right.



STEVE:  So I won.



LEO:  Commonsense is uncommon.



STEVE:  Yeah.



LEO:  Especially when you get a lawyer involved.  Aaron, who is @vader in real life, @vaderIRL on the Twitter, needs to - [Yoda voice] Darth Vader he is - need to use a VPN and wonders whether Steve still recommends proXPN.  Actually, I don't think you ever recommended proXPN.  That was an advertiser, so let's make that clear, that advertising endorsements are not the same.  They come from us, from me, and I don't ever expect Steve to get involved in that.



STEVE:  Well, and I sort of have an interesting take because things have changed.  In our contemporary modern surveillance world, the traditional centralized VPN server model, I would argue, has become maybe a little challenged.  Certainly valuable, but I would say there's certainly a use case for it.  But the problem is, if what people want is true privacy and surveillance avoidance, the concern is that this is not unlike the trouble that Tor exit nodes are known to have.



We know that intelligence and law enforcement agencies are naturally attracted, sort of like bees to honey, to Tor exit nodes because that's where the information is.  Something is coming out of there that somebody wanted to obscure somehow.  They went to some effort in order to hide themselves, which sort of begs the question, "Huh, wonder what's going on there?"  And a VPN's exit node is essentially, it is a data concentrator by nature.  It's inherently similar.  There are people using a VPN for whatever reason.  But at that server point, the traffic emerges unencrypted from the VPN encryption tunnel that was carrying it, out onto the Internet, where it is then subject to scrutiny.  So as opposed to the pre-Snowden world, today's hugely increased, nearly de facto application of TLS encryption for all web communications does, I would say, dramatically reduce the need for a separate encrypted tunnel in many instances.  Not all.



And the problem is we can't know that all of our traffic is encrypted unless we explicitly take responsibility.  But so, for example, the typical model of operating at open WiFi at Starbucks, or a hotel's network, which we used in the past as examples of horrifying problems, where you just - it's amazing to see the amount of plaintext going by.  That level of plaintext has dropped to almost nothing because encryption is becoming, post-Snowden, there's been a huge move in that direction.



And so for many applications I think that running one's own VPN server at home can make much more sense.  Then, when you're out on the road, your traffic can be protected on its way to your home base, where you are then able to directly access your home assets - like, Leo, your Drobo, which you've left at home with your 300 Audible books, and you can grab one that you forgot to download.  But also your traffic can emerge onto the Internet from there, even if you're traveling remotely.



So what that avoids is the attention concentration that any commercial service creates.  And of course, as we know, home routers are increasingly supporting OpenVPN natively.  The pfSense firewall offers it because it's FreeBSD based, and OpenVPN is a feature, a dropdown menu feature of it.  And even though it's not available at the UI, we know that at the command line even the Ubiquiti EdgeRouter is able to run OpenVPN.  So there's, you know, not only is it providing you with really good security, it's also giving an Internet-facing OpenVPN service that the user can access wherever they are in order to get their traffic out of the environment where they're located securely to their home base.  And there they have access both to their internal network in a secure fashion, as well as the rest of the Internet, without it coming under the concentrated scrutiny of any single high-volume exit point onto the Internet.



And as we're discussed before, that little controversial super simple shell script which was created by one of our listeners, that PiVPN project, for $35 you get a Raspberry Pi.  Which, by the way, just passed 10 million units sold.  Which is amazing when you consider it's not even a phone, it's a circuit board.  Yet 10 million of them have sold.  They just crossed that benchmark.  So that little Raspberry Pi can be used to create an OpenVPN endpoint that will do the same thing plugged into a spare port inside of anyone's network, into the router there.



So it is the case, I think, that a VPN provider can be needed, for example, if you want an international presence.  And we know that we want one that does not log our traffic.  And we know that proXPN is not a traffic logger.  So I do support them from the standpoint of knowing of no disqualifying factor.  I think they're a good company.  Although, again, I'm beginning to wonder whether that traditional traffic concentration model holds up as well as an individual personal VPN which allows you to access the assets you have at home or the Internet, no matter where you are.



LEO:  I might disagree just slightly with you.  It depends on what your goals are.



STEVE:  Correct.



LEO:  Not everybody is trying to avoid government surveillance.  I mean, that is just one of many reasons to use a VPN.  So, yes, if you don't want - if you're trying to avoid government surveillance using Tor or VPN, or PGP for that matter, is a red flag.  And so you might be attracting attention.  But as you point out, people use VPNs for a lot of reasons.  You're not going to use your home VPN if you want to avoid geographic restrictions.



STEVE:  Correct.



LEO:  You also, I think, should use a VPN in an open WiFi access point.  I've said, I agreed, for a long time I said exactly what you said.  Well, as long as you're using encrypted services, it's not a big issue.  But increasingly these very widely available tools like the WiFi Pineapple that Hak5 sells, which they use in other ways to attack you, even if you're using SSL websites.  I mean, if you're sitting in an open WiFi access point, they can observe some things about you.  They can apparently, and I'm not an expert on this, even figure out what WiFi access points that your system has attached to in the past and then spoof it.



STEVE:  Yeah.  Unfortunately, a VPN won't protect you.



LEO:  Ah, yeah, because your WiFi would then be promiscuous and join this other guy's thing.  You mean a VPN won't protect you against a Pineapple?



STEVE:  No.  No, because essentially the VPN is data traffic, but you still have your WiFi presence.



LEO:  Oh, I see what you're saying.



STEVE:  It's still there.



LEO:  That's why I use a hardware firewall, the Tiny Hardware Firewall.  So at that point I'm using the firewall to choose an open access point.  It joins the access point.  I join the firewall.  The firewall is my access point on all my devices.  And it also then logs me through a VPN, and optionally a Tor server, as well. 



STEVE:  Yes.  So it becomes your point of presence.



LEO:  Right.  And it's too dumb to be useful to anybody with a Pineapple.  I think.  I hope.  Tell me if I'm wrong.  So I think there are arguments for using a VPN that might supersede the argument, well, it attracts government attention.



STEVE:  Well, and we have Part 2 of Aaron's question.



LEO:  Coming up next.  I was thinking about going to - and the other reason is many people have bandwidth restrictions.  There's, you know, a home VPN server isn't always a perfect solution.



STEVE:  Good point.



LEO:  Yeah.  Part 2 from @vaderIRL.  [Darth Vader voice]  I was just thinking about going to the Pi route.  My father - we know who his father is.  My father travels to Kuwait - oh, sure, Kuwait - for work and just needs a basic U.S.-based connection from time to time.  Well, there you go.  That's a good way to do it.



STEVE:  Yeah.  So anyway, so this was in a little Twitter dialogue that I had with him.  And so I sent back, I noted, I said that's perfect.  The only glitch is that home IPs can drift.  So arranging some DynDNS is useful for finding a router's current public IP.  And DynDNS is short for dynamic DNS.  And the idea is that it's a service, a public service, a publicly accessible service that your router informs of its current IP so that you're able to query the public service.  And then it will tell you, it will inform you of any changes to your router's IP.



I did a little bit of looking around, and I remembered that there were some registrars that offered that as part of their package.  Unfortunately, Hover doesn't.  Hover is my chosen registrar.  Whenever I can get a domain from them, I do.  There are some top-level domains they still don't support, so I'm stuck on a couple of those with Network Solutions.  But I'm really happy with Hover.  But they do not offer a dynamic DNS natively.  Namecheap does, and Google, the Google Domains service does.



And it looks like Google Domains, for a dotcom domain, is $12 a year and includes dynamic DNS support.  So many people already have a relationship with Google.  So to me that seems like the path of least resistance.  If you were interested in doing this, make up some crazy domain for yourself.  You will have a dotcom domain, maybe for the first time in your life, your own.  Host it with Google, and for a dollar a month Google will provide the domain registration and supports dynamic DNS so that you're able to find your router using your own custom dotcom domain wherever you are out in public.  And so this is...



LEO:  There are routers that do this, too.  My Asus router does DynDNS.  A lot of routers will do that.



STEVE:  Correct.  Although you need to use a third-party service.



LEO:  Yeah, they offer it through their [crosstalk].



STEVE:  Yeah.  And there were - it used to be free.  Now they're beginning to charge because they're...



LEO:  Ah, that's too bad.



STEVE:  And so it turns out, it looks to me like Google is the - I wasn't able to see anything that was as good as 12 bucks a year, a dollar a month for that service.



LEO:  Right.  Yeah, that's a good deal.  What was I going to say besides that?  Oh, also your router may have a simple OpenVPN solution.  You can kill two birds with one stone.



STEVE:  Yeah.



LEO:  Darth Vader.  Scott Pritchett asks via Twitter, he's @bitman:  I don't understand.  I don't understand, Steve, how a memory page could be identical between VM instances, yet contain their private key.



STEVE:  So I don't think I was as clear - he's referring, of course, to last week's coverage of the Flip Feng Shui exploit.  And I wasn't as clear as I should have been.  I did say that it was the public key.  But I'll say it again, it's the public key, which is available because it's freely given out as part of the authentication.  And this is something I don't think I've ever really explicitly explained.  I've shied away from it because you know I don't like to be inexact.  And the math is very tricky.  But here's the way we can think of it.  The public key contains the private key because the private key - and I'm deliberately simplifying.  But the private key is one of the two primes.



So essentially what we know is that it's impossible to separate the multiplied primes in reasonable time.  So the public key contains the private key.  And the trick is that you can't pull it back apart.  So essentially it's hiding in plain sight.  The public key has the private key as part of it.  And it's only if you knew the other prime that you could then divide that by the public key in order to extract the paired prime which is the private key.



So now you can understand why this bit-flipping works.  If you do something to it that suddenly makes it much easier to factor, then this problem of deliberately created non-factorizable huge primes disappears.  But that's really the key to the way this crypto works is that the private key is one of the two primes that is multiplied to give you the public key, but no one knows what it is.  There's the public key.  Somewhere in there is the private key, but you can't find it.  It's literally hiding in plain sight.  Which is so cool.



LEO:  Here you go.  Steve Gibson.  You ready for more?



STEVE:  You betcha.



LEO:  The action continues with Question 5.  Stanislav Leaderman in Oregon - I love this question.  He wants to know how to be secure with less technology.  With less technology.  I used to be a regular listener and strong follower of Steve's suggestions related to security.  I bought SpinRite seven or eight years ago.  I still like it to this day.  However, over a few years I haven't been focusing so much upon security due to other distractions.  Moreover, security has become so much more complex that an ordinary person can't get his head wrapped around what one should and shouldn't do.



For example, banks require your phone number to send a text message.  Yeah, that's a good security measure.  But then they sell your phone number to telemarketers, and you get sales calls late in the evening.  I used to give banks my Google Voice number, but then they began requiring a physical number.  I just went through an ordeal with CITI credit cards.  They wouldn't accept a forwarding number like Google Voice, and they knew Google wasn't mine since they rely on some third party who apparently has all my personal information, including my actual cell phone number.



Steve, what are the prudent measures one could take to secure accounts like banks and emails against fraud, but also not to be so caught up in this that it doesn't take over and become your entire life?  Sorry for the lengthy email.  What measures would you recommend to implement?  Paper passwords?  YubiKey?  I have LastPass, but not a smartphone, only a flip phone. It seems many applications like LastPass need a smartphone for their multifactor authentication.  Thank you.



STEVE:  I thought that was a really great question because we're so steeped in technology and our smartphones that it's easy to fail to appreciate that some of these solutions aren't applicable to everyone.  And it's like, yeah, it's easy to say, oh, every website you use needs to have a unique 20-character crazy high-entropy password.  But, boy, I mean, I don't know how I would do it if I didn't have LastPass or a similar password manager to manage that for me.  And we've been talking about how SMS second factor is falling by the wayside and now formally being deprecated in favor of the time-based password.  But that requires an app on your phone, which is, you know, we just assume someone's going to have a smartphone.  But what when you don't?



LEO:  There are desktop authentication apps, though.  You don't have to have a phone, only if you're mobile.



STEVE:  Right.



LEO:  And you can always have it texted to you.  Well, not always, but in many cases.



STEVE:  Right.  So anyway, I did appreciate his observation.  I mean, this is really becoming a mess.



LEO:  Yeah, yeah.



STEVE:  And smart people are trying to come up with solutions, and we keep trying things.  I don't have a great answer.  And especially for somebody mobile who is unable to use the technology which sort of does, I mean, I would argue he's right.  It requires a smartphone.



LEO:  Right.



STEVE:  If you've got a flip phone, well, you can't play.



LEO:  That's the nice thing about authenticator apps.  You don't need to give them the phone number.  Although you're going to give the bank your phone number anyway for all sorts of other reasons.



STEVE:  Good point.



LEO:  Get a bank that has a good privacy policy.  If they, I mean, I wouldn't assume they're selling your phone number.  We all get calls all the time.  I have an unlisted number I never use, but I get calls on it, soliciting calls, because they're calling random numbers.



STEVE:  Yeah.  I have two physical landlines, and I get the same robot spaced about 30 minutes apart on each phone.



LEO:  Yeah, it's an automated dialer.



STEVE:  Because they're just - yup.  That's all they're doing.



LEO:  At this point, they're not targeting people anymore.  They just call everybody.  It's so cheap to get labor in India and elsewhere.  You know, Lisa and I were driving to the football game last night, and a call comes in from a very long international number.  And I thought, oh, maybe it's Abby.  I'd better answer it because she's in Mexico.  And sure enough, "Hello, this is Microsoft.  We've been seeing some unusual behavior on your Windows system.  Are you in front of your computer right now?"



STEVE:  Yeah, please launch event viewer.  And, oh, look at that, yeah.



LEO:  And I thought, I could play along with him.  And instead I said, you know, "Shame on you for scamming people.  You should not be doing this." 



STEVE:  Good.



LEO:  "How does your mother feel about you doing this?"  I tried to humiliate him.  I don't know if he - he hung up, by the way.  I don't know if he...



STEVE:  Jobs are scarce, I think.



LEO:  Yeah, and I understand.  But then scamming people is not the solution.  And by the way, that was a cell phone number.  It wasn't my Google Voice number.  It wasn't a public number.  It's not widely available.  They're calling random numbers.



STEVE:  Yeah.



LEO:  You know.  So don't assume that your bank has sold your number.  Bu if they do, if you really think they are, get a better bank.



STEVE:  And caller ID is now spoofed.  I noticed...



LEO:  And that's why you can't tell.



STEVE:  ...that things show as my area code.



LEO:  Oh, yeah.



STEVE:  It's like, okay, now.



LEO:  Yeah, yeah.  It's always my area code now.  "Hello.  Your auto insurance is about to expire."  No, it's not.  "We have a very important offer for Leo Laporte."  Actually, they don't usually know my name.  It's, you know, I wish there were some better solution.  But certainly, look, ask the bank what its privacy policy is.  And I would never, I would never patronize a bank that is selling your information of any kind to anybody.  Banks have to have a lot of personal information about you.  You want to be able to use your phone number with a bank; right?



STEVE:  Yeah.  They are fudging in that direction, though.  They send you their privacy updates in fine print.  And it's like, oh, okay, just do whatever you're going to do.



LEO:  Yeah.  Michael Zimmermann, Sydney, Australia wonders how SQRL can evolve - into a killer SQRL.  No, not that kind.  Hi, Steve and Leo.  There are classic engineering designs.  We all remember the 1963 Jaguar XK-E Roadster.  My best friend in sixth grade's dad had one of those.



STEVE:  Ooh, yes.



LEO:  Yeah.  The 1955 Mercedes-Benz 300 SL.  That's the one with the doors that went - the gullwing doors.



STEVE:  Like you have now, Leo.



LEO:  I have falcon wing, please.



STEVE:  Ah, falcon, upgraded from a gull.



LEO:  Let's suppose you have one, but you can only keep it if you convert it by swapping out the engine with the latest electric model.  Quite a challenge.



Now, I started thinking about SQRL, how it is going to be a classic design with very high adoption across major websites.  That's what we all hope for.  As I understand it, you have your master key and your web URL as inputs, the black box engine where the crypto runs, and the resultant output, which is used by the website to identify you.  You have explained how you can rekey your master key.



But I was wondering what happens if your engine is no longer safe, and you need to swap it out for a better model.  A different engine would produce different output; right?  Does the client and server have the ability to say we are using crypto engine V6, V8, electric, warp drive?  Or Mr. Fusion?  Thanks for the show, and looking forward to your explanation. Please let us know how to push SQRL - I think he means push it as in get the word out - once it's released.



STEVE:  I hope that's what he means.



LEO:  I think that's what he means.



STEVE:  Yeah.  So the answer is yes.  And it's as simple as a version number, which is built into the specification.  And the way it's - remember what we've done with SSL and TLS, "we" meaning the industry in this case, where it was always built with a large array of different suites that it could use, where the browser would offer the ones it knew about, and the server would respond with what it understood.  SQRL has a similar facility.  It's a compound version number which can contain any information.  Right now it's set to one.



But, for example, if it turns out that there is something where we need to evolve, if any fundamental change needs to be made, either the crypto needs to be evolved, or a problem is found, or we want to add some feature, not change one, but add it to a future one, then the client could say v1,2 or anything it wants to, really, depending upon how the spec evolves.  The server then receives that, knows what the client understands, and then the server's response is which version it chose of what the client knew.  So very similar to that model, and that protects us and makes us future proof.  So, yup, we got that.



LEO:  Question 7 comes from an anonymous listener who shared a brief note about Windows Update issues.  He says:  Can you address this for us, Steve?



STEVE:  Yeah.  This was just - I put this in here as a reminder to me.  Thank you, Leo.



LEO:  This is Woody on Windows.  You've quoted him before, Woody Leonhard.



STEVE:  Yeah.  And I guess Windows 7 is having a real problem with getting updated after a clean install.  Some people have said that they imagine the reason that Never10 is still being downloaded, because I've built-in that little grabber of Windows Update Update, and it just makes it easy to apply.  What's very cool, though, I did some digging, and I found an answer which is very comprehensive at answers.microsoft.com.  The link's in the show notes, but it's also made it now into the permanent link database which is the link farm, GRC's link farm.  So anyone - and believe me, this is what you want to use.  Even better than the Windows Update Update Update Update link that I have already in the link farm, it walks a Windows clean new install through a surprisingly daunting process that involves interrupting normal things, setting it to never update, rebooting it, going in and stopping a service.



Anyway, this guy has worked through what it takes to absolutely nail it.  So I just wanted to let our listeners know.  I know that we have many people who are having whatever occasion to install Windows 7, maybe only for testing purposes in a VM, if not in a new system.  But from everything I've seen, this really works.  It's new.  It's mid-August, I think, was the date of it.  And if anything changes after today, actually, Patch Tuesday is today, then it'll be updated.  But if anyone's curious, GRC.com/linkfarm in the upper section of permanent links, it now has a home there because it looks like this is the way to do it.



And in fact the guy's posting starts out saying:  "Windows Update has become quite problematic for Windows 7 users.  For the past year or so, we've been working to find a solution that will work for you.  We have found one that works very well indeed for most.  We know for certain this works well for August 2016 until this September 2nd Tuesday, known as Patch Tuesday.  We hope to be able to update this for September."  Anyway, anybody, I would say, in the future check this posting because they will keep it updated, and I wanted to make sure people could always find it.



LEO:  Nice.  GRC.com/linkfarm.



STEVE:  And, boy, you know, I guess it's unfortunate that it's that difficult.  I can't imagine Microsoft did this deliberately.  I think it's just that the original Windows 7 image, which is SP1 is the latest image you can start with, it itself is so old that what Microsoft didn't do was provide backwards compatibility for Update all the way back to there.  And so you sort of have to bootstrap yourself.  I mean, they provide the means to get there, but it's just not automatic.  It's not install Windows 7, and then click "Give me all the updates."  



LEO:  Question 8 is a follow-up to last week's Flip Feng Shui episode.  George Mallard in Texas wonders whether DRAM ECC could prevent Rowhammer.  He says:  I heard your podcast on Rowhammer.  I have a quick question.  Would parity error checking, or ECC RAM on a server, pick up that bit that was flipped and potentially flip it back?  If so, do high-end cloud servers employee ECC RAM?  Thanks for your show and SpinRite.  I use it monthly on my system.



STEVE:  So that's a very good point, and it's something I skipped over in the coverage of Rowhammer last week, although the guys that wrote the paper did cover it extensively.  In their Section 6.1.1 of the paper they wrote - and that section is about hardware, that is, hardware remediation.  They wrote:  "We recommend DRAM consumers perform extensive Rowhammer testing to identify vulnerable DRAM modules."  And I'll talk in a minute about how end-users can do that because it turns out we can.



"These DRAM modules should be replaced; but, if this is not possible, reducing DRAM refresh intervals, for example in half, which I did talk about last week, may be sufficient to protect against Rowhammer.  However, this also reduces DRAM performance" - but not by much, 1 or 2%, they wrote - "and consumes additional power.  Another option is to rely on memory with error correcting codes (ECC)" - which actually works in a very similar fashion to the way we've often discussed it works on hard drives, where there's additional information stored with the memory that allows it to fix its own problems, essentially - "which protects against single bit flips.  Unfortunately, we have observed," they write, "that Rowhammer can occasionally induce multiple flips in a single 64-bit word confirming the findings of the original Rowhammer paper."



So not only did the original Rowhammer paper mention that, they've seen it in their own subsequent research.  "These multi-flips," they write, "can cause corruption even in the presence of error correction memory.  More expensive multi-ECC DIMMs can protect against multiple bit flips, but it is still unclear whether they can completely mitigate Rowhammer.



"A more promising technology," they write, "is directed row refresh" - which I did talk about last week - "which is implemented in low-power DDR4" - which is abbreviated LPDDR4 - "and some DDR4 implementations.  Low-power DDR4 counts the number of activations of each row; and, when this number grows beyond a particular threshold, refreshes the adjunct rows, preventing cell charges from falling below the error margin."  So it's cool, it's sort of a demand refresh-based RAM hardware.



"Newer Intel processors support a similar feature for DDR3, but require compliant DIMMs.  While these fixes mitigate Rowhammer, replacing most of current DDR3 deployments with low-power DDR4 or secure DDR4 DIMMs is not economically feasible as it requires compatible mainboards and processors."  So you're not just swapping the memory out.  You need to change everything, essentially.  "As a result," they write, "a software solution is necessary for mitigating Rowhammer in current deployments."



Now, what's cool is that the free, well-known, venerable Memtest86 has, since v6.2, added a Rowhammer vulnerability test.  And I got a kick out of noticing, as I was doing some research, some people asking the question, "Hey, why does my memory pass all the tests except Rowhammer?"  It's like, gee.  I wonder why?



LEO:  Oh, my.



STEVE:  Anyway, so Memtest86.com, M-E-M-T-E-S-T-8-6 dotcom.  I imagine that'll be of huge interest to our listeners, who are just curious whether they've got Rowhammer-susceptible DRAM.  You can now find out just by running that on your machine.



LEO:  I'm amazed that program is still around.  And not only still around, but being updated.



STEVE:  Yes, yes.  It is still current.  And I used it, oh, I used it - I use it in a perfunctory fashion whenever I'm building a new system, just as part of what I do, is after the hardware is there - because you boot it.  It takes over the system, much as SpinRite does because it needs full access to everything.  And it just - it's got a nice little text display, and it just cranks away and exercises your RAM.



LEO:  It's amazing.



STEVE:  And you remember that I was having - it was a challenge for me.  I was trying to use 128GB at high speed, and I was never able to get that to work.  So I either had to drop to 64GB at high speed or go to a lower speed to get 128GB.  And I opted for high speed and 64GB.  Although I've not done any extensive benchmarks yet.  But I was using Memtest86 to essentially torture-test the RAM at all of these different speed settings as I was setting things up.  So it's a super useful utility. 



LEO:  Wow.  Lai Min-Hui in Malaysia wonders about lithium-ion battery advice:  For years, I've followed your advice that lithium-ion batteries loved to be fully charged, so plugging in the charging cable whenever we can is the best thing to do in terms of prolonging battery life.  However, assuming that lithium polymer is equivalent to lithium-ion, Father Robert mentioned in TWiT TNSS-69 - that's The New Screen Savers #69 - that these batteries prefer to stay at 50% charged.  I don't know who to believe anymore.  Hope you can clarify.  Well, they're both right, Lai Min-Hui.



STEVE:  Exactly.  The good news is we both get to be right on this one.  Here's what's important to understand.  Not loving to be deeply discharged is not the same as loving to be charged.  So what I have often said is that you do not want to run lithium-ion batteries all the way to the ground.  And I've seen real-world evidence of this.  I've got a good friend who's killed a number of his non-battery replaceable iDevices because his habit was just wait till everything turned red, and there was like a little sliver, a little itty-bitty sliver, and it said 2% left.  Then he would plug it in and charge it up.  And what do you know, six months later it was dead.  It would no longer hold a charge.  And I explained to him, I said, "No, no, no, no, no.  Lithium-ion cells really do not like to be run to the ground."



So my advice about plugging them in is to keep them off of the ground.  The challenge is that they also don't like to get overcharged.  And so when you're right up there with the battery topped off, you're skating on thin ice because, if the charging technology is not good, it can push it too far, and then you start damaging the battery.  So, and then we were just talking about this a couple weeks ago, actually, how impressed I was that Lenovo noted that I had my Carbon X1 third-gen laptop plugged in.  That's like, it was just living on the adapter.  And it popped up a little balloon and said, hey, we see that you seem to be, like, just docked all the time.  In that case, bringing the battery down to half-mast will make it happier.  And so I said, oh, that's brilliant for you to, like, realize that.  And so I gave it permission, and it let the battery come down, and now it holds it at 50.



So the problem, of course, is if I then grabbed it to take it out on the road, it's already half discharged.  So the idea is that, in this mode, I would turn that off.  It would top off the battery.  Then I would unplug it and take it on the road with me and use regular cycling.  But when it's living on the adapter, much safer and better for the battery over the long term if it's kept at about half full.  So that's what Father Robert was saying.



And I did want to take this opportunity to draw the distinction between "love being charged," which they don't quite so much.  What I really meant, though, was them really disliking being deeply discharged.  So the best behavior is - and Apple seems to have nailed charging technology.  I don't have any problem with any of my devices living on their charger.  Every one of them is plugged in all the time except when it's not, which is typically just briefly.  Like I'll take my phone out with me, and then when I'm home it gets plugged right back in.



LEO:  So keep it plugged in.  It would be nice if they had a setting that said "keep it at 50%."



STEVE:  Right.  And in fact, Leo, you should know, before my Palm Tungstens went into the refrigerator, I did bring the charge down about 75%, and then I disconnected the battery inside so there would be no long-term leakage, and then they went into the deep freeze.



LEO:  Oh.  Will they come out at 75?  There's no leakage at all?



STEVE:  No, they will probably be discharged.  But it's better if they drop from there than if they drop from 100.



LEO:  Right.  It's hard for me to imagine a scenario where you would actually take your Tungstens out of the freezer for use.



STEVE:  And you know, Leo, when I look at that sad puppy now, I think, why did I...



LEO:  What was I thinking?



STEVE:  Why did I ever think I would - well, you know, I was not wrong about my HP calculator.  I've got nine of those.  I keep waiting for one of them to die.  But I just - I never want to be without this calculator.  Although now, 42, you know, PCalc.



LEO:  Right, excellent.



STEVE:  On iOS?  Oh, it's - I use it whenever I'm not in front of my physical calculator.  So some things don't get better; some things do.



LEO:  How much time do you actually use a calculator, though?  I mean, I haven't used a calculator in years?



STEVE:  Oh, I'm - constantly.



LEO:  What are you using it for?  Balancing your checkbook?



STEVE:  No.  Engineering.



LEO:  Oh.



STEVE:  I do a little electronics on the side.



LEO:  Engineering, yeah.  That's what they call it now.



STEVE:  I'm looking for a sample, but my engineering pad's over in the...



LEO:  Are you - oh, okay.  Like you mean the Portable Dog Killer kind of engineering.



STEVE:  That kind of stuff, yeah.  Circuit design.



LEO:  Circuit design.  Yeah, well, that makes sense.  Sitbit in London, Ontario, Canada has our last question of the day.  He weighs in on the debate stimulated by television's "Silicon Valley" on tabs versus spaces.  You showed us last week a graph.  Somebody had analyzed hundreds of thousands of GitHub submissions and came up with a winner.  Sitbit says I think what the Googler actually discovered was the default setting of the preferred editors used for the various languages because, well, for instance, anyone writing C is probably also using VI.



STEVE:  So I thought that was a useful and interesting observation.  I would argue a little bit - okay.  So first of all, I would absolutely give him credit, him or her, Sitbit, credit for observing that there would certainly be a bias.  Although I can't think of any population more than programmers who would tend to change the settings to what they want.



LEO:  Right.



STEVE:  So I've often spoken of the tyranny of the default, how browsers typically are just going to be left the way they're set by most users.  I think programmers and programming editors probably customize to a much greater degree.  Although I did want to - I wanted to use this as a reminder and trigger that several people wrote to let me know that the reason why Golang has almost 100% tabs, as was shown on that chart - remember I noted that it was Go and C that were the two strongest tabbed languages, is because Go contains a built-in formatter, go-fmt, which is always run.  And it enforces, it programmatically enforces the use of tabs.  So tabs, there's no question of tabs versus spaces with Go.  You're using tabs because the system says, what are all these spaces?  We can just turn that into one tab and...



LEO:  Save space.



STEVE:  ...save seven bytes.



LEO:  Yeah.  Well, there you go.  We weigh in on every possible important topic in the [crosstalk].



STEVE:  The definitive statement.



LEO:  Steve Gibson's at GRC.com.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility.  That's his bread and butter.  Everything else, though, is free, including SQRL.  You can find out more about his login solution, his Perfect Paper Passwords.  He mentioned those.  ShieldsUP, very famous for that.



STEVE:  And even the passwords page, an amazing number of people just go there to get random gibberish every day.



LEO:  Well, of course.  What a great tool.



STEVE:  Yeah.  I've got good gibberish, Leo.



LEO:  Good gibberish.  It's truly random, not pseudorandom.  None of that pseudorandom gibberish.  No, it's real gibberish, all right.  And the sleep formula, which I plan on using on Sunday.



STEVE:  Great. 



LEO:  When I will be massively jetlagged after flying to Europe.  Although somebody has sent me, I haven't received it yet, a book, apparently long out of print, but highly esteemed by global travelers - you could buy it on eBay for 100 bucks - with the ultimate jetlag cure.  It involves carefully dosed bits of caffeine and peanuts and sleep and fake sleep.  I haven't seen it yet.



STEVE:  Wow. 



LEO:  But it sounds like a highly complicated but surefire cure.



STEVE:  Oh, that'll put you to sleep.



LEO:  Just read this book.  So I wish there were some way I could do a kind of clinically controlled test comparing Steve's ultimate sleep formula - because that would be good for jetlag; right?  I would think.



STEVE:  Which?  



LEO:  Yours.  Because what I'll do is I'll stay awake best I can till the sun...



STEVE:  Then knock yourself out.



LEO:  ...goes down and it's nighttime.  The problem, of course, is it'll be nighttime in Paris at 8:00 a.m. here.  And so my eyes are going to go boing, it's time to get up.  That's when Steve's Healthy Sleep Formula will kick in.



STEVE:  Yeah.  I updated the page yesterday with the news of the third ingredient.



LEO:  Oh.  Oh, dear.



STEVE:  And I didn't anything because I wanted the people - 2,700 people a day go to that page.



LEO:  Geez, Louise.



STEVE:  I don't what is happening.  But the problem is, and I mentioned it quietly on this podcast about a month ago, it's something called oleamide.  And some researchers discovered it in the cerebral spinal fluid of sleep-deprived cats.  We have it in ourselves, but of course no one wants to have their cerebral spinal fluid tapped.  So the cats got used for that.  Anyway, so it's a natural compound.  It nails the formula.  And I'm only talking about it now because it lasted about 12 hours, and now they're all sold out of that.



LEO:  Oh, man.



STEVE:  I know.  So I had written them.  On Sunday I wrote them a long note - the company's called LiftMode are the people in Chicago who offer it - and telling them what was going to happen, giving them a heads-up, asking them how much of this can you make?  Because you're going to have to start making a lot of it because it perfects the formula.  And I've just - I'm been biding my time because I wanted to get this one right.  And I did also talk to Source Naturals.  They promised me that niacinamide will be back at the end of the month.  So that's finally going to be available again, after the entire planet sold out when it became part of the v2.  So anyway, I have not heard back from the LiftMode people about oleamide.  I've got my fingers crossed that we won't have to wait long.



LEO:  Looks like they're out of stock, though.



STEVE:  Yeah, I know.  I refreshed the page before the podcast.  They had 10 available a little bit, like an hour before the podcast, and now it's gone.



LEO:  Oh, well.



STEVE:  Yeah.



LEO:  Maybe I'll have to do peanuts and coffee after all.



STEVE:  Well, no.  You have the two components.  You have the niacinamide and the melatonin.



LEO:  Yeah, yeah.



STEVE:  And that does a good job.  It wasn't enough for me.  The oleamide - oh, and the other thing is that the two-piece formula didn't solve sleep initiation.  It only was targeted at sleep maintenance.  Well, the oleamide knocks you out.  So it also solves the sleep initiation problem.



LEO:  So our flight leaves at 8:00.  I was thinking I'll have dinner, watch a movie.  Around 11:00 I'll go to sleep.



STEVE:  Didn't you say you were going to go and see the IPTV guys?  I mean the...



LEO:  That's next.  That's after we get back.  They're in Gainesville.



STEVE:  Oh, okay.



LEO:  That'll be another one.  Lisa calls them "turn and burns."



STEVE:  That's right.



LEO:  Yeah.  So, okay.  Well, you know, I might just be tired.  That sometimes happens.  I can live with that.



STEVE:  Ultimately, I think the way to solve the jetlag problem is just go to sleep.



LEO:  Yeah.



STEVE:  Sleep as long as you possibly can and just...



LEO:  Yeah, yeah.  It's a good - it's nature's natural nurse.



STEVE:  Yeah.



LEO:  Ladies and gentlemen, if you don't go to GRC.com to get the sleep formula or other stuff, or SpinRite, you could go there to get this very show.  Steve has audio versions and transcripts of the show.  We also have audio and video.  No transcripts at our website, TWiT.tv/sn.  And by the way, I don't care where you get it.  It's all good.  You can also get it in your favorite podcatcher because a lot of people subscribe to this show and then save it on their massive Drobo drive, all 577 episodes with Steve, because you never know when you're going to need some Security Now!.



Thanks, Steve.  I won't be here next week.  I think Father - you're doing a show Friday, right, with Father Robert, or something?



STEVE:  Well, we're not going to see you for four weeks.



LEO:  No, no, no, no, no.  October, you'll see me October - you're right.  October 11th I'll see you.



STEVE:  Yeah.  I believe Father Robert will be my co-host because we did arrange - he had a scheduling conflict.  And so we're recording one of them at an odd time in order to keep continuity.



LEO:  Yeah, I'm going to miss three episodes, yeah.



STEVE:  Our listeners will miss nothing.



LEO:  No, because I'm not the point of Security Now!, Steve is.  I am merely your amanuensis, your maitre d', your...



STEVE:  Facilitator.



LEO:  Facilitator.  I'm here just to make sure the pages are turned.  But Steve will be back next week.  We do it every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC, if you want to watch live and be in the chatroom.  Otherwise, of course, download it anytime.  Thanks, Steve.  We'll see you next time.  I'll see you in a month.



STEVE:  Thanks, Leo.  A month it is.  Bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#578

DATE:		September 20, 2016

TITLE:		GRC's XSS Adventure

HOSTS:	Steve Gibson & Fr. Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-578.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Father Robert and I discuss concerns over a significant expansion in effectively warrantless intrusion into end-user computers; the forthcoming change in Internet governance; generation of a shiny new (and bigger) DNSSEC root signing key; Google's next move in using Chrome to push for improved security; the interesting details emerging from a successful NAND memory cloning attack on the iPhone 5c; some fun miscellany.  Then I share the details and findings of a recent Cross-Site Scripting (XSS) problem on GRC, including the best website security scanner I found and now recommend!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here to go all propeller-head on breaking through Apple's NAND Flash.  Is it proprietary?  You're going to find out.  Google has changed the Internet into being more secure.  ICANN says goodbye to IANA and hello to DNSSEC and DANE.  And cross-site scripting:  It's the adventure of GRC.com.  Security Now! is next.



FR. ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 578, recorded September 20th, 2016:  GRC's Cross-Site Scripting Adventure.



It's time for Security Now!, the most secure show on the Internet, where we are guided through the security issues, software updates, and coding conundrums by our Explainer in Chief, Mr. Steve Gibson, of course from GRC.com.  Steve, it's so good to be working with you again.



STEVE GIBSON:  Father Robert, is absolutely a joy.  I was thinking last week, I was hearing Leo already, even though he hadn't left yet, bemoaning the fact that he had to be back in two and a half weeks.  And I'm thinking, okay, wait.  So we've been hearing about this vacation for the last six months.  Now, as you're getting ready to go, you're worried about having to come home too soon.  So the good news is I think that in the future you and I will have probably more opportunities like this to do the podcast together.



FR. ROBERT:  And you know what, Steve, I think that's actually healthy.  That's the whole idea, that he's getting used to the good life.  He's worked really hard to build this thing up, and it's time for him to actually enjoy it.  And I've got to say, after going on a vacation for a month, if you've ever done one of those, these little two-, three-day vacations just don't - they don't mean much anymore.



STEVE:  Right.  Takes a while to disconnect.  And then you're not in a hurry to reconnect.



FR. ROBERT:  That's so true.  And actually I've got a Jesuit analogy for that, an analog, actually.  It's when we go on retreat.  So we disconnect for at least eight days a year, and by "disconnect" I mean really disconnect.  There's no Internet, no phone.



STEVE:  Are you allowed to talk?



FR. ROBERT:  Some of us - you are allowed to talk, but most of us don't.



STEVE:  Oh.



FR. ROBERT:  It's just sort of you give yourself permission to just be introspective.  But it does take a good day to three days for you to get into that mode.  And it's the same thing for vacations.  So, but we're not going to do that, Steve.  What we're doing is we're going the other way.  We're going to go full steam ahead.  We're going to look at some very interesting security issues that have been popping up over the world.



STEVE:  So, yeah.  We've got - this is going to be a fun podcast.  I haven't mentioned this at all.  But there was an event a couple weeks ago that unfortunately distracted me in an unexpected fashion, when a security researcher reported an unknown cross-site scripting vulnerability on GRC.  So the adventure that ensued resulted in my, first of all - well, okay.  Sort of chronologically, in looking for a way to determine what the problem was, I looked at three site-scanning, site security scanners.  And one of the three stood out and has become the formally recommended terrific solution that I'll be talking about.  And then I'm also going to talk about what it found, which is interesting because we've sort of - we've glanced over cross-site scripting problems, but this is a perfect opportunity to dig in a little bit further.



But there's also a bunch of other news.  We're going to talk about the concerns over the significant expansion in what is effectively warrantless intrusion into end-user computers which, unless Congress acts to block it, will automatically take effect at the beginning of the year.  There's also a forthcoming change in Internet governance which has been causing some controversy, I think largely due to misunderstanding what it is and what it means.  There's a new DNSSEC root signing key on the way.



Google has moved further or is continuing to move in its push for improved browser security, well, web security using the power, the marketing power, essentially, of its browser in order to force change.  And that's always been controversial because they're regarded as being rather strong-armed.  But it's being effective.  And then we got some really interesting details from an individual who successfully cloned the EPROM, the NAND memory in an iPhone 5c, which was the target, of course, of the San Bernardino issue, the FBI wanting Apple to decrypt the phone and so forth.  And the write-up is fascinating because it gives us, first of all, proves that it's possible to use that theoretical technique which had been proposed.  But there's some surprising things hidden in the details.  And we have a little bit of miscellany, and then we're going to talk about the cross-site scripting as it happened on GRC.



FR. ROBERT:  Wow.  I guess there really must not have been much going on because we're only talking about an intimate look at cross-site scripting, about how the government's getting more spying powers, about how the iPhone has been broken into, and of course how the governance of the Internet's going to change.  So I guess it was a slow week.



STEVE:  Yeah, well, we try to scrape some things together to talk about.



FR. ROBERT:  All right, Steve.  Set us loose on this wonderful, wonderful amendment to Rule 41 because this, at first glance, it seems a little scary.



STEVE:  Well, so what's most upsetting about this, I mean, we'll talk about what these amendments are.  But the thing that's most annoying is that an obscure process was apparently deliberately used to cause this change to occur unless Congress acted to block the change.  So as we know, the way the U.S. legislative process works, Congress creates, it's supposed to be the creator of laws, which are then voted on typically in the House and the Senate.  Then, if there are differences in those bills, then they try to pull them together and ratify them to a single one in a conference.  So the concern here is that Congress had no role in writing or approving these changes.  They were developed within the U.S. court system through what was described as an "obscure procedural process."



Okay.  So what happens is this proposal, or these changes, will automatically go into effect on December 1, that is, so the beginning, well, the last month of this year, which doesn't also give us much time.  There's just six more working weeks until the Senate recesses, and there is a long to-do list of other things that have to happen.  What the rules essentially make lawful is the government and governmental law enforcement's ability to hack any number of computers, I mean, like millions or more, with a single warrant.  So the government says it needs this power to investigate, for example, botnets, as we know so well, networks of devices which are infected with malware and controlled by a criminal.



But these are typically innocent victims' machines.  And I talked about this years ago on the podcast.  I was involved in a big conference call with, like, the person in the government, like the DOJ person, I don't remember now who she was.  I want to say Jennifer Granholm, but I don't think that's the case.  But it was somebody way up.  And a group of people who were involved, this was back in the Code Red and Nimda days, where innocent Windows machines had been infected by this worm and were then perpetuating that infection, were out scanning the Internet independently in order to find targets.  And in this discussion we had, the security researchers sort of on our side were saying, is it not possible for a white hat hacker to fix these machines?  That is, we knew the IP addresses because they were non-spoofed TCP connections.  



So we had a list of the infected machines.  And they had essentially an open backdoor, which is how they got infected.  That same backdoor, that is, that same flaw in Windows back then could be exploited to remove the bad thing.  And this was like half of the conference call was discussing the legality and, unfortunately, the illegality of doing that.  It was absolutely against the law, even for the best of reasons, for a system to be modified without its owner's permission.



That's what this changes.  This essentially is what the government has been wanting, what law enforcement has been wanting, they would say "needing," for quite a while.  And we all feel victims from time to time, depending upon who's being DDoSed or attacked, of networks of autonomous slave computers.  So essentially what this does is it changes that from being illegal to being legal in a very broad way.



Essentially, it represents, in fact Wired magazine editorializing said:  "This kind of vast expansion of government mass hacking and surveillance is clearly a policy decision.  This is a job for Congress, not a little-known court process.  If Congress had to pass a bill to enact these changes, it almost certainly would not pass as written.  The Justice Department may need new authorities to identify and search anonymous computers linked to digital crimes.  But this package of changes is far too broad, with far too little oversight or protections against collateral damage."



And the biggest thing this changes is it allows a warrant to be issued by a court, which then grants search and penetration right to the requesting agency, essentially irrespective of jurisdiction.  We have traditionally had jurisdictional boundaries such that a magistrate was only able to issue a warrant for a specific jurisdiction, something that they controlled.  This removes that limitation.  And you can understand.  Like, you know, the Internet is global.  We've got computers all over the place.  So you can see how they want this.  But this is a big change.



And again, I don't think anybody would have a problem if it was well argued and thought through in committee, by Congress.  Ron Wyden is screaming at the top of his lungs, trying to keep this from happening, saying this has to be stopped.  This is far too broad.  The language is too permissive.  And so the concern is that this has sort of happened without our normal process of figuring out is this something we want to do.  Look at the problem we've had with Net Neutrality that refuses to go away, despite the fact that we keep deciding how it should be.  But people, powerful entities don't want it to be that way.  So it never seems to go to bed.



And now we have something sort of similar.  Essentially, this does allow the FBI to implant malware, that is, their own software, in a machine that they believe they have reasonable cause to do so with, like it scanned somebody, or it sent a probe somewhere.  And, I mean, it's a big change.  And I wouldn't argue that we don't need to discuss solutions to this problem.  But having ISPs prevent spoofing of their own addresses in packets that egress their network would be a nice, simple, technical first step to take, rather than immediately saying, oh, the only solution is to let law enforcement do anything they want.  



FR. ROBERT:  Steve, I'm with you.  And I understand that this is one of these laws of unintended consequences, where I see the problem that they're trying to solve.  I understand how they're trying to legislatively deal with it, and yet I can very easily see how this could be abused and how this could lead to horrible, horrible secondary effects.



But let's be fair.  I'm going to play devil's advocate.  I don't think the law should be as it currently is.  But if I'm law enforcement, I could make a good case for saying, look, we need to update the warrant process because it's so difficult to know where a perpetrator might be operating out of.  They may have servers in all 50 different states.  They may have servers outside of the country.  And I cannot, in my investigation, wait for a warrant for every jurisdiction that a mal-packet may have passed through.  And so this is essentially giving me the authority to track down the bad guys where the bad guys actually live.  What would be your answer to that?  I mean, if you had a law enforcement officer come to you and say, what's the better way to do this, what would your answer be?



STEVE:  I don't have one.  I mean, the other interesting thing is that cyber warfare is becoming a bigger issue.  I mean, it's like it's on the radar now.  The politicians are talking about it.  It's moved from sci-fi into reality, like with chilling speed.  And so there are two sides to this.  There is, might this be itself a backdoor into providing a means by which the U.S. government would have the legal authority, A, to reach into attacking machines and deal with them; or, B, to commandeer IP-connected bandwidth generators, which is what our machines are  these days, and rally them for an attack. 



FR. ROBERT:  The interesting part about that is I could understand the law enforcement mentality that says, okay, this server is generating bad packets, so therefore we're going to confiscate it.  We're physically going to go and take it away so that we can analyze it and find out where the attacks were coming from.  But that's not how the Internet works anymore.  I mean, if you're running a service somewhere on the Internet, most likely you're on a shared box.  You're a virtualized machine.  So there's nothing that LE can take without disrupting what is most likely dozens of other completely legal, completely legitimate traffic sources.



STEVE:  And we've seen stories of that.



FR. ROBERT:  Yes, we have.



STEVE:  I mean, the FBI has gone in and yanked out racks that had completely unrelated domains that just disappeared because there was one bad guy among them.



FR. ROBERT:  Right.  In fact, during the MegaUpload debacle, when the DOJ actually physically took servers, there were people who were not hosting pirated content, did not have copyright content.  But it was a multi-year fight for them to get the data off the hard drives because essentially the DOJ was saying, you need to prove to us that you own the data that you own.  And they're saying, wait a minute.  How are we going to do that?  Our ownership was the hardware.  You took the hardware.  I don't know.



STEVE:  Yeah.  There was a - I don't know how long ago it was.  It was maybe more than a decade ago there was a relatively mild attack on GRC that was not using spoofed packets.  It might have just been ICMP flood.  But so I captured the traffic and looked at it, and then wrote a little Perl script to run a quick reverse DNS through the entire block of IPs.  And I found four that were oc.oc.cox.net.  Well, that was clearly - that was my own reverse DNS.  That was Orange County Cox Cable.



And so I contacted some local friends at the FBI, and I said, "Hey, I've got four IPs belonging, I'm sure, to some people who don't know their home PCs are infected with some malware.  Is there any way you could contact them and arrange for me to get permission to take a look at them?"  And as it happens, my relationship was strong, and they were able to get a hold of one of the families.  Oh, so I gave them the IPs because I didn't know who they belonged to.  So they asked Cox for the physical real world identities of these families, after opening a case to make this legal, and contacted the families.  One of them was only a couple miles away.  I drove over and found the bot that was attacking me.  And of course that was part of the process of unwinding the mystery of the very early attacks by some hacker named Wicked that GRC underwent.



So that's an example of the way it's being done today.  I was only able to do that because I have that kind of working relationship with law enforcement that made it possible.  So not everybody can do that, and they wouldn't know what to do with the information probably if they had it.  But still, it involved a lot of real-world interaction with the court system, with the bandwidth provider, with the victims of the attack, and getting their permission to allow a non-law enforcement security researcher to make a house call.  And so it worked, but it doesn't scale.



And I think what we're - this feels to me like at-scale issue, that is, all of this is getting bigger.  Attacks are getting stronger.  And existing tools that were designed for the physical world are failing the cyber world.  So, I mean, I can absolutely see both sides of it, too.  I guess the only problem is this didn't have any oversight.  This was clearly - the only reason these amendments happened - and this, by the way, it's like an obscure rule in something that was completely unrelated to this, literally just slipped in, was to avoid this process.  Now, maybe it's a problem that something as broad as necessary could not get past.  But that's the way the system works.  And it seems wrong to arbitrarily bypass it, if some people's interests are to do so.  That's not a democracy.



FR. ROBERT:  Right.  And unfortunately, I think we're just in this very scary part.  And we've known this.  We've talked about this on multiple shows on TWiT.tv, where law is so far behind where we live in the virtual world that, when they try to apply law that was built for the physical world, it always ends up breaking something, or it always ends up just looking foolish, ham-handed.  We've got people in the chatroom, like Eric Duckman and the like, who are saying, you know, it's easy to say that you're against this because of course there's going to be unintended consequences.  But it's more difficult to say, okay, well, then what is the solution?  What do we do?  If you don't want to do it that way, and you admit that we need this authority, we need the ability to reach into a box that is generating mal-packets, that is owned, especially a box that - let's take your example.  You were lucky enough to have a relationship with law enforcement.  You were lucky enough to have an IT administrator who was willing to let you in and fix what was wrong with his gear.



STEVE:  Oh, his team, the two teams there were very happy because their big problem was they could no longer record pirated CDs because the computer was so busy attacking things that the CD burner no longer worked.



FR. ROBERT:  We're trying to do our illegal things.  



STEVE:  My music, my music, I don't have my music.  It's like, okay, that's got our priorities straight.



FR. ROBERT:  No, but, I mean, even in your case, that was someone you could work with.  There are so many servers that have been compromised on the Internet,, that have been abandoned for 10 years.  And they will never get patched, and they will never be looked at.



STEVE:  In the closet.



FR. ROBERT:  Because someone spun them up a while ago and forgot about them.  And what do you do about that?  When there is no contact person?  When it's paid for the next five years, and it's just going to spin at the bottom of that rack, but it is completely useless and generating traffic across the 'Net.  And so I think all of us understand that there needs to be something, some provision to allow us to fix that.  But I think you're right.  It's just the lack of oversight really does, it makes us feel like the FISA court again. 



STEVE:  You know, you asked me, you posed the theoretical problem, what could we do?  An interesting compromise is service termination.  That is, just disconnect the bandwidth to that malfunctioning machine so it's no longer able to contaminate the shared resource that is the global Internet.  If somebody then is behind it who's trying to send letters to their mother, and suddenly their Internet goes down, then they contact their ISP and say, "Hey, I don't have any connectivity."  The ISP says, "No, we had to shut you off because you've got malware in your machine."  And then thereby get permission to proceed.  So maybe just cutting the cord of these things, of these machines that are misbehaving.  Again, it's not a perfect solution, and it is subject to abuse.  But it's a midway between doing nothing and actively having a court issue a warrant that gives global rights to law enforcement to do what they cannot do today.



FR. ROBERT:  Steve, there is one more provision in this rule change that we haven't yet talked about, and that is - this is interesting because it does sound like the lawmaker was trying to be responsible, that there is at least the mention that the best effort must be made to inform...



STEVE:  Notify.



FR. ROBERT:  ...the owner of a server that it's been searched.  I'm not sure if that was just tacked in at the end, or if that was the original intent of the bill, to make this seem balanced.  That's not enough oversight, though, because, I mean, the language is, well, I mean, you should try to make your best effort.  But we're not actually going to hold you to that.



STEVE:  Right, it's very open to interpretation.



FR. ROBERT:  Yeah.  So in other words...



STEVE:  And, I mean, Edward Snowden has shaken our confidence, I think, in an important way.  And as a consequence we view what is being done on our behalf with a little more skepticism than we did before, when things were theoretical, but were assumed not to be happening.  Now we keep seeing conspicuous, I think, evidence of what appears to be deliberate manipulation of equipment across the industry, all aimed at essentially, I mean, and this is illegal manipulation.  Cisco didn't give anyone permission to crack into their routers using previously unknown SNMP flaws.  Yet we have evidence that that's been going on.  And probably from some government bodies.



FR. ROBERT:  You know, two years back at Black Hat, Dan Geer, the keynote speaker, was saying how he thought that governments should be responsible for buying up zero days and then sharing them.  They're the only entity that has the resources to be able to find these and then secure Internet infrastructure.  But it seems more that the governments are buying up zero days and then using them.



STEVE:  Yeah.



FR. ROBERT:  Yay.  All right.  You know what, let's go on to something that I consider to be a related topic because you just mentioned how our confidence in government organizations has really sunk to a low.



STEVE:  Eroded.



FR. ROBERT:  Yes.  I mean, "eroded" is being gentle.  It was washed away completely.  And even now, even the smallest mention of something that happens in the dark, or without oversight, just raises all sorts of red flags.



STEVE:  Well, even something that's being changed.  It's like, well, do we really have to change anything?  So, okay.  This is a - the way I put the show notes together, it was as a bit of an acronym glossary.  Because this is a little bit of acronym soup.  The headline I put on this is "NTIA's contract with ICANN to handle IANA is expiring in 10 days."



So, okay.  So we've never really on this show looked at the bureaucracy of the Internet.  That is, you know, the behind-the-technology mechanisms which are important, but they're such a mess that I'd just rather talk about bits and bytes and protocol numbers, rather than the politics of it.  But there is politics.  So the IANA, that's the Internet-Assigned Numbers Authority, and of course that includes DNS.  That's the group, the body which manages the DNS route and two top-level domains, INT and ARPA.  It coordinates the global pool of IP and AS.  That's the autonomous system numbers.  Those are the numbers that large ISPs are given that BGP routers use for moving bulk data between top-level networks.  And they maintain Internet protocol assignments.  So we don't normally, you know, our normal use of the Internet only encounters that a little bit, that is, the IANA work.



But down at the packet level, for example, an IP packet has a header field that identifies the protocol like UDP or TCP or ICMP that is carried by that IP wrapper packet.  Well, those protocols are identified by a number.  Who decides what that number is?  Who sets that number?  That's the job of the IANA.  And so their job is crucial.  The only thing that allows the level of interconnectivity that we have is an agreement about protocols.  And you have to have an enumeration of stuff within the protocol, like which sub-protocol of IP you're talking about, and so on.  So the Internet-Assigned Numbers Authority, like the name sounds, manages those sort of static definitions for the Internet.



Okay.  Now, ICANN, I-C-A-N-N, is the Internet Corporation for Assigned Names and Numbers.  Now, that's already today a multinational, multistakeholder body.  It happens to be based here in Southern California, in Los Angeles.  And it is composed of many member countries, including China and Russia.  So it's already multinational in nature.  And while the Internet has been growing and happening, ICANN has managed the IANA functions, which are technically its responsibility.  So ICANN has been managing or providing these Internet-Assigned Numbers Authority functions under a contract with the Commerce Department's NTIA.  That's the National Telecommunications and Information Administration.  However, the United States has long made clear that it intended to eventually privatize the domain name system in order to, that is, sort of to release implicit ownership of it, in order to facilitate international participation in its management moving forward.



So the news here is that in 10 days, on September 30th, the NTIA, which has been the contractor under ICANN to perform the IANA services, intends to allow its contract with ICANN to expire, at which time ICANN will assume stewardship of the IANA's key technical functions.  And this is only controversial in some corners, arguably with people who don't really understand what's going on.  Most Internet experts and the major Internet companies - Apple and Google and their ilk - universally support this Internet governance transition because it counters the growing argument which repressive regimes can use to lobby for greater power over Internet governance, or even their own local Internet, by breaking off from the global Internet altogether.  In other words, if it can be said that the Internet is a U.S.-controlled thing, then Putin over in Russia can say, we're not sharing this network with the United States that is controlling the whole thing.  We're going to just sever ties and create our own Russian network that is disconnected from the global one.



FR. ROBERT:  Steve, that is important.  But that is really a PR thing, though.  Because, I mean, oppressive governments are going to want to break off from the Internet anyway.  So they want their own version.



STEVE:  They're going to want control.



FR. ROBERT:  Right.  But this makes it so that they can't publicly say, well, we're only doing this because the horrible, horrible empire that is the United States controls the Internet right now.  We can't stand for that.  This way we can say, no, it's under private control.  So it's a private corporation, a multinational.  Everybody has a stake in it.  We are out.  Now, okay.  We are getting a little bit of a letter salad going on in the chatroom.  So we know what ICANN is.  We know what the IANA is.  Where does ARIN fit in?  So that's the American Registry for Internet Numbers.  Where do they fit in, in the grand scheme of assigning IP addresses?



STEVE:  You know, in terms of a bureaucracy, I don't know who they report to.  It feels like they would be another - technically ICANN is the overlord.  ICANN is the entity that has responsibility, which is why it was subcontracting the work that the IANA needed to do to the NTIA, which now is coming back to it.  But again, you'd have to look at it like an org chart of bureaucracy of the Internet, which as I said I have shied away from as much as possible.  But you're right.  ARIN is another one of these bureaucratic but necessarily registries to maintain order.



FR. ROBERT:  Right.  And we've actually had them on This Week in Enterprise Tech, I think three or four times.  Their president, John Curran, was talking about their most recent push for IPv6 and DNSSEC.  So that's a good thing.  I like that about the organization.  But I want to talk a little bit about the transition we made between the last story and this story, when we were talking about the mistrust of government institution, and therefore that's why we're getting rid of the IANA.



But it should be noted that ICANN does have a bit of a checkered past.  They had an at-large board member by the name of Karl Auerbach, who was a long-time member of the Interop team and a frequent guest of This Week in Enterprise Tech, who he wanted financial transparency for ICANN.  He wanted them to publish a budget just like every other public organization on the planet, and they fought him tooth and nail.  And so, Steve, I want to throw back to you, we in the United States tend not to trust the government, and we trust corporations, even though it could be argued that ICANN is less transparent about what it does and how it uses the resources at hand than the U.S. government.



STEVE:  Yeah, again, I have to plead ignorance about the individual specifics.  I know that Esther Dyson was intimately involved with ICANN.  She was a board member for some period of time.  Her integrity is beyond question.  But she also wasn't running the whole thing.  And I've been a board member of various organizations where I've ended up resigning ultimately because I was frustrated with the way the whole entity operated.  And politics.



FR. ROBERT:  That's actually a very - that's a very, very common experience.  I know a lot of people who have had some sort of involvement and just kind of threw their hands up and walked away and said, "I don't know how to navigate this organization.  I guess it works.  I have no idea how that is."



STEVE:  Where does the work actually get done?  Who does anything here?  Because all we're seeing is reports and memos flying back and forth, yeah.



FR. ROBERT:  Yeah, yeah.



STEVE:  Well, you mentioned DNSSEC.  And I am so bullish on, as the listeners of this podcast know, on the promise of DNSSEC.  That is, if we, or when we, because we're clearly moving in that direction, when we have a securely verifiable Internet-scale directory, what we can do is, I mean, it's hard to think of anything you can't do.  For example, the existing troubled certificate authority structure, which we bemoan just because it has become so bloated, and because we're now trusting many, many hundreds of certificate authorities who say they're going to act on our behalf and correctly, but we keep finding instances, discovering instances where they have failed in that mission.



And so, for example, there is no reason that a server's certificate has to work the way it does, where we trust a certificate authority to sign our public key to assert its validity on our behalf.  After all, we created the key pair.  We have the private key.  We give them the public key.  In some cases pay, but now with Let's Encrypt it's an automated process.  Get a signature which asserts, if nothing more, that we're who we say we are, or that we do control the domain that this certificate is providing security for.



So if we had DNSSEC, there's already a protocol - I think it's DAME, or DANE.  I don't remember.  I think it's DANE, D-A-N-E - which is a DNSSEC-based certificate solution.  That is, you ask DNS for the private key of your site, rather than needing to accept its signature from a certificate authority.  And that's just one example.  I mean, just the mind boggles when we could have a scalable, controlled, caching, truly secure, global directory that can contain all manner of different information.



So I'm, you know, it's taking a while to get there.  Comcast got their root signed in 2012.  Google's DNS has had theirs signed since 2013.  I've looked at it for GRC out of curiosity.  But it's like, okay, well, there's nothing I really, at this point, that I want to secure from GRC's DNS.  And at the moment the tools are awkward to use.  I think Hover, which is the name server that I'm using, or the registrar, I think they can provide DNSSEC.  But I'm also playing with my DNS records often.  In fact, later in the story, in today's podcast, I'll explain how I had to do that a part of this cross-site scripting issue.  And that would have broken the signing of my domain, and it would have been a problem because I would have had to then get it re-signed.  So we're still in this awkward stage.



But the point of all this is that there is an intriguing event that is on the horizon, and that is that the famous DNSSEC root zone signing key, as it's called, is being changed for the first time.  There are no known problems.  It's just regarded as good security policy to rotate your keys periodically, especially for something as high value as the DNSSEC root zone signing key.  And in the process they are doubling its size.  So they're also, as we always do, moving to larger size keys as the ability to crack smaller keys gets worrisomely close.  No one thinks that the 1024-bit key today is vulnerable.  So now's a good time.  As has been said in some of the coverage of this, there's no emergency.  It's a quiet time.  That's when you want to do this is because it's a big change.



So they're going to go from a 1024-bit key to a 2048-bit key.  And the process is almost mystical.  I mean, it's weird how, well, I mean, you could imagine the value of this key.  If the private side of the key pair were to escape absolute control, it would allow any entity, a nation-state or anyone, to essentially spoof DNS with no ability to detect it because it would have been signed properly.  It would be signed by a private key that everyone holding the matching public key would authenticate.



FR. ROBERT:  Which, Steve, I think means, if the secret key were to escape, it would essentially become the DNS that we're all using right now.



STEVE:  Well, I mean, that's a very good point.  There's no encryption by default on DNS.  It's a UDP packet.  Everybody can see it go out, everybody can see it come back, and your computer implicitly trusts it.  It's just, okay, this is the IP for the domain I'm going to.  And notice that, when we're talking about security vulnerabilities, for example like how do we know if a TLS certificate is valid, it's does it match the domain name.  And when we see the name in the browser, it's like, oh, okay.



But there's an implicit assumption that the IP address behind that domain name in the browser's URL is the correct IP.  And the point is that crucial in the exploitation of this is spoofing DNS.  And we don't talk about it as much as we should.  But it is an Achilles heel.  In fact, as we secure other bits, this is the one which sort of is beginning to stick out as, boy, we ought to get - let's get moving on locking down DNS because we've been running around doing all the easy bits, and we're kind of running out of those because everything's getting pretty secure.  But DNS, also, we have to trust that domain name-to-IP address mapping.



FR. ROBERT:  It's not just that it's insecure, it's that it's scary insecure.  We were explaining this to a group of people who dropped by Interop Labs a few years back.  And the easiest way to explain it was currently DNS is a yelling contest.  If you can yell louder than the other machines around you that you are the domain that you want to spoof, it belongs to you.  That's how it works.  Which is why we were making a big push for DNSSEC and DNS DANE.  And actually we did talk with Cricket Liu from Infoblox about DNS DANE, and he was saying it's not just that it's a more secure system, it's that it makes it easier for people to actually start using certificates without using CAs that can be compromised, that can get revoked, that just might be bad actors, as you talked about on Security Now!.  We've already run into at least two that they weren't even pretending to be issuing valid certificates, and yet they were still in the trusted CA list.



STEVE:  Right.



FR. ROBERT:  And actually the real part I wanted to bring out about this, and this is what I find so beautiful about the story, is when DNSSEC was first cooked up, they built in this function, this ability to upgrade the key, into the spec, which is huge.  That's important.  It means that it's a forward-looking standard.  They realize that we are at some point going to upgrade the encryption level from 1028 to 2048, maybe to 4096.  And we don't want to break it by upgrading security.  So this is the first real test of us saying, okay, well, upgrade it, and let's see what happens to those who are currently using DNSSEC.



STEVE:  So I love this description of the procedure.  ICANN incorporates some extraordinary security measures and considers its potential threats as everything up to nation states.  At its quarterly ceremonies, so-called "crypto officers" from all over the world congregate in one of the key management facilities after passing multiple layers of physical and digital security.  Next month, this coming October, in a hyper-secure key management facility on the U.S. East Coast, ICANN will generate a new cryptographic key pair.  One half of that pair is private and will be kept super securely by ICANN.  The other is public.  Internet service providers, hardware manufacturers, Linux and other OS developers, anything and anyone who needs to verify future DNSSEC records, needs to have the updated DNSSEC public key.



Then, in the first quarter of next year, 2017, two employees will transport a copy of the encrypted key files on a smartcard over to another facility on the West Coast, using regular commercial transport.  I thought it was interesting that they tossed that in.  I guess, what, instead of a military jet or something.  Eventually the public part - or I guess a private executive jet.  Anyway, yeah, standard commercial transport in full public view, but super encrypted.  Eventually the public part of the key pair will then be distributed to other organizations.



And then, finally, the whole switchover will take around two years from start to finish.  The new key will appear in the DNS for the first time on July 11th, 2017.  So next summer, next July 11th.  And then in October of 2017 the new key will be used for making signatures.  So I imagine that initially it'll be cross-signed, so you'll be able to continue using your previous 1024-bit key, yet the root will also be signed with a new 24-bit key.  And then any new equipment, and of course OSes will be updated, and anything using and depending upon DNSSEC will need to - there'll be some grace period, which is probably where this two years comes in, where both keys, both the old and the new, either can be used.  And then eventually it will be necessary to retire the 1024-bit key.



And I'm sure they'll be able to get statistics and things and watch to see the hopefully quickly diminishing use of the 1024-bit key.  If history is any lesson, there'll have to be a threat of, okay, this key is being removed on this date.  Everybody, you had two years, get your act together, update to the public key.  And in embedded appliances and devices, that can be a challenge.



FR. ROBERT:  You know, Steve, I think they're missing out on a great opportunity here.  And if anyone at ICANN is listening, you could take advantage of my priestly experience because I think this meeting should have seven figures that are robed in brown robes so you can't see their faces.  There's a big smartcard in the middle of the room, shrouded in fog.  And it lights up as the key is copied to it, and it's broken into seven pieces and sent to various parts of the world.



STEVE:  I think it's very much like that, Robert.



FR. ROBERT:  it's all about the mystic experience.



STEVE:  I've seen some of the videos of these ceremonies, and there's a lot - they're very serious.



FR. ROBERT:  I've seen it, and it is like that, except they don't have the robes and the fog and the weird light and the Celtic music in the background.  See, they're missing an opportunity, Steve.



STEVE:  It might freak some people out.  I'm not sure.



FR. ROBERT:  This is how the Internet works.



STEVE:  Yeah.  So we've been following Google's efforts for years to strengthen the security of the Internet.  And the most controversial one I would argue was their decision to move up the already planned sunsetting of SHA-1 hashed and signed certificates.  But that happened.  And starting at the beginning of this year, no CA is issuing an SHA-1 hash signed certificate.  So, okay, that's behind us.  Now Google is turning their attention to the problem that, while HTTPS connections are shown as explicitly secure, non-HTTPS connections are just kind of vanilla.  That is, they don't say anything.



And Google's concern is that, in the long term, once we accept the idea that HTTPS, protected with TLS privacy and authentication, is the de facto web protocol, not HTTP - remember, traditionally, HTTP was the de facto protocol.  And even as recently as a few years ago, major sites would switch their users to HTTPS, only while transacting privileged information.  And, controversially, they would leave their cookies, which were maintaining session, when the browser switched back to HTTP, allowing things like the Firesheep attack, which made it trivial to impersonate people in any open WiFi environment.  So Google is saying, okay, our next push is we're going to actively discriminate against non-HTTPS connections.



So in their blog post they wrote:  "To help users" - oh, by the way, this is starting January 2017, so the beginning of next year, only a few months away.  "To help users browse the web safely, Chrome indicates connection security with an icon in the address bar.  Historically, Chrome has not explicitly labeled HTTP connections as nonsecure.  Beginning in January 2017 with Chrome 56, we'll mark HTTP pages that collect passwords or credit cards as nonsecure, as part of a long-term plan to mark all HTTP sites as nonsecure.  Chrome currently indicates," they write, "HTTP connections with a neutral indicator.  This doesn't reflect the true lack of security for HTTP connections."  In other words, you can sort of see the thinking now.  It's like, it's not that this connection is secure, oh goody.  It's wait a minute, why is this one not secure?  That's bad.



So they say:  "When you load a website over HTTP, someone else on the network can look at or modify the site before it gets to you.  A substantial portion of web traffic has transitioned to HTTPS so far, and HTTPS usage is consistently increasing.  We recently hit a milestone with more than half of Chrome desktop page loads now served over HTTPS.  In addition, since the time we released our HTTPS report in February, 12 more of the top 100 websites have changed their serving default from HTTP to HTTPS.  Studies show that users do not perceive the lack of a 'secure' icon as a warning, but also that users become blind to warnings that occur too frequently.



"Our plan to label HTTP sites more clearly and accurately as nonsecure will take place in gradual steps, based on increasingly stringent criteria.  Starting January 2017, Chrome 56 will label HTTP pages with password or credit card form fields as 'not secure,' given their particularly sensitive nature.  In following releases we will continue to extend HTTP warnings, for example, by labeling HTTP pages as 'not secure,' initially in Incognito mode, where users may have higher expectations of privacy.  Eventually, we plan to label all HTTP pages as nonsecure, and change the HTTP security indicator to the red triangle that we use for broken HTTPS."



So, you know, any time someone uses their power, as Google is, it creates some controversy.  And no one likes being told what to do.  I imagine there will be people who for some reason HTTPS is a problem, is not practical.  Something prevents them from doing it.  I don't know what, but something.  So the dicey part here is that Chrome is going to be scaring anybody who uses those servers.  Now, we could argue, well, they deserve to be scared, or this needs to put pressure on that problem to get it fixed.  Which may be the case.



Ultimately, everyone knows I'm bullish.  GRC has been HSTS, Strict Transport Secure, for years, and known by all the browsers that way.  And ultimately I think this is clearly where we need to go.  But Chrome now has the lion's share of the browser market and is taking advantage of that in order to push security forward.  Which, ultimately, I mean, I think the process is always painful, like what we went through with SHA-1 certs.  But once you're past it, it's like, okay, this is better now.  And every lesson that we have been taught by this industry is, I mean, okay, just say IPv4, is we're not moving.  We're not doing it unless something makes us.



FR. ROBERT:  You know, Steve, we've got a couple of folks in the chatroom.  We've got Klaatu and Eric Duckman, who are saying thing like, well, you know, some sites don't need HTTPS.  And you've got Eric Duckman saying, oh, what, so everyone's supposed to get a cert now?  And I understand that frustration.  But at the same time, no, absolutely not.  The argument that only some things need to be encrypted is the wrong way to think about it.  I think both of us are in agreement that you encrypt everything because you don't want people to know what's important by what's encrypted and what's not.  It should be equally for them to break into my WordPress session where I'm reading a blog as it is for them to break into my session that's transferring financial information.  And as far as...



STEVE:  We have a perfect, just interrupt you for one second.  A perfect example of that is what law enforcement has called the "going dark" problem.  Well, how do they know it's going dark if they weren't looking for the light?



FR. ROBERT:  Precisely.  Precisely.  And as far as certificates are concerned, I mean, this is the DNS DANE story.  We are about to get a system based off of DNSSEC, using the same key from DNSSEC, that will allow us to have certificates at a much lower price - read free - that are more secure and more easy to revoke when they go bad.  So I like that Google's doing this.  They're one of the only entities that has the muscle to shame sites into doing what they should have done a long time ago.  I mean, the Internet should be end-to-end encrypted.



STEVE:  Yes.  And, well, it is an enduring problem that security is an afterthought for the Internet.  I mean, we need to cut them a lot of slack because they were amazed when a packet made it between two of their processors on Day One, back when it was the Arpanet, and it's like, oh, my god, you mean this actually works?  And so no one could have foreseen what was going to happen.  I mean, I'm still complaining about the fact that we have to say http://.  Who was this designed for?  This wasn't designed for people.  So, yeah, we're dragging a lot of legacy behind.



But I completely agree with you.  I think that - and don't forget, too, Let's Encrypt does automate and make easy and has been a huge success with exponential growth in the number of certificates that they're issuing, providing trusted certificates at no cost.  And from what I've seen, in people who are complaining, I mean, I get it.  There are technical reasons.  It's like they're on a shared hosting provider, and CPANEL doesn't yet support Let's Encrypt.  Well, okay, it needs to.  Fix that.  And then those sites can use encryption, and everybody'll be happy.  And so, yeah, again, there's going to be some pain.  But I think where Google is taking us is the right direction.  Or pushing us.



FR. ROBERT:  Yeah.  And I'm okay with some short-term pain for some very long-term gains.  And what we are talking about is a long-term gain.  I think we can all agree that everything encrypted is a better way to do business and to live on the Internet.  And, yeah, it seems a little heavy-handed.  I get it.  I get it, folks.  Some people don't like the fact that Google is using its huge market share to be able to force this change.  But someone has to force the change because otherwise it just - it won't happen.



STEVE:  Yeah.  On this podcast we're constantly talking about the reticence to change, the inertia against change.  It's significant.



FR. ROBERT:  Right.  All right, Steve, here's a story that I know some people are tired of hearing about, but it's important.  And it's important because it deals with the devices that we use each and every day and sometimes assume that they are secure, even though we know that they're not.  Tell me a little bit more about the iPhone 5c NAND saga. 



STEVE:  So what was interesting about this, I've got the links to the detailed PDF in the show notes, and there's no need to dig in.  But for anyone who's interested in, step by step, how was this done, this research is just fabulous.  Lots of photos showing what this engineer went through in order to pull this off.  And we covered the concept of this when it was brought up, and that was you have a phone which is locked, and the person will not or cannot divulge the information.  Maybe they're no longer alive.  But the government or law enforcement is desperate to get into the phone.



So the problem is that, as a security measure, proper security, Apple has a lockout after X number of wrong guesses at the security code.  And so there have been hacks in the past that we've discussed where guessing the code, seeing that it's wrong, and then immediately powering down the phone before it has the chance to update the nonvolatile counter in memory was an example.  And that worked for a while.  You would guess it, see that it didn't work, quickly power down the phone, and that guess wouldn't count against your X number of strikes.  However, Apple fixed that, so that that no longer worked.  And the 5c has that advanced technology where you can no longer perform this fast power shutdown/reboot in order to prevent the fact of the guess failing from being written to nonvolatile memory.



So any engineer looking at this says, oh, well, then what we need to do is clone that memory before we even start guessing.  Make a copy of it.  And then we'll make as many guesses as we can before the phone gets upset and then copy from the clone back to the working memory, which essentially resets the count, as if we had never made any guesses.  But we obviously don't repeat those guesses.  We make new guesses until we decide it's no longer safe, and we repeat the process.  So the theoretical concept of cloning the iPhone's memory, that is, with a state where guesses were allowed, and then resetting the state, it's an end around all of the other security measures.  But it was only until now theoretical.  We've talked about it on this podcast.  It's been proposed.  No one had done it.  It has now been done.  



So the abstract of this paper, I'll just read this from the top, says:  "This paper is a short summary" - but it's actually not, it's a wonderfully detailed summary - "of a real-world mirroring attack on the Apple iPhone 5c passcode retry counter under iOS9.  This was achieved by desoldering the NAND Flash chip of a sample phone in order to physically access its connection to the SoC (System on a Chip) and partially reverse engineering its proprietary bus protocol.  The process does not require any expensive and sophisticated equipment."  Although having looked at the pictures, it's not for the faint of heart, either.  You need a steady hand.



"All needed parts are low cost and were obtained from local electronics distributors.  By using the described and successful hardware mirroring process, it was possible to bypass the limit on passcode retry attempts.  This is the first public demonstration of the working prototype and the real hardware mirroring process for iPhone 5c.  Although the process can be improved, it is still a successful proof-of-concept project.  Knowledge of the possibility of mirroring will definitely help in designing systems with better protection."  And in fact I will propose some of that before we're done.  "Also," they write, "some reliability issues related to the NAND memory allocation in iPhone 5c are revealed.  Some future research directions are outlined in this paper, and several possible countermeasures are suggested.  We show that claims that iPhone 5c NAND mirroring was infeasible were ill-advised."



Now, I went through the paper, and I am really impressed with this guy.  And so I just want to share a little bit of some of the inner techiness that demonstrates that Apple was aware of this and proactively worked to thwart it in a sneaky way.  They're going to have to up their game with the next round of hardware.  I don't know what the 6 or the 7 phones look like.  But so in one part of the paper, where they get into actually making this happen, they say:  "The process of cloning involves creating a fully working copy of the NAND Flash memory chip.  However, as it was already mentioned in the previous section, simply copying the 8GB information from the original chip into another identical chip taken from another iPhone 5c does not give the desired result, and the iPhone does not boot."  Meaning cloning was not enough.



"Some additional research was undertaken to figure out why simple copying doesn't work.  For that same model of the NAND Flash chip was programmed with the data from the original chip, and then the communication was" - oh, I'm sorry.  "For that" - there should have been a comma there - "the same model of the NAND Flash chip was programmed with the data from the original chip, and then the communication was analyzed with both an oscilloscope and a logic analyzer.  First, some pages were accessed from addresses outside the normal 16GB address space.  For example, instead of reading and writing to the block" - and they give an example, 0x00041Axx - "the CPU was accessing the block 0x00841Axx.  Although such accesses wrap around and are mapped back into the 0x00041Axx block, the page numbers were different, as well as the status of those pages."  Then they have a figure that shows a table of a bunch of those, just to detail it.



"Secondly, some irregularities were found in the" - irregularities - "were found in the communication prior to the access of those hidden pages.  Although the data transfer during the access is performed in the SDR mode at 17 MHz, while the configuration commands use the even slower speed of 1 MHz, some data inside the commands are smuggled at an astonishing rate of 256 MBps in DDR3 mode.  Also, a dummy value for data bit 7 was introduced for the period of 23 nanoseconds.  Given that the data setup time in those transfers is less than one nanosecond, there is a very high chance that such information would be overlooked by most would-be attackers."



So decoding that, this means that Apple deliberately - they understood that there was a vulnerability when the NAND chip that stored the keys to the kingdom in many ways was physically separate from the SoC, from the processor, the System on a Chip.  That is, there were communication lines connecting them.  That exposed a bus which the processor used to communicate with the  memory, which was then subject to reverse-engineering.  So knowing that, they went to tremendous effort, essentially, to hide critical details of what was going on, like in otherwise much shorter and faster little bursts of data that you wouldn't see unless you really, really looked closely enough, down to a resolution of one billionth of a second.



So they continue:  "After those findings, the implementation of the communication protocol was amended in the test board."  Because basically they, like, through this process, built a number of different jigs in order to hold these bits with this poor-looking red case iPhone 5c with its back cut open and wires coming out of it, like a zombie.  "Then the data-mirroring software was modified to include cloning the hidden pages.  As a result, the newly created clone of the original NAND chip was fully functional in the iPhone 5c.  It was then tested with six incorrect passcode attempts before replacing it with the original chip.  After the boot process, it was possible to enter the incorrect passcodes again six times until the one-minute delay was introduced.  This fully proved the correctness of the hardware NAND mirroring attack on iPhone 5c."



And then, to put this in real-world terms, they write:  "Because there's no limitation on the number of such NAND clones, they can be created in advance and restored in parallel when one of them is being used for passcode testing."  And I would argue that you could also do deeper reverse-engineering in order just to zap whatever little bits are being changed and put those back by comparing pre- and post.  "This way, it only requires 45 seconds for six passcode attempts.  For four-digit passcodes, the maximum attack time would be" - and then they do the math - "75,000 seconds, or about 20 hours.  For six-digit passcodes, this time will increase to about three months, which in some cases might be acceptable."  So I just - there was too much detail not to share.  It's just wonderful stuff.



FR. ROBERT:  Let me ask you, because the trick that they did with accessing address spaces outside of the standard 16MB block, was that randomized?  So I know in order to access Block A, you actually had to access Block X, which referred back to Block A.



STEVE:  Right.



FR. ROBERT:  Does that change, or would that be the same on every iPhone?  Is it like address space randomization that you would get in a Windows box?



STEVE:  From something else they said elsewhere, and I didn't have it in my notes, they indicated that it was swapped-out pages.



FR. ROBERT:  Okay.



STEVE:  So I think that that's fatigue.  It's wear leveling of the NAND.  So for whatever reason, they needed to clone that, that is, like they had to develop an awareness of the physical location, not just the logically addressable location, and incorporate that.  And again, that may have been by design.  That feels like it was another confounding factor that Apple added, just thinking, ah, this will get them.



FR. ROBERT:  Well, it's just that one little extra bit where, well, if they figure out where the actual, what the address spaces are, this will throw them off because they actually have to access a different address space in order to access the address space that they want.  But, I mean, it sounds like then it's not random.  It's just a reassignment.



STEVE:  Yes.



FR. ROBERT:  Hmm. 



STEVE:  Yeah.  And they mapped that out and then showed us a table of where the reassignments were.  And once they incorporated that into their clone, then the 5c didn't know there was any difference.  It thought it was talking to the original chip, although it was talking to a true copy.



FR. ROBERT:  Now, Steve, Creamy Corn Cob in the chatroom has an interesting question.  He wants to know what is the actual encryption that takes place between the SoC and the NAND itself?  Because the NAND, it's not specialized NAND.  They're just - they've got it from Hynix, and then they're running their own encryption on top of it.  So is there encryption between the SoC and the NAND?



STEVE:  I don't know that - to me, from the description, it does not sound like a standard part.  They were playing some games at the electrical protocol level which would violate the specifications of a standard NAND chip.  So my guess is that Apple had these things custom made.  They had a little, like they tweaked the NAND controller in a way that customized it for their use.  And the trick of this is that, by cloning the memory, it was not necessary to decrypt the protocol.



FR. ROBERT:  Right.



STEVE:  So, for example, both ends could have a private key, and all you would see is gibberish going across the bus because you would never see it in plaintext.  But if you are able, without knowing anything about what it means, if you just copy it and use its behavior, rather than its information, then you get a shortcut.



FR. ROBERT:  Well, I mean, that in itself is fascinating, that iPhone NAND is not regular NAND.  It's not what every other manufacturer is buying.



STEVE:  If I read, yes, if I read what they wrote, the fact that they were sending a little burst of data, essentially hiding a small packet of information, well, that's not - no spec reads like that.  That's special.



FR. ROBERT:  That's very special.  And you know what, there are some people in the chatroom who are joking that this is way too propellerhead.  And, yeah, you know what, it's actually, it's getting over my propellerhead, too, because anytime someone talks about how they hooked up an oscilloscope, and they were able to figure out what it was doing just by looking at the waveforms, I'm nowhere near that.  That's a lot of skill.  That's a lot of knowledge.  Wait, are you - wait, are you going to bust out your oscilloscope?



STEVE:  Well, no, I mean, it's - it's right here.



FR. ROBERT:  I can build an oscilloscope, but I don't know how to use it.  I mean, because all they're looking at is they're looking at the rising and the falling edges of the clock; right?  They're looking at, well, what are they receiving back when they send a signal to the individual cells.



STEVE:  Correct.  Although these things all have a lot of lines.  One of the things that has happened is we've gone to a much more serial world than we used to have.  Look at the slots on our motherboards.  They're little itty-bitty slots.  Yet it's like faster than when we had huge long slots.  So the idea is we're going to serialize things in order to bring pin counts down, to minimize bus size, and also you need driver electronics at each end in order to make this all happen faster.  It's much better if you have only a couple of them than if you have, like, 64 of them.  Move the 64 bits down one lane, rather than all in parallel across 64.  It's a huge savings in chip size, in pin count, and in bus complexity.  Anyway, I understand that this is tech-y, but I thought it was fun to basically rip the cover off, so to speak, of an actual exploit, a physical exploit against a phone, which works.



FR. ROBERT:  Yes, yes.



STEVE:  And if anyone wants to see, again, the link is in the show notes.  The pictures are just captivating.  The guys, they really documented it beautifully.



FR. ROBERT:  That's a lot of work.  And I understand, yeah, everything that's there I can build, or I probably have in my lab already.  But to say that this is something that you can do easily, no.



STEVE:  Well, and there's no instruction manual.  You know, this is all - first of all, I don't even know how you unsolder a BGA, a ball grid array, NAND.  Because, I mean, it's got little solder dots on the bottom of it.  It's like, and so it's done once, and it's there for good.  So I don't even know how this guy got it off of the back plane.



FR. ROBERT:  Well, I have the device to make that happen, but it would destroy the PCB.  So again, don't try this at home, folks.  Leave it to the professionals and the professional amateurs.



STEVE:  So I had three bits of miscellany.  I got a tweet from a Will D., who said:  "@SGgrc My school's DNS server was down this morning, but I remembered your DNS Benchmark tool.  I am back online and faster than before.  Thanks."  So I did just want to remind people that that Windows app that runs under Wine, so if you've got Wine emulation in Linux you could use it there, too, or even on your Mac, it's become the industry standard DNS Benchmark.  Google had something for a while, but it sort of fell by the wayside.  And this little bit of freeware that I wrote, I think it was like in '06, really does the job.  And so I just wanted to put it back on people's radar.



Remember we spend a lot of time talking about DNS in various contexts today.  You have to, our browsers have to have the IP address, the physical Internet protocol address, of all the sites that they're accessing data from.  And today's web pages are covered with resources coming from just a huge scattering of servers.  If your local machine doesn't already know what the IPs are, it's got to ask somebody.  And it's got to wait until it gets an answer.  So if you're not using fast DNS, your entire experience of the Internet is hampered by that because that's the first thing that happens is that those ASCII names get mapped into an IP address.



FR. ROBERT:  Right.  Actually, a fan of the network sent me a little plugin that he's creating for Synology's router, their RT1900ac.  It's their SRM operating system.  It allows for plugins, just like you would have on one of their NASes.  And what he created was a service that you could put an app on your desktop.  And every time you do any sort of search, it breaks down how much time it took for the query to take place versus how much time it took for the actual content you requested to be downloaded.  And it's fascinating to have that running up on the desktop, and you get to see, wow, I spent more time waiting for DNS than it took to download all this text and pictures.  And it does kind of change your appreciation for good DNS.



STEVE:  Well, and you know that DNS sometimes doesn't get the attention from ISPs that it deserves.  It's not sexy.  It's sort of, okay, we have to provide a DNS server.  Maybe they don't give it the fastest one because they want their website to run fast, but DNS, eh.  And no one really complains when it's slow.  So you may - your ISP, it's sort of like the unloved stepchild of Internet service providers.  It's like, yeah, well, yeah, we have it.  And so it's worth making sure that you're not being slowed down because your ISP just doesn't care to give you good DNS.  You could certainly change it, take responsibility and find something faster.  And GRC's little DNS Benchmark tells you, helps you rate all of your alternatives.



FR. ROBERT:  Steve, you run your own DNS; right? 



STEVE:  Yeah.



FR. ROBERT:  And I used to, and then two moves ago I decided I just didn't want to bring the box with me anymore.  And so I've used Google 8.8.8.8 and OpenDNS at, what is it, 208.67.222.222 and 220.220.



STEVE:  That's right.



FR. ROBERT:  If you had to use a third party, what would be your favorites?



STEVE:  I'm with you.  I still like 4.2.2.1.



FR. ROBERT:  Ah, yes, of course.



STEVE:  And of course that's a Level 3 server, and I'm hosted by Level 3, so that works.  And 8.8.8.8 is another choice.  What I do is one of my FreeBSD boxes, the one that runs the GRC newsgroups, the NNTP groups, that also runs BIND.  And mine is a master for two Level 3 slaves.  So when they need to check in and get an updated zone, they ask for that from me.  And so the public sees these very strong, big iron DNS servers that can handle any load, that are super well connected, that are right on the Internet backbone for high performance.  And then, when I make changes, I'm able to send them an update command that causes them to immediately refetch an updated zone file.  So it's sort of the best of both worlds.  I don't actually myself handle any public traffic.  They're my front servers for me.  But mine has the master records that they pull from as needed.



FR. ROBERT:  Let's move to a different type of DNS question now.  People always ask what I use to host my services.  And I'm lucky enough to actually still have access.  I have a /8 that I can borrow from every once in a while in IPv4 space, which is amazing.



STEVE:  Oooh.



FR. ROBERT:  Yeah, I know.  So I still like using my quads.  But some people want to use a third-party solution.



STEVE:  Well, we talked last week about the whole dynamic DNS issue.  We were talking about the idea - it was a Q&A episode.  And one of the people asked, do you still recommend proXPN as a VPN provider?  And I explained that there were certainly applications where using any of the major VPN hosts made sense.  And you wanted one that was not going to be logging and tracking your traffic, just for prudence.  And we know that proXPN doesn't.  So it's as good as any others.



But the position I took was that the problem with that is that, very much like a Tor exit node, a VPN server will be emitting traffic onto the 'Net from all the people using the service.  And that just has to be a tasty spot for any government agencies that are interested in what it is that people are doing over their VPNs.  Why do they need more privacy, for example, or need to appear to be in a different location than they actually are?  So the nature of its concentration of traffic is a little off-putting in today's world.



So what we're seeing now are good options for running an OpenVPN server on your own router at home.  We've talked about that there's a project called PiVPN, which takes a Raspberry Pi and, using a shell script, just completely automates the process of establishing and configuring an OpenVPN server for $35 in a little Raspberry Pi, which you then plug into a port on just a generic router, do a little bit of port mapping so you can get to it from the outside, and now you've got an OpenVPN endpoint.  And then the alternative is, if you have something like pfSense running on a router, or the router that's now the show favorite is the Ubiquiti EdgeRouter, all of those are FreeBSD based and have OpenVPN servers built into them.



So the problem, of course, though, is that ISPs are not obligated to give their typical home cable or DSL subscribers a static IP.  That requires dynamic DNS.  That means we need some service in a fixed location on the public Internet that we can refer to, that has been updated by our device about its current IP.  And so I talked about last week that Google's domain name services, for a dollar a month, $12 a year, would provide domain name and provide dynamic DNS as part of the bundle.  There's another registrar, Namecheap, that also offers dynamic DNS.  Hover, my chosen registrar, does not.



But Kevin Garman tweeted me about a service that I wasn't aware of, and I've not used it.  But I spent some time poking around, and I'm impressed.  It just has the right feel to it.  It's called, unfortunately, Afraid.org, A-F-R-A-I-D dot org.  It's FreeBSD based.  His slogan near the top of the page says:  "Why is it free?  It's quite simple.  We wanted a challenge.  That's it."



So what this lets you do is they're a DNS server and essentially a DNS host.  So you can create yourname.afraid.com, that is, whatever you want .afraid.com, and point it at your home IP, and then use the dynamic DNS support in your router to keep it updated if your home IP changes.  And they offer a bunch of other services.  So I just wanted to sort of put it on our listeners' radar, Afraid.org, for free DNS, including dynamic DNS.  And I just, as I was poking around there, I just got a good feeling about the place.  It looks like the right kind of deal.



FR. ROBERT:  Yeah.  I still have a bad experience that I remember every time someone asks me about dynamic DNS.  I was living with a Jesuit who - he wanted to host his own little web server, so I showed him how to make a web server, and then he said he was going to use dynamic DNS.  I'm like, okay, obviously he knows what he's doing.  He didn't.  And all he did was he opened up a DMZ port, the entire - all the ports to the box.  And so within 24 hours I started seeing this weird traffic running over our network.  And I go over, I'm like, yeah, that was one of the fastest ownings I've ever seen.  Congratulations.  So, yeah, if you're going to do this, just make sure you understand port forwarding and know what services you actually want to run.  And then what I would suggest is you run ShieldsUP against your newly created dynamic address, just to make sure it's only listening on the ports you want.



STEVE:  Yup, exactly. 



FR. ROBERT:  All right.  That's good to know.  Afraid.org.



STEVE:  Yes, Afraid.org.  Check it out, if it sounds like it might be interesting to people.  Again, it looks like a straight-up good deal.  I feel good about it, looking at it.



Simon Zerafa, who's a friend of the show and frequently sends me valuable links and tips and oftentimes funny O'Reilly covers, he sent me something he wanted me to share.  He said:  "Hi, Steve.  Can I please request a PSA?"  Which I thought, a PSA, okay, that's a - I don't know.  I have to figure that...



FR. ROBERT:  Public service announcement.



STEVE:  Public service announcement, okay, for this week's show.  I thought maybe a personal shout-out or something?  I didn't know what.  Anyway, public service announcement, thank you, for this week's show.  He says:  "My wife had a serious medical emergency yesterday, and we hadn't filled in the Emergency Contact information on the iOS Health app.  As a result, the emergency services were delayed in contacting me.  Can we ask listeners with iOS devices to fill that info in and enable it on their lock screens?  It should make it easier in the future for emergency services to contact people and won't require them to enter their iOS PIN code to access their emergency contact details."



So I thought that was a great tip.  It hadn't occurred to me.  It's the kind of thing you never think to do, but once you wish you had, it's often too late.  So now would be a good time to do that.  It makes a lot of sense.  Apparently something happened to his wife such that she was unable to provide her contact information.  They had her phone, but they couldn't get into it in order to know who to contact.  So thank you, Simon.  That's a great tip.



FR. ROBERT:  I just realized that your smart device is your new medical ID bracelet, the little thing that you used to carry.  I mean, I used to carry one that would say what you're allergic to and who I should contact.



STEVE:  Right.



FR. ROBERT:  I haven't done that in over two decades because now I just carry my mobile device.  And it does have my emergency contact info on the front locks page.



STEVE:  Nice.  Nice.



FR. ROBERT:  You know what, Steve, I can't do an episode of Security Now! unless I hear about SpinRite.



STEVE:  Well, believe me, you're not subjected to them every single week, like all of our listeners.  I just have two short notes that are kind of fun.  Michael Nation in Michigan referred to me as "Steverino," and he said, "Apologies to Steve Allen."  He said, "I run SpinRite on all my drives all the time, and nothing ever goes wrong.  I'm disappointed.  If I'm paying for health insurance, I expect, well, to get sick."  And so I thought, okay.



And then I thought, okay, wait.  To apply the health insurance analogy, it would be more like using RAID to recover from drive problems.  Using SpinRite is more like taking an adequate level of Vitamin D to prevent any drive from having problems in the first place.  So insurance doesn't keep you well.  SpinRite does keep your drives well.  So I think that's even better than having something that is able to recover from problems or cover you if there are problems.  Just don't have them in the first place.



And then an anonymous person shot me a note with the subject "SpinRite rescues a stuck Windows 10 update."  And that's the first I'd heard of that happening.  He said, "My Windows 10 v1607 patches got stuck today, and this isn't the first time in all, although it is the first time for a v1607 update.  Retrying didn't and doesn't help.  So usually I would revert using system restore and try re-updating again. But this time I tried SpinRite - and it worked."



So this is sort of a reminder that drives are, they continue to be, even SSDs we are finding, arguably the least reliable component in the system.  Everything else is just - it's a lot more solid.  Maybe we're demanding much less of it.  Certainly the bit density of mass storage has been subjected to huge competitive pressure for decades now, with the consequence being we all see reports about drives not lasting as long as they used to, manufacturers creeping the warranties down over time, just sort of hoping no one will notice that they went from a five-year to a three-year warranty, and so forth, because they're under pressure.



I'm happy that the mechanical spinning drives are staying alive, although it looks like SpinRite is going to be able to provide a solution for non-spinning mass storage, as well, based on experience.  But for what it's worth, when something doesn't seem right, just run SpinRite on the system.  And a surprising number of times it actually was a small mass storage glitch that wasn't revealing itself to be that because they often don't.  There's something wrong, but who knows what?



FR. ROBERT:  You know, Steve, I just realized what I want out of a future version of SpinRite.  I want, again, your elegant assembly code, but something that runs as a timed script in either Windows or OS X, specifically for my SSDs.  I want it to do garbage collection at 4:00 o'clock in the morning when I'm not awake, just because every time I start to slow down, I will pull out my copy of SpinRite.  And is it Level 1?



STEVE:  Level 2.



FR. ROBERT:  Level 2, Level 2, where it's just - it's basically going to the drive.  It's not using up any of my writes unless it needs to actually destroy something.  And it's just looking at what garbage collection has not yet been done.  I tell you, you've saved a couple of my Samsung SSDs from the brink of death, and you've definitely improved my performance.  So personally I thank you.



STEVE:  Well, thank you.  And we had a story just last week about exactly that.  Some guy's machine was just not running well and fast, and it was an SSD-based system.  Ran SpinRite across it, and it was snappy as ever.  So there again, even solid state memory.  Unfortunately, the marketing pressures have pushed the density to the point where it's good enough, but there just isn't any tolerance.  The old engineering margin has just been squeezed out.  So, I mean, it's inevitable, but it's unfortunate.



FR. ROBERT:  Right, right.  And actually... 



STEVE:  Good news is we have a solution.



FR. ROBERT:  If you could get a version of SpinRite that runs on my Android phone because I'm pretty sure that memory has not been leveled at all.  It's horrible.  All right, Steve.  Big story.  Big story for us and for the people in the chatroom and the long-time listeners of Security Now!.  They've followed this saga a little bit.  We all know that a while back you raised the alarm that there might be some weirdness going on at GRC.com, maybe some cross-site scripting.  And you've put on the propeller hat and figured out exactly what was happening.



STEVE:  Well, so what happened was a couple weeks ago someone tweeted me, someone using the Twitter handle @tbmnull said just - it was a short tweet - "XSS vulnerability found at GRC," and then a link to a site called OpenBugBounty.org, www.openbugbounty.org, which is where this person was apparently very active because I looked at the cross-site scripting problems he had reported, and they are all over the place.



So he didn't single me out.  I think he's a white hat hacker who's decided to take it on himself, take on the mission of finding vulnerabilities in websites and reporting them.  He made some money from me.  It's a voluntary payment, but I wanted to thank him for bringing this to my attention and for everything that transpired because I ended up with something that I think will be very valuable to a subset of our listeners, arguably anyone who has responsibility for a website.  So that page didn't show me what the problem was.  I had no idea where there was a problem.  The fact that this person, this tbmnull, had reported so many caused me to give it some credibility.  But, so, okay, what did he find?



So the first thing I did was I thought, okay, there's got to be some free or reasonably priced scanning services, sort of like ShieldsUP has always been for a person's ports, but this would be a service that would scan a website, looking for these kinds of problems.  There's got to be.  And sure enough, I dug around, and I found three that had kind of the right profile.  I think there was like a list of 11 that I found in an article.  But the other eight were sort of off target.  They weren't exactly what I was looking for, which was spider my site and tell me what you find.



So the first one was an offering called Acunetix.  And they offer both an online scan and a local Windows app, which I love the idea of being able to download an app.  So this would be very useful if you wanted to scan a non-publicly facing Intranet server, which an outside site could not get to.  Or if you just like the idea of running your own scan against your own site, rather than having a third party do it.  So I signed up, downloaded the app, and they were clearly in a trial mode.  But it was like, okay, they're saying that they're going to allow me to do scans in trial mode.



One of the things that you always have to do, and it's very much like applying for a certificate, you need to prove ownership of the site, not surprisingly.  That prevents random third parties from scanning other sites that they don't own and control and having problems revealed.  So clearly a responsible scan service would require you to prove ownership.  In this case, it was put a file on the root, and I did that, and it just worked.  So authenticating with them, authenticating that I was the person who had control of the content of GRC.com, not a problem.



Well, then, okay.  So their online service scans - and I don't remember now which one I did first.  But I tried both.  And both of them reported all kinds of horrors.  Oh, my god, the sky is falling.  How have you not been attacked every which way from Sunday by now?  What's wrong with you?  But we're not going to tell you what.  And I said, what?  And then, you know, dire warnings, but you've got to pay us.  And so, well, which did not impress me because the whole thing was a bait and switch.  Nowhere was there any implication that we're going to frighten you, but use that to get your money.  Which just pissed me off.  Also, for what it's worth, the local app was very poorly written.  They want many hundreds of dollars a year, so it was not like it was cheap.



But, for example, one of the first things you learn to do when you're programming Windows is you create a UI thread that is a separate thread to run the UI.  For example, the DNS Benchmark has one.  While the benchmark's running, you can push buttons and flip pages and do all kinds of things.  You know, it all just sort of works at the same time.  Well, this thing had pause and stop buttons that you couldn't push when it was running, although that's a little contrary to common sense, because they don't have a UI thread, or it's not being sampled often, or I don't know what.  But anyway, I ended up thinking, okay, this is not what I'm looking for.  I don't want to be told that the sky is falling; but, sorry, we're not going to tell you where.  Then the spam began, four or five pieces of marketing sales promotion per day from this company.  So anyway, Acunetix, no.



Second one I looked at was a company called Beyond Security.  Now, I had an interesting problem with those guys.  I was unable to authenticate without their help.  They provided me a file that I drop onto my root, but they refused to see it.  And I immediately realized why.  And that is, from the first day of its existence, like 15 years ago, the root redirects to a page called Intro.htm.  I don't know why.  And if I were to do it again, I wouldn't.  But back then, 15 years ago, it was all sort of magical and new, and I thought, ooh, this'll be fun.  So there's a 301 redirect which is the only response anyone gets to trying to pull GRC's root page.  It doesn't deliver the full document.  It bounces you to a named document.



Well, apparently Acunetix knew how to follow the 301 redirect.  I don't think that represents a security vulnerability.  But the Beyond Security guys' scanner didn't.  So I was unable, late at night, whenever this was I was doing this, to use their service.  I did send them a note, and I think they recognized me because they immediately said, "Oh, hi, yes, we'll authenticate you."  And so I was able to user their service.  I noted that their page required Flash for displaying summary graphs, which is a little disappointing because there's three blacked out boxes because of course Flash is not running without my permission on my browser.



FR. ROBERT:  That's the first warning flag, there.  A security scanner that demands you have Flash.  Like, oh, okay, hmm.



STEVE:  They're very nice people, and they were willing to work with me.  But their scanner didn't find any problems.  It gave my site, GRC, a 100.00 and an A+ grade.  So I thought, well, okay.  I know, I'm pretty sure there is a problem somewhere.  I'm trying to find it.  So far one service says, oh, my god, how is this server even up?  But we're not going to tell you how to fix it or what's wrong without money.  And then these guys, who are fabulous people, said, yeah, no problems here.  Move along.  Nothing to see.  So I thought, okay, I've got to keep looking.



Number three, and the third time was the charm:  TinfoilSecurity.com.  I am incredibly impressed with this service and with the user experience, with the user interface.  It is a teaching site.  It is the Security Now! podcast chosen website security scanner until further notice.  I'm sold.  Now, their authentication, as with Beyond Security, would not allow a resource on the site to be seen.  So they're also not following a redirect to my intro page, which is my nominal home page.  But they offered one additional means.  I could put a text record in my DNS.  And that's, like, brilliant.  So that demonstrates I'm controlling the domain of GRC.com, which is tantamount to controlling the server.



So they gave me a blerch blob of nonsense.  And as I was talking about earlier, I updated the GRC.com zone with that text record and then informed Level 3's DNS servers that I had a new zone.  They grabbed it.  And then I said to Tinfoil, I clicked the okay, authenticate me, and they said, yay, you're authenticated.  So now they knew that I was in control, and the account that I'd just created was there.  They offered a single-domain 90-day trial.  It's a three-month trial, which I think is generous.  And believe me, I'm sold.  I'm, well, and so here's the details.



Their report found 64 problems.  Now, okay.  And I'm going to go through them real quickly.  They're finding things that are good to know, but they're not cross-site scripting or cross-site request forgery problems or anything, but useful.  And our listeners will get a kick out of some of them.  But this is the kind of thing where I'd rather have too many than to be told, oh, you get an A+.  Nothing wrong.  So because you can always look at them and go, okay, I know about that.  That's not a problem.



So most of them were informational.  A couple were low impact.  And then there were some that they thought were high impact.  For example, I was notified, one of them, they called it "credit card number disclosure."  And sure enough, their spider found a string in my PDP-8 source code listing, which I have on my PDP-8 pages:  4207 0610 0000 0013.  That's a credit card.  Except it's also octal, and it's machine language.



FR. ROBERT:  I think that's Leo's credit card.  Hmm, Amazon.com.



STEVE:  So, and maybe they're smart enough to know that the first digit has to be a four.  That's actually one of the leading digits for credit cards.  But I was impressed.  It was like, okay.  If I actually did have somehow a credit card flapping in the breeze, I'd want to know.  This thing would have found it for me.  In this case it wasn't a problem.



They also identified 10 instances of what they called "missing subresource integrity protection."  Now, I should explain that with every one of these, it's itemized.  You can click on that item.  It takes you to a page that completely breaks it down, shows you where it was, what the query was, what the response was, what they matched on, and what it is they think it means.



So, for example, in this case they said:  "All externally loaded resources" - externally loaded resources - "must have their content pinned by using the subresource integrity mechanisms provided by modern browsers.  This involves computing a hash of the contents of the resource, and specifying this hash when loading that resource.  In the case of a script, this might look like the following."  And they give you a sample of, like, here's what we mean, where they show include.js being loaded from example.com, and then the integrity is an SHA-256 following.



And so the point is that this is your declaration of exactly the code you are pulling from some remote site that you don't have explicit control over.  So this is your way to tell the browser, make sure no one has messed with this.  If you get it and load it into the web page, hash it and make sure the hash balances.  Otherwise don't.  So great advice.  And there are a couple places where, on my side, I am pulling something from somewhere, and they saw that.  And it's like, bravo to these guys.  Again, another nice piece of information.



They also found 14 email addresses.  And I thought, what?  Well, it turns out in more than 11 years of Security Now! transcripts, some email addresses for one reason or another have been put in the transcripts.  It found them all.  It went through every single Security Now! transcript and said, hey, you've got some email addresses here.  You sure you want to expose those to the public?  And again, not a problem, but very nice to have something with a push of a button that can go find those for you.



And this was interesting.  There are two problems which it called "found robots.txt."  And I thought, well, yeah, of course.  I have a robots.txt to keep spiders from getting lost in my dynamically generated code.  And so when I clicked on it they said:  "If you require it, try not to list important files or directories in robots.txt.  Instead, password-protect them such that, even if they are crawled, the crawler gets nothing but an authentication page.  A good robots.txt file includes content like image directories or locations that are generated dynamically and do not work if a search engine accesses the page, but does not include administrative areas or server logs."  And so I think that's sort of a generic comment that they make when they, you know, sort of like, "Here's a tip for tightening things up on your site."  Again, a nice observation.



They found seven things they called an "HTML object."  And I do have some.  I have HTML native video players, for example, on the various PDP-8 pages and on a couple of the SpinRite pages.  And so their comment was:  "This is nothing to be concerned about at the moment, as we are purely providing it for informational purposes.  It often gives the hacker a beachhead of where to begin searching for a vulnerability, but isn't a vulnerability in and of itself."



They reported four insecure cookies, saying:  "Set the 'secure' flag in the cookie such that all cookies are served over a secure channel like HTTPS only.  If you tell us what software stack you're running on your website, we'll be able to give you more detailed results on how to fix this issue.  You can do this from your dashboard."  And then there's a link there to their dashboard, which is their online configuration tool.  Oh, and I should say, by the way, you can dial how aggressive you want the spider to be.  I think it defaulted to 50 simultaneous requests.  I pushed it up to 100 just because I have a fast server.  But, I mean, it did, I could tell when it was on the site, it was sucking everything out.  But again, if you want a less aggressive spidering, you can ask for that, too.



It also noted non-HTTP-only cookies four times.  And they said:  "Set the 'HttpOnly' flag in the cookie, such that cookies cannot be manipulated via client-side code like JavaScript.  If you tell us," again, what software stack you're running, blah blah blah, we'll tell you how to fix it.  Again, the whole experience is handholding; explains what's going on; and, where they can, gives you samples and fixes.  And I should mention, the only place I use cookies is in that - and they're crazy named cookies.  I don't do it for any sort of login state ever.



Even my eCommerce system does not maintain state using cookies.  It encrypts a blob of current transaction state and returns it with each phase of the transaction.  And no one has the decryption key but the GRC server.  So even there I don't use cookies.  The only place I do is in the cookie forensics research that I did when we were finding bugs in cookie handling years ago in browsers.  And so the reason I've got cookies is just as instrumentation probes, essentially.  And they're right.  There's no reason I don't have them marked secure because now GRC is all secure.  I just never went back and retrofitted it.  But here's the reminder.  It's like, okay, that would be a good thing to do.



FR. ROBERT:  I've been looking through their site as you've been talking, and I love the fact that they separate issues from potential exploits.  I think that's very important for someone who's just scanning their page, and they're not going to freak out.  And then I love the fact that you can drill down on the individual issues to see exactly what they're talking about.  And, honestly, I'd never thought about that with robots.txt.  Yeah.  [Crosstalk] files tell someone who might want to exploit my site exactly where I don't want them to go.



STEVE:  Right, right.



FR. ROBERT:  Oh, wow, okay.



STEVE:  And so the last of the insignificant things was 16 what they called "private IP address disclosures."  And again, given the nature of my site, you can imagine, and in fact on the intro page to ShieldsUP I say "You should be aware that scanning probes will come from this range of IPs," from this IP to this IP.  So there's two, you know, there's two IPs.  So again they said these were again - oh, no, I'm saying in Security Now! podcast transcripts.  And then they said:  "Remove private IP addresses from the body of HTML pages."  And they wrote, "These can often be left over from testing and may indicate that your website is not running in the environment it expects.  These IP addresses also give information to an attacker that can be used as a beachhead for other more harmful actions."  So again, if you don't have reason to know that you've got IP addresses exposed, that's something good to know.



But they did find three things.  One was a false positive, but I love that they flagged it.  On the GRC Fingerprints page, I provide a field that allows someone to fingerprint the certificate of any domain they choose, of any site they wish.  And they flagged it as a potential cross-site request forgery, saying it was due to no replay protection.  And their advice on that said that it would be possible for some entity to resubmit that form in the future because there was no - like a serial number embedded in the post data that the page was placing in front of the user, and that the user was then sending back to the server.  And that's true.  But that isn't an issue here.



And I do show the domain name in a - I display the domain name back to the user, which is sort of scary because anytime you display something the user provided, that's the big danger, when we've talked about things like SQL injection attacks or cross-site scripting, like for example a forum, back in the days before forums were carefully filtering what users submitted and they posted, when the forum puts up on the display what somebody has submitted.  Well, if they submitted something malicious, and it was left intact, that would be displayed and then potentially running in the user's browser.  So, but in this case I carefully parse out the domain name from whatever the user provided, and I have a zero tolerance policy.  And so I tried to, like, mess with it and get something through and was unable to.  And nobody thought that was a problem anyway.



However, they found four URLs in the discussions client, essentially.  GRC, as I've often talked about, has an old-school NNTP server where we have a bunch of discussion groups.  That's where all the work on SQRL has gone on, and it's where I will be returning to SpinRite to work with a community of people testing and asking for thoughts as I move forward.  It's a huge resource for me.  We have a read-only facility which allows people who just want to browse what's going on, that's always been there, which I did not write.  It used to be called DNewsWeb.  And their server was awful, so I had purchased it years and years ago, and I abandoned it and switched just to FreeBSD Unix and a real INN Internet news server.  But I kept their little web frontend because it was just a handy means to allow people to browse.



Well, it turns out that it has a facility to allow people to kind of login.  They can identify themselves.  I don't use that.  But it's called a "utag," a user tag.  And once you provide that, it goes in the form.  And then, in order to link successive browsing together, every response returns it.  And it's not filtered.  Meaning that anything you put in the utag will be found and returned.  And so if something malicious were put in there, then that would come back and potentially be executed by the browser.  So there are four instances of that.  The bad news is I didn't write that little, I mean, it's an inelegant piece of code.  It's big, and it's an EXE, and it sometimes misbehaves.  But it hasn't caused us any problems.



The problem is, without source, I can't fix it.  And so it technically represents a problem.  So what I did was I wrapped those pages in what's called Content Security Policy, CSP.  Content security policy can be delivered either as reply headers or response headers in the page, where their metadata is not seen, or in the actual HTML headers of a page.  And essentially they control what the browser will do.  Without any content security policy, because we need to be backwards compatible, everything is wide open.  So there is no control.  But you can add the CSP, the Content Security Policy rules, which will restrict what can be done.



So, for example, now all of those browser pages, every one of them has a header which is incredibly restrictive.  Just enough for the page to work.  I said, I allow images to come from GRC.  I allow CSS.  I'm blanking.  CSS style sheets.  I allow the GRC style sheet and images and text.  But, like, nothing else.  No script, because this thing does not need scripts.  No inline scripts.  No child frames.  No fonts coming from anywhere else.  No media, no other objects, and so forth.  So it is just - it's completely locked down.  It's not as nice as being able to filter it.  But I don't want to take the time to wrap that in my own code, to provide a filter or to write one myself.  And I've got work to do.  So that solved that problem.



But so those things it found.  And then finally they found what the attacker found.  And there actually was a problem.  Again, in the particular case of GRC, it wasn't mission critical because I don't have any cookies of any value.  And it's hard to see how this would actually get exploited.  But under the support page, or sales support, I allow a user to put their SpinRite purchase transaction ID into a form and basically make a database query.  We look up that record for them, which then allows them - they get download links if they want to download another copy of SpinRite, or they want to print out another copy of their purchase receipt or whatever.  If their transaction ID was not found, I was providing them the service of returning the form, saying that we did not find your transaction ID, and populating the field with what they provided.  [Buzzer sound]  That's dangerous because user-provided data is being returned without filtering to the site, that is, to their browser.



And what this white hat hacker found was that there was a clever way of escaping HTML characters such that he was able to insert inline script in the form field.  You actually couldn't do it in the field because I had restricted its length.  But a spider could do an automated posting that would have no length restriction because it wasn't being enforced by the page UI, and get their script to execute in the GRC domain of the user's browser.  And you don't want that to happen because, if I were, for example, maintaining state, like session state, in a cookie, script running on a page from GRC is trusted.  And it would have access to, if my cookies were not marked HttpOnly, which is the other thing these guys found, it would have access to cookie contents and could then, for example, generate a URL query to a malicious site with that cookie, the name and value embedded in the query tail, and thereby exfiltrate data that was meant to be private between the server and the person looking at the page.



So I was delighted to find this, and I immediately fixed it.  The standard best practices says that less than, greater than, ampersand, double quote, single quote, and forward slash are dangerous.  You cannot allow those to come to the browser unescaped.  And so the update I made a couple weeks ago is to have a safe HTML send function that this and anything else that sends data back to the user runs through.  So, for example, it converts an actual less-than symbol into the &lt;, which the browser displays as less-than, but which doesn't trigger script execution.  It's not like the angle brackets containing the word "script."  And I also added content security policies just as belt and suspenders, as well.



So, and I notified the hacker, and I thanked him.  He mentioned that he'd be willing to accept a little donation in thanks, and I treated him very well with an Amazon gift certificate, which is the means that he suggested.  And in the process I found an online website scanning service that, based on all of my experience, and even the experience of looking at the competition, I can recommend without hesitation.  TinfoilSecurity.com, 30 days for free.  I mean three months, yeah, 90 days, three months' trial, 100% functional and much more comprehensive than anything else I have found.  If you are responsible for a website, I don't know what you're doing still listening to this podcast.  Sign up, have them scan your site, and then browse through the results.  There's no way, based on what I've seen, they could ever be happy, which is what you want from something checking your site to make sure you haven't had any oversights.  So bravo to Tinfoil Security.



FR. ROBERT:  Steve, talk about burying the lede, this should have been at the top of the show because this is a practical example of so many things that you talked about over the years on Security Now!.  This is you finding a vendor that you trust.  This is you finding a couple of vulnerabilities within your own site, mostly because...



STEVE:  I know more than I did before, precisely.  It educated me.



FR. ROBERT:  This was your "Iliad" and your "Odyssey" all rolled into one.  And thank you.  This is something I'm hoping that we hear from more podcast celebrities and more big websites because I think the more that you disclose about the vulnerabilities that you find, the more people are secure, the more that they'll patch it in their own instances, their own services.



STEVE:  Right.



FR. ROBERT:  Of course, we have gone way over time, which I guess is actually pretty normal for Security Now!.



STEVE:  We broke our record, I'm sure, Father.



FR. ROBERT:  No, no, no.  Actually the two of us still own the record.  I think we went 2:40, 2:40 something on one.



STEVE:  Okay, we're at 2:24 right now.



FR. ROBERT:  2:24.  And they actually restructured the schedule so that we can't break our record without really messing up the shows behind us.



STEVE:  And we're not going to do that.



FR. ROBERT:  No, we're not going to do that.  But of course, Steve Gibson, you're going to find him every week here at, what is it, 13:00 Pacific time - 13:30 Pacific time.  He is our security guru.  You're going to find him at GRC.com, where you can also find transcripts and audio versions of the show.  We do Security Now! here on the TWiT.tv network normally with Leo Laporte, but I'll be subbing for him while he is looking for the Holy Grail.



STEVE:  Two more times.



FR. ROBERT:  Two more times.  Two more times.  Exactly.  And I'm very much looking forward to it.  And don't forget that you can find all of the back episodes.  If you need to replay - and trust me, there's no dishonor in having to replay it because Steve is pretty condensed in the information that he gives to us - you can always go to his show page at TWiT.tv/sn, that's for Security Now!.  There you'll find all of the back episodes, as well as ways to subscribe to get the show automatically downloaded into your device of choice.  Of course, you can also find Security Now! wherever fine podcasts are aggregated.  Steve, would you like to say some final words of wisdom before we send the Internet back into the ether?



STEVE:  I think you've got it covered, Padre.  It was a pleasure working with you for the last 2.5 hours, and we'll do it again next week.



FR. ROBERT:  It's been an absolute pleasure, Steve.  And on a personal note, I do have to say this.  And this only makes sense to the people in the TWiT Army.  I'd like to say rest in peace to Tater, and we will miss you.  Until next time, I am Father Robert Ballecer.  He is Steve Gibson, the man himself.  And we'll see you next time on Security Now!.



STEVE:  Thanks, Padre.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#579

DATE:		September 27, 2016

TITLE:		A Very Busy Week

HOSTS:	Steve Gibson & Fr. Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-579.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Father Robert and I discuss Brian Krebs' forced move from Akamai to Google's Project Shield, Yahoo's record-breaking, massive 500-million-user data breach, and Apple's acknowledged iOS 10 backup PBKDF flaw.  A well-known teen hacker jailbreaks his new iPhone 7 in 24 hours.  Microsoft formally allows removal of GWX.  There's a new OpenSSL server DoS flaw, also more WoSign/StartCom woes as Mozilla prepares to pull the plug.  BitTorrent Sync is renamed and more deeply documented.  Then we have a bit of errata, some miscellany, and 10 questions and comments from our terrific listeners.



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  1Tbps DDoS attacks are on the horizon; it's time for you to say goodbye to Yahoo!; iOS 10 is 2,500 times easier to crack; and it's judgment day for misbehaving CAs.  It's all coming up next on Security Now!.



FR. ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 579, recorded September 27th, 2016:  DDoSes, breaches, and other records to be broken.



It's time for Security Now!, your respite from the increasingly insecure world in which we live.  It's the show where we take a deep look at the hot topics and the newest exploits and the most frustrating worst practices in the security world with our Explainer in Chief, Mr. Steve Gibson.  Steve, of course, of GRC.com, the man who created ShieldsUP!, SpinRite, and SQRL, fine security products that we all use.  Steve, again, it is a pleasure to work with you, my friend.



STEVE GIBSON:  Hey, Father Robert.  Great to be back with you for our second of three recordings with you of Security Now!.  And it's interesting, when you were saying "increasingly insecure world," I was thinking, okay, is it increasingly insecure, or are we just more aware of the existing, always have been there insecurities?  And I think both are true.



FR. ROBERT:  Absolutely.



STEVE:  And unfortunately I think, as we keep adding features and new capabilities, the lesson is we're introducing vulnerabilities that didn't exist before.  So there's both cleaning up the new messes and catching up with the old messes.  So oftentimes we're talking about some OpenSSL problem that's been in there for 20 years, and no one had found it.  So in one sense we're less secure because now it's been found.  On the other hand, then it gets fixed, and so we're more secure than we were, even though we didn't realize before that we were less secure than we thought.  So if that doesn't confuse you, this podcast will.



FR. ROBERT:  Steve, this is actually a very common trend inside of any kind of reporting, not just the tech world.  But it's the whole idea that, since the news cycles now go 24/7, and not only that, but they go beyond because anybody can be a news source now with social media, you find out about things a lot more quickly, and you find a lot more hyperbole in our standard news sources.  And I'm with you.  I think a lot of these exploits have existed forever.  It's just now they're being brought to light.  But there is one thing, and we're going to talk about this later on in the show, that I think goes on the other side, where it is more and more insecure.  And that is the Internet of Things, the exploding Internet of Things, as it's really changed a couple of the equations as far as what we think is secure and what is not.



One quick, though, before we go, I can't believe this.  This is your Q&A 240.  This is 240 Q&A, Steve, of 579 episodes?  That's amazing.



STEVE:  Yeah.  I didn't realize that we started that as early on as we did.  But I was beginning to get feedback from people.  And I thought, you know, it's really great to hear from our listeners.  It engages our audience, and it helps me to better understand, like to steer the podcast and understand the sorts of things that we need and should cover.  And this week we've got a bunch of stuff.  We've got to, of course, talk about Brian Krebs' problems with a big sustained DDoS that finally forced Akamai to say, "Brian, we're sorry, we cannot continue hosting you."  That generated a lot of controversy and some interesting social commentary, as well.  And of course he got picked up by Google's Project Shield that we'll talk about.



Much abuzz in the news was Yahoo's - they actually broke a record, and not in a good way - half a billion user record data breach.  There are some interesting details about that, that I haven't seen much covered in the press.  Apple did break something crucial in iOS 10's backup.  We'll talk about that.  Within 24 hours of getting his new iPhone 7, a teenager, hopefully after he finished his homework, jailbroke the phone.  Microsoft formally offers the removal of the Get Windows 10 - I don't want to call it malware - annoyware.  There's a new OpenSSL DoS flaw, which essentially allows a remote person to crash a server that's based on OpenSSL.



More problems with WoSign and StartCom relative to Mozilla.  We covered this a couple weeks ago, that is, looking at Mozilla's very careful march forward, laying the groundwork for basically pulling the plug on their support for WoSign and StartCom's certificates.  BitTorrent Sync is one of the most requested for podcasts, that is, for me to talk about it.  The problem is they absolutely refuse to provide documentation for the protocol.  There is a new paper out, still doesn't give me what I want, but it's probably enough that I can give it a podcast and talk about what we do know, with the caveat that, well, without the details, there could be something hidden.  But their heart seems to be in the right place.



We've got a little bit of errata, some miscellaneous stuff.  And then, being a Q&A, as you say, the 240th one, we'll look at 10 user/listener-prompted comments and questions and discuss those.  So I think another great couple hours for our listeners.



FR. ROBERT:  That's absolutely amazing, Steve.  Just the amount of security-related stories that have broken this past week and a half or so have been fantastic.  As you mentioned, everything from Yahoo's very, very unfortunate record to Akamai.  And actually that's a very serious problem which, as you mentioned in your opening comments, is actually a problem that's been around for a long time, it's just being amplified by the emergence of new technologies.  Now, Steve, Brian Krebs had a very interesting week.



STEVE:  Well, Brian has been, of course, we talk about him often, he is a leading researcher whose sort of focus is security breaches in the private sector.  And he seems very fascinated by the whole underground hacker world.  And he's also very outspoken.  So he tends to be a frequent target of denial of service attacks.  So finally he sought greater protection and arranged a deal with Akamai, the well-known content delivery network, in order to essentially have them host his site.  They provided caching services.



The problem with a denial of service attack, which we've covered through the years, is a bandwidth concentration.  That is, you typically have widely scattered clients, and they're clients inasmuch as they are targeting a server, trying to flood that server.  And so the traffic bound for that single point of service, as it jumps from router to router, heading in toward that server, the traffic is aggregated into larger and larger streams until, at some point, the devices trying to feed that server are no longer able to handle just the raw brute force size of the traffic.



We've often talked about the way routers work.  We're talking about buffer delays and queuing packets and so forth.  So if you've got a router with the same speed links in and out, and you've got saturated links, like five saturated links coming in, all trying to route traffic through the sixth link, well, the math is simple.  You can't squeeze that 5x traffic through a 1x link.  There just isn't a way.  So the router understands this.  The technology is very robust.  Its buffer of packets overflows, and it starts dropping packets.  What legitimate users experience is an inability for their little microscopic, by comparison, trickle of packet traffic which is trying to access a site.  It just can't compete, statistically, with this flood of what looks like valid traffic, but is designed in order to flood these aggregation points.



What a content distribution network like Akamai uses is an interesting technology.  It's something we've never really talked about.  And that's anycast routing.  We've often talked about how the job of a router is, when a packet comes in, it looks at the destination IP.  And it's got a routing table which contains a series of masked IP addresses which are associated with different outgoing interfaces.  And so its job is to look at the incoming packet and figure out where to send it, that is, out of which interface that packet should then go.



Well, this is done in a routing table by matching the most specific route, meaning the route which matches the packet with as large a mask, that is, all the one bits coming down from the top, and with a small - a hostname.  Well, what that means is that, if it's configured correctly, you can put servers all over the Internet, that is, well, I'm sorry.  I interrupted myself.  All over the Internet with the same IP.  And that changes the topology.



Now, even if attackers all over the world are all attacking the same IP address, rather than it physically aggregating at a single location, all of these distributed routers have short routes to local Akamai servers, for example, using Akamai as an example.  And so they end up handling the traffic locally and prevent that single point of ultimate failure because no links these days are able to sustain the kind of denial of service attacks that we're seeing.



So I read a lot of the coverage in the news.  And people who support Brian and think he's doing a great job were upset that essentially this attack successfully knocked him off the 'Net. I think it was, like, last Thursday he announced that Akamai was suspending his service.  I guess, being neutral in this, I understand, certainly I understand Brian's disappointment that a huge sustained DDoS attack was able to push him off the 'Net.  But there is a non-zero cost that any bandwidth provider is bearing when they absorb that kind of traffic.



We've talked a lot in the past about peering agreements between top-tier providers.  And the agreement is that there will be pretty much a balance of traffic ingress and egress across peering relationships.  But an attack like this completely flips that.  And we've talked about, for example, the problems that Netflix has had because that's an example of a service in the evening that dominates Internet traffic in a decidedly one-way direction.



And I remember when I was setting up my relationship with Level 3 about a decade ago, they asked me, you know, what's the ratio of your inbound to outbound traffic?  Because they would like to have it be 50/50.  Well, no server is.  GRC has a lot more people pulling things out than it pulling things in.  In fact, there's like zero inbound except just the request traffic going in that generates much larger reply responses.



So anyway, what Brian ended up doing after being off the 'Net for a while is he managed to get Google's Project Shield to pick him up.  And this is something we talked about briefly, but there wasn't much - I guess we covered it when it was announced.  And it's Google's sort of, in the same way they do everything, they're exploring protecting sites that, under their own criteria, they think deserve to be protected, to be on the Internet.  For example, sometimes, as in the case with Brian, DDoS attacks are used to silence individuals or news organizations or dissidents or whomever who are taking a controversial position, or whom somebody somewhere wants to shut up.  And so Google has said, for free public news profile sites, we will experiment with this thing we call Project Shield.



So on their page they say:  "Advanced DDoS protection.  Project Shield is built on Google's infrastructure, creating a multilayer defense system to protect your site against DDoS attacks, including layer 3/4 and 7 attacks."  That is to say, 3 and 4 are just sort of raw brute-force bandwidth, just flooding attacks, and layer 7 is protocol level.  And, see, that's the problem with some of these later attacks is, in the old days, they just used to be SYN floods.  And the infrastructure got strengthened, so it got smarter about allowing endless numbers of SYN packets, that's S-Y-N, short for synchronized, the first packet in a TCP connection setup.



So what's happened is attacks have - there are still layer 3 and 4 attacks going on.  But layer 7 means this is like just a valid HTTP query asking for content.  And if enough devices scattered around the Internet ask for a server's content, making each of them a valid request, once again, you get just too much bandwidth.  In this case, the incoming bandwidth probably wouldn't have a problem, but there wouldn't be enough outgoing response bandwidth that allowed everybody to get their answer.  And so, like, 99.999% of the queries would be bogus.  And so a little 0.0001% query has almost no chance of getting a page pulled up.  So that's a different approach to the denial of service attack issue.



FR. ROBERT:  You know, we've had people on from CloudFlare and AlienVault, even Akamai, come onto This Week in Enterprise Tech.  And one of the questions that they get most often is why does the DoS attack still work?  Why does DDoS still work?  I mean, it was one of the first that was popularized.  It was the first to hit the mainstream consciousness.  Shouldn't we have solved it by now?  And they all have the same answer, which is, well, the problem is, it's not really an attack.  It's not an exploit.  All it is...



STEVE:  It's overload.



FR. ROBERT:  It's just an overload.  It's legitimate traffic that you're just ramping up.  And in this particular case they were able to use a lot of compromised edge devices that were able to send legitimate traffic from multiple IPs.  So there was no blocking upstream.



STEVE:  Correct.



FR. ROBERT:  Which is what we hear sometimes when you have an event that's under attack.



STEVE:  Correct.  Now, there are sort of two issues here, I think.  That is, in the press, the press has enjoyed jumping on the whole IoT problem.  And we're already getting new acronyms on this podcast for various issues of Internet of Things problems.  But there's another problem.  And I think it's the superset of the IoT problem.  That is, if you had a houseful of insecure IoT devices connected by a modem to the Internet, 1200 baud or 9600 baud, well, evil as they might be, they couldn't do any damage.



The other problem is, the related problem, the enabling problem, is consumer bandwidth is skyrocketing.  Until I lost my pair of T1s, where I was limping along at 3.4Mb, I don't know how I survived now, I switched to a cable modem.  Now I've got 300 downstream and 50Mb upstream.  I mean, one individual, one entity has that kind of bandwidth.  And of course we're seeing this escalation of bandwidth as consumers are demanding greater levels of connectivity in order to support the kinds of services we now want.  But with that comes the problem that then those individual endpoints are individually far more capable of participating in devastating DDoS attacks.



So, yes, them being distributed is important.  Them having easily compromisable devices is important.  But ultimately, if those things can't talk with high bandwidth to the Internet, that doesn't do them any good as attacking components.  Well, that problem's been solved because all of our consumer bandwidth is just going up as fast as it can grow.



FR. ROBERT:  You know, Steve, also the attackers are getting far more sophisticated in terms of how they hide their attacks.  It used to be when you owned a device, all you cared was that you had root access.  Now you can make that device do anything you wanted it to.  Now they realize, no, I want to own a device, and I want it to stay owned for as long as possible.  So they will not max out an outgoing connection.  They will not max out a device so that it stops responding to its legitimate purpose.



In other words, they want the person who buys the X label consumer Internet of Things security camera to be owned, and not even notice that, yeah, a little bit of your upstream seems to be leaking out every month.  And that's really what's enabled this because if you get 1,000, 10,000, 100,000 of those devices, there is no mitigation service on the planet that can stop that.



STEVE:  Well, and I don't know how much our listeners look at their own traffic.  I have a cute little chart which monitors the SNMP counters in my pfSense router.  And it turns out many routers offer SNMP, Simple Network Management Protocol, that allows you to watch.  When, I mean, I have got multiple iPads.  I've got, yeah, you know, I've got a couple TiVos and computers that are on all the time.  Point is, there is constant activity.  This is like, my network, even when nothing appears to be going on, it's, I mean, I'm looking at my switch and router lights.  They're never not flickering.  They're just flashing all the time.



So exactly as you say, Father, if you add a few light bulbs, IoT light bulbs, or a couple cameras, how would you even know?  As you say, it's able to hide in the noise.  And unfortunately, we all now have very noisy networks.  And I know that some people are like, okay, I'm going to figure out what all of these streams are.  Well, if you don't have a life, okay, go for it.  But, I mean, some of this stuff is just unknowable.  It's going off to random IPs.  And it's like, well, I don't know where it went or what's in there.  And of course now it's encrypted, more and more, so you can't even see what's going on.



FR. ROBERT:  You know, I've always suggested that people, I mean, because Wireshark is free, and you can get a gigabit tap for relatively little, or use a hub, if you can find one on eBay and drop [crosstalk].



STEVE:  Or just use port mirroring.



FR. ROBERT:  Or use port mirroring if you've got a smart switch.  And I just tell them, watch your traffic for 24 hours.  Just collect packets for 24 hours when nothing is happening, when you're gone on vacation.  And you will be surprised how many packets leave your network.  And unfortunately [sic] a lot of that is not malicious; a lot of that is just housecleaning that the various devices on your network will do.  But as you mentioned, that's a noise floor.  And so unless something goes above that noise floor, my tools are not sensitive enough to know, hey, you know what, this one device, it keeps beaconing out to this IRC channel, and then it does stuff.  And it's not smart enough to realize, oh, that's command and control.  I should probably shut that down.



STEVE:  Right.



FR. ROBERT:  And they'll never know.  Those devices will always be owned.  Those devices will always be compromised, as long as the people who control those botnets don't do something really stupid like max out their attack power.



STEVE:  Yeah.  And so you're right.  These are, while they're valuable for attackers to have, they don't want to lose them.  And they're so easy to get now, that is, the fruit is so low-hanging, that all they have to do is generate a trickle out of each of their 10,000 webcams, and that gets the job done at the other end, unfortunately.



FR. ROBERT:  Yeah, yeah.  A fun little attachment to this.  I did manage to get a visit to one of these DDoS protection outfits, one of their datacenters down here in Northern California.  And it's actually, it's a wonderful, wonderful thing to see how they do it, how they use anycast, which by the way, is anycast part of the original Border Gateway Protocol specification?  Or was that tacked on later on?



STEVE:  Oh, I was confusing it with CIDR.  I know that the addition of CIDR came later because they wanted to create more networks, instead of just having class A, B, and C.  I don't know whether it was part of 1.0.  My guess would be it was not because it's not the way the Internet was originally set up.  As we know, the Internet purists don't like NAT, the idea that we're going to have a single point that represents multiple devices sharing an IP.  The Internet purists say no, that is breaking the rules.  We designed this network so that every device had its own IP.  And of course IPv6 will allow that to happen once again because finally we have enough bits.



But so my guess would be that something like anycast was an extension added later, when the need grew which didn't initially exist.  Because it doesn't feel like this kind of addition to BGP would have been - there wouldn't have just been a reason for it, day one.



FR. ROBERT:  Right.  And so I use anycast if I'm going from outside in; and I would use VRRP, the Virtual Router Redundancy Protocol, on my inside to give my clients a redundant gateway.  That actually makes sense.  We've actually got a good comment in the chatroom from [indiscernible] who says, "So now even our dumb networks have to be secure?  What's next?"  Oh, he's joking, but it is actually a good point, which is in the old days, when you were you talking about when we were still on dialup modems - in fact I remember when I first got my Practical Peripherals 14.4, it was this little white box with an LCD screen in the front.  Oh, my gosh, it was heaven.  It was so fast.



STEVE:  And it was also flat so that the telephone could sit on top of it.



FR. ROBERT:  It had to because I actually had the one that still had the little dial thing.  I had to wire the thing in myself.  But our dumb networks, way back when, they didn't have the bandwidth to become a nuisance.  Whereas today my home connection has more power than my corporate connection did 15 years ago.  I've got more bandwidth.  So my dumb network is suddenly a bigger threat.  It's like saying, well, the little kid with the BB gun can't do much, but now we're going to give him a bazooka.  That's where we are.



STEVE:  Yeah.  Exactly.



FR. ROBERT:  All right.  Let's get away from bazooka and DDoS.  We understand that this is a problem.  We understand that the ISPs are dreading the day when they start to see commonplace 1Tbps attacks, which is coming.



STEVE:  Yeah.  And I don't see any mitigation unless we, I mean, we sort of talked about this last week.  And I did get a lot of feedback from our listeners when I mentioned that the only thing I could see, if it was not legal to allow, or ethical to allow infected machines to be tampered with, then to hold ISPs responsible and disconnect them from the Internet.  A lot of people like the idea.  Some people said, eh, you know, ISPs are far from perfect.  I'm not sure - in fact, one person sent me his own story, where Comcast had been doing that a few years ago, and he got disconnected, though he was absolutely sure that he was not at fault.  They just messed up their detection algorithm one way or the other.



So the only thing I can see is that, somehow, these attacks are raising the visibility, and we're getting more buzz about needing a solution.  Problem is, we're steeped in this technology.  And if you can make valid, just too many valid queries, then filtering those really becomes a challenge.  The only thing I could imagine would be much more caching so that, for example, the queries being made would end up hitting the cache and not go any further.  But then you just do cache busting.  You change the URL a little bit.  The cache doesn't know if it's valid or not.  The query has to go through in order to see, well, maybe it is valid, and you're back there again.



So, I mean, from everything I've seen, anything someone can propose, we've got, you know, there is an attackable workaround.  And the reason, of course, going back to first principles, is it wasn't designed to be resilient against attacks.  It was designed when universities and major businesses were connected to this experimental network, and everyone was amazed it worked at all, rather than, okay, we're designing something for a 50-year future horizon where the world is unrecognizable from what it is today.  Well, that wasn't what they were trying to do.  They were just trying to say, hey, can we send a packet from Northern California to Southern California?  And they were shocked when it worked.  So don't...



FR. ROBERT:  That's actually the source of most of our exploits these days, which is something that just worked, and they never thought that it would be misused.



STEVE:  Right.



FR. ROBERT:  We trust, you know what, security folk, I mean, networking folk, by nature, before we got into all the security stuff, we were trusting folk.  And now we've seen the error of our ways.



STEVE:  Yeah.



FR. ROBERT:  Steve, let's get away from massive DDoS attacks because I want to go back to a good old-fashioned cluster breach.



STEVE:  Old-school security breach.



FR. ROBERT:  Old-school security breach.  This is just someone let everything out.  And, yeah, we've heard about a lot of breaches over the past couple of years.  But this one is of note, not just because of size, but also because of the circumstances behind the disclosure of this breach.  Of course, this is [crosstalk].



STEVE:  Well, yes.  So, and I'm really not - I'm not interested in the politics.  The problem with that is that there's so much subject to interpretation.  Just so people know what that is, the argument is that executives at Yahoo!, Marissa and company, were aware of this breach for as much as two years and didn't talk about it publicly.  So of course that's really misbehavior.  When we talk about problems that arise, and I don't mean to use LastPass as anything but a good example because mistakes can happen.  There was a strange problem with, I think it was just Firefox browsers with the way their extension interacted with something.  They had it fixed before the person - it was Tavis Ormandy who found the problem, and he was creating a timeline for, like, managing this problem.  And it was fixed before he had posted the timeline.



So that's what you want.  We all understand that everyone can have a problem.  The question is how quickly and responsibly do you deal with it.  That may be a softer standard than some people would like.  People would like no problems ever.  But we can't do that.  So the best we can do is immediately remediate by, for example, informing those who might be affected.  In this case, as many as 500 million Yahoo! accounts were breached sometime in the past, and they didn't tell anybody.



Now, the part that I found interesting was a little bit of the technical details because the good news was that Yahoo! has been using a very strong password-based key derivation function known as bcrypt, which is very difficult to accelerate and speed up, by design.  It was designed for this purpose, so that it would be a memory hard problem that was resistant and resilient against brute force attacks.  The bad news is that, if you parse Yahoo's announcement, it suggests that most - but on the other hand, these are people who didn't tell us for two years, so I'm not sure that their adjectives should be believed completely - but not all of their passwords were hashed with bcrypt.  We don't know how many passwords were hashed with not bcrypt.  And we don't know what not bcrypt they were using.  That is, was it MD5?  What did they obsolete and strengthen?  The good news is they did strengthen something.  The bad news is we don't know.



Now, we've seen, and we've covered in the past, instances where a company exactly with Yahoo's profile implemented stronger password-based key derivation; but, for the sake of backward compatibility, left the old hashes there, too.  Well, okay.  So as users signed in, they would migrate the old hash, they would verify with the old hash, and then they would rehash with the new stronger algorithm.  What they should do is then delete the old hash.  We know that there have been cases where that was not done.  But that's what you have to do in order to evolve from an old hashing scheme to a new one.  That is, there needs to be a period of overlap.



And because the whole nature of hashing is that you cannot, like, on the server side, Yahoo! can't simply change the MD5, if that's what it was, to a bcrypt.  They have to wait for that user to log back into their Yahoo! account.  And that's the other thing, too.  I mean, we don't even know how many of these were not just throwaway because Yahoo! is the classic, oh my god, I want to post something to this blog.  Must I create an account?  Well, I'm not giving them my real email.  So you just get a throwaway account.  Yahoo! has been a great source of those.



So the idea being, though, that in order to advance the hash, they have to wait for somebody whose account is currently weakly hashed to provide the plaintext password to them.  They then hash it with the old algorithm to verify that that's a proper login.  Then they take the same plaintext and rehash it with the new one and thereby upgrade.  So again, it's frustrating that there's so much still not known.  So the takeaway for everyone is the greatest danger would be probably that you've had a Yahoo! email account for a long time, like ever.  Did you ever make one?  And did you ever reuse your password?



And unfortunately, everyone used to.  Monkey123 was popular for a reason.  And so if it's both old, it is probably the password, like what used to be your password, "Oh, this is my password, and I use it everywhere I go."  It's like, well, we've known for a long time you can't do that.  But if there's any other instance where you may have reused that password, that's the vulnerability because, from this breach of personal information, it's probable that, from what they said, a percentage of those accounts were weakly hashed.  And if those were hashed with a weak algorithm, MD5 for example - and Yahoo's been around long enough, it probably was once MD5 - then if you had reuse, that's probably where you're vulnerable.  And so you definitely want to change the passwords on any accounts, any non-Yahoo accounts that might possibly have ever shared it.



FR. ROBERT:  You know, Steve, I'm like you.  My Yahoo! accounts were always my throwaway accounts.



STEVE:  Yeah.



FR. ROBERT:  They were the ones that I had just because I wanted a place for junk to go.  And I have five of them, and none of them have been checked within the last seven years, would be my guess.  But I went back in, and I changed all the passwords.  When I was at DEF CON, though, there was a very nice gentleman who was explaining to me that he specialized in looking for those throwaway accounts because, he says, it's got a couple of points that make it very dangerous.  First, throwaway accounts typically don't have really strong passwords because that's something that someone wants to remember.  So it is a reused password.  Secondly, throwaway accounts, because they are discounted as to their importance, people forget...



STEVE:  [Crosstalk] passwords?



FR. ROBERT:  Well, people forget what services they had attached to that account.



STEVE:  Ah.



FR. ROBERT:  So if I sign up for a service with a throwaway account, and then I just forget about the throwaway account, that email's probably still in there.  So they'll know what services they can get into by requesting a password reset, and it will go back to the throwaway account.  And it was fascinating.  I talked to this guy for about 45 minutes, and he was telling me about all the different ways that he could use what most people consider digital refuse to ultimately get into that top layer of accounts, the stuff that was actually still active.  



STEVE:  Well, and I did see one interesting piece of advice that I appreciated regarding this.  And that was don't retain old email only because you can.  Following on from your example, Padre, it is important to recognize that those confirmation emails and so forth, that is a rich repository of your history which is probably not entirely obsolete.  Probably not entirely useless.  So the fact that these gargantuan email services allow you the luxury of never having to permanently delete something, that's, I mean, that's a mixed blessing.  It can be useful, but it can also bite you.



We've talked about, I want to say Mail Home.  MailStore Home is my favorite little local archiver.  And it's what I do for all of my various GRC-based accounts and the other stuff I'm doing, is it's a beautiful indexed database.  And so I run it periodically.  It sucks down my email and indexes it and archives it and makes it searchable here.  So I still have all the benefit of everything being available, yet not the liability of that everything being out in the cloud.  And here's a classic, perfect example of why that's not safe.  So if you've got those Yahoo! accounts with lots of old email sitting in them, somebody who can get in there can learn more about you than you would like them to.



FR. ROBERT:  Right.  That might actually be an interesting exercise for our audience, to look through their throwaway accounts to find out what's been left in the deleted items folder, or what's been left in those folders that you filed away on Yahoo!.  See how many other accounts those can actually lead into because I'm betting there are quite a few.  In fact, on mine I realized that one of my very first throwaway Yahoo! accounts I used to verify a Google account because Google originally, way back when, required another email address for you to be able to establish the account.  And so my Yahoo! account had the information for the Google account.  The Google account actually had the information for an Exchange account.  And then the Exchange account led into a folder that could give you access to my password hash.  Which I was looking at it, going, okay, that's convoluted, and I know where those are.  But still, that's way more information than I thought I was giving away.



STEVE:  Well, and we're not good at saying "what if."  As we've talked about, it's instructive to say, although a little dark, perhaps, to say, what if I die in the next five minutes?  Literally, like, what if I die?  Can my friends and family get to the things that they may need to?  That is, planning ahead.  Similarly, you challenge yourself by looking at your email berg and say, what if a bad guy got this?  I mean, put yourself in that position.  Browse through that.  What if this was in the hands of someone malicious?  What are the consequences?  And again, just exactly as you were giving an example of, it's potentially frightening.



FR. ROBERT:  And I think you're right, we just - we don't like to think about that.  Or maybe it's not even that we don't like to think about that.  We can't think of that.  We just - we're not built to think of worst-case scenario.  Go figure.  Steve, is it just the standard mitigation practices that we're talking about here?  We've got people in the chatroom saying, well, okay, if I change my password, if I use a strong password, is that enough?  Or do I consider my accounts dead now?



STEVE:  I guess, okay, there are several ways to look at this.  One is how do you feel about Yahoo!?  There are alternatives to  Yahoo!.  So does their behavior inspire confidence in their future custody of any of your email?



FR. ROBERT:  And that answer should be no.



STEVE:  Yeah.  It really should be no.



FR. ROBERT:  If it took them two years to tell me about a massive breach that they've known about for at least that long, then no.  I mean, I can't actually - there is no way to delete the accounts.  You can empty them out, but they stay there, which is wonderful.



STEVE:  Yeah.  So, okay.  So to take those accounts then out of service, you empty them all out as much as you possibly can.  Then you change their passwords to something insane that you deliberately don't write down, and you will never be able to get back in there again.  And you're not going to have a problem with sharing your password.  Basically you're saying, Yahoo!, no more.  I mean, the reason LastPass still has my confidence is the way they respond to any problems found.  That's the flipside of Yahoo!, where I'm proud to say I've never had an email account because it just always seemed a little too strange to me.  I mean, I just never took them seriously.  So, but I also had the advantage of my own domain and email server, so there wasn't much pressure on me to go looking for other solutions.



But still, yeah, I think you're right, Padre.  I think that no one - maybe there's some reason you must keep your Yahoo! email.  In that case, yes, certainly change the password.  If you haven't logged in for a long time, knowing what little we know, which is distressingly little because they're just not being as forthcoming even now as they should be, logging in hopefully promotes you to a stronger hash.  And at the same time then change it to a state-of-the-art, 20-character, mixed-character-class password, managed by a password manager, and you're doing everything you can.  That and maybe just sweep out all of the debris that Yahoo! has been holding for you because other people can get to it, potentially.



FR. ROBERT:  Yeah, we've got - the chatroom is starting up a micro flare here right now because of people saying, look, I use Flickr.  And we've got PC Guy who is saying, "Yahoo's not just email, people."  And I get that.  But I think you're dead-on, Steve, which is every company will suffer a breach.  If you're on the Internet, at some point, something will leak that you don't want to leak.  The question is how do you respond to it?  And if a company's willing to be 100% transparent, as soon as they know that there's a breach, to let us know, to let us know that we need to change our authentication credentials and to keep us up to date about what was taken and what was not, then I'm willing to stick with them.  I'm willing to say, okay, yeah, that was a mess-up.  But you've learned, and you're going to do better in the future.  There's nothing about the way that Yahoo! handled this that makes me want to continue using their services because I'm just thinking...



STEVE:  And not even providing full disclosure.



FR. ROBERT:  Precisely.  Yup.



STEVE:  Even now not telling us what we need in order to make a more informed decision.  That's what we would want, how to make the best decision.  Well, we have to have information, and there's still, oh, well, you know, don't worry about the man behind the curtain.



FR. ROBERT:  Because the man behind the curtain has your password.  Right.  Steve, it's not all DDoSes and breaches.  There's a little mischief going on in the latest version of iOS.



STEVE:  So, yeah.  We've discussed ElcomSoft a number of times in the past.  They're a relatively well-known security firm who sells iPhone-cracking commercial software.  So a security researcher at ElcomSoft, Oleg Afonin, he discovered a flaw in the password hashing used to protect iOS 10's backups.  And I would love to know what's really going on here, and I'll explain what makes me so curious.  But what he discovered is that iOS 10's backups, that is, the brute-forcing of the password - we've just been talking about password-based key derivation function, where you deliberately use a technology to make them slow.  He realized that, with moving from iOS 9 to iOS 10, it was 2500 times faster, which is to say easier, to brute-force a local iOS 10 backup than it had been under iOS 9.



Now, unfortunately, because of the nature of his commercial enterprise, he irresponsibly disclosed his discovery publicly, without first notifying Apple.  They immediately did get in touch with him and said, "What?  What?"  And then he told them what he knew.  But the cat was out of the bag first.



So here's what he wrote.  And I'm quoting it because I don't want to paraphrase this because what he said is really interesting.  He said:  "When working on an iOS 10 update for ElcomSoft's Phone Breaker" - one of their products - "we discovered an alternative password verification mechanism added to iOS 10 backups.  We looked into it and found out that the new mechanism skips certain security checks, allowing us to try passwords approximately 2,500 times faster compared to the old mechanism used in iOS 9 and previous."



FR. ROBERT:  Wow.



STEVE:  "This new attack vector is specific to password-protected local backups produced by iOS 10 devices.  The attack itself is only available for iOS 10 backups.  Interestingly," he writes, "the 'new' password verification method exists in parallel" - this is why I would love to know what's really going on - "exists in parallel with the 'old' method, which continues to work with the same slow speed as before."  So, okay.  What was Apple thinking?



So continuing:  "By exploiting the new password verification mechanism, we were able to support it in our latest update, ElcomSoft Phone Breaker 6.10.  Since this is all too new, there is no GPU acceleration support (yet) for the new attack.  However, even without GPU acceleration, the new method works 40 times faster compared to the old method with GPU acceleration.  This," they write, "is extra-troublesome" - and here's another juicy nugget - "because decrypting a backup is currently the only way of cracking modern non-jailbroken phones.  And even a jailbreak will not expose the Keychain's protections, but decrypting a backup will.  So within the iPhone cracking/break-in community, backup encryption is the golden goose."



And then he provides in his blog posting a little table showing under iOS 9, CPU only, using an Intel i5, they can do 2,400 passwords per second brute force.  Also iOS 9, but adding GPU acceleration, in this case an NVIDIA GTX 1080, that 2,400 jumps to 150,000 passwords per second.  And now, okay, so iOS 9 with state-of-the-art GPU acceleration, 150,000 password guesses per second brute-forcing, cracking the backup password encryption.



FR. ROBERT:  That's pretty good, 150,000 per second, yeah.



STEVE:  Now we move to iOS 10 with just CPU, that is, they've weakened it so much that, back to that Intel i5 that was only able to do 2,400 passwords per second on iOS 9, six million passwords per second.



FR. ROBERT:  Holy...



STEVE:  Just with the i5.  So if we assume this scales linearly, you know, look at the 2,400 to 150,000.  What is that, about 70 to one?  So that probably puts us at, what, 4.2 billion passwords per second.  So pretty much the entire IP space of the Internet per second you could do brute-forcing under iOS 10 with GPU.



FR. ROBERT:  Okay.  So if I understand it, the original, the hard encryption, along with every guess, it was a little bit of work that your system had to do.  It actually basically had to do some math.  Are you saying that they took that part out in the backup?  You no longer have to do the math? You can just brute-force the guesses?



STEVE:  Well, he's being deliberately obscure, and this hasn't been published because Apple's - he says, you know, he wants to sell his software as much as he can before Apple fixes this.  And they're running around frantically in Cupertino right now, saying, "Oh, shoot," or worse.  So all he says is certain security tests were bypassed.  But what's curious is that what this says is, I mean, if we take what he wrote, and I'm sure it's accurate, exactly as written, that for some reason they're doing both.  Now, their reasons for both, we were just talking about the notion, for example, of Yahoo! moving from an old hash to a new hash.  So maybe they thought this was better, but they broke it.  Or I don't know.  But somehow the new one is far weaker.



So any iOS 10 backup is apparently dual-hashed.  The password is double-hashed with the old algorithm.  And the new algorithm, normally it's new and improved.  In this case it's new and catastrophic.  But the fact is you don't need to worry about the slow old one because you've got a much easier fast new one that you can use to do your brute-force attacking.  And both of them are hashing the same backup password.  So either one, the fastest one to finish gives you what you want.  And in this case it's the new one which would finish much quicker.



FR. ROBERT:  Wow.



STEVE:  It's like, again, there's a mystery here.  We don't have the details.  Maybe we'll get them someday when someone reverse-engineers this, figures out what's going on.  And we know that Apple is not big on telling us in detail about their mistakes.  They just say, "There's a new 10.0.3.  Please download it immediately."



FR. ROBERT:  To their credit, though, Apple is - they've acknowledged, like, okay, yeah, this was a mistake.



STEVE:  Yes.



FR. ROBERT:  This is something we're going to fix. 



STEVE:  They did immediately acknowledge it, yeah.



FR. ROBERT:  Yeah.  If it had been another company, they might say, well, we'll fix it in two years because we don't think anything's going to happen bad between now and then.



STEVE:  Well, and so what this does mean, too, is that any local backups made by this iOS 10, those need to be considered dangerous.  That is, that backup needs to be destroyed, like maybe immediately, and then just refrain from backing up locally until you've got 10.0.3 or whichever update fixes it.  I think we're at .2 right now.  So, yeah, maybe .3.  But you want to make sure that that backup is destroyed because it's a statically sitting, brute-forceable complete image of your phone which significantly also contains the Keychain.  And if you crack the backup, you crack the Keychain, which even a jailbreak won't give you.  And then you've got literally the keys to the kingdom.  So any backups, any local backups made under iOS 10.2, well, 10.0 to 10.2, need to be considered a ticking timebomb.  You want to make sure those don't persist.



FR. ROBERT:  Right.  And even after you update your software, you really should delete those old backups because they will still sit there.



STEVE:  Exactly.



FR. ROBERT:  Especially if they get moved over to, say, a time machine.  Yay.  All right.  More iPhone news because it's not just about really fast hashing here.



STEVE:  Well, so I love this one because the people covering the story picked up on the fact that Luca Todesco is a teenager.  And so the headlines were how quickly he did this, apparently in less than a day.  And so I could sort of imagine the conversation in the evening in his household, where his parents say, "Now, Luca, you can crack your new iPhone 7 after you've finished your homework."  And he says, "But Mom, a new crack is worth up to $200,000."  And his parents say, "Well, yeah, that's nice, dear.  But geography is important, too.  You need to know where Aleppo is if you're going to be President someday."



So anyway, the story here is that, within 24 hours of obtaining his new iPhone 7, a well-known teenage hacker who has successfully - he's got a reputation in the hacker community, which is why everyone believes him.  He's not published details.  He's just - he's achieved it.  He says he wants to polish it and do a better job with handling all the details of the attack.  There was a classic one years ago where you could simply go to a web page, and the attack was entirely supported by Safari.  So a web server was able to deliver payload that would, just visiting that page, would jailbreak the phone.  I don't know that this one can be reduced to that, but that was referred to in some of the coverage here, where he was saying, you know, "I just - I want to clean it up and polish it.  Yes, I got my 7 jailbroken."



And what's interesting is that he wants a jailbroken phone, not to sell the exploit or to do evil, but because he is truly interested in poking around.  He is a teenage security researcher.  And it's very valuable for him to have root on his phone.  In fact, in his little video that he produces he brings up a root console which he's then able to use to poke around.  So he's annoyed that Apple won't give developers an official means for having that level of access to their phone.  So he gets it for himself after dinner, and hopefully after doing his homework, and then plays with hacking his phone after school.



FR. ROBERT:  That's not a bad hobby, a hobby that gets an extra $200,000.



STEVE:  Well, this is the kind of kid you want to hire.



FR. ROBERT:  Yeah; right?



STEVE:  Absolutely.  Somebody who's actually there, really reverse-engineering and digging in.  I mean, I have no doubt that Luca knows his stuff.  And I don't have any doubt that he'll have no problem getting a job.



FR. ROBERT:  Right, right.  And there actually is a little bit of a tradition of doing the right thing that we've seen the last few years.  You may remember Zimperium X.  They're the ones who found the Stagefright bug.



STEVE:  Yup.



FR. ROBERT:  And they could have sold that for seven figures.  They really - in fact, they could still be selling it because it's the gift that keeps on giving.  It's the exploit that will never be completely patched.  But they disclosed it responsibly to Google for $1,337.  And the only reason why they asked for that amount was so that it would spell out LEET. 



STEVE:  LEET, of course.



FR. ROBERT:  Yeah.  So some people really just want to be curious and then do the right thing.  And hopefully Luca's like that.



STEVE:  Yeah.



FR. ROBERT:  All right.  We've been hammering a lot on Apple.  And I think we need to do some fair time here and talk a little bit about Microsoft because...



STEVE:  Well, yeah.  And this isn't really a hammer.  This actually surprised people.  And I wanted to make sure that our listeners know.  I meant to look because I think we're right on the cusp of - let me refresh the Never10 download count.  Yes.  Oh, my god, no:  1,999,138 downloads.  I was thinking by podcast time we would have crossed two million.  It's slowed down to only 3,666 downloads per day.  So maybe by the end of the podcast we will have crossed two million downloads.  But of course it's been phenomenally popular because a lot of people said no, thank you, for whatever reason, I want to stay where I am.



Somewhat controversially, I never fought with the GWX, the Get Windows 10, because, I mean, and I looked at doing so.  And we've discussed this on the podcast in the past.  There is no API, no means for a program to say to its own system, where it's running, please don't download this update.  Because if you think about it, what would malware want to do?  So of course any malware would want to hook onto an API that gave it control over updates to Windows that might raise Windows' awareness of that malware.  So this is one area where Microsoft is adamant at minimizing programmatic control.



Well, so I hit that.  I understood why there wasn't an API.  And I said, okay, I can't prevent this Get Windows 10, which was being offered through the Windows Update, which was supposed to be security, controversially, but wasn't, as we all know.  So all I did was I leveraged the existing registry options, which at least told Windows, the GWX, don't do anything.  Just sit there and squat on some hard disk space, but don't even think about updating the system to Windows 10.  I don't want it.



So the good news is Microsoft just released a formal remover.  For anybody who wants to find it, there is a link in the show notes, or just look for, and here's the key number, it's 3184143.  So it's KB (Knowledge Base) KB3184143.  And they describe it as "This update removes the Get Windows 10 app and other software related to the Windows 10 free upgrade offer that expired on July 29, 2016.  For a complete list of the software removed by this Windows Update, see the update replacement information."  And on that page you'll find four links for Win7 and Win 8.1 in each of 32- and 64-bit system flavors.



And I just haven't had a chance, but I'm planning to post this on the Never10 page formally, just so that people who are, for whatever reason, wanting Never10 - actually, I've been told, because I've argued that it's not useful anymore, it's like, why are people still downloading it?  Well, one of the things it does is it intelligently finds the one update that fixes the Windows Update update update update update problem, and it solves it for you.  And so people are saying, yeah, we just use that now as the easier way to find that Windows Update update update update update.  And, like, okay.



But anyway, so I will update the page after the podcast today with this link there because anyone who wants Never10 certainly would be interested in just running this and finally removing that lingering debris which otherwise isn't removed.  And I don't know that this needs to be sought.  Actually, when I turned on my Win7 machine which I use for Skype, I did see that there were some updates.  I failed to see whether this one was being offered.  So maybe this is automatic.  People may want to go do it right now, when they hear this.  Or maybe Microsoft will ultimately be just pushing this out in the channel, and the GWX will just dissipate from their systems on its own, which would be the right thing to do.  So I imagine that's probably what they're doing.  But at this point it looks like it's a go-get-it if you really are serious.



FR. ROBERT:  By the way, Paul Thurrott did mention last week on Windows Weekly that you still can get the Windows 10 upgrade for free if you are on 7 or 8 or 8.1; that, even though the offer is expired, you can still do it.  I just rolled back all my machines from 10.  I had a few on 10.



STEVE:  I heard that yesterday.  You were talking about this.



FR. ROBERT:  Yeah.  It was...



STEVE:  Or I guess on Sunday.



FR. ROBERT:  I just, you know, it was one of these things where I was willing to put up with so many of the little quirks and foibles of Windows 10 because I actually do kind of like the OS.  A few things like the sticky borders and the fact that the registry edits don't work anymore really bugged me.  But what finally did it was the fact that I have active hours set on my machines so that it doesn't do any updates while I'm working.  And evidently this last big update ignored that.  Either Microsoft thought it was so important, or it was just not set up properly.  So this machine went into its update - no notification, no ability to cancel it, just a notice saying "Do not turn off your machine" - in the middle of a show.  It delayed the show by 30 minutes because this had all the tools that I needed to get to, and there was no way to stop it.  There was no way to cancel it.  And if you turn off a Windows machine in the middle of an upgrade, it will bork it.  



STEVE:  Thank god you're not a heart surgeon, Father.



FR. ROBERT:  I know; right?  But then I got home, and I thought, okay, maybe I messed up active hours.  Maybe that was me.  And so I checked, before I started that night's video editing, I checked my active hours, and they were still on.  Like, okay, I'm good.  And in the middle of the video edit it did the same thing.  It dropped into the update screen.  I'm looking at it, I'm screaming at it, going, "I didn't even save any of my work."  I lost an hour and a half of work because Windows just decided now is a good time for it to update.  And I'm thinking, you know what, it might be a bug, and I'm willing to say Microsoft could fix it.  But no.  If your OS thinks that it's more important than the work I'm doing on the OS, we can't use you.  I guess I'm a Never10 now.



STEVE:  Well, it'll stabilize.  I don't have any doubt that it'll stabilize.  We've seen this history of Microsoft going from good versions to bad versions.  Normally, it's an every other one.  I think they've got two turkeys in a row in this case.  The problem, of course, is now they're saying there's not going to be an 11.  We're just stuck with 10.  But the other new thing about this is that they're moving towards the software as a service, and this now becomes an OS as a service because, one way or the other, if people are not going to upgrade, they're going to figure out a way to turn us into revenue streams.  So I'm happy at 7.



FR. ROBERT:  Okay.  Let's propeller-head a little bit because OpenSSL has a little issue that I think our Security Now! folk need to know about.



STEVE:  So the problem with - okay.  The problem with OpenSSL is it is old, and that's not good.  And huge, and that's not good.  And bloated, and that's not good.  And the work product of countless, literally countless developers, that's not good.  And incredibly difficult to maintain.  The good news is, it is, for better or for worse, it is our industry's go-to de facto standard SSL/TLS and related privacy and encryption and authentication development and testing platform.  That's where these technologies go to get their first life.  And so it's sort of the galactic standard for everything, which again is a mixed blessing, which is why we're now seeing new packages.  Amazon has one, for example, because of AWS and everything that they're doing.  They just said, okay, we're not going to have that blob which is just - it's become unknowable on our servers.  And the other problem is, you know, every single feature, every possible widget and gizmo and gadget which anybody had an itch to scratch added to the formal specification, it's in OpenSSL.



So the good news is, if you want it, it is there.  The bad news is, if you don't want it, it is there.  And we know what a problem complexity is.  So this is yet another instance where, again, a mistake was found.  It was immediately fixed.  So again, the kind of response we want from an important mission-critical package like OpenSSL is what we got.  What we're seeing, though, is that its role is changing.  It's now the standard testing bench for new stuff where it makes sense to just graft another barnacle onto this thing in order to test the protocol.



But increasingly people are saying, eh, you know, we just don't need all of that for our web server, so we're going to do another one.  And we're going to, by only implementing the features that actually ended up being in use - that's the other thing that OpenSSL represents is the entire exploration through history of Internet connection privacy and authentication.  So obsolete stuff is there because everything is added in a forward and a backward compatible fashion.  So stuff that nobody uses any longer is there.  And I'm not saying it shouldn't be.  We need one of those.  I just don't think it ought to be used in production as much as it is.  But it's the default de facto standard still for the Internet because maybe we'll need to turn that switch on, or use that.



So in this case I talked a couple years ago in detail about certificate revocation.  One of the protocols that is really interesting, in fact, where I ended up coming down on the whole issue is stapling.  OCSP stapling is the solution.  The idea there is, okay, OCSP is the Online Certificate Status Protocol.  And it provides a means by which a web browser can, when it receives certificates from a server, can, in real-time, on the spot, query the issuing authority for the validity of that certificate.  So there are extra fields in the certificate providing the URL for that certificate's OCSP server.



The browser then gets it.  And if you've turned that on - and we've talked about this.  Firefox has supported it, and a lot of our listeners turned it on for a while.  Google had some problems, surprisingly, with their own OCSP servers not being reliable enough.  They just, they often didn't answer.  And that was one of the controversies was, well, if we don't get an affirmative yea or nay, what do we do?  And for the sake of user experience and the fact that OCSP servers weren't at that time, and maybe even now, reliable enough, it would be a fail open.  It would be, well, we couldn't get a "No, it's definitely bad."  So we're going to go ahead and accept it.



Okay.  Stapling solves this problem.  It is a beautiful solution.  I think it's where we're ultimately going to be.  And that is that the server that is issuing the certificates also provides a recent, a sufficiently recent OCSP status reply with the certificate.  So the website says, here's my identity and a recent revalidation of that assertion.



So the beauty is that changes the connectivity.  Instead of there being a triangle where your browser goes to the server, gets the certificate, then your browser goes to the CA and gets that, instead now we're reusing the existing connection.  And the server, the web server, notices that its OCSP validation is getting old, and what could that mean?  That could be minutes or hours or days.  But it's going to be a relatively short time because then it reaches out to the CA and updates and gets a new, timestamped, signed by the certificate authority, reassertion of its certificate's continued validity.



So that's the way the system works.  What this means in terms of implementation is that a browser which is configured for it is able to explicitly ask the server to provide a stapled OCSP status response.  And so what happened was, of course this all got implemented in OpenSSL.  That's where it first started breathing, and it has since.  Turns out there was a little mistake made in the code where - and I would call this a "classic edge case."  So it's on the server side.  A malicious client could leverage this edge case by causing, essentially - in fact, I'll read from the OpenSSL post:  "A malicious client can send an excessively large OCSP Status Request extension."  So that's an extension to the TLS protocol, some additional fields, that says I'm aware of OCSP stapling.  Please send it back to me if you can.



"If that client continually requests renegotiation, sending a large OCSP Status Request extension each time, then there will be an unbounded memory growth on the server.  This will eventually lead to a denial-of-service attack."  Now, that's not a DDoS.  That's a DoS.  And we'll clarify that in a second.  They continue, saying:  "...through memory exhaustion.  Servers with a default configuration are vulnerable, even if they do not support OCSP."  So the fact that they're using that version of OpenSSL that offers the feature, even if they don't turn it on, they can still be brought down.



So there's three different tracks of OpenSSL.  There's 1.1.0, which needs now to be updated - and that's, of course, 1.1 is the latest - needs to be updated to 1.1.0a.  Then there's 1.0.1, and those users need to go to 1.0.1u.  And 1.0.2, and those users need to go to 1.0.2i.  I get nightly security reports from my Unix machines, and they immediately informed me that there was a new version of OpenSSL available.  So it's been propagated.  It was immediately - and it was a trivial thing to fix.



So basically it was a memory leak where it was discovered that a client could deliberately cause OpenSSL to request blocks of memory over and over and over, never freeing previous blocks, by both leveraging this flaw in the OCSP handling, coupled with renegotiation of the connection.  So those two together sort of slipped by the original testers, and this got fixed.  So essentially what it does is the system just keeps giving the memory to OpenSSL, which is running with tremendous privileges in the system so that it'll just - that process bloats and bloats and bloats and bloats until memory requests start failing for other legitimate processes, and the so-called denial of service in this case is that the web server, which has grown to the entire size of the server's memory, no longer has any memory available to serve as additional requests.



FR. ROBERT:  The ever-expanding memory blob.



STEVE:  Exactly.  Yeah.  So it's not one of our horrible remote exploit, end-of-world meltdown problems.  But not good.  But immediately fixed.



FR. ROBERT:  Right, right.  Now, if you didn't do that, if you didn't always reserve that memory, you would run into Jelly Bean problems; right?  I mean, eventually, because you'd start releasing memory that still contained sensitive bits.



STEVE:  Well, but we don't really know what's in there.  For example, the OCSP, if it's just the OCSP response, that's public domain.  So it's an assertion signed with the certificate authority's public key.  So that's freely available.  I mean, any browser can ask for one from a certificate authority.  So if that's what is there, then it's just a mistake.  But maybe the information contains something sensitive.  But in this case it really doesn't matter.  It's going to bring the server down.  Somewhere in the renegotiation logic they forgot, when they allocated a new block of memory to service the renegotiated connection, there's just, like, one line of code missing, which was release the old connection's outstanding allocation.



So, you know, easy to do.  Mistakes happen.  And these guys did fix it as quickly as they could.  And again, I want to make sure people understand.  OpenSSL is the reference standard.  But due to all of its history, it's no longer really becoming what you want to use in a production environment.  You want to test new things there and then selectively move them maybe over to a much leaner armature that you'd then use for actual work, just because who knows what we haven't found?  That's the thing.  We continually find problems in it.  And it should be no surprise to anyone.  It's just too big.  It's too old.  It's too complicated.  And we've talked about the alternative TLS stacks, which are 1/200th the size.  I mean, it's hundreds of thousands of lines of code compared to 6,000.  It's like, okay.  If this 6,000-line system solution does everything we need, thank you.  We're done.



FR. ROBERT:  And speaking of done, let's move on a little bit because this next story is actually something that I'm very interested in because we've talked a lot about it over the last couple of weeks.  And that is, what do you do when a CA misbehaves?  Of course certificate authorities are the way that we learn how to trust on the Internet.  And of late we've seen some CAs do some very, very peculiar, if not downright malicious behavior.  Now, Steve, you know this.  You know that trying to revoke the authority of a CA is very difficult.  In fact, it's been almost impossible.  It's one of the biggest reasons why people are saying we need to move over to DNS DANE so that we can start doing self-issuance of certificates and just forget the CA system altogether.  But we've got sort of a good news/bad news thing with WoSign.  Can you tell me about that?



STEVE:  Yeah.  We talked about this in detail a couple of weeks ago.  And the framing of our discussion then was I wanted to, and did, share Mozilla's thought process, essentially, with our listeners because, exactly as you say, there is big financial impact when a major browser like Firefox or Chrome or IE or Edge decides to pull the plug on trust with a certificate authority.  Essentially, they're out of business because they're no longer - who's going to buy a cert from them when there's a competitive marketplace, and there are other certificate authorities which are trusted by all the browsers.  So it's game over.  So politically, from a bureaucratic standpoint, this has to be done carefully.



So a couple weeks ago we sort of went through phase one of that.  And what popped up, and I caught this in a post by someone who follows me, Vincent Lynch, who's very much involved in and follows the certificate authority industry very closely, he summed it up, saying Mozilla now believes that StartCom - and remember there's also this weird WoSign/StartCom connection, where we discovered that changing a post parameter at StartCom would cause it to issue a WoSign certificate.  So it's like, uh, what?  I mean, this is just all stinky.



So anyway, he said:  "Mozilla now believes that StartCom purposefully backdated an SHA-1 certificate for a payment processing company," in flagrant violation of the CA browser industry, the so-called CAB Forum, rules.  And so Vincent linked to today's update from Mozilla.  And again, this is all out in the open, open for public comment.  They don't want to hide anything because they recognized the consequences of them doing this are severe.  But if we don't hold certificate authorities accountable, then the system really collapses.



So Mozilla wrote:  "Today, Mozilla is publishing an additional document containing further research into the backdating of SHA-1 certificates, in violation of the CAB Forum Baseline Requirements, to avoid browser blocks."  Meaning that they now have clear evidence that WoSign backdated certificates.  Remember that there are "valid after" and "valid until" fields.  And no browser today will accept an SHA-1 signed certificate that appears to have been issued after the start of this year.  That is, with a valid after date in 2016.  So that can cause problems.  And we've talked about the problems that that can cause.  So you can imagine that there would be pressure to issue a certificate with a previous date.  And in this case it was December 20th, I think.  I remember it was like 10 days before the end of the year this certificate appeared.



So Mozilla continues, saying:  "It also contains" - that is, this write-up - "some conclusions we have drawn from the recent investigations and a proposal for discussion regarding the action that Mozilla's root program should take in response.  Taking into account all of the issues listed above, Mozilla's CA team has lost confidence in the ability of WoSign/StartCom to faithfully and competently discharge the functions of a CA. Therefore, we propose that, starting on a date to be determined in the near future, Mozilla products will no longer trust newly issued certificates issued by either of these two CA brands.  We plan to distrust only newly issued certificates to try and reduce the impact on web users, as both of these CA brands have substantial outstanding certificate corpuses."  And should that be corpi?  Anyway.



Okay.  So once again we see this careful, methodical march to removing trust.  And so the nice thing about, I mean, they're doing the right thing.  They're not saying we're going to retroactively distrust.  We're not going to yank the certificates, the roots out of our store.  Rather, we're going to add some code to see, if the certificate is otherwise valid, when was the valid-after date?  So essentially putting them out of business on Firefox, and other browsers will likely follow because, again, this is community connected so that they are no longer able to issue certificates in the future which will be trusted.



But that also protects the investments made by everyone who has an existing certificate.  And what that means is that, when it's time to renew, they will go somewhere else.  And Mozilla did say that maybe a year from now they will revisit this.  But just to remind people, it wasn't just this flaky website and this one backdated certificate.  When we covered this a couple weeks ago there were, like, six different separate isolated problems.  Among them, many certificates had been misissued.  And they didn't report that in their required auditing, and only revoked the ones that they were explicitly notified of they had to revoke, rather than, as they should have, going back through their own records and retrospectively revoking anything which they could determine had been misused and was subject to abuse.  They didn't do any of that.



So, I mean, goodbye.  I'm not going to miss them.  And again, well, you know, websites can just go get the certificate from someone else.  We have to hold certificate authorities accountable.  And so we're seeing played out here in public the necessary bureaucratic drama of creating a careful case and then ultimately saying, okay, we're sorry.



FR. ROBERT:  You know, Steve, I'm with you.  I think CAs absolutely need to be held accountable for what they do.  The question I would have, though, is looking into the future, how do you do that?  I mean, this is an isolated case.  And this took a while.  I mean, this company did a lot of really bad things before finally...



STEVE:  Yeah, over and over and over.



FR. ROBERT:  Over and over.  And they got little slaps on their - actually, not even slaps on the wrist, really, until finally there was enough oomph in the community saying, okay, we have to do something about this.  But you can't do that for every CA that goes off the reservation.  I mean, it just takes too long.  And in the interim you've got this massive security hole because the entities you're supposed to trust are not trustworthy.  And then I could see this evolving because we already know that there are, have been, a couple of CAs who have been in bed with nation-state level entities.



STEVE:  Yup.  Yup.



FR. ROBERT:  And I could see this becoming a cause to fracture the Internet, where you have nation-states saying, well, if you don't trust our CAs, we're not trusting your CAs.  And, I mean, unfortunately, that sounds childish, but that's not unheard of.  This sort of tit-for-tat happens all the time.



STEVE:  Yeah.



FR. ROBERT:  So is the only way out of this to move to DNSSEC and DNS DANE?



STEVE:  Ultimately, and we talked about this last week, everyone knows what a fan I am of DNSSEC.  And DANE is one of the many, many benefits that we will get once we have DNS secured throughout the entire system.  I wouldn't - I don't begrudge anybody, any entrepreneur, the opportunity of starting up a certificate authority.  But it's not as if the field is so rarefied that we need another one in order to, for example, bring the price down.  It's not like we're in a monopoly situation where everyone's having to get theirs from VeriSign, for example.  So it's like, I'm not going to miss them.  And they probably have loyal followers who are going to miss them.  But unfortunately the trust was misplaced.  And we have a system - and I agree with you, Father.  What you're basically saying is the system is based on trust, and it's not a strong enough assertion.



FR. ROBERT:  Right.



STEVE:  Trust is not strong enough.  And as you note, it's also not completely resilient in the face of fracturing, different types of fracturing of the Internet.  But today it's what we have.  And those guys can go away.  Their customers will simply move to one of the other 400 certificate authorities and I'm sure get the same kind of price that they would have from these guys.  So they had an opportunity to make some money.  They did for a while.  They weren't responsible.  And because this is entirely resting on trust and behavior, I mean, that's the obligation that comes with basically printing money.



The certificate authorities perform a very valuable service.  Everybody knows I'm a huge fan of DigiCert.  They are my CA.  I'm never moving away from them.  I am so happy with the job they do.  And they earn the money they're making.  But they're selling bits.  And it's like, wow, that's a great job if you can get it.  And so unfortunately WoSign just, you know, they blew their opportunity of selling bits for dollars.  It's like, okay, sorry.  With that printing money capability comes the obligation of printing it responsibly.



FR. ROBERT:  They killed the cow to have a steak, basically.  And actually I'd go one step further.  It's not just that the system is built on trust that may not be there.  Unfortunately for most of the world, the CA system is built on ignorance of the process.



STEVE:  Yes.  Yes.



FR. ROBERT:  You say "CA" to most people who don't watch Security Now! or the TWiT.tv network, and they'll just sort of glaze over and say, uh, I have a padlock in my browser.  That's okay; right?  And that's it.  That's the extent of their knowledge.



STEVE:  I will never forget the podcast, I don't know which number it was, but we're at 579 today.  But it was many years ago when, between podcasts, I had for some reason looked into the CA root in a Windows machine.  And I remember when there were 12 certificates...



FR. ROBERT:  Remember that.



STEVE:  ...in there.  I mean, VeriSign was there.  Global Trust was there.  And a couple other companies that sort of, I didn't know they were in the CA business.  But, I mean, you didn't have many more fingers than there were certificates in a Windows machine.  And one week, between podcasts, I looked in there, and the scroll thumb went [sound effect] down into this little bitty thing.  And I thought, what?  And I started dragging it down, and hundreds of trusted roots go by.  And with the next podcast I said, "Oh, my god, Leo, what has happened?"  And then we did a podcast talking about the consequence of this explosion of certificate authorities, that it is a Trust Everyone-based model.  And unfortunately, the more everyones you have, any single point of failure cripples the entire system.  So again, the only response to that is a zero-tolerance policy.



FR. ROBERT:  Zero tolerance and zero trust.  Is there another way to say zero trust?  Huh.  Trust very few people?  Trust just a few?  Maybe not.  We'll figure it out later on.  All right.  We do need to push on because we're not going to get to any Q&A in this Q&A.



STEVE:  No, we're not.  We will do that tomorrow for next week's podcast.



FR. ROBERT:  But we still do have something funnier.  We get to talk about BitTorrent Sync.  And this is one of the services that many members of the TWiT family were asking us to cover on Know How.  And it's interesting.  I used it once or twice.  It wasn't really my flavor anymore.  It was renamed.  Does that also mean that it's a new being?



STEVE:  Okay.  So, yeah, they renamed it Resilio, I guess as in resilience, Resilio, R-E-S-I-L-I-O.  So Resilio is the new name for BitTorrent Sync.  And from the first day of announcement, our listeners have said, "Oh, my god, Steve, what is it?  Give us an analysis, like you do when you have the information, so you can explain it to us and tell us we can use it because it looks wonderful."



And so I immediately got in contact with the BitTorrent PR guy.  And I said, "Hey, look, I'm not buying anything.  I know who BitTorrent is.  What I want is the whitepaper for the documentation."  And instead he said, "Oh, you know, we just put a brand new monument in the front of our building, and it's four inches marble, and it's a beautiful italic font."  And I said, "No, no, no, no, no.  What is the protocol?"  "Oh, well, you know, we've got this great team of blah blah blah blah."  I mean, and finally I told him, "Stop sending me your press releases.  All I want is the technology."  Never got it.  They published a non-whitepaper whitepaper about a year ago.  Still nothing.



Now they've done it again, which is what got it onto the show notes.  There's a whitepaper.  Actually it's not white.  It's fancy.  It's got marble italic font, just like the monument in front of the building.  They call it "Resilio Sync Security & Privacy Brief."  Notice it doesn't say "privacy specification."  The good news is it's not too brief.  So there is a huge demand for this podcast to say something about what used to be BitTorrent Sync and is now BitTorrent Resilio.  I think there's enough there for me to at least discuss what they're willing to say.



Again, that falls far short of, okay, here are the protocols.  For example, Telegram could say everything that these guys have said.  And from that it would look wonderful.  But when I actually saw the block diagram of the Telegram architecture, I said, "Holy crap, this is the biggest crock I have ever seen."  And not long afterwards the rest of the security community agreed.  And so the problem is, as we know, the devil is in the details.  And for whatever reason, they're not publishing it.  And the only reason I can imagine is competitive.  I don't think they think there's anything wrong.  But unfortunately, those who create it are not those who need to judge it.  And I imagine they don't want competition.  They don't want the compatible products to be created.



There was some effort a couple years ago at reverse-engineering it.  There's something called the Initial Protocol Specification, actually hosted in a forum on their site, dated summer, July of 2013, so three years back, where someone took some time to dig around and work on it.  I sort of thought more than that existed today, but I thought there was a working BitTorrent Sync-compatible implementation.  But just in looking briefly, I didn't see it anywhere.  But so I just wanted to put it on people's radar.  I will find some time, in a future podcast, before long, to dig into it.  And we will finally do a podcast, not on BitTorrent Sync because we waited long enough for it to become BitTorrent Resilio.  And I'll share what there is to share.



But I'm still annoyed because - and as you said, Padre, it's closed, and not your cup of tea.  Not mine, either.  There's something called Syncthing which a lot of people seem to be liking.  And I believe that's completely open.  And that's, I mean, that's what you want.  So if these guys got competition from a knowable open alternative, I can't think of anybody who would deserve it more. 



FR. ROBERT:  And the thing is not just that it's closed, it's that what they've opened, they've let us take tiny little peeks into how this handles encryption.  It's not impressive.



STEVE:  No.



FR. ROBERT:  It's not.  



STEVE:  Well, that's just - it's the PR guy.  Oh, yeah, well, you know, we've got military-grade encryption and John McAfee said it's wonderful.  Okay.



FR. ROBERT:  Let's see.  John McAfee was the man who invited me to come to a strip club for Black Hat at Vegas.



STEVE:  How well does he know you, Padre?



FR. ROBERT:  Well, no.  This was an invitation to all the journalists.  And who went?  Ian, Iain Thomson actually went.



STEVE:  Of course he did.



FR. ROBERT:  And he was asking me if I went.  I'm like, are you kidding me?  John McAfee asked me to come to a strip club.  I'm like, okay, this is like a red flag had a baby with warning tape.  Just no, you stay far, far away from that.  And it turned out, yeah, it was really that bad.  It was a really skeevy club.  I guess they're all kind of skeevy.  And he showed up, like, two hours late and then didn't want to talk about anything.  So, yay.



STEVE:  Well, and you know, Showtime has a documentary, produced it.  My TiVo sucked it in, and I keep forgetting that it's there.  But it was called, oh, shoot, it had a short name, and then "The Dangerous Life of John McAfee."  And so if anyone - I did tweet about it.  I think it aired for the first time on Saturday night on Showtime.  And so for what it's worth, I'm glad it came up because, if anyone's curious, it's a two-hour documentary.  John has said it's all lies, full of lies.  So it sounds like it was probably going to be fun.



FR. ROBERT:  I mean, yeah, love him or hate him, he's a very interesting person.



STEVE:  Yes.  He's entertaining.



FR. ROBERT:  He is entertaining.



STEVE:  I did want to correct the record, just for the sake of accuracy.  I misspoke last week when we were talking about OSes and routers by saying that pfSense and a Ubiquiti router were both FreeBSD based.  I know better.  Ubiquiti uses Debian.  We've talked about that in the past.  Someone said, "Uh, Steve, no."  And it's like, okay, you're right, sorry about that.  So I just wanted to close that dangling mistake.



FR. ROBERT:  Naturally, naturally.



STEVE:  Two bits of miscellany.  I did want to put also on people's radar a science fiction program on NBC beginning week after next, on October 3rd, called "Timeless."  Time travel.  I don't know much.  I'm not recommending it.  But for anybody, I mean, I'm going to record it and hope that it's engaging and fun.  Time travel is neat stuff.  I think the bad guy is the actor who played Luka on "E.R."  So, yeah, I'm dating myself.  But it just looked, you know, it's going to be made - it's a network show.  I'm sure it's not going to be deep sci-fi.  But it looks fun.  Apparently the plot is that a state-of-the-art time machine is stolen by this bad actor with the intent of going back in time and messing up the past.  So, but there's a prototype of it also.  And so the good guys use that and go chase them around.  So anyway, for what it's worth, it's called "Timeless."  I'm not vouching for it, but I wanted to make sure people knew about it.  Looks like some fun special effects and an interesting cast.



FR. ROBERT:  Yeah.  I want another time travel series because we haven't had many.  I mean, "Heroes" kind of had some time travel in it.  But before that it was "Seven Days," which I really enjoyed.  I was sad when they canceled it.  And before that there was "Timecop," which was what time travel would be if everything was really cheesy and hokey.



STEVE:  Oh, that was a classic movie.  I've seen it about three or four times.



FR. ROBERT:  Oh, but they turned it into a series.



STEVE:  Yeah.  And we all remember when Spock and Kirk and McCoy went back in time.  One of my favorite, you know, and we met Edith Keeler, who had her soup kitchen.



FR. ROBERT:  That was "City on the Edge of Forever"?



STEVE:  Yes.



FR. ROBERT:  That episode? 



STEVE:  Yeah.  And there was that time gate, that weird sort of organic-looking thing that - yeah.



FR. ROBERT:  And it was McCoy who went through.  And immediately as he went through they lost contact with the Enterprise because the Enterprise no longer existed, so they had to go back and fix the timeline.



STEVE:  Don't you hate when that happens?



FR. ROBERT:  I mean, seriously.  I can't tell you how many times that's happened.



STEVE:  Yeah.  And actually he mistakenly OD'd on cordrazine or something.  So he went out of his mind.  He went crazy.  He jumped through the portal.  And so then Spock and Kirk had to go back and rescue him.  Anyway, I'm sure everybody already knows about that particular episode.  It's one of the best.



FR. ROBERT:  Oh, by the way, the chatroom just called me out.  I just realized one of my favorite shows, "Dr. Who," is a time travel series.  So, yes, we do have one currently.  My bad.  Totally my bad.  Sorry about that.



STEVE:  And Padre, I meant to ask you this before, whether by any chance you're watching "The Strain."



FR. ROBERT:  I am not.



STEVE:  It's now in its third season.  It's on FX.  And I really like it.  As they say, there's no accounting for taste.  I'm not suggesting that everyone is going to love it.  But it holds up.  They've built a complete coherent mythology essentially around the vampire myth, but brought it into the present day with some useful acting, some fun writing.  And it's in its third season, and it's really good.  So I just...



FR. ROBERT:  Oh, and Guillermo Del Toro.  Okay, all right.  No, I'm in, I'm in.  I'm totally in.



STEVE:  So the first two seasons are available on Hulu and, hint, elsewhere.  I don't think anybody - now, again, it's not going to be everyone's cup of tea.  I get it.  But if you don't mind a little gore, but something really engaging, it's just, you know, a plane lands at the airport, and no one gets out.  And they wonder what's going on inside.  And the CDC is brought in.  So it's state of the art.  And I've noticed in this third season they recognize they have something good.  And so now we're getting - the writers are writing back in some of the older back story, which is equally good.  I've just - I'm impressed.



So FX has "The Americans," that I also really enjoy.  And it's going to start its fourth or fifth season.  And I only know about "The Strain" because they were advertising it during the breaks of "The Americans."  So I just wanted to put it, again, on our listeners' radar.



FR. ROBERT:  This might be something that I have to get onto my computer because I'll be taking a trip over to Rome.  And I'm actually responsible for some of the entertainment nights.  



STEVE:  Ohhh.



FR. ROBERT:  Maybe we can be in the Eternal City watching "The Strain."  I'm sure that will go over well.



STEVE:  Give it a try.  I would love to know what you think because it's - I really enjoy it.  I mean, it's just - it's well done.  And I like things that are well done.  And, oh, my god, that's an awkward segue to start talking about SpinRite.  But Anthony Cunningham sent me a long DM.  And he said:  "Hi, Steve.  As I listened to last week's Security Now!, Father Robert made a comment that I thought I might be able to help with, plus it would work as a SpinRite story.



"Close to the end of the podcast, he mentioned he wished you could get SpinRite to work on cell phones.  And I would like to note that that request might be possible already.  A previous SpinRite testimonial talked about using it on a virtual machine to do multiple runs at the same time.  At the time that got me to try it.  And what do you know, it worked.  I also used it on a live Linux USB distro that was at the time not working right, and it fixed that as well.  Recently the cell phone I use at work as my podcast streaming player was getting rather slow and laggy, so I thought, 'What the heck, I'll try SpinRite on it and see what happens.'



"Using VirtualBox on Linux, I plugged in the phone to the USB, had VirtualBox set it as a raw disk, spun up a VM with SpinRite, and pointed it at the cell phone.  SpinRite did its thing, and about an hour later it was done.  I unplugged the phone, rebooted it, and after that it was running faster and more stable than it had for over a year.  I thought to myself, this was great.  I'll try it on my Nexus 5 next.  But that, unfortunately, was a no go.  The phone must be able to be seen as a mass storage device in order to be used as a raw disk in VirtualBox, and for some reason the Nexus 5 will only read as a non-mass storage USB device.  I hope Father Robert can try this out and see if it helps."



So, Anthony, thanks for the great DM and another example of how SpinRite can be leveraged, in this instance in a VirtualBox, in order to run on a cell phone and fix it.



FR. ROBERT:  That is amazing.  I am trying that tonight on my OnePlus One because I know exactly what's going on.  Every once in a while it will just kind of hang.  And it's just the garbage collection has not been done properly over the course of the lifetime of this device.



STEVE:  Level 2. 



FR. ROBERT:  Yup, Level 2.  All right.  That's my task for tonight.  Actually I built a SpinRite-only machine a while back for Know How.  We never did the episode.  But it's sitting there.  It's like one of my break-in-case-of-emergency projects.  I've got six or seven in case I'm just really lazy one week, I can just [crosstalk].



STEVE:  Queued up, right.



FR. ROBERT:  But I made a tiny little machine that has just a hard drive docking station.  And it's got all the different formats.



STEVE:  Nice.



FR. ROBERT:  All the way from mSATA to the M.2 to SATA to the large version.  And so you just plug in the one you want, turn it on, and then walk away. 



STEVE:  Nice.



FR. ROBERT:  So I'll try that with this.  Who knows?  Maybe it will fix my OnePlus.



STEVE:  Cool.



FR. ROBERT:  Steve.



STEVE:  That's the podcast.



FR. ROBERT:  That is the podcast.  You know what, it is absolutely a pleasure.  I am so sorry to everyone who was hoping to hear the Q&A.  We will get to it next week, which is actually tomorrow.



STEVE:  Hey, what we promise is two hours of engaging content, whether it's sourced from our listeners or from the events of the week.  And in this case, now, as our listeners may or may not know, you're traveling, as you just mentioned, to Rome next week.  So you and I are recording next week's podcast tomorrow evening.  Which means there won't be a week's worth of news aggregated.  So I think it's very safe to say that next week's podcast, actually recorded not more than 24 hours from now, will be pretty much all user sourced content, and nothing that the industry has brought to us, because there won't have been any time.  As I said, we don't have a time machine.  So we'll have to work with what we've got.



FR. ROBERT:  Steve, I think that's the only way we're ever going to get to Q&A because any time I work with you, I just - I have way too much - I know, sometimes I know I'm like, you know what, just let Steve do it.  Let Steve do it.  And then I just want to get in there.  I just want to have so much fun.  Thank you for the knowledge you drop on us each and every single week.



STEVE:  Well, this was great, and it's a pleasure working with you.  And we'll do it in a little over a day for next week's Security Now!.  And if anybody is interested, if the change in schedule allows you to watch it live, we're recording at 7:30 Pacific time, so 10:30 p.m. Eastern, on Wednesday, that is, tomorrow.  And so if that allows you to watch it live, what is that, is it still live.twit.tv?



FR. ROBERT:  It is indeed.



STEVE:  Cool.



FR. ROBERT:  Of course, you know Steve Gibson.  He is the mastermind behind GRC.com, the creator of treasures, gems like ShieldsUP!, SpinRite, and of course SQRL.  And he's just - he's our Explainer in Chief.  He is the man that everyone at TWiT turns to for the latest and the greatest in security.  And, well, we couldn't do it without him.  Steve has audio versions and transcripts of the show at his site at GRC.com.  And you can also find the show wherever fine podcasts are aggregated, including at our show page at TWiT.tv/sn for Security Now!.



We do Security Now! every Tuesday at 13:00 Pacific, actually it's 13:30.  You can watch live at live.twit.tv or download episodes from TWiT.tv/sn.  You can also subscribe to the show to get it automatically downloaded to your device of choice in your format of choice, as well as downloading directly from the page.  We want to give you every chance possible to get your dosage of security goodness.  Until next time, I am Father Robert Ballecer, the Digital Jesuit, in for Leo Laporte, saying go be secure.



STEVE:  Thanks, Padre.  Talk to you soon. 



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#580

DATE:		October 4, 2016

TITLE:		Listener Feedback #240

HOSTS:	Steve Gibson & Fr. Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-580.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  Father Robert and I discuss an "update" on Microsoft's GWX remover; an encouraging direction for the Windows 10 Edge browser; HP in the doghouse; "Oh, yeah, that's what I meant to say about how to upgrade a site's password hashing"; a really terrific Dynamic DNS hack; another update on Windows Update; a distressing heads-up about how some unseen behavior of our web browsers is fatiguing our SSDs; a bit of errata and miscellany; and then a discussion of feedback from our terrific listeners.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here to give you the skinny on the Windows nag remover; HP is in the doghouse; browsing the web might kill your SSD; and your questions, Steve's answers.  Security Now! is next.



FR. ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 580, recorded September 28th for October 4th, 2016:  Question & Answer #240.



It's time for Security Now!.  It's a safe harbor in the increasingly turbulent sea that is security in the age of the Internet.  We're here for a two-hour tour with our skipper, Explainer in Chief Mr. Steve Gibson - of course, Steve Gibson of  GRC.com, creator of ShieldsUP!, SpinRite, and SQRL, the security tools that we love, that we know.  Steve, my friend, one last time before Leo comes back I get the honor of working second chair with you.



STEVE GIBSON:  Well, and I love it, Padre, because you never reuse your analogies for what this - now we have the safe harbor in the stormy seas.  So yes, indeed.



FR. ROBERT:  Well, if you're Skipper, I get to be Gilligan.



STEVE:  Yeah, okay.  Oh, no, you could be - wasn't there some scientist?



FR. ROBERT:  Oh, the Professor.



STEVE:  The Professor, of course.



FR. ROBERT:  I didn't want to [crosstalk] Professor.  I might be Thurston Howell III.



STEVE:  Thurston Howell III, yes.



FR. ROBERT:  Yeah, my kind of character.  But, sir, we've got a packed episode because of course we've got the Q&A which we were  going to get to last episode, but we didn't.  But it was a fun episode.  It was full.



STEVE:  It was, you know, two hours of quality content is actually our goal.  So we have more things to talk about, even though it was only yesterday because we're recording this Wednesday night, the day after, because you're going to be a traveling man for the next couple weeks.  And Leo has been gone, of course.  So we're doing this now.  So if our listeners are confused, if anything like major security catastrophe happens, like in what they're seeing as "last week," and wonder why I'm not talking about it, it's because I didn't know about it in the future because, as I mentioned yesterday, our time machine is broken.  Actually, there's a part that I need, the [wegelstegen], which is only available downstream, down the time stream.  And so - since when you break in the past you're kind of stuck there.  



FR. ROBERT:  It's a time Catch-22.  You need a time machine to get the part for your time machine.



STEVE:  Precisely that.



FR. ROBERT:  That's always a problem.  Yeah, it's right next to the flux capacitor and the heart of the Tardis.  So there we go.  And actually I just wanted to say I did check out the time travel show that you mentioned.



STEVE:  "Timeless," yeah.



FR. ROBERT:  "Timeless."  And it does look actually pretty good.



STEVE:  It looks, the special effects - I'm kind of a special effects junkie.  And I should mention that last night, after we talked about the original Trek series, I thought, you know, I think Amazon has all of those.  And so I watched one.  Not the "Gate to Tomorrow" or whatever that one was.



FR. ROBERT:  Yeah, "City on the Edge of Forever," yeah.  



STEVE:  But I watched the one where they mistakenly jump back in time, and a pilot who's flying a jet sees them and attempts to intercept.  They beam him out.  The tractor beam shakes the plane apart.  Now they've got a problem because now he's got information about the future, blah blah blah.



FR. ROBERT:  Right, right.



STEVE:  Anyway, so I just thought, okay, I'm just going to watch this.  And I get why now it's, I mean, it's 50 years ago; right?  Because we're in the 50th Anniversary of Star Trek.  And even 50 years later, while, yes, the sets are made of cardboard, and it's a little hokey, there's a charm to it that explains why it worked back then.  So that, I mean, even now, just there's like - it's so full of good writing and little touches that I just thought, okay, this, you know, it's charming.  It's not edge-of-the-seat gripping.  But of course, because we've all memorized all those plots by heart.  But it was fun.  So we've got a bunch of other stuff to talk about.



FR. ROBERT:  Yes, we do.  Yes, we do.



STEVE:  We've got - I mentioned - I keep wanting to say, okay, should I say "yesterday" or "last week"?  I'm not sure.  Oh, well, last podcast.



FR. ROBERT:  Last episode, there we go, yes.



STEVE:  On the last episode...



FR. ROBERT:  Last time on Security Now!.



STEVE:  Last time I talked about this new update which I would provide links for on the GRC Link Farm page to Microsoft's official GWX remover.  I've got news about that.  After all, it's been a whole episode, and I've got news.  An encouraging direction, but a little bit of misdirection also, for the development of Windows 10 Edge browser.  HP has landed themselves in the doghouse, and they're trying to behave now.  And then I titled this one, "Oh, yeah, that's what I meant to say about how to upgrade a site's password hashing."  That's actually a topic.



A really terrific dynamic DNS hack that a listener suggested that I just love.  Another update on Windows Update.  A distressing heads-up about some unseen behavior of our web browsers which has the consequence of dramatically accelerating SSD fatigue.  A little bit of errata.  Some miscellany.  And, given that we don't completely occupy two hours with that stuff, we'll take as many questions and comments and thoughts and discuss those things from our listeners as we have time for.



FR. ROBERT:  Who knows?  It might actually be when Leo gets back that we finally get to the Q&A.  Hey, look, if you've got good topics, you have to talk about those topics.  That's just how it works.



STEVE: Of course.  And really that's what the show's about anyway.  It's called Security Now!, and I'm happy to have feedback from our listeners.  It makes great material when we need some.



FR. ROBERT:  I would like the record to show that all the times that I've been able to sub for Leo and talk to you on Security Now!, I think this might be the first time where your rundown at the beginning of the show actually contains a few stories that sound positive about security.  I'm blown away.  I mean, normally it just scares my pants off.  So this is fantastic.  This is not just my last episode with you in this particular run, but it's a momentous occasion where Steve is actually going to give us some good news about security.



STEVE:  It's nice to know that, after all, even the word "security" is meant to imply safety and what it says.  So every so often it actually does.



FR. ROBERT:  Indeed.  Okay, Steve.  So last time, and by "last time" I mean last episode, which we really mean yesterday, we talked about how Microsoft was finally pushing out an update that would kill the much hated Get Windows 10 nag screen.



STEVE:  Yes.  And it wasn't clear, well, actually, not only that, but there's like eight or nine different widgets that they put onto people's machines at one time or another.  Remember that it was very controversial, at one point they began, they, like, changed IE so their banner was coming up in your browser saying, oh, you know, you should upgrade to Windows 10.  It's like, where did this come from?  It turns out it was on your own system.  It wasn't from a website you were visiting.  So they famously pushed this thing like crazy.



So last time we talked about KB3184143.  That's the magic number for getting rid of this, KB3184143.  I did not know then whether it would be necessary for people to go to that Knowledge Base article, which I have a link to in GRC's Link Farm, or whether Microsoft was going to proactively push this out in Windows Update and sort of voluntarily do the right thing and remove all of that debris.



Well, kind of yes and no.  I mentioned, I think last episode, that I had seen that Windows Update had some new goodies for me.  I had not at that time looked at them.  I looked at the Optional updates, and there it was, unchecked but available.  So it is not necessary for people to go find the link, but it will be necessary in this instance to say, yes, I do want 3184143.  So you'll find that probably henceforth sitting there in the optional category.  And if you install it, it'll pull all the GWX stuff out.  So it's better than it not being pushed at all.  Maybe they'll promote it to Recommended at some point.  Who knows?  But it's not now.  And it's not important, either.



FR. ROBERT:  At some point I'm sure someone's going to do a breakdown.  But I'd like to see if this actually really does pull out all of the cruft that has been added to Windows 7 and 8 machines over the last year and a half because...



STEVE:  Well, remember, though, there is also new telemetry that they've been back porting.  And I don't think this pulls that out.  That's all part of their long-term strategy. I think this is just GWX that it removes.



FR. ROBERT:  That's not - I'm not real happy about that.



STEVE:  I agree.  Okay.  So, many people tweeted this little news item.  And I don't know whether they read the entire, like all the fine print, because it sounds very encouraging until you get down to the last bits.  And it's like, oops.  So the good news is, and the headline that grabbed people, was that Microsoft was moving Windows 10's Edge browser into its own VM.  This was picked up by so many of our listeners.  And you and I talked about it.  I remember you were talking about your solution for basically somehow creating browser isolation.



FR. ROBERT:  Containers. 



STEVE:  Yes.  And I've talked about thinking that the only way to do this safely is, one way or another, and there are of course many ways to skin that cat, but not to have the browser running in the machine where you also have all your other valuables, but somehow isolate it.  Well, this news is, as the headline says, that Microsoft has announced that the next major update to Windows 10 will run its Edge browser in a lightweight virtual machine to make exploiting the browser to attack the underlying operating system or compromising the user's data significantly more challenging.  They've got a name for it.  They call this Windows Defender Application Guard for Microsoft  Edge.  Doesn't exactly run off the tongue, but clearly explains what it's about.



Now, Edge is a great browser.  We've talked about the fact that Microsoft bit the bullet and truly did a rewrite from scratch, taking everything they learned, and we hope they learned a lot, from Internet Explorer because it was getting a lot of arrows in its back for years, and started again.  The architecture, the design of Edge is state of the art.  And I'm impressed with it.  I would like to be able to run it on earlier operating systems.  But no, that's just another reason to drag you up to Windows 10.  It is already constrained in a sandbox where they're deliberately attempting to isolate the browser, recognizing, as we all do, that it's just too difficult to guarantee containment of something as complex as a contemporary browser.



So it needs its own firewall, essentially.  So putting it into a VM leverages some technology that we got earlier this year, basically Hyper-V being in there underneath things.  And it does sound like they're doing the right thing.  The way they're implementing this, they're not putting an entire second copy of the OS into a VM, but they're using virtual machine technology to very tightly constrain what the browser can do.  All of that is good news.  All of that got everybody excited.  Only one problem.  It's only available on the Enterprise edition of Windows 10.



FR. ROBERT:  Oh, naturally.  I mean, who else would want that?  That's a completely useless feature to the rest of us.



STEVE:  It's like, "Oh, Microsoft."  So, okay, now, that's today.  Maybe they're doing it - and it's controllable using the whole Windows Group Policy system.  There is this notion of untrusted and trusted sites.  And it's not clear to me that this is such a great idea, why there needs to be a delineation between trusted and untrusted.  Part of the problem, though, apparently, is that the VM does what it should do and, for example, doesn't allow permanent alterations to the system.  So apparently you want to run as many things as possible in the trusted site outside of this VM and as few things as necessary, but the dangerous ones, in the internal one.



So the more I looked at it, the less wonderful it seemed, not only because most of us won't be running the Enterprise edition of Windows 10.  But this could also be sort of some incrementalism, where they're going to get it out there, develop some experience with it, let corporate IT manage their networks.  Maybe it's a little bit of a tease for getting corporate America or corporate global to consider Windows 10 because that's kind of a hard sell, even now.  But anyway, for what it's worth, in the future, I mean, I like the direction they're going in.  And so with any luck in the future they may be bringing this out for everybody.  But at this point, Enterprise only.



FR. ROBERT:  I did an interview with a company at the Intel Developer Forum that had a version of this.  They actually used Intel Skylake or better processor.  So they used that plus the TPM that was built into a lot of Enterprise machines.  And they're calling it micro VM.  It's essentially a container, but it acts like a VM.  Like you said, it's a VM that's been stripped down to the core, actually below the core.  It's a VM that really won't work unless it's in a full operating system.



STEVE:  Right, it's more sort of like an API VM.



FR. ROBERT:  Exactly, exactly.  But the important thing was that it could launch in 15 milliseconds.  And that's always been the issue with running VMs in Enterprise.  We understood it's better to do that.  But did you really want to stop and wait another 30 seconds for a VM to spin up?  In this instance you don't have to.  I mean, it's essentially the same thing as if you just clicked the icon for the browser itself.  But Steve, don't you feel as if we're heading in this direction?  I mean, yes, it might happen with Enterprise customers first.  But eventually we should get to the point where all native Microsoft apps will run in some sort of micro VM.  They should not touch the actual operating system at all.



STEVE:  Yes.  And the coverage for this did talk about, first of all, that one of the reasons the deployment was somewhat constrained is that there were some hardware requirements.  You mentioned Skylake processors.  There are some hardware requirements that all consumer processors may not meet.  So it won't run on some hardware platforms.  And the coverage also did talk about other Microsoft applications which could similarly benefit from this kind of containment.  And of course one of the other things that many of our listeners have aimed me at is the Qubes OS.  And I've talked about it, I've responded to people saying, hey, why not that?  And I haven't run it myself, but I've watched it being run.  And to me, that's a heavyweight VM.  I mean, there, from my watching it in use, it seemed like the notion of compartmentalization dominated the user's experience.



And from my standpoint, I don't want to think about compartmentalization.  I just want it to work.  I want it to be not seen and not heard, just there.  Whereas the whole point with Qubes is, I mean, to me it felt like something an NSA workstation would use, where you really are willing to focus on what goes in which VM and who has to talk to each other and which things need isolation and all that.  It's like, no.  No, I just want to run my apps and have them unable to damage my system.  So it needs to be, for me, way more transparent than that.



And our listeners know that I built a machine with a Haswell chipset, back when there was the threat that Microsoft was going to stop supporting Windows 7 and only support the later OSes on the newer hardware.  And I said, whoa, whoa, whoa, whoa, whoa.  I built one with either 64GB or 128GB, the reason being I just want to have lots of VMS.  And they'll be spun up, and the browser will run in one, and other things will run somewhere else.  And to me, for me, if I'm going to make the move to a 64-bit OS, I might as well take advantage of the fact that memory is comparatively inexpensive now.



FR. ROBERT:  Right, right.  And it's interesting, this is also a strategic move for Microsoft because they are heavily invested on the VM side.  They've got their own hypervisor.  Their Enterprise customers are really pushed to VM.  And I think they're not too happy with the incredible, incredibly explosive popularity of containers.  Containers don't get them the same profit margin that they would off of VMs.  So they understood they needed to create something that was lighter weight.  They needed to...



STEVE:  Oh, you mean like from a licensing standpoint?



FR. ROBERT:  From a licensing standpoint.



STEVE:  Oh.



FR. ROBERT:  Absolutely.  And we've seen this both from Microsoft and from VMware, which are two companies incredibly invested in this.  VMware has their own version of this, not really available.  The one they have right now is not great, but they've got one coming up that is also incredibly lightweight.  It's essentially a container, but it runs inside of VM management.  And their selling point, and this is the same thing for Microsoft, their big sell is it's like a container, it works like a container, you set it up like a container, but it doesn't have the inherent security problems that containers have because right now containers, you don't get 100% isolation, and you can actually break out of a container and infect the hardware below.  So I don't know.  Maybe this is a good play.



STEVE:  The EFF wrote a open letter to the President and CEO of Hewlett Packard, 1501 Page Mill Road.  And I'll just sort of read the beginning because this explains what the letter's about.  And this was to Dion Weisler.  "Dear Mr. Weisler, I write to you today on behalf of the Electronic Frontier Foundation, a nonprofit devoted to defending technological freedom, human rights, and privacy in courtrooms, legislatures, and online.  Like many others, we are alarmed by reports that HP has activated a dormant feature in Officejet Pro printers, and possibly other models, so that the printers now automatically verify whether its ink cartridges are official HP ink and not competitors' products or even refilled HP cartridges.  If these printers detect third-party ink, printing stops.  This activation was disguised as a security update.



"You must be aware," they write, "that this decision has shocked and angered your customers.  Below, I have set out our concerns and the steps HP must take to begin to repair the damage it has done to its reputation and the public's trust."  And I'll just - there were a number of bullet points that they elaborate on.  But, for example, the first three were "HP deprived its customers of a useful, legitimate feature; HP abused its security update mechanism to trick its customers; HP's time-delayed anti-feature is a bait-and-switch."  And so this was a few days ago.  Their page was recently updated with the result of a major outcry.  The EFF in their follow-on story said:  "Over 10,000 of you have joined EFF in calling on HP to make amends for its self-destructing printers in the past few days.  Looks like we got the company's attention.  Today HP posted a response on its blog.  Apparently recognizing that its customers are more likely to see an update that limits interoperability as a bug than as a feature, HP says that it will issue an optional firmware update rolling back the changes that it had made.  We're very glad to see HP making this step."



So, and we've covered Microsoft's misbehavior.  I'm trying to think if Apple has been caught doing the same things, you know, slipping some features in, calling it a "security update," and in fact doing things to people that they don't like.  And very controversial, we know that Microsoft is in the process of, I think it's next month, actually, they're going to be switching over the way they handle Windows updates.  But we'll cover that here in a minute.  So, yeah.  The good news is HP did this, and, wow.  We've often talked about how expensive ink and toner are for printers.  Basically it's the razor handle and razor blades model, where a lot of money is being made on the consumables.



FR. ROBERT:  Right, right.  And, okay.  So the official policy line here is that they're trying to protect their consumers from third-party ink that might damage the printer.  And that actually is true, that you can destroy a printer if you use really, really bad cartridges.  That doesn't happen to most people.  I've used reusable ink cartridges just fine with many of my printers.  I did have one that leaked on me.  I had to clean it up.  And so it's this heavy-handed thing that you just don't trust that a company did it for your benefit.



STEVE:  Yeah, well...



FR. ROBERT:  Even if they did, even if there is a clear benefit, you just don't trust them.  A very good example, there's a 3D printer that I kind of enjoyed, the Da Vinci Jr.  I've moved past it.  But it used DRM filament.  Now, I was able to bypass it, and what I found out was that third-party filament did destroy it at one point.  So they were right.  They were right in that they were trying to protect you from that happening.  But it didn't matter.  All you saw was the fact that they wouldn't let you do what you wanted to do with something that you bought.  I mean, Apple it's the whole upgrading your OS and not being able to push it back.  That's another thing.  Yeah, it's better for the entire ecosystem.  It's better for the company.  But I think we as users, consumers, we get really upset any time a company says this is for your own good.



STEVE:  Well, and so, right.  It was a security update inasmuch as it was for their financial security.



FR. ROBERT:  Right.



STEVE:  And I think, I know that when I was up, I think it was New Year's before last, I fell in love with the Keurig machine that you guys have in the kitchen.  And the point was made, though, that you wanted to make sure you got the right one because the newer ones were enforcing their Keurig's IP and not allowing non-Keurig K-Cups to be used with it.  And so, but there it was caveat emptor.  You knew upfront which one you were getting.  I think the extra controversial thing here was that - and this is one of the things that's got some people upset about Windows 10, also.  Microsoft has reserved the right to change what it is, you know, unilaterally.  And especially with the change coming in Windows Update.  Users no longer have the opportunity to pick and choose what things they want to accept.  It's like, no, here's the operating system.  And it's like, but wait a minute, that's not the one I want.  The one I wanted was last month and not this one.



And so what HP of course did was they, after the sale, they changed the terms of what their printer would do.  And I think that's just not okay.  If new printers refused anything other than HP cartridges, and refused to be refilled or to have those cartridges refilled, even if they were HP, it's like, okay.  Then let's see how many HP sells compared to their competitors?  But coming in afterwards and, I mean, I'm just glad HP backed off of this.  I'm hoping other manufacturers saw that and take a lesson from it because it's not okay.



FR. ROBERT:  That's actually a great analog, Steve, because when you talk about Keurig and their CRM, their Coffee Rights Management, that was one of those things where I know it sounded like a great idea in the board room.  They're like, oh, okay, well, our patent's going to run out.  Hey, how about this?  We're going to make it so that our machines will only work with our coffee cups.  So they have to buy them from us.  And, well, of course people weren't going to buy a new machine that gave them less options.



STEVE:  Right.



FR. ROBERT:  And so they saw their sales tank completely, not just sales of the machines, but the sales of their K-Cups, as well, because people were properly outraged that they had bought this machine, and it gave them less functionality than the machine they had bought prior.  And so they returned them.  I think you're right.  If HP had two models of the same printer, and one sold for $199 and the other sold for $250, and the 199 one they told you, oh, well, you could only use HP cartridges with this, and the 250 one you can use with any cartridge you want, people are going to buy the 250.



STEVE:  Yeah.



FR. ROBERT:  All right.



STEVE:  I mean, and if you don't know that yet, just look at the cost of cartridges.  Oh, I mean, the printers are free almost.  I look at this thing that you can get for 150 bucks, and it's like, how can they make this for $150?  Well, maybe they don't.  Or maybe they're not profiting from that at all.  They're just counting on people buying their branded consumables.



Okay.  So I just loved this.  A number of our sharp-eared listeners were confused by something that I said last podcast, when I went into great detail about the problem that Yahoo! probably has with, we presume, an older hashing algorithm and the need to upgrade to a newer hashing algorithm.  And I proposed a means by which that change could be made.



Well, the reason I confused people is that, some time ago, a couple years ago, I laid out the right way to do that, which I didn't do in the last podcast.  In the last podcast I said, oh, well, they would have to hold onto the old hash until the user logs in with it, and then take the same plaintext and rehash it with the updated hash, and that would allow them to sort of ratchet the user forward.  And years before I had said, oh, this is an easy problem to solve.  You simply rehash the old hash with the new hash.  So you take your existing database of old hashes.  You hash all of those with the new hash.



Now you've got the strength of the new one, and you've transparently updated the database so that it now essentially uses a chained hash.  But there's nothing wrong with that.  And probably the old one wasn't very time consuming or there wouldn't have been a problem using it.  So chaining them isn't going to hurt you very much.  And so a number of users said, Steve, you know, you really - I thought you solved that problem a few years ago.  It's like, ah, you're right.  That's what I meant to say.



FR. ROBERT:  Okay.  As always, he meant to say exactly what he said when he said it, and now you understand.



STEVE:  Exactly, and now we're all confused.  So, okay.  This is the coolest DNS hack.  We've been talking about dynamic DNS and the idea, for example, in the case of operating your own OpenVPN server, rather than using a third-party service, because it's got the problems of we're not sure they're not subjected to a government security letter.  Any place that their tunneled traffic egresses onto the public Internet, it would be a high-interest location for any nation states or law enforcement.  So the idea of distributing VPNs by not concentrating them on a single service, but rather now these days with the Ubiquiti router, with pfSense, with a number of other routers, you can run an OpenVPN server yourself on your home network.



The problem is most people use DHCP from their ISP to get their network's IP - which, while relatively static, can change from time to time.  So then you want some sort of DynDNS, dynamic DNS, so that, no matter where you are, you're always able to find the IP address of your home connection, even if you're away traveling, and while gone your IP changes.  Dynamic DNS is the famous means for doing that.  Then we talked about a number of DNS services that offer that.  And we've sort of been talking about this for a couple weeks now.



So, for example, my favorite registrar, which is now Hover - and, by the way, I should mention I think they're just becoming an advertiser of the TWiT network.  So we're supposed to give a disclaimer, I guess, of that; but I loved them before, and I'll love them afterwards.  They don't offer dynamic DNS.  Namecheap does, Google's Domains offering does, and so forth.  This hack is wonderful because we talked also about, I think it was week before last with you, Padre, about the service afraid.org, where you can create any subdomain of your own at afraid.org.  So stevespiffydynip.afraid.org would be a domain name.



Now, the problem is, you may not like that domain name.  It's like, well, okay, you know, it works, but I'm not sure I want to, you know, I mean, afraid.org?  Really?  So here's the hack.  There's a record in DNS called a CNAME, stands for "canonical name."  And what it essentially is, is an alias for a different name.  I'm using that at GRC.  I have a couple CNAME records.  My blogs are steve.grc.com and blog.grc.com, but those are CNAME records over to wordpress.com domains that happen to be agilesynapse.wordpress.com and grcblog.wordpress.com.  But users don't see those.  They see and can easily remember steve.grc.com or blog.grc.com.



So anyone can do this with their existing non-DynDNS provider, like, for example, my favorite one, Hover.  That is, if you already have a domain somewhere, then you can put a CNAME, a canonical name record, there which points to randomgibberish.afraid.org.  And the DNS lookup process will fetch your formal public-facing DNS record, which is a nice, you know, like your own domain, and you can create a subdomain or whatever you want to do.  And then, when the DNS resolver fetches that and obtains this CNAME record, it goes, oh, that's an alias for the real name.  And then it goes and fetches this, wherever you pointed that CNAME record to, which has to be another DNS name.  It's got to be a DNS record.  It can't be, for example, an IP address.



That points it then to something.afraid.org, which does support dynamic DNS.  So your device that you want to track as its IP changes, it keeps afraid.org updated.  And then your actual DNS provider has a CNAME record pointing to afraid.org.  Beautiful hack.  So that was Angelo, and I can't pronounce his last name, S-I-J-P-T.  So Angelo, he does this, and it works for him.  So I just wanted to pass that on.  I thought that was really a cool solution.



FR. ROBERT:  And that is actually the proper way to do it.  It will stay working throughout the time that you've got the CNAME set up properly.  I will say, though, Steve, I kind of miss the days where everything was IPv4, and you could just memorize the IP.  I don't know what it is.  And you can't memorize an IPv6 address.  That's just - it's too, I mean, that you actually do want to use a DNS or a CNAME entry in order to do that properly.  But when you used to be able to know like the 50 IP addresses you need for all of your hardware, there was never a question of whether or not this was going to get to the right piece of gear.  That was the only piece of gear that had that number.



STEVE:  Yup.



FR. ROBERT:  Those days are gone. 



STEVE:  Yup.



FR. ROBERT:  Or mostly gone.  You probably still - you have a couple of pieces of gear that are still IPv4-only; yes?  Or have you dual-stacked everything?



STEVE:  No, my whole site is still IPv4.  I mean, I'm still running on XP.  So of course I'm still using IPv4.



FR. ROBERT:  Okay, all right.  I don't have anything still running XP, but I do have a few IPv4 addresses.



STEVE:  Well, there's the demand from people for ShieldsUP! to support IPv6.  I actually have the equipment that I need.  I just don't have the time.  And everybody knows that I'm behind the eight ball, finishing getting SQRL wrapped up and then getting SpinRite 6.1.  I'm not letting myself get diverted again onto any other major projects.  And rewriting, see, because I wrote my own full IP stack for ShieldsUP!.  I called it NanoProbe.  And, I mean, I'm using WinPcap kernel filter, and I wrote everything on top of it.  So it was fun, and I would love to do IPv6 support.  Again, it's just a matter of time.  So I'll get around to it once other projects are behind me.



FR. ROBERT:  Indeed.  And perhaps at some point I'll sell off the last of the IPv4 address space that I'm holding onto.  I've got a little...



STEVE:  Wait, wait, wait, wait, how much?  How much?  What size?



FR. ROBERT:  We had a /8 at one point.



STEVE:  Ooh.



FR. ROBERT:  I know.



STEVE:  Ooh.



FR. ROBERT:  I know, that's incredible.  That's beachfront property.  We don't have it anymore.  We were good citizens. 



STEVE:  Who?  You and the Vatican?  Is that what we're talking about here?



FR. ROBERT:  Something.  It was legitimate research.  It was legitimate research.  And we do have active traffic on a good 30% of those addresses.  But, yeah, we turned back over a lot of it.  We kept two Class B's and a Class C.  But, yeah, we turned over the Class A.



STEVE:  The challenge is to find the right point in time for selling it because the curve is going to look like a hump; right?  It's going to increase, IPv4 will increase in value up till the threshold of pain.  And at some point IPv6 will just become more worth doing than the going price for an IPv4 block, in which case its price will start to fall.  You'll be able to get less and less money for it because the world ultimately will switch over, and I'll be the only one still using IPv4.



FR. ROBERT:  And actually it will be very noticeable.  If you were to chart it out, there will be a major spike.  And at that spike, people will realize it's just not worth it anymore, and then they'll switch, and immediately it will just plummet.  Once half of the world decides, okay, I'm just doing IPv6...



STEVE:  We give up.



FR. ROBERT:  We give up.



STEVE:  Yeah.



FR. ROBERT:  Although I will say you're going to be making a security scanner for IPv6.  What are the challenges of scanning ranges in IPv6 versus IPv4?  Because, I mean...



STEVE:  Well, not a scanner because it's always targeting the client that is requesting the scan.  And so it's scanning ports rather than scanning IPs.



FR. ROBERT:  Ah, got it.  That makes sense.



STEVE:  Yeah.  And believe me, I mean, you can't - I know security researchers scan.  But the point you're bringing up is absolutely salient because right now security researchers routinely scan the entire IPv4 space because it's very dense, most of it is in use, and compared to IPv6, IPv4, as we know, is a tiny little space.  It's 32 bits rather than 128.  And so your point is you can't actually scan all of IPv6.  And of course I don't think people will.  I think what will evolve is probably taking the BGP tables, they'll determine what blocks of this essentially infinite address space are actually in use, and they'll be scanning those.



FR. ROBERT:  Right.  And actually we ran into a problem not too long ago at one of the shows that we were doing.  There was an enterprise-class router from a manufacturer in China, relatively big.  You've heard about them.  I don't want to use their name, though.  But this was supposed to be their top-of-the-line enterprise router.  They didn't put enough memory to dual stack the routes.



STEVE:  Ooh.



FR. ROBERT:  So you could do IPv6, or you could do IPv4.  But if you tried to do both, it couldn't handle enough routes for even its own internal network, much less routing BGP.  So we'll see.  Some hardware will get a new life when suddenly it dumps its IPv4 stack.



STEVE:  Yeah, yeah.



FR. ROBERT:  Now, Steve, this next one actually has me tickled a little bit because there is a member of the chatroom whom I very much value.  So he's a good guy.  He's an important person, intelligent person, sorry, who - he asked for a way to fix his Windows 7 machine because his updates weren't working properly.  And what I told him was I had found a fix that involved you doing a single manual update.  You couldn't just go to the Windows Updates program.  You had to download something from the Microsoft site.  You would do a manual update.  And then it started working again.  And he said that's absolutely bunk.  It doesn't work.  You have a way to fix this.



STEVE:  So, yes.  We talked about this, I think three weeks ago.  And this is a link that I've also got in GRC's Link Farm page, which is to a - it's in the Microsoft Community Forum.  And they've been keeping this page current as the situation, which is a little bit fluid, is evolving.  So there is an absolutely guaranteed solution for getting a new Windows 7 install updated.  The reason I'm bringing this up again is that there's sort of some ominous wording in the most recent update to this page.



So the beginning of it reads:  "Windows Update has become quite problematic for Windows 7 users.  For the past year or so, we've been working to find a solution that will work for you.  We have found one that works very well indeed for most.  We know for certain this works well for September 2nd Tuesday, known as Patch Tuesday, which is today" - they were writing back then - "and onwards till October 7th.  You want to ensure you get all your Windows updating done before the next Patch Tuesday on October 8th. From that point onwards, there will be a very significant change in the way Windows Update works.  Some may like it a lot.  Some may dislike it intensely."



Now, we've talked about what that change is, and that's that Microsoft is doing away with the granularity of updates.  Essentially, they will be creating a monthly rollup that moves the entire OS forward.  And their plan is, in the future, that rollup will go further and further back in time.  And at some point it will be like the ultimate service pack which you apply as a single monolithic blob to the original install image, so that you would - and we don't know when they'll get there.  But if you were to set up a new Windows 7 machine at that point in the future, you would start with your install image and then apply this one blob.  Which, I mean, it makes sense when you think about it.



And I can empathize with Microsoft because it's so much easier to just have a single coherent update to all of the system files, essentially, all the things that they've changed over time.  Frankly, as a coder, I have no idea how they actually implement selective updating because many of these things are making changes to the same modules, to the same files.  And it's like, how do you figure out, how do you arrange to give the user the kind of choice we are spoiled with having up till next week?



FR. ROBERT:  Well, a famous case of that was the .NET components, which were absolutely famous for failing out, and it would make Windows Update not work properly.  And it was a convoluted process, and a lot of people didn't believe it worked.  But I would always - I had this step-by-step thing which was essentially, get rid of .NET, and then install these patches in this order.  And if you don't do it in this order before you do your next update, you'll have to start over.  You'll have to erase everything again and start over.  And I think that was actually - that's exactly what you're talking about.  That's what you run into.  When you give people granular control of updates, then sometimes they choose some, and sometimes they don't choose others, and now they're interacting on the OS level, and things don't work.



STEVE:  Yeah.  And I don't know how they could.  It's like, I just don't understand how it ever could have worked.  Now, there are a lot of people who are upset.  For example, during this whole Get Windows 10 fiasco, people were deliberately not installing that one GWX Update.  And every month they'd say no, and every time it would come back, no, and so forth.  And so they managed to get to now never having put it in because Microsoft gave them the option.  And there have been other things, I mean, we've seen instances where a specific update will crash specific hardware.  And so the user rolls back and then doesn't do that again because something about that update and their implementation or the state of their system, whatever, just is incompatible.  Well, that's a freedom and a flexibility that we're going to lose.



So moving forward, I mean, again, I get it.  I understand Microsoft wanting to do this.  We don't have a choice.  Moving forward, starting with 7 and 8.1, it's going to be more like it is with 10, where it's like you don't have a choice.  These are mandatory.  Otherwise you get left behind.  You can certainly turn them off, but then no one wants to do that because they want the security improvements that are being made.



FR. ROBERT:  Right.  And I'm mixed about that.  I mean, I actually do like the system of everything rolled up because I, like many other people, have had that experience of installing the fresh Windows 7 machine from a root image and then having to do literally days' worth of updates, pack after pack after pack, in order, in order to bring it up to snuff.  This kind of simplifies that.  At the same time, I have a really bad taste in my mouth right now with Windows 10 doing updates when I absolutely need it not to do an update.



STEVE:  And you mentioned last episode that you've rolled back from Windows 10 because it refused to respect when you wanted to give it permission to update.  And talking about this monolithic-ness, we were just talking about the telemetry additions which Microsoft is moving back from Windows 10 into 8.1 and 7.  Well, right now people know what those individual updates are, and they're rejecting them.  They don't want that added to 7.  They're going to lose the ability to do that.



FR. ROBERT:  Right.  I actually do have an experiment up right now.  I have a Windows 7 machine, it's a root install off of an old Dell laptop I have.  It's behind a firewall, so it can't talk to anything on my network.  But it's just sitting there waiting for its Windows update.  And when that updates, I'll know, okay, they've reached all the way back through all the versions, and they're now - this is every machine.  So when that machine updates, it means every Windows machine that's eligible for this will now have it.  And I'll let you know when it triggers.



STEVE:  So, okay.  This is important.  And I was feeling a little bummed because it seemed to be really bad news about Firefox, which is still my chosen browser.  I know everyone knows Google's Chrome is now the winner at the moment in the browser wars.  So here's the story that appeared to only affect Firefox.  And I'm phrasing it that way because it turns out Chrome's no better.  But we'll get to that in a second.



And paraphrasing from the report, Firefox users running on SSD mass storage should consider this must-change setting.  Today's modern multicore processor systems and higher quantities of RAM allow users to open multiple Firefox tabs in Windows simultaneously.  I've got two windows.  I have something like 227 tabs open at the moment.  I just sort of use them as infinite placeholders.  I have tabs from the work I was doing on SpinRite 6.1 that are still open from when I stopped working on 6.1 to turn my attention to SQRL, until I get back to 6.1.  So that gives you a sense of they're a little dusty.  But they're there.  They're my placeholders.



So these guys write:  "This can have an unintended effect for those SSDs, as session store data is being written constantly to NAND memory, thus fatiguing it.  Purely by chance, the author of this report fired up a free copy of SSDLife on two consecutive days on a workstation used only for email and browsing.  For those unfamiliar with this tool, it reports estimated lifetime for an attached SSD, and it also shows the amount of data read and written.



In this case, SSDLife notified the user that 12GB was written to the SSD in one day.  Since he didn't recall downloading any huge files over the previous day or visiting any new sites that could have resulted in bringing down a lot of new content to cache, this puzzled him.  He monitored these stats over the next couple of weeks, and this behavior stayed consistent.  Even if the workstation was left idle, with nothing running on it but a few browser windows, it would invariably write at least 10GB per day to the SSD."



FR. ROBERT:  Wow.



STEVE:  Uh-huh.  "Using Sysinternals Resource Monitor's disk utilization immediately revealed the culprit: 



Firefox.  It was continuously writing between 300K and 2MB per second to a file named 'recovery.js.'  This is Firefox's session backup file, which is used to restore browser sessions in case of a browser or an OS crash or hang."



Now, there's a setting in Firefox you can change.  If you go to, in the URL, you put about:config to bring up this daunting array, I mean, just a blizzard of settings.  In fact, there are so many, you have to have a search bar, and so there is one.  Then you search for "browser.sessionstore.interval."  Even when I put in browser.sessionstore, I thought, oh, it probably narrows it down enough.  No, there's still, like 25 different things.  Anyway, ".interval."  It defaults to 15,000, and that interval is in milliseconds.  So that's every 15 seconds the default is Firefox will store its state.  And if that state is a lot of large pages, it is redundantly, and I guess not very intelligently, not incrementally, it's just dumping its entire state constantly.



So this experimenter, in his case - what I did was I added a zero.  So I dropped it from very 15 seconds to every 150 seconds.  This guy set it to 30 minutes.  Now, I have to say I appreciate that crash recovery.  With the latest Firefox, where they've created a separate thread for the UI that was supposed to increase stability, for me, I'm having more trouble with it.  It's not as stable as earlier Firefoxes were.  So I'm not that happy with it.  And so I'm having to restart it sometimes.  And I'm happy that it recovers all those tabs.  But, boy.  And I'm using an all-spinning drive RAID for this workstation.



But this next machine that I've talked about, this Windows 7 machine with all that RAM, I'm going to seriously look at revisiting a RAM disk and see if it isn't possible to redirect Firefox's state store, its crash snapshotting, over to a RAM disk because an SSD is my primary drive on that system, a nice one.  But still, I don't want it just sitting there chewing up the SSD.



So anyway, so this guy says:  "Bottom line is that, if you have a lower capacity consumer-level SSD in some of your machines, you may want to check and tweak your Firefox config.  Those drives can be rated for about 20GB of writes per day, and Firefox alone might be using more than half of that."  And, like, for no reason.  I mean, doing an insane amount of redundant writing, essentially.  I'm hoping that this is going to put some pressure on the architects to make this incremental because it's ridiculous that, leaving it alone on an idle workstation, every 15 seconds it saves the entire browser state nonincrementally.  It's just poor engineering.



They finished saying:  "This is especially true if you're like [this guy] and have several browser windows open at all times."  I haven't looked at mine.  I shudder to think how much my system is writing redundantly to hard drives.  "Changing this parameter may even help with normal hard disks.  Your machine will feel faster if it doesn't have to constantly write this session info.  Users have observed that content open in the browser does have a major impact on writes" - so not just how many tabs, but how big the tabs are, that is, in terms of how large the page is that the tab is holding - "as does the number of open windows and tabs.  If you are using Firefox and a lower write endurance SSD, you should check this immediately."



And then, in an update to this, they said:  "We are now testing other browsers.  Currently in the middle of a Chrome v52.0.blah blah blah blah blah test.  We have been able to see a pace of over 24GB per day of writes on this machine."  So they're seeing a gigabyte per hour under Chrome.  So it's not just Firefox.  It's both of those browsers that are not intelligently saving their state.  And it's interesting because I have noticed that, when I do a restart, sometimes - in fact, I have an add-on, a Firefox add-on that's like a little green curly arrow which is a demand restart.  And sometimes its use of memory just sort of grows.



And so it's like, I'd say, okay, and I push the button, and it does a Firefox restart.  It takes it out, I get back three quarters of my machine's memory, and then it creeps up again.  The point is that I've noticed that, if I then touch, if I open a tab or switch to a tab that I haven't looked at since it restarted, it brings up the old page's content.  And I thought, oh, isn't that interesting.  Where is that?  Well, now we know.  It's sitting in this monster file which it's been redundantly writing.  But it didn't load it back into the browser until I actually viewed it.  But anyway, so I think that's a really valuable tip, especially for people who are on SSD-based machines.  A lot of laptops these days...



FR. ROBERT:  Oh, yeah, we're all on SSDs now.



STEVE:  Yes, yes.



FR. ROBERT:  The scariest part about this is how many of us have desktops that are on all day, and we leave our browser open?  I do it all the time.  And now I need to go in and find out what it's doing.



STEVE:  Yes.  It's your portal to the Internet.  I mean, I've got two browser windows open statically.  It's now part of my environment is the browser.  And it's sitting here just chewing up the hard disk.  So again, Sysinternals Resource Monitor.  And there is a disk utilization feature there which shows you by process how much what processes are using your disk.  Anyone who's interested who is worried or curious about this, spin that up and see what your browser is doing.  The good news is, for Firefox, there wasn't any follow-up yet for Chrome.  But for Firefox we can slow that way down.



FR. ROBERT:  And I will say that, if you want to see what damage may have been done already, all of the major SSD manufacturers - Samsung, Intel, Kingston, I think even Toshiba maybe, they've got utilities that you can run that will actually show you how many writes have been made to the cells, on average.  Assuming, of course, that they're doing trim properly.  And I know that most modern drives will safely do between two and 3,000 writes per cell.  Some of the Enterprise drives will up to 10,000 writes per cell.  And that should give you a good clue as to how much damage has been done.  I really want to check that now because I've literally had a desktop on for about 18 months with browser tabs open at all times.  I don't know.



STEVE:  Yeah.  Yeah.



FR. ROBERT:  Steve, we've got a little bit of errata that we need to take care of.



STEVE:  Well, last episode we were talking about corpuses.  And I said, wait a minute.  Should that be corpi?  Yes.  And I got two responses.  Someone tweeted me "corpora," and then a friend of mine who is bit of a linguist, he just sent "corpora, because third..."



FR. ROBERT:  Declensions.



STEVE:  "...third declension neuter."  It's like, okay, John, yes, of course.  Who doesn't know that?



FR. ROBERT:  You are bringing me back to really dark days of learning Latin during my master's in divinity [crosstalk].



STEVE:  Third declension neuter is why it's corpora.  So, okay.   Corpora.



FR. ROBERT:  I prefer "corpo."  It sounds friendlier.



STEVE:  That does sound very corpo.  It sounds like something you'd want to order a large size of.



FR. ROBERT:  Sir, can I get the large corpa?  And a beer.  Let's do that, yeah.



STEVE:  So a couple little bits of miscellany.  Our listeners know that I've been working on a Healthy Sleep Formula for a few months now.  Actually, I began working on it almost a year ago.  It was the end of October of last year.  So we're coming up, so it's 11 months.  And a lot of people have been using it with great success.  One of the problems has been that immediately upon putting up the ingredients that it uses, they have been selling out, those that are not heavily sourced on the Internet.  I wanted to make sure everyone knew that the niacinamide that has been impossible to get for the last few months, as promised, by the end of this month is coming back.  Both iHerb and Swanson Vitamins are now restocked with that niacinamide.  And I found two others that are lower dose and smaller pills.  Some people were having also problems with the size of that.  So just an FYI.



I'm going to - I'll find some time to update the page.  I haven't for a while, although I have been keeping it up with that news.  My plan is to wait until, like, all the way through October, and then in early November ask people explicitly to send me their feedback about their experiences with it and dosages and so forth.  It's only now that people have been able to purchase all the ingredients reliably.  So I want to give people some time, finally, now that they're able to get it, to use it.  And then I will incorporate their feedback into a page where we begin to generate some user experience and guidelines.  But it's been a hit, so I'm really pleased for that.



Everybody also knows that I love puzzle-style toys on iOS and Android.  One of our favorites, which disappointed us only because it only had 50 levels, was called Hook.  And then another puzzle succeeded it, different, called Klocki, K-L-O-C-K-I.  They've just both been made free.  So if anybody didn't get them before, I don't think they were ever very expensive, like $0.99 or something, but they are now, both Hook and Klocki, are free for iOS and Android.  So I wanted to give people a heads-up.



And also, unfortunately, this podcast airs on the 4th, and HBO will have premiered their new "Westworld" series on Sunday the 2nd, two days before this podcast.  But they'll be - I'm sure they'll be reairing it throughout the week.  So I just wanted to, again, give people a heads-up.  The previews look wonderful.  I don't know how it could have 100% on Rotten Tomatoes when it hasn't yet even aired, but somehow it has.  And there are reviews available over at IMDB and elsewhere.  So it's a remake of the original, well, it's based on the original Michael Crichton novel, "Westworld," which was Yul Brynner, famously, the sort of defective robot gunslinger.  And it looks really interesting.  So for those of us who enjoy science fiction and have access to HBO, it looks like that's going to be fun.



And I just made a little note here about SpinRite.  We actually did a podcast yesterday, and I didn't dig around for any other feedback from users.  So everybody knows about SpinRite.  So we'll just move on.



FR. ROBERT:  Well, before we move on about that, I will say that last night I ran SpinRite on my OnePlus One, as was suggested, because I can use my phone.  There's a setting for me to make it a mass storage device.



STEVE:  Right.



FR. ROBERT:  And it worked.  Now, I wasn't able to complete it because I needed to come in to work today.  But now that I know that it works, now that I know that it can access it, that's something I'm going to kick off once I land in Rome because I can't wait to see if it will get me the speed back that I've lost over the years.



STEVE:  Well, and I did hear from some other people who watched us live in the last podcast who said that they're seeing SpinRite speeding up dodgy SSDs all the time now.



FR. ROBERT:  Right.



STEVE:  So it's interesting that, I mean, apparently SSDs get slow for retry reads or something, like very much the same way that spinning hard drives do.  And SpinRite does successfully speed them back up again.  So, yay!



FR. ROBERT:  Now, I know a little of the mechanism behind that, Steve.  I understand that, first of all, there's the garbage collection.



STEVE:  Right.



FR. ROBERT:  And anytime you do garbage collection, you're helping the SSD perform better when it's actually doing active transfers.  But the other part, and this is the wonderful physics of this, every cell is actually, it's a capacitor.  It's a little battery that stores a charge that lets the controller know if it's on or off.  And over time that charge will diminish, and it gets more difficult to tell the difference between an on and an off.  Level 2, does it actually go to those cells that could be on or off and recharge them and force them, so it makes sure that the on are really on and the off are really off?  Or what's the mechanism behind that?



STEVE:  Okay, so no it doesn't because that would be writing.  And we know that that would be the fatiguing the drive.



FR. ROBERT:  That would be bad.



STEVE:  Yeah.  So what it does is it reads it in a way that - because there's lot of extra commands down in the ATAPI API.  So it's able to put it into a maintenance mode, which makes it less - it makes it more finicky.  And then when it reads it, the SSD looks at the amount of error correction needed.  And only if the cells are becoming weak, so that more error correction is necessary, then selectively the SSD will rewrite those problematical areas.



FR. ROBERT:  I love that.



STEVE:  So it does, it just, like, it does what you want.  It won't rewrite it unless it needs to in order to fix it on the fly.



FR. ROBERT:  Now, what mechanism did you write in so that it knows when the cell is in trouble?



STEVE:  Well, that's built into the SSD.  So both hard drives and SSDs rely heavily on error correction code.  And there's something, the error correction process, when it realizes that it got a bad checksum, which is the fast thing to do, then it falls into error correction.  It uses the math of ECC to locate the region which is in trouble, and it looks to see how bad it is.  The actual term in error correction logic is the syndrome.  The syndrome is an XOR mask of the problem area.  And the number of bits from the first one to the last one of the mask tells it how large the error is.  And if it starts getting too large, then it says, okay, I'd better fix this before it grows out of my ability to correct it mathematically.



And so it actually has, it's like the drives are deliberately tolerating some persistent correction and then making sort of a value judgment about, okay, is this bad enough that it's worth rewriting this in order to fix it?  And so basically - but here's the key.  The drive doesn't go and police itself.  It only knows there's a problem when you ask it to read a sector.  And if that sector - you were talking about the capacitors, the charges stranded on little electrostatic islands.  If it's been a long time since you've visited that sector, then that can have become weak to a point that it will no longer read.  So what SpinRite does is just, very methodically and in a linear fashion, so it's as efficient as possible, just move through the entire addressable area of the medium, whether it's a hard drive or a nonvolatile NAND storage, and just give the NAND controller or the hard drive a look at its own storage.  And it fixes what it needs to. 



FR. ROBERT:  Fantastic.  All right, Steve.  I would love to talk more about the tech because that's who I am, and I love when you explain things.  But if we don't get into Q&A we're going to have yet another episode where we have to kick the Q&A down the street.  This first one, it's a little interesting.  Tell me about how am I going to handle DNSSEC on Windows 10?



STEVE:  So, yeah.  I got an interesting question because we were talking up DNSSEC in the last couple episodes, and you and I are both bullish on the promise of having secure DNS.  Normally DNSSEC is not something that the client does.  It's typically something that the web, I'm sorry, that the DNS server the client refers to uses to verify that the records it has received are accurate.  However, it can be pushed down to the client.  And, for example, Windows 10 does support DNSSEC.  That is, Windows 10 can be instructed to itself verify the signatures on records that it retrieves.  It's not the default setting.



And the problem, of course, and this is in general the problem with DNSSEC, it's sort of an all-or-nothing proposition.  That is, either we tell our client to not trust any non-DNSSEC record, or to go ahead and trust them, I mean, like not to check.  And but the problem is, not everybody is signed.  I'm not.  GRC, as I said a couple weeks ago, I have not signed my site because the nature of it is I'm constantly changing things and tweaking it.  And the tools that are available, just they make that a little problematical at this point.



So the way I would phrase it is, it's good that Windows 10 supports DNSSEC.  There are other clients for Windows that you can add which do support DNSSEC.  But very much like IPv6, where the infrastructure is still being laid down, the DNS roots are being signed.  And we talked about how they're being rekeyed from 1024 to 2048 bits.  And but we need then the other DNS servers to get signed, and for it to be supported universally.  Until it's supported universally, then we're not going to be able to insist on it.  And we see this in many instances.



We were talking about OCSP last podcast, the Online (SSL) Certificate Status Protocol, where because it's not universally available, it's a soft fail if you can't get it.  Well, we'd like to say hard fail, but then you end up with problems because it's a little spotty still.  So we're still sort of in the same place.  We're moving forward, but making fundamental changes to the entire infrastructure.  It's just a slow process, like with IPv6.



FR. ROBERT:  I think the comparison with IPv6 is dead-on because this is one of these technologies where it's good to have it on.  It's good to have your machines understand IPv6 and understand DNSSEC.  But until everyone is willing to turn the key, it's not going to be that much use.  Like right now, your router is probably dual-stacked, and you're probably not using the IPv6 portion of it.



STEVE:  Right.



FR. ROBERT:  All right.  We've got one here from Wildkarde.  Oh, and by the way, the last one was from Lockpicker, @AspiringLockpick on Twitter.  This one's from WildkardeUK, I guess.  I love the spellings here.  He wants to know the difference between HTTPS and HSTS.  



STEVE:  So a little bit of acronym soup there.  I think I - he says he just finished watching Security Now!.  And I referred to HSTS.  And he was saying, wait a minute, what's that versus HTTPS?  So HSTS is HTTP Strict Transport Security.  So it's kind of a superset, although they're different things.  HTTPS, of course, is HTTP Secured, HTTP SSL or TLS, where you exchange a certificate with a server to get both authentication and encryption privacy of your communications.



So there are [audio dropout], though, with various ways attackers have of intercepting pages which the site, the website intends to be secure.  But if somebody, a so-called man in the middle were to intercept the communication, for example, and in all the URLs on the page, if they removed the s: from the end of the https: so that they essentially turn them into http's, the browser would just assume, oh, okay, this site doesn't use HTTPS.  That is, it's possible, even if the server wants to enforce security, because of the way this evolved, the browser might not know that.



So Strict Transport Security, just like its name says, HSTS, is a later add-on to the HTTP specification, to the web spec, which allows a site in the response headers so that, when the web browser asks for a page, the response headers contain an HSTS header which explicitly says, for the following X number of seconds, this server will always be HTTPS.  That is, it allows a server to assert its intention in the future to be strictly HTTPS.  And that information the browser stores.



So the idea is, if you ever visit a website, and it's HSTS, then it's able to send you a header to educate your browser so that the site says we are always going to be secure.  And if you ever receive a nonsecure URL, you have permission to upgrade it to HTTPS without even asking.  If you see any HTTP URLs from this site, promote them to HTTPS.  So that solves a really nice problem.  It then means that subsequent visits cannot be usefully downgraded by a man in the middle.



Now, smart people recognized, oops, there's still a little loophole here.  And that is, what about the first time?  Again, this is the sort of problem you get when you add things on after the fact.  So there is that first visit problem because it's on the first visit that you get that HSTS header that the browser can then store permanently.



So the various browsers have gone a step further.  Years ago, when GRC committed to being HTTPS, I submitted both www.grc.com and grc.com to Google so that it would be built into the browser.  And there's a shared list that Firefox also uses which now wires a growing number of website domains as preset to HSTS so that that even solves the first visit problem.  Anybody, for years now, who uses Chrome, if they'd never been to GRC ever, and some bad guy tried to demote the URLs, Chrome would ignore that and know that GRC was HTTPS and have the flexibility to upgrade any query right off the bat.  So a very cool sort of incrementalism that we're seeing as we move forward, increasing the security of the web this way.



FR. ROBERT:  Fantastic.  All right.  We've got another one here from Ian Anderson Gray.  Can I just read it out?  Because it's actually pretty insightful.



STEVE:  Yeah, cool.



FR. ROBERT:  He says:  Hi, Steve.  I wrote an article on how to broadcast to Facebook Live from your desktop:  iag.me/socialmedia/br.  It's become very popular with over 600 comments.  Most people are able to connect without any issue, but it seems that some people can't.  I have a feeling that some people's ISPs are blocking the connection.  Facebook Live uses RTMP, and I think this is port 1935.  In order to help less techie people, what's the easiest way to check if their ISP is blocking port 1935, and what can they do to get their ISP to unblock it?  Could there be another issue?  Thanks so much for your time and Security Now!  I never miss it.  Ian.



STEVE:  So that was a great question.  And he and I actually exchanged DMs back and forth for a while because I was sort of curious to try to come up with a solution.  And I had a couple of ideas.  So we've talked about how ISPs are preemptively blocking packets for known troublesome ports.  Many ISPs block port 25, which is the SMTP port, because there was a - and the problem's sort of gone away, maybe because they've just gotten so good at blocking them.  But spam used to come from users' infected machines, and port 25 was the SMTP port, so they would block that.  And in some cases ISPs just want you to use their own SMTP server so they don't let you get outside their network.  You have to use their server so that they have some control.



And then, of course, the famous Windows file and printer sharing ports, 137-139 and 445, also generally blocked by ISPs.  And that's a service they provide, sort of, because if anybody had their filesharing open on the Internet - and Windows machines are often, historically have been.  Now they've got firewalls that are turned on by default, so things are better.  But this was what the original impetus for ShieldsUP! was back in the day.  I scanned the region around my business's IP when we first got a DSL line.  And here were all these C: drives, like just open.  And I thought, okay, I have to make the world aware of this.  So I created ShieldsUP! specifically to allow people to check to make sure that their C: drive wasn't available to everyone on the Internet because for a while they were.  Those were the Wild West days.



FR. ROBERT:  Those were the days, where you could send people something, and the Microsoft Messenger protocol, and just have a message pop up on their screen.



STEVE:  Yes.



FR. ROBERT:  That was actually - that was fun.  For pranking, that was actually a lot of fun. 



STEVE:  So now ISPs are proactively blocking the more troublesome ports.  So there's at least the possibility that this RTMP protocol, which he was right, it is port 1935, and it is over TCP by default.  There is a UDP variant, but it's not very popular.  So there's a chance that some ISPs might be blocking it.  The question is, how does he know?  And this is sort of a nice broader question for anyone, like how could you detect what ports your ISP is blocking, if it's doing so?  And so there are a couple ways.  One is, if you have a configurable router, which you can tell not to drop packets, but to reply with an ICMP message, the formal proper behavior for an IP stack device is, if a packet comes in trying to open a connection, and there is nothing there to accept a connection, the proper behavior is to politely say, sorry, there's no service running on the port you just requested.  So it sends back an ICMP saying, eh, no.



Now, the problem with that is it makes you probeable.  That is, scanners will know you're there.  So one of the other things that ShieldsUP! I think really popularized, as far as I know I coined the term "stealth."  Of course I used that from ShieldsUP! and Star Trek and so forth.  Because in stealth mode the router doesn't reply.  It just drops the packet.  So somebody scanning across an IP region would not know there was anybody at that IP.  If you can change your router to disable stealth temporarily, you can then use ShieldsUP! to scan all of the service port range from port 1 through - I actually go a little bit above 1024, and you'll get this beautiful grid.



Now, normally the grid is green, meaning all stealth, because your router is dropping the packets.  If you disable stealth on your router, it switches to blue, which is the port is closed, except where your ISP is dropping the packets, before they have a chance to get to your router.  So if you switch your router to respond - and you can immediately tell if it works by going to ShieldsUP! and scanning yourself.  Rather than this normal field of green, you'll get a field of blue with some green spots.  Those are the ports which your ISP is blocking for you before they got to your router and gave it the chance to say, yeah, I'm here, but there's no port open at that port.  And 1935 is above that range.



But ShieldsUP! also has custom port scans, so you can scan custom ranges or even individual single ports.  So once you confirmed that your router was responding by getting a field of blue with some green spots, then you could check, you could have ShieldsUP! scan 1935 and see if it comes up blue or green.  If it's blue, that means that that scan from the public Internet, from me, from GRC, got all the way to your router and then bounced off of it and came back showing that your ISP is not blocking.  If it shows as green on port 1935, then your router never received the packet, and something between the public Internet and your router, probably your ISP, arranged to drop that.  And so that allows you to check to see whether incoming packets are being blocked.



There is a chance, though, because the way RTMP operates, it is an outbound connection.  That is, your RTMP client is initiating a connection to port 1935 on some remote RTMP server.  So how do we check for that?  Well, I have another little piece of freeware called ID Serve - I-D S-E-R-V-E.  I wrote it years ago as a simple way to identify, to ID a remote service because many services in a response give you a whole bunch of information in their reply headers.  So it's a very simple, it's super light, small - of course I wrote it in assembly language - cute little Windows app and also runs under Wine, which allows you to put in a domain name or an IP, and it will issue a connection to that and show you what it got back.



You can override the port that it goes to.  Normally it goes to 80.  So if you wanted to check a TLS connection, you'd put in :443.  If you want to check RTMP, you'd put in the domain name or the IP :1935.  It will then attempt to initiate a connection to that port.  And its response will tell you if it was able to connect.  And if it did, what the reply looked like.  So there are some simple tools here that, with a little bit of jiggering around, you can actually answer the question of is traffic on any given port able to actually get to you.  And are you able to initiate outbound connections to any given port.



FR. ROBERT:  I used to have a server back in the day that I kept hidden away from the public.  And I could turn it on, so it had an out-of-band management, so I could turn it on and off as necessary.  But it had all ports open.  And that was just so that I could run NMAP on my side and ping through and just see what was being dropped by my carrier.



STEVE:  Ah.



FR. ROBERT:  It was important because I spent a lot of time in convention centers where they always had some weird rules, and you never knew who was responsible for blocking a port.  Of course, you'd never do that today.  You would never put a server on the Internet with ports open like that.  But back in the day it worked.  



STEVE:  And of course we've also seen situations, for example, where you have captive portals, like you're in a Starbucks WiFi, and they're doing things like blocking VPN ports and so forth.  So it can be interesting to get a snapshot of what traffic is able to get out and in from, as you said, Father, from a location that you're not familiar with.



FR. ROBERT:  Right, right.  Right, let's move on.  We've got another one from, I'm going to say it's either Stijn or Stijn Crevits.  We'll see.  He says:  Hey, Steve, good news.  cPanel does in fact support Let's Encrypt now.  But they need to fix a bug where only admins can configure it.  One issue with LE's auto-renewal, however, is that you can't use HPKP, which is, again, we're getting into alphabet soup here.



STEVE:  Yes.



FR. ROBERT:  What is HPKP?



STEVE:  So we've never talked about it.  It's yet another incremental extension.  It stands for HTTP Public Key Pinning.  So this is cool.  And so this is like - this is sort of off-topic for the question, but I just wanted to mention it because it is a cool feature.  We know that certificate pinning provides clients with a means of affirmatively verifying, sort of a priori, the identify of a certificate.  I have the GRC Fingerprinting page, which allows users to check the fingerprint of certificates and compare them with the ones that GRC receives and see if they're getting the same certificate that GRC is getting in order to potentially detect a decrypting proxy in line where they'd be getting the proxy certificate rather than the actual server certificate.



So another way to do this - and of course Chrome does this for Google's certificates.  This is the way Chrome is always able to catch anybody who screws around with Google's certs, is that Chrome knows the fingerprint, the actual hash of all of Google's currently-in-use certificates.  And that's called "pinning," where instead of relying on the trust in the CA system, which is sort of one level of indirection, and we've talked about the various ways that can fail, instead it's, okay, we know what certificates are valid for Google.com.  Here's the list of the hashes of those certificates.  And so that's called a "pin."



Well, HPKP, in the same way that HSTS allows a site to assert that it will always be using HTTPS security, HPKP is a means in the protocol for a site to give a browser a pin, that is, to pin its own certificate.  Which, as with HSTS, the browser caches for a length of time that the site has said this pin will be valid.  So it's another very cool, sort of we're creeping along,  making the 'Net more secure, looking for things that are still hackable, and coming up with ways around it.  And so this is a way for a site to provide browsers with the precomputed signatures of the certificates it will be giving them.



And so, for example, if you had visited a site that had given you a pin for its certificate, then you went somewhere else, you went to work maybe, where you are behind a proxy, or a proxy was brought up without your knowledge.  Your browser would immediately complain, saying, wait a minute.  This certificate that I have received, even though it looks otherwise valid because, for example, someone had snuck a CA for a dynamically issued certificate into your machine store - which can be done through group policies, for example, for administration.  If that happened, then the browser would say, wait a minute, this certificate's hash does not match the one that I previously received from the site, and the pin is still within its valid, non-expired time.  So alert, warning.  And so you get advised.



So anyway, I did want to - I wanted to note that cPanel, which is the widely used control panel for hosting providers, is now supporting Let's Encrypt.  And more things are supporting it moving forward, which is just great news.



FR. ROBERT:  Any time my service provider wants to give me more security, I'm down with that.



STEVE:  Yeah.



FR. ROBERT:  All right.  We're on a role.  Let's keep it going.  Let's see if we can actually get through a good number of the questions here.  We've got Chris A., who says, Steve, love Security Now! and SpinRite.  I would love to follow your advice and offer TLS on my personal website, but there's a problem.  Let's Encrypt is hosted by the Akamai CDN, and I trust Akamai about as far as I can throw a datacenter.  And it says, "More on that if you wish."  That much lauded DigiCert doesn't appear to have joined the free cert party yet, and other free cert issuers have had numerous problems, as you've recently detailed on the podcast.  Is there a free cert issuer other than Let's Encrypt that you could recommend?  Thank you for all you do.  Chris.



STEVE:  So this was an interesting question because I took it from a different angle.  I said to myself, okay, he doesn't trust Akamai.  What evil, what wrong could Akamai as the carrier of Let's Encrypt do?  And I can't see any.  The protocol protects you from the delivery system's misbehavior.  So Let's Encrypt is hosting in order to scale, that is, they're hosting on a big CDN in order to scale.  And so they've got servers which Akamai's network finds.



So Akamai, we're used to thinking of them as a caching system.  But in this case they're not doing caching because Let's Encrypt is not a caching-based solution.  It is a dynamic client-and-server protocol where the client and server have a well-designed state-of-the-art handshake that allows the client to assert and prove its control over a domain, and for the server to then issue a certificate which has been signed by a CA that the client trusts.



So I'm going to throw this back to Chris and say, you know, sorry you don't like them, but I think it's okay.  All that Akamai is doing is helping the Let's Encrypt system scale.  We talked about anycast routing last episode, about the idea that a single IP can appear to be widely geographically distributed.  So that's what's happening here.  And due to the nature of it, you don't have to trust Akamai.  You're actually trusting Let's Encrypt's servers.  And no man in the middle, I mean, this is MITM-proof.  It was designed to be robust against that attack, specifically because it needs to be.  And so Akamai is the man in the middle, as the deliverer, as the conduit of the content.  And there's nothing they can do to screw it up.



FR. ROBERT:  But I understand his sentiment here.  If he doesn't trust a carrier, a service provider, and if I don't trust a carrier, a service provider, I don't want any of my services to touch anything that might even be remotely connected.  It might not just be a security thing, too.  It could also be I don't want to support this company in any way, shape, or form.



STEVE:  Okay.  That's a good point.  I would say consider all the things we don't trust between here and sites that we do.  Like a lot of people don't like Comcast, you know, their ISP.  Do they trust them?  No.  But they don't have to because they're just a carrier of the traffic which is being authenticated and encrypted outside of their ISP's control.  The exact same is true with Akamai.  So I appreciate what Chris may be saying, and I think you make a good point, Padre.  But from a technical standpoint, there just isn't anything to worry about.  Well, okay, with the caveat that there's always something to worry about.



FR. ROBERT:  Yeah.  We always worry about something.  But you know what, there are other things that are more important to worry about than that.



STEVE:  Yes.



FR. ROBERT:  Right, right.  We've got Ben Moore here, who says:  Steve, thank you for all that you do.  Of course I think we all have that sentiment.  In 2015 I experienced a compromise of my eBay account.  Turns out eBay has a "feature" where you can have a password reset code sent to your mobile phone by text message, and within the dialog box you can select "Try a different number" if you no longer have access to the phone number associated with your account.  After the compromise, I got everything sorted out.  However, now in 2016, my account was compromised again - oddly enough, by the same phone number as last year.



So after resetting all my passwords - easy enough - I discovered that somehow the phone number used to reset the password is still associated with my account, but cannot be corrected or deleted.  After a few very long calls to support to correct, the final one ending in me demanding a return call with a resolution - still waiting after a month for a call back - the phone number is still associated with my account.



Here's why I'm writing:  Have you, in your experience, found a way to correct this sort of problem?  Is my account, which has been open since 2001, to be forfeited?  Can I better protect myself?  I'm hoping your experience can assist, or your exposure might be able to highlight the absolute failure on the part of eBay to be "able" to alter account information for security purposes or, frankly, willingness to help keep customer accounts secure.  



STEVE:  That was a great question.  And I replied to Ben already, saying I can't think of anything you can do except to forfeit your account, even adding multifactor.  What eBay is doing is saying the phone number is your ultimate solution for proving your account control.  And it's crazy that it isn't possible to revoke previously issued phone numbers that you no longer wish to have associated with your account.  The fact that he can't through the UI, and the fact that he can't through many conversations with them, says they've got a problem with their system.



But if Ben wants security, and he clearly does, I think you just have to drop that account and create another one.  And I can't think of, I mean, like in fact you'd have to drop it in a way that somebody who then compromised it could not do any ill under your name.  So, like, change all the information, remove credit card information, remove your first pet's name and all the other nonsense that anyone who got access to it could abuse.  I think you just have to abandon it.  And I did want to give this a little bit of light because it's wrong that this is the way eBay's management is set up for this kind of account recovery.  It's crazy.



FR. ROBERT:  And, oh, I want to get your thoughts on this.  Like you, I believe eBay is wrong.  I believe the system is backwards.  There needs to be some way to update the way that you reconfirm an account or you get an account back.  However, barring that, so barring the fact that they've messed up on the implementation of security, it is something to be lauded for a company not to surrender credentials to someone who they think might be the person who owns the account.



STEVE:  Yeah, that is a good point.  I mean, if a bad guy was able to remove the good phone number, then you lose your ability to recover your own account.



FR. ROBERT:  Yeah, exactly, exactly.  I mean, this would be another story if it was someone who said, "Someone called up eBay, and they pretended to be me, and eBay gave all my information to them."  That would be horrendous, as well.  So there's always that fine line of a company sticking by its security principles and willing to work with customers.  Although in this particular case, as you mentioned, the fact that he can't update that phone number, that's a fail.  That's a big fail.



STEVE:  Yeah, that's the problem, yeah.  Padre, we're at two hours.



FR. ROBERT:  I think so.  We've actually hit the two hours.  This will be the first time I've ever done a show with you where we actually hit two hours and didn't go over it grossly.  So go figure.  Steve, it's been a pleasure.  I am, of course, I'm happy to have Leo back.  I love working with Leo.  I love having him in the office.  But it will be a little sad that I don't get to do Security Now! with you anymore.



STEVE:  I know that our listeners feel the same way.  I always see a lot of tweets saying, hey, you and Padre have a great chemistry, love listening to you work together.  And I know that we both feel that way about each other.  So thank you very much for the last three weeks.



FR. ROBERT:  Indeed, thank you.  Thank you for working with me.  And of course Steve is the skipper of this two-hour tour.  Steve Gibson can be found at GRC.com.  He is the author of ShieldsUP!, SpinRite, SQRL.  He is the man that we turn to whenever we have  a question about security, about best practices.  And of course he's got audio versions and transcripts of every show at GRC.com.  So head over there if you need to get your fix.  Of course you can also get, at our show page, TWiT.tv/sn, you'll find all of our episodes plus a place to subscribe, as well as being able to download the podcast whenever and wherever fine audio podcasts are aggregated.



We do Security Now! here on the TWiT.tv network every Tuesday at 13:30 Pacific, of course unless we're prerecording them.  And you can watch us live at live.twit.tv.  As long as you're watching live, jump into our chatroom at irc.twit.tv.  I feel that it's actually a big part of the show.  I love seeing people respond, comment, ask questions in real time.  Again, that's live.twit.tv and irc.twit.tv.  Until next time, I'm Father Robert Ballecer in for Leo Laporte, saying get out there and get some Security Now!.



STEVE:  Thanks, Padre.  Always a pleasure.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#581

DATE:		October 11, 2016

TITLE:		Yahoo & Primal Worries

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-581.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss today's Windows Update changes for 7 and 8.1.  An exploit purchaser offers a $1.5 million bounty for iOS hacks.  WhisperSystems encounters its first bug.  An IEEE study reveals pervasive "security fatigue" among users.  We've got Firefox and Chrome news, WoSign Woes, Samsung Note 7 news, some errata, a bunch of miscellany, and a look into new Yahoo troubles and concerns over the possibility of hidden trapdoors in widely deployed prime numbers.



SHOW TEASE:  It's time for Security Now!.  Steve and I renew our acquaintance after a few weeks gone.  There is a lot of news, lots of things to talk about, including our own personal favorite shows and that kind of thing.  We'll also get into the Yahoo hack and what Yahoo has done, which is frankly reprehensible.  And Steve will explain a new problem, maybe you read about it, the trapdoor prime issue, and why it may not be a bad as it sounds, although something to keep in mind.  Anyway, details to come, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 581, recorded Tuesday, October 11th, 2016:  Yahoo & Primal Worries.



It's time for Security Now!, the show where we cover your security and your privacy online.  And the king of security and privacy is here, Steven "Tiberius" Gibson of - this is now your middle name, by the way - of GRC, Gibson Research Corporation.  Hi, Steve.  I missed you.  Thanks to Father Robert for filling in.



STEVE GIBSON:  Likewise.  Well, we did, you know, Father Robert is a great co-host, but this feels like home, having you back.



LEO:  Well, we have been, you and I, together for 11 years doing this show, and many years before that.  So it is kind of just a couple of buddies, sitting around over a cup of coffee, cup of Joe, talking security.



STEVE:  Comfortable old shoe.



LEO:  That's me.  That's me.  A little more comfortable after living on a cruise ship for two weeks, I might add.



STEVE:  I would imagine so.  And nobody got sick.  Everybody's healthy.



LEO:  Everybody's great.  We had a great time.  It was a really fun trip.  And I have to say, you know, towards the end I started doing shows, having imaginary conversations with people and stuff.  And especially when you read security stories or something, I go, oh, I'd love to talk to Steve about this one.  Or we're in Russia, and we're thinking about Putin.	



STEVE:  Putin and hacking email and so forth.



LEO:  Hacking and, oh, I'd love to talk to Steve.  I'd love to know what he thinks.  So now I get to find out what Steve thinks about a lot of stuff.  Weren't we - we're going to cover Yahoo; right?



STEVE:  Yes.  In fact, the title of today's show is "Yahoo & Primal Worries."  



LEO:  Oh, whoa, well, sounds deep.



STEVE:  Because a paper was just released which brings into question some assumptions which, 25 years ago, when some of the current technology was put in place, were questioned.  And then there was a little controversy, but it was dismissed.  However, some researchers in France and the university of something in the states, I can't remember what, they've successfully demonstrated an implementation or an exploit of the fear that was originally voiced 25 years ago.  And it's not good.



Of course we have to talk about Yahoo because just, like, could - in fact, there's even some news some people may not have caught up with yet because it's just happened, which is like yet another nail in the coffin.  And it's funny because last week Father Robert and I were discussing this.  And in one of the Q&As that we did, sort of the person posed the question, you know, given what we know, should I move away?  And it was like - and we came down on saying, how could you not?  I mean, if you actually care about security.  I mean, for convenience, if you're there, okay, fine.  But if you truly are giving more than just lip service to security, yeah, you have to move.  Anyway, and so there's more reason to feel that way even than there was last week.



But a lot of stuff is going on.  We're going to talk about this being the October Patch Tuesday, the first one.  This is the one where everything changes.  And I fired up my Win7 machine an hour early to give it a chance to get itself synchronized; and, sure enough, no more batch of patches, just a monolith.  So we're going to talk about that.



There's a $1.5 million bounty for iOS hacks.  And in the coverage of this, there was some interesting commentary about why Android hacks receive less money than iOS hacks.  WhisperSystems had its first bug discovered in attachments for its Signal protocol.  The way they handled it we'll talk about.  An IEEE study that wasn't intended to yield the results it did surprised them, and that's being presented, and we'll talk about the results.  A little bit of Firefox and Chrome news.  The ongoing woes of WoSign drama.  I wanted just to briefly mention the Samsung Note 7, which has been much in the news also.  And then we've got a little bit of errata, a bunch of miscellany.



And then we're going to wind up talking about catching everybody up on the latest Yahoo troubles, and take a look at what this concern is about prime numbers.  As usual, the headlines and the first paragraphs of the press coverage tend to be probably overwrought, which is not to say there isn't a concern.  But this podcast is all about helping our listeners to sort of calibrate these stories and what they actually mean in the real world.  So I think, for 581, another great podcast.



LEO:  Another jam-packed podcast.  I'm disappointed to hear that everything's not settled down since I've been gone.



STEVE:  Well, you know, Father Robert and I were able to do a bunch of Q&As.



LEO:  I'm glad about that, yeah.



STEVE:  Because you and I hadn't been because there was just too much to talk about.  Like every single week was a cornucopia.



LEO:  This Yahoo thing, I can't, I just can't wait to hear what you have to say about it.  All right, Steve.  On with the latest.



STEVE:  So our Picture of the Week on the first page of the show notes is just sort of keeping an eye on what Let's Encrypt is doing.  There was some coverage that was claiming that Let's Encrypt had now become the largest certificate authority on the Internet.  And it's sort of a function of how that's measured because there's numbers of certificates issued.  There are the numbers that are currently in circulation and so forth.  But anyway, this is a graph which shows, maybe for the first half of this year, pretty much an exponential curve.



LEO:  Wow, wow.



STEVE:  Now, from the summer until now, with the exception of a little blip, it's gone sort of linear.  But it's linear at a good clip, like a million certificates every couple months.  So it's clear that...



LEO:  So those numbers on the left, that scale's not labeled, but that's millions.



STEVE:  Those are millions, yes.



LEO:  Wow, wow.



STEVE:  Although I've seen the number six million, so I think this chart must be those currently in use because...



LEO:  Each month, or maybe it's not cumulative, yeah.



STEVE:  Well, the Let's Encrypt certs, also there may have been people experimenting with them, or revoking them, or having short expiration times.  So there's a lot more churn.  Which it makes sense to do because, remember, one of the ideas that we've discussed in the past for improving just the general robustness of the CA system is to shorten the lifetime of certificates.  Right now they're two to three years, typically, depending upon what type of cert.  But what that means is that, if a private key were to escape, the proper solution is revocation.  But we know that the certificate revocation system is badly broken.



So the alternative is to issue very short life certificates so that even a stolen one would self-expire, that is, the signature on it would take it out of service quickly anyway.  The problem is that's not practical when there's a lot of per-certificate issuance overhead.  So the fact that the Let's Encrypt system automates and completely makes that whole process transparent, it means that it's completely feasible to roll or rotate your certificates very frequently, obsoleting them and having the automated system replace them with refreshed and timestamped signatures, but with none of them having a long lifetime.



So that's why it's important to draw the distinction between the total number of certs issued, especially in a model which encourages short lifetime certificates.  Make that separate from how many are actually in use at any given time.  But no matter how you look at it, it's been a smash success.  And in fact, as I will show toward the end of the show, it is arguably this success, and in general the "going dark" problem, which drove the U.S. government to do what we believe it did with Yahoo.  So we'll discuss that.



But it is Patch Tuesday.  And as I mentioned at the top of the show, Microsoft did release a single monolithic bundle.  And so essentially what we're going to get now is what we've traditionally called "rollups," where a bunch of individual patches were rolled up into one.  It is more efficient because many times different patches are containing different versions of the same component.  In Windows, sort of the unit of a component is an EXE, a SYS which is typically a device driver, or a DLL.  And many times, three or four patches in a given month will each be making their own change to the same, to one of the same DLLs.  So you're getting that same DLL four times.



And then the nightmare that I really salute Microsoft for even attempting is how do you allow users to selectively decline individual updates and have, like, everything else still work?  It's amazing to me that they were able to do it for as long as they have, given the complexity of Windows, which is beyond any individual's comprehension at this point.



So what they're saying is they're going to do, essentially, with 7 and 8.1, starting today, what they've been doing with Windows 10, which is, on one hand, you can say taking away user choice.  The flipside is, if there's just one set of updates, it can be more robust, better tested, and probably overall more reliable at the cost of no longer allowing users to pick and choose among them.



This, of course, as we've talked about, was very useful during the whole Get Windows 10 period because a number of the techier users were going in and, every single month, turning off the GWX reattempt to install itself and saying, no, I don't want that.  No, I don't want that.  That kind of thing won't be possible in the future.  You simply won't be able to pick and choose.  So today's update is important.  It sounds weird even to say "today's update" because...



LEO:  Hasn't been one update in years, yeah.



STEVE:  Oh, it's been 18.  You know, we go, oh, my god, it's 18 updates that are fixing 57 different vulnerabilities.  Now it's, okay, it's an update.  There were five zero-day flaws, however, which have been fixed in this.  They're each in IE and Edge, so each of the browsers has one.  There's a zero-day in Microsoft Office.  There's one in the GDI+ module which is exploitable through the web browser.  And then the Internet messaging component of Windows has one.  So, and of course, as we know, zero-day is not just nobody knew about it because typically these are all a surprise.  It's that they learned about it by seeing it in use.  So these are actively being exploited.  So you're going to want to install today's update.



Now, in digging back into this a little bit, I thought it was interesting that what Microsoft has announced is that there will be essentially three monoliths from now on.  There's what they call a "security only" update, which will be a single update containing all new security fixes for that month.  Okay, so that's sort of an incremental - that's still not going back any further, but it's one thing.  So all that's essentially doing is it's removing the granularity.  It's a single update containing all new security fixes for that month.



Then there will be what they're calling in the notes, they said, that is, in their post, a "Security Monthly Quality Rollup."  But I'm looking at my machine, and it calls it "October 2016 Security and Quality Rollup."  Oh, now, here's one for the .NET framework, and then they have "October 2016 Security Monthly Quality Rollup" for Windows 7.  So those are the two.  And then they will be also offering a preview of the monthly quality rollup on the third Tuesday of the month, which is to say next Tuesday they'll be making a preview of what they're planning to offer two weeks later, on the second Tuesday of the next month.



So that's what's going on.  Essentially, users who've never been intimately with Windows Update won't notice any difference.  It'll just be like, okay, you know, update me.  Oh, only one?  Okay, fine.  Those of us who know better realize that they've all been crammed together into a single blob.  I guess I'm of two feelings about it.  It will be very nice in the future for people who want to set up new older versions of the OS because right now these rollups only deal with current fixes.  That is to say, and I mentioned it last week, everybody should make sure their Windows is current by today because then the single blob moves it forward.



But in coming months, Microsoft has stated they intend to reach back further and further in time, eventually all the way back to, for example, in the case of Windows 7, to Service Pack 1, which was the first and only official service pack, and you can get from Microsoft an image of Windows 7 SP1.  And then the idea would be, once the monthly "quality rollup," as they call it, is comprehensive, a new Windows 7 install would be installing the old Windows 7 SP1 image, and then one single blob which would be the most recently issued monthly quality rollup, and you'd be done.



So I think this is good in the long term.  We'll sort of have to see how it plays out.  Again, if there were any problems caused by the granularity that they had traditionally been offering, while we lose that, if we get more stability, I think that's probably a net win for everybody, for Microsoft and for users.



I guess it was last week I saw that the exploit purchasing company Zerodium had tripled the price that it was offering, or the bounty that it was offering for iOS exploits, and doubled the price that it had been offering for Android.  And Dan Goodin of Ars Technica, he had a nice little bit of coverage of this.  He said:  "A controversial broker of security exploits is offering $1.5 million for attacks that work against fully patched iPhones and iPads, a bounty that's triple the size of its previous offering.



"Zerodium also doubled, to $200,000, the amount it will pay for attacks that exploit previously unknown vulnerabilities in Google's competing Android operating system; and the group raised the amount for so-called zero-day exploits in Adobe's Flash media player to $80,000 from $50,000.  After buying the working exploits, the company then sells them to government entities, which then use them to spy on suspected criminals, terrorists, enemies, and other targets."



Dan writes:  "Last year, Zerodium offered $1 million for iOS exploits, up to a total of 3 million."  And it paid it out.  It paid three of those a million dollars each, after which it dropped the price to half a million dollars.  On Thursday of last week Zerodium's founder - and I cannot pronounce his name - Chaouki Bekrar said, "The higher prices are a response to improvements the software makers, Apple and Google in particular, have devised that make their wares considerably harder to compromise."  So that's the good news. 



And then Dan quoted him a little further, explaining the price difference.  He said:  "Prices are directly linked to the difficulty of making a full chain of exploits, and we know that iOS 10 and Android 7 are both much harder to exploit than their previous versions."  Asked why a string of iOS exploits commanded 7.5 times the price of a comparable one for Android,  he said, "That means that iOS 10 chain exploits" - meaning front to back, soup to nuts, drop this on the phone and it just takes over the phone, a chain exploit - "are either 7.5 times harder than Android, or the demand for iOS exploits is 7.5 times higher."  And he said, "The reality is a mix of both."



So as we know, Apple's had a focus on security.  They've implemented much of their solution in the hardware architecture of their device, which is where I think they are able to arguably claim they've managed to really make it more difficult because they've locked so much up into proprietary hardware.  And also that's the phone that high-value targets are using.  And so governments and other agencies willing to pay an incredible amount of money for these things have the money and do.  Wow.



Moxie at WhisperSystems reported the first bug that had been found of this type in the Android implementation - and it's important to say only the Android implementation - of Signal.  And it was a wonderful bug.  That's really the thing that brought it to my attention.



LEO:  A wonderful bug.



STEVE:  It's so perfect.  But get this.  When the Android code retrieves an audio, video, or image attachment, it verifies a cryptographic MAC, as we know, a Message Authentication Code, to ensure that the attachment has not been modified in any way while in transit.  Two guys, security researchers, pointed out that a 32-bit integer was used to represent the attachment's length in that calculation.



Well, okay.  We know what 32 bits is.  That's the size of the IP address space.  That's 4.3 billion.  But that's 4GB.  Which maybe once upon a time was unlikely.  But, you know, it's a large attachment.  But what this means is that, if the attachment size is greater than 4GB, the integer representing the attachment's length wraps back around, starting from a value of zero.  That is, what it really needs is 33 bits, or 34 bits.  Because once you go to all ones, and that is the maximum non-signed scalar value that 32 bits can hold, you add one to that, and the thing goes back to zero.  It wraps around.  That's why we call it a "wrap."



So if an attacker were to hack a Signal server - that is to say, they'd need to establish a man-in-the-middle presence somehow, and so hacking a server is one way to do it - and were to append 4GB of data to a legitimate, for example, 1MB attachment, while it was in transit from one end to the other, the code that verified the integrity of the attachment on the recipient's end would only see that initial pre-appended 1MB of data, the 32-bit value would show a 1MB length, even though it had tried to show a 4GB plus 1MB length.  But because of that 32-bit wrap, the extra 4GB would be hidden, essentially, from it.



So, now, what this means is that it turns out it's difficult to exploit.  The attacker would be forced to always append exactly 4GB, that is, they don't have any choice of the size of what they append.  And Android will separately reject most media attachments that are that large.  But they immediately recognized that this was an oops.  They fixed it, pushed out the fix for Android and noted that exploitation is difficult; but it was wrong, and they have fixed it, and none of the other platforms were affected.  So probably this was just a tiny mistake in the coding or the casting of the size of a value or something.  Who knows what really went on behind the scenes.



I was curious that neither the iOS implementation nor their desktop flavor were affected, only the Android versions.  Oh, and nor were any other consumers of the Signal protocol, for example, like WhatsApp over in Facebook and so forth.  So the blog over on WhisperSystems said this is the first time that anyone has ever found a bug like this in Signal.  So huge thanks to the researchers for helping to further improve the security and stability of the app.  So not a big deal, but WhisperSystems handled it as well as they could.



LEO:  Yeah.  There's no such thing as a bug-free program.



STEVE:  There was an interesting article, and it didn't make it into my notes, but it was the idea of provably correct software.  There are people working on it.  And remember, bugs, you know, we spend half of our time on this podcast talking about mistakes.



LEO:  All security holes are bugs, essentially; right?



STEVE:  Yeah, but it's also math.  And we have seen subtle defects in Intel processors that made lots of news.  There was a famous division error in one of the early Pentium chips that caused spreadsheet flaws, and then you were able to...



LEO:  The 386, yeah.



STEVE:  Exactly.



LEO:  It was like a rounding thing, yeah.



STEVE:  Right, right.  So it is possible that the hardware has a problem.  Again, a bug.  But ultimately it's math.  So, and this is what used - I used to have a bigger problem with this than I do today because 11 years of this podcast has educated me as much as it has all of our listeners about, I don't want to say the futility, but the challenge, certainly.  And where we've done down is that the best we can do is responding as quickly as we can and try not to make mistakes.  But if you do, fix it quickly and openly and move on.



LEO:  Some day it'll be fun to do a show about mathematically provable, provably correct.  Because I can't remember who I had the conversation with.  I think it was on Triangulation.  But they are endeavoring to create languages that are provably correct.  Certainly if you're NASA, and you're launching a rocket that you can't modify once it gets out there, you want to get it as good as you can.



STEVE:  Well, and a perfect example was the cost of the space shuttle's code because it was very little code, and it was - pardon the use of the term - "astronomical."



LEO:  In its potential for screwing up.



STEVE:  Oh, I mean, they absolutely had to get that right.  And so the point is they did.  But with the tools they had at the time, it was pure manpower, and how many eyeballs could look at it.  And so the goal of the whole open source movement was, oh, we're going to have everybody looking at this code.  Well, history demonstrates that four people look at it, three of them who didn't write it, who assume it's correct.  And they kind of, you know, they're tired, and their coffee ran out a few hours ago and, oh, yeah, this looks fine to me.



LEO:  Looks good to me.



STEVE:  And it just goes right past them.



LEO:  But there is a mathematical - there is a field of mathematically provably correct software.



STEVE:  Yes.



LEO:  Which boggles my mind that that even could be such a thing.



STEVE:  Well, we know that every time you add two plus three correctly, you get five.  



LEO:  Right.



STEVE:  No matter, I mean, we got that.  The problem is we haven't figured out how to scale to something way bigger than that and have the same...



LEO:  Given that a program is provable, you're right.



STEVE:  Yeah.  So, and one of the problems is, you know, notice that what's happening with this crazy amount of storage and computation power is suddenly, kind of out of nowhere, AI is in the air again.



LEO:  Yeah, yeah.



STEVE:  I mean, it's like, whoa, how did this happen?  How does this thing actually know what I'm saying?  So my point is that we have had an escalation in power over the last few years.  Well, one of the other ways that could be applied is for this kind of software integrity.  That is, right now we're writing software the way we have for 50 years, where every byte counted - well, okay.  We're not writing it that way anymore.  But still, the idea is it's an individual who's expressing in a non-natural language, algorithmically, what they're trying to get the computer to do.  But there's a language gap, essentially.



Well, one of the other ways we could apply this crazy amount of excess power that we now have is to fixing that language gap, to fixing this problem of what the programmer intends not being expressed correctly to the computer.  And a perfect example is, okay, why is it that on Android that attachment size was 32 bits?  How did that happen?  It would be really interesting to look closely at that.  And we have, because this kind of thing fascinates me, in the past we've looked at exactly how it was that this mistake occurred, where somebody went in, and they had too many nested levels of parentheses, and they just got it wrong.  And only when you really look at it you go, oh, look, these parentheses encompass this.  And so the cast on that expression is done this way here and that way there, and that difference can be exploited.  I mean, we're in the weeds.



And there hasn't been any dramatic change.  There have been some efforts to create more abstraction in the way we express what we want the computer to do.  I would argue that that'll be one of the next things to happen.  At some point in the future, and it's probably a ways away because we know how slowly these things change, the way we program may be very different.  Because it is just math.  We should not be having these problems.  I think it's clear that it's just inertia.  On the other hand, I like to program the way I do.



LEO:  You know, it's that debate of art versus science.  Art is imperfect, and it's a lot more fun for humans.  And I think programming is, in some degree, an art as well as a science.  But that's where the mistakes creep in.



STEVE:  You could argue that, for example, music could be programmed so that every note is precisely hit at exactly the right...



LEO:  Yeah, and you wouldn't enjoy it.



STEVE:  Right.  It loses its warmth and its something ineffable that is there that is valuable.  And I don't know whether tubes actually sound warmer than transistors.  I'd have to get into that one [crosstalk].



LEO:  That's something else.  That's another [crosstalk].  



STEVE:  Okay.  So the IEEE - I'm sorry.  The NIST, the National Institute of Standards & Technology, the NIST conducted a survey where they were not looking for what came out.  And it wasn't a huge survey.  I saw an N=40.  So they interviewed - they gave 40 typical computer users a questionnaire.  But a surprising outcome is being reported and submitted to the IEEE's IT Professional Group.  And that is they identified something known as - and everyone's going to understand this - security fatigue.



And in their own reporting of it, they said, "Security fatigue came oozing out of the questionnaires.  People are tired and fed up with the burden of being made so responsible for their online security."  And when you think about it, that's what we talk about all the time.  When Jenny finally started using LastPass, she's like, oh, my god, how have I - and she was mad that I hadn't told her about it sooner.  You know, "Why didn't you tell me about this sooner?"  And I have another friend who still isn't using it, and he's got crazy passwords.  And I say, "Mark, you're not using LastPass yet?"  "No, no, not yet."



But the point is that, unfortunately, the way the system has evolved is the "solutions," unquote, that have been put into practice so far mostly make the user increasingly responsible for their security.  That's the way the system works at this point.  So in the abstract of their report they wrote:  "Security fatigue has been used to describe experiences with online security.  This study identifies the affective manifestations resulting from decision fatigue and the role it plays in users' security decisions.  A semi-structured interview protocol was used to collect data," and they say N=40.



"Interview questions addressed online activities; computer security perceptions; and the knowledge and use of security icons, tools, and terminology.  Qualitative data techniques were used to code and analyze the data identifying security fatigue and contributing factors, symptoms, and outcomes of fatigue.  Although fatigue was not directly part of the interview protocol, more than half of the participants alluded to fatigue in their interviews.  Participants expressed a sense of resignation, loss of control, fatalism" - just shoot yourself.



LEO:  Throwing up their hands and saying, "I give up."



STEVE:  "Risk minimization" - like, okay, I'm just not going to go there, I'm not going to click on that link, I'm afraid, I don't know what's going to happen.  "And decision avoidance" - it's like, god, no, I just don't want to have to decide, don't make me.  "All characteristics of security fatigue.  The authors found that the security fatigue users experience contributes to their cost-benefit analyses in how to incorporate security practices, and reinforces their ideas of lack of benefit for following security advice."



LEO:  Yeah.  It's not surprising.



STEVE:  No.  No, I'm sure all of our listeners have friends and family who are just like - who just glaze over.



LEO:  We all recognize this, yeah, absolutely, yeah.



STEVE:  Yeah.  It is, it's a pain in the butt the way things are right now.  So anyway, I just thought it was interesting - security fatigue, resignation, loss of control, fatalism.  And it's sad, you know, this is what we've done.  As if http://www. wasn't bad enough.  On top of it all it's like, in the news, 500 million accounts lost by Yahoo and so forth.  Oh.



Anyway, two bits of news about our two favorite browsers.  Someone tweeted me, actually several people did because they know that I'm a heavy tab user, that Firefox is experimenting with native tabs, native side tabs.  It's always, of course, had them across the top.  There's something called Firefox Test Pilot which is where the Mozilla team stages experiments.  Something called Tab Center is one that is being looked at right now which uses native side tabs.  I use an add-on called Tree Style Tab, which also, as its name implies, allows a hierarchy of tabs so that I can group tabs and then close them up so that I don't have to look at actually my 222 currently open tabs. I can see a subset of them.



Also in this Test Pilot at the moment is something called Page Shot, where screenshots are built right into the browser.  And once again I've solved that problem.  I use a really cool Firefox add-on called Screengrab.  And what's slick about it is it grabs the entire web page, not only the visible portion.  And you can tell it which you want.  But normally I'm wanting to grab the entire web page.  And if it's a multipage document or a big scroll-y page, I just, you know, one grab, and I've got the whole thing.  Which is really handy.



And so they're looking at - and I assume that Page Shot would have the same sort of features.  So it may be that they're looking at some of their more popular add-ons and considering moving those features native.  There's something called Min Vid which would be native support for a sticky video window which would remain visible and playing while users browsed other tabs and used the browser.  They're looking at tracking protection being built in; something called Activity Stream, which they say makes it easier for you to go back and find things that you were doing.  This was an interesting one.  The item is called No More 404s, where it auto links the browser to the Wayback Machine.  So if you have a dead link that was once live...



LEO:  Oh, I like that.



STEVE:  Isn't that cool?  Yeah.



LEO:  You get the historical page.



STEVE:  Exactly.  Rather than just saying that link is no longer valid, the browser itself will go tap into the Internet archive and say...



LEO:  Love that.



STEVE:  ...this isn't the current one, but this is the last one that the archive took a snapshot of.  Which I think is very clever.  And then Universal Search, which is their, well, they have a name for their - where you're typing it in, and it's dynamically showing you things.  And so they're...



LEO:  Autocompletion or...



STEVE:  Yeah, that kind of thing.  They call it the happy bar or something.  I don't remember their name for it.  Anyway, so that's good news on the Firefox side, things moving forward.  Chrome has made an announcement about memory which will be a comfort to those who want to use Chrome, but are struggling with the bloat, which many people are talking about.  Oh, that sounds like Trump.  The bloat of memory consumption.



LEO:  I like how you snuck that in there.



STEVE:  So this is due in December.  It'll be Chrome 55.  And what they've done is they've done a major rework of their V8 JavaScript engine for both desktop and mobile.  So users of Chrome on even mobile platforms should see a significantly reduced memory footprint, by as much as 40% on sites such as Reddit, Twitter, and The New York Times, which are large heavy sites.  So a couple more months, with Chrome 55, I think users will notice a dramatic reduction in memory consumption, which is great.



So we've been tracking, and I think you and I must have talked about it, Leo, before your vacation because I know that Robert and I did also, the ongoing woes of WoSign.  So today - it's in the past because it was in London.  So in London time Tuesday, today, representatives of WoSign, StartCom, and WoSign's parent, because WoSign is actually a subsidiary of - I guess I pronounce this Qihoo, Q-I-H-O-O, 360?  I'm not good with those Chinese names.



But anyway, they all met in London to discuss this problem because we've talked about and we've shared on the podcast, I think this is a really nice, a perfect example of the problem that a web browser has, due to the power of their decisions about which certificate authorities to support and which not to.  I mean, it is truly life and death for a company whether their root keys are available to the browsers that users use because, if that's not the case, none of their certificates are going to be trusted.



So what Mozilla was proposing and is apparently continuing to do is they would honor previously signed certificates, but essentially give WoSign a timeout for a year, saying we are going to no longer honor certificates signed after a certain date, and we will revisit this a year from now.  So this, of course, got WoSign's attention and the parent's attention.



And remember that, just to remind our users because we've been talking about this now from time to time, we've discussed several of the problems that the WoSign website certificate issuing system had.  One was that, remember, users didn't have to use port 80 and 443.  They were able to name the port where they wanted to provide authentication, which in retrospect was just crazy because it's only the ports below 1024 which the kernel has control over.  And running processes are able to open ports above 1024.  So that would mean that a non-privileged process running on a server within a domain could open up its own port where it runs a web server and then obtain a certificate for the privileged real domain that it's running on.  Bad idea.



And then there was one where, if you obtained a certificate for a subdomain, their system allowed you to also get the parent domain.  So charliebrown.github.com, you could demonstrate ownership of that because that was your subdomain on GitHub.  But WoSign would give you a certificate for GitHub.com, which everyone thought was a bad idea, too.



LEO:  Yes.



STEVE:  So, yeah, not good.  So what's happened is - and it was a fascinating read.  I have the link in the show notes for anyone who's interested.  They finally generated a full disclosure document.  And it's revealing.  First of all, it demonstrates, I mean, one of the things that Mozilla took issue with was not only did WoSign not acknowledge these problems, did not report them when they were informed of them to headquarters essentially, to the CA Browser Forum group, where the baseline requirements under which they are entitled to be trusted, they were just in violation all over the place. 



Then there was a sense of "You're only telling us about things we tell you about."  But you've got flaws in your system which may have been exploited, we don't know how many more times.  We can't trust you.  And again, if there's a weakness in the CA system, it's that it is about trust.  And so the players have to be trustworthy in order for any of this to make sense.  And of course the other weakness is that it's a trust anyone, that is, any WoSign certificate for any domain, unless the certificate is pinned, as Google's tend to be, will be trusted.



So reading through this document, it turns out there were even more problems.  First of all, most of what they explained were just sloppy coding bugs.  Sometimes it was the person who wrote the code didn't understand the rules, was their explanation.  They had another one, which was news to me, we hadn't covered before, where they wrote:  "This is another system bug that, when the subscriber finished the domain control validation, he/she can use a special professional method" - whatever that is - "to add other unvalidated domain to the order.  Then our system issued the certificate including all domains in the order."  So they're saying...



LEO:  Oh.



STEVE:  You prove ownership of one domain.



LEO:  And you get them all.



STEVE:  So now you get the green flag, and it says, "Then you use the special professional method."



LEO:  Special professional method, exactly.



STEVE:  Yeah.  Maybe that's the advanced link, the advanced button.  And then, you know, are there any other domains you'd like to put in the certificate while you're at it?  Oh.



LEO:  Mm-hmm, yeah, all of them.



STEVE:  Yeah.  Give me all of them.  What have you got?  Oh, goodness.  And then there was - this one was just - I had to read this a couple times and then dig in a little to make sure.  They were actually putting ads in their certificates.



LEO:  What?



STEVE:  They had a buy, B-U-Y, dot wosign.com advertising link.



LEO:  In the cert?



STEVE:  In the cert.



LEO:  It's like you examine the cert, and if you'd like more of these special professional services, buy.wosign.com.  Wow.



STEVE:  So the CEO of WoSign, how did they put it, has had his responsibilities changed.



LEO:  Oh.  Wow.  Oh.



STEVE:  Yes.  He's out.  WoSign and StartCom are divorcing.  Turns out that having one entity issuing certificates under multiple names is also against the baseline requirements.  Which they didn't worry about at the time.  So now they're splitting up, and they're each going to have separate CEOs and management teams.  They're demerging.



LEO:  It's a Chinese company?



STEVE:  Yeah.  And anyway, so this is the next stage.  I don't, I mean, the meeting was very good.  The WoSign people and StartCom and the parent, their...



LEO:  Their response was basically, we didn't read the manual.  But now we know, so we won't do that again.



STEVE:  But we really liked making money.



LEO:  We didn't read the manual.



STEVE:  Selling these certificates.



LEO:  Wow.



STEVE:  Yeah.



LEO:  So that is kind of a flaw in the process.



STEVE:  Well, yeah.  It's a perfect example of what can go wrong with a system based on trust.  It's only trust.



LEO:  Yeah.  So you just apply and say I want to be a CA, and they say okay?



STEVE:  Yeah, I mean, you have to...



LEO:  Is there some sort of vetting?



STEVE:  Oh, yeah, yeah.  You have to jump through hoops and demonstrate that you're able, that you have the infrastructure to support the certificates and so on.  The problem is that there are so many of them.  And again, the dilemma is that none of the browser vendors want to be the heavies.  They don't want to say, you know, we don't like the color paint on your building.



LEO:  Right.  Just because you're in Hong Kong and you're the Post Office doesn't mean...



STEVE:  Right.



LEO:  Right.  I understand that.  They shouldn't.  That's right.  Speaking of which, when I was gone, did you talk about the Department of Commerce giving up, ceding control of IANA and ICANN?



STEVE:  Yeah.  



LEO:  You did.



STEVE:  Yeah.



LEO:  And I presume that your conclusion, I mean, it happened October 1st, and the Internet's still working.  So I presume your conclusion was it's okay.



STEVE:  Yes.



LEO:  Yes.



STEVE:  Yes.  Essentially, I understand the argument for why give up something we don't have to.  Isn't the U.S. a better manager of this than an international body?  But the fact is it's already international.  All of the key management and root signing and everything, it's already being done in a multinational fashion.



LEO:  It was anachronistic to have the Department of Commerce.  And they reasonably asked for assurances that no other government would then step in.



STEVE:  Right.



LEO:  Right.  So as long as it's not a government, and it's the stakeholders that are responsible for this, and the engineers and so forth, that's the way it should be, I think.



STEVE:  Well, and we did, we really drilled down into it.



LEO:  Good.



STEVE:  And what it actually was.  It was a contract which ICANN had with a division of the U.S. government to perform some of the management duties, and the contract was expiring.  So it was simply that it was not going to be renewed, that is, ICANN had been subcontracting.  See, because ICANN is already multinational.



LEO:  Right.



STEVE:  It had been subcontracting a part of its job to an entity that was in the U.S.  And they said, okay, we're not going to renew the contract.



LEO:  You and I are old enough to remember that it was a professor at USC that ran the whole thing for years.  Jon Postel did the whole thing.



STEVE:  Yes, and his name is all over the early RFCs, when I was writing the early Internet protocols.  It's like, ah.



LEO:  He's passed away since.  Otherwise I'd get him on in a heartbeat for Triangulation.  But it was such an ad hoc thing all around.  And it's just, you know, it's just...



STEVE:  Well, and as we know, it has functionally scaled beyond anyone's wildest dreams.  And that's the problem.  



LEO:  I only bring it up because of the WoSign thing, which is that it is all kind of ad hoc.  And so, you know, but stuff happens.



STEVE:  Well, and you'll remember the podcast where, when we came on the podcast, we began the podcast, and I said, "Leo, I just looked inside my XP's" - and that's when XP was new - "my XP's CA list."



LEO:  I remember this.  Who's the Hong Kong Post Office?



STEVE:  There's 400 things in there.  There used to be seven.  What happened?  Oh.



LEO:  Yeah, yeah.  That's all right.  It's working.  It's working.  And the thing is, it's self-healing.  Right?  It's not like Russia could come along and say, "Okay, the Internet, it's ours.  We're taking it now."



STEVE:  Right.  Yeah.  The only thing that they can do is play with traffic at their border.



LEO:  With BGP and mess stuff up, yeah.



STEVE:  Yeah.  And if they started doing that, then their broadcasts would get blocked by...



LEO:  Yeah, we'd cut them off, yeah.



STEVE:  Yeah.  I mean, so it's just - it's, I mean, essentially people, you know, individual dictators and, well, and non-dictatorial governments would love to have control.  But it's too big for them to have control.



LEO:  They can't.  It's like controlling the ocean.  Nobody owns the ocean.



STEVE:  Yeah.  And what's interesting is, unlike electricity, where you say, okay, well, yeah, electricity is a local delivery system, the value of the Internet is that it is global.  And so if you cut yourself off from the rest of the world, it would be you that suffered.



LEO:  You've got the Russia Net.



STEVE:  Yeah, the Russki Net.



LEO:  Russki Net.



STEVE:  So I did just want to mention, in case there was anyone who didn't know, that there have been a couple reports which are still being researched more deeply, that the replaced Samsung Note 7 phones, or a couple, like three of them, I think, so far, may still have a problem.  And so Samsung has stopped - they've halted production of the Note 7.  And it may just never come back.



And reading between the lines, I'm wondering if this wasn't more of a firmware problem than a battery chemistry problem because everybody knows about the Hoverboards that were exploding.  This is the same technology.  We take for granted the way batteries work.  But there is a huge amount of energy that is chemically stored in a battery.  And what we want it to do is to come out in a nice, even flow of electron pressure from its two connections.  It can come out as an all-at-once chemical flow.



LEO:  Right. 



STEVE:  And that's not what we want.



LEO:  That's an exact analog to the gas tank in your car.



STEVE:  Yeah.



LEO:  Anything that stores energy, a considerable amount of energy, is potentially explosive if it comes out too fast.



STEVE:  Right, right.  And that, of course, is the problem, the potential problem with supercapacitors is we like them because we can charge them fast, and they have no chemical-limited cycle life.  The problem is there's still enough energy to push your car - in a big supercapacitor system - to push your car for hundreds of miles.  That's an amazing amount of energy.  And if instead it is somehow released all at once, you don't want to be anywhere in the neighborhood when that happens.



LEO:  Yeah, a gas explosion.



STEVE:  So very much like a full tank of gas exploding.



LEO:  There have been, let's not forget, cases where gas tanks have been not safe.  The Pinto; right?



STEVE:  Yup.



LEO:  I mean, this is just more like that.  I feel bad for Samsung because I think the Note 7 is dead.



STEVE:  I think it is.  And maybe we need, I mean, I hope there are lessons that come out of this.  If there's something that can be learned about, like, what it is in the battery chemistry or the charging algorithm that is weakening the battery so that it can be prevented.  That would be good.  I assume that the problem with the Hoverboards was just poor quality, as absolutely low cost as possible, just pump a gazillion out of these before Christmas.



LEO:  I think WoSign was making the batteries, and they just forgot to read the manual.  The thing that's scary, and this was true also of the Hoverboards, is it wasn't just when the Note 7's were being charged.  They could be in your pocket, and they would just spontaneously erupt.  And that's really scary.



STEVE:  Yeah.  Well, and so what could have happened is that there was an overcharging which weakened the electrolyte, essentially, and caused the problem.



LEO:  Oh.  So it happened during charging, but the impact was felt later.



STEVE:  Correct.  Well, and we've also noticed how warm the batteries get when they're in use.  That's not just the processor burning the juice.  It's because batteries have what's known as an internal resistance.  And so when you move a lot of energy across that internal resistance, what gets hot when you run current through a resistor, we call those "heaters."  We all remember the old-school red coil winding heaters.



LEO:  Right, it's how your toaster works, yeah.



STEVE:  Right.  And so the battery itself is made hot when it is in use and discharging.  And so that could just be the straw that broke the battery's back.



LEO:  That actually makes sense because Samsung's advice is turn it off.



STEVE:  Right. 



LEO:  And apparently they are safe if they're not on.  So it's not a physical hazard.  Yeah, that makes a lot more sense.  Although XDA Developers' site had a picture today of the box Samsung will send consumers if consumers want to turn their phone in.  It's a fireproof box.  It includes gloves for you to wear.  And then it says in bold letters on the front, "Contains potentially explosive lithium-ion battery.  Not to be put on an airplane." 



STEVE:  How do you get to them?  You put it on a boat?



LEO:  By truck.  Slow boat.



STEVE:  Wow.



LEO:  So, I mean, I'm glad they're taking it seriously.  They should.



STEVE:  You know, and what's so sad is, as you have noted, it is a very nice device.  It's probable... 



LEO:  It's wonderful.  So sad.



STEVE:  It's probable that the majority of them would never have a problem.



LEO:  Right.



STEVE:  But who can take that chance?



LEO:  Right.  It's one in 30,000 or something like that.  But that's too big a chance; right.



STEVE:  I got a nice little bit of errata from a Peter Brumby, who said:  "Hi, Steve.  Love the podcast and SpinRite.  It is the first and probably only time I will be able to contribute to the podcast."  Well, but he doesn't know that.  He says:  "In SN-580," so that was last week, "you said you submitted grc.com and www.grc.com to the HSTS preload list.  However, you can only submit the base domain, grc.com.  The HSTS preload list is then applied to the base domain and all its subdomains, including www.  It's a very minor point, but could mess up a non-HTTPS subdomain if you weren't aware.  Keep up the good work."



So Peter, thank you.  What's actually happened is there's been some evolution of that.  I did originally submit both because, when I did it, it was before there was a list.  This was just to Google themselves.  Google was the first browser to say we're going to do, very much as they'd had for themselves, we're going to make this available to third-party sites.  And what they wanted was explicit domain names.  Since then, it's been generalized.



And I did go poke around the list and verify what Peter said, which is true, which is now it's only the base domain.  The reason given was two things.  One is that the way cookies are handled, there could be some confusion, that is, with cookie security, if subdomain security was allowed to differ from the base domain security.  And the second is the size of the list.  So many people are wanting in that they have said, okay, look, we don't want your 27 subdomains.  We don't have room on the list.  So we're just going to make it all or nothing.  If you want to be on the list, you've got to have your entire site secure.  Which is much easier to curate anyway.  So thank you for giving me the chance to update everybody, Peter.



LEO:  Continue on with miscellany.  We're going to talk about Yahoo in a minute.



STEVE:  We will.  And about the problem with primes.  I just did want to check in about "Westworld."



LEO:  Oh.



STEVE:  Wow.



LEO:  You know, it's hard to live up to the hype; right?



STEVE:  It is.



LEO:  And we've been waiting for this all summer.



STEVE:  Yes.



LEO:  And it was highly hyped.  And yet I think it did.



STEVE:  I am enraptured.  IMDB has given it a 9.2.



LEO:  Wow.



STEVE:  Which is, like, you know, to get 9.2, everybody has to either say 9 or 10, essentially.  It is visually wonderful.  Anyway, it's science fiction, robots...



LEO:  Ed Harris.  What could go wrong; right?



STEVE:  What could go wrong?



LEO:  Now, you said you had one quibble with it.  Now, I don't want any spoilers here.



STEVE:  No, this is not a spoiler.  And you know I won't do spoils.  And anyone watching the first episode would - it began to bother me in the first one, and then it really bothered me last Sunday, the second one.  And that's the one-sidedness of the fact that the humans can't get shot.  And but you can shoot the robots.



LEO:  Well, what kind of amusement park would it be if the customers could get hurt?



STEVE:  Well, it would be more interesting.



LEO:  Well, it would be.



STEVE:  I mean...



LEO:  But not for the customers.



STEVE:  The robots could be bad shots.  Or maybe you get drugged or stunned or you lose a week of your life, you're in a coma for a week or something.  I don't know.  But when you see them, it's like, you know, a guy just standing there being shot from all sides and ignoring them.  It's like, okay, this is a problem.  So that's the only thing that bothers me is that, I mean...



LEO:  That doesn't bother me at all.



STEVE:  Okay.



LEO:  I mean, first of all, it's not central to what is clearly developing as the point of it.



STEVE:  Oh, well, and we should say that there are multiple plot lines going on, too.



LEO:  It's really good that way.  And because you have the amusement - look, we're not saying anything people don't know because it's based on that 1973 Yul Brynner movie, "Westworld," which was an amusement park where the cowboys were robots, the humans would go there, but what happens if everything goes wrong kind of a scenario.  But this is going to be, I think, a lot deeper than that, and very interesting.  And because you have these amusement park plots, as well as the stories that the guests participate in, as well as the subplots, it's multilayered.  I think it's going to [crosstalk].



STEVE:  Well, yes.  And the whole exploration of what it means to be "real," unquote, that is, versus, you know, like does Dolores, is that her name, does she know that she's...



LEO:  Right, what does she know?



STEVE:  Some of them apparently don't know.



LEO:  Right.



STEVE:  Like they're surprised when they get shot.



LEO:  Every time.  Over and over.



STEVE:  And they think they're doing their job.  So, yeah, it's rich.  If anyone has access to HBO, you should not be missing this.  It's two episodes in so far.



LEO:  Yeah.  And it's really about artificial intelligence.  This is just one of many, many, many stories we're going to encounter over the next few years as we grapple as humans with this emergence of these artificially intelligent machines.



STEVE:  And the special effects, the visual effects, like the 3D printing, it really - it goes a long way...



LEO:  Oh, isn't that cool?  Yeah.



STEVE:  ...to sell, it sells you on the idea that we don't know when in the future this is, but it looks real.  I mean, they're, like, they're convincing you that somehow - I'm just wondering, what is the power source for these things?  I'm trying to reverse-engineer them.  And it's like, they're not going to tell us.  But anyway, I just - it's delicious.



LEO:  It is.  It's really fun.



STEVE:  And I'm less excited about "Timeless."



LEO:  Oh, I haven't seen it yet.



STEVE:  I was hoping.  It's had two episodes.  The second one was last night, which I have not seen.  But, I mean, I think it's going to immediately fall into being just sort of a serial, like chasing around to famous moments in time, and cops and robbers and stuff.  So it's like, eh.  I mean, visually it looks fun.  They're developing some interesting storyline.  But I'm not sure.



LEO:  That's pretty much what Hollywood does with time travel is they just say, oh, it's really a way to talk about different storylines.



STEVE:  Right.  Well, and that's what Star Trek was, too.  As I mentioned once before, for my birthday one year, when I had a company with lots of employees, one of them pretended to be my agent and obtained the Star Trek scriptwriter's kit from Paramount.



LEO:  Oh, neat.



STEVE:  And she had to say, yes, I'm Steve Gibson's agent, and he writes a column in InfoWorld, and he's interested in doing some - and I never had the time or real interest.  But the point is that this was something - this was a behind-the-scenes look that I had never had before.  And I did read through this writers' guide.  And they made it very clear that this is not - this series - oh, and this was the Next Generation period.



So they said, you know, this is not about tractor beams and photon torpedoes and warp drives.  This is about human drama, set in this period.  So be careful you don't write an episode that is about technology because we have no interest in that.  We want to write about people set in these situations.  And so I thought it was interesting that even Star Trek was basically just, you know - well, and I think that's what the appeal was.  People could, even non-sci-fi people could relate to the dilemmas that were being set up in that franchise.



LEO:  I think any good science fiction has to be about people, not tractor beams.



STEVE:  Right.  In fact...



LEO:  That's why we like Peter F. Hamilton; right?



STEVE:  Yes.  And I was just going to say, I am, as I mentioned months ago, I've decided, because the Lost Fleet series had been finished, the second block was the Beyond the Frontier.  And so I thought, okay, it's been a long time since I read the first bunch.  So I started from the beginning.  And that was like 11 books ago.  And I'm - whew.  The good news - and then "A Night Without Stars" has been released, which is the sequel to the - what was the first one?  I can't remember now.  Oh, The Fallers.



LEO:  Oh, that's out, that's right, the new Peter F. Hamilton.  I know.  Oh, boy.



STEVE:  And of course I can't start until I finish the Lost Fleet.  But the Lost Fleet has turned into politics, which many people find annoying and boring.  I am a junkie for politics, the human drama, the interaction, the interplay.  So I'm on the last book of that.  And then "A Night Without Stars."  So I did want to mention to everyone that that second book, that finishes - and it's funny, I was listening to you.  There's, you know, trilogy is such a nice word.



LEO:  What is it?  Biology.  What is it?



STEVE:  Exactly.



LEO:  Bilogy.



STEVE:  Yes, duopoly?  No, it's...



LEO:  There's no word.



STEVE:  There isn't.



LEO:  There must be a word.



STEVE:  You know, you could say the sequel; but it's really not a sequel, it's the second half.



LEO:  It's a two-part book.



STEVE:  We know what a trilogy is.  There's got to be - anyway.  



LEO:  Good point.



STEVE:  Someone will know what it is.



LEO:  Yup.



STEVE:  And I did, I had something that just meant so much to me that I wanted to share.  Not about SpinRite, but about the Healthy Sleep Formula.  And I have a lot of these that I've not been sharing.



LEO:  Oh, I know which one you're going to share because I just read it on the page.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  So this is from a Janice Morse, who tweeted me, @sassyjan1209.  She said:  "Hi, Steve.  My son listens to your podcast.  I have not had a good night's sleep since 1978.  I have been diagnosed with all three forms of sleep apnea.  I have had eight sleep studies.  The conclusion is that I never hit REM sleep.  I live being exhausted at all times."



LEO:  Horrible.



STEVE:  "I wake up exhausted and shook-up from nightmares.  My son brought over the niacinamide and melatonin.  The first night I only got up once, instead of the usual every 25 minutes, with a headache.  But I gave it another night; and, wow, not only did I get up only once, but I woke up rested, ready to go for the day, and had a pleasant dream.  Wow.  Now I've had my fifth successful night in a row.  And I'm not only looking forward to going to bed, my entire demeanor has changed.  I am so excited.  If I continue to respond to these natural remedies, this is a life changer.  Thank you.  I will pray that this information gets out to more sufferers.  I certainly will do my best.  Janice Morse."



And so I replied, and I thanked her for her tweet, and I told her how happy I was that this had worked for her.  And I asked her if I could share her feedback publicly.  And she wrote back:  "Absolutely, use it.  I have never imagined I would ever have energy and happiness.  I had no idea what lack of sleep was actually costing me.  I am giddy with hope."  So as people who have followed this know, the only problem that we've had has been availability of the components because enough people are interested and listen to this podcast and have been curious that, every time I post links to these things, the online suppliers sell out.



The good news is the niacinamide has been back since the beginning of the month - or, wait, the beginning, yes, of the month.  And the oleamide, which you asked me before, Leo, whether it was necessary.  For some people it is.  I need that third ingredient which, as I mentioned once, is a natural substance that's endogenous to us, which some researchers at Scripps Research discovered when they kept cats awake longer than they wanted to be.  



LEO:  Oh, that's scary.  



STEVE:  Which tends to build up and made them sleepy.  So it is sort of a natural make-you-sleepy stuff.  But some people are just fine with only the first two, niacinamide and melatonin.  I need the second.  Another insomniac friend of mine needs - I mean need the third.  Another insomniac friend of mine needs the third.  So if you do, it's available also now.  And I had a really good communication with the people who make it, and they said they will endeavor to keep it in stock.



LEO:  Yeah.  It's good for them.  Man, this is...



STEVE:  I haven't pushed anybody to provide feedback.  I've just - so I've been getting it sporadically.  The problem is, it just hasn't been practical for people to obtain what they needed in order to experiment with it.  Now it is.  So I just did want - I wanted to put it back on people's radar, now that all the pieces are there.  A couple months from now I'll make an explicit request for, you know, let me - I'd like to put together a little testimonials page, just things like Janice's feedback, to encourage people to give this a shot because a lot of people have a problem, I included.



LEO:  I prefer not to take something on a regular basis.  But it's nice to have around as a kind of less intrusive way of easing into sleep.



STEVE:  Yes, I would say, if you don't need it, that's great.  I also felt I could totally relate to her mentioning of feeling, like, excited about going to bed.  Instead of just, after a while, you just think, okay...



LEO:  Instead of dread.



STEVE:  Yes, exactly.  You just dread the hours you're going to spend wanting to be asleep, but not being asleep.  And this just - that's just gone now.  It's just like, okay, I'm going to go to sleep and sleep through the night.  And get up, you know, a couple times, maybe, to empty a bladder, but then right back to sleep again.



And lastly, believe it or not, there is a SQRL song.



LEO:  Oh, you're not real on the Internet until there's a song.



STEVE:  I'm not singing it.  But I got a DM from a listener who is a songwriter, and he wanted to make his contribution.  So he sent me the lyrics, which I posted over in the SQRL newsgroup yesterday.  And so he's working on the song.  And in fact, I don't even know it's a he.  The handle on his Twitter didn't make that clear.  But in any event, at some point we'll probably have a link to the SQRL song on the SQRL pages.



And I did have a quick SpinRite anecdote to share, also through a tweet on the 10th.  Someone who - I guess that's "Enomaly," 3n0m41y?



LEO:  Oh, how fun.



STEVE:  So I think that's Enomaly.  Anyway, he said:  "So yet again SpinRite saves the day for me.  Had an old drive with baby pictures on it.  Would not read at all.  Knew that if I'm not able to recover pictures, wife will put me out with the trash."



LEO:  Oh, oh, oh.



STEVE:  He says, parens:  "(Kidding).  Pulled out my trusty copy of SpinRite; and, on Level 2, it fixed the drive.  Now I have all pictures back.  Thanks for an awesome product.  Just sent you a Yabba Dabba Doo for another copy because you saved the day."  And I replied, I said, "Wow, well, thank you for your generosity.  That's above and beyond."  But so mostly I just thanked him for letting me share this with everybody.



LEO:  And from - oh, go ahead.



STEVE:  And Leo, just because you missed this, in case this ever comes up, we have verified, and this was two different instances, I think it was, during your vacation, that people have used SpinRite to repair their phones.



LEO:  Oh.



STEVE:  If the phone can be put into a mass storage mode, and in this case it was done with, not Virtual Drive.  I can't think of the name of it.  It's one of the VM tools.



LEO:  VMware or Virtual Box you're thinking of.



STEVE:  Virtual Box, yes, Virtual Box.



LEO:  That's the free one from Oracle, yeah.



STEVE:  Yes.  Yeah, it was done with Virtual Box.  The drive could be put into mass storage mode.  SpinRite saw it, ran a Level 2 on it, and fixed the problems.  The phone is working much better now than it was before.  And Father Robert had that same problem on one of his phones.



LEO:  Nice.  That's good to know.



STEVE:  So, yeah.



LEO:  Good little tool.  From Stack Exchange comes, well, an answer to the question of what do you call a two-book series.  It's not a trilogy.  It's not a dilogy.  Although there is a Greek word "dilogy."  Duology is one proposed, but that's a neologism.  Dilogy is a Greek word, but it means the use of an ambiguous or equivocal expression.  So I don't think that's really quite right.  There's an author, Dan Simmons, who writes diptychs, stories published in two halves.  The author of this is obviously quite literate.  It's on Stack Exchange.  In fact, I googled, "What do you call a two-book series?"  And there's lots of answers out there.



STEVE:  But none of them sound very good.



LEO:  None of them sound very good at all.  Diptych.  An epic cycle.



STEVE:  "Diptych" sounds like something you go to the doctor for.  



LEO:  Diptych doesn't sound good.  A saga, perhaps?  And also the author points out that "Lord of the Rings," for instance, which often appears in three volumes, isn't a trilogy.  It's a novel that's divided into three parts, sometimes by the publisher, sometimes more.  So a series of three may not be a trilogy.



STEVE:  So it might - so the idea of a trilogy, it's like three interconnected, but each individually complete, stories.



LEO:  Right.  Or it might be a three-part serial.  You know, it doesn't - so, yeah, so we'd have to ask Peter F. Hamilton what his intent was.  Diptychs, dilogies, duologies, series, cycles, and sagas is this answer from Stack Exchange.  And the question on Stack Exchange was, "A series of three is a trilogy; a series of two is blank."  This is apparently not an uncommon question, if you google it.  By the way, just for complete...



STEVE:  It's funny, one of the things that I've been wondering in this era of electronic books is, if someone's creating a book series, why is it that the 11th book in the series has to go back and tell you everything of the back story that has been established in the first 10 books?  Who...



LEO:  Like somebody would just pick up Book 11 and start there.



STEVE:  Precisely my point.  Who is going to, like, oh, look, I've got this at the used bookstore, and I don't know who the character is.  Well, that's his fault for, like, not getting the first one.  They're all available now.



LEO:  I agree.



STEVE:  So I don't want to read, now I'm on the 11th cycle of what the situation is, and I've read it 11 times, and I'm thinking, please don't.  Let's move on.  Because I'm just thinking, today, why quickly try to recount what's gone on?



LEO:  Well, in this day of, you know, the same thing's happening with TV shows in this day of binge watching.  The old "Previously on L.A. Law" has - it's still around.  I notice "Westworld" is doing it.  But "Stranger Things" did not.



STEVE:  No.  And I would notice, though, that sometimes in a long-running series what they're consciously doing is reminding you...



LEO:  Remember 18 episodes ago when the Kingslayer slit that person's throat?  Well, now you'll understand why he's back.



STEVE:  Right. 



LEO:  I hate that.  "Game of Thrones" does that every single time.  Yeah, because you're watching "Game of Thrones," you go, who the hell was that?  What's he doing here?



STEVE:  Yes.



LEO:  Previously, on "Game of Thrones..."



STEVE:  And so sometimes you'll need a little bit of a conversation from three months ago.  And then something, and it's like, oh.  So I'm understanding that they're, like, trying to give us a little bit of, like, crib notes for, like...



LEO:  Memory jog, yeah.



STEVE:  Yeah.



LEO:  Yeah, sometimes you really need it.  I think maybe it's the Netflix originals that aren't doing that so much.  I'm trying to remember if "House of Cards" did it.  I don't think it did.



STEVE:  We're in the final - we're coming into the last cycle of "Game of Thrones"; right?  This is it, finally?



LEO:  Thank god, yes. 



STEVE:  I know.  Exactly.



LEO:  It's almost, at this point, it's like a forced march.  I feel like I can't not watch it.  I came this far.  But at the same time I'm not looking forward to it.



STEVE:  No, well, it's like how I am with Lost Fleet.  I've got to finish because otherwise I'll never know.  But I can't wait to switch to Peter Hamilton and get back to that because that's just joyous.



LEO:  Yeah.  That's really true.  When you get a really long series, sometimes it's just - you're slogging at some point, just for completeness.  All right.  Now we continue on.  Let's talk about Yahoo and prime numbers.



STEVE:  Yeah.  Speaking of paying the expenses.



LEO:  Uh-oh.



STEVE:  Oh, boy.  You're not - okay.  The last shoe to drop here, no one's going to believe.  But first, just to rewind a little bit, we know that back two years ago Yahoo was aware of a massive breach.



LEO:  Yeah.  That pissed me off.  Two years ago.



STEVE:  Yes.  Which they did not confess, which they did not warn their users of.



LEO:  Shocking.  Shocking.



STEVE:  Which is incredibly irresponsible.  So that was one of the obvious things of concern when a user is saying, should I stay with them or not?  It's like, okay, what would it take for you to leave?  If they will lose all of their user accounts, be aware of it, but decide, oh, that will hurt our reputation, so we're not going to tell anybody.  Again, I understand why that's the case.  But what we see on this podcast over and over and over is that the best thing anyone can do for their reputation, because everyone can make a mistake, is to say, this is what happened.  We fixed it immediately.  And we're taking responsibility for it and hope you appreciate that.  So maybe that requires some sophistication.  I don't know.  I just - so, okay.  So that's the first thing.



Then comes the news which Reuters dropped about a week ago, that Yahoo had been, for about the first half year of last year, from January through June of 2015, secretly scanning all customer emails for U.S. intelligence.  They reported that Yahoo complied with an order received from the U.S. government to search all of its users' incoming emails in real time.  The EFF in covering this said:  "There's still much that we don't know at this point; but, if the report is accurate, it represents a new and dangerous expansion of the government's mass surveillance techniques."



The EFF wrote:  "This is the first public indication that the government has compelled a U.S.-based email provider - as opposed to an Internet-backbone provider - to conduct surveillance against all its customers in real time."  And then in quoting from the EFF I interjected my own note, and that is that this, of course, is the logical outcome of the going dark problem, where now the majority of the traffic that's flowing across the Internet is strongly encrypted.



So in this new environment, the endpoints where traffic is both concentrated and decrypted is the place to which mass surveillance must now move.  And our listeners will remember that this was why I'm becoming more bullish on individuals creating their own OpenVPN endpoints at home, rather than using a central service, because that's, as I said then, that's another concentration point where traffic is decrypted and massively available.  So it is obviously foreseeable that there would be packet capture going on there.



But the EFF continues:  "In attempting to justify its warrantless surveillance under Section 702 of the FISA Amendments Act" - including the other two programs that have been covered before, Upstream and PRISM, that we discussed extensively - "the government has claimed that these programs only 'target' foreigners outside the U.S. and thus do not implicate American citizens' constitutional rights.  Here, however, the government seems to have dispensed with that dubious facade by intentionally engaging in mass surveillance of purely domestic communications involving millions of Yahoo users.



"The Reuters story explains that Yahoo had to build new capabilities to comply with the government's demands, and that that new code may have itself opened up new security vulnerabilities for Yahoo and its users."  And I'll explain that in a second.  "The security personnel inside Yahoo who discovered this previously unknown software described it as buggy, poorly written, and rootkit-like in nature."



And then finally the EFF concludes:  "We read about new data breaches and attempts to compromise the security of Internet-connected systems on a seemingly daily basis.  Yet this story is another example of how the government continues to take actions that have serious potential for collateral effects on everyday users."



So, okay.  What happened?  The security team in Yahoo, which by the way has the, I would call it "complimentary" nickname, but it was not regarded that way.  They were known as "The Paranoids" because they were always saying to the rest of management, we need to do this, we need to do that, we need to - and so unfortunately they just got labeled "paranoid."  So those guys...



LEO:  Gee, I wonder who else I know might be labeled "paranoid" for their overarching concern about security.  Hmm.  Stamos was very good.  I think he was very good, and I think they had a good security team.



STEVE:  Yes.  I completely agree.  So a small group in the security group under Stamos, Alex Stamos, discovered this.  They believed it to be rootkit malware that somehow got into their systems through a malicious entry point.  The discovery was escalated several levels until it reached Alex Stamos's desk, who at the time, he's now at Facebook, but he was the head of Yahoo security.  He researched it within the rest of upper Yahoo management, discovered or learned, he himself learned that it had been deliberately planted, without knowledge of Yahoo's security people, into Yahoo's servers by others within Yahoo.  And under orders the incident was closed, and all further pursuit of the case was immediately suppressed.



So that's the way Yahoo handled this.  It is believed, as Reuters reported, to have been done due to a secret order from the U.S. government.  Now, there has been some recently enacted legislation which makes disclosure of this possible, and open speech advocates are pushing for clarity and visibility on this specific matter.  So we may get a little more news about this in the future.



So, okay.  So then the final piece.  It's hard to believe.  As of the beginning of this month, Yahoo has disabled automatic email forwarding for their service.  Where it used to be, when a user tries to enable forwarding, they get the notice that forwarding is currently under development, even though it's been in place for 15 years.  Existing forwarding is being honored.  But no one is now allowed to establish new forwarding for email coming into their Yahoo accounts.  And of course it's transparent as to why because the upshot of all of this, of the news of all of this misbehavior, is people want to leave.  Well, the way you leave is you go create a new email account at another provider.  And then you set up forwarding on your old email address to your new email address.



LEO:  But not so fast, Mr. Gibson.  I don't think we're going to let you do that.



STEVE:  Unbelievable.



LEO:  Now, I presume I can set up a Gmail account, and I've been telling people to do this, and have Gmail fetch the mail from Yahoo mail.



STEVE:  Ah.  I'll bet you can, yes.



LEO:  Yeah.  Now, what I don't know, and you might have to have a paid Yahoo Mail account to do that, in other words I don't know if they give you POP or IMAP settings unless you have a paid account.  But maybe somebody in the chatroom would know that.



STEVE:  Yes.



LEO:  Just because Yahoo won't forward it for you doesn't mean you can't fetch it.



STEVE:  Although, I guess...



LEO:  They couldn't stop that or you wouldn't be able to - email wouldn't work.



STEVE:  Right.  Well, exactly.  So we assume that you have either POP or IMAP access to Yahoo accounts, that is, external access, so you're able to pull from Yahoo rather than just going through the web interface.



LEO:  I should log in and see.  Because I - problem is I have a pro account, so I don't know.



STEVE:  I'm sure we'll have some people tell us, maybe by the time we're through talking about this, in the chatroom.



LEO:  There is no, by the way, button to delete my account, either.



STEVE:  No.  And what some people have had to do is they've had to set up "out-of-office" because you can still do that.  You can create an out-of-office autoresponder where you give your new email.



LEO:  Yeah, say "I'm not here," yeah.



STEVE:  So people are having to do a workaround because Yahoo suddenly decided to take that longstanding service offline.  There's only one possible reason.  They want to thwart people from leaving.  And I think that is reprehensible.



LEO:  Horrible, horrible company.



STEVE:  And, finally, Verizon wants a $1 billion discount on its pending purchase because of all of this.



LEO:  I wouldn't be surprised to, I mean, maybe if they can get it at a fire sale price they'll say, well, let's go ahead.



STEVE:  Could they abandon?



LEO:  They can probably abandon it.  You know, there's usually a clause that says, if you abandon it, it's going to cost you a hundred million or something like that.  But I bet you there's a further clause that says "unless it's for cause."



STEVE:  Yes, an escape clause, yes.



LEO:  And I'm sure this is good enough cause.  I can't imagine a judge would say, I don't know, I mean, Yahoo has completely damaged its reputation.  And what makes me sad is so has Marissa Mayer in this.  She's completely culpable all the way through.  She's the CEO.



STEVE:  Yes.  It was her decision two years ago.



LEO:  Just very disappointing.  I really expected better from her.



STEVE:  Okay.  Now, trapdoored primes.  This is interesting.  I will quote from the abstract of the paper and discuss it in a little more detail.  So the abstract reads:  "We have completed a cryptanalysis computation which is at the same time a formidable achievement in terms of size, a 1024-bit discrete logarithm computation" - okay, now, okay, we'll stop for a second.  What they're saying is they successfully solved the discrete logarithm problem for a 1024-bit key, essentially, which breaks it.  I mean, it is the impossibility of doing that which is the security that we're relying on.



So this first line is like, what?  "We have completed a cryptanalysis computation which is at the same time a formidable achievement in terms of size - a 1024-bit discrete logarithm computation - and a small-scale undertaking in terms of computational resources, two months of calendar time on between 2,000 and 3,000 cores."  Okay, now, that's earthshaking that you could crack a 1024-bit discrete logarithm problem in two months on a university research-scale parallel processing system.



"In comparison," they continue, "the 'real' record" - and they put "real" in quotes for second, I'll explain why - "for discrete logarithm," that is, the only one that has actually ever been cracked, "is 768 bits," which was announced earlier this year, in the spring, and that that 768-bit discrete logarithm computation "required 10 times as much computational power."  So then here's the kick.  "To achieve this dramatically faster cryptanalysis of a much harder 1024-bit prime" - and remember, when we add bits, it doesn't go up linearly.  It goes up by a power, essentially by a factor of two.  So 768 is vastly weaker than 1024.  And we're all relying on 1024 today.



So, "To achieve this," they wrote, "we cheated.  Deliberately.  We chose the prime number which defines the problem to be solved in a special way, so that the computation can be made much more efficient.  However, we did this in a subtle way, so that the trapdoor we inserted cannot be detected."  In other words, they demonstrated for the first time ever that it is possible to carefully choose a large 1024-bit prime in such a way that it is dramatically weakened to someone who knows how it was chosen, but that that weakness cannot be seen:  a "trapdoor" in crypto parlance; a "backdoor" in popular parlance.



They wrote:  "Unfortunately, for most of the prime numbers used in cryptography today" - and this is an exaggeration, like I'll explain in a second, and that's why we want to clarify this - "we have no guarantee that they have not been generated with such a trapdoor.  We estimate that breaking a non-trapdoored 1024-bit prime" - that is, a solid, properly, non-maliciously created prime - "is at least 10,000 times harder than breaking our trapdoored prime was for us once we knew the trapdoor."



In other words, what they have demonstrated is the feasibility of creating a deliberately weakened large prime which they know how to break in one ten-thousandth the time that it would normally take.  And that's enough of a difference to mean that somebody, a state-level actor with a massive computational facility in Utah, next to a river to cool its heels, would be able to do this.



So they continue:  "Our computation raises questions about some Internet standards" - and here I completely agree with them - "that contain opaque, fixed primes.  Theoretically, we know how to guarantee that primes have not been generated with a trapdoor, but most widely used primes come with no such public guarantee.  A malicious party who inserted a trapdoored prime into a standard or an implementation would be able to break any communication whose security relies on one of these primes in a short amount of time."



Okay.  So when GRC creates a certificate, one of the things we - and anyone who has created a CSR, a Certificate Signing Request, on their server.  You run the certificate generator.  And it's kind of cool.  On the various Unixes that I've used, you see little asterisks being printed out as it's working.  Basically it's running a pseudorandom number generator and testing the primality of big long numbers that it's coming up with.  And so it's pseudorandomly using good entropy, hopefully, generating primes.  We have talked in the past about that process not being random enough.  That is, if you freshly boot the machine and immediately ask it to generate a new key, it hasn't had enough time to acquire entropy.  And we've actually found on the Internet instances of collisions where independent parties both came up with the same really big key, which is not good.



So, but the point is you use a pseudorandom number generator, and you just start spitting out guesses, and you test each one's primality until you find one that is prime.  Then that's what you use as the private portion of your key.  You choose another one.  You multiply them.  That gives you the public key.  You send that off to be signed by the certificate authority.



Now, okay.  So they're not suggesting that there's any way that that's being misused.  There's the problem of, as I said, not having enough entropy, but that's a different problem.  But there's another place where primes are used, and that's in, for example, the TLS handshake, where you use perfect forward secrecy with the Diffie-Hellman key exchange.  The standard itself describes and specifies the prime that is being used for that.  That's not something that needs to be a secret with Diffie-Hellman.  The whole idea is that you're able to - both ends are able to exchange the information.  The attacker can know what is being exchanged, but they still cannot perform the computation, even seeing all of the packets going back and forth.



So the beauty, I mean, the elegance of this system is that it requires no secrecy.  But nobody clearly described where that prime came from.  Now, this may be reminiscent to that dual elliptic curve problem we had a few years ago.  Remember the RSA, it was the default pseudorandom number generator algorithm, even though it was slower than the other good ones.  It was based on an elliptic curve with unknown prominence.  It was just, you know, the NSA maybe, we never knew, but no one could say how it was arrived at.  It was just, here's the curve you use for this dual curve random bit generator, and everyone was using it until some people said, wait a minute.



So 25 years ago the question was raised, are primes safe against a trapdoor?  And the cryptographers of that era knew that there was a theoretical weakness.  But 25 years ago is long in terms of computational power.  Earlier in this podcast we were talking about AI and the crazy amount of power that's available, the fact that a university research team can have 3,000 cores, you know, of high-speed GPUs cranking on something.  You know, 25 years ago we had PDP-8s whose lights were blinking.  I mean, that thing could not do crypto.  So what was a theoretical, as we've often seen, what was a theoretical concern at the time was dismissed and largely forgotten.  These guys said, "Okay, let's revisit this."



So here's the concern.  We have no evidence that any prime in any standard in any wide use has a trapdoor.  We never really knew that the dual random bit number generator, we never knew that it was a danger, but it was a concern because we knew it could be.  One of the reasons that I liked and chose Dan Bernstein's elliptic curve for the SQRL protocol is he explains exactly where the numbers he chose to use in his curve came from, how he got them, and where they were derived.  And that's what we need, and that's what's missing from the existing standards.



And, for example, one of the ways that this could be solved would be to show the random seed which was used to - or show the seed which was used to drive the pseudorandom number generator, which after generating a whole bunch of non-primes arrived at a prime.  The point is, nobody, if it's a good pseudorandom number generator, there's no way to reverse-engineer the prime you arrive at back to the seed which 10,000 numbers later generates the prime.  So if you show, here's the prime we want to have in the standard, and here's the seed and the pseudorandom number generator that found that prime, then there's no way to engineer a trapdoor into the result.



The other interesting way is for most of the bits of the prime not to be under anyone's control.  So, for example, you take the bits of pi, or the bits of "e," and you compose your prime of all of those that you can.  And then you start fiddling with them in one small area until you find a number which is prime, only by modifying a few of the bits.  And again, the type of manipulation required to insert a trapdoor would be thwarted by that.  So we have good means of solving this problem.  We just haven't been applying them.



And so I love that this research came out.  I think what this means is that, moving forward, any [audio dropout] in the future, in order to be accepted as part of a standard that involves "magic numbers," as they're often called, will have to show us, as part of it, where those numbers came from.  Not just, oh, you know, and a miracle happened.  And after I hung up the phone with the NSA, I realized what my prime should be.  No.



So the good news is, even though a 1024-bit prime is weakened by their estimate of about 10,000 times, if we switch to 2048 bits for our crypto, which is where we pretty much are now moving forward, even a 10,000-factor reduction in strength is still not a concern because, again, remember, it's not twice as hard when you go from 1024 to 2048; it's bizarrely, incredibly exponentially.  It's 2^1024 times as hard, roughly.  It doesn't actually scale linearly like that.  But it's vastly harder.



So one thing we could do is to now, is to sort of more strongly deprecate the use of smaller primes, knowing that just going to two k-bit primes makes us safe because - but again, the idea of a trapdoor still is a problem.  Maybe, for example, there are stronger trapdoors, that is, there are entities in the world that know of other means to put trapdoors in primes, that is, to deliberately choose a prime that has some special features they're able to leverage that give them more than a 10,000-factor weakening.



So I would argue, regardless, we absolutely have to know the provenance of any magic numbers moving forward, that someone came up with it somehow.  And that process of coming up with it now needs to be transparent.  It has to be demonstrated that anyone else, starting with the same seeds, could have, would have resulted in finding the same prime, which demonstrates it was not subject to manipulation.  So a really nice piece of research.  And this is really what you want.  You want this kind of a canary to say, you know, to be, like, getting a little woozy on its perch, and for you to say, oh.



LEO:  Pre-death canary.



STEVE:  Yes, the woozy canary.



LEO:  Yeah.  Not dead yet, but any day now.



STEVE:  Yeah.  So just a great piece of research.  Again, so I just want our listeners to have this context because the press is going bezonkers over this.  You know, like, oh, the primes all over the Internet are compromised.  It's like, no.  As far as we know, none of them are.  But we now know that it's possible.  So moving to larger ones is an immediate solution.  And, moving forward, we have to know where the magic numbers came from.



LEO:  As always, Steve makes everything crystal clear, and I highly recommend that you listen to each and every show so that, when somebody comes along, your mom says, "Honey, what's all this I hear about trapdoor primes," you can explain.  Okay.  Let's see.  We're going to be back here - this is it; right?  This is it.  This is the conclusion of this episode.



STEVE:  Yes, sir.  And we'll see what news the week brings.  If not sufficient to engage our listeners...



LEO:  To derail...



STEVE:  ...for two hours, then we'll do some more Q&A. 



LEO:  That you can do by of course following Steve on Twitter, @SGgrc.  He's wide open to DMs and questions there.  But you can also go to the old-style GRC.com/feedback.  Actually, while you're at GRC, pick up a copy of SpinRite.  It's the world's best hard drive maintenance and recovery utility, and Steve's bread and butter, keeps him in PDP-10s or 8s or whatever those are behind him.  So, you know, throw the guy a Franklin.



STEVE:  It pays the bills and keeps me able to do everything that I like to do for everybody.



LEO:  Everything else, like this, yeah.  And SQRL and all the other freebies there.  It's just an amazing site:  GRC.com.  He also has audio copies of the show and transcriptions:  GRC.com.  We have audio and video at our website:  TWiT.tv/sn.  But I think the best way to do this would be subscribe.  That way it's always downloaded as soon as it's available, and you just, you know, it's a nice feeling.



STEVE:  It's like a TiVo season pass.  I would go crazy if I didn't have - just put it in and then don't worry about it.



LEO:  Then Wednesday morning, you get up, you say, what can I listen to on the way in to work?  Oh, I've got a new Security Now!.  Just happens automatically.  And you can do that on iTunes, and Google Music has it, Stitcher, Slacker.  I can go on and on.  Just find anywhere that you can get podcasts.  Find Security Now! and subscribe.  That's the best way to do it.



Have a great week, Steve.  We will be back next Tuesday at 1:30 Pacific, 4:30 Eastern, 20:30 UTC, to renew the conversation.



STEVE:  Yes, sir.  Welcome back, and I'll talk to you next week.



LEO:  Right.



STEVE:  Bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#582

DATE:		October 18, 2016

TITLE:		Listener Feedback #241

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-582.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss some serious concerns raised over compelled biometric authentication, then do a detailed dive into the recently completed audit of VeraCrypt, the successor to TrueCrypt.  We've got more on web browsers fatiguing system main SSD storage and a bunch of interesting miscellany, including a question asked of Elon Musk:  "Are we living within a simulated reality?"  We conclude with 11 questions and observations from our terrific listeners.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  For the first time in a while we've got questions and answers.  Steve's going to answer a whole wide-ranging list of topics.  But before we do that, we've got security news, and he's going to talk about the VeraCrypt audit - very good news for people who want to find a replacement for TrueCrypt.  Stay tuned.  It's coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 582, recorded Tuesday, October 18th, 2016:  Your questions, Steve's answers, #241.



It's time for Security Now!, the show where we cover the latest security news and help keep you safe and then explain how things work.  And it's all done by this one fellow right here, the hardest working man in podcasting, Steve Gibson of the GRC company.



STEVE GIBSON:  Yo, Leo.



LEO:  Hey.  Yo, Steve.



STEVE:  Great to be with you.  So we don't have a lot of individual pieces of news.  We're going to do a Q&A this week, just because there's a bunch of a fun stuff that our listeners have submitted, thoughts and observations and questions in some cases.  But there were a couple significant stories.  And the one that just burned up my Twitter feed was the announcement of the audit results from VeraCrypt, which of course is the successor to TrueCrypt.



LEO:  I was thrilled that they audited it so quickly.



STEVE:  Yes, yes.



LEO:  Because we went years without an audit for TrueCrypt.



STEVE:  Yes.  And it's a consequence of the OSTIF, which is a small organization.  And I can't remember what the acronym is for.  But I have it in my notes.  We'll get to it - Open Source Technology Improvement Fund.



LEO:  Oh, I like it.



STEVE:  And so they generated the funding and then contracted with a French security firm who put two people on it.  They spent 32 man-days - and I thought, okay, well that should be probably person-days - in order to go through it.  But the depth of their analysis is really informative, as is what they found.  There's also, that we'll talk about, some concerns, a new big concern about biometric authentication problems.  And you missed a story that I had some follow-up for that I wanted to make sure you were aware of, where web browsers turn out to be fatiguing SSD main storage on systems.  A ton of miscellany, including we need to address the question of whether we're living within a simulated reality.



LEO:  Hah.  How have we missed that one?  That's a - yeah.



STEVE:  And then a Q&A.  Well, because it happened since you and I talked last, with Elon going on the record saying, yeah, I think there's probably only maybe a one in billion chance that we are not in a simulated reality.



LEO:  Yeah.



STEVE:  So anyway, it turns out that a lot of the popular press completely misunderstood what he meant because the only thing that we are aware of sort of popularly is "The Matrix," and he's not referring to that model at all.



LEO:  Ah.  Oh, good.



STEVE:  So I thought it would be fun to discuss that.



LEO:  I'd love to.



STEVE:  So lots of fun stuff this week.  So this is my second edition of the famous book that is often referred to as the "K&R text" I'm holding up in front of the camera for our listeners.  This is the book, "The C Programming Language."  And I looked around for my first edition copy, which is about half the thickness of this one - even so, very thin by any standards of modern programming languages.



LEO:  It's funny, I have both the first and second, as well.  And I keep the second here and the first at home.



STEVE:  So I've reread the preface so many times because I just get goose bumps.  And I've referred to it on the podcast a few times.  Just the first paragraph reads:  "C is a general purpose programming language which features economy of expression, modern control flow and data structures, and a rich set of operators.  C is not a very high-level language, nor a big one, and is not specialized to any particular area of application.  But its absence of restrictions and its generality make it more convenient and effective for many tasks than supposedly more powerful languages.  C was originally designed for and implemented on the Unix operating system on the DEC PDP-11 by Dennis Ritchie."  And he passed away.



LEO:  Five years ago.



STEVE:  What?



LEO:  You know, I saw all this social...



STEVE:  What?



LEO:  Yeah.  He passed away the same week Steve Jobs did.  No, you fell for it, and I almost fell for it, too.



STEVE:  How weird.



LEO:  It was all over Twitter and Facebook that he'd passed away.



STEVE:  Yes, and I got sucked right into it.



LEO:  But if you click the link, there's a date on it:  2011.  But nobody looked at that.  So, yeah, he passed away when Steve Jobs did.  In fact, one of the reasons I remember...



STEVE:  And now that you say it, I remember.



LEO:  Yeah, because people were saying, oh, everybody's making a big deal about Jobs dying.  Nobody's saying anything about Ritchie passing away.  Yeah.  Anyway, but you know what?  We deserve a tribute to Dennis Ritchie, five years later or a hundred years later.  This was a great man and wrote, not just this, but much of Unix. 



STEVE:  Yeah.  He and Brian Kernighan.



LEO:  Yup.  K&R, they call this.



STEVE:  Yup.



LEO:  And, you know, I actually haven't read the second edition.  But the first edition, my first edition is well thumbed.



STEVE:  Oh, it's just - yeah.  What I love about it is that it is so lean.



LEO:  Yeah.  It's just very simple.



STEVE:  Of course it appeals to me as Mr. Assembly Language, so...



LEO:  It's as close to assembly language as you can get in a high-level language. 



STEVE:  And many people shared with me a Photo of the Week, which I just got a kick out of.  So this is the "you're doing it wrong" in a simple picture.  And so this shows a password field which is highlighted in red because the system's not happy.  And it's saying, "Password is used by another user."



LEO:  Oh.



STEVE:  It's like, oh.  So count the number of things that must be wrong with a system that is able to tell you that.  Now, it's true that it could be checking the hash.  And we know that hash collisions are, for reasonable size passwords, are going to be very rare.  But why would a system check the hash?  So what it's clearly doing is looking up a user's record with the password as the index.  And it finds an existing one and says, oh, sorry, we can't have - two users cannot use the same password because then our index will return two records, and we can't have that happen.



So, I mean, it just - it's mind-blowing that somebody could say, oh, sorry, that password is in use.  Well, now, of course, that also begs the question, ooh, I wonder who's using it.  Because of course it's an information leak, as well.  So, I mean, bad architecture, fundamentally flawed account management, it's just horrendous.



LEO:  And we should add, if you ever see this, you should never see it for two - not only that, but because it means you have a crap password.



STEVE:  Very good point.



LEO:  Right?



STEVE:  If your password is colliding with somebody else...



LEO:  You've done a bad job, my friend.  You've got to stop using Monkey123.



STEVE:  That's a perfect point, Leo.



LEO:  You should never, ever see that image.



STEVE:  So anyway, thank you, everybody, for sending that to me.



LEO:  That's pretty funny.



STEVE:  I just - that was wonderful.



LEO:  It's pretty hysterical.



STEVE:  And we've got super astute listeners who've, you know, been following along.



LEO:  They got it.



STEVE:  Yeah, they got it.



LEO:  Yup.



STEVE:  So the first story was covered by Forbes.  And I'm looking now at the date to make sure it's recent.



LEO:  Well, you know, and by the way, this is a lesson for anybody who snarkily says, well, heh, heh.  So right after I said that to you, I pulled up your show notes because I was going to show the image, and it didn't match what you were saying.  And I thought, well, this is strange.  Then I realized the show notes I had were from 2011.  So somehow 2011 is back, baby.  Now I have the real show notes up.



STEVE:  So anyway, Forbes' title is rather brutal:  "Feds Walk Into a Building, Demand Everyone's Fingerprints to Open Phones."



LEO:  Wow.  No.



STEVE:  And so I'm just going to read the top of the story, and two wellknown legal experts were consulted for their opinion.  So Forbes wrote:  "In what's believed to be an unprecedented attempt to bypass the security of Apple iPhones" - although actually the warrant specified four different brands, all known to have fingerprint readers.  So the law enforcement officials didn't even known which phones people might have, so they just blanketed it.  I mean, and that's the big concern.  Not only is there a concern with forced use of biometrics, which the argument has been is not constitutionally protected, but in this case it's also just the breadth of this warrant.



So "the security of Apple iPhones or any smartphone that uses fingerprints to unlock, California's top cops asked to enter a residence and force anyone inside to use their biometric information to open their mobile devices.  Forbes found a court ruling dated May 9, 2016, in which the Department of Justice sought to search a Lancaster, California property.  But there was a more remarkable aspect of the search, as pointed out in the memorandum:  'authorization to depress the fingerprints and thumbprints of every person who is located at the subject premises during the execution of the search and who is reasonably believed by law enforcement to be the user of a fingerprint sensor-enabled device that is located at the subject premises and falls within the scope of the warrant.'  The warrant was not available to the public, nor were other documents related to the case.



"According to the memorandum signed off by U.S. Attorney for the Central District of California, Eileen Decker, the government asked for even more than just fingerprints:  'While the



government does not know ahead of time the identity of every digital device or fingerprint (or indeed, every other piece of evidence) that it will find in the search, it has demonstrated probable cause that evidence may exist at the search location and needs the ability to gain access to those devices and maintain that access to search them.  For that reason, the warrant authorizes the seizure of "passwords, encryption keys, and other access devices that may be necessary to access the device."'



"Legal experts were shocked at the government's request.  Marina Medvin of Medvin Law said: 'They want the ability to get a warrant on the assumption that they will learn more after they have a warrant.  Essentially, they are seeking to have the ability to convince people to comply by providing their fingerprints to law enforcement under the color of law because of the fact that they already have a warrant.  They want to leverage this warrant to induce compliance by people they decide are suspects later on.  This would be an unbelievably audacious abuse of power, if it were permitted.'"



And then Jennifer Lynch, who's the senior staff attorney at the Electronic Frontier Foundation, added:  "It's not enough for a government to just say we have a warrant to search this house, and therefore this person should unlock their phone.  The government needs to say specifically what information they expect to find on the phone, how that relates to criminal activity, and I would argue they need to set up a way to access only the information that is relevant to the investigation.  The warrant has to be particular in how it describes the place to be searched and the thing to be seized, and limited in scope.  That's why, if a government suspects criminal activity to be happening on a property, and there are, say, 50 apartments on that property, they have to specify which apartment, and why, and what they expect to find there."  And then she concluded, saying:  "We've never seen anything like this."



Now, nobody really, because this is not public, nobody understands the details.  But from our technical perspective, if we were to sort of reverse-engineer what may explain this - because I was thinking about, like, okay, first of all, the concern is this is now what law enforcement - this is apparently law enforcement's maybe another test.  But their reaction to the famous iPhone fingerprint hack problem, where they're just saying, okay, fine, we're just going to, since the courts have said a password constitutes - coercing a password constitutes self-incrimination, which is protected by the Constitution, we can't do that.  But the courts have also previously said biometric information is not protected.  So law enforcement is just saying, okay, fine.  We want specifically the warrant to give us the right to force anyone in this location to unlock their phones.  So again, the generality of this makes me think it's tied to an IP address.  That is...



LEO:  Ah.



STEVE:  Right?



LEO:  Interesting, yeah.  That makes sense.  They know it's this building.



STEVE:  Or this residence.  It was actually a house.  And so they probably found some traffic which they believed represented, whatever it was, criminal activity.  They got the address from the cable provider or whoever provides Internet service.  So now they know that it is a device, and they just presume probably a cell phone.  If not, maybe a PC, but those don't tend to be locked the way mobile devices are.  And so they wrote the warrant to give them permission when they get there to force everyone to let them look inside their phones, presuming that one of them will have been the endpoint of that electronic communication.



LEO:  Yeah.  Wow.



STEVE:  Which in my mind doesn't excuse it, but it sort of explains, like, probably...



LEO:  What they're up to, yeah.



STEVE:  Yeah, what was going on.



LEO:  So then that begs the question, because all of us now I hope have fingerprint-protected phones, what you should do.  And it seems to me the easiest thing would be, when the feds pound on the door, besides flushing all the drugs down the toilet, you want to turn your phone off because at least all the phones I've used, iPhone and Google phones, once you turn it off, the fingerprint won't re-unlock it.  You'll have to then enter your passcode.



STEVE:  Right.



LEO:  Which they can't reasonably demand.  I mean, they can demand, but not reasonably.



STEVE:  Right.  That, or call your attorney and impose a 48-hour delay.



LEO:  Oh, there you go.  And that'll do it, too.



STEVE:  Because that's the other thing that will cause that to expire.  So, yeah.  Again, we're in some interesting uncharted territory.  I will say that Apple seems to have solved with iOS 10 the problem of the fingerprint reader working too quickly.  I hate this double-staggered...



LEO:  I have a fix for it, if you want.



STEVE:  Oh, do you.



LEO:  Yeah.



STEVE:  I looked for one, couldn't find one.



LEO:  I do, too.  I hate it, too.



STEVE:  I just - I hate it.



LEO:  So that's something new in iOS 10.  And the reason - I figured out why they do that.  Because a long press of the fingerprint opens Apple Pay.  So they want you to be able to use Apple Pay.  So what they've asked is that you have to unlock it and then press it again.  But if you go into the accessibility settings, you go to Settings > General Accessibility, and then there's a Home button setting.  You can restore the original pre-iOS 10 behavior of it both unlocking and...



STEVE:  It goes right in.



LEO:  Goes right in.



STEVE:  Oh, good.



LEO:  So it's in the Home button settings of Accessibility.  Not the general Home button settings.  You have to go into Accessibility.  But, yeah.  As is often the case, they hide stuff.  They hide the stuff you really want under Accessibility.  But if you...



STEVE:  Yeah, well, I always turn up the visibility to - because I don't like that whole color bleed-through thing.



LEO:  Right.



STEVE:  I get rid of the animation...



LEO:  Exactly, yeah.



STEVE:  ...because I don't need things zooming up and down and all that.



LEO:  Oh, but you're not going to get, then, the cool fireworks in the iMessages.  All right.  So here it is:  accessibility home button.  You have click speed, but you also have rest finger to open.  And that, if you turn that on, it restores the previous...



STEVE:  Oh, good.



LEO:  You don't need to do the double-step tango.



STEVE:  Ah.  It just - and it's funny, too, because, I mean, I just - I liked being able to press a button, and I'm in.



LEO:  Yeah, that's the point.



STEVE:  Instead of now you kind of have to wait for it to say it, or you press it again, or it's just so aggravating.



LEO:  It is, yeah.



STEVE:  So, yeah, I'm glad they have a workaround.



LEO:  Yeah.



STEVE:  Okay.  Now I want to take our listeners through what Quarkslab found when they did what could only be considered a really thorough audit of VeraCrypt.  Okay.  I will step on the conclusion here and just say that you want 1.17.  Or is it 9?  Let me look.  Nine, 1.19.  What these guys audited was 1.18.  So most of the problems, but not all of them, are fixed.  And I think one of the reasons that so many people sent links to me, breathlessly, is that, once again, the headlines in the popular press show big red warning flashing, you know, "Emergency upgrade right now."  And nothing here was a real showstopper.  We've been living with it as it has been for a while.



But this is a perfect case for us on this podcast to take a look in detail at the nature of these sorts of problems.  So as I mentioned before, this came about as a result of a small group who call themselves OSTIF, the Open Source Technology Improvement Fund.  And they sort of have three missions.  One is to offer bug bounties to help improve code, direct code improvement through grants, and professional audits.  And so, due to the history of TrueCrypt, and the fact that VeraCrypt took it under their wing and then have moved it forward, they felt it was time to give this thing some real scrutiny.



So 10 weeks ago, from around today, on August 1st, the OSTIF announced:  "OSTIF is proud to announce that we have come to an agreement to fully fund an audit of VeraCrypt.  Using funds that were donated by DuckDuckGo and VikingVPN, we plan to hire Quarkslab to go over the code and search for vulnerabilities and backdoors.  VeraCrypt is a crucial piece of open source software that can encrypt any storage medium with powerful and highly tamper-resistant encryption that greatly enhances the personal security of anyone who uses it.  An audit of the code brings fresh professional perspectives and a deep analysis of the code to search for vulnerabilities."  And it goes on like that.



So basically, 10 weeks ago, this was contracted.  And after they began, 32 man-days later, we have results.  So, okay, first of all, what was found?  I would argue no huge showstoppers.  But the devil's in the details, and we'll go over that.  But they did find a handful of both old and new things that needed to be cleaned up.  Most of these were weaknesses that could sort of theoretically be used in highly targeted attacks to compromise the target's privacy and security.  But mostly they are things that fell out of the technical scope of coverage.  That is, even TrueCrypt noted some problems and said, "But that's somebody else's problem."  That is, this is not the kind of thing it's feasible for us to protect against.  But there are some things that were feasible that we're still not protected from.  So there are both troubles inherited from TrueCrypt in VeraCrypt, and then there were new troubles introduced by new VeraCrypt features.



So, and it's funny, too, because, I mean, any of our longtime listeners, a lot of this will be very familiar because, step by step over the years, as problems were found in TrueCrypt, we talked about it on the podcast and covered it in some detail.  So as I was reading through the audit, I'm going, oh, yeah, I remember that one.  Oh, yeah, I remember that one.  So one problem was, from TrueCrypt, their password-based key derivation function was not acceleration resistant.  That is, they didn't use a so-called "memory-hard" function like scrypt.  It was just an iterated hash.  And we know from all of the work that's gone into minting bitcoin and other crypto currencies that you can apply especially large-scale integration to hugely accelerate those operations.



So VeraCrypt was using, or VeraCrypt inherited from TrueCrypt, iterations of either 1,000 or 2,000, which depended upon which hash algorithm was used and its usage, that is, whether you were mounting a volume within the system or essentially accepting a password to boot the system from an encrypted system partition.  So the original iteration counts were 1,000 and 2,000.  They are now - get this - 200,000 and 655,000.  So way stronger.



There's also an additional feature that VeraCrypt added, but introduced a bug that we'll cover later known as a PIM, in this case a Personal Iterations Multiplier.  And that gives the user some additional control so that, if they don't mind waiting longer at boot or mount time, they can specify a so-called Personal Iterations Multiplier which, as it sounds, allows you to dramatically multiply that even further.  Problem is, turns out there was an overflow in the math for the dramatic multiplication so that it ended up reducing the rounds count, rather than increasing it, when you thought you were getting more security.  Whoops.  Anyway, that was easy to fix and was fixed.



There was also a problem from TrueCrypt that sensitive information might be paged out from the kernel stacks.  So you've got a kernel driver where the encryption/decryption is going on.  It has to have an operating symmetric key present, which means that key is persistently vulnerable to exposure.  If, in a low memory situation, a page of the kernel gets swapped out to non-encrypted storage, your key might be there.  So that's a concern.  However, that was the case in TrueCrypt.  VeraCrypt doesn't change it.  They simply state that this will be a vulnerability unless the system partition is encrypted and the paging file is therefore written to an encrypted partition.  So, and that's, I guess, that's some protection.  It means that the key won't be readable.  But you really don't want the key to go out into the swap file because that's potentially accessible, too.



In the details of this they talked about the fact that, unfortunately, both of these programs, the original TrueCrypt and VeraCrypt, which inherits most of itself from TrueCrypt, has sensitive data scattered around.  So it is very difficult to collect it all in one place.  As an aside, that's one of the things that I did very carefully, like from day one of the SQRL client for Windows, is I created a protected memory region, and absolutely everything that matters is within one solid contiguous block.  And I also arranged to lock it into memory.  And the program is so small, there's no danger of it being swapped out because programs all get a chunk of memory that isn't in danger of being swapped out.  It's only if they get really huge that then they're at risk of having some other pieces removed.



So anyway, so this is the problem with trying to do sort of add-on security to an operating system after the fact.  You are fighting some of the architecture of the system.  And it tends to be an OS by OS thing, too, because of course this is all multiplatform.  And the auditors did acknowledge that this is a difficult problem to solve on a multiplatform system, or a multiplatform solution, because it requires deep knowledge of, not just one OS, down at the kernel level, but Windows and Mac and Linux.  Wherever it's going to run, it's a significant implementation challenge.



Another problem that they did fix, but that TrueCrypt inherited from - I'm sorry, that VeraCrypt inherited from TrueCrypt, was the various uses of compression and decompression.  TrueCrypt used and sort of forked some early Zip and Unzip libraries which had known problems.  And VeraCrypt didn't change it until this audit brought that to the attention and said, you know, even though exploitation is unlikely, why keep using these known problematical libraries?  So the idea would be that, if it were ever possible for an attacker to manipulate what was being decompressed, then that could be used to create a buffer overrun and potentially execute some code under the attacker's control.



So the reason this wasn't considered - oh, and I should mention this was brought up in '08, so eight years ago.  And the TrueCrypt guys knew this and said, well, you know, again, this is sort of out of scope.  So an example of an attack would be the recovery disk is compressed, as is the boot code, because it has to be so small in order to get the system going.  But it's unlikely the boot code could be manipulated.  The recovery disk, though, could theoretically be manipulated by an attacker so that, when a user used their recovery disk, it would decompress.  And if the recovery disk had been modified, the decompressor could have an overflow induced in it that, for example, might write the user's password to some external location or some fixed location where the attacker could then access it.



But the counterargument is, okay, on the other hand, if a bad guy has that kind of access, the ability to alter the recovery disk, then they could do a lot more than something as awkward as manipulating the decompression problem.  So essentially the auditors were saying, "This is bad, and we're trying to figure out why."  But it's the kind of thing where - and we see this all the time in security - vulnerabilities that are not obviously exploitable initially, even when they're identified, oftentimes in the future, due to changing circumstances or processor power or whatever, suddenly they then become exploitable.  So the compression/decompression has been fixed.



We also talked about, and VeraCrypt had fixed and these auditors verified - and you'll remember this one, Leo, where - TrueCrypt is written in C.  And the authors were using the memset function, which basically allows - memset is a C function or a library function which allows you to say "Set the following block of memory to this value."  And typically it's zero.  And so you want to zero out or null a block of sensitive data like the password, or like the master key or something.  I mean, and so secure systems are often having to have transient, highly sensitive data, and they're often allocating it dynamically.  So you say, "give me a buffer."  You ask the operating system for a block of memory.  And it says, okay, here's a pointer to the block of the size you requested.  You're then able to use that until you free it, that is, you essentially tell the operating system, "I'm done using that block of memory, thank you very much."



So what the programmers of TrueCrypt did was they were careful, because they don't know what the operating system is going to do with the memory that they give back to it, they were careful to zero it, to write zeroes across the buffer, then return it to the operating system so that memory that might have had something sensitive didn't just go floating around and may be available to somebody else.  The C compiler, though, as one of its optimization strategies, is looking for things that don't do anything.  And some clever programmer somewhere said, oh, look.  This memory is being zeroed and then immediately returned to the operating system.  Well, so there's no purpose to zeroing it.  That must have just been a mistake.  And so the C compiler optimized out.



LEO:  They didn't want to do that.



STEVE:  Yeah, that serves no purpose.  You've zeroed the memory and given it away.



LEO:  Isn't that a funny error.  Wow.  Too helpful.



STEVE:  Yeah.  So there is a secure zero memory function which doesn't have this problem.  And so one of the early things that VeraCrypt did was to switch over wherever memset was being used to this secure zero memory function which doesn't risk being optimized to nothing by the compiler.



And there were too many subtle TrueCrypt kernel driver problems fixed to mention that were fixed by VeraCrypt since it inherited TrueCrypt.  And I won't go through them all.  I mean, there were just a collection of little subtle things.  But the takeaway is these guys, the auditors, really did a nice job.  There's no way you could come away from this thinking, wow, this hasn't been scrutinized deeply.



There was one that was sort of interesting where they found that the kernel driver was not checking access permission on behalf of the user requesting to see whether a file existed.  Now, the kernel, of course, can do anything.  It's the god of the local environment.  But it has to respect access permissions.  And like I said, it has to enforce access rights permissions.  In this case, that was deliberately left out by the TrueCrypt developers because they wanted the boot time, or they wanted an unprivileged user running TrueCrypt to be able to determine whether there was boot code on the system that would be privileged.  So the kernel driver was specifically allowed not to check access permissions.



What was again found by a close examination, and you have to take an adversarial position, which is what these guys did, is that you could use that, you could leverage that as an information leakage, allowing anybody to probe the system for the existence of files for which they have no access.  The system should say, "You have no access."  Instead it says, "Yeah, that exists"; or, "No, that doesn't exist."  And so this could be exploited for an information leakage problem.  And this is an example of something VeraCrypt had not addressed.  And so these auditors brought that back to their attention and said, yeah, you know, you need to think about this.  Also, the AES cipher, which is sort of the de facto default cipher, has cache timing vulnerabilities, if the chip it's on does not support the AES instruction set.



Now, the mitigating factor here is that Intel has supported the AES instruction now for quite a while.  And maybe really low-end chips or old chips might not have it.  But mainstream strong desktop chips have had it for years.  So if the hardware instruction-assisted code is used, then there's no problem.  But the system runs on processors without the AES acceleration instruction.  And in those cases this software is not cache timing proof, which is something that these guys again found.



One thing that we talked about in the past was that the TrueCrypt developers misused the cyclic redundancy check.  CRC-32 was never designed to function as a cryptographic integrity mechanism, and they kind of crossed the line.  They use it that way.  What it was designed for and what it's really good for, is efficient error detection.  But that's different than integrity mechanism, and the difference is it's intended to prevent accidents, not thwart attacks.  And so as a consequence of the fact that TrueCrypt does - and VeraCrypt has continued for the sake of backward compatibility because unfortunately it's built into the volume headers and various signatures, and it's very small and very fast, which are both reasons that they used it.



The problem is it is subject to manipulation.  So, for example, the CRC-32 is used to mix the keyfiles in.  Remember that TrueCrypt introduced this notion that not only could you make the master key that you decrypt dependent upon a user-provided password, but you could also use a keyfile, the idea being that it's just going to be some file unknown to an attacker with presumably a lot of entropy.  And why not just pour that in?  Well, that would be nice if they had run it through a good hash.  Unfortunately, they ran it through CRC-32, which is explicitly not a good hash.  You know, it's a horrible hash.  It's not a hash.  And so from a valid set of keyfiles it's possible to create another distinct one file which will also mount a volume.  Which is something you really don't want.



One of the properties of a hash is that it's not easy to compute, well, it's really, really, really hard to compute an outcome; to figure out what to put in in order to get something out.  And so what that first example is is that the CRC-32 doesn't provide that same guarantee.  It's also possible to create null keyfiles, that is, a big file that does nothing to modify the so-called "keyfile pool."  And it's even possible, given a set of keyfiles, to remove the security brought by that set of keyfiles, essentially to add another file that completely nulls the effect of all previous ones.  Again, something you could never do if you were passing all this through a real hash function.



And finally, from a known passphrase, it's possible to create a keyfile which removes the security provided by the passphrase.  And again, this problem, too, has been known since 2008, for eight years.  But the TrueCrypt authors just decided they didn't feel this was a [audio dropout] because it required prior knowledge of a secret or the prior manipulation of a machine.  And so here's, again, this is like, well, okay, yeah.  But, boy, if you just used a hash, then you wouldn't have these problems.  And this is the kind of thing that, as we've seen before, that tends to come back and bite people downstream when some clever person figures out how to use that special case in a way that just happens to fit their needs.



Also, volume headers are "authenticated" with CRC-32, which is weak authentication.  Mostly it's just a means for the TrueCrypt driver to validate that what it's being given is a TrueCrypt volume.  And so it's not clear why using CRC-32 opens a vulnerability, but it just seems sloppy.  Also, James Forshaw, who's with Google's Project Zero, he discovered, and we reported back when he did discover this, a pair of problems in the kernel driver.  One was a drive letter symbolic link creation elevation of privilege, and a lesser concern problem.  Both have been fixed, and these auditors verified that.



Here's an interesting one that I just really appreciated due to its subtlety.  And again, it just shows you that these guys thought about the code.  The auditors really thought about this. When booting from a BIOS, and that could be either UEFI or traditional BIOS, it turns out the user's password length can be obtained.  And we know that's not good because that makes brute-forcing substantially easier.  You don't have to bother, if you know the password length, you don't have to bother with trying any shorter passwords or any longer passwords.  So it doesn't, like doesn't make it instant, but it dramatically simplifies the problem.



The BIOS saves keyboard keystrokes in a 32-byte, 16-character ring buffer.  Essentially, every key you press puts two bytes in the buffer, the scan code of the keyboard and its ASCII equivalent.  And it's a ring buffer, meaning that - and this is a common programming technique.  When you get to the 30, well, to the last word, the last two bytes, then when you go to the next one, essentially it wraps around to the beginning.  It goes back to the start of the buffer.  And so, and this is sort of - this is commonly done in programming.  It allows you to sort of have the equivalent of an infinite buffer, as long as somebody is reading from the end fast enough to keep the front from wrapping around and overwriting the oldest data.



So these buffers are managed, ring buffers are managed with a typically called a "head" and a "tail" pointer.  The head is the pointer to the last entered character.  And so when a new character gets entered, that pointer is advanced or wraps around to the beginning, and then the characters are written there.  And then the tail pointer is the character next to be read by somebody requesting the next character from the buffer.  So if the head and tail pointers are equal, that is, essentially that means that the reader has read everything that's available in the buffer.  And so when another character gets pushed, the head pointer moves forward.  And then if the software pulls because it's looking for input, it notices that the head and tail are different, meaning that the head has moved further forward.  So then the tail is advanced as characters are retrieved.



Well, it turns out that the authors of this code - and it wasn't clear to me whether this was VeraCrypt in the beginning or the original TrueCrypt.  But somebody recognized there was a problem, and they explicitly cleared the buffer.  We know where that buffer is in the BIOS.  It is in a universally fixed location in RAM.  And so TrueCrypt zeroes it.  But they forgot to zero the head and tail pointers.  Those are two words immediately in front of the buffer, that is, the lower addresses.  And those are not being cleared.  Never have been.



Which allows an attacker to determine, with mod 16, essentially, the length of a user's password.  I don't expect many people are entering passwords longer than 16 characters.  Maybe they are.  In which case, that would still give an attacker a clue.  If it looked like it was four characters, it might have been 20 characters.  So that would still allow them to hugely decrease their search space in brute forcing.  And so these auditors picked up on this problem and said, eh, you know, the head and tail pointers is another little information leak that should be taken care of.



Also, the VeraCrypt guys added command line options to the TrueCrypt invocation.  Unfortunately, you can give it the volume password.  And VeraCrypt added support for smartcards.  Smartcards require a PIN in some cases.  And you can also put that on the command line.  These auditors thought that was a really bad idea because there are systems, for example, command line stacks that would keep that separately in the system.  So there you've got, potentially, your TrueCrypt or your VeraCrypt volume password sitting in the past command line history stack and available to anyone who knows to look for it.  So they've strongly objected to the provision of secure information like that on the command line.



And one of the other problems is that VeraCrypt added four new non-Western cryptographic algorithms, three ciphers and a hash.  And one of the ciphers and hash were Russian design.  The cipher is old, dating back from the 1970s, called GOST89.  And while it has a very nice 256-bit key, its block size is only 64 bits.  And just recently on the podcast we've been talking about the inherent problem with 64-bit block ciphers.  They're just - they don't allow enough permutations of the bits in order to be secure.  And because the VeraCrypt guys apparently so much wanted to use this Russian-designed cipher, just I guess for the sake of internationalism, I mean, there's nothing wrong with AES that everyone can use, which is 128-bit block cipher.  They created sort of a CBC, a cipher block chaining variant, to concatenate two 64-bit cipher iterations in order to sort of kludge 128-bit equivalent.



Unfortunately, it turns out that many of the security guarantees of cipher block chaining fail when you always have a null initialization vector which they had to have because there was no provision for having unique initialization vectors in this application.  So the good news is the auditors understood all of that, and GOST89 has been removed from VeraCrypt.  There just wasn't a safe way to essentially backport an old cipher with a small block size.  It was just a bad idea.  So again, another reason why having lots of eyes on these problems is a good thing.



And there were another bunch of problems, I won't go into detail, that the auditors considered as informational, you know, sort of things that should be cleaned up, but weren't crucial.  However, it is worth noting that the UEFI bootloader - I talked about the BIOS key buffer problem.  It turns out that that may even be worse with UEFI driver.  UEFI drivers maintain their own keystroke buffers; but, unlike the BIOS, the buffers' internal address and location are not known.  There's an API that you use, and there is no visibility past that API.



So the console in API does offer a reset method.  But there's no guarantee of what that does in any specific implementation.  So it may just, for example, it may be to empty the buffer.  But emptying a ring buffer means setting the tail pointer to equal the head pointer.  So that may be what reset does is just align the two pointers, rather than zeroing the memory.  It's really feasible to imagine that that's all it does.  And so it turns out that, in examining the Intel Developer Kit sample code for UEFI, it turns out that the Intel sample UEFI ConsoleIn driver calls Int16, which is the old BIOS ring buffer.  And so it's added another layer of abstraction, but the fundamental problem is still there.  And maybe it's got its own internal buffer.  We don't know.



So this is interesting because here's a collision of low-level operation at boot time before the OS is running, where we're relying on very old, I mean, like, you know, from day one of the IBM PC, that's where the BIOS first appeared, and Int16 appeared, and we had the clanky IBM keyboard, and it had the 16-character buffer, and it's still there today.  The problem is back then we weren't trying to boot TrueCrypt volumes.  And so there was, like, no expectation that what was being typed in had to be super secure.  And, if it had to be, IBM published the source code for the BIOS, and so everybody knew where the buffer was.  It never moved.  And so you could zap it if you needed to.



But now we've, like, moved several generations beyond that, and we're imposing requirements for security that the underlying architecture was never designed to explicitly support.  And so it's a fundamental architectural problem, rather than a mistake that anyone made.  And I guess the only thing you could do would be to service the hardware yourself.  But that's a problem that SpinRite has, for example.  The reason it doesn't currently run on a Mac natively is the Mac doesn't have a BIOS.  It uses a USB keyboard and emulates that.  SpinRite in one area of its code assumes it's on a PC, and it does its own hardware keyboard reading because it needs some of the facility that that provides.  And so that's, for example, something I had to back off from when I was beginning to work on 6.1, in order to allow it to run over on a Mac without any problems.  So not easy solutions.



So the audit concludes:  "This audit, funded by OSTIF, required 32 man-days of study.  It shows that this follow-up of TrueCrypt is very much alive and evolves with new functionalities like the support of UEFI.  The results show that evaluations at regular intervals of such difficult security projects are not an option. When well received by the project's developers, they provide useful feedback to help the project mature.  The openness of the evaluation results help build confidence in the product for the final users."  And I think that's 100% correct.



So essentially these guys verified that many old problems had been found and fixed.  And they looked carefully at the new things that had been added and found some problems that needed to be and have been fixed:  GOST89 was removed; the compression and decompression algorithms were replaced with secure zip libraries; that password length leakage and the buffers are being cleared to whatever degree is possible; and other bootloader vulnerabilities were resolved.  So VeraCrypt is now at v1.19 and is even more Vera than it was before.



LEO:  Sounds like it might even be better than TrueCrypt was.  I mean, a lot of these were TrueCrypt flaws.



STEVE:  Yeah, I agree.  Now, again, it was never our sense that there was a critical gotcha in TrueCrypt.  But we did say, oh, was it about a year ago, I think it was when the Project Zero findings came out, it's like, okay.  Because it was a problem in the kernel driver.  There was an elevation of privilege that any process in the system could leverage because there is no way to restrict driver access to a specific process.  So it just, it was like, okay.  And we said on the podcast, eh, it's probably time to migrate.  Certainly if you're setting up a new system, use VeraCrypt.  Don't stay with TrueCrypt.  It's a superset.  And of course moving forward it's becoming more important to be able to have support for UEFI for modern hardware platforms.  And VeraCrypt continues to do that, and TrueCrypt just won't do it at all anymore.



LEO:  Yeah.  I'm also pleased to see that it was audited so quickly in its life compared to TrueCrypt, which we used for years without really any audit.



STEVE:  Yes.



LEO:  I think that's great.  I mean, this is something a lot of people are going to rely on.



STEVE:  Yeah.  And if nothing else, as I said, this just overwhelmed my Twitter feed because so many of our listeners said, wow, okay, what does this mean?  And so it's obviously of huge interest to people.  And I'm probably fine with BitLocker because I don't have...



LEO:  Microsoft's solution.



STEVE:  Exactly, Microsoft's built-in solution, where it's available.  It's not available on all platforms, not the lower-end platforms.  



LEO:  Windows Pro, yeah.



STEVE:  Yeah.  But I fully understand that there are people who like the idea of a third-party solution, and one that is open and has received this kind of scrutiny.  This is what this kind of software needs.



Okay.  So what we talked about, I don't remember which of the three weeks it was, Leo, when you were away, and Father Robert and I were doing the podcast, was it came to light that both Firefox and Chrome are frantic about taking snapshots of the current browser tab space constantly, and to the tune of gigabytes redundantly written to the system drive per day.  And in fact, if you take the write endurance of an SSD, that is, the amount that you write to it per day over its life, leaving Firefox or Chrome open, even on an idle system, can be consuming half of the total write life of the SSD.



So one of the things that we talked about the first time this came up was that Firefox does offer a tweakable setting under about:config.  And we've talked about that little amazing zone of configuration many times.  But you put about:config in the URL, and then you need to use a search term because there are so many options.  But browser.sessionstore.interval is the item.  And it's in number of milliseconds per refresh.  It defaults to 15 seconds.  And what it must be doing, and this is what's sort of disturbing, is that apparently they just didn't try to optimize this at all.  If they had done any optimization, they would, for example, ask the question first:  Has anything changed in the last 15 seconds?  Apparently they don't.  And so they just take a snapshot of the entire context of the browser and write it down into your session profile.  And not only Firefox, but Chrome does the same thing.  In fact, I think Chrome was even a little - it was writing a little more.



Now, this was of huge interest to many people.  I have an SSD-based laptop, and we know that the Windows 7 machine that I recently built has an SSD as its system drive, with spinning drives in a RAID as backup.  And so I am absolutely going to do what I think is a better solution, and that is, at least for Firefox - and I haven't explored this for Chrome.  But for Firefox, under application data > Mozilla > Firefox directory, there's a profiles.ini.  It's a short little INI file, about seven lines, and one of the lines is IsRelative.  You need to set that from a one to a zero, and then there's a path where you can specify where these profiles are written.  Just change that to a spinning drive, that is, you know, not your system C, typically, SSD, but I normally use Z or something, like something at the other end of the alphabet as my archival storage.  And so I will absolutely create another non-write-fatigable place for my browsers to write their profiles.  And I will also hope that they get smarter about this because it's just crazy how much data that they're writing constantly.



LEO:  I'm surprised, given that almost everybody at Google, presumably at Mozilla, too, is probably using computers with SSDs...



STEVE:  Yeah.



LEO:  ...that they haven't fixed this.  I'm sure they will.



STEVE:  Yeah.  Again, it sort of feels like it just didn't come up.  The architecture's been there since before SSDs, and until somebody pointed it out - what happened was they used Mark Russinovich's Process Explorer.  And so anyone could do this, and we talked about this a couple weeks ago.  You just run Process Explorer, and under the View item there are columns.  You're able to turn on more columns in the display.  And there's Disk I/O.  You go to that tab, and then it's Bytes Read and Bytes Written.  You turn both of those on, click Okay, and that adds those columns to the display.  And if you just sit there watching it, you just see Firefox or Chrome [sound effect], just going crazy.



And so, you know, my immediate reaction, although I'm on spinning drives on this old system of mine, on a RAID, was to just slow it down by a factor of 10.  I added a zero.  It was 15,000, meaning 15,000 milliseconds.  I made it 150,000 so instead of every 15 seconds it was every 150 seconds.  But a better solution is just move it to somewhere else.  And if you don't have a somewhere else, like for example on this nice laptop that I've got that is SSD, I think I may go back to the days of a RAM disk because it's got a ton of RAM.  So I'll just create a D: RAM drive and have the profiles live there.



LEO:  You'd think that the controller and the caching software would handle all this and not pass it on directly to the hard drive.



STEVE:  Well, but anything you - so it could, if it was reading it.  But the problem is it has a write-through cache.  



LEO:  Has to write; right.



STEVE:  Yeah.  Because the whole point is, if the system, if the browser crashes or hangs, or the system crashes, you want to be able to restore your session.  So this is all just session restore.  But, boy, what a cost.  Again, it has to be because they just didn't give it any attention.  And I'm hoping that, now that this has come to light, that somebody will spin off a little side project and get busy and fix this.



So the setting is the Recode Code Conference, 2016.  Elon Musk is onstage with interviewers Walt Mossberg and Kara Swisher, taking questions from the audience.  Josh Topolsky, who is a co-founder of The Verge in the audience, asks Elon whether he thought we might be living in a simulation.  We immediately learn, to our surprise, that Elon has ruminated about and hashed through this topic so thoroughly already that he and his brother have formally banned its further discussion anytime they are in hot tubs.  Its discussion is formally banned from hot tub debate.



And he was dead serious about this.  So in answering the questioner, Elon put a number to it and even, like, worked through his logic, concluding that he believed we are indeed living within a simulation.  And he says, in fact, he thinks there's only probably about a one in a billion chance that we are not simulated and are living in what - that is, a one in a billion chance that we are living in what he refers to as a "base reality."



So it turns out that this is - and maybe Josh knew this already because Elon was on record, at least for a couple years.  Back in 2014 at Vanity Fair's 2014 New Establishment Summit, Elon made the case that our lives are not at all what we think they are.  He concluded, again, even back then, there's a one in a billion chance that this is reality.  And so he said, for example, quoting from this Recode Conference recently, he said:  "The strongest argument for us being in a simulation is the following:  40 years ago we had Pong, two rectangles and a dot.  Now, 40 years later, we have photorealistic 3D with millions playing simultaneously.  If you assume any rate of improvement at all, then the games will become indistinguishable from reality.  It would seem to follow that the odds that we're in base reality is one in millions."



Anyway, so I thought, okay, so that's interesting.  Now, a lot of the press jumped on "The Matrix."  And what I realized was that, okay, that's sort of the pop version of what this sort of sounds like, but it's not what Elon means.  So the difference is "The Matrix" we can think of - everyone knows the movie, of course.  We can think of it as sort of an MMO; right?  Just it is a massively multiplayer environment, where you are sort of a reflection of yourself in this other environment.  What Elon is referring to is different than that.  He's referring to more something like the Game of Life, of course Conway's famous game, where you have rules by which these little cells are born or live and die.  And those rules create this surprisingly rich result.



And so what Elon is meaning is that everything, everything, what we regard as reality, could be running in some sort of a reality support container, meaning that we, life, are an emergent property of that.  So it's not that we exist as ourselves outside of this, as was in the case with "The Matrix," but in fact that reality as we know it is something that we perceive from inside, but that it exists in some sort of a container.  And Leo, I heard you talking about it, I guess over the weekend.  And there was some conversation about continuity, like the continuousness of space.  And what is a little creepy is that it turns out that most recent theories of space time is that it is quantized.  That is, photons do not travel continuously at the lowest level.  They are jumping from one, essentially, pixel, for lack of a better word, to the next.  So that's kind of creepy.  Anyway, I just - I thought that was a kick and wanted to stick it into the podcast.



So, and I did, when I was trying to think of an example of this, Star Trek followers will remember in the Next Generation series the creation of Professor Moriarty on the holodeck, where Data was role-playing, essentially, as Holmes, Sherlock Holmes, and asked the computer to create a rival worthy of Holmes in the form of Professor Moriarty, and a conscious entity was created.  I think it was entitled "Ship in a Bottle," I think was the title of the episode.  And everybody felt bad about having created this consciousness who, like, apparently did exist.  But they ended up giving him his own reality which would continue running, so at least he'd be happy in his little world that was all a program.  Cool stuff.



LEO:  Well, there you go.



STEVE:  So a little quickie on the lithium-ion battery issue.  And Leo, I know you've been interested in this.  I've got two pictures.  I found a guy, thanks to a follower who pointed me at a link, and I followed it down.  There is a company, Qnovo, Q-N-O-V-E, dotcom.  The guy there has a blog, and this person is in the middle of this battery technology.  For example, the most recent blog posting is titled "The Perils of 4.4 Volts."  Before that, "The Real Science Behind Battery Safety."  Before that, "It's Easy, but Not Right, to Pick on Samsung."  Before that, "Making Sense of 100 kWh."  And, for example there, I picked up on this because it mentions Tesla.  He says:  "Tesla Motors announced today upgraded versions of the Model S and X boasting 100 kWh battery packs, up from 90 kWh used in their earlier top-of-the-line electric vehicles.  One hundred kilowatt-hours sounds like a lot, and it is; but I bet that many readers won't have an intuitive sense of this amount of energy.  This is what this post is for."



Anyway, this guy, to sum up - and I've got links in the show notes for anyone who wants to dig in more.  Or you just go to Qnovo.com, and you'll find at the top in the menu a link to his blog.  And it's really good stuff.  He explains that the problem that these batteries are experiencing is the formation of lithium metal crystals which, due to a combination of physical manufacturing problems and pushing the batteries as hard as we do these days, can force the lithium crystal to grow through the insulator and create a lithium bridge between anode and cathode.  Then you have a short circuit, and the battery dumps its energy into itself, essentially, and explodes.



And so one of the things - and this is, I mean, this is well understood.  But the solution for this is to guarantee that the cathode is physically smaller than the anode.  That is, that the anode, the edges of the anode extend beyond the cathode.  And that simple physical property prevents the formation of these crystals, or mitigates the problem.  But that extension, while it creates a safety margin, it does not store energy.  So in the pressure to get the energy storage as high as possible, the manufacturing engineers have cut the margins.  And you can imagine the pressure on battery makers for their batteries to, I mean, that is the pressure is we want them to charge fast, and that's dangerous; and we want to charge high, that is, right up to their maximum voltage because, if we aren't charging it as high, we're not putting as much energy in.  And so the combination of speed and extent of charging, then weakened by this loss of margin in the oversizing of the anode, ends up creating a catastrophe.



And so his point is Samsung was only the first to get bitten.  And of course remember years ago, he says 15 years ago laptops were having this problem because there were problems with laptops back in the day.  And as we talked about a couple weeks ago, last Christmas the hoverboards were catching fire and exploding.  So it's a problem, a combination of manufacturing and that we're pushing the margins.  We have pushed the safety margins out in this quest for storing ever more amount of energy in a smaller space.  And wanting quick charging, which is challenging, as well.  So I just wanted to kind of end that topic, follow up on it, because I found this terrific site.



I did want to briefly mention that I spent some time this weekend and made a major update to the Healthy Sleep Formula page with a complete dosage determination protocol.  Many people have been reporting success, but they just didn't have any guidelines for determining how much of what they should take.  And I realized that I'd had enough feedback from people, enough experience myself and interacting with enough people, that a step-by-step protocol had emerged that would allow anybody to move through it in order to set the dosage for themselves because we've also learned that there's a range of dosage.



So for many people who say, yeah, I tried one of each and it didn't work, it's like, okay, well, you need to do a little more work.  The problem is we're all so different, both in the way we sleep, why we don't sleep, and how sensitive our bodies are to being pushed away from where they would normally be by supplements, that everybody needs a different dosage.  And there's nothing you can do except work it out for yourself.  So I provide that.



LEO:  I ordered mine, got my oleamide.



STEVE:  Oh, good.



LEO:  Yeah, so I'll try that now.



STEVE:  Good.



LEO:  Does it come with a micro scoop?



STEVE:  Yeah, it does.



LEO:  But you take 20 micro scoops' worth.



STEVE:  Yeah, yeah.



LEO:  I should just use a tablespoon or something; right?



STEVE:  Well, and actually the page has a picture of the micro scoop.  It shows that a micro scoop, a level micro scoop is 50 milligrams.  But then you can get for a couple bucks standard measuring spoons.  And so I've used them and weighed them to determine how much, how many milligrams of weight each different measuring spoon is.  And so the one-eighth measuring spoon is 500 milligrams.  And so I just, actually, I do two of those.



LEO:  Oh, okay.



STEVE:  That makes it much easier.



LEO:  That's a quarter, if my math may be correct.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  So I also wanted to follow up on this what do we call a two-book series.



LEO:  Yeah?



STEVE:  There was "trilogy," and you found the reference to "bilogy."  Apparently "duology" is the formal noun for, as it described, a pair of related novels, plays, or movies.



LEO:  Except it's not - it's incorrect Latin.  It's not an existing Latin usage.



STEVE:  Right.  And what I didn't explain is that it felt like there just must be a word that I had forgotten.



LEO:  Right, but no.



STEVE:  Like trilogy is so obvious.  We all know trilogy.  What's the one for two?  And it's like there really isn't one.



LEO:  Isn't it funny?



STEVE:  Yeah.  I don't get it.  It's just like, okay.  It's like, I must just be having, as they say these days, a brain fart.  But no.  There just isn't...



LEO:  Isn't that weird?



STEVE:  There isn't a common word for two, and you would think there would be, one that would be as familiar to us as trilogy.



LEO:  Apparently not.



STEVE:  No.  A real quick note from Bob Port, who's in Albany, New York.  The subject was "How SpinRite Kicks Butt."  And everyone knows what the story is going to be.  He said:  "It finally happened.  I knew it eventually would.  A five-year-old hard drive" - okay, so not very old - "on a perfectly serviceable Dell Windows PC started acting up.  It was just getting old, like all of us always are.  I downloaded your utility, SpinRite, and voila.  My hard drive was back in business, virtually good as new.  How simple can life be?  My eternal thanks.  Bob Port."



LEO:  Nice.



STEVE:  And so, Bob, thanks for sharing your success.



LEO:  Voila.



STEVE:  Voila.  And I found myself, when I was reading this, him talking about how simple it is, I've for years - many, many years - resisted adding this or that feature to SpinRite because, I mean, yeah, I could have taken the path of kitchen sink stuff.  But what it does makes so much sense to just simply do what it does, which is just fix the disk.  And in fact it's interesting because recently, when I was working with the beginning of the 6.1 project with a bunch of people online, I sort of suggested, what about if, in the next version of SpinRite I add the "beyond recall" feature?  And the community pushed back hard and said, no, no, no, no, no, you know, make that a separate product, and we want SpinRite just to stay what SpinRite is.  And it's like, oh, okay.  So that's probably what I'll do.



And in fairness, my plan in the future is in fact to recognize that things change, with drives becoming so inexpensive now.  I mean, it's just nothing to go get a replacement hard drive.  SpinRite in-place recovery was born back when nobody had a second drive.  I mean, you weren't using them as doorstops.  They were really expensive.  It was the most expensive component in the entire computer.  And so SpinRite fixed the one you had.  Seven will evolve to doing things like moving your data, being file system-aware and pulling files that specifically you ask - basically, in fact, adding all of those additional features that people have wanted over time.  I'll have a good platform for doing that, then.



LEO:  Nathan Hartley, our first question of the day today,  Nathan Hartley tweeting:  Listening to 578 and would rather see a push to IPv6 with encryption enabled kind of built in for everything than just this push towards IPv4 with HTTPS.  Actually, that echoes what the Father of the Internet told me, what's his name.  You know.



STEVE:  Famous guy.



LEO:  You know that guy.



STEVE:  Yeah.



LEO:  Father of the Internet, you know, Vint Cerf.



STEVE:  Vint Cerf.  I'm glad you and I are of the same age, Leo.  It's like, okay.



LEO:  The guy.  The dad.  



STEVE:  Is he still alive?



LEO:  Yeah, he's a beautiful guy, wonderful guy, beautiful guy, still alive.  Made me cry.  Because we had him on Triangulation.  We had a two-part series.  But I asked him, if you were doing it again - he did TCP/IP.  I said, "If you were doing it again, what would you do different?"  He said, "I'd put encryption in."  



STEVE:  Yeah.



LEO:  So this is a chance to go back and fix it.



STEVE:  Kind of.  The problem is, and I get - I've had many people ask, so I was glad that Nathan's question hit me at a time when it was time for a Q&A.  What was part of the spec of IPv6 was called IPsec, IP Security.  And what it does is it formalizes, I mean, we already have IPsec, which can be used on IPv4, sort of as a higher level protocol.  This puts it into layer three of the OSI seven-layer architecture.  That is to say, IPv6 must support IPsec, as opposed to we're not sure if it's there or not.



But the problem is, and nothing shows this better than the ecosystem surrounding HTTPS and all of its challenges, IPsec doesn't solve any of that.  That is, it's a mistake to just say, "Let's just put security in," because remember that what we're getting is two things.  We're getting privacy from the encryption and authentication.  And so the authentication means we're sure about who we're talking to.  But that's a problem that IPsec doesn't itself solve because there isn't a solution, in the same way that HTTPS doesn't itself solve it.  Those provide a carrier.  They provide a possibility of solving it.  They provide a substrate.



But you still need all of that other gunk which is so problematical.  In the case of HTTPS we have certificate authorities and root trust stores and certificate chains and intermediate certificates and expiration and all that.  So that's the best mechanism we've come up with for really employing HTTPS.  IPsec is definitely useful for point-to-point sort of fixed connection applications.  There is a good key exchange protocol.  But it doesn't - it's not like just switching to IPv6 and suddenly everything is encrypted.  And even if you were to employ, for example, opportunistic encryption, where you do create privacy, that still doesn't solve the authentication problem, meaning that a man in the middle could still decrypt and reencrypt unless you had end-to-end verification of who you were talking to.



And so I just wanted to - I had been looking for an opportunity to say, yeah, it's great that it's going to be there.  But it's not like it's some miracle that allows us to avoid all of these other real bad or big and enduring and even getting worse problems that we see with HTTPS.  All it does is it submerges it down into the lower level plumbing.  And because it is bound into the spec, anything that says we support IPv6 inherently supports IPsec.  Definitely good, so it's necessary; but it's not sufficient just by itself.



LEO:  You know what we really need to do?  We need to start a campaign.  This is kind of off topic.  But Google kind of did this HTTPS Everywhere campaign, and I think they've done probably a pretty good job of encouraging and Let's Encrypt supporting this HTTPS Everywhere.  But, okay, that's good for security.  But we need to do a campaign to end DDoS.  And it's really a simple campaign, just to get ISPs all over the world to block traffic that's not coming from IP addresses they own.  Right?



STEVE:  I wish that were the case.  



LEO:  Oh, but now with these amplification attacks does that mean...



STEVE:  No, no, because those are spoofed also. 



LEO:  Okay.



STEVE:  It's the in-band attacks.  What the IoT devices are doing is issuing valid HTTP requests.  And they don't care about being exposed.  You know, some camera in someone's backyard...



LEO:  Doesn't care.



STEVE:  Doesn't, you know.  And so if they lose that little bot, you know...



LEO:  That's the problem, isn't it, yeah.



STEVE:  Yeah.  It's that unfortunately, just the IP spoofing, that would be part of a good solution.  But what's happened is we've moved now to just flooding sites with valid queries.



LEO:  Right.



STEVE:  Because now the devices...



LEO:  You can block - there's so many IP addresses in there could be real because so what, you turn off that camera.



STEVE:  Right, and so...



LEO:  There's 80,000 other ones.



STEVE:  Right.  And so an ISP technically could see a ridiculous number of redundant queries.  But that's a huge burden to place on them.  They would then be doing traffic inspection in order to look at every single query leaving, and then making basically a value judgment.  And, for example, we know it's impossible to come up with a good porn blocker because it tends to misfire.  It misses things, and it blocks medical pages, for example.



LEO:  Right, right.



STEVE:  So in the same fashion, it's just those sorts of heuristics just don't work.



LEO:  Never mind.



STEVE:  But, yeah.



LEO:  Never mind.  Dante Bertana - oh, go ahead.



STEVE:  No, no, go ahead.



LEO:  Question 2, another tweet.  I wanted to let you know about DuckDNS, another free DDNS, or DynDNS.  They even have copy/paste-able guides to configure your own Pi OpenVPN server:  DuckDNS.org.



STEVE:  Yeah.  A number of listeners have referred to them.  I've heard they've got a great reputation.  And of course we were talking about the idea of people running their own VPN endpoints where that made more sense than using a service.  And so DuckDNS.  I like that also, as Dante mentioned, they explicitly support the little Pi OpenVPN server, which is a simple $35 way of just sticking a VPN server onto your existing router.  And then this solves the problem of its IP moving around if you're away from home.  How do you find your IP if your ISP moves it?  And Dynamic DNS does that.  And DuckDNS provides it.



LEO:  Is that DuckDuckGo?  Is it the same people?  Or is it another duck?



STEVE:  I don't think they're related.



LEO:  Might be Aflac.  Dagan Henderson:  You have said in the past, Steve, that forcing users to change their passwords regularly offers no increase in security.  In fact, we've even said it might even reduce security.



STEVE:  Yup.



LEO:  Because they'd be tempted to reuse passwords or use variants of old passwords or just make them easy and short, easy to remember.  But during Security Now! #578, you said rotating encryption keys (DNSSEC) is considered a good security practice. In both cases, isn't it just a secret being expired and replaced?  Why is key cycling a good practice, while password cycling is unnecessary?



STEVE:  So a great question.  And as your comments, Leo, indicated, it is gray.  There is no question.  We know from experience that where corporations have forced their entire employee base to routinely change passwords, there is a huge back pressure from the people who the IT department are imposing this upon, to the extent that they'll, for example, game the system.  They'll figure out that, oh, look, if I rotate among three, that fools it because it only keeps track of the previous two.  And so I give it a third, and that pushes the one that I'm giving it off the end of the little queue.  Or they'll, like, deliberately change it six times right away and then right back to the one they originally had.  I mean, they just - they don't want to do it.



And so in the case of DNSSEC, though, it wasn't just for the sake of rotating keys.  It was also the fact that they were going from a 1024-bit to a 2048-bit key.  And so that's a ridiculously large improvement of security.  And it's the kind of thing you don't, you explicitly don't want to have to do very often.  So their feeling was, since we're not in an emergency, everything's kind of quiet right now, we can schedule it, people can buy airfare and so forth for the meetings to come together.  Now would be a nice quiet time to do it.



And the other reason is we've talked about the crazy security that that process is surrounded by.  Well, that also says you don't want to do it very often.  It is the weak time when all that is happening.  When this key change is occurring, that's when the system is most vulnerable.  So you want to do it infrequently.  But then that also means you want to get as much value from that as you can.  You want to get enough bang for the effort.



So again, there isn't any sort of black-and-white.  I do argue that changing keys seems more like a bad idea than a good idea because the only argument that I can see for it is if there's a reason to believe old keys are compromised.  And that's when we are changing passwords; right?  When a service announces, oh, shoot, we just lost half a billion of our subscriber accounts' passwords, everybody has to change their password.  So, okay.  There is makes sense.  So what some people have felt is, okay, maybe we don't know of breaches which have occurred.  So we're just going to preemptively force everyone to change their password.  Wow, you know, that's just - that's an expensive thing to ask a large community to do.  So it's a gray area, but I think it could easily be overdone.



LEO:  Question, let's see here, 4 from a fellow named Steve.  Hmm.



STEVE:  Not me.



LEO:  Is that his real name?  Hey, Steve.  Just finished your latest podcast, still a highlight of my week.  A quick note about Windows 7 update problems.  I'm in a team that administers 100s of Windows 7 machines and have found that, if a Windows 7 machine has SP1 installed, simply stopping the update service, then installing Microsoft KB3102810 does the job every time.  We run WSUS servers, and heaps of machines were not updating.  The job was given to me.  I made a group policy startup entry.  It's just a batch file that checks to make sure Windows 7 is running, checks the architecture, then downloads the appropriate update.  Windows actually has a built-in wget equivalent called bitsadmin.  So the batch file stops Win update service, installs the update.  It can still take a couple hours for the machine to finally finish searching for updates the first time, but it has had a 100% success rate so far.



STEVE:  I really appreciate...  



LEO:  What does that update do?



STEVE:  So that's the one that informs Windows of the change in the update service that Microsoft offers.  So if you get a brand new, you know, Service Pack 1 was the one and only service pack for Windows 7.  So if you get a Windows 7 machine with SP1, which is the last image Microsoft made available, and you just say, you know, you install it, and you say go, it just, well, as he said, and as all of our listeners who've tried this know, it just - oftentimes days go by, and nothing happens.



Well, it turns out that, since SP1, Microsoft changed the actual service.  And so the Windows Update back at the time of SP1 doesn't know how to contact Microsoft.  The API was not done in a backward-compatible fashion.  So you stop the update service, install just this one update, and that then informs Windows 7 how to get the other updates from Microsoft.  But the key here, and this is what's often missed, is manually stopping the update service.  That's the key.  Most people just sort of assume it won't be in the way, and so they try to install this update while the update service is running, and there is a collision.  So you stop the update service.  Then you install this and then, like, reboot your system.  Update service will restart, and then it will move forward.



LEO:  Kind of weird, Microsoft doesn't say anything about stopping it in the note about this.  



STEVE:  No.



LEO:  Although they mention that svchost.exe, one of the symptoms is occupying 100% of CPU usage.  Is that the update service, svchost.exe?  I would guess that is, huh?



STEVE:  Yeah.  Yeah, the svchost is a generic process that hosts a whole bunch of different services.



LEO:  Okay.  So stop the update service, you know, you know how to do that; right?  And then apply this patch.



STEVE:  Yeah.  If you go under the Admin tab, there's like a Services.  Or you can click on - I'll never forget, it was Crazy Chris.



LEO:  Pirillo.



STEVE:  Pirillo, yeah, exactly.



LEO:  All you had to say was Crazy Chris.  I know who you're talking about.



STEVE:  Crazy Chris; right.  It was he, because I was new to whatever version of Windows it was, must have been XP, and he said, "You right-click on My Computer."



LEO:  My Computer.  Select Properties, yeah.



STEVE:  Well, actually it's...



LEO:  Actually it's system management; right?  Yeah.



STEVE:  It's Manage.  You select Manage, and that brings up that little tree.  And among there is Services.  And then as you scroll down you'll see Windows Update Service.  And so you just click the little stop button, and that stops it, and then install this update, yeah.



LEO:  Nice, very good.



STEVE:  But it was Chris Pirillo who - and I thought, hey, I didn't know you could get to it that way.  Very nice.



LEO:  You can also, I think, Windows - I wonder if Windows X works on Windows 7?  I think it might.  Windows Key X is the way to do it on Windows 10.  It gives you a great menu of stuff.



Question 5, Good Morning:  Good morning, Steve.  In your episode "Flip Feng Shui" you mentioned that researchers flipped a bit in a public key, making it easily factored to find the private key.  The problem is, if you flip a bit in a public key, it's no longer a product of the private key.  How would you then figure out what the private key was?  So that's a good question.  



STEVE:  It's a great question.  And in my description of how this worked I failed to explicitly note that what the Flip Feng Shui guys had done - I explained how they deliberately caused the memory coalescence so that their process was sharing a memory page with the target process, and that they were then using the Rowhammer attack to flip a bit in where they knew was the private key.  Okay, but what I didn't explain was that what that does is it flips the bit in the one copy that they both share.  So in doing that, you have changed, as Mr. Good Morning here notes, you've changed the key in the other process.  So then in the attacking process they perform the factorization of the modified key.  They then extract the private key and immediately use it, like right now, to log into the process being attacked using their private key.  And it works because it's now being compared against the modified shared public key.  And so in my description I just sort of - I left out that final piece.



LEO:  Wish you had told me.  I've been trying to do this Flip Feng Shui all week.  Joey Bueno.  Hey, Joey.  Steve, could you check out Intel Security's True Key app?  It's free, and it leaves LastPass for dead.  My question is, can we trust it?  Could you please check it out and let the world know if it's okay to use it?  Or is it a spy?



STEVE:  So, okay.  So I thought, okay, this is interesting.  I should find out what Intel's True Key is.  So I dug in, and I didn't see anything special about it.  It's free only for 15 passwords.



LEO:  Oh.



STEVE:  Yeah, exactly.  Thank you.



LEO:  What are you going to do with that?



STEVE:  Yeah.  Which is useful only as a trial, of course.



LEO:  Right.



STEVE:  So not useful for any real use.  Any real use costs $20 per year, with an apparent maximum of 2,000 passwords.



LEO:  What?



STEVE:  Well, okay, so that's a lot, but why have a maximum?



LEO:  Right.



STEVE:  But that's what they say.  The only hook that this has for appeal appears to be Intel's biometrics, which is really, you know, that's what they're actually trying to leverage is their camera and their scanners and so forth.  And so that's okay.  But biometrics are already built into mobile devices and will soon become standard options and features on probably everywhere.  So, for example, by comparison, LastPass and even the SQRL Client for iOS already reprompt the user for their fingerprint confirmation when you use LastPass or SQRL.  So Apple, as we know, made the API available so that apps could ask you to reassert your identity.  I know, for example, the Amazon app on iOS does that, too, which is nice because sometimes it asks, like, twice.  And I have a Pad that doesn't have the fingerprint reader, and now they're making me type in my password twice.  It's, like, so annoying.  But, yeah.



LEO:  Fingerprint's awesome.  Let's get everybody - let's just, you know, just - we all have a phone now.  Almost everybody should have a phone by now with a fingerprint reader on it.



STEVE:  Yup.



LEO:  Apple with OS X Sierra now lets you unlock your Mac using the fingerprint reader on your phone.



STEVE:  Nice.  We're getting there.  We're getting there.



LEO:  A little Catch-22, though.  I thought, oh, great, I'll set that up.  And then it says, well, you have to have two-factor authentication on, on your iCloud account.  I said, oh, that's great.  I didn't even know they had that.  They added that last version, El Capitan.  So I was going to turn on two-factor authentication.  It said, okay, but we've got your security questions right here.  What was the name of your best friend in high school?  I don't - I must have set these questions up seven years ago.



STEVE:  And, if you were smart, you probably...



LEO:  You didn't use the real answer anyway.



STEVE:  Exactly.  You used Joey Bueno.



LEO:  I have no - I said Joey Bueno was.  I remember him well.  So I had no idea.  So I call Apple to reset my security questions.  And by the way, once you turn on two-factor, your security questions go away, another good reason to use two-factor because security questions are the worst idea in the history of security.



STEVE:  Yup.



LEO:  So she reset my security questions.  And I go back, and it says, well, since you've changed your account, you can't turn on two-factor.  First it said for three days.  I understand that.  Three days would be fine.  I understand that.



STEVE:  Yup.



LEO:  Then it said 30 days.  Three days is so a hacker can't just kind of instantaneously reset all your stuff, give you a little time to notice.  Thirty days?  Really, Apple?  So now I'm completely insecure for 30 days?



STEVE:  Wow.



LEO:  Wow.  Funvacuum, not his real name.  Maybe it is.  I don't know.  Shouldn't say.  He might be Finnish.  SQRL.  SQRL, Steve.  You may have already covered this.  I'm on Episode 564.  I'm a little behind.  Do you store a list of websites so we can automatically rekey for all sites?



STEVE:  That question comes up a lot.  And the answer is I don't.  It's not part of the spec.  Okay.  So what he's asking is, as we know, with SQRL you are able to securely rekey your existing SQRL key if you have some reason to believe it's been compromised.  So that's part of SQRL's full lifecycle key management.  But it's incumbent upon you to go to the various sites and do that.  And you can lock them to keep a bad guy from logging in as you until you're able to rekey.  That's easy to do.  Or with your rescue code you are able to rekey and then prove your identity which a bad guy is unable to do in order to get control back.  So this all works.  It's been proposed, and I'm not - I have not put it into my client for a couple reasons.  If it were there, then a bad guy who got your key would also get the list of all the sites where you have used it, and where you visit, and where he should go attack you.  And that seems like a bad idea.



Maybe it could be encrypted, I mean, if I had to solve the problem, I could.  I could come up with a way where it would be dynamically stored, and only the rescue code could be used to decrypt it.  Maybe somebody will want to do that.  I sort of figure, first of all, the system is designed for you not to lose your key, and this is a secure recovery system.  And all you have to do is go to the most important sites first and either shut them down until you get a new key or change the key.  And then you can catch up with the less important ones over time.  Basically, SQRL always carries your old and your new key and is able to seamlessly update them.  So it's really pretty easy.  But I just don't - I don't really like the idea of trying to hold onto every site you've ever visited because it is a potential attack vector.



LEO:  Christian Turri asks:  LastPass is now showing an alert if you have a Yahoo password in your LastPass vault.  That's very nice.  This prompted me to run the LastPass security challenge, which I'm sure you know what it is.  Once the scan on all my passwords was finished, it showed a section of compromised accounts I should change passwords for.  Among them were Yahoo and Dropbox, of course totally expected.  I was surprised to see my Amazon account there, too.  Hadn't heard of any attacks on Amazon.  Appears they have also had and informed some customers about it.  I hadn't heard that, either.



STEVE:  Yeah, I just wanted to share that.  I love the fact that LastPass is doing that.  And I would remind people from time to time, run that little security test that LastPass offers.  You'll probably be a little bit surprised.  And in this case, surprise is a good thing.



LEO:  LastPass makes it easy, though, to fix the duplicated passwords, the bad passwords, the change of passwords.



STEVE:  Yeah, yeah.



LEO:  And just a follow-up, Joe Siegrist is still doing a great job there.  The LogMeIn acquisition doesn't seem to have hurt LastPass.  In fact, I think we have seen evidence of improvements.  I think it's still usable; right?



STEVE:  Yup.  I'm staying with it.



LEO:  Yeah, me, too.  We use it for Enterprise, so we're kind of all in on it.  Okay.  Three fun ones.  You ready?



STEVE:  These are quickies.  And then we're done.



LEO:  MSPoweruser:  Microsoft adds 24-bit color support to the Windows Console.  What?  The c-prompt?



STEVE:  I love this.  This is so good.  This is - and the show notes have a picture of the color palette that you can now present in the Windows Console.  And to me this is, okay, we have run out...



LEO:  Of things to do.



STEVE:  ...of actually useful things to do.



LEO:  In their defense, it probably wasn't that hard to add; right?



STEVE:  What can we, you know, we've got to have a new version.  Oh, my god.  That's what we need.  We need 24-bit color for the command prompt.  Thank you very much.



LEO:  And here's a tweet from Mikko Hypponen.  Of course we know him.  We had him on Triangulation.  He's a security guy...



STEVE:  I love this.



LEO:  ...at F-Secure.  He tweets:  Yahoo's ad revenue is skyrocketing, as 500 million users log into Yahoo for the first time in years to change their password and log out.  True.  True.



STEVE:  Yes.  How many eyeballs have seen those annoying ads?  Yes.



LEO:  I turned on two-factor, too, because they have that.  



STEVE:  Okay, and - okay.



LEO:  I was just going to say - we talked about this last week.  Better to do that than to delete your Yahoo account because you don't want somebody reusing your email.



STEVE:  Good point.  And we did cover the problem of email account reuse.



LEO:  Right.



STEVE:  Somebody was deleting them a long time ago, and it caused a lot of problems.



LEO:  Yahoo was.



STEVE:  Yahoo was.



LEO:  Ironically, Yahoo announced that, if you don't use your email for a period of time, if you let it lie fallow, we'll recover your email address and use it again.  So, especially if you have an email address like I do, that's yourname@yahoo.com, you might want to just kind of keep it around.  And every few months I'm going to send and receive an email there so they think I'm still using it.



STEVE:  Every mistake possible.  



LEO:  Couldn't be worse.  Couldn't be worse.  



STEVE:  And this last one, Leo, I just love it because it shows us that we are in fact getting up there in age.



LEO:  Oh, my god.  This must be a - oh, well, I'll just read it.  An anonymous listener says:  Here's an esoteric question.  Do you know of any audio-based protocols or standards for transmitting ASCII symbols?  Did old machines beep and chirp?  Wow.



STEVE:  Isn't that great?



LEO:  Do you think he's joking, or he's serious?



STEVE:  I think he's serious.  And I just love it.  He probably doesn't have to shave yet.



LEO:  Doesn't know what dit dit dit dot dot dot dit dit dit means?



STEVE:  Or what's a modem?



LEO:  Or a modem.



STEVE:  Alex.



LEO:  Yeah.  



STEVE:  Yeah.  It's just - I just loved it, you know, an audio-based protocol or standard for transmitting ASCII symbols.



LEO:  There must be a way.



STEVE:  Yeah, there are a few of those.



LEO:  But even going back to Samuel F. B. Morse, and they had those wires strung up along the Pony Express routes.  And he said, you know, we should really have some way of sending messages over those wires.



STEVE:  Yup.



LEO:  And we'll make a dit dit dit be an "S," and a dah dah dah be an "O."



STEVE:  Dit dah.



LEO:  Dit dah.



STEVE:  Yup.  I think that's "A"; isn't it?



LEO:  Yeah, the ETAIO, you know, the first most used letters are the simplest.



STEVE:  Yes, which was brilliant.



LEO:  Brilliant.



STEVE:  And basically it's sort of a form of Huffman coding.  The ones you use most often are the shortest.



LEO:  Yeah.  His story is interesting.  You know he was a painter, a very, very, very good painter, shown in the salons of Europe and France.  If you ever want to read...



STEVE:  Morse?



LEO:  Morse.



STEVE:  Really.  Interesting.



LEO:  Well, you know, I only realize that when I'm looking at these great paintings from Samuel F. B. Morse and thinking, gee, I wonder if there's any relation to Morse code?



STEVE:  And did he do anything else of note?



LEO:  I think so.  I think he had quite the life.



STEVE:  Oh, cool.



LEO:  I don't - there must be a biography of Morse somewhere.  But, yeah, if you just look in the Wikipedia, you'll find some interesting stuff.  That's our assignment for this week.  Are you not doing any brain teasers anymore?  Or they just don't - they're hard to come by?



STEVE:  Yeah.  If any present themselves, I absolutely will.



LEO:  Those were fun.  I liked those.



STEVE:  Yeah, those were great.  I have...



LEO:  That would have been a good one.  Does anybody know of any way to transmit ASCII characters in sound?



STEVE:  Yeah.  Can you imagine the amount of effort and time that has gone into that over the years, you know, the sound of geese mating is what I always called the [crosstalk] x-dot...



LEO:  [Modem sounds]



STEVE:  Yeah, exactly.  Boing boing boing.



LEO:  [Modem sounds]  Is there a direct, I mean, I guess it's bits; right?  [Modem sounds] is ones and zeroes; right?



STEVE:  Yeah, yeah.  Oh, I mean, it started as two frequencies, of course.  You know, frequency-shift keying, FSK.  And then, as they kept pushing the standard further and further along, you got all kinds of fancy quadrature and much, much more complex modulation of audio, to the point where, again, as an old-timer, it's like, you can't put 56K through a phone line.  What are you talking about?



LEO:  Actually, there is - this would be a good - here we go.  Here's your brain teaser.



STEVE:  Okay.



LEO:  Is there a theoretical limit to the amount of data you can push down an analog copper wire?  And we'll be back next week, and Leo will do some research.  Because I have a feeling I'm going to have to.  There is, actually.



STEVE:  I know the topic for next week.



LEO:  Yes?



STEVE:  But I am embargoed.



LEO:  [Gasp]



STEVE:  Yes.



LEO:  So a surprise.



STEVE:  So we have a big podcast next week.



LEO:  Can't wait.



STEVE:  Yeah.  It's going to be a goodie.



LEO:  Can't wait.  Well, here's the deal.  Come back here Tuesday, 1:30 Pacific, 4:30 Eastern in the P of M, post-meridian.  Or, for those of you who are on a 24-hour clock, 20:30 UTC.  And you will find me and Steve jawing about security and all that stuff.  You can also join us in the chatroom, irc.twit.tv as you watch, or be in-studio, too, like Nick did.  He came up from Menlo Park to join us.  He's a fan.  Hi, Nick.



STEVE:  Oh, cool.



LEO:  Yeah.  Email tickets@twit.tv, we'll put a seat out for you.  And a pair of headphones.  And you can also, of course, watch after the fact.  We make on-demand audio and video available.  Steve's got the MP3 plus transcripts, which is really nice, available at his site, GRC.com.  And while you're there, don't forget to pick up SpinRite, the world's best hard drive recovery and maintenance utility.



STEVE:  As the slogan for it says:  "It works."



LEO:  What is the slogan?  Oh, it works.



STEVE:  It works.



LEO:  It works.  It's a good slogan.  Pithy.  He has lots of other free stuff there, including his Healthy Sleep Formula and Perfect Paper Passwords.  And you probably first discovered Steve, as many did, with ShieldsUP!, which is still there testing your shields, your router.



STEVE:  Yeah, as this whole IoT thing has happened, there's  been a real resurgence in people wanting to make sure, like, what's going on with their homes.



LEO:  Is my router working, yeah.



STEVE:  Yeah.



LEO:  We also have audio and video at our site, TWiT.tv/sn for Security Now!.  And you could find the show as a podcast, so you can find it everywhere podcasts are aggregated, like iTunes and Stitcher and Slacker and Google and everywhere else.  You know, we also have an Alexa, I'm sorry, an Amazon Echo briefing.  You know, we're on the on the flash briefing - Steve sometimes is, as well - a daily tech news headline.  If you ever do your Amazon Echo flash briefing, what you should do is go on the app and search for TWiT and add us to it.  It's not automated.  It's real voices.  Usually it's Jason Howell and Megan Morrone from TNT.  But we also do bits from the other shows and so forth.  That's for your Amazon Echo.  Thank you, Steven.



STEVE:  You know, you think about ShieldsUP!, I was never able to scan more than that block of service ports because I developed it all when I was behind my two T1s.  But I'm at Level 3 now.  And it might be time...



LEO:  You could do more.



STEVE:  It might be time to do them all.



LEO:  All 65,636?



STEVE:  Yeah.



LEO:  Hmm.  Why not?  I didn't know you didn't do them all.  You just do the canonical zero through 1024?



STEVE:  Actually, I go one line above.  I think it's - I don't remember what the last port number is.  But I go a little bit past that because there was some reason, once upon a time.



LEO:  To cover some port.



STEVE:  To do that.



LEO:  Some port up there.



STEVE:  And then I do the standard port scan or the full port scan.  But those are only the service ports which, back in the day, those were the ones where you would be running services.  But these days and age you're going to have a camera up at port 50,000.



LEO:  Oh, I have stuff on all sorts of ports.  Yeah.



STEVE:  Yeah.  Ah.  Don't worry, everybody.  I'm going to get SQRL finished first, and I'm going to get on...



LEO:  Yeah, you're going to make people mad.



STEVE:  Yeah.  They are, oh, yeah.



LEO:  You have a few things on your plate.  You have a punch list now, Steve.



STEVE:  I do.  But the good news is it's fully parameterized.  When I rewrote it, it's just like, I could just tweak it a little bit and suddenly be scanning the entire port range.



LEO:  See, that's smart.



STEVE:  And now I have the bandwidth, which I didn't used to have.



LEO:  That's smart. 



STEVE:  But, no, I won't do that soon, I promise.  I'll get other stuff done first.  



LEO:  You won't be allowed.



STEVE:  No.



LEO:  Thank you, Steve.  You work hard enough on this show, by the way.  Thank you for that hard work.  We really appreciate it.



STEVE:  My pleasure, my friend.  Talk to you next week with a big story.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#583

DATE:		October 25, 2016

TITLE:		DRAMMER

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-583.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss last week's major attack on DNS, answering the question of whether or not the Internet is still working.  We look at Linux's worrisome "Dirty COW" bug, rediscovered in the kernel after nine years.  We address the worrisome average lifetime of Linux bugs; share a bit of errata and miscellany; and offer an in-depth analysis of Drammer, the new, largely unpatchable, Android mobile device Rowhammer 30-second exploit.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with the latest security news.  He's going to talk about that, of course, widespread Internet DDoS attack from last week, and have info on a brand new exploit.  He was embargoed last week and can talk about it now:  Drammer.  And we'll show you how to test your Android device for it.  It's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 583, recorded Tuesday, October 25th, 2016:  DRAMMER.



It's time for Security Now!, the show where we cover your security and safety and privacy online with this guy right here, Steve Gibson of the GRC Corporation.  Live long and stay safe.  There he is.



STEVE GIBSON:  Yes.  So I promised last week that I already knew the title of today's podcast, and I was under embargo.  I was brought in by the guys who did the Flip Feng Shui some time ago, a slightly different crew that also involves three researchers from Santa Barbara in addition to the guys at the VU University in Amsterdam.  I was informed of what was going on under the agreement that I would abide by their disclosure timeline.  And of course that was before the Internet melted down at the end of last week, which actually affected me in two interesting ways that I'll share when we get to that.  So there was some competition for, like, what's the week's biggest story?



So anyway, I settled on Drammer, which is the name they've given to this next-generation Rowhammer DRAM memory bit-hammering exploit.  But this is significant because they answered the question of whether this could be done on ARM platform mobile devices in the affirmative.



LEO:  Uh-oh.



STEVE:  Which was not believed to be possible.  And remember that I described the Flip Feng Shui as a sublime hack, I mean, just - and I'll quickly review it when we start talking about this at the end of the podcast.  But this is equally sublime.  I mean, these guys are good.  So I'm just so happy that they're on our side, and that they're working to reveal flaws and responsibly disclose as they have to Google.  Google informed their upstream partners - or downstream partners, I'm not sure which way the stream flows - a month ago.  Although while there is some mitigation possible, the underlying problem, as we've discussed when we've discussed Rowhammer for the last couple years - it was in 2014 that this first emerged as a problem - it is a hardware flaw.



And so, while you can sort of dance around and make it more difficult to leverage the flaw into an exploit, everything we see as we look at the history of these things over time is that something that looks like a problem, but, oh, it's nothing to worry about?  Well, give it a year, and someone figures out how to make it a big worry.  So that's the main focus.  But of course we're going to talk about last week's powerful denial of service attack.



Linux has a new problem that Linus himself wrote about.  It was actually a problem he took some responsibility for nine years ago, known as "Dirty COW."  COW, C-O-W, is the abbreviation for Copy On Write.  And it turns out there is a longstanding race condition in all Linux kernels which is really critical.  Essentially, any web-exposed Linux server is vulnerable.  So all of our listeners who have web-facing Linux servers need to understand what's going on and get themselves patched.  Oh, and it was discovered in the wild.  So this is unlike, for example, Drammer, which is a researcher-driven theoretical problem that they've made real.  This was discovered from traffic analysis happening to someone's server.  We also, sort of related to that, an interesting look at the average lifetime of Linux bugs.  There was a study done about six years ago, and that's been updated by a Google researcher.  And nothing has changed, unfortunately.



We have a little bit of errata and miscellany.  And then, as I said, we'll take a real close look at the details of this latest Rowhammer exploit, Drammer, as they call it, which is quite a concern.  So lots of good stuff to talk about.



LEO:  It's going to be a good show.  Looking forward to it.  Let's pause briefly before we get to the news of the week.  And the news of the week is going to talk a little bit about the danger of Internet of Things devices.  And here we go with an Internet of Things device.



STEVE:  And it sort of brings the point to bear, along with this week's Picture of the Week in the show notes, that not all of these connected things really justify their connectivity.  I mean, it's sort of a reach, for example, when you've got, like, an Internet-connected coffee pot.



LEO:  Right, right.



STEVE:  It's like, okay, well, you know...



LEO:  Okay.



STEVE:  Yeah, I guess I could start brewing while I'm stuck in traffic so the pot is ready for me when I get home, but...



LEO:  But there are some things that are really useful, too.



STEVE:  Yes.



LEO:  And so that's the thing is be judicious.  I mean, you can't not connect a router to the Internet; right?  So make sure you get one that's well designed, I guess.



STEVE:  Yeah, yeah.  Well, and several people sent me this The Joy of Tech cartoon.



LEO:  I have it here, so I'll show it.



STEVE:  It was titled "The Internet of Ransomware Things," where the smoke alarm up on the ceiling is saying, "30 bucks in bitcoin, or next time I smell smoke, I might just let you sleep."  Or the dishwasher says, "Your dirty dishes can wait.  I'm busy mining bitcoins."  The lamp hanging from the ceiling and the camera sitting on the counter say, "Excuse us while we participate in a DDoS attack." 



LEO:  Yikes.  That's a little too close to home, huh.



STEVE:  It is a little too close, yes.  So anyway, and this is just full of - it shows a little robot vacuum zooming around, saying, "Wire my hacker $100 or I'll reverse my motor and blow dirt all over the place."



LEO:  That's pretty funny.  This is Nitrozac and Snaggy.  We love The Joy of Tech.  And of course they do the album art for this show.  Nitrozac did that great illustration of Steve, which we're going to maybe have to update.  I think your mustache has gotten a little grayer.



STEVE:  Yeah.  And I always look a little snootier in that than I [indiscernible].



LEO:  We could get another one.  We'll go get another one.  She's very kind.  She updates us.



STEVE:  Anyway, so clearly they know their IoT problems because they pretty much nailed every bad thing that could happen.  I was tempted to call this "Attack of the Light Bulbs," or then in homage to an old Internet meme that you'll of course remember, "All your light bulbs are belong to us."



So my own intersection with last week's problem was when I received, at about 7:30 in the morning, an iMessage from Sue, my bookkeeper.  She had been away from the office for about a week, traveling with her laptop and checking in constantly to deal with any sales.grc-related mail stuff.  And she sent me a note saying that Eudora - yes, we're all still using Eudora - was returning "GRC.com address not resolved" error.  And I thought, whoa, that's odd.  And so I shot her a text note back and said, well, okay, that doesn't really sound like our problem, but I'll look into it.



And then, like maybe two hours later, I got an alert saying that one of GRC's eCommerce transactions had failed.  And I do, if the GRC server is unable to connect to our merchant gateway through which we process customer credit card transactions, it waits like a few seconds and tries again.  So it does 10 retries and then declares a failure, and then returns a response to the user through the web page that something outside of our control is preventing us from successfully completing the charge.  You know, it's not you've got the zip code wrong or your street address doesn't match.  It's something else.  So that happened.  Someone was determined to buy a copy of SpinRite, so I had to listen to 30 individual sets of - or three sets of 10, so 30 total error messages.  It generates the Star Trek hailing whistle, and then a voice says...



LEO:  [Whistles]



STEVE:  ...something about - exactly - eCommerce transaction retry, and then does that 10 times, and then eCommerce transaction failure.  So I always know what's going on.  So then I started seeing the news about a DNS-related outage.  And that, of course, put all the pieces together for me.  That explained why Sue, wherever she was, she was down like in Texas or somewhere, where whatever DNS server her location was using was unable to obtain the IP for GRC.  And suddenly I thought, ah, I'll bet you that that's what's happening because of the coincidence that GRC's eCommerce system was unable to obtain through DNS lookup the IP for the merchant gateway.  But I was able to get it from here as a Cox subscriber.



So I looked up the IP, jumped over to GRC's server, and dropped an entry into the hosts file.  And as we all know, the hosts file, even today, is - and this is on a Windows 2008 R2 server, so a recent server - it looks in the hosts file first.  Well, what I found, interestingly, was I had already commented out the line I was going to put in.  In other words, this had happened previously.  So all I did was I removed the pound sign from the from of that line because the IP had not changed from whenever it was I had done that before.  And then immediately eCommerce transactions started to process again.



So we had a big DNS problem.  And of course everybody knows about last week's massive outage.  Now, I think what surprised people, though, was, well, several things.  Our listeners know enough to wonder why DNS caching didn't mask the problem.  And I will explain why that is.  But essentially there was a company based on the East Coast, Dyn, that is the authoritative nameserver for, as we learned, many major providers.  Meaning that that service - and, I mean, Dyn is a major DNS provider.



LEO:  So are they one of the 13?  Or are they a subsidiary to the main phone books?



STEVE:  So, yeah, they're not the root servers.



LEO:  The root servers, yeah.



STEVE:  They would, for example, they offer the servers that a domain registrar points to.  So, for example, if you look up Twitter.com's registrar, whoever they're using - very much the way, for example, I'm using Hover right now.  So for the domains I have at Hover, I've given them the Level 3 servers that GRC uses.  And so those are the authoritative domain nameservers for GRC.  That is, that's where GRC.com's DNS records are.  And so it turns out that many of these large companies have outsourced their DNS.  You know, being me, of course, I don't.  I do my own.  And in fact I actually have the root server, and Level 3's are slaves.  So they actually handle all of the traffic, but they obtain what's known as the GRC.com zone record from my master server, which is a FreeBSD Unix machine.



So these major companies just thought, you know, there's no value to be added by DNS.  And they also wanted, you know, I mean, they're much larger than GRC.  I'm fine having two strong Level 3 DNS servers serve GRC's DNS.  But Twitter and Amazon AWS and huge, huge Internet presences, they really need multiple physical presences, you know, multiple points of presence - so West Coast, East Coast, international and so forth - so that the world's DNS queries are not all just pounding on one or two servers, but are being distributed by essentially the equivalent of a content distribution network for name services.  And that's what Dyn offers.  The problem is...



LEO:  So if I'm using Hover - I didn't go down because I was using what they chose.  But you were doing your own.



STEVE:  Correct.



LEO:  Got it.



STEVE:  And so, yeah, so you could use Hover's DNS; or, as I do, I could point my Hover registration record at Level 3's DNS.  And instead they, like Twitter, have pointed their registration's record at Dyn's DNS servers.



LEO:  Oh, so it's because you were using Level 3 that you got hit.



STEVE:  No.  It's actually that whoever - well, for example, my merchant account company was using Dyn because they're all...



LEO:  So your GRC wasn't down.



STEVE:  Correct.



LEO:  But you couldn't take a credit card.



STEVE:  Correct.



LEO:  Got it.



STEVE:  And wherever Sue was, her DNS provider was somehow affected by this, too.  So anyway, it was a wakeup call that so many major sites could be taken down by an attack on one part of the infrastructure.  And we've often talked about, because we've talked about DNS often, it is UDP protocol, which is meant to be lightweight.  And what that means is that it is inherently spoofable.  TCP connections cannot be spoofed because you need that three-way handshake.  Packets have to be able to make a successful roundtrip from each endpoint to the other and back in order for a TCP connection essentially to be completed and connected.  But that's an overhead that simple lookup services minimize, so they simply just send off an unverified UDP packet towards its destination.  And if they get a response, that's great.  It was very quick and inexpensive.  If they don't, they wait a minute, well, not a minute, but a few seconds, and then they try again.  So they take responsibility for trying to get a response.



But what that also means is that, for example, they're able to deliberately rewrite the outgoing packet's apparent source IP to mask their actual source IP.  And if those illegitimate source IPs are allowed out onto the Internet, and that's something we've talked about often, the whole issue of egress filtering, where ISPs currently do allow packets that cannot have, I mean, whose packets clearly are known, could be known to the ISP to be falsifying their return address, essentially, their source IP.  All the ISPs know if packets are leaving that could [audio glitch], if there is an illegitimate source IP.  They arguably should be dropped onsite.  They should just simply be ignored.  But that's not happening today.



So there is actually - there is an RFC and a proposal, BCP 38.  And the RFC is 2827, which is titled "Network Ingress Filtering:  Defeating Denial of Service Attacks Which Employ IP Source Address Spoofing."  And there's even an acronym for a movement that is trying to get itself going called SAVE, which is Source Address Validation Everywhere, the implication being there are even chokepoints where - and I've talked about this, too.  A router in the middle of the Internet has a routing table that tells it which connections to send packets to based on where they're going.  But that can also infer which connections packets can have come from.  And so even routers in arbitrary locations could be made smarter and to recognize packets which cannot be valid.  But, again, nobody's doing that.



And we talked about this last week.  It was funny because you and I were talking about IoT and about source address spoofing.  And I mentioned that, unfortunately, there were other attacks that did not rely on spoofed source addresses.  And so those would pass right through such filters.  And in fact, the attacks last week did not rely on whether they spoofed their source addresses or not - and they may have because they were DNS attacks - but they didn't need to.



Okay.  So Dyn wrote something, sort of a, not saying very much, corporate-level speak.  In their blog posting under "What We Know," they said:  "At this point we know this was a sophisticated, highly distributed attack involving tens of millions of IP addresses.  We are conducting a thorough root cause and forensic analysis and will report what we know in a responsible fashion.  The nature and source of the attack is under investigation, but it was a sophisticated attack across multiple attack vectors and Internet locations.  We can confirm, with the help of analysis from Flashpoint and Akamai, that one source of the traffic for the attacks were devices infected by the Mirai botnet.  We observed tens of millions of discrete IP addresses" - assuming those were not spoofed because, of course, if they're just pseudorandom, then they could easily be, not tens of millions, but 10 pretending to be more.  But we now know that this is a huge botnet.



Okay.  So what was interesting, as I dug into this, is that I looked at some of the traffic that this Mirai was using, and it looked disturbingly familiar because I realized that it was using a weaponized version of the technique I used six years ago when I wrote GRC's DNS Benchmark and GRC's DNS Spoofability Testing.  For the Benchmark, I explicitly need to bypass caching, or selectively bypass caching, because the DNS Benchmark wants to determine how fast your local DNS caches are, but it wants to separate that from the speed of the authoritative nameserver that is the ultimate source of the DNS information.



The way I do that is I create made-up domain names, pseudorandom gibberish, for example, dot something dot com.  And so the idea is, since that pseudorandom gibberish cannot yet exist in the local DNS resolver, it is forced to shrug and forward it to the authoritative nameserver to see if that's a domain that the authoritative nameserver knows about.  So this is a deliberate cache-busting technique.  And, unfortunately, it's what Mirai uses, whereas I was very careful never to use this to overload any DNS server.  And in fact, one of the things that the DNS Benchmark does, it wants to determine the reliability, the response reliability of the servers that it is benchmarking.



So I do not want to clog the channel which would cause a false positive packet loss.  So I meter these queries out, only allowing one to be in flight at any time to any given server of the batch that are under test.  Of course, Mirai wants to attack remote DNS servers.  And, so, see, what it needs to do, it must bypass its local ISP cache because, if it simply asks for Twitter.com, well, if the local cache run by its ISP wasn't already aware of Twitter.com - and, I mean, it almost certainly would already have it in its cache.  But if it wasn't, then it would have to make a query to Twitter.com's authoritative nameserver in order to determine what Twitter.com's current IP is.



And so that's where it goes to the root, to the com, the dotcom servers, essentially, in order to look up Twitter.com.  Then it goes to Twitter.com's server to see what Twitter.com's current IP is.  So but the point is that, if say an aberrant DVR - because we know that a lot of these were commandeered DVRs.  If the DVR made a query once, it might force the local DNS server to look up Twitter.com.  But now it's in that local DNS server's, that local resolver's cache.  So all subsequent queries for Twitter.com would not bother the actual Twitter.com DNS server because they're now cached.



And so what I did many, many years ago, and even do now for the spoofability testing, is I deliberately make up fake domain names, subdomains, in order to get queries from - in order to send queries through the cache to get to the actual servers.  These guys are doing it to attack the servers.  So that's a cache-bypassing attack which, as we've seen, is super effective.  Now, our listeners wondered why a DNS server going down, an authoritative DNS server, why wouldn't that be buffered by valid caching for valid domain queries?  And the answer is it certainly was.



But the problem is, not only do you have the IP address in a domain record, but the domain owner is able to set the cache duration.  As part of the DNS record, they're able to specify, once this is queried, how long they want that result to survive out in the Internet's caches.  And, unfortunately, not everyone has those set optimally.  There are instances where you would deliberately want it to be shorter.  For example, when many years ago I was moving GRC from behind my two T1s, where it lived for a long time, over to Level 3, that meant that GRC.com had to - I was going to completely change all the IP addresses from the block that I had with Cogent who was my bandwidth provider, over to a block that I had been assigned by Level 3.



So what I did a couple days before this planned changeover, and everyone will remember that it was - "planned" is being kind because suddenly I lost my connection.  And I called them up.  I said, "What happened?"  And they said, "Didn't you get the mail?"  I go, "No, I haven't had that email address for 10 years."  So, anyway, it was a little bit of a fire drill around here.  But the point is that, knowing that it was going to happen, I shortened GRC's DNS to 15 minutes, and I did it a day before.



So what that meant was that essentially I drained the cache, or at least I drained the long expiration cache out of the Internet.  And it took, for example, if it had been previously set for eight hours - I don't remember now if it was eight or 24.  But I had to wait at least - I had to keep the old IP at least as long as the cache had been, so that all DNS servers on the Internet would have come back and refreshed themselves.  But when doing so, they would be refreshing themselves with the 15-minute, the very short-duration DNS record, so that would then force them to come back every 15 minutes and get an update.



So what that meant was, when I did bring up the new servers at Level 3 and then changed GRC's DNS, within 15 minutes the entire Internet was informed of that change because I had planned it that way.  And so there wasn't a big outage.  If my DNS, for example, had been set to 24 hours of caching, and something had forced me to make an unplanned emergency change, it would be staggered through the 24 hours because DNS resolvers all over the Internet would have different comeback times.  But the oldest of the caches wouldn't have expired for a full day before it got news of the new IP.



So the point is that, if these major companies had their caching set to 24 hours, there still may have been some outage, but it would have been spotty.  So the point is that the authoritative nameservers were effectively DDoSed off the air.  So nobody was able to refresh their cache with new information.  But if these major, like Twitter and others had set very long records, and they could do that if they had a known stable IP address, then they could better survive a few hours here and there of a shortage.  Some people would see an outage.  Others, their local resolvers would have been able to keep the cached information for a much longer period of time and would have never had to come back and update themselves.



Anyway, so that's the whole story of what happened.  Stepping back from this a little bit, I was reminded of a comment that our friend Bruce Schneier made recently regarding IoT device security.  He said:  "The market can't fix this because neither the buyer nor the seller cares."  Now, of course, that's not true of our listeners.  But look at all the DVRs that are out there.



LEO:  I think people are caring a little more than they did before.



STEVE:  Yeah.  



LEO:  They'll care.  XiongMai, that made most of these devices, has already started to update them and do recalls and stuff.  They are a Chinese company.



STEVE:  Well, and to threaten suing Brian Krebs and others.



LEO:  XiongMai is suing Brian Krebs?



STEVE:  Yes, saying that he is maliciously reporting and blaming them for the whole attack.  They're denying that they are as responsible as they are.  So it's like, okay, well, you know, play the game.



LEO:  That's a problem.



STEVE:  Yeah.



LEO:  That does validate what you just said.  They don't care.



STEVE:  Yeah.  So I should mention also that we've talked about the Shodan search engine, which is scouring the Internet and logging anything it finds.  There is a simple IoT scanner which makes a query of Shodan for a user's IP to see if any given user's IP exists in Shodan's database.



LEO:  Oh, that's nice.



STEVE:  It's iotscanner.bullguard.com, I-O-T-S-C-A-N-N-E-R dot B-U-L-L-G-U-A-R-D dot com.  It gives you a nice presentation and just explains that, if you click this button, it'll check Shodan for you to see if you are listed.  I pressed it, and I wasn't.  I passed it on to my buddy who's gone IoT crazy, although he's got the three dumb router configuration, and he's isolated.  And, good, you are not public on Shodan.  You can do a deeper drill as the next phase; but they warn you that, if you do, that may bring you to Shodan's attention, where you may not have been there otherwise.



LEO:  Why would I not want to be brought to their attention?  I am now, apparently.  I just pressed the button.



STEVE:  Yeah.  And I think that probably, you know, they're doing enough job of scanning.  And, good, no vulnerability found again.



LEO:  Now, this is here, of course, and we got Astaro routers in between us and security boxes in between us and the outside world.  



STEVE:  Well, so of course, that's the problem, too.  It's why I referred to, someday, considering doing a comprehensive 65K, or 64, depending upon how you count, port scan because what a lot of these IoT devices do is they leverage universal plug-and-play in people's routers in order to open up incoming ports to themselves.  I mean, that's the only way something out on the Internet can find your DVR, if the DVR has, as part of its setup and configuration, opened up an incoming port to itself.  And unfortunately, ShieldsUP! doesn't currently find that.  And it's very labor intensive.  It's not something you can scan for inside your network.  You need somebody to scan for you on your behalf outside your network.  And so it might be worth having our listeners use this iotscanner.bullguard.com, just to make sure that there's nothing that they've got flapping in the breeze publicly that they're not aware of.



LEO:  You can't provide it with an IP address.  It just checks the network you're currently on.



STEVE:  Correct.



LEO:  Be nice if I could say - because I'd like to check my home address right now, but I'll have to [crosstalk].



STEVE:  It would be nice, although, of course, that's subject to abuse.



LEO:  Right.



STEVE:  I do the same thing with ShieldsUP!.  I will test where you are connecting from.



LEO:  Right.



STEVE:  But I do not let you put an arbitrary IP address in because, of course, people would then be using me to scan other people.



LEO:  Right, right, exactly.



STEVE:  That's not...



LEO:  Check and see how safe they are.



STEVE:  Yeah, no.



LEO:  Yeah, I don't blame you.



STEVE:  So anyway, you know, there's nothing we can do except protect ourselves.  And I don't know how this gets resolved.  As Bruce said, the problem is, you know, you go to Amazon, and people are clicking buttons to download light bulbs and baby cams and all this stuff.  And they're fun, but they're creating a problem, not only for - I was explaining to my friend, who's like, he's always showing me his pictures around his home when we're out grabbing a bite.  And I go, "Uh-huh, well, that's not good," you know.



And at this point these devices are of interest to attackers for use in commandeering them for attacks like we saw last week.  That's sort of the low-hanging fruit.  Eventually, they're going to get around to poking around inside people's networks using, I mean, this absolutely can be done.  If you've got these DVRs which have had malicious software installed in them, this Mirai botnet, then that's - and it does exist only in RAM, as we know.  If you reboot these devices, that flushes it out.  But if they remap a port and go public again, they're infected within five minutes because there are so many of these things now scanning for others.



But what this means is that you've got remotely controlled malware on your internal home network, and it has full visibility to the net it has access to.  So there's never been a better case for network segmentation that we've been talking about now for quite a while.  You have to have these, you know, your high-value computing resources separated from stuff that you can't and no one can reasonably represent are secure.  And ultimately we're going to see people beginning to have - right now it's just using these things for attack.  They're going to end up becoming points of intrusion.  It's inevitable.  So it's called...



LEO:  Lovely news.



STEVE:  Yes.  It's called "Dirty COW."  Linus wrote...



LEO:  This is not what Donald Trump called Hillary Clinton, I don't believe.



STEVE:  No, that was "nasty woman."



LEO:  That's right, okay.



STEVE:  Dirty COW.  So on last Thursday - he does pronounce his name "Linus."  I always feels self-conscious saying "Linus."



LEO:  Does he?



STEVE:  Yes.



LEO:  Everybody's saying, "It's Linus, it's Linus."  It's Linus, huh?



STEVE:  I made a point once of listening to him say it of himself.  I found some audio of him pronouncing his own name.  It's Linus.  So he wrote:  "This is an ancient bug."  He called it "ancient."  Okay, well, maybe in Torvalds' timescale.



LEO:  It goes back to almost the beginning; right?



STEVE:  Well, nine years.



LEO:  Okay.  That's a long time.



STEVE:  So, but, yeah, okay.  "An ancient bug that was actually attempted to be fixed once" - he says in parens - "(badly) by me 11 years ago in a commit," and he gives the commit number.  And it was called "Fix get_user_pages() race for write access."   Then he says:  "But that was then undone due to problems by a subsequent commit which was ('fix get_user_pages bug')."  So he made a fix that he's now unimpressed with, which was then fixed.  And that fix broke the kernel in a way nine years ago that allows this race condition.



And you know, but a lot of our listeners don't, a race condition is sort of a famous problem in computing in general, and actually before that in electrical engineering.  It's any situation where two things are not supposed to happen at the same time.  That is, typically, they're trying to be mutually exclusive.  So that, for example, each one checks to see if the other one has happened.  And, if not, then it happens, and it blocks the other one.  And this is a problem.  I've been dealing with it for years.  For me it's just now at an instinctual level I'd handle this because in multithreaded code you've got multiple threads of execution.  And when we've got multiple cores, we actually have multiple processors running around in our code at the same time.



There are some things, for example, say that you had an increment, where you want to increment a value in memory.  Well, you do that by reading the current value into a register, incrementing the register, and then writing it back.  But say that one thread read the value from memory, and at that instant there was a context switch, so that thread was paused, while another thread ran.  And that other thread read the same value into its context.  And then the context switches back.  And the first thread increments that and writes it back.  Then the second thread increments its copy and writes it back.



Well, notice what happened.  We intended to have two increments, but only the second one survived because of a race condition where they both had essentially nonexclusive access to a single location in memory.  And this causes all kinds of problems in computing because, for example, you have things like reference counts in garbage collection where a variable is dynamically allocated, and you need to keep track of how many different places it's referenced, and you increment that going upwards.  And when you no longer are using that variable, you decrement it going downwards.  The last process or user to cause it to be decremented to zero allows that to be freed.  Well, if your counting has been faulty as a consequence of race conditions, all kinds of havoc.  That's where you get memory leaks, and buffers that are deleted when they shouldn't be, and nightmares.



So this can happen in electronics, where you have two edges of two different signals that are not supposed to happen at the same time, and it can happen in OS kernels.  So there is, has been for nine years, an unappreciated race condition in the Linux kernel.  And this was discovered by a Phil Oester, who is a Linux developer who routinely logs all HTTP traffic to his web servers and analyzes it for forensic purposes, just to kind of keep an eye on what's going on.  And so a few days ago, or last week, he's looking at his logs and processing them however he does because no doubt that's a lot of data, which is why most people don't keep track of every single query, and he discovers this thing being done to his Linux servers in the wild.



So this is a high-severity, nine-year-old bug in the Linux kernel.  Any system running Linux on a web-facing server is vulnerable.  Somebody knows about it and has been exploiting it.  It allows an attacker to gain write-access to memory that should be read-only.  And it's a big concern because it's not difficult to develop exploits that work reliably.  It's located in a section of the Linux kernel that's part of virtually every distribution of Linux that's been released for the last nine years.  It has been fixed.



And so Red Hat is aware of it.  I saw an announcement from them talking about, you know, this is a zero-day.  Update your Linux kernels.  So everybody who's running Linux on web-facing systems needs to get themselves updated because no doubt bad guys, I mean, now the information is out there.  This is where we see a quick escalation in exploits, and it's not difficult to do.  Which means people are going to be looking for unpatched Linux kernels.  And now we have the problem of little, small, micro Linux kernels in IoT devices that are never going to get patched and that have been sitting on networks.  Maybe they're in closets; maybe they're people's routers.  But they're certainly web-facing if they're exposed to the Internet.  We're in for some interesting times, Leo.  Wow.



LEO:  Yeah.  I mean, it's web servers, we should point out.  So if you're running Linux at home, unless you're running a server on it, you're not...  



STEVE:  No, it's web-exposed servers.  So anything with an open port is a server by definition.



LEO:  Okay, all right.  Okay, all right.



STEVE:  Yeah, yeah.  So it's not just classic web servers.  It's anything that is responding to unsolicited incoming traffic, like all those DVRs that have opened a port and are being scanned for and located.



LEO:  So it could be a remote exploit.  But you would have to, well, go to ShieldsUP!.  Make sure you don't have any open ports.  You'd have to have a port open for something on your Linux box.  Which many people do.  I mean, if you allow SSH into a Linux box, if you...



STEVE:  Precisely, precisely.



LEO:  Yeah.



STEVE:  Yeah.  I mean, this is bad.



LEO:  Or a mail server.



STEVE:  Oh, and it takes five seconds, by the way.  I forgot to mention that.



LEO:  Oh, well.  You didn't mention that.  Oh, never mind, then.  Nothing to worry about here.  All right.  On we go.



STEVE:  So he spells his name "Kees," but it's pronounced "case."  Kees Cook is with Google.  He describes himself, saying:  "I work for Google on ChromeOS security.  Previously, I worked for five years at Canonical as an Ubuntu security engineer.  My work is to stay alert, curious, and creative while keeping one step ahead of the bad guys.  While I'm not working, I have been known to play with MythTV and generally poke around at video formats."



So last week he wrote in a blog post:  "In several of my recent presentations, I've discussed the lifetime of security flaws in the Linux kernel.  Jon Corbet did an analysis in 2010 and found that security bugs appeared to have roughly a five-year lifetime.  As in, the flaw gets introduced in a Linux release, and then goes unnoticed by upstream developers until another release five years later, on average.  I updated this research for 2011 through 2016 and used the Ubuntu Security Team's CVE Tracker to assist in the process.



"The Ubuntu kernel team already does the hard work of trying to identify when flaws were introduced in the kernel" - which is really neat to know, like, where this came from, which whenever I find a bug in my own code, I just - everything stops, and I say, okay, how did this happen?  Because I want to work on the process rather than just fix the problem.  I want to work on perfecting the technique of not having this happen again.  So I'm delighted that they're looking back to determine where this came from to see if they can, you know, if there's anything they can do to improve the process.  So, he says:  "So I didn't have to redo this for the 557 kernel CVEs since 2011."



LEO:  Wow.



STEVE:  Uh-huh.  So the numerical summary is critical flaws were two, and they were fixed at 3.3 years of age.  High vulnerabilities were 34 of them fixed at 6.4 years of age, on average.  There were 334 medium concern vulnerabilities fixed at an average age of 5.2 years.  And then 186 low-impact vulnerabilities fixed at an average of five years.  So he says his comes out to roughly five years lifetime again, so not much has changed from Jon's analysis in 2010.



And he says:  "While we're getting better at fixing bugs, we're also adding more bugs."  And of course that brings us back to that T-shirt that we talked about a few months back of the 99 bugs on the wall, take one down, whatever it was, fix it, 113 bugs.  Or 99 bugs in the code, and then it's 113 bugs in the code because this stuff is complicated.  And so often now things we do have unintended consequences.



So he says:  "And for many devices that have been built on a given kernel version, there have not been frequent, or sometimes any, security updates, so the bug lifetime for those devices is even longer.  To really create a safe kernel, we need to get proactive about self-protection technologies.  The systems using a Linux kernel are right now running with security flaws.  Those flaws are just not known to the developers yet, but they're likely known to attackers."  And we just discussed exactly such a story, where this race condition was discovered from its use in the wild.  "But they're likely known to attackers, as there have been prior boasts/gray-market advertisements for at least" - and then he notes a couple common vulnerability numbers.



So anyway, from my standpoint, I mean, we recognize now that very complex software is very difficult to make perfect.  And we also know that security is, by its nature, in our current model, and they say it because I don't think it always has to be this way, but our current model, exactly sort of as he implies, is the weakest link, that is, security is a chain.  And the strength of the overall chain is limited by the strength of the weakest link.  And every single one of them has to be strong.  And the way our systems are designed today, unfortunately, that's the nature of it.  I mean, so you could argue we're fighting a losing battle.  The systems are inherently insecure, that is, their design promotes problems.  So it's only by being as perfect as we can about not inducing problems which are sort of natural, that we get security.



So, again, it's an uphill battle.  And now, with the IoT revolution and the fact that so many people are using tiny Linux microkernels, pulling from the free open-source codebase in these devices, they're going to have these problems, and they're never going to get fixed.  I mean, even older mobile phones with Android are not going to get fixed.  They're not going to get patched.  And I've heard you talking, Leo, about for example the Pixel and how good it is, that it's a phone you love, and Google is 100% behind it, and we know that it's going to be kept current.



LEO:  Well, for a couple of years anyway.



STEVE:  Yeah.



LEO:  I mean, that's the only problem.  Even Google doesn't - like the Nexus 6 is already out of support.



STEVE:  Right.



LEO:  Or will be in a couple of weeks.



STEVE:  And in fact it was the 5 and the 6, it was the 5 specifically, but also the 6, that we'll be talking about shortly, that the Drammer guys found as exploitable.  So as soon as those phones are no longer maintained, they become platforms, yeah.



One little bit of errata from last week.  I got a kick out of this.  Someone shot me a tweet after the podcast on a CNET article whose headline was "Tech luminaries laud Dennis Ritchie five years after death."



LEO:  Did they mention you?



STEVE:  No, no, no.  I'm not a luminary.  But the subtitle was:  "Well-known tech figures appear to have forgotten the father of the C programming language died years ago, falling victim to social media's 'second death syndrome.'"  They go on.  "Some of tech's biggest names are paying tribute this evening to computing pioneer Dennis Ritchie.  Ritchie was an internationally renowned computer scientist who created the C programming language.  He also made significant contributions to the development of the Unix operating system, for which he received the Turing Award in 1983.



"The problem, especially if you look at it from Ritchie's perspective, is that he's been dead for five years - exactly five years.  The time gap seems to have escaped some of the biggest names in tech, including Google CEO Sundar Pichai, who late Wednesday tweeted out Wired's five-year-old obituary on Ritchie..."



LEO:  That's where it started.  So you know what?  That's where it started.  Everybody copies Sundar, yeah, yeah.



STEVE:  "...thanking him for his immense contributions."  And then:  "Om Malik, a partner at True Ventures and the founder of tech site GigaOm," who of course is a wonderful and frequent guest on your TWiT show...



LEO:  Yeah, we love Om.



STEVE:  "...retweeted Pichai's tribute before soon recognizing his mistake and tweeting an apology for 'adding to the confusion and noise.'"  Which of course I also did last week.  So I thought that was an appropriate [crosstalk].



LEO:  You did for moments, and then you corrected yourself.  You know, in a way it's fitting because one of the reasons I remember this vividly is because he died the same week Steve Jobs passed away.  And Steve Jobs, of course, got all the ink.  And I received numerous emails, and there were many tweets from people who said, "How come Steve gets all the credit?  He created nothing.  And Dennis Ritchie passes away, and no one notices."  And, of course, neither is exactly true.  But, sure, five years later...



STEVE:  Well, it's pop star versus, you know, our star.



LEO:  Right.



STEVE:  You know, I mean, I'm waving my K&R book around last week.



LEO:  Yeah.  Well, I think in a way it's kind of fitting that now all the noise about Steve Jobs has faded away, we can give Dennis the tribute he finally deserves.  



STEVE:  Indeed.



LEO:  Mm-hmm.  I was wondering where this started, and I bet you it started with Sundar.  It had to be somebody so influential that everybody else would say, oh, and retweet it.  And I saw those retweets; and I thought, this is weird, because I remembered it.  And so that explains it.  It's somebody so kind of godlike that no one would even say, "Well, let's see if that date's right."



STEVE:  You just don't bother doing a double-take, yeah.



LEO:  Right, right.



STEVE:  Yeah.  And in fact, even if you had doubts, you accuse yourself of being wrong.



LEO:  Right.  Oh, I must have forgotten, or I must be mistaken.



STEVE:  Yeah.  I was thinking about somebody else.  And of course we did lose Dave Bunnell in this past week.



LEO:  And Beranek of BBN (Bolt, Beranek and Newman).



STEVE:  Yes, yes.  



LEO:  Who's an interesting story because he was an acoustic engineer, formed BBN in Boston, and was invited by ARPA to design the early Internet.  And BBN did, in fact.  And he passed away.  He was 102.



STEVE:  Wow.



LEO:  So it shows you.  Invent the Internet, live a long time.  David Bunnell, sad to say, merely 69, which...



STEVE:  I know.  And do we know anything...



LEO:  As we get into our '60s, that sounds too young.



STEVE:  Hey, I'm there, baby.  You know, I'll be crossing in...



LEO:  Steve, they'll be talking about us soon enough, believe me.  We're getting into that territory now; you know?  But Bunnell was, in many ways, I did not know him.



STEVE:  Instrumental.  He was key in the PC industry.



LEO:  Yeah.  He founded PC Magazine and PC World, arch rivals; MacWorld magazine; and was the inspiration, mentor for many of the people we work with in the tech industry.  Harry McCracken wrote a great article about him last week, too.



STEVE:  You remember PC Mag?  It was every two weeks, and it was an inch thick.



LEO:  You had to read it.  And you had to read it.



STEVE:  And it was, like, 95% ads.  I mean, it was the biggest cash cow the industry has ever seen.



LEO:  No, one bigger.  Computer Shopper Magazine.



STEVE:  Oh, okay.  Right.  That horrible oversize newsprint thing.



LEO:  It was huge.



STEVE:  You had to wash your hands, yeah.



LEO:  It was tabloid size.  It was four inches thick.  I think it did have the merit of only coming out once a month.  But I got it, I loved it, also from Ziff-Davis.  I got it because that's where, you know, you could peruse the ads.  Now, with the Internet, none of these have survived.  Nobody prints the stuff anymore.



STEVE:  I got an award once from David Bunnell.



LEO:  Did you.  So you knew him.



STEVE:  Oh, yeah, I knew him.  I designed and inserted the highest pulling ad in the history of PC Magazine.



LEO:  What?



STEVE:  And they gave me an award for that, yeah.



LEO:  Wow.



STEVE:  It was a simple page.  The headline was "Hard Disks Die."



LEO:  Oh, I love it.  



STEVE:  And then the subhead was "Ever Wonder Why?"  And it was just a little bit of prose with some cool photos.  But it, I mean, it was expensive as all get-out because it was in PC Mag.  But it pulled more than any other ad they ever ran.  



LEO:  Nice.



STEVE:  Well, because people understood that that was the case back then.



LEO:  Yeah, yeah.



STEVE:  I just did want to mention, just complete random miscellany, but this AT&T/Time Warner merger.



LEO:  Wow, huh?



STEVE:  You know, I'm a free enterprise entrepreneur capitalist.  But I recognize that our system has a problem, which is that power begets power.  And when companies acquire an advantage, they use it to their own further advantage.  I guess, in reading into this a little bit as I have over the past week, there has been some suggestion that, if this is allowed to proceed, then maybe some concessions can be obtained, like unbundling of cable packages and other desirable things.  But, boy, I just, you know, here I am stuck with only one viable source of Internet connectivity, as an example of how the system fails the consumer when companies acquire too much domination in a market.  And this scares me as much as the, what was it, the Comcast/NBCUniversal acquisition.



LEO:  It's very similar, isn't it.



STEVE:  Yeah, yeah.  It is a carrier acquiring content.



LEO:  Yeah.



STEVE:  And it's like, okay, well, let's hope our Network Neutrality legislation finally does come down doing the right thing because this is worrisome.  You know, when a carrier has an interest in some content over competing organizations' content, that's just scary.



LEO:  Not good.



STEVE:  Also, a little more on topic, at least relative to this podcast, This Week in Energy Storage.  I knew of this last week, but we were too crammed full of stuff.  And so I thought, okay, I'm just going to save this one for this week because this isn't particularly time sensitive.  But I just wanted to put it on our listeners' radar.  You know, as everyone knows, mobile energy storage is an interest of mine.  We've talked about super capacitors and battery technology and, you know, nanotubes and all that.  This comes out, this was a press release last week from the very well-known Oak Ridge National Laboratory.  They, as often happens, accidentally discovered what they believe is an efficient process to turn - are you sitting down, Leo?



LEO:  Yes.



STEVE:  CO2...



LEO:  Oh, I saw this, yeah.



STEVE:  ...into ethanol.



LEO:  Huge.  I hope this is not bogus.  I hope this is real.



STEVE:  This sure has all the smell of real.



LEO:  Yeah.



STEVE:  And it uses inexpensive components at room temperature with a little electricity to catalyze a reaction.



LEO:  So why is this a big deal, Steve?



STEVE:  Okay.  So as we all know, we believe there's a problem with increasing levels of CO2 in the atmosphere.



LEO:  It's not belief anymore.  It's demonstrably true.



STEVE:  I'm just - right.  I'm trying to be politically...



LEO:  No need to be politically correct.  It's demonstrably true.



STEVE:  So, and we know that that tends to have a heating of the planet effect.  There's been a lot of talk about carbon sequestration, that is, trying to trap the CO2.  And then they want to, like, pump it back down into the dirt.  And it's like, well, okay.  But that just seems to be expensive, with no return for the investment other than keeping green people happy.



So what these guys have, and I'll read from the Oak Ridge National Laboratory's official release:  "In a new twist to waste-to-fuel technology, scientists at the Department of Energy, the DOE's Oak Ridge National Laboratory, have developed an electrochemical process that uses tiny spikes of carbon and copper" - both abundant - "to turn carbon dioxide, a greenhouse gas, into ethanol.  Their finding, which involves nanofabrication and catalysis science, was serendipitous.



"ORNL's Adam Rondinone, lead author of the team's study published in Chemistry Select, said:  'We discovered, somewhat by accident, that this material worked.  We were trying to study the first step of a proposed reaction when we realized that the catalyst was doing the entire reaction on its own.'  The team used a catalyst made of carbon, copper, and nitrogen and applied voltage to trigger a complicated chemical reaction that essentially reverses the combustion process."  I just love that phrase.  "With the help of the nanotechnology-based catalyst which contains multiple reaction sites, the solution of carbon dioxide dissolved in water turned into ethanol with a yield of 63 percent.  Typically, this type of electrochemical reaction results in a mix of several different products in small amounts."  So this is both very efficient and very selective.



Adam continued:  "We're taking carbon dioxide, a waste product of combustion, and we're pushing that combustion reaction backwards with very high selectivity into a useful fuel.  Ethanol was a surprise," he says.  "It's extremely difficult to go straight from carbon dioxide to ethanol with a single catalyst.  But this does that."



LEO:  Amazing.



STEVE:  "The system operates by dissolving CO2 in water at room temperature and, with a bit of electricity, produces ethanol." 



LEO:  Wow.



STEVE:  So, again, when I see something like this, I think, this is why we absolutely have to keep raw science funded.



LEO:  Yeah.  You never know.



STEVE:  Exactly.  I mean, we got the Internet from it.  And now here's a potential win because this makes it then feasible to just have big CO2 scoops, you know, suck it in.  CO2 dissolves easily in water.  Run it through this process, out comes gas.



LEO:  Wow.



STEVE:  I mean, hello.



LEO:  Hello.



STEVE:  I hope Elon knows about this.  Maybe he can just build this onto one of his next ideas.



LEO:  Pretty amazing.



STEVE:  And finally, I just want to say that last night I hit 24%, because I looked down at the little bar on my Kindle, in Peter Hamilton's "Night Without Stars."



LEO:  Oh, okay, okay, okay.



STEVE:  So, and you know, I should know better by now because he divides this into what he calls "books."  And the books have chapters.



LEO:  Yeah.



STEVE:  And so Book One, so I go in, you know, last week and start learning about a whole bunch of new people, and I kind of get up to speed on them.  And then I go to Book Two.  It's like, okay.  And now I've got a whole - I changed location and new people.  And it's like, oh, okay.



LEO:  I just got up to speed on the first set.



STEVE:  Exactly.  So then I got to learn all these people.  And then I switch.  Then I get into Book Three.  It's like, oh, no.  And yet another name I haven't seen before, and a whole new location.  I'm thinking, oh, come on.  And then, wham.  It just took off like a rocket ship.



LEO:  Yeah.



STEVE:  And I remembered having exactly this experience with "Pandora's Star," where it was interesting; but it was like, okay, where are we going with this?



LEO:  Right.



STEVE:  You know, I mean, and because many books are written as sort of in a first-person narrative, where you're just, you looking out of the eyes of the protagonist as he walks around and talks about what's happening, or it's being described or something.  Peter doesn't write that way.  Peter writes big, complex, swooping, sweeping, you know, stories.  I mean, he's a real storyteller.  And so he needs to set up the pieces and the people and, you know, establish.  And so it took 24% of this book to establish what's going on.  And then it just, like, I mean, I kept looking at the clock last night thinking, oh, I've got to get up early to work on the podcast all day today.  Anyway, so for what it's worth, oh, boy.  You know, we find out what happened with Bienvenido, which is where we left off on the first half of this duopoly here, duology here, whatever the heck it is.  And it is really looking like another fun book.



LEO:  Oh, boy.  I can't wait.



STEVE:  Yeah.  Twenty-four percent and fasten your seatbelt.



LEO:  It's my next book, yeah.



STEVE:  Oh.



LEO:  I have it on Audible, of course.  I listen.  Yeah, that's awesome.



STEVE:  Yes, yes.  So Colin Wills in Dorking, England, shot me a nice note.  And he's a listener, so he knows how to put in the subject line, "SpinRite saves a guitar lesson."  And he did a little smiley-face.  So he says:  "I worked from home today using my bitlockered" - and I kind of like that, "bitlockered," I've been bitlockered - "using my bitlockered Windows 7 work laptop so that I could take my daughter to her guitar lesson.  But last night I thought I was going to have to go into the office and that we would have to skip the lesson because my laptop wouldn't boot.  It had recently hung at some point during the boot, but had recovered at a second attempt.  But last night it repeatedly got stuck.  Being a Security Now! listener almost from the start, I immediately thought of SpinRite."  And of course that's why I tell everybody about it every week, so that you immediately think about SpinRite.



LEO:  No fool, you.



STEVE:  Instead of, you know, instead of, like, oh, no, what do I do?  Who could not know at this point?  And he says, parens, "(Actually started around Snowden but also recapped and now just past the Sugar Hill at 353 and reading Taubes.)"  He's referring to Gary Taubes's book.



LEO:  Yes.  "Why We Get Fat."



STEVE:  He says - exactly.  "The work laptop is locked down such that I cannot boot my SpinRite CD, so I transferred the hard drive to my personal laptop and spinrote," he says...



LEO:  That's a new verb.



STEVE:  Spinrote.



LEO:  Spinrote.  New tense.



STEVE:  Yes, "...it quickly at Level 2.  Of course, the fact it was bitlockered didn't matter, and SpinRite cut through the disk like a knife through full fat butter and completed after about an hour.  After that, the work laptop booted, I worked from home, and we made it to the guitar lesson.  Thanks for the great product.  I am really, really looking forward to v6.1."  Colin, not as much as I am, and all of our SpinRite listeners are.  So Colin, thank you for sharing the news and helping me further plant the "Aha, I know how to fix this..."



LEO:  Aha.



STEVE:  ...in our listeners' minds.



LEO:  Aha.  All right, Steve.  I sit here poised with my finger over the Install button.



STEVE:  So what Leo is referring to is the fact that these guys who have revealed this new Rowhammer version of an attack that they named DRAMmer, or Drammer - it can stand for DRAM Hammer, or also Deterministic Rowhammer because that's one of the innovations of their particular implementation of this.  They have produced a side-loadable tester that runs in Android devices.  They had been expecting Google Play to host it for formal availability, but it has not yet appeared in the Google Play Store.



So I tried it last night.  I meant to try it on a Kindle Fire.  But I did try it on an older Samsung device.  And when I clicked the link and tried to run the .apk file, I got the notice that the device is not configured to allow unauthorized software to run.  So, of course, I clicked the settings and went in.  And I said, yes, I do want to drop my shields for a moment.  So then I allowed that to happen and ran the APK.  It doesn't have a fancy UI.  You can see it allocating some memory.  And then it produces a log if, over time, it manages to induce bit flips in the DRAM of your particular Android device.  I'm a trusting person.  I trust these guys.  So I don't have a problem.  It's coming from their site, vvdveen.com/drammer/drammer.apk.



LEO:  Oh, man.  I'm trusting you on this one because this is against every instinct I have.  But you trust them.  You know them.



STEVE:  Yeah, if there was any way to, well, I mean, I'm in a dialogue with them.



LEO:  Now, we should say that the tester is not open source, because otherwise they'd be publishing exploit code.



STEVE:  Correct.



LEO:  Right.  So should I do it?



STEVE:  Yes, do it.



LEO:  So this is Pixel.  This is the new Google phone which, in theory, and it has all patches applied, would be as secure as it could be.  Now, note, even after you turn on the "install from third-party sources," which it warns you against, you'll get this further warning:  "Installation blocked.  Drammer.  This app contains code that attempts to bypass Android security protections."  I'm encouraged, by the way, that you see stuff like this.



STEVE:  Yes.



LEO:  One would hope that it would see that in other applications.  You could say "okay," and it won't install it.  But if you say "more details," it'll say, even if you've heard of this app or the app developer, it's still dangerous to install an app from an untrusted source.  They warn you three times.  Now I'm going to say "install anyway."



STEVE:  Yeah, because these people are not untrusted.  I mean, they are, you know, they're on our side.  I mean, they told Google about this.



LEO:  I think it installed.  Did it install?  Let me do it again, just to make sure.  More details.  Install anyway.  There we go.  Okay.  App installed.  Now I'm going to open it.  It downloads something.  Should I do - "Check whether your device is vulnerable to the Rowhammer bug."  Relaxed or aggressive?  Should I go all the way?



STEVE:  Yeah, crank it up.



LEO:  In for a penny, in for a pound.  And then you can send statistics or not about the test result.  Of course I'll help them out.  And then I love the button, "Hammer time."  Now, you're seeing - I'm seeing it, the log.



STEVE:  Yeah.  And I didn't get it.  I didn't get the log on mine.



LEO:  Well, it just crashed is what happened.  



STEVE:  And did it say "flipped" in those entries?



LEO:  Well, it crashed.



STEVE:  Okay.



LEO:  It's crashing out.



STEVE:  Okay.



LEO:  I don't know if that's a good thing or a bad thing.



STEVE:  And what I'm wondering is, I see there's a little block that are, like, memory allocations, which I'll explain in a minute.



LEO:  Yeah, yeah, yeah, yeah, [crosstalk].  Low memory, boom.



STEVE:  Okay.  Okay.



LEO:  Is that good or bad?  I don't know.



STEVE:  Oh, it means nothing.  It just means that it's raw code that they put together and that hasn't been widely tested.  Although, as I'll explain, they've tested it on a whole lot of devices.  So there may be something about the Pixel which is a little bit different.  And I imagine it will evolve.  And maybe that's why it hasn't appeared in the Google Store.  They might be waiting to tweak it a little bit.



LEO:  Let me turn down aggressiveness.  Would that make it maybe more reliable?



STEVE:  Oh, that might - how about put it back where it was, just a little, like only half an inch over from the left.



LEO:  Right.  It crashed again.



STEVE:  Okay.



LEO:  But I'm going to keep turning it down until it doesn't; right?  Boom.



STEVE:  Well, it's probably...



LEO:  I don't know if it's actually crashing because I see it in [crosstalk].



STEVE:  Well, it is deliberately coming up against an out-of-memory condition.  And I'll explain why they're doing that.



LEO:  Oh, okay.



STEVE:  And so that's on purpose.  But it's a little - oh, now it didn't.



LEO:  No, it's just slower.



STEVE:  Okay.



LEO:  It's going to take a while.  But I saw the same thing.  This is, by the way, all the way relaxed.  And it's reading from page zero and page X, X=0 to 128.  So, and then eventually it's going to say "exhausted," and then it's going to say "out of memory," and that's when it usually crashes.  So what is it doing here?



STEVE:  Okay.  So the background.  Our listeners who've been following the podcast for two years will remember that we first discussed what was initially a theoretical "this doesn't sound good" problem.  And as so often is the case, things start out as, oh, that's not good, but it seems like it'll be hard to exploit.  Well, a few months ago we talked about the Flip Feng Shui.  And in fact that was the title for that podcast, where this same group there at the VU University in Amsterdam, led by Professor Herbert Bos - there's a team of researchers that work with him, and a trio from UC Santa Barbara in this case.  These are the guys who figured out how a process running in a shared hosted environment could arrange to flip the bit in the public key in an adjacent process, rendering that public key factorable, and then factor it and immediately use that modified public key to securely access, with full privileges, that other process.



So to do that, they had to do some amazing gymnastics, essentially, very clever, where they were able to use the fact that these virtualized environments do page coalescing, or deduplicating, which is coalescing, where any duplicate pages are being looked for constantly by a background thread.  And if they're found, the page tables which describe each process's mapping of logical to physical memory, the page tables are modified so that both instances of logical memory in the two processes refer to the same physical memory.  And this is a highly effective memory-saving technique that modern virtual environments provide.



So these guys were able to leverage, to take the raw capability of, okay, if we pound on memory, our own memory, which is the only memory we have access to, we can flip a bit in it.  And so you first think, well, okay, how's that going to be useful?  Well, they turned it into something that was an actual attack.  Now they're back.  So they call this one Drammer.  And as I mentioned, I think of it as DRAM Hammer.  But on the other hand, all Rowhammers are DRAM Hammers because this is a fundamental problem with DRAM.



Just to remind our listeners, DRAM is arranged in a grid array.  And the nature of the dynamic RAM is such that rows, entire strips, strip rows are refreshed and read at the same time.  And it turns out that designers have shrunk the cell size of DRAM, as they're always doing, in the same way they pushed the margins out of hard drives, and then they pushed the margins out of lithium-ion cells, trying to squeeze as much usable surface area as they can at the cost of manufacturing tolerances being reduced.  They also squeezed DRAM cells down to where they, oh, look, they still work when they're this small.  It's like, uh-huh, unless you create a lot of noise in the neighborhood.  And so that's what this does.  This creates a noisy neighborhood.  And if you have particularly weak cells that are not being refreshed at a high enough rate, you can cause them to misread.  You can flip the bits from zero to one or one to zero.



So the question had been, that had never been answered before -  because all of the Rowhammer attacks to date have been on x86 and Intel x64 platforms, never on the ARM platform.  And of course most mobile devices are ARM-based because it's so efficient with battery power for the computing that you get out of the power consumption.  So they decided to tackle the ARM platform.  The first problem - oh, and in a realistic environment, not just some raw ARM chip on a board, but an existing smartphone, Android-based phones and tablets, Android-based ARM tablets or ARM devices.



So from the beginning of their abstract they said:  "We show that deterministic Rowhammer attacks are feasible on commodity mobile platforms and that they cannot be mitigated by current defenses.  Rather than assuming special memory management features, our attack, Drammer, solely relies on the predictable memory reuse patterns of standard physical memory allocators.  We implement DRAMmer" - or Drammer, I don't know how they pronounce it - "on Android/ARM, demonstrating the practicability of our attack, but also discuss a generalization of our approach to other Linux-based platforms.



"To support our claims, we present the first Rowhammer-based Android root exploit relying on no software vulnerability, and requiring no user permissions.  In addition, we present an analysis of several popular smartphones and find that many of them are susceptible to our Drammer attack.  We conclude by discussing potential mitigation strategies and urging our community to address the concrete threat of faulty DRAM chips in widespread commodity platforms."



So the first thing they needed to do was to verify experimentally that the DRAM memory in existing ARM-based smartphones could be subject to Rowhammer.  There was some suggestion in the researcher community that DRAM required faster repeat writes to DRAM than the memory controllers in these devices might support.  So it might be that, while the DRAM itself could be faulty, the DRAM controller wouldn't allow a high enough bandwidth writing to inflict the Rowhammer fault on the underlying hardware.  So they first had to determine whether that was possible or not.



Now, in order to pound on DRAM, you need to get the cache out of the way.  We've talked about caching, how for example in modern Intel architectures you have a hierarchy of caches - the L1, the L2, and the L3 cache.  And so any attempt to write is typically written through to the DRAM.  But if you write it again, the cache realizes you're writing the same thing you just wrote, so it discards it.  And so that write doesn't get propagated down into the hardware because the cache is already synchronized with what's in the hardware, and so it saves that write cycle, which is also a benefit for performance in a busy system.



So in order to bypass the cache on the Intel platforms, there is a cache flush instruction which is available from userland, from Ring 3, from where normal user code executes.  And remember also that, in the intervening time, Google found that there was a Rowhammer vulnerability that they were able to inflict in Chrome because their NACL, their native code execution, had not ruled out the use of the Intel cache flush.  Well, they simply changed that native code interpreter in order to make that no longer possible.  So that solved the problem.  That is, if you can't flush the cache, you can't do Rowhammer because the cache will get in the way.  In a very similar way to the DDoS attacks we were talking about at the top of the podcast.



So the first problem was that, whereas the cache flush is a non-privileged instruction on the Intel platform, it is privileged on the ARM.  So this is, like, whoops, wait a minute.  That means that an application running in user space has no ability to flush the cache through the instruction that is present in the ARM architecture, but only available to privileged code.  So the first thing they did was they said, okay.  Let's just not worry about doing this from userland.  Let's first figure out whether the DRAM controller can permit this.  So they wrote a kernel loadable module and their own kernel code just for the moment, to be able to have access to the privileged cache flush instruction.  They pounded on DRAM, and they got bits to flip all over the place.  So they said, okay.  If we can come up with a way of doing Rowhammer without the cache flush instruction, which is not available to us from userland, then we've got something to work from.



Turns out, again, these guys, I don't think anything could stop them.  As I said, I am so glad they're on our side because it turns out that there is a way to pound on memory without having to flush the cache.  And that's from direct memory access.  DMA inherently avoids the cache because you need to keep the view of different DMA'ing processes coherent, meaning that you can't have any situation where the cache might contain data which has been modified, but not yet written to DRAM.



So DMA, Direct Memory Access, is a cache-bypassing process.  So they were able to come up - oh, and DMA is available to userland processes, all kinds of things, things doing video and webcam apps and even audio.  I mean, all kinds of things need high bandwidth access to main memory for reading and writing.  So that's something reliably available, certainly on the Android platform, and probably everywhere.  So they explained that they consider Drammer to be a particular instance of the larger Flip Feng Shui technology.  So for Flip Feng Shui in general to be successful, three requirements have to be met.  An attacker needs to be able to hammer sufficiently hard one way or the other, hitting the memory chips with high frequency, because no bit flips will occur if the memory controller is too slow.  And now they know that they're able to do that.



Also, physical memory needs to be manipulatable and manipulated so that exploitable data can be located in a vulnerable physical page.  And we saw them do that in a different instance using this memory deduplication on a VM platform.  They don't have that environment in Android, but they needed some way to do that.  And physical memory mapping must be determinable to allow what's known as double-sided row hammering, that is, where you literally, when you hammer a row, you are writing to the row of cells adjacent to another row.  Double-sided row hammering typically ping-pongs between the row above and the row below the target hammered row, really just hammering the crap out of it.  So, but in order to be able to do that, you have to know how the actual bits on the chip are organized.  And they designed a heuristic that allowed them to figure out on any given platform the row length in bits so that they were able to relate logical addresses to actual physical rows on the grid of DRAM.  Like I said, you know, you want these guys on your side.



So none of those three requirements were initially met with any of the previous research that had been done on Rowhammer.  They had to fulfill those from scratch in order to move this over into the ARM platform and make it workable.  So with all of this background, here's what they do.  They allocate a single physically contiguous block of memory.  Now, the good news is allocating memory for DMA does that because DMA solves two problems for them.  Not only does it bypass cache, but it also allows for the explicit allocation of physically contiguous memory because you need physically contiguous memory because the DMA is writing to the physical memory, which the process sees a logical view of through the memory mapper that exists in the system, the memory management system.



So it's necessary to have the logical to physical mapping and physically contiguous DMA pages because the DMA just works with a physical counter.  And when it's streaming data in or out of memory, it just does that by incrementing the counter byte by byte, or block by block, as it's writing, and just going for however long you tell that the buffer is.  So they allocate a big contiguous block of memory.  Then they deallocate it and immediately reallocate a ton of tiny blocks of memory.  So, and this is the deterministic aspect of what they've done.  So because we know how Android manages memory, and how its memory allocator works - I mean, it's open source.  It's public domain.  You can probe it.  And so that's a given.



So they allocate a single huge block of memory.  Then they release it and immediately basic request all of that memory again in tiny blocks.  And what happens is the way Android manages memory is it uses page tables which will be located out in the physical space in between blocks of pages that the page tables describe.  So it's a way of essentially forcing a layout of memory which is deterministic and well known and gives them the property that they want, which is these page description tables exist at essentially knowable periodicity within this large region.



Now, here's the kick.  And the trick is the page tables are exclusively the property of the kernel.  They are kernel memory management structures which are absolutely off limits to any user code because the users just see an abstraction of memory through the memory manager.  The OS is managing the actual physical allocation.  But you absolutely cannot allow a process to mess with it own memory management because that would be giving it the keys to the kingdom.  That's something that only the privileged OS is able to do.



So what these guys figured out a way to do was, after templating, they allocate this big block of DRAM.  Then they hammer the crap out of it in order to find all the flippable bits within the region of memory that they have access to.  And they call that "templating."  They template the memory.  And by the way, the templating code is up on GitHub in public domain for people to experiment with, if anyone's interested.  So they template the memory.  Then, knowing how the memory is laid out, they are able to use the Rowhammer on - oh.



So they template the memory, fragment it, deliberately fragment it, which is going to sprinkle page table management structures throughout that fragmented region, which they technically no longer have access to because that's OS.  Those are OS-owned blocks which they can't see.  But because they know where it must be, they have been able to arrange for those management blocks to fall in areas with soft flippable bits.  So then they hammer, as they have already proven they can, on a row adjacent to a row of memory that is in one of these page tables, which flips the bit and maps the page table into user memory.



Once again, they flip a bit - now, again, because this is a hardware flaw, the operating system just thinks they're a strange app.  You know, it's writing a lot to this couple of locations.  But who cares?  Well, that induces an unseen bit flip in the hardware, in the memory management system.  And they've engineered that bit flip so that the page table then appears in their user memory.



Now, they have just been given something no application should ever have, that is, an OS memory management structure that they have full read and write access to because they tricked the hardware and mapped that into their own process memory space.  So that means they can point entries in the page table which they now control to any physical memory in the system, including the kernel memory.  So they do that to scan through the kernel memory, looking for the well-known process management structure, the process credentials, where the UID and the GID and other common Linux structures are stored.  They find the structure for their process, that is, the structure in the OS which is managing the rights and privileges of their process, and they simply give themselves root access.  They manipulate their own credential structure to grant themselves root access.  And they now have full access to the entire system.



So they start as an application like any other that needs zero permission; and, simply by manipulating a weakness in the hardware, they get control of critical kernel structures, give themselves root access, and then they have the keys to the kingdom.  And the bad news is there's no clear solution for this.  On their page they show a range of existing current generation smartphones which are vulnerable, how many have been tested, how many of those have found flippable bits.  Most have; a few haven't.



Google has known about this for a month.  The problem is there's no clear solution.  When we were talking about mitigating this back in the Flip Feng Shui episode, we talked about the next generation of DDR memory, which would notice that access had been particularly heavy in a given region and increase the refresh of any rows that might be susceptible to Rowhammer attacks, sort of a dynamic refresh.  Another approach is just to crank up the refresh rate.  That, as we know it, does take a hit on performance, and it does consume more power.  And mobile devices are, if nothing else, very sensitive to power consumption.



So basically they have demonstrated that a two-year-old theoretical flaw does affect a wide number of existing ARM-based mobile devices; that unprivileged software can give itself root access, and it takes about 30 seconds overall to do this; and it's not clear how this thing gets mitigated.  I mean, the problem is it's not a flaw in any code.  It's a flaw in the hardware that we are trusting not to have its bits flipped.  And they've shown they can.  Beautiful piece of work.



LEO:  Now, I reran the thing with the relaxed mode all the way up, and it did complete, but it didn't give me any report.  So I don't know what to think about Drammer and the Pixel.



STEVE:  Okay, yeah.



LEO:  I mean, it passed?  It doesn't mean anything.



STEVE:  Yeah.  The fact that - it shouldn't have crashed.  Mine didn't crash.



LEO:  Sounds like it's safe.



STEVE:  Yeah.  And they don't have a big UI on it yet.  They are presenting this toward the end of this week, which is why it came out of embargo, and the world knows about it.  Dan Goodin wrote a great piece in Ars Technica.  And I started getting, as I knew I would, tweets about it yesterday when the news broke.  So we'll keep an eye on it.  I don't know how soon Google's going to have patches out.  And it's not clear how they're going to mitigate this.



LEO:  Yeah.  Apparently the 5X is not vulnerable.  So I wonder, is DDR4 vulnerable?  Does that make it invulnerable because it's DDR4?  Or does it matter?



STEVE:  Both are.



LEO:  Three and four?  Yeah.



STEVE:  Yeah, they did find some DDR4 that is vulnerable.



LEO:  This is DDR4.



STEVE:  Yeah.  And there is a next-generation DDR4 which does incorporate adaptive refresh.  And so that's probably what's going to happen.  But the problem is look at all the hardware that's already out there.



LEO:  Right.



STEVE:  I mean, you know, this is...



LEO:  Unpatchable.  I mean, unfixable.



STEVE:  It's not clear how you fix this.



LEO:  Right.



STEVE:  Yeah.



LEO:  Well, it looks like, what I would guess from the warning I got is that Google at least is scanning for software that tries to do stuff like this, or tries to do something, anyway.  Because I did get this "unsafe software."  You have to override this to - not merely that it's untrusted source, but that it's literally unsafe.  So that's encouraging.  Do you get that on your 5X?



STEVE:  No, I didn't.



LEO:  Yeah.  I wonder if that's something new.  Now, you said your 5X was vulnerable; right?



STEVE:  No.  In fact, it was a Samsung.  It's an old Samsung tablet.



LEO:  Oh, you did it on an old Samsung.



STEVE:  It's an old Samsung tablet.



LEO:  They said 12 of the 15 5's were vulnerable.  I don't know.  It's unclear.  They only tried one 5X.  So more to come, obviously.



STEVE:  Well, yes.  And they refer to their Nexus 5 as, like, their old beat-up war horse.



LEO:  Right, right.



STEVE:  I think, you know, this is the one that they subject to everything.  And so one question they had was whether this might be usage fatigue.  You know, might there be a more prone tendency for bits to flip on, like, well-hammered DRAMs?



LEO:  It's worned out.  It's all worned out.



STEVE:  Although there is an electrochemical process that we know of to describe that.  You know, for example, we know exactly why flash RAM fatigues and dies over time.  We know why we need wear leveling and to limit the number of writes for flash.  DRAM doesn't have that characteristic.  So I suspect it isn't usage base.  But it certainly could be also the case that even the same model phone in batches is made with slightly and subtly different DRAM.  I mean, because they just say we need 4GB of DRAM.  And they buy some batches from this supplier, and some batches from that supplier.  So even things like little process-to-process variations, I mean, because we're down at the margins.  But as this demonstrates, margins matter.



LEO:  Yeah.  All right, ladies and gentlemen.  There you have it, the scoop of the century.



STEVE:  So for our listeners who probably, I think without fail, want to run this DRAM test, if you just google Drammer, D-R-A-M-M-E-R, you'll find the article and the page.  It's in the show notes this week.  And it's from these guys.  I trust them.  And all it's doing is seeing whether it's - it doesn't do any exploiting.  It just looks for flippable bits.



LEO:  Yeah.



STEVE:  And in fact, if somebody finds them, send me a tweet.  I'd just love to know that some listeners found flippable bits in their phones.



LEO:  And of course I immediately uninstalled it and rebooted, just in case.



STEVE:  Yeah, good.



LEO:  Just in case.  And I'm deleting the APK right now.  Well, thank you, Steve.  I don't know.  My results were inconclusive on the Pixel.  But I'm sure we'll learn more in time.



We do this show every Tuesday at 1:30 Pacific, 4:30 Eastern, 20:30 UTC, if you want to watch live at TWiT.tv and be in the chatroom at irc.twit.tv.  But if you can't, don't worry.  On-demand audio and video also available at Steve's site, GRC.com.  Actually, he does audio.  And he has something unique there.  He has transcripts.  You'll also find, of course, SpinRite, the world's best hard drive maintenance and recovery utility.  You'll find many freebies.  Steve's very good on that.  ShieldsUP! might be a useful thing if you have an IoT device running.  I'm sorry, no, no, ShieldsUP! would be for the COW, the Dirty COW.  Test your network for a Dirty COW.



STEVE:  I can't believe they called it that.  Oh.



LEO:  And of course everything else.  It's a great site:  GRC.com.  But do come to our site, TWiT.tv/sn.  If you want to subscribe or download video, we have that.  And any podcast app will have the latest version.  Subscribe.  That way you get them all.  Complete your set, all 800 and, what is it, no, 583 versions of this show.  We're going to keep doing it till we get it right.  Or till the Internet is safe, whichever comes first.  No, that's going to be a long time, Steve.  Thanks so much.



STEVE:  Yes, we're not going to run out of anything to talk about.  We'll do a Q&A next week unless all of the world's toasters decide to gang up.



LEO:  Revolt.



STEVE:  And attack the Internet and bring the world to its knees.



LEO:  By the way, you can ask Steve questions:  GRC.com/feedback.  But he's also on Twitter @SGgrc, and you can DM him there and ask a question there.  He uses Twitter questions, as well.



STEVE:  And we will see you next week.  Thanks, Leo.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#584

DATE:		November 1, 2016

TITLE:		Listener Feedback #242

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-584.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss an oh-so-subtle side-channel attack on Intel processors, the quest for verifiable hacker-proof code (which oh-so-subtle side-channel attacks on processors can exploit anyway), another compiler optimization security gotcha, the challenge of adding new web features without opening routes of exploitation, some good news about the DMCA, Matthew Green and the DMCA, and how the relentless MPAA and RIAA are still pushing limits and threatening the Internet.



We talk about the secure ProtonMail service feeling the frightening power of skewed search results, how to regain control over Windows 10 upgrade insistence, a new zero-day vulnerability revealed by Google before Microsoft has patched it, a bit of errata and miscellany, and as many listener feedback questions and comments as we have time for.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  We have a lot of security news, but we also have a Q&A coming up.  We're going to talk about security flaws in Windows.  We're going to fix some errors and security flaws in Linux.  And I'm excited - our Security Stumper of the Week is back.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 584, recorded Tuesday, November 1st, 2016:  Your questions, Steve's answers, #242.



It's time for Security Now!, the show where we cover your security and privacy online.  We protect you, thanks to this fellow right here, our Commander in Chief.



STEVE GIBSON:  We protect you, we confuse you, we worry you, and probably upset you.



LEO:  Yeah.



STEVE:  It's all in the name of understanding what's going on.



LEO:  That's Steve Gibson, by the way.  Let me say your name.



STEVE:  Oh, yeah.



LEO:  And I want to say one other thing, by the way.  I don't know if you know, but I was back in Gainesville, Florida on Friday for the ITProTV grand opening.  And so that is a bunch of geeks; right?  There's, like, 300 people who work for ITProTV, who are customers of ITProTV, and then people who just said, "Hey, let's go see it."  And to a person, they said, "Say hi to Steve."  They are massive Security Now! fans.  And I think that what is really clear is, because this is the geekiest show by far that we do on the network, that these people, who are the geekiest listeners we have on the network, love this show.  So you have a very devoted fan base out there, and they all said, "Say hi."  At one point I said, "Look, I'm going to have to get a card and start writing this down because I can't keep track."  They love you, Steve.



STEVE:  Well, thank you.  Thanks for sharing that.  I had a little note in the show notes today to mention that I saw a very nice tweet from Victor van der Veen.  He was the project lead on our topic for last week, the Drammer attack, at UV Amsterdam.  And he tweeted, "This is so cool.  Your explanation of Drammer is absolutely perfect.  I just fell in love with your show."



LEO:  Aw, isn't that great?



STEVE:  So, yeah.



LEO:  Yeah, and I knew that because I didn't understand a word of it.  So I knew that it must be right.



STEVE:  Well, so nominally we have a Q&A, although we also have just a crazy news week.  But I thought, okay.  Instead of just doing too much news, I've got 10 questions and answers.  The last one was a listener-provided puzzler.  So we will definitely at least do that.



But so we'll do the news.  It turns out there's - oh, there's just some delicious stuff here - an oh-so-subtle side-channel attack on Intel processors, the actual hardware.  Many people have shot me a note, actually it was a couple weeks ago, about the quest for verifiable hacker-proof code, which of course is a little bit of a hobbyhorse of mine because I've always represented that software could be perfect.  It's just not.  But, you know, it's math, and so it could be, although this little side-channel attack on Intel processors is very worrisome.



We've seen another instance of a compiler optimization wrecking security; an interesting thread about the challenge of adding new web features without opening routes of exploitation; some DMCA news, some good news relative to some exceptions which have just been added which have a two-year life before renewal; Matthew Green asking the court for a formal waiver so that he can write a book; the MPAA and RIAA really going even further than ever in pushing the limits on their language.  ProtonMail suggests that they were almost put out of business by Google, which is sort of interesting.  Father Robert, as our listeners know, while you were on your last vacation, Leo, gave up on Windows 10 when it insisted on upgrading...



LEO:  Oh, I didn't know that.



STEVE:  ...in the middle of a podcast.



LEO:  Oh, man.



STEVE:  I have the solution for that.  So we'll share that.  There's a zero-day vulnerability which Google had to, following their own rules, release, even though Microsoft has not had time to patch it.  We have a little bit of errata, some miscellany, and however many questions and feedback from our listeners that we have a chance to get to.  Oh, and a wonderful Picture of the Week.  Somebody sent this to me, snapped it off of their Windows 10 machine.  So lots of fun stuff.



And I need to correct myself.  This may not be Windows 10.  This is definitely Windows Update, though.  And it looks like it's a Windows 7 screen, when I was looking at it while you were talking.  Anyway, for those who don't see the show notes, the screen was a snapshot.  It says:  "Configuring Windows Updates.  4002% complete."



LEO:  Oh, lord.



STEVE:  "Do not turn off your computer."



LEO:  It does look like an old screen, huh?



STEVE:  But wait a minute.  If it's 4002% complete, it's really complete.



LEO:  It's more complete than not.



STEVE:  So I don't know why you can't turn it off.  It's complete till, you know, 2020, when no more updates will ever be offered for Windows 7.



LEO:  This is, though, a category of bug we've had ever since we've had computers, ever since - remember you start copying a file, and it says we'll be done in 342 years?



STEVE:  I love it, yeah.



LEO:  Because it's just doing math; right?  And, you know...



STEVE:  Well, and  SpinRite has the same problem because SpinRite estimates how long it'll take to do the whole drive based on how long it's taken to get as far as it has.



LEO:  Exactly.



STEVE:  And many of the problems are at the front of the drive because that's where the heads spend most of their time, so there's more damage that accrues there.  And so many people say, Steve, this thing says it's going to take 324 hours.  And it's like, no, no, no, no, it's just having a hard time at the beginning so it extrapolates that, assuming the whole thing is going to be that bad.  But as soon as it gets past the rough patch, it'll just cruise along.  And I often hear them come back and go, oh, yeah, now it's only four hours.



LEO:  Although, and I'm sure somebody's going to point this out, I don't know how you get to 4002%.



STEVE:  Now, that's a stretch.  That's not a rounding error.



LEO:  That's a typo is what that is, I think.



STEVE:  Okay.  So there's a really big story that would not fit in today.  But I wanted to let all of our listeners know that I'm aware of it, and we will do it as the topic next week because it's really interesting.  So normally I start off the show notes with "this week on Security Now!."  So my second item here is "next week on Security Now!" is the Windows "Atom Bomb" exploit and attack.



LEO:  Is this the one Google is talking about?



STEVE:  No.



LEO:  No, all right.



STEVE:  This is different.  This is really a problem because it isn't leveraging a bug.  It is leveraging a longstanding feature known as the "global atom table," which is a way for applications to have Windows store arbitrary strings which they then receive a token for.  The problem is it's shared.  And some very clever hackers figured out how to turn this into an exploit.  And here's the problem, is it's not a bug.  And Microsoft can't change it.



LEO:  Ooh.



STEVE:  Because it's in all Windows OSes, and existing software depends upon it working just the way it does.  So unless something else happens, it will be our Election Day topic for Security Now! - that is, the U.S.  election, of course, which is one week from today.



LEO:  Wow.



STEVE:  For next week.



LEO:  I can't believe we're in November already.  Whew.



STEVE:  I know.  So, which is your birthday month, Leo, at the other end.



LEO:  Oh, don't...



STEVE:  The other end of this month.



LEO:  Oh, it's not a good birthday.  I don't want to celebrate.



STEVE:  I had already purchased a hat brush for you by the time I found...



LEO:  No.



STEVE:  I had, by the time...



LEO:  No, I'm sorry.



STEVE:  I was watching you click "Buy It Now," thought, well, I should have known.  It was only $14.



LEO:  I realized - I got a black hat, and it gets a lot of lint.  You are so kind.



STEVE:  I got the good one for you.



LEO:  Yeah, see, you got the good one.  I got the $4 one.  You are so kind.  Thank you, Steve.



STEVE:  I'll bring it up with me on the day after your birthday.



LEO:  I can have it at - it'll be my work hat brush.



STEVE:  That's right.  You need one in both locations.  Although I like your Sunday hat better than this one.  I really thought...



LEO:  This is the flat brim.  You like the Sunday - the Sunday hat had the press - I put the little press pass in there.



STEVE:  Yeah.



LEO:  And it really looked like a fedora, didn't it.



STEVE:  You were having fun with that.



LEO:  I like hats.



STEVE:  So, okay.  So I did want to mention something that I only saw after we stopped recording the podcast last week, which is, on cue, Windows Update on my Win7 machine had an optional update which was called "October, 2016 Preview of Monthly Quality Rollup for Windows 7 x64-based systems."  Meaning, and this is what we were talking about, part of this new change that began in October is that we will now start getting a single monthly quality rollup, as they call it, on the second Tuesday.  And then a week later they are planning to release the preview for the following month.



And it's interesting because there has been a lot of concern, and I teased it at the beginning of the show, about the fact that Windows 10 has become really insistent about installing updates, where at some point you are unable to tell it not to.  You're not able to reliably schedule them as Microsoft suggests.  I mean, it becomes increasingly insistent.  So I'm wondering if the deliberate release of a preview before the recommended, that would allow people, like corporations, the Enterprise users to experiment with it before it arrives.  Anyway, I just - this is the first time this has ever happened because this was a few weeks into October.  So I did want to say that, as we were told, and as we discussed on the podcast, this is happening.  So at the beginning of the month, the second Tuesday, you actually get the single blob containing all the updates for all of the fixes.  And then a week later they say, okay, and here's what we've got for next month.



Now, I'm wondering, though, because for example we will be talking shortly about a zero-day vulnerability which Google found both in Flash and in Windows; but, due to Microsoft's release schedule, they weren't able to respond in seven days.  Google's policy is we will notify, we will go public, seven days after responsible disclosure, that is, private disclosure, whether the problem is fixed or not, for active, in-the-wild, zero-day exploits.



So now I'm wondering, wait a minute, what happens in this case where Microsoft has issued a preview of their single blob?  And then, by the time it comes due, essentially, like comes time to actually deploy it, they change their mind because of something exactly like what has just happened where they, like, oh, shoot, you know, we've got a bad problem we have to address as quickly as possible, where it's possible to address it quickly.  So I'm a little - kind of like it will be interesting to see what happens, whether they disavow this preview of next month's quality rollup or go with it.  I just don't know what they're going to do.  So it's, you know, it'll be interesting to see.



And I mentioned Victor van der Veen's tweet saying that he had listened to the podcast, and I got the stamp of approval from the guys who did the whole Drammer project.  He also subsequently tweeted:  "We now know that LPDDR4 RAM is also vulnerable."  And he quoted Ars Technica's Dan Goodin, tweeting:  "Bit flips on Google Pixel XL, OnePlus 3, Galaxy Note 7...."  And I should mention also that, since last week's podcast, I've had a few, but not a huge number, but some people finding both positive and negative results to bit flips.  There was one I just saw this morning on a Galaxy Note 5, I think it was.  So they do exist, and I'm glad that these guys brought this to light because this is a problem that needs to get fixed.



Okay, now, speaking of problems that, oh, that can't get fixed, or that don't have an obvious fix, this is beautiful.  As I described it, "an oh-so-subtle side-channel attack on Intel processors."  Now, we know that side-channel attacks are typically clever ways of observing the state or obtaining leaked information from something that you want to keep secret, where somebody figures out that there is, for example, a secret dependency, that is to say, say that a cryptographic algorithm has a secret key.  Well, you want the encryption and decryption, for example the timing and power consumption, not to be dependent upon bits of the key.  So, and what that would mean is that somebody observing the timing or the power consumption would not be able to determine what the key bits were from something not directly related, but very indirectly related.  So that's a side-channel attack.  And, you know, and we've covered many of them over time, things like just the sound of the drive heads moving or acoustic noises being generated by fans.



Now, in those cases they were deliberate exfiltration approaches for deliberately essentially telegraphing a secret out of a machine.  What these guys found is more of a classic side-channel attack.  Researchers at UC Riverside and the State University of New York at Binghamton have devised a robust technique.  I think they said it takes, like, 50 milliseconds, I mean, like no time at all to bypass the important protections provided by ASLR, Address Space Layout Randomization.  And we've talked about this before.



ASLR is an important technology because what it does is it takes pieces of the operating system, typically the kernel, and places them at boot time in unpredictable locations.  This is important because one of the exploits which has been developed to thwart the execute-only or no-execute bit on systems, where for example exploit code cannot bring its own code in and run it on the stack as it used to be able to, it can't do that now because the stack is marked for data only, no execute.  So then what happened was the bad guys said, oh, well, obviously the kernel, the OS itself is executable.  So if we can find little bits of code and knit that together to achieve our goals, then we can do that.  So that happened.



And then we said, okay, let's randomize where the kernel chunks go so that blinded exploit code would not know where to jump to in order to get their work done.  So address space layout randomization was again a mitigation against this particular type of problem.  These guys have found an incredibly subtle and clean way around it.  And if left unfixed, and it's unclear how to fix this, it would render malware attacks much more potent, essentially neutralizing the security benefits of address space layout randomization.



So this was described a couple weeks ago in a paper at the International Symposium on Microarchitecture titled "Jump Over ASLR:  Attacking Branch Predictors."  And when I saw the title, it's like, oh, my god.  Okay.  So we talked years ago, we did a series on this podcast on sort of walking through the evolution of processor architectures from the very early days, like those machines that are over my left shoulder, to where we are today.  And toward the end of that series we talked about the ways in which the pressure to increase performance had made the Intel architecture really complicated.



So Intel was struggling against the risk threat.  Intel is a CISC, a Complex Instruction Set Computer.  So one of the things that Intel did was they read ahead of where the instructions are being executed and look for things that are safe to execute in parallel.  And that means that the instructions downstream that the system technically hasn't gotten to yet are doing things that do not depend upon the results from the instructions that are currently being done.



And so this is known as pipelining.  And one of the problems with pipelining - oh, and also instruction prefetch, and there's a prefetch queue where all this goes into.  One of the problems, though, is when you hit a fork in the road.  That is, you come to a jump instruction in the future that you haven't actually gotten to yet.  Well, the jump instruction is almost always, inherent by definition, dependent upon a condition, that is, it's called a "conditional jump," on a condition that was left over from an immediately previous instruction.



So pipelines have a problem.  They could take both paths.  But if they could be smart enough not to take the road less traveled, but to take the probable path, then that would dramatically increase their efficiency.  So what Intel did was they incorporated branch prediction.  Down in the microarchitecture, down in this incredibly complex chip, there are branch prediction tables which remember, I mean, and even statistically, what the likelihood of individual branches are in the code.



And, for example, analysis has shown that branches tend to go in the same direction.  Branches are normally not taken 50/50.  For example, in a loop, you might loop 100 times, and then at the end you don't branch back up to the top.  You continue going down.  Well, that means that that particular branch is 1% not taken, 99% taken.  So if there was a system in the processor that could dynamically learn about that branch being taken and not, then it could dramatically increase performance because it would never go reading downstream on a whole bunch of instructions ahead that would end up being thrown away when it branched back up to the top of the loop.



Okay.  But think about what that does.  That inherently creates a context of what the processor has been doing, and it is inherently shared by everything in the machine.  This is just a beautiful insight by these people.  So, and again, this as much as anything demonstrates the degree to which almost invisible, but still existent, subtleties can be leveraged into an exploit.  What these guys did was they realized that Intel has a certain amount of granularity to the branch table, and that the branch table is shared.  So they're able to deliberately set up in their own code subtle tests which allow them to indirectly probe the branch table in their code, which is shared with the kernel.  And knowing what the kernel is, and they did this in Linux although it's applicable to Windows and OS X, they're able to essentially deobfuscate the address space layout randomization simply by looking at little fluctuations in the branches their own code takes because that's influenced globally.  It's just - it's breathtaking.



So now the problem, of course, is how do you fix this?  So these researchers demonstrated the technique on a computer running a recent version of Linux on top of the Haswell processor by exploiting this - they call it a "flaw."  It's not.  It's a design feature.  I mean, they turned it into a flaw in the CPU's performance accelerating branch predictor.  The demonstration application that they developed was able to identify the memory locations where specific chunks of code reside.  And it's applicable to virtualized environments, which as we know are common in cloud-based computing and hosting.



And it's not clear how you fix this.  Right now the branch prediction table is in the processor, and it's global.  That is, it doesn't make any distinction among processes or among privilege rings.  So one thing you might do is, if you wanted to protect the OS, is to make separate branch prediction tables for different privilege levels so that applications running at privilege zero, ring zero, would not be sharing the same branch prediction table as those running at ring three.  That's a simple thing to do.



In their paper that I have linked to in the show notes, they suggest other sort of workarounds where they would be hardware enhancements.  And that's the problem.  We know that Intel has themselves a big pipeline of processor architectures for things coming, none of which probably take this into account.  So, first of all, it's not clear at all how you fix this on any of the hardware that exists today.  And as I mentioned, they demonstrated a robust exploit that takes 50 milliseconds that they set up and run in order to deobfuscate address space layout randomization.  So just another beautiful piece of work.  And it demonstrates how difficult this, I mean, how difficult security actually is.



And I immediately put the following story, this concept that Quanta Magazine had.  They had a story talking about this notion of hacker-proof code.  The title was "Hacker-Proof Code Confirmed."  And so just to summarize it, this is actually workable, provably correct code which has been shown to function in the real world.  From the article they said:  "In the summer of 2015 a team of hackers attempted to take control of an unmanned military helicopter known as Little Bird."  So this is a helicopter drone.



"The helicopter, which is similar to the piloted version long-favored for U.S.  special operations missions, was stationed at a Boeing facility in Arizona."  So this was legitimately done as a test.  "The hackers had a head start.  At the time they began the operation, they already had access to one part of the drone's computer system.  From there, all they needed to do was hack into Little Bird's onboard flight-control computer, and the drone was theirs.



"When the project started, this 'Red Team' of hackers could have taken over the helicopter almost as easily as it could break into a home WiFi.  But in intervening months, engineers from the Defense Advanced Research Projects Agency (DARPA) had implemented a new kind of security mechanism, a software system that could not be commandeered.  Key parts of Little Bird's computer system were unhackable with existing technology, its code as trustworthy as a mathematical proof.  Even though the Red Team was given six weeks with the drone and more access to its computing network than genuine bad actors could ever expect to attain, they failed to crack Little Bird's defenses.



"Kathleen Fisher, who is a professor of computer science at Tufts University and the founding program manager of" - get this - "High-Assurance Cyber Military Systems (HACMS)" - I didn't even know we had that, but I'm glad - "said:  'They were not able to break out and disrupt the operation in any way.  That result made all of DARPA stand up and say, oh, my goodness, we can actually use this technology in systems we care about.'"



So just to conclude:  "The technology that repelled the attackers was a style of software programming known as 'formal verification.'  Unlike most computer code, which is written informally and evaluated based mainly on whether it works, formally verified software reads like a mathematical proof.  Each statement follows logically from the preceding one.  An entire program can be tested with the same certainty that mathematicians prove theorems."



So it's neat that that works.  I would argue, though, that while it's necessary, it's not sufficient because, for example, Drammer or this ASLR bypass that we were just talking about.  That is, you can have perfectly bug-free code, but now we're beginning to see exploits that no longer depend upon bugs.  They depend upon subtle old decisions which nobody worried about once, but are now just - it's like, if you look at a perfectly smooth surface from a distance, if you run your hand over it, it seems absolutely smooth.  You look at it under an electron microscope, and it's got bumps all over the place.



So that's sort of what we're dealing with here.  We are creating ever-greater degrees of magnification in the way we look at the systems.  And everywhere we turn we're finding things that are not bugs, but are just characteristics which, if we really want to, can be used to exploit security.  We're sort of in a new era, I think, of depending upon these machines and at the same time discovering that they're less dependable than we were hoping they were.  



LEO:  I almost feel like they're not less dependable, but that hackers have become amazingly ingenious.  I mean, that last, the ASLR hack...



STEVE:  Yeah.



LEO:  It feels like hackers have been so encouraged, or I shouldn't say hackers, security people have become so encouraged by their successes that they've really gotten, you know, it's like I'm looking for a needle in a haystack, but we found a hundred already, so I'm pretty sure I'm going to find one.  And they've gotten just really ingenious and clever, much more so than in the past, I think.  



STEVE:  Yeah, I think that's exactly right.



LEO:  All the low-hanging fruit's long gone.  Now they're just, wow.  But it does make you feel like, but it's hopeless, because what are you going to do?



STEVE:  Yeah, yeah.  So here's another example.  I got a kick out of this.  Now, this was the 15th International Conference on Cryptology.  And when I saw it, I said, what a minute.  Cryptography?  No, cryptology.  So they call themselves Cryptology and Network Security.  And just to give you a sense for the topics in this, I think it was a three-day conference, we have presentations titled:  Diversity Within the Rijndael Design Principles for Resistance to Differential Power Analysis.  Or Efficient Implementation of Supersingular Isogeny Diffie-Hellman Key Exchange Protocol on ARM.  Or Signer-Anonymous Designated-Verifier Redactable Signatures for Cloud-Based Data Sharing.  Or how about Efficient and Secure Multiparty Computations Using a Standard Deck of Playing Cards.



LEO:  Oh.



STEVE:  So, yeah, kind of a fun conference.  But I perked up when I ran across When Constant-Time Source Yields Variable-Time Binary:  Exploiting Curve25519-donna Built with MSVC - that's Microsoft Visual C - 2015.  So as we know, Curve25519 is the one I fell in love with a couple years ago which is the foundation for SQRL.  It's an elliptic curve whose property that I needed was that the private key was deterministic.  That is, you could give it a private key which would be used to verify, I'm sorry, which will be used to sign something.  And then from the private key it gets the public key, which you then give somebody else to verify your signature under the private key.  But the cool thing, the thing where I went, "Oh," I mean, it was the aha moment, was that you could give it the private key.  And that allowed me to derive the private key deterministically from a super-secret user key mixed with the domain name so that every domain that you visited would automatically get its own private key.



So, and of course since then, and this was in 2006 when Dan Bernstein presented this, the world has fallen in love with it.  We see it everywhere.  And so it naturally provides state-of-the-art timing attack protection.  Bernstein designed it as a constant-time system.  And specifically, as I was mentioning before, in this case particularly the implementation avoids input-dependent branches and input-dependent array indices and other instructions with input-dependent timings - meaning once again that, if you observe it, it isn't the observation of it, where it's timing or power or memory access patterns.  Observing it doesn't leak any secret information.



Then Adam Langley, our friend at Google, implemented a constant-time elliptic curve Diffie-Hellman algorithm in C, using Bernstein's Curve25519, calling his version "Donna."  So that's curve25519-donna.  And he did it correctly.  However, as these guys write in their paper:  "Although the computation of the scalar multiplication should be time-constant," they write, "we spotted some timing differences depending on the value of the key."  And in the show notes I show a chart that they generated where the purple pluses are different keys, and the orange crosses are the same key.  And it's very clear that different keys are resulting in different timings than the same key across time.



So they thought, huh.  That's not supposed to happen.  They dug down into it.  And I show the code that was actually generated.  And they write:  "After a careful analysis of the binary code, the observed timing leakage appeared to be coming from the assembly function llmul" - that's a long multiply - "dot asm found in the Windows runtime library.  The function llmul.asm is called to compute the multiplication of two 64-bit integers.  It contains a branch condition which causes differences in execution time.  If both operands of the multiplication have their 32 most significant bits equal to zero, then the multiplication of these words is avoided as the computation is correctly judged to be zero."



So in the show notes I have a snippet of code.  What happened was Adam carefully designed, at the source level, the system to be time-constant.  But the library, which was compiled by MSVC 2015, got clever.  Whoever designed it realized there was a short-circuit, that is, this was an optimization such that, if the hiwords of these two 64-bits were both zero, why bother doing a multiply?  Let's just jump out immediately.  And that subtle effect meant that the resulting implementation, while designed and important to be time-constant, actually wasn't in its implementation.



So the short version is Visual Studio breaks time-constant code, which also tells us here's yet another place where we have to really look.  It's not enough to design something to be time-constant.  You have to verify it, and actually verify it in its final state because you can imagine - and here's the real challenge is that an earlier version, I mean, this was many years go that Adam did this, on a compiler before 2015, where it may in fact have been time-constant; but then, completely asynchronously, an engineer at Microsoft whose job it was, you know, after he had put in 24-bit color into the console so that you could have exactly the kind of cursor color that you want, he then said, "Oh, look.  I'm going to optimize the Windows runtime library in assembler."  And so he went in and coded this by hand.  Anything compiled and linked after that suddenly was broken out of being time-constant.



So again, another lesson in how hard it really is to get this stuff done.  And Leo, I agree with you.  It's, I hate to say "hopeless," but, you know...



LEO:  That's a subtle bug.  I mean, come on.  That's a very subtle bug.  Geez.



STEVE:  Yeah.  But it skewed the results enough that they were able to extract the key at a distance.



LEO:  Wow.



STEVE:  Yeah, wow.



LEO:  Again, I think it's because they've gotten so good; right.  The hackers have gotten so good.



STEVE:  Yeah.  It's why we just cannot any longer underestimate what can be done.  And in fact in the errata this week, that I'll get to in a second, are two tweets that I quote of people who were annoyed with me last week for they felt overstating the exploitability of the attack on Linux servers, where I was talking about any web-exposed Linux server, and they said this is a local privilege vulnerability only.  And anyway, I'll get around to that in a second.  But the point is that it's today, but not necessarily tomorrow, because one of our favorite quotes on the podcast is "Attacks never get weaker."



LEO:  Mm-hmm, mm-hmm, mm-hmm.



STEVE:  "They only get stronger."



LEO:  Are the bad guys as good as the security guys, though?  I mean, these are sophisticated folks, people like Google and some of these companies.  And they're white hats.



STEVE:  Yeah.



LEO:  Are the black hats this good?  I guess they are.



STEVE:  I think when, yeah, I think when the payoff is really worthwhile.



LEO:  That's it, isn't it, yeah.



STEVE:  Yeah, yeah.  Okay.  Now we talked a couple months ago about a worrisome API that the W3C, the World Wide Web Consortium, had added into the formal HTML5 spec.  And that was, our listeners will remember, the state of the user's battery.  And it was, like, seemingly innocuous.  But it turns out it was being used to track people.



LEO:  Crazy.



STEVE:  I know, just amazing.



LEO:  Ingenious.  I mean, you can't knock it.



STEVE:  Yeah, yeah.  So this is sort of like why this is difficult to do.  Mozilla's Chris Peterson has a nice thread.  I've got the link here in the show notes.  But he muses:  "What is the use case for the Battery Status API?" which is navigator.getBattery.  He asks rhetorically:  "Can we remove the Battery API, or perhaps restrict it to non-web content, like browser extensions or privileged web apps?"  Because right now any web page that you load with Mozilla, and anybody else who supports this API, can query the status of your battery.  And he says:  "Chrome and Firefox support the Battery API, but neither Edge nor WebKit have signaled an intent to implement it."  And one must think that, now that we're seeing exploits of it, they're not going to change their mind.



So he says:  "In theory, web developers would use the Battery API to save document data before the battery dies, to ease off heavy computation when the battery is low, or to implement the Firefox OS settings app.  The real-world use cases, however, seem," he writes, "to be fingerprinting users and inflating Uber prices for desperate users with low batteries.  Can anyone point," he asks, "to a real website using the Battery API for a legitimate purpose?"



And then he shows some statistics.  He says the battery status count probe - now, this is probes built into Firefox, which is sending generic data back to the mothership.  You can see the value of this here because it lets them check the real-world usage of things to get some balance.  So he says the battery status count probe reports over 200 million battery API calls for Firefox 49.



LEO:  Okay.



STEVE:  And he says the use counter2 deprecated navigatorbattery page probe reports that 6% of web pages use the Battery API.  Now, of course that includes ads, remember.  So what this really says is that ads have immediately deployed this battery status as another tracking parameter.  And they've seen 200 million hits on that.  So as he says:  "That seems surprisingly high, given the few legitimate use cases."  So he says:  "I have a patch that makes the Battery API chrome-only" - meaning not web page facing - "and fixes the web platform tests."  Then this thread that I linked to contains a bunch of back-and-forth.



I did note that there was some commentary about them having previously reduced the reporting resolution, that is, the number of bits that, who knows, like, what - somewhere there's an A-to-D converter or a down counter or something that was probably creating a very granular, just because it was available, like 16 bits.  But nobody needs the lower eight of those.  You know, a half a percent would be a byte because that's 256, or actually even 0.4%.  So first what they did was that they fuzzed the results so that fewer bits were available from the API for finger printers.  And now they just said, okay, you know.



The upshot of this was nobody has said we absolutely have to have it.  And it looks like it's purely tracking.  And no one can depend upon it because the biggest browser in the industry, Chrome, doesn't - I'm sorry, Chrome does have it.  But Edge doesn't, and WebKit doesn't.  So again, a website can't absolutely require it.



And so, sort of stepping back from this a bit, I appreciate that this stuff is difficult.  So the steps are the web standards folks add stuff that they think is cool, without really a proven use case; but, hey, let's let the web interface get the status of the mobile battery.  Then the browser guys, who want to be fully standards-compliant, implement it so that they can check that off the list, so they're not dinged for not supporting the whole HTML5 suite.  Then the real-world folks realize that they have a new tracking hook and immediately deploy it and start using it.  Then the browser guys realize that the nifty new feature they put in is being abused to reduce their users' privacy.  Now what do they do?



So it's never easy to take things away that have previously been given.  But as we know, sometimes that's the best path because this stuff just - there are competing pressures.  And of course a classic example is the decision about what to do about certificate authorities that seem to be irresponsible.  It's so difficult to take away honoring their certificates.  But the system depends upon having reliable CAs.  And without enforcement, how does that happen?



So some good news about the DMCA.  And this was - I thought it was Iain Thomson, but actually his article is next.  So this one was also in The Register.  But it turns out that there is a - it was a year late, and this exception coverage was supposed to last three years.  But at least it has an additional two years to go before it's revisited.  So these are specific exemptions in the DMCA to allow security research.  And this, of course, this is a constant refrain on this podcast is, you know, look at the value we are inarguably obtaining from researchers who need to be able to dig into systems that have security in them to verify the security.  We have to have that.



So the exemptions cover the use of recorded and streaming video in educational and documentary contexts; the use of electronic literary works in conjunction with assistive technologies; jailbreaking phones and tablets to enable interoperability or remove unwanted software.  So that's interesting.  That's in.  That's an official exclusion now from the DMCA.  Efforts to access automobile software.  So this sounds like deliberate cover being provided for important classes of research.  Efforts to make non-functioning videogames accessible.  Efforts to bypass 3D printer materials controls.  Seems a little specific, but nice.  Efforts by patients to access data in personal medical devices now has an explicit...



LEO:  You can hack your own pacemaker.



STEVE:  ...waiver.  Yeah, just don't turn it off.  And attempts to reverse-engineer software for security research, broadly.



LEO:  We were talking about this yesterday because...



STEVE:  Oh, good.



LEO:  We had Ron Rivest on Triangulation, of RSA.



STEVE:  Oh, yes, the "R" of RSA.



LEO:  Yeah.  And he and his colleague David have founded something called VerifiedVoting.org to promote secure voting and to talk about voting and why online voting is a bad idea.  And we got to talking about the Diebold voting machines, you remember, from about 10 years ago; and Ed Felten, the Princeton professor who hacked the machines, but was very worried that the DMCA would prevent him from doing that kind of research because he's reverse-engineering proprietary code.  They even have, Princeton has a Freedom-to-Tinker.com website.  But so I had not realized that that new regulation had gone into effect today, so I didn't - we didn't - I neglected to mention it yesterday.



So a couple of points.  If you're interested in election machine fraud and election fraud and how to - there's actually a proposal for how to do a secure election, which of course involves paper auditing.  Watch Triangulation from yesterday.  It's a great show.  And then the second point is, I'm sorry, I didn't realize that that was now legal.  You can tinker, thanks to the Librarian of Congress.



STEVE:  Right.  And in fact Ed Felten was mentioned by Iain Thomson.  Iain Thomson covered just yesterday a story in The Register titled "Crypto Guru Matt Green" - of course Matthew Green, who we're often talking about - "asks the court for," as Iain put it, or whoever titled his column put it, "DMCA force field so he can safely write a textbook."  Iain wrote:  "Assistant Professor Matthew Green has asked U.S.  courts for protection so that he can write a textbook explaining cryptography without getting sued..."



LEO:  Wow.



STEVE:  I know, I know.



LEO:  So sad.



STEVE:  Like this is the world we're in.



LEO:  Yeah, yeah, yeah.



STEVE:  "...under the Digital Millennium Copyright Act.  Green, who teaches at Johns Hopkins University in Maryland, is penning a tome called 'Practical Cryptographic Engineering' that examines the cryptographic mechanisms behind the devices we use every day, such as ATM machines, smart cars, and medical devices."  And this is what you want.  I mean, what a cool idea for a book.  "But this could lead to a jail sentence if the manufacturers file a court case using [the infamous] Section 1201 of the DMCA.  Section 1201 prohibits the circumvention of copyright protection systems installed by manufacturers, and comes with penalties including heavy fines and possible jail time.  As such, the Electronic Frontier Foundation (EFF) has taken up Green's case [yay] and that of another researcher to try to get the provision ruled illegal by the courts.  EFF staff attorney Kit Walsh said:  'If we want our communications and devices to be secure, we need to protect independent security researchers like Dr.  Green.'"



So the EFF has decided to support two actions against the DMCA, Green and this other case of a researcher who wants to make an open-source computer that would allow commercial videos to be edited.  EFF is hoping that these test cases can bring down Section 1201, and hopefully the entire DMCA.  And I had in my show notes here, God bless the EFF.  So I'm so glad we have them as our ombudsmen.



And on the other side we have the MPAA and the RIAA.  Oh, boy.  Now, this was a piece in TorrentFreak.  So, yes, it's got their angle.  But it looks like it's mostly facts.  There is something known as the Internet Infrastructure Coalition, the I2Coalition, which is a group of it looked like more than a hundred when I scanned through it.  But some prominent names popped out, including Amazon, Google, DreamHost, GoDaddy, Plesk, Rackspace, Tucows, and VeriSign, just to name a very few of them.  They are urging the U.S.  government not to blindly follow the RIAA's and MPAA's new input regarding online piracy threats.



This group is warning that the future of the Internet is at stake.  "The problem is those copyright stakeholders are dramatically broadening their attacks beyond specific sites, such as The Pirate Bay, to now include technologies and technology providers which they claim threaten their rights.  For example, this year the MPAA and RIAA identified domain name registrars as possible piracy facilitators."  A registrar.



In addition, several "rogue," as they called them, hosting providers were mentioned, including Cloudflare.  The MPAA characterizes Cloudflare as a service that creates "obstacles to enforcement."



LEO:  Oh, my god.



STEVE:  I know, claiming that it helps pirate sites to hide.  So the I2Coalition, pushing back, argues that the submissions, the MPAA and RIAA submissions show a misinterpretation of the obligations domain name registrars have under the Registrar Accreditation Agreement, the RAA.



The MPAA and RIAA would like domain registrars to suspend domain names that are merely accused of copyright infringement.  Can you imagine what havoc that would wreak?  But most registrars refuse to do so without a court order - rightfully so, according to the I2Coalition.  "The vilification," they write, "of technology and misconstruing of the RAA" - that's the Registrar Accreditation Agreement - "have one goal in common:  forcing Internet infrastructure companies to act as intermediaries in intellectual property disputes.  This is not the answer to intellectual property infringement and is not the purpose of the Special 301 process."  That's the process through which the copyright holders are able to make their case.  And, they write, "Proposals to extend the use of these companies as intermediaries are misguided."



So, wow.  I mean, we all know that every step of the way the RIAA and MPAA, the Motion Picture Association of America, have fought essentially advancements.  You know, they didn't want, famously, VCRs.  They didn't want home recording of television content, even for the purpose of time shifting.  They absolutely tried to keep it from happening.  And what's so weird, Leo, and I know you know this, is look at all the benefit they have reaped from DVDs, which they also fought against.  And now the Internet itself.  I mean, this is a huge content delivery system.  And, yes, there's some piracy.  But that goes along with the tremendous benefits that they're getting.



LEO:  Yeah.  We've been saying this for years.



STEVE:  Yeah, yeah.



LEO:  They never give up.



STEVE:  So Proton Mail is a service that many of our listeners have asked me about.  And I'm, you know, I haven't looked at it closely.  It bills itself as a secure email solution.  And my problem is that is an oxymoron.  So, I mean, I don't know how you do that.  And I understand the problem.  So it's like, okay.  I'm not wanting to discourage anyone from it.  I'm sure it's a more secure email solution than essentially no security.  But, okay.  Anyway, this was really interesting.  And in my little note here I titled this:  "How Google Almost Killed ProtonMail."  And I'll just share what they wrote because it's interesting.



"The short summary is that, for nearly a year, Google was hiding ProtonMail from search results for queries such as 'secure email' and 'encrypted email.'  This," they write, "was highly suspicious because ProtonMail has long been the world's largest encrypted email provider.  When ProtonMail launched in Beta back in May 2014" - okay, so it hasn't been that long - "our community rapidly grew as people from around the world came together and supported us in our mission to protect privacy in the digital age.  Our record-breaking crowdfunding campaign raised over half a million dollars from contributors and provided us with the resources to make ProtonMail competitive against even the biggest players in the email space.



"By the summer of 2015, ProtonMail passed half a million users and was the world's most well-known secure email service.  ProtonMail was also ranked well in Google Search at this time, on the first or second page of most queries, including 'encrypted email' and 'secure email.'  However, by the end of October" - so that was the summer of 2015.  "By the end of October 2015" - so just exactly a year ago - "the situation had changed dramatically," they write, "and ProtonMail was mysteriously no longer showing up for searches of our two main keywords.



"Between the beginning of the summer and the fall of 2015, ProtonMail did undergo a lot of changes.  We released ProtonMail 2.0; we went fully open source; we launched mobile apps in beta; and we updated our website, changing our TLD from .ch to the more widely known .com.  We also doubled in size, growing to nearly one million users by the fall.  All of these changes should have helped ProtonMail search rankings as we became more and more relevant to more people.



"In November 2015 we became aware of the problem and consulted a number of well-known SEO experts," you know, Search Engine Optimization experts.  "None of them could explain the issue, especially since ProtonMail has never used any black hat SEO tactics, nor did we observe any used against us.  Mysteriously, the issue was entirely limited to Google, as this anomaly was not seen on any other search engine.



"All throughout Spring 2016, we worked in earnest to get in touch with Google.  We created two tickets on their web spam report form explaining the situation.  We even contacted Google's President of EMEA Strategic Relationships, but received no response nor improvement.  Around this time, we also heard about the anti-trust action brought forward by the European Commission against Google, accusing Google of abusing its search monopoly to lower the search rankings of Google competitors.  This was worrying news because, as an email service that puts user privacy first, we are the leading alternative to Gmail for those looking for better data privacy.



"Finally, in August, with no other options, we turned to Twitter to press our case.  This time, though, we finally got a response, thanks in large part to the hundreds of ProtonMail users who drew attention to the issue and made it impossible to ignore.  After a few days, Google informed us that they had.  quote, 'fixed something,' without providing further details.  The results could be immediately seen."



And I didn't put it in here, but their posting shows their page rank, like historically and on that day, and they just jumped immediately right to the top of the pile again.  So I thought that was interesting and just sort of a reminder that Google has an awesome responsibility to be fair, as Google themselves say, to do no evil, or to not be evil.  And they do have their own commercial side which is driven by people using Gmail.  Yet they're also a search engine.  And, you know, I'm now myself aware of the individualization that Google does.  Frequently I'm looking at a - I'll do a search, and I'll look at the results that come up, and I'll notice in faint gray, "You've visited this site five times."  Which is, you know, it's like, oh, okay.



So we know that, if you're logged in, and Google knows who you are, they're doing what they think is best, hopefully, for you.  But I often wonder when I say to someone, oh, just google this and you'll find it, because I do, but that doesn't necessarily mean somebody else will.  So anyway, I wanted to shine a little bit of light on this because it's an important thing, I think, that, I mean, we don't know what happened.  Maybe, we don't know, maybe there was a problem spidering their site, or they got blacklisted by mistake.  Who knows?  It's good that it got fixed.



LEO:  Yeah.  We did that to ourselves with the new TWiT website because we didn't want spidering to go into our old site.  So there's a webmaster tool, you can say don't look at the old site.  And we didn't know that it's a wildcard tool, and anything to do with TWiT.tv, no matter what the subdomain, will get blocked.  So we basically took ourselves off the Google listings.  And it took Matt Cutts, who works, worked for Google.  I asked Matt, and I said, "What can we do?"  And he looked into it, and he figured it out, and he fixed it.  So it's easy to do it by accident.  So I wouldn't jump to conclude that Google's doing it.



STEVE:  Right, right.



LEO:  And by the way, a little tip, if you want to know what other people see with search results, just use an incognito tab in your browser.



STEVE:  Ah.



LEO:  And you'll be logged out, and you'll see plain search results.



STEVE:  Good, good.



LEO:  Are you ready?



STEVE:  So, yes.  Windows 10 users, high-end users, our listener users, will probably find this interesting.  We know, because he said it on the podcast while you were on vacation, Leo, that Father Robert finally gave up on Windows 10 when on two separate occasions it forced an upgrade and reboot that took his system away from him for, like, a chunk of time, right in the middle of a podcast, or when he was doing something that could not be interrupted, like in real-time.  And he said, okay, that's it.



So thanks to somebody tweeting, I did some digging, and I found a post, a nicely written post by someone basically ranting about the fact that Windows Update has become user-hostile, and arguing that Microsoft is really disrespecting its users.  I don't take any position on that.  But he also linked to a different posting which I have in the show notes for anyone who wants it.  I'll just walk everybody through this quickly.  I mean, I will tell you enough to do it if you're interested, but you can also get it from the show notes.  And that is, there is a group policy setting which can be changed to give you back control.



As I understand it, and I don't have this from personal experience, but I've certainly heard of it from many people, Father Robert and the guy who wrote this, who looked at it deeply, it becomes impossible after a certain amount of nagging, and you putting off the upgrade, Window Update finally just decides, look, we're giving you the new code whether you give us permission or not, and it just does it.  And there isn't a way to prevent it.



So for everyone except Win10 Home, which doesn't include gpedit.msc, if you just do the Windows "R," or just use the Run option, and then enter gpedit.msc, that launches the Group Policy Editor, which is not a part of Windows most people see, but it's there.  And there are all kinds of good stuff.  Under Computer Configuration, and then under that Administrative Templates, and under that Windows Components, and under that Windows Update, that will bring you to a right-hand panel that lists a whole bunch of different settings.



What you're looking for there is Configure Automatic Updates.  You double-click that in order to open up its settings.  And you'll find four different levels which for some reason there's no Level 1, but so they're numbered Level 2 through 5.  What you want, I think 3 is the default.  You want Level 2, which is notify for download and notify for install.  Level 3, if memory serves, I didn't write it, but I think Level 3 was download and notify for install.  But that's the default.



And apparently what happens is, if Windows downloads the updates, then at some point it just gets impatient with you, if you just keep saying no, no, not now, it's not convenient now; or if you leave your machine on, for example, overnight because you're in the middle of something, and you wake up in the morning and it's been rebooted without your permission and losing whatever you may have had.  So what you want is Level 2, which is notify for download and notify for install.  That way Windows doesn't get the download and then become impatient with it.



So you choose Level 2 and make sure you enable the policy.  There's a sort of a separate two radio buttons, Enable and Disable the implementation of that policy.  Then say Apply and Okay, and you should then regain control of Windows 10.  You'll get notified, which you want.  But it won't take control from you at any point.



LEO:  I think at some point you are compelled to do the updates,  though.  That was part - if you did the free Windows 10 upgrade, part of the service agreement is that you will do updates.  And you know why we want you to do that, because people put off security updates, and they become a hazard on the Internet.  So Microsoft made that a condition of the free upgrade.  There's a - I'm going to ask Paul and Mary Jo tomorrow.  But another way to do that, if you don't have Group Policy Edit, is to - this may have side-effects that you don't like.  But it's to say you have a metered connection.  Because Windows Update will only automatically download and install if you don't have a metered connection.  In other words...



STEVE:  Oh, that's nice, very nice.



LEO:  Right?  Because they don't want to incur charges for you on the updates, and these updates are quite hefty.



STEVE:  Without permission, yeah.



LEO:  Right.  So if you do that in the network settings, say this is a metered connection, that will also change the behavior.  It may have other side effects, though.  So I'll ask Paul about this.



STEVE:  And that is, by the way, one thing I did notice is that the quality rollups are big.  I think this month's was 364MB.  That's the number that sticks in my mind.  The preview for next month is only showing, I just looked at it, 120.5MB.  But still, they used to be seven and eight and sometimes 15.



LEO:  If you have a small bandwidth cap, and a lot of our listeners do, they don't want to incur charges for you.  So I think just say, hey, this WiFi is a metered connection.



STEVE:  Nice.



LEO:  I don't think it'll have any other negative effects.  But just be aware that you did that.  And do patch eventually.  It's just you don't want these annoying - I completely agree with Robert, there's nothing more annoying than trying to do a show, a dialogue.



STEVE:  Yeah, well, in fact, for two weeks now Skype has said, oh, there's an update.  You want to do it?  And I go, oh, no, no, no, no, no.  Not right now.  Let's wait till after the podcast.  So today I will remember, and I will let Skype do its update.  Actually, I think I did it last time, so it just seems to be updating all the time.



LEO:  There is some urgency.  I mean, if you listen to this show, you understand the urgency of applying updates.



STEVE:  Oh, yes.



LEO:  And most people just don't do it.  They go, oh, yeah, yeah.  So you can see why Microsoft kind of opted for this pushy thing.



STEVE:  No, and yes, I actually absolutely do understand it.  I think that they were recognizing that, I mean, they want to help their users be secure.  And you have to push.  I mean, look at, you know, Google has done the same thing with security.  When they absolutely set a drop-dead for SHA-1 certificates...  



LEO:  That's why.



STEVE:  ...we all went, whoa, wait a minute, Gestapo, you know.  But it's like, well, that's what was necessary in order to finally get the industry to give up.



LEO:  Your mother knew that.  Without a good swift kick in the butt, you ain't going to do nothing.



STEVE:  So speaking of Google, on Friday, October 21st, so what is that, 10 days ago, they reported zero-day vulnerabilities, previously publicly unknown vulnerabilities, to Adobe and Microsoft.  Adobe updated Flash on October 26th to address the zero-day flaw that they were given.  And Google notes in their security blog:  "This update is available via Adobe's updater and Chrome's auto-update.



"After seven days, per our published policy" - and you can see Google's a little sensitive to this.  This is why they're making this clear.  "After seven days, per our published policy for actively exploited critical vulnerabilities, we are today disclosing the existence of a remaining critical vulnerability in Windows for which no advisory or fix has yet been released."  So they gave Microsoft a week, which is not time, you know, not enough time.  First of all, I mean, it would have to be, like, really important for Microsoft to, after they'd just unveiled the big bundle updating system, for them to - and as I said, that also seems to create some lead time for them because they're also giving us previews of next month's coming bundle.  Suddenly Google says, "Oh, by the way, you've got seven days to fix this."  Well, okay.



So anyway, it didn't happen.  So they say:  "This vulnerability is particularly serious because we know it is being actively exploited.  The Windows vulnerability is a local privilege escalation in the Windows kernel that can be used as a security sandbox escape.  It can be triggered via the win32k.sys system call SetWindowLongPtr."  And they give the details.  You give it an index GWLP_ID on a window handle that has a child window, which most windows are.  That's anything that is slaved to the parent containing window.  "Chrome's sandbox blocks win32k.sys system calls using the Win32k lockdown mitigation on Windows 10, which prevents exploitation of this sandbox escape vulnerability.



"We encourage," they say, "users to verify that auto-updaters have already updated Flash" - because again this is happening now, Flash is being exploited until this is fixed - "and to manually update if not, and to apply Windows patches" - Leo, to your point - "from Microsoft when they become available for the Windows vulnerability."



LEO:  Mm-hmm.



STEVE:  So as I said at the top of the show, it would be interesting to see how Microsoft dances with this one because this is important.  They've already released next month's update preview.  I don't know if it incorporates the fix for this.  But it seems hard to believe that it could because it was sitting in my Windows Update last Tuesday after the podcast.  So, again,  there is now an unpatched zero-day in the wild.  We don't know anything more about it.  It's not remote-exploitable.  It's a local privilege elevation.  But as Google said, that can be used by an app running on your system to break out of a sandbox.



Which brings me to this week's errata.  I got a tweet from a Darko Vrsic, and also Jeff Bearer.  Darko tweeted:  "Hi, Steve.  In SN you said any unpatched web-facing Linux server is vulnerable to Dirty COW exploit.  Isn't it only locally exploitable?  Jeff was a little harsher.  He said:  @SGgrc really got his description of Dirty COW wrong.  Like super extra wrong."



LEO:  Oh.



STEVE:  He says:  "It's not remotely exploitable."  Okay.  Now, I think the mistake - first of all, they're right.  The mistake I made was that you and I were talking about this before we began recording because I had sent you email that morning asking you to bring in some of your Android devices.  Although that's different than this vulnerability; right?



LEO:  That was for Drammer.



STEVE:  That was the Drammer.  So anyway, I got my wires crossed because I remember there I was talking about how Drammer could be used if, for example, you had a Stagefright exploit, which in fact the Drammer guys did use in order to gain a foothold, and then Drammer was used to give them root access.  So these guys are right.  Dirty COW is a local exploit.  So, for example, it could be used by somebody who had access to a console on a shared system to elevate themselves to root and then get free rein of the system.



The problem is that - and I should have been more clear about this, so I certainly take everybody's point.  And that is that it is not itself a remote exploit.  But it's worrisome because what we see often is a chain of these vulnerabilities where you link them together in order to achieve what you want.  And you just don't want any of these links intact.  So everybody's right.  I wanted to clean this up.  It is not, as far as we know, directly exploitable.  But if there was a vulnerability that allowed someone to run some code on a web-facing Linux server, then this allows them to convert themselves to root, which you absolutely don't want to allow happen.  So thank you, everybody, for helping me fix that.



A couple bits of miscellany.  I finished Hamilton's "A Night Without Stars," which was a good conclusion to the Faller saga.  I love Hamilton's Commonwealth.  I love that little universe that - well, it's not little - the galaxy that he has created.  But overall I have to say I thought this was not as wonderful as the "Pandora's Star"/"Judas Unchained" pair.  It felt a little bit like he was finishing the story because he had to.  It was fun; and there were points, as I said last week, when I hit 24% it just took off like a rocket ship.  But I'm glad I'm done.  I'm not reading anything right now.  I'm taking a break.  But I just did want to say it was good.



I did want to put on everyone's radar that, except for us in the U.S., apparently, the second season of "Humans" has begun airing.  I already saw some tweets about it.  We don't get it until February of next year, of 2017, on AMC.  And it looks like it's going strong.  Season two introduces Carrie Ann Moss, who we all know as Trinity from "The Matrix," as an AI expert who works herself into the plot.  And it sort of picks up a couple months after we left off with the first season.  And it was only eight episodes.  I was surprised when I saw that again because it was so rich, and it was so interesting.  So for what it's worth, if you missed it, the first season is available on various outlets, and I think it's really worthwhile.  It was really well done.



And I'm not going to say much about this, but this is in the Blue Sky Department.  Apparently scientists have actually successfully written data in diamonds.  There is a way, by using either a red or a green laser, to flip a molecule in a microscopic flaw in a diamond matrix, and it's a stable change.  And it's a long way away from being ready for the world.  But I just keep thinking of the little storage wafers on Star Trek; and I'm thinking, you know, we're heading in that direction.



LEO:  It would last forever, too; right?  I mean...



STEVE:  It absolutely would.  It would be, as they say, "Diamonds Are Forever."  And this article, it was in The New York Times, it also said, "And your data could be, too."  So again, blue sky, no time soon.  And apparently you can use industrial manufactured diamonds.  You don't need to have high-end...



LEO:  Oh, that's a relief, yeah.



STEVE:  Yeah, exactly.  And I did get - now, this is weird.  I thought, what's the punchline?  Because he says:  "Hi Steve.  A SpinRite story for you with a punchline."  This is from Matthew Olmsted in Davis, California.  And he was sort of stretching a little bit.  Or reaching.  He said:  "My story begins when I advised my dad to give your product a try on a failing drive in his laptop.  Sadly, it was already so far gone mechanically that SpinRite wasn't any help, though he was able to eventually get the data off."  So I guess he just kept trying, but SpinRite wasn't able to, like, fix the drive.



"He was frustrated and decided to give his SpinRite license to me.  Fast-forward a few months, and a friend of mine in Colorado" - thus the punchline we're getting to - "has started having troubles, saying his system was getting blue screens on boot with the error mentioning:  'This was probably caused by the following module:  hal.dll.'  Which all of us long-time Windows users know is one of the core boot dll's and often causes a problem.  



"After looking it up," Matthew writes, "I found that it's the Hardware Abstraction Layer module.  Not good.  I sent my friend a copy of the SpinRite ISO and walked him through setting up a bootable CD.  After that, I got him set up running a scan over a drive.  The next I heard from him, the system was running again without any problems.  So whether you like it or not, Steve, you can now say of SpinRite:  'So easy, a stoner can do it.'"



LEO:  Hah.  Yeah, maybe not.



STEVE:  I don't think that's going to be my tagline.  I think "It works" is probably what I'm going to stay with.



LEO:  It works is the main thing.



STEVE:  Yeah.



LEO:  It works.  All right, Steve.  I've got questions.  I'm thinking that since you gave me the questions, you have answers.  I could be mistaken.  I don't know.



STEVE:  Generally I do.



LEO:  Maybe not for the last one.  Actually, I know you do.  I know you do.



STEVE:  Ah, yes.  



LEO:  You know all.  You may not tell all, but you know all.  This is a tweet, comes to us from @dpmanthei.  I guess that's his name.  Would changing the target - this is an interesting question - of my Chrome bookmarks, instead of the name of the site, the actual IP address of the site, would that mitigate the impact of a DNS DDoS?  In other words, if you don't need DNS, who cares if it's down?



STEVE:  Exactly.  So, okay.  The first problem is that, if a site's IP address changes, obviously then the bookmark would be obsolete.



LEO:  Right.



STEVE:  One of the beauties of DNS is that it does provide a mechanism, as we've discussed, for allowing a controlled degree of caching.  But it's easy to look up a site's address in Windows from a command prompt.  You do nslookup, space, and then the domain name; and, bang, you get the IP.  Now, sometimes you get five because one of the ways that sites load balance or handle redundancy is they will give you a batch of IPs.  And some DNS servers will automatically rotate them with every query because the idea is you will try them in the order that they are delivered.  And so that statistically spreads users out across a number of different IPs.  And the advantage is, if one goes down, then the DNS record contains four others that the system can try in succession.  And it also automatically, as I said, spreads people out.



But let's say that's not a problem, that is, that the IP is fixed.  The problem you still have is that, when you obtain the web page, it absolutely contains URLs for other assets from that site.  Now, the URLs could be relative URLs, meaning that they just begin with a slash for the root and then specify the directory.  If a browser sees that it implies the same HTTP whatever, colon slash slash whatever domain that the page came from.  So you can use what is known as a relative URL.  But what I tend to see on web pages is explicit URLs, where every other, you know, widget and gadget and thing on the page says https://www dot whatever.



So the problem is you could get the first page.  You could get sort of the page framework.  But the assets from that site would still need DNS to look them up.  Technically, your system knows what the IP is, but it doesn't know about the mapping.  So if you were really wanting to do this, that is, to switch your bookmarks to an IP, the hosts file, the hosts file that I talked about as the way I solved that problem that morning by mapping the IP for our upstream merchant provider into the hosts file.  Suddenly then the commerce system came back alive because it thought it was able to look up the domain name.



So if you wanted that, you could simply create a hosts file with all of those domains and their IPs at the time that you create the file.  And if there was ever an outage like this, then you'd drop that hosts file in, or change the hosts file from your normal mostly empty one to one that's been populated, and suddenly you and you alone in your neighborhood will have access to those sites because you've hardwired the lookups into your local system.



So just setting the tab or the bookmark probably isn't going to do the job because pages will have so many references inside to other assets on the same server.  If they were relative URLs, then it would probably work all right.  It would just fetch all of those things.  I mean, the site might be a little flaky, like if it tried to move you to a secure, if you weren't secure, and it moved you there, that might break things and cause things to stop.  So you really can't rely on it.  But essentially the hosts file is the first place the system looks.  So if you were interested in creating a defense against this, you could create a fully populated hosts file, and it would work.



LEO:  Yeah.  A lot of people do that.  That's also a way to block ad sites, by pointing a known ad site URL or number to local hosts, something like that.



STEVE:  Right.  In fact, at GRC, I have a 10-dot network inside the network.  Yet the various machines there need to refer to each other using domain names.  But the problem is, if they look up DNS, they get the public IP, which is in Level 3's space, you know, 4.79.142.200, for example, for GRC.com, which won't allow them to reach a machine inside the network.  So I use, I mean, it was easy to do because I didn't have many places to do it.  I used a hosts file on those machines to override the lookup of public DNS, and so they're able to find each other in the 10-dot network.



LEO:  Of course you could just memorize all the important IP addresses.  Just type those in instead of names.



STEVE:  That's right.



LEO:  That's the way a real geek would do it.  @Sundance1555 asks:  Why don't browsers store/cache IPs to skip DNS?  Wouldn't that prevent attacks like what happened on Friday?



STEVE:  You know, and that question always comes up because we've had attacks on DNS before.  And people say, hey, you know, why is the system so stupid?  Well, the reason - our listeners probably know that you always see pairs of DNS numbers, DNS IPs.  That is, like 4.4.4.1 and 4.4.4.2.  Generally it's in pairs.  The only reason for that is the original recognition of the importance of DNS.  And so the original people who implemented this said, "You know, if we don't have DNS, we don't have anything.  So let's always provide a pair of servers."  In some cases, they both map to the same hardware.  Technically, they're supposed to be in different networks.  And you'll see sort of older school providers who remember those days will deliberately have the second to the last digit be different.  Even if it's technically on the same network, they're just wanting to play by the rules, which was you ought to have geographically dispersed DNS because it's really important for people to get to.  And a local network outage should not bring your DNS down.



So it is important.  But that's really the only concession that was made.  The original designers said, oh, we'll just give them redundancy.  There wasn't this notion of, wow, we're going to be suffering through long attacks without DNS.  We need to fall back to the most recently known IP.  Why not use that?  And in fact what Sundance1555 has suggested is a good idea.  And it's been discussed, for example, that it'd be nice to have a DNS add-on or like a local shim that could intercept requests and cache them statically and permanently so that, if DNS fails, and you're unable to obtain a fresh IP address, falling back to what was the last obtained IP for that domain name, that would work.  It would certainly work for GRC and for most other companies, just as it worked for my upstream merchant provider.



So it's not something that our systems have at the moment; but, yeah, it's a good idea.  And if attacking DNS becomes more prevalent, I bet we're going to see somebody do that because it would allow people to cruise right across an outage without even knowing it.



LEO:  Yeah.  Robert Hancock, @chuhaitime on Twitter, notes a known bug in the EdgeRouter X:  Hi, Steve and Leo.  I think Robert's one of the people I saw at ITProTV, by the way.



STEVE:  Hi, Robert.



LEO:  Just FYI, there's a bug in the EdgeRouter X bootloader which causes it to function as a simple switch at boot.  A firmware update does not fix it.  The file from the Ubiquiti forums, update-boot.sh, it's a shell script, will fix it.



STEVE:  So this was interesting for two reasons.  First of all, I wanted to bring this to the attention of our listeners because...



LEO:  A lot of them have it because of you.



STEVE:  Yeah.  This is our favorite router.  I mean, it's $49, and it's a five-port router and a little powerhouse.  But the problem is an interesting one.  The bug is that - and what's so interesting is that it happens actually a lot of the time.  When it is booting up, the hardware comes up, and it functions as a switch.  And it's only after a supervisory layer or process starts, a little bit after that, that it then becomes a rule obeying router.  And the problem is that could be leveraged.  That little slice of time could be leveraged for exploit.



For example, say that a high-level state actor wanted access to your network.  So they briefly shut off your power and bring it back up and then immediately start hitting your router.  They're going to get through because it won't be doing any NAT or any blocking or any rule-obeying.  It's a simple switch, giving them complete brief access into your network.  I mean, again, it's a farfetched scenario; but what we're seeing now is that farfetched scenarios are being realized.



So although this is a shell script, I grabbed it and looked at it because I was curious.  First of all, I was curious when it was so big.  I wrote it down, I thought, somewhere.  Oh, yeah, 166K.  So I thought, okay, wait a minute.  What?  It's mostly, it is a shell script.  It's a little bit of script at the top and at the bottom of a huge 165K base64 encoded ASCII blob.



LEO:  Ooh, I don't like that.



STEVE:  Well, right.



LEO:  Because you can't tell what it is.



STEVE:  Well, but it is, I mean, you would download firmware, right, from Ubiquiti.



LEO:  Yeah.



STEVE:  And they do provide an SHA-1 hash so you can verify that it has not been changed.  And it's coming from - the actual shell link is ubnt.com/firmwares/edgemax.  So it is coming from them.  It's not coming from like a forum posting.  So I'm glad you brought that up, Leo, because, yes, it is actually from their firmware repository.  But for whatever reason they did it as an update boot shell script.



LEO:  Yeah.  I like that, actually, yeah.



STEVE:  Yeah, yeah.  It's easy to deploy.  So you just use cURL in order to grab it and then run it.  And it goes.  And it fixes this, which prevents there from being this little gap while it's booting that it is not a router, it's a switch, because there are some conceivable exploits of that.  So thanks, Robert.



LEO:  Yeah.  And I might have gotten Robert's Twitter handle wrong.  It is ambiguous, because [Bleak] tells me that Chuhai is a beverage, an alcoholic beverage in Japan.  So it could either  be chu-haiti-me or chuhai-time.  I think it's ambiguous.  Don't know what it really means.  Only Robert knows.



STEVE:  And I was going to say most people have no idea.



LEO:  No idea.



STEVE:  They're just like [crosstalk].



LEO:  I like chu-haiti-me.  Will Larson in Gilbert, Arizona has deployed Local Egress Filtering, or LEF:  Hey, Steve and Leo.  Just listening to the podcast about DDOS and Dyn, and you mention egress filtering at the ISP level.  I mentioned it, and you told us why it wouldn't work.  Using a packet filter in a local router - I use OpenWRT firmware - I have my router check that the source IP is legitimate - oh, this is a good idea - before it leaves my WAN port.



STEVE:  Ah, yes.



LEO:  So everybody could do that, and at least they'd know that they weren't having a spoofed IP address on an outbound packet.



STEVE:  Now, here's what was interesting.  It's exactly that, Leo.  I hadn't - either I knew this once and I'd forgotten it, because I was once deep into NAT'ing and all that, or it never occurred to me.  But I don't know why a NAT router would pass...



LEO:  Right.  It should - yeah.  I mean...



STEVE:  Yeah.  Because as a packet...



LEO:  It's clearly wrong.



STEVE:  Right.  As a packet is leaving, what it does is, because it's called "packet rewriting," it rewrites the source IP from an IP in the LAN to the router's current public IP.  That way - so the packet arrives at the router from the inside, from the user's network.  And it's got a source IP of one of the machines in the LAN, you know, 192.168 dot something dot something.  The router, the act of NAT is it changes that 192.168 that'll be in the packet header, in the IP packet header, changes that to whatever the IP is, four dot whatever, eight, you know, the public IP.  And it makes an entry in the NAT table which says, when a packet comes back from the same destination IP and port, change the destination back to 192.168 whatever and stick it onto the internal network so it'll find its way back to that machine.  That's NAT.



But what would the router do when it gets a packet trying to leave that doesn't have a local IP, that is not 192.168, but it's like the IP of some DNS server somewhere, which some light bulb or your toaster or something that's been taken over remotely is attacking.  So I'm a little mystified.  Do routers, I mean, if it's possible to spoof a source IP across a NAT router, that would suggest - and this is where I'm thinking either I knew it once and forgot it or I never knew it.  But that would suggest that the router looks at the source IP, decides first is it within the LAN range.  And, if so, it NATs it; and, if not, it passes it.



But if routers simply dropped a packet that has got a spoofed source IP, all of this problem would go away because there's not a light bulb in hell that is not behind a NAT router.  They're all behind NAT routers.



LEO:  But didn't you tell me last week that that doesn't work at the ISP level because these IoT devices aren't in fact sending spoofed source packets?  They don't care.



STEVE:  Correct.



LEO:  They say, yeah, it's me, I'm doing it, because even - there's millions of them.



STEVE:  Yes, you're right.  And that's the argument about anybody bothering with all this is it's not going to completely solve the problem because they simply do legitimate HTTP connections or DNS queries or [crosstalk].



LEO:  Or GREs or whatever.



STEVE:  Yes.



LEO:  And the reason I brought it up last week is because in the early days of DDoS attacks they would use raw sockets, which you rightly pointed out is a real flaw, to spoof their outbound address, or I'm sorry, their source address, so they couldn't be stopped.  But that was when you had a limited number of machines doing the attack.  Now that you have virtually infinite machines, you don't care.  You don't care.



STEVE:  Hundreds of millions.



LEO:  Right.  No reason to hide.  You can't be, you know, you can be blocked, but there's plenty more where those came from.



STEVE:  Okay.  Let's skip to the last question.  It's 4:00 o'clock.



LEO:  All right.  All right.



STEVE:  And we've got two hours on the podcast.  We'll pick up these questions either next week or the week after.  But we've got to do our Brain Teaser of the Week.



LEO:  And this is a long one.  Wow.  Holy cow.  Or am I looking at the wrong thing?



STEVE:  Yeah.  Way down at the bottom, number 10, James Patrick.



LEO:  Way down at the - oh, yeah.  Well, I only see five.  Oh, there it is.  Ah, yeah, yeah, yeah.  James Patrick, Indiana, brings us the Security Puzzler of the Week.  Listen carefully, friends.  I guess you don't have to listen carefully.  You can always rewind it if you didn't get it the first time.  We know, writes James, that when we have compressible data which we also want to keep private through encryption, if the data is compressible, we want to compress it first, then encrypt it, since encryption creates maximum entropy which is inherently uncompressible.  In other words, if you encrypt it first, you wouldn't be able to compress it because it would be data.  It would be random anyway.



STEVE:  Right.



LEO:  But can anyone think of a case - and this is the stumper; right?  - where compressing the file before encrypting it, compressing before encryption, which is the routine course of events, would have undesirable side effects?  It would give you a result you didn't want.



STEVE:  Yes.  Think about that for the week, and I will explain why that could be a problem.



LEO:  So you might not want to compress at all.



STEVE:  The question is how can that be a problem?



LEO:  I think I know.  Do you know?



STEVE:  You gave it away last time, so don't guess.



LEO:  I'm not - was I right last time?  Oh, I didn't even know.



STEVE:  Yeah, you were.



LEO:  So much for that.  I think I know.  But we'll find out next week.  That's an excuse to listen next week.



STEVE:  That's what they need.  They need a reason.



LEO:  Another excuse, yeah, they don't need [crosstalk].  Every Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC, we gather together to sit at the feet of the master and learn.  And, boy, is it an education, 584 episodes' worth.  And 585 is next week.  Now, if you can't be here in person, and it's kind of fun, you know, the chatroom, and we're all sitting around, we're listening together.  But if you can't do that, you can always get it on demand.  And Steve makes it available at his website.  We do at ours, too.



But I'll tell you Steve's first, GRC.com.  The reason you might want to go there, he not only has the audio of the show, but he also has a transcript, which we don't have.  A human, Elaine, writes that all down, and she does a great job of transcribing it so you can read along as you listen.  He also has so many other things at GRC.com that it's worth a trip, not to mention SpinRite, the world's finest hard drive maintenance and recovery utility, which I just mentioned.  But things like the Healthy Sleep Formula and the ShieldsUP! and the Perfect Paper Passwords and details on the latest SQRL.  There's a whole lot of stuff there, GRC.com, all written in beautiful 1994 HTML.  No, you do use JavaScript.  Right?  Or no, just CSS.



STEVE:  Just CSS.  I know JavaScript.  I've written a bunch of stuff, as we know.



LEO:  Oh, yeah.  But you don't need it.



STEVE:  I don't need it.



LEO:  That's the point.  And the whole menu system is CSS.



STEVE:  I know all my hex colors.  I know all my hex colors.



LEO:  In his head.



STEVE:  #990033.  That's my favorite red.



LEO:  What's your favorite color?  Oh, #006699, of course.  Don't you know?  Steve is also on the Twitter at @SGgrc.  And as you could see, a lot of the questions come via that, so you can also DM him there.  He accepts DMs from everybody.  We have the show at TWiT.tv/sn, YouTube.com/securitynow.  It's on every podcast platform out there.  You absolutely must subscribe.  And what I think most people do, and I certainly encourage it, is archive past episodes.  This is not one of those things where you want to delete after you've listened to it.  Keep it around.  Burn it to a DVD or something because there's always stuff to go back to, to refer to, and we constantly do that on the show, too.  We'll say, well, as you remember from Episode 432, packets are not...



STEVE:  Well, for example, that series we did on processor architecture was really cool back then.  



LEO:  It's an education.



STEVE:  And it's still valid today.



LEO:  Yeah, this show is an education.  So please take advantage of that.  They're all available for you at GRC.com and TWiT.tv/sn.  Thanks, Steve.  I'm excited we're going to - in a month we're going to see you in-studio.



STEVE:  Yes, you are.



LEO:  You're going to bring me a hat brush.



STEVE:  I'm going to bring you a hat brush.



LEO:  And we're going to do our special holiday episode.  And I think we can mention that because I think we're going to stream it live.  We're going to prerecord an episode for Christmas week with you and a bunch of other hosts.  Denise Howell is coming up for it.



STEVE:  I think Rene is going to be there.



LEO:  Rene Ritchie's going to come for it.  Because we had so much fun...



STEVE:  And Paul.



LEO:  And Paul Thurrott.  You remember a couple of years ago, and this was the inspiration, during our New Year's Eve thing.



STEVE:  Oh, great time.



LEO:  We got you and Randal, bunch of other hosts, all sat at a roundtable, and we did half an hour.  And it was great because it was so cross-discipline.  And you guys don't usually get to talk to one another.  I think there's been a drumbeat of you and Paul Thurrott in the same room for a long time.  I think that will be - we can fight over Windows 10.  Should be a lot of fun.  Thank you so much, and I'll see you next time.



STEVE:  Okay.  Thanks, Leo, talk to you next week, on Election Day.



LEO:  Ooh.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#585

DATE:		November 8, 2016

TITLE:		The Windows AtomBomb

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-585.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the answer to last week's security and privacy puzzler, Let's Encrypt Squarespace, the new open source "LessPass" app, LastPass goes mobile-free, many problems with OAuth, popular Internet services' privacy concerns, news from the IP spoofing front, Microsoft clarifies Win10 update settings and winds down EMET, a hacker finds a serious flaw in Gmail, MySQL patches need to be installed now, a tweet from Paul Thurrott, a bit of errata, and the Windows AtomBomb attack.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Wow, there's a whole bunch of stuff to talk about:  the Patch Tuesday update, which came out today from Microsoft for Windows 10.  We can talk about LastPass, now free for some; LessPass, maybe not as good as it sounds.  And Steve will explain this whole Windows AtomBomb exploit.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 585, recorded Tuesday, November 8th, 2016:  The Windows AtomBomb.



It's time for Security Now!, the show where we cover your security and privacy online with the king.  My god, this man is the Explainer in Chief, Mr. Steven T. Gibson.  The "T" stands for Tiberius.  Hey, Steve.



STEVE GIBSON:  Ah, that would have been actually very fun if Dad had thought to do that.  But he gave me - my middle name was his first name, which was common back then.  But that's fine.



LEO:  That's fine.  Now, this is Election Day.  Before I let you do the show I have to make sure that you've voted.



STEVE:  Oh, my god, yes.  In fact, I'm annoyed that I forgot before we started recording to get the sticker off of my absentee ballot paperwork because I noticed it was down there in the lower right-hand corner.



LEO:  Yeah.  I didn't do it, either.



STEVE:  But I didn't peel it off.  And it's like - because I want to proudly say that, yes, I'm a member.



LEO:  You want to wear the sticker, yeah, yeah.  It's okay.  We voted a while ago.  Our votes are already in the system.



STEVE:  As did I, yup.



LEO:  Yes.



STEVE:  Yeah, I'm a permanent absentee, just because it's like, you know, you get the ballot a month before, you can study it.



LEO:  Right, it's convenient.



STEVE:  I normally sit down with some friends, and we all go over it together and figure out what we want to do.  It's sort of a nice little social time.



LEO:  As I mentioned last week, we did a special episode with Ron Rivest on voter security.  And one of the things Ron said, though, is early voting's great, but it should be poll-side voting.  Mailing ballots is problematic.  Sometimes ballots don't make it through.  In fact, I heard somebody got his ballot returned because the machinery misread the address.  You would think the postal service would handle those ballots with kid gloves, but some mistakes do happen.  So he said the best thing to do is do that, but then take it to a polling place.  And here in our area there are places I could have gone last week and the week before to hand it in personally.



STEVE:  Right.



LEO:  And that's the recommended, for security, that's the recommended way to do things.



STEVE:  That certainly does make sense.



LEO:  Yeah, yeah.  Anyway, what are we going to do today?



STEVE:  Well, so as promised last week, which began with "Next Week on Security Now!," we're going to finish this podcast with a discussion of a very clever use of existing Windows APIs that allows an attacker to execute their code in a victim process.  So that's not something you want to allow.  And normally the way that's done is with the famous buffer overrun.



It turns out a very clever security engineer researcher figured out how to do the equivalent of a buffer overrun without breaking any rules, not relying on any misbehavior of any kind.  And he called that the AtomBomb because it uses something known as the "global atom table," which is a feature we'll discuss that Microsoft built into the Windows API back in Windows 1.0.  It's always been there.  And the point is it turns out it's fundamentally insecure, and they can't remove it because lots of applications that exist depend upon it.  So very, very intriguing.  And, now, there are some mitigations we'll talk about.  But a great topic for the podcast.



But that's on the heels of another crazy week.  We've got the answer to last week's security and privacy puzzler.  Squarespace decides to encrypt.  A new open source app, unfortunately named LessPass - I hope he doesn't try to get a trademark on that because LastPass's attorneys are going to stomp on it.



LEO:  I kind of like the solution, though.  I'm curious what you think about it because it is open source, yeah.



STEVE:  Yes.  We have LastPass going mobile free, which confused a lot of people.  They all think that means it's free.  So we'll clarify that.  A surprising bunch of problems with OAuth, both concept and implementation, which we need to cover.  Some new Internet services' privacy concerns, and some of the details are sort of gut-wrenching.  News from the IP spoofing front.



Microsoft is clarifying the settings for Windows 10 Update and declaring they're winding down EMET, their enhanced mitigation technology, saying that it's really kind of obsolete now.  A hacker finds a serious flaw in Gmail.  The need to make sure, if you're using MySQL, that you have patched it because some patches have gotten out operating proof-of-concepts, and they're only about a month old, so you want to make sure you're current.  A tweet from Paul Thurrott that I got a kick out of.  A little bit of errata, and we'll talk about the Windows AtomBomb.  So buckle up, baby.



LEO:  Wow.  Quite the table of contents.



STEVE:  We've got a great Picture of the Week.  This shows a salesman standing in front of a couple.  In the background is a big banner sign that says, "Connected Appliances."  We've got washers and dryers and little microwaves on the side, and they're standing in front of a bunch of refrigerators.  And the caption on this cartoon says - it's the salesman speaking, saying, "Can I interest you in a firewall for your toaster?"  Yes, the future.  The future, folks.



LEO:  You know, I had somebody call the radio show.  He had bought a Samsung refrigerator five years ago.  And, you know, we think of the timeframe of a refrigerator, 10 years?  You keep it a long time; right?  But the problem is it had a big - not actually at the time, it wasn't that big, but it had a screen, and it had Calendar and stuff on it.  And it had interfaced with his Google Calendar.  But Google changed the API, and Samsung has never updated the software.



STEVE:  Wow.



LEO:  So he called and said, you know, "How can I get my calendar back on my refrigerator?"  I said, "You can't, you can't."



STEVE:  Wow, that's a perfect example of the state we're in at the moment.  I haven't said this yet, but I'm beginning to think that the only way this IoT thing is going to settle out is if we end up using the existing major proven security-conscious hubs, like Apple and Google.  I think, you know, what they need to do is create an open API.  And Apple may be a little challenged to do that.  We'll see how that evolves.  But from my standpoint, right now there are no standards.  As we've talked in the past, there are some standards sort of trying to evolve.  But I think the way to do this is to allow consumers to purchase all of the gizmos and gadgets they want, but have them communicating through a responsible party, someone like an Apple or a Google.



LEO:  Good, good, yup.



STEVE:  Who can invest in getting it right.  The problem is people are getting cameras and light bulbs and door locks, and there's complete fragmentation.  The traffic egressing from their home now carries separate streams for all of this stuff, you know, blasting across the Internet with lord knows what and literally unknowable sets of vulnerabilities.



LEO:  I don't know if this is new; but the story came out, now maybe there was something from DefCon about a flaw in ZigBee allowing the Hue light bulbs to be hacked from 300 feet, 350 feet away, and then the worm spreading? 



STEVE:  Yeah,  actually we talked about it months, yeah, we talked about it months ago.



LEO:  Yeah, that's what I thought because it sounded like that story.  So this is just somebody who's found it and repeated.



STEVE:  And that's a perfect example.  As long as, well, you know, I think the argument is this won't get fixed by itself because consumers can't be bothered to care, and manufacturers don't need to care in order to sell their stuff.  You know, people just don't understand the threat that they're under when they're putting cameras in their home and thinking how wonderful it is that they can see what's going on in their home when they're away.  Well, we've covered specific instances where, yeah, and so can everybody else see what's going on in your home when you're away.  Which is not what you had in mind.



LEO:  Yeah.



STEVE:  So anyway, last week's security and privacy puzzler asked - it posed the question that actually came from a listener that I thought was great.  We know that common security practice dictates that compressible data should be compressed before it's encrypted because after any data has been encrypted, it by definition will not be compressible because encryption essentially removes the entropy.  It removes the patterns.  It removes any of the hooks that compression uses in order to squeeze out space.



So, for example, a perfect example is if you had in a file a 4K bit of zeroes.  Any compressor worth its salt will look at that and go, whoa, wait a minute.  And instead of sending out 4,000 zeroes, it'll put out one zero and a "repeat this 4,000 times" clause.  And so, as a consequence, two little tokens go out across the wire; and at the other end, the decompressor understands that, interprets that little token, and then re-expands it to its original size.



Well, the problem is that 4,000 block of zeroes, if it's encrypted, it becomes noise.  Any good encryption will turn something like that into something that's indistinguishable from any other data.  So that can't be compressed.  So the question we posed was, does compressing, then encrypting, which we know is what you have to do if you're going to get any compression, create any threat to security or privacy?  And I guess it was sort of a rhetorical question because we know the answer is yes.



Now, we have covered in the past two famous and classic attacks on compressed HTTPS sessions.  And that was the CRIME and the BEAST attacks, where the researchers realized that, because the headers of queries were being compressed and encrypted, if they had a means to insert some of their own data, to add some data into the headers and then have it compressed, and if they could see the result after compression - so they had to have kind of a strange position on the network.  They had to be able to monitor, passively monitor the communications as it was leaving the system, but also have a means of affecting what was being compressed.



So it was a theoretical attack.  It took a huge amount of time, a crazy number of queries.  But it wasn't infeasible.  But more than anything it demonstrated, okay we have a problem here because this shouldn't be allowed to happen.  And all it took was the browsers to essentially introduce their own little kludge to work around this potential problem.  And that kludge served to obscure the information that this attack was keying on.  So we've seen it before.



The reason this came back up - and I found just a beautiful example of this - is some researchers recently, at the University of North Carolina at Chapel Hill, have extended this concept by successfully attacking encrypted VoIP, that is, Voice over IP communications such as Skype, Fring, Google Talk, and any SIP-style encrypted comms.  It turns out that, in order to get real-time interactivity, in order to have minimal delay, which is what you want in an interactive conversation, the VoIP, the digitized voice, is encrypted in packets, very short packets, so that they're able to then immediately be stuck on the wire and get to the other side to be decompressed, or I should say decrypted, decompressed, and then heard.



Well, the show notes have just a beautiful, frightening diagram from their research paper, where they demonstrate - and they pulled this off.  Taking nothing but the packet lengths, they are able, through a series of steps, to determine what was said.  And the reason is that it turns out that different vowels and  consonants and sibilance and so forth have characteristic sizes, and they compress at sort of well-defined known rates, that is, percentages.  And it's possible just from the size of the packets to reverse-engineer what was said.



So, now, once again, if somebody actually wanted encrypted VoIP, there are several things you could do.  You could sacrifice the responsiveness, a little bit of the real-time speed, by grouping in blocks rather than sending individual variable-length packets out for the sake of speed.  The other thing you could do would be to deliberately pad the packets with a pseudorandom, where the pseudorandom key is known only to the sender, you know, just generated on the fly.  You just grab a random number.  That drives a pseudorandom number generator that decides how much fluff to add to the packet.  The problem, of course, is that that tends to increase the overall bandwidth of the conversation.  So there is a cost.  But it would solve the problem of this being otherwise essentially decryptable or interpretable without decryption, just using the size.



So anyway, I love this as a classic example of why there are applications where you cannot safely compress, then encrypt, just because of the nature of the data you're compressing and the way it's available.  Again, if you were to record an entire conversation in VoIP and digitize it, then compress it as a block and then encrypt it, no problem because you wouldn't be getting the little essential time markers of when these utterances were made and how long they each were.



So it's not that it's generally bad to do this.  It's just that this was done without fully thinking it through.  And in general, and we'll see more examples of this this week, it feels to me like we are sort of moving - and we talked about this last week, Leo - to sort of a next generation of the degree of effort being put into finding problems and demonstrating that things that we've been using in the past aren't as secure as we thought they were.  And of course that's all for the good.



So today is November 8th, Tuesday.  The 1st was last Tuesday.  That makes this the earliest possible Patch Tuesday to occur in a month.  It can't ever happen sooner than the 8th.  On my Win7 system there was 134MB blob, the single security monthly quality rollup for Windows 7 for November.  And so my system installed it.  I did want to mention that last week we were wondering, I was wondering whether Microsoft would have had time to get the fix in which we discussed last week.  This was that zero-day flaw that Google informed Microsoft of just, I mean, like without much notice.  And after seven days, Microsoft's policy is we're going to let everybody know about this because this is being exploited in the wild.  Microsoft did get that fixed, so that has been fixed as part of this.



So what users should know, our listeners I'm sure are always installing patches, although we have often talked about how in some cases it's inconvenient to do it at the moment.  This is one you don't want to put off too long because it is fixing a known, currently being exploited, zero-day flaw that we discussed last week.  So good news is it's been fixed.



LEO:  Whew.



STEVE:  Yeah.  So on October 24th, about two weeks ago yesterday, Squarespace had an announcement.  And a bunch of our listeners, knowing that Squarespace is a TWiT sponsor, made me aware of it, and it just slipped through the cracks for the last two weeks.  So I wanted to just note that Squarespace has adopted Let's Encrypt.



LEO:  Yay.



STEVE:  Yes.



LEO:  And it's even easier than really - because I just did it myself.  You can see if you look at my LeoLaporte.com, HTTPS.  



STEVE:  Yay.  Cool.



LEO:  But it's so - you don't have to do any Let's Encrypt stuff.  They're doing it all behind the scenes.  All you have to do is check a box.



STEVE:  Right.



LEO:  It's awesome.



STEVE:  Yes.  On their blog announcing this on the 24th they said:  "Secure Sockets Layer, or SSL, is a technology that secures the connection between your browser and the website you're visiting.  It allows you and your website visitors to feel confident that their information is secure.  And we believe that confidence is an important part of your online identity.



"So, starting today, we're proud to offer free SSL on all Squarespace websites.  Website owners should not have to pay extra or wrestle with complex technical issues to offer this basic security to their users.  Every website can enable SSL, which will automatically direct users and search engines to a secure version of that site.  The result is that millions of more domains on the Internet will be secured via SSL, our customers can take advantage of the confidence that secure websites bring users, and we will have helped the Internet take a huge step forward in promoting security by default.



"As an added benefit," they wrote, "websites hosted on Squarespace may enjoy a boost in search ratings."  And we have heard some grumblings, I don't even know if it was put into practice yet, but we know that Google was thinking at some point they're going to promote encrypted sites over non-encrypted sites, just as another signal for their site ranking to pour into the pot as it's deciding what to do.



And finally they said:  "Squarespace is taking care of almost everything, making this an easy transition for customers.  To seamlessly manage SSL certificates for all of our websites, we've partnered with Let's Encrypt, a free and open certificate authority run for the public's benefit that provides free SSL certificates.  Current Squarespace users can see instructions on how to enable SSL on their site by checking out our Help guide."  So, yay.  That's a nice step forward.



And I also encountered a couple sample screens of the upcoming, I think it's next year, but next year's around the corner.  It's in early 2017, Google has said, and I saw sample screens from Chrome, Google's browser, where they're going to start criticizing non-HTTPS connections.  That is, rather than saying nothing, they're going to say "Secured" when it is, "Not Secure" when it's not.  And then there was a red one.  I think "Not Secure" is gray.  "Secured" is green.  But there was a red one that was like, if there's some problem with the site of some sort that Google's not happy with.  So, yeah.  So clearly no site wants to be in a position where Chrome, now the majority browser on the Internet, is saying "Not Secure."



LEO:  Yeah.  That kind of made me mad.  But you know what, in the long run, we all benefit.



STEVE:  Yeah.  Everything Google does like this makes us mad for a while.  And then we go, well, yeah, I guess it was necessary.



LEO:  All right.  And I should point out we didn't - it's a sponsor.  Squarespace is a sponsor.  They're not sponsoring right now, this show.  And I just showed you real quickly, you go to your Settings > Security & SSL, and there's just a new setting in there.  And your choice is "Insecure" or "Secure."  You don't have to do - see, when I first read Let's Encrypt, I thought, well, how - am I going to have to run a script in my - I don't understand.  But no, no, it's simple.  Secure or insecure, boom.



STEVE:  Just turn the switch on.



LEO:  And you get HTTPS.



STEVE:  It's interesting, too, because I'm careful not to say "insecure."  I say "not secured."



LEO:  That's a better way to put it.



STEVE:  Yeah, because that's the correct way to say it.  But I understand what Squarespace - this was an investment on their part.  They want everybody to turn that on.



LEO:  They tweeted it a couple of days ago, and a lot of people said - because they said "SSL," and people said, "Oh, no, you meant TLS."  Is that a pedantic distinction?  Or is there actually...



STEVE:  Okay.



LEO:  "I hope you meant TLS, not SSL."



STEVE:  They're right.  You're right.  So we have abandoned SSL.  But the legacy term is still there.  And I think they probably used it on purpose because it's more commonly known.



LEO:  Right.



STEVE:  I would imagine that, I mean, I know that our listeners know what TLS is.  And in fact, even SSL 3.0, which was the last SSL, has been now formally deprecated in favor of at least TLS 1.0, and you should really have 1.1.  So, I mean, we have moved to TLS.  But for this purpose I could see why they would do that.  I think I would have instead said HTTPS because that's the visible thing that typical Squarespace visitors and even users would be more familiar with.  And it's the "S" of HTTPS that matters, rather than really the underlying protocol. 



LEO:  And they, I mean, it's Let's Encrypt, so we know it's the best; right?  I mean, it's not - because it's Let's Encrypt, you can't use an insecure algorithm; right?  I mean, they're using TLS.



STEVE:  Oh, I'm sure it's going to be, yes, yes.



LEO:  Yeah, yeah.  Yes.



STEVE:  And it's Let's Encrypt.  And it's, what, you know, a year old.  So it's absolutely going to be state-of-the-art.



LEO:  Yes, right.  So really all you - I think you're right, HTTPS.  Although I notice in your notes here it says SSL.



STEVE:  Yeah.



LEO:  So, you know, what are you going to do?



STEVE:  Yeah.  And I did copy what they said, which was SSL.  So, LessPass.  First of all, I was confused when people started tweeting me the news of LessPass.  And I'm thinking, okay, is that a snarky blog posting about something wrong with LastPass, which is what it sounded like?  And the very fact of that confusion is a problem because that is the definition of a trademark violation, I mean, a trademark collision.  So this is free and open source, but he'd better not try to get a trademark because he can't.  That's the problem with something that is deliberately confusing and sounds alike.  I mean, so for example, any attempt to trademark this would get violently stomped on by LastPass's intellectual property attorneys.  So I would have advised this person, if he'd cared, not to call this thing LessPass.  I mean, it is confusing.  Okay, so...



LEO:  He's not charging for it, I don't think; right?



STEVE:  No, and it's not commercial.



LEO:  Yeah.



STEVE:  So, you know, but again, it's just, you know, it's inelegant to have an obvious confusion with what is arguably one of the most popular, if not the most popular, well-known browser password managers.  Okay.  So this is something similar to what you were using a long time ago, Leo.



LEO:  Yeah.  Super Password Gen, yeah.



STEVE:  Right.  And we've even considered it for SQRL because, okay, so let me step back a bit.  What this does is it's a hash-based deterministic password generator.  So you have three fields:  the site's domain; your login name at the site, which is often your email address; and then your master password.  Those three things are just poured into a hash.  And I didn't dig into the technology much because it's not hard to do, and I'm sure this guy did it right.



So the point is that the result is dependent on every single character of the site's domain, your login name, and your master password.  And it produces then probably a 256-bit, or maybe more, blob.  The problem is then you need to format that, since you can't submit a binary blob to a website, as we know, they want passwords.  So then there's a series of checkboxes.  Do you want to have lowercase alpha, uppercase alpha, digits 123, special characters?  What length do you want?  And then he also thoughtfully added an integer increment modifier, which is a nice touch.  And I'll explain what that's for in a second.



The result of all of that, when you've set all that up, it gives you a password.  And the point is it is absolutely deterministic, that is, because it's based on - because what comes out the other end is based on all of those settings, if you later input exactly the same settings, you get exactly the same password in response because it's just based on a hash with then a bunch of output formatting to turn it from a binary blob into a password.  And the reason it came up when we were looking at SQRL is that we know that one of the challenges that SQRL or any new authentication technology faces is that it requires support from the sites you want to use it on.



You know, the argument for SQRL is that SQRL's technology is very simple to implement on the server side, and there's already lots of packages that are in process.  Many of them are working now, in fact.  But the problem was all those other settings, that's what stopped us.  And it's what would stop me from considering LessPass instead of LastPass.  And that is, you would be advised to always - you have to always set the post-processing parameters the same, or you're going to get a different password.  So you always have to say upper- and lowercase, and you want digits.



Now the question is, ooh, wait, did I, when I created the password for that site last month, did I use special characters or not?  And I don't remember what the length was.  And that's a problem because, as we well know, websites don't have standard policies for password acceptance.  People are constantly tweeting me their discoveries of some otherwise hopefully secure site that says, oh, passwords are limited to 12 characters.  So the problem is, if you set it at 20 because you're security conscious, now you encounter a site that says, no, sorry.  Some sites don't tell you why.  You know, we've talked about that, where there are instances where you just have to keep guessing until it finally accepts it.



So this is the problem with that is that I like the idea, I mean, very much, of a deterministic password.  But because there isn't a universally accepted standard for what is an acceptable password, and the fact that, what would there be, the greatest common multiple, or least - I don't know what it would be, the least common factor, something, to find the one that all sites would accept?  Actually, there probably isn't one because some sites say you must have at least one special character and one digit and one uppercase and one lowercase; whereas some other site says, eh, no, you know, can't have any special characters.  So this is a nice idea, but I just don't - I think it ends up being a lot more burdensome on the user than something like LastPass, where you can negotiate with a site to get a good password.  And if it rejects you a few times, you just keep trying until you find one that works, and then LastPass remembers it for you.  And you don't ever have to bother with this again.



Oh, and one last thing, the integer increment modifier.  That was - I sort of smiled when I saw that because SQRL has something that is the equivalent.  And that is, what if, with all of those settings not changed, for some reason you need a different password?  That is, this is deterministic, so same stuff in, same thing out.  But what if that password, you have to give it to a friend, and now you can't trust it; or the site gets compromised, and they say you must change your password.



Well, the problem is you can't change your password if it's deterministic.  But you can change the integer increment to two, and then you get a completely different password because that gets put into the hash, as well, and gives you a whole second, you know, another password.  But there again is another problem.  Now something has to be remembering for you all the settings you used for every place you visit.



So a lot of people have asked me what I think.  Now you know.  It's like, okay, that's what it is.  Maybe it's the right thing for some people, but I don't think it's the right thing for most of us.  And, boy, LessPass?  No.



LEO:  Yeah.  And LastPass does the job.  The problem, of course, LastPass has that single point of failure issue, where all of your passwords are stored in one blob on their server.



STEVE:  And maybe someday we'll be phasing out.  We'll see.



LEO:  Yeah.  Oh, I see a smile on your face.  Have you been talking to Joe again?



STEVE:  So, okay.  The confusion of, okay, now we're no longer talking about LessPass; right?  We're talking about LastPass.  LastPass announced last Wednesday, in fact Joe posted, he says:  "I'm thrilled to announce that, starting today, you can use LastPass on any device, anywhere, for free.  No matter where you need your passwords - on your desktop, laptop, tablet, or phone - you can rely on LastPass to sync them for you, for free.  Anything you save to LastPass on one device is instantly available to you on any other device you use."



Okay.  So what happened was people worried what this meant.  They said, "Wait a minute, LastPass is now free?  Well, then, what's their revenue model?"  What are they, you know, I mean, people were immediately suspicious.  So here's what happened.  LastPass has three plans:  the free plan; the premium plan, which is just a dollar a month; and then the enterprise plan, that has all kinds of extra multiuser collaboration features and stuff.  Until last Wednesday, mobile devices required the premium plan.  So that meant, so for free, you could sync all of your desktop and laptop browsers, but the mobile apps only would run with the premium plan.  What they did was they just - they changed that one caveat so that now the non-paid free plan includes mobile devices.  So, yay.  That's just a nice benefit and a step forward.



LEO:  And they'll still make money.  I mean, we pay a lot for the enterprise version.  It's well worth it.  I continue to pay for a premium version personally.



STEVE:  As do I.



LEO:  Just to support them.



STEVE:  Yup.



LEO:  I think this is doing the right thing.  It's encouraging more people to use LastPass.  And I hope that that will help their business, as well.



STEVE:  Well, and it's funny because I, in researching this, I dug back into time and found a Q&A where they asked themselves the question, why does LastPass - now, this is in the past, previously.  "Why does LastPass require a premium charge for the mobile apps?"  And they answered:  "We give away the majority of our features and service for free because we sincerely want to make password management accessible for everyone.  We've determined that mobile access and a few other advanced features create added value for our customers, and the premium service provides unlimited access to all of those added features.  While we've striven" - and I stumbled over the word "striven."  Striven?  Really?  You want to - I guess that's right.



LEO:  Or have strived.



STEVE:  "While we have striven" - that just seems, you know, although I didn't know what penultimate meant, so I'm not anyone to criticize - "to offer as much as we can for free, our Freemium business model allows us to maintain our service and further its development.  We continue to add new features to both the free and premium services and increase the value for our users."  So I just think this is a step of maturation for LastPass.  And bravo.



LEO:  Happy to see it, yeah.



STEVE:  And I'm glad that they could do it, yeah.



LEO:  Yeah.  And one thing LastPass does that this other one, LessPass, doesn't do and I find very important is application passwords.  So LessPass works great for browser web-based passwords, as does SQRL.  But I still want to have, you know, my applications have passwords, too.  And I kind of - you don't get the benefit, really, of seeing LastPass at its finest.  On Android, LastPass fills in passwords, has all sorts of nice features they can't do on iOS.  Because you use an iPhone, I know you don't see those.  But it's really - it's a great solution for everything.



STEVE:  Yeah.  I use it slavishly.



LEO:  Yeah, yeah, me, too, yeah.  So.



STEVE:  So.  Okay.  So a team of university researchers in Germany conducted the first formal security analysis of OAuth 2.0.  Okay, now, just step back for a minute.  The first formal security analysis, meaning...



LEO:  What?



STEVE:  ...it had never had a formal security analysis.  However, we just all started using it.  So that people that know what we're talking about, to be sure, OAuth is that increasingly ubiquitous "Sign-in with Facebook," "Sign-in with Twitter," "Sign-in with Google" that we're all seeing increasingly everywhere.  What it boasts is convenience because, rather than needing to create new credentials for a site where you don't already have an account, you can just sort of defer them, delegate them to a well-known site where you do have an account - Facebook, Twitter, Google and so forth.



I've never been a fan.  We've talked about it extensively in the past.  The [audio dropout] is exceedingly complex, which is always a problem for, as we know, complexity is the enemy of security.  It's always felt like an inherently error-prone kludge because your web browser bounces around among sites in order to pull this off.  And it's also annoying, or users should be aware, that it is a three-party solution, which inherently leaks privacy information to the identity provider, that is, to the Facebook or the Twitter or the Google that you're signing in through because they know by definition who you are because you're providing your Facebook, Twitter, or Google credentials to them.  And they know everywhere you log in on the web using them with this method because they are involved in bouncing your browser back to where you want to authenticate after you've given them your credentials.



So you betcha people like Facebook, Twitter, and Google are all excited to offer OAuth sign-in because it is allowing them to track you by a known account on their service everywhere else you use them to sign in.  So obviously that's not going to make me a fan.  And it's a three-party solution which is inherently a concern because it's not just between you and the site you're visiting.



Okay.  So this group tackled a seriously hairy problem because, again, a formal analysis of two plus two is not difficult.  A formal analysis of OAuth with the bizarre level of special cases and complexities, and there's four different ways to do some things - I'm not kidding, four ways - to unwind that and tackle it, when they say a "formal security analysis," they don't mean, yeah, we ordered pizza and discussed it and decided it was good.  They mean with mathematical rigor, which is incredibly difficult to reduce OAuth to.  In fact, it required a 95-page technical report which we don't have time in this entire life of the podcast to do, so we're not going to.



But I'll just - there was a 12-page summary.  And just to give you a sense for it and for what they wrote:  "The OAuth 2.0 protocol is one of the most widely deployed authorization single sign-on protocols and also serves as the foundation for the new single sign-on standard OpenID Connect."  And just to pause for a second, it's like, yes, because it's simple.  And unfortunately this is a classic case of ease of use and simplicity completely trumping security and privacy.  But, you know, this is still the Wild West.



Anyway, continuing, they said:  "Despite the popularity of OAuth, so far analysis efforts were mostly targeted at finding bugs in specific implementations" - and, oh, boy, our next piece here is the mother lode of that - "and were based on formal models which abstract from many web features or did not provide a formal treatment at all."  That is, there never was any formal foundation laid.  It was just like, this information bounces here, and then it gets sent over there, and so forth.



"In this paper," they write, "we carry out the first extensive formal analysis of the OAuth 2.0 standard in an expressive web model.  Our analysis aims at establishing strong authorization, authentication, and session integrity guarantees, for which we provide formal definitions."  Again, you need that if you're going to - you need formal conclusions and then demonstrate that this protocol brings them, yields them, results in those.



"Our modeling and analysis," they write, "of the OAuth 2.0 standard assumes that security recommendations and best practices are followed in order to avoid obvious and known attacks."  So that is to say, they're assuming that the implementation didn't make any mistakes, and that the best practices that are understood for OAuth were followed.  "When proving the security of OAuth in our model, we discovered four attacks which break the security of OAuth.  The vulnerabilities can be exploited in practice and are present also in OpenID Connect.



"We propose fixes for the identified vulnerabilities and then, for the first time, actually prove the security of OAuth in an expressive web model."



LEO:  Wow.



STEVE:  Yes.  "In particular, we show that the fixed version of OAuth, with security recommendations and best practices in place" - that is, assuming no other mistakes were made - "provides the authorization, authentication, and session integrity properties we specify.  The problems were reported to the OAuth and OpenID Connect working groups who confirmed the attacks."  So again, just a beautiful piece of very difficult work because the OAuth spec just is a mess and a kludge.



LEO:  Where did it come from?  Was there an OAuth working group?  Or did it come out of Google?



STEVE:  Boy, you know, we covered it years ago.  I think it began...



LEO:  Isn't there an OAuth 2.0, like isn't there a...



STEVE:  Well, OAuth 2.0 is where we are now.



LEO:  Oh, we're looking at OAuth 2.0, then.



STEVE:  Yeah, yeah.



LEO:  Oh, okay.



STEVE:  Yeah, this is 2.0.  So this is the second iteration.  And the idea was clever, that is, I mean, you know, essentially it's I want to authenticate to a site that doesn't know me.  But I want to use a site that does know me.  Well, okay.  And so a group of people said let's do that.  And so they came up with a way of essentially using browser redirection to send you to a site that knows you, where you authenticate, and then that site contacts the server of where you want to be known and sends your credentials there, and then bounces your browser back to there.



So the user's experience is textbook perfect.  You know, log in with Facebook.  Everybody who's on Facebook, it's like, oh, yeah, why not?  Well, you know.  And Facebook, again, they're seeing everywhere you log in through them as a consequence of this.  But again, no username and password needed.  Login with something you already have.  So it's a huge appeal.  But it's not without its problems.



LEO:  Well, should we stop - should I stop using it?  I mean, I use it all the time.



STEVE:  No.  I wouldn't say so.  I would say - the only thing I would say is that somebody who is a high-risk target could be attacked by using that.  And everyone should understand that who you're logging in with is definitely logging what you're doing.  They're accumulating that data for their own purposes.  There's no question about it, that that is part of their vacuuming, which unfortunately we know all these big companies do now.  So again, if that doesn't put you off, fine.  And if you're not a high-value target, fine.  But I think it's worth understanding that you're making a tradeoff for that convenience.  There is some privacy tradeoff.  And that is all, after these four problems have been fixed, and there's no implementation error.



But a trio of Chinese researchers from the Chinese University of Hong Kong, which actually is right next door to the Post Office, they have examined 600 Android apps.  Now, they're picking on Android only because Android apps are easy to examine.  But they are sure the same problem exists in iOS.  What happened is that OAuth was designed for browsers.  And it makes some assumptions about the way the browser works with this bouncing around.  But again, because it is an appealing hook, you know, it's an appealing offer, apps are now allowing you to sign into them with OAuth, you know, sign into this app with your Facebook account.



Well, it turns out that apps did not implement the OAuth protocol correctly.  They examined 600 of the most popular U.S. and Chinese Android apps.  In 41 percent of the 182 apps which supported OAuth single sign-on, they found significant problems with the implementation.  So here the problem was not the spec.  That was also broken, which we just talked about, that the German researchers have now found and fixed, or at least specified the fix for, and it'll get deployed.  This is implementation mistakes which apps have made.



The problem is that many iOS and Android apps offering OAuth have failed to rigorously follow the standard.  When testing real-world implementations, the researchers found that the developers of a huge number of these Android apps were not properly checking the validity of the information sent from the ID provider, which, for example, in this case would be Facebook or Google.  And there's a major provider, SINA, S-I-N-A, that is a Chinese company.



The vulnerabilities resided in the way many app developers implemented OAuth.  When a user logs in via OAuth, the app should check the ID provider, like Facebook, Google, or this Chinese firm SINA, that they have the correct authentication for those sites.  If so, OAuth provides an access token from the ID provider's server, which is used with the server of the mobile app, that is, the site that the mobile app is a frontend to.  So this allows the apps server to gather the user's authentication information and then let them begin logging in with their Facebook and Google credentials.



But the researchers found that, for many Android apps, again, 41 percent of those that offer OAuth sign-in - and again, we believe iOS has probably the same problems because no one is enforcing or testing or checking except here's the first instance of it.  The app developers did not bother to verify the validity of the information returned by the ID provider.  They failed to verify the signature attached to the authentication information retrieved from Facebook and Google.  That is, part of the OAuth spec says "sign this so it cannot be changed."  So, yes, Google and Facebook and SINA are signing their provider packet that goes back to the app.  The apps don't check the signature.  So what that means is they won't notice if that gets changed.



And then, in a different case, the app server would only look at the return's userID and login the individual without checking the attached OAuth information to see if they were linked.  So what this essentially amounts to is the appearance of logging in with none of the actual safeguards implemented, which the protocol specifies and requires.  It works.  But it doesn't work in any way securely.  So the upshot of this is it's possible for a remote hacker to download the vulnerable app, login with their own information, that is, log into Facebook or Google with their own information, but change the username that comes back to them to that of the target individual, and then submit that to the app.  They will be logged in as that user on the app.



So it's a complete subversion of OAuth; 41% of Android apps that were looked at out of the 180-some that do support OAuth, out of a set of 600 that these guys looked at, had this problem.  That is, the appearance of it all working, but none of the safeguards that the OAuth spec explicitly requires to prevent exactly this problem.



LEO:  Geez.



STEVE:  Yeah.  So in their paper they suggest that part of the problems are that the developer document is not very clear.  OAuth was originally designed for websites, not for apps.  And there are some implementation errors by some identity providers, that is, the likes of Google or Facebook, probably not those guys, but some of them have their own problems.  And so as a consequence, to get stuff to work, the apps may have backed off on some of the rigor for the sake of compatibility, when in fact in doing so they completely sacrificed security.  Wow.



I got a couple notes from people, from our listeners in the U.K.  And I just thought this was sort of interesting.  I got a kick out of the timeline.  A major automobile insurer named Admiral announced that they planned to use data from public postings on Facebook to decide how to rate customers.  They called it "firstcarquote," and on their page it says, "How do I get a quote?"  And then they say, "The firstcarquote online app is really easy to use.  Enter car registration.  Agree to our terms and conditions.  Connect with Facebook.  Answer 10 simple questions.  Get a quote.  Call us to buy your coverage."



So following this announcement, the Guardian on the 1st, so one week ago on Tuesday, had a story announcing this, said:  "Admiral to price car insurance based on Facebook posts."  The reason I'm sharing this is that some of the details are just too fun.  And then their sub-headline was "Insurer's algorithm analyzes social media usage to identify safe drivers in  unprecedented use of customer data."



And they wrote:  "One of the biggest insurance companies in Britain is to use social media to analyze the personalities" - I mean, the language is just so creepy - "to analyze the personalities of car owners and set the price of their insurance.  The unprecedented move highlights the start of a new era for how companies use online personal data and will start" - I hope - "a debate about privacy," they write.  "Admiral Insurance will analyze the Facebook accounts of first-time car owners to look for personality traits that are linked to safe driving."  Okay.  Get out your AI.



Anyway, "For example," they write, "individuals who are identified as conscientious and well-organized will score well.  The insurer will examine posts and likes by the Facebook user, although not photos, looking for habits that research shows are linked to these traits.  These include writing in short concrete sentences" - I think I would fail that one - "using lists, and arranging to meet friends at a set time and place, rather than just 'tonight.'"



LEO:  4:37 p.m. on Thursday the 19th.



STEVE:  Yes, rather than just "tonight."  Oh, lord.  In contrast, evidence that the Facebook user might be overconfident, such as the use of exclamation marks and the frequent use of 'always' or 'never' rather than 'maybe,' will count against them.



LEO:  Wow.



STEVE:  Wow is right.



LEO:  You know, though, I don't have a problem with that if you opt in, and there's people who don't do it.  Maybe you get a much better deal; right?  Maybe it's so effective.



STEVE:  Well, and that was the hook, yes.  But it took 24 hours, and then The Verge reported.  Their headline a day later, on November 2nd:  "Facebook blocks insurer exploiting user data to find 'conscientious' drivers."



LEO:  Oh, well.



STEVE:  With the subhead:  "Admiral Insurance wanted to analyze Facebook users' posts to see if they would make good drivers."  And then The Verge wrote:  "Facebook has blocked one of the UK's biggest insurers from using the social media network's user data to set insurance rates.  A recently launched scheme" - I got a kick out of the word "scheme."  It seems kind of skeezy.  The scheme "from Admiral Insurance targeted first-time car owners, offering to analyze their Facebook posts to see if their personality traits matched those of successful drivers.  Participants were told they could save as much as 350" - which is currently $429 - "a year on their car insurance if they were judged to be conscientious" as well as organized.



"The scheme, named firstcarquote," wrote The Verge, "was set to launch this week; but, as first noted by U.K. privacy advocates Open Rights Group, the app has been blocked by Facebook from accessing user data.  The initiative from Admiral Insurance would contravene Facebook's Platform Policy, which states that developers cannot 'use data obtained from Facebook to make decisions about eligibility, including whether to approve or reject an application, or how much interest to charge on a loan."



LEO:  Isn't that interesting.  Huh.



STEVE:  Yeah.  So Facebook was ahead, yes, Facebook was ahead of the game on this one and nipped them in the bud.  So, wow.  But, you know, just the...



LEO:  You know, I get reduced insurance because I don't smoke.  But they don't check my Facebook postings to find out if I smoke.  They simply ask me.  Yeah, I have mixed feelings about it.  But you're right, I mean, the fear would be that people would be denied insurance because there's a picture of them eating a doughnut, which I might have just done.



STEVE:  Well, it's going to be - we are navigating some new waters because, as we all know, there is, you know, for us old-timers, this seems a little George Orwellian.  But apparently the studies have shown that the Gen-Xers, or are we on Z now, maybe, Y or Z, that, yeah, it's like they just don't care.  Like, okay.



LEO:  Wow.



STEVE:  So I forgot to mention at the top of the show - our listeners are going to love this - we are about to, in two stories, to have a user-side action.  It turns out we can all determine within some limits whether our ISPs are blocking outbound spoofed packets from our own network.  But first, GCHQ in the U.K. has announced that they want Internet providers to rewrite systems to block hackers.  Now, I consider this premature, but encouraging.  So of course this is following on the massive outage a couple of weeks ago at Dyn, launched by the Mirai botnet and just the general problem of DDoS attacks.  And in fact, Leo, if you want to put up on the screen, there's a graphic here at the bottom of the story, shows the daunting number of attacks that are currently occurring.



So the GCHQ "is urging Internet providers to change longstanding protocols to stop computers from being used to set off large-scale cyberattacks.  The government's cyber-defense arm said it plans to work with networks such as BT (British Telecom) and Virgin Media to rewrite Internet standards to restrict spoofing, a technique that allows hackers to impersonate other computers and manipulate them to carry out anonymous attacks.



"Ian Levy, technical director of GCHQ's National Cyber Security Centre, told the Sunday Telegraph:  'We think we can get to a point where we can say a U.K. machine can't participate in a DDoS attack.  We think that we can fix the underpinning infrastructure of the Internet through implementation changes with ISPs and [what they call] CSPs, Communications Service Providers.'



"The plan would involve changes to the Border Gateway Protocol (BGP) and Signaling System 7 (SS7)" - that we've been talking about recently because it doesn't provide authentication natively and thus is prone to attack, as we know - "standards that have been in place for decades and are widely used for routing traffic.  GCHQ wants providers to stop the trivial re-routing of U.K. traffic and help prevent text message scams.  The Internet Service Providers Association (ISPA), the body that represents ISPs, expressed skepticism, saying GCHQ was applying a 'we can fix it, it's easy' approach to a complex, historic system."



And of course we know, because we've been discussing this a lot, that spoofed attacks are only one class of DDoS.  And back in the day when an individual probably had valuable bots and not an infinite supply of them, spoofing was a way to keep them hidden.  And it was difficult to protect against.  But in this day and age, where every light bulb is able to attack, and there's apparently tens of millions in the Mirai botnet, who cares if it's a known IP?



And so what they're talking about, of course, is egress filtering.  Sometimes it's referred to as ingress, if you're ingressing to the public Internet, but you're egressing from a private network.  And we've often said this is just not a problem.  Well, our next story looks at that.  But, for example, here, in just one week, October 1st through the 7th, so last month, first week of last month of October, the number one attacked country was the U.S., where 256,212 DDoS attacks occurred.  Second, and not many fewer, was Russia, 211, almost 212,000 in Russia.  Then France at 118.6 thousand, India at 34.8 thousand, and Germany at 30.7 thousand.



So, you know, DDoS attacks are happening.  And in some of the commentary that I didn't putting here in the show notes, people have criticized, exactly as we have, noting that, okay, so U.K. ISPs won't be able to host spoofing bots, but everybody else will because, as we know, the only way to kill all spoofing is for all providers to prevent spoofed packets from leaving their own control.  That is, it's at that point where the packet is leaving an ISP that it can be inspected to see if it has a legitimate return address.  And it's worth noting, too, that you could spoof within the ISP, and then it might not detect it.



So if you had an ISP, for example, Level 3 - I was going to say Level 4, but it's a 4-dot.  Level 3 has the 4-dot space, 4-dot everything.  Well, so if they were only checking the packets as they finally went out on the Internet to make sure they began with 4-dot, you could still have 24 bits, the remaining 24 bits of the 32-bit IP randomized, and it would pass right out through the egress filter.  And that's one of, what, 16 million addresses available.  So you still get to hide, even if egress filtering is in place.  So I think this is hopeful because the size and the severity and the concern over these attacks is raising the level of interest, and people are beginning to talk about getting this thing fixed, which is good.



I then came across a story, and I'd forgotten about these people, Leo.  We talked about them years ago, maybe a decade ago, CAIDA.  I first encountered them back in the early days of DDoS attacks when DDoS was still novel, because what these guys had done, what they'd done is very clever.  They had arranged to borrow huge chunks of the then-unallocated IPv4 space.  And as we know, 10 years ago half of the IPv4 space - doesn't seem that long ago, but the growth has been rapid.  Half of the IPv4 space was still unallocated.  It was, you know, universities had huge unused chunks.  And famously - boy, I'm blanking on a name, our favorite ad hoc network, I want to say - oh, Jungle Disk.  They were using 5-dot for their network because nobody had ever used any 5-dot.  And so that's the way they avoided colliding with anybody else in the...



LEO:  Hamachi.  Hamachi.



STEVE:  Oh, you're right, Hamachi.  Thank you, yes, not Jungle Disk.  Jungle Disk is network backup.



LEO:  Right.



STEVE:  Hamachi.



LEO:  Hamachi.



STEVE:  Thank you.  Hamachi.  And so...



LEO:  It was a really clever kind of a hack, actually.



STEVE:  It was great, yes.  And so what this Center for Applied Internet Data Analysis, CAIDA.org, what they did was they arranged to have these unallocated chunks routed to them.  And the idea was that spoofing software at the time was just using a pseudorandom number generator for its source IP.  So a percentage, and a relatively high percentage because a lot of unallocated space was available, a percentage of the attacking packets would have the unallocated space as its source IP, meaning that when, if a SYN packet was sent to a server to spoof a TCP connection, the SYN/ACK response would go into that unallocated space, which this Center for Applied Internet Data Analysis had borrowed.  And since it had never been used in the history of the Internet, there was no valid reason for any packets ever to enter.  So that meant that those that did were an indication of DDoS attacks.



So this was a decade ago, the first, as far as I know, or at least the most comprehensive DDoS monitoring system.  And so they began to provide statistics for where attacks, like they also knew what the attacks were against because when an attack bounced off of a valid server, the source IP of the incoming packet to the unallocated space would be the legitimate IP of the victim being attacked.  So neat work that they were doing.



Well, they've moved on.  And in fact they wrote:  "Seeking to minimize Internet susceptibility to spoofed DDoS attacks" - and Leo, if you want to go there, it's CAIDA.org.  Under the top-level menu is Projects, and then look for Spoofer underneath the Projects at the top level of that site.  Then they write:  Seeking to minimize Internet susceptibility to spoof DDoS attacks, we are developing and supporting open source software tools to assess and report on the deployment of [what they call] Source Address Validation (SAV) best anti-spoofing practices.  This project includes applied research, software development, new data analytics, systems integration, operations and maintenance, and an interactive analysis and reporting service.



"We have developed and support a new client-server system for" - and this is why I want our listeners' ears to perk up - "Windows, Mac OS, and Unix-like systems that periodically tests a network's ability to both send and receive packets with forged source IP addresses" - in other words, spoofed packets.  "We are in the process of producing reports and visualizations that will inform operators, response teams, and policy analysts.  The system measures different types of forged addresses, including private and neighboring addresses."  Oh, and in fact neighboring spoofing is what I was just referring to.  "The test results will allow us to analyze characteristics of networks deploying source address validation," in other words, network location, business type and so forth.



So they have downloadable, free, open source executables for Windows, Mac OS, Ubuntu; and the source is also available.  I ran it on my Win7 machine this morning, and it is very cool.  I mean, this is too much fun.  Our listeners are going to go crazy for this.



LEO:  I'm installing it now.  It's safe; right?



STEVE:  Oh, absolutely.



LEO:  Okay.



STEVE:  Yeah, yeah, yeah.  It maybe took about 10 or 15 minutes to run.  There is a button at the bottom that opens the log.  You definitely want to do that, just because then you can see what it's doing.  When it was all finished, it reported that over IPv4 it had identified my carrier of my cable modem, which is Cox, as ASN 22773.  And then it said below, "Spoofed private addresses:  blocked.  Spoofed routable addresses:  blocked."  But then it also gave me this really cool link, which was to their site, with a big long serial number after it - and there it is running on your system, Leo - a big serial number after it.  You click that.



Actually, I don't think it was clickable, so I copied and pasted it into the URL.  What I got was this wonderful graphic map built from my test which showed red where spoofed packets were transiting.  And in my case it showed the host machine and my router, and it said the comment:  "Your host is behind a NAT router or firewall which rewrites the source addresses of the test traffic.  To test your provider's network further, you must remove the NAT router firewall and connect directly."  Well, needless to say, I'm not doing that.



And this comes right back to the question, I mean, sort of the puzzle I was asking us rhetorically last week, which was how can spoofed packets even egress through a NAT router?  Why would a NAT router inherently, that is going to be doing packet rewriting, why wouldn't it drop them?  Well, pfSense, we now know, does, the one I'm using.  I can't wait to hear from our listeners whether the Ubiquiti EdgeRouter X does also, in which case you're not able, your network cannot send spoofed packets out.  They are dropped at your own border.



LEO:  Now, if I have an Astaro gateway, which we do - we run the Sophos, you know, they bought the Astaro company - does that impact this?  I mean, is my own security part of this?  Or no?



STEVE:  No, no.



LEO:  So it's really just testing the external network.



STEVE:  Well, yes.  This is a public service that all of our listeners can perform because what we're doing is we're giving this group the data on our providers, is what it amounts to.  And unfortunately, because my router is dropping, is blocking any spoofing at its border, I'm not able to provide information to them about Cox.



LEO:  So I might not be as useful, either.



STEVE:  Yes.



LEO:  We're on Sonic.net here, so I'm sure...



STEVE:  And I'm super interested because we've been talking, you know, like Linksys routers, Cisco routers, Netgear routers, Ubiquiti EdgeRouters.  I can't wait to learn, and this software will show you, whether your router will pass spoofed packets out.  And the diagram is this beautiful network diagram.  Wait till it gets done and it gives you a link, Leo, because it'll show - you get this network diagram of where everything went, all sorted and organized.  But the upshot of this - so first thing is I would love our listeners who are inclined to do this.  And, I mean, I would love to know if Cox is blocking this.  And I can set up a secure machine.  I'm afraid, obviously, to not have a NAT router between me and the Internet because I depend upon it for firewall services to such an extent.



LEO:  Ooh, yeah, yeah, yeah.



STEVE:  But if there are NAT routers that do not rewrite spoofed packets, I would love to know.  But the upshot is they are now beginning to collect data.  I hope our listeners will do this because this will help to dramatically expand the knowledge of what providers are blocking.  But now look at the chart.  I put three charts in the show notes.  It's also available in those pages.  They've got both lists and graphical presentations of what they have found so far.



In the announced, the so-called announced IP space - oh, and I forgot to mention that my system is still IPv4 only, so the test does run under IPv6.  But it just noted that I don't have IPv6 operating in my network, so it didn't do testing there.  But, okay, 75.3% is unspoofable.  So sort of quietly, without bringing any attention, ISPs have in fact been taking action.  And I read some quotes saying, yeah, we don't like DDoS attacks.  We don't want spoofing, either.



LEO:  No.



STEVE:  So this has been going on.  So they got inconsistent results from 6.9, so call it 7%, and a confirmed spoofability in the balance of 18%.  But still, three quarters of the IP space will not allow spoofed packets out.  So what this essentially means is this is already probably to the point where bots won't spoof because spoofing bots will be less effective.  Their bullets will hit a wall and not reach the target.  



LEO:  But as we talked about, nowadays with IoT, spoofing isn't as necessary as it used to be.



STEVE:  Right.  But it's also nice, you know, spoofing is a violation of the Internet protocol.  So it'd be nice if we just nipped that in the bud, even though it's not going to give us any affirmative protection against non-spoof attacks, which are all today still very practical.  Anyway, I love the idea that there's something our users can do.  Did your test finish?



LEO:  Still running it.  Not quite done yet.



STEVE:  Okay.



LEO:  It went through all the way to the end of the progress bar and now is doing something else.  So I guess Test 5 now.



STEVE:  Oh, it just does all kinds of cool stuff.



LEO:  How many tests are there?



STEVE:  I think it was seven, if I remember right.  And it ends up with a whole bunch of traceroutes out to various points.  So what it's doing is it's looking at your endpoint to something like 13 other servers that they operate, scattered all over the globe.  So it's not just to them.



LEO:  Hmm, interesting.



STEVE:  It is, you know, to all over the place.  And so they build a really comprehensive chart, and you'll end up seeing this nice spider diagram of your network as soon as it's finished.



LEO:  Neat, neat.  I'll show it to you as soon as it comes up.



STEVE:  Cool.  In the meantime, clearly Microsoft is understanding that they've gotten the feedback that Windows 10 updates and this often problematical insistence on restarting is causing their users problems.  We of course discussed last week the group policy editing that can be done to prevent Windows from ever downloading updates.  It will notify you, but it will not update.  It will not download them.  The problem is that that's the only choice you have.  If you let Windows update them, it ultimately will insist and override any attempts not to.



In Microsoft's own posting, they wrote:  "You can use Group Policy settings or mobile device management" - that is for Windows Mobile 10 - "to configure when devices will restart after a Windows 10 update is installed.  You can schedule update installation and set policies for restart, configure active hours for when restarts will not occur, or you can do both.  After an update is installed, Windows 10 attempts automatic restart outside of active hours. If the restart does not succeed after seven days" - then they say in parens (by default) - "the user will see a notification that restart is required.  You can use the 'specify deadline before auto-restart' for update installation policy to change the delay from seven days to a number of days between two and 14."  So again, you can't push it any further than two weeks. But really that's hopefully plenty of time.



Anyway, I put the link in the show notes.  And that's just a tiny snippet from an extensive posting.  That TechNet article at Microsoft.com that I link to in the show notes goes through the whole enchilada, so all of the group policy settings which are available to help people configure Windows 10 updates the way they want them.  So I just wanted to share that with everybody.



LEO:  I have the graph.  And just like you, I'm blocked by my NAT.



STEVE:  Ah, right, exactly.  That's exactly right.



LEO:  Preventing rewriting of packets.



STEVE:  Cool chart, though.  Isn't that neat?



LEO:  Yeah, that's neat.  Are these all nodes, these numbers here?



STEVE:  Those are all router hops.  And so that's the result of the traceroute that was done.  So all the endpoints are where it was checking, and it watched the packets hop out and then track where they went.  And so, for example, if it turns out that consumer routers - and we'll know a week from now.  I'll tell everybody because I'm sure our listeners will try this and send me the results.  What you would expect to see is those red arrows propagating further out.



LEO:  Right.



STEVE:  And where they get snubbed would be a point where packets are being checked for validity.



LEO:  Right.  So I cannot - I'm blocked.  I cannot do it.  I'll go home, though, and do this on my ASUS router and on my Eero router.



STEVE:  Ooh, yeah, yeah, yeah, good.



LEO:  Yeah, and let you know.



STEVE:  Nice.  Microsoft also announced that they are winding down, they are end-of-lifing their Enhanced Mitigation Experience Toolkit, EMET, E-M-E-T.  And I won't go through this in detail.  I'll just say that their posting sort of talks about how good it's been for so long; that their rationale for it was that major Windows releases to address problems that required architectural changes were, as we know, spaced many years apart.  That wasn't often enough to allow them to evolve Windows in ways that just security patches were insufficient to fix.  So they regarded EMET as their stopgap, that is, as an OS adjunct which could evolve much more quickly and live with initially XP and then 7 and then Windows 8 and even 10.



But due to the new architecture of Windows 10, where it is no longer a static OS over the long term, but it's Windows as a service, now Windows 10 itself will be able to evolve.  And they explain that there was a fundamental problem, a limitation that EMET wasn't part of the OS.  So there were things they wanted to do with it that it couldn't do because it wasn't the OS.  It was better than nothing.  But what they now have is better than the earlier OSes with EMET.  So EMET is winding down - they've, like, formally announced end of life - to be replaced by the evolving Windows 10, which as we know will change as needed moving forward.



Okay.  And this is too simple.  I'm surprised this flaw existed in Gmail.  The good news is it's been found, and I'm sure Google will be on it, if they haven't already.  A student in Pakistan, the CEO of a company called Security Fuse, Ahmed Mehtab, discovered a flaw in Gmail's authentication and verification methods when a confirmation email bounces.  If a user has more than one email address, Google lets the user link all of the addresses and also lets emails of the primary account be forwarded to secondary accounts.



Mehtab identified an inherent flaw in the verification bypass method adopted by Google for switching and linking email addresses, which lead to the hijacking of email IDs.  He discovered that the email addresses became vulnerable to hijacking when one, any one of the following conditions occurs:  when the SMTP of the recipient is offline, so the mail bounces; or the email has been deactivated by the recipient so it can't be sent; the recipient doesn't exist at all; or it's an invalid email ID so, again, a send fails; or the recipient does exist, but has blocked the sender, another reason for bounce.



So the attacker tries to verify the ownership status of an email address by emailing Google.  Google sends an email to that address for verification.  The email address cannot receive the email; and, hence, Google's mail is sent back to the actual sender with the verification code in it.  This verification code is then used by the hacker, and the ownership to that particular address will be confirmed.  So a startling flaw in essentially an edge case of multiple email addresses, one of which cannot receive the confirmation email.  And so, due to the fact that the confirmation email contained the verification data, it can be made to bounce back to the attacker, who then gets the verification data and is able then to verify their ownership of an email account they don't own.  



LEO:  So don't block any senders.



STEVE:  Clever and deadly, yeah.



LEO:  Yeah.



STEVE:  I did want to mention, just as a public service announcement - this is now a couple months old.  But the very widely used MySQL, you know, MySQL server, had some serious problems discovered back in August.  And they were responsibly disclosed by a researcher with Legal Hackers.  There are two known exploits.  He waited more than 40 days.  So both the official Oracle MySQL and its MariaDB and PerconaDB all have these problems.  So they existed, not only in MySQL, but in both of those forks.  So both of them, MariaDB and Percona, both updated their servers and issued patches.  After 40 days, Oracle had not.



So he decided to go public with the details of the zero days.  Last Tuesday he released proof-of-concept exploits for two of these vulnerabilities.  So Oracle has since patched MySQL.  Both the forks, Maria and PerconaDB, have been updated.  So attacks are in the wild.  I just wanted to make sure that any of our listeners who have MySQL on servers that may need to be updated know about this.  So, and I did get the notification on my FreeBSD box because I'm a MariaDB user, and patches are available, and it was easy to do.



And, finally, I loved Paul Thurrott's tweet a couple days ago.  He tweeted:  "Here we go again:  Microsoft's popping up ads from the Windows 10 toolbar."  So we get to be the customer AND the product.



LEO:  Oh, well.



STEVE:  Okay.



LEO:  Oh, well.



STEVE:  And a bit of errata.  Last week I went on at great length addressing the question of replacing domain names with IP addresses and explained that, well - and this, of course, was brought on through a Q&A where a listener was asking, hey, if DNS goes down, could I just bookmark the IPs of the sites and get there?  And I explained the various problems that that would cause, completely forgetting that everything I was saying applied only to non-HTTPS connections, which we now know are becoming increasingly rare.  That is, this of course absolutely breaks HTTPS.



LEO:  You can't enter a website by number if it's secure?



STEVE:  No, because the certificate has the domain name.



LEO:  Oh, it's the name.



STEVE:  Yes.  So you get a "no name match."  Right off the bat, I mean, it's like, sorry.  You can't get here.  And I also noted that multihomed sites are increasingly used because the communication from the browser contains the host name in the TCP, the first TCP packet, or rather the first TLS packet, the SNI extension, the Server Name Identification, and that allows the receiving server to enumerate or disambiguate among many sites that it may be hosting at a single IP.  And of course that breaks.  If you put an IP address into the browser bar, you're not giving it the hostname information that it needs to determine which site in a multihosted IP you want access to.  So I absolutely wanted to correct that, that it's like, yes, no longer can IPs be used, unfortunately.  They just break too much.



And lastly, I got an interesting question from Norm in Thailand regarding SpinRite drive orientation.  He said:  "Hi, Steve.  I've been searching for an updated answer for this, but I would like to get confirmation on drive orientation when using SpinRite.  I'm sure this was covered before, but I cannot find it."  He says, "I've been using SpinRite for a long time.  Normally I have all drives mounted flat board down.  My newer NAS has some problems with one drive, and I'm planning to run SpinRite on all of the drives.  I have a new mini computer now for running SpinRite which is under test now and seems to be doing fine.  The new NAS has the drives installed vertically on their side.



"So the question is, should newer hard disk drives be done in maintenance mode with the drive in the orientation that it will be installed in?  I think on your new computer they are mounted vertical, if I recall."  Good memory.  That's amazing how he knows that.  I guess from a photo that he must have seen, striven to see.  "Did you run SpinRite in that same orientation?  Just for information, does the drive run upside down make a difference on newer drives?"



Really great question.  And remember back - I was talking about this a couple weeks ago, Leo, where the genesis of SpinRite was that a gal that I was dating 30 years ago had her company's accounting information irretrievable on an old-school linear actuator hard drive.  It was a big Seagate something or other.  And I managed to recover it by lifting one end of the drive, that is, in the axis that the linear actuator moved, thus adding a gravitational acceleration to the heads.  And that allowed - that worked against the servo information that caused the heads to then be able to find the tracks.  And by successively low-level reformatting the drive nondestructively while inching the drive back down to horizontal, I was able to get the drive to then read flat, which it had stopped being able to do.



Modern drives do not use linear actuators.  They are, as far as I know, all rotary actuators.  So there's a pivot on the side.  The heads have sort of a cantilevered right-angle head mounting.  So it actually rotates as the heads move in and out.  As you would expect, this is extremely well counterbalanced.  That is, the heads moving will create a little bit of rotational torque.  There's no way not to have that.  But there is no linear vector torque created as there once was.  In fact, I remember way back when a previous company, Minicomputer Technology, where I cut my teeth on hard drives, you could do random seek testing.  And these things were like washing machines, and the whole thing shook.  It was like a badly off-center load in the spin cycle of your washing machine.  I mean, it was just...



LEO:  It was terrible.



STEVE:  It was crazy.  Oh, my lord.  So drives don't do that now because they are carefully rotationally balanced.  And what that means is they are orientation-independent.  That said, I do - I mean, clearly Norm in Thailand is a perfectionist, which I appreciate.  And yes, my drives are vertical.  Vertical is fine because the drives, again, are carefully balanced.  They have to be in order to be able to seek as well as they do without just vibrating themselves to pieces.  So, but again, perfectionists, yes.  I would run SpinRite on a drive with the same orientation it will have when it's in use.  So great question, Norm.



LEO:  This is going to go away pretty soon, thought; right?  We're just all going to be using SSD drives any minute now.



STEVE:  You know, we've been predicting that for a while.  But the problem is the drive technology is so mature and getting more so.  We're now heading to shingled drives, which is the next iteration.  We're going to see another ridiculous capacity jump.



LEO:  Ugh. 



STEVE:  Yeah.



LEO:  Yeah.  I mean, what is it?  What's the biggest now, 8, 10 terabytes?  They're big.  Big.



STEVE:  Oh, they're, I mean, yeah.  And I think people get them just because they can.



LEO:  Capacity.



STEVE:  It's like, oh.



LEO:  Yeah.



STEVE:  Although I will tell you I made a mistake of I thought - and I'm sure I told you that, with one of my iPads, I thought, okay, I am not going to load this up with memory.  Jobs is not going to cheat me.



LEO:  Not going to get me.



STEVE:  So one of my pads is only 16 billion bytes.



LEO:  Oh.  Yeah?



STEVE:  I can't survive.



LEO:  No.



STEVE:  It's constantly complaining that it's out of space.



LEO:  You need data, yeah.



STEVE:  I've got to delete things.  So I will never - I love my  iPads.  I am always getting the most memory I can because that's what happens to work.



LEO:  And I haven't bought a computer with anything but SSDs in a long time.  I just can't even imagine buying a spinning disk.  I admit, you know, you want capacity.  But I have Drobos and other external stuff for capacity.



STEVE:  Well, and backup.  See, what SSD does have is spontaneous catastrophic failure.  That is the way they die.  And hard drives tend not to.  Because their technology is just kind of old and obvious, they just die in small increments, which we can typically see and fix.  But I run across all these stories of SSDs just dying, bang.



LEO:  Yeah, yeah.



STEVE:  So you really do need them backed up.



LEO:  Yup.



STEVE:  Okay.  So following up on last week's Windows AtomBomb, with the details, there's a company, enSilo, who has a team leader, Tal Lieberman, who did a beautiful bit of creative engineering.  AtomBombing, as he called it, is performed only by using long-established features of every Windows operating system.  There's no need to exploit an operating system bug or any vulnerabilities in an application.  So there's nothing to patch.  Microsoft cannot, at this point, significantly change or remove these features because all the apps, I mean, like in the ecosystem of Windows, depend upon them.



However, it is the case - I'll put in a caveat - that antimalware, including Microsoft's native AV, will likely quickly adopt some augmented heuristics in an effort to detect the use of the technique that Tal has developed.  So, okay.  So he called it AtomBombing because this uses something known as the Windows Global Atom Table.  And it's one of these features that Microsoft put in in 1.0.  It's always been there.  And it's not really clear what Microsoft was thinking.  You can have local atom tables, or there is a global atom table.  And all that means is it is essentially - you can think of it as a user-definable dictionary.  That is, you can give Windows a blob, a string, typically, to hold.  And it gives you back a token by which - and that's called an "atom."  And then you refer to that in the future with this token.



So there's one call, an API call, where you say, here's a null-terminated string buffer.  Insert this in the global atom table and give me back the token.  And so Windows gives you a little 32-bit widget, just it's like a cookie.  And then, in the future, you can have Windows look up for you that original string with the cookie.  So it's just sort of like a dictionary.  Applications can use it locally for their own private dictionary; or, as I said, there is a universally, globally defined atom table that Microsoft must have thought was useful for something.  I'm not sure why or how it's used.



But if there were a system that had multiple processes, then this would be a means of doing interprocess communications, allowing one process to establish atoms that were accessible by another.  But as we know, from a security standpoint, this is breaking process isolation boundaries by definition.  That is, it's inherently a concern.  I would argue it's inherently insecure, not by itself, but when leveraged with other exploits.



So what Tal did was, as he describes it in his own write-up, he just sort of sat down and went through the API, looking for problems.  And he ran across global atoms, and he thought, huh.  That's interesting.  Because, okay, what normally happens with a buffer overrun, we know that a buffer overrun exists when an application accepts attacker-controlled data, and it somehow overruns the buffer.  Sometimes they can be made self-executing.  But in this world of data execution protection or prevention, many times the data's area, where the data buffer would be, is non-executable.  So some tweaking has to happen.  That segment of data needs to be made executable.



And so for that the attackers use so-called return-oriented programming, which we've been talking about in the context recently of address space layout randomization that makes ROP more difficult - but, as we know, unfortunately not as impossible as the designers would like.  So the idea is that, with return-oriented programming, you are jumping to known executable code to get little bits of work done, just by jumping to the end of a subroutine that already exists in some code that is executable, like in the kernel, for example.  And then it returns to you after finishing the subroutine.  But you just use the last few instructions to get some work done on your behalf.  And by stringing a few of those together, you can create a result.  It's difficult to build a whole malware exploit out of little snippets.  But the idea is you can get it to do things like flip the non-execute bit for you, which then makes the buffer overrun code executable, and then you jump to it, and it runs.  So again, a hybrid attack.



So what Tal worked out were all the details of using the global - okay.  What I should say is that the starting point for that is a buffer overrun.  That is, the way the attacker gets their data in an innocent victim process space is a flaw in that code, in a web server, for example, where some crazy response is made to a query, and the buffer wasn't big enough to hold it; and it ends up, you know, the attacker's response ends up sitting in data that is the way the attacker gets the data in.  What's haunting about the global atom table is this is a non-defective means.  That is, this is an officially sanctioned way of getting one process to have its data inserted into another.



So what Tal realized was that the global atom table created a break in process isolation.  So he created - and it's on GitHub, by the way, all open source, all documented for anyone who wants to play.  He created, again, because it's not based on any defects, it's a problem with Windows.  He created a small return-oriented programming script which - so his application, his attacking application first stores the executable code in a global atom.  It says to Windows, here's the string.  It needs not to have any nulls in it, so it's got to be a little tricky because a null terminates a string.  So it's got to be a chunk of code with no zeroes somehow.  That would be a bit of a challenge, too.



But anyway, so he did that.  Now his code has been accepted by Windows and is sitting in the OS.  He then strings together a short chain of return-oriented programming snippets which he injects and causes a victim application to run.  And he gives a bunch of examples.  And again, they happen to work.  So, for example, the VLAN program, VideoLAN, was exploitable.  And Paint was exploitable.  He just used those as examples, due to no flaw in them, but just the fact that he was able to get his little return-oriented programming to run in that process, to request the global atom that he had loaded into the OS, which then transferred it into the process.  He then copied it into a read/write/execute buffer and ran it, and pulled it off.



And so this was really interesting because, as I said, normally you need to start with a flaw.  You're exploiting a flaw in the victim process.  Here any qualified - there are some qualifications required.  But any qualifying Windows process can be the victim of this attack.  It is local, that is, you need an attacker in the same OS that is an attacking process.  So it's not remotely exploitable directly.  It does need somebody, you know, you need to have a malicious app available to then exploit across process.



But anyway, beautiful piece of work, Tal.  So congratulations.  And as I said, Microsoft can't fix this.  He only used officially sanctioned, highly used APIs.  So the only solution would be for malware, unfortunately, to become increasingly heuristic; to, for example, hook these different APIs and try to detect the malicious use of the global atom table for this purpose and then prevent that from happening.  So it's not what we would prefer to have.  But thanks to his work, a potential exploit has been found and killed.



LEO:  Bravo.  And now we can get to the election results as the polls start to close.



STEVE:  I'm there, baby.



LEO:  Your timing is very good.



STEVE:  Polls are closing.



LEO:  Actually, we're going to get to Tech News Today.  So if you want to avoid any - I was just listening to MSNBC, and they said that candidates often at this time of the night go and do something besides watch the election results because it's too easy to misinterpret.  For a while Senator Kerry thought he had beat George W. Bush in the 2004 election, and the people on his plane were calling him President Kerry, and the people in Bush's plane, George W. Bush went down the aisle thanking them for their hard work and saying, well, we did our best.  And of course that's not what happened.



And then, kind of surprisingly, Chris Matthews, who started his political career before he was a reporter working with Tip O'Neill, said that - I can't remember who it was - I think it was Kennedy went to an adult theater.  They couldn't get into a regular theater, so they went during the West Virginia primary...



STEVE:  That'll take your mind off the election results.



LEO:  They went to an adult theater in 1960 to avoid finding - hearing early an incorrect result.  So I'm not going to say anything, and maybe we should just pretend nothing's happening for the next few hours as polls now start to close across the country.



I hope you've enjoyed Security Now!.  Don't forget, we have a wonderful Ugly Christmas sweater design.  We're selling it at Teespring.com/twitmas.  And you only have till November 23rd.  So just a couple of weeks left, if you want to get that in time for the holidays.  The Ugly Christmas - we also have tank tops, Ugly Christmas T-shirts, and Ugly Christmas sweatshirts.  "Merry TWiTMAS," they say.  And you can get it for a song, well, a song and some dollars at Teespring.com/twitmas.



This show is every Tuesday, 1:30 p.m. Pacific, 4:30 Eastern.  And that is 19:30 UTC.  You can watch live if you wish at TWiT.tv and/or be in the chatroom at IRC.twit.tv.  But I suspect many of you will want to get a copy and save it to your hard drive.  We have on-demand video and audio.  Steve's got 64KB audio plus transcripts at his site, GRC.com.  By the way, while you're there, don't forget to pick up a copy of SpinRite, if you don't already have one, the world's finest hard drive maintenance and recovery utility.  And also, of course, lots of other freebies.  You can see SQRL, Perfect Paper Passwords, ShieldsUP!, and on and on and on.  GRC.com.  



STEVE:  And I'm going to quickly put up the link to the show notes on the Security Now! page at GRC.



LEO:  Oh, good.  It's not there yet.



STEVE:  Normally I wait until Elaine has finished the transcript, so I just do it all at once.  But this podcast had so many links in it that I want to make them available to everybody.  So GRC.com/sn.  That'll take you to the Security Now! page.  And right at the top you will see the links for 585, only with the show notes at this point, until a day or two, until Elaine has the transcript ready.



LEO:  Good.



STEVE:  And probably a Q&A next week.  We will find out what our listeners are thinking and get their thoughts and answer some questions.



LEO:  You can ask Steve at GRC.com/feedback, or his Twitter handle is @SGgrc.  He takes direct messages from everybody.  Ask your questions; we'll get to those next week.  We have audio and video at our site, TWiT.tv/sn.  And of course you can subscribe wherever you get your podcasts.  That way you'll never miss an episode.  Add to your collection.  Collect all 585.



STEVE:  Drive yourself crazy.



LEO:  Yeah.  Listen again and again.  Thank you, Steve.



STEVE:  Thank you, my friend.



LEO:  And we will see you next week on Security Now!.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#586

DATE:		November 15, 2016

TITLE:		The BlackNurse Attack

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-586.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the results from our listener's informal CAIDA spoofing testing; how "LessPass" turned out to be even less than it appeared; my great day at Yubico; a whole bunch of IoT news; updates from PwnFest and Mobile Pwn2Own; a bit of miscellany, including the probable elimination of the need for Dark Matter; a new WiFi field disturbance attack; a wacky Kickstarter "fingerprint" glove; and the "BlackNurse" reduced-bandwidth DoS attack.



SHOW TEASE:  It's time for Security Now!.  We're going to find out why LessPass is even less than it was last week.  Steve visits Yubico and Stina and her husband.  A lot more IoT news.  News that will relieve you, if you're a Pixel owner, from the PwnFest.  And, wow, a new WiFi sniffing attack you won't believe.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 586, recorded Tuesday, November 15th, 2016:  The BlackNurse Attack.



It's time for Security Now!, the show where we protect you and your loved ones online, the show most beloved by geeks worldwide.  And I can't take any credit for it.  It's all this guy right here over my left shoulder, Mr. Steve Gibson.



STEVE GIBSON:  Leo, you made it all happen, however.



LEO:  I turn on the lights.



STEVE:  None of this would be going on without you.  I sometimes remind people that, you know, I was even sort of reluctant in the beginning.  It's ended up being one of the most useful things I've ever done.



LEO:  Good, good.



STEVE:  So I'm completely pleased by it.  And I think it works really well.



LEO:  Good.  Well, I'm of the same opinion.	



STEVE:  This could have been a Q&A, but the industry has given us no opportunity to catch our breath and to handle some listener questions.  Although I haven't been saying, but I have wanted to mention that, if our listeners have noticed that the podcast has become much richer with stuff recently, it's that I've been making a concerted effort to, the day before, go through my Twitter feed for all of the previous week, which because I'm so busy I often can't do interactively.  But it allows me to sweep up all of the tidbits and findings that our listeners have sent through that channel.



There's a lot of repetition, which I have no problem with.  People say, "Oh, Steve, I'm sure you already know about this, but."  And I always, when I can, I will say, "Thank you for making sure I knew," because sometimes I don't.  There's always somebody who's first.  But I just wanted to make sure.  I don't always have the chance to respond to everybody whose tweet I receive, of course, because I'm getting hundreds of them.  But it is for me a clean, fabulously useful channel.  So I just wanted to make sure, for any people who have tweeted me things who have then noticed that I have mentioned it in the following podcast, even if I didn't have a chance to say explicitly thank you on a per-tweet basis, that it is a consequence of our listeners that the podcast, and of course my willingness to make the effort to really pull all this together, I think has gotten better in the last few months as a consequence of this.



LEO:  Good, yeah.



STEVE:  And this is another example.  This is nominally titled "The BlackNurse Attack."  I have no idea where that name came from.



LEO: Terrible name. 



STEVE:  Normally we can figure out where it came from.  I don't know, that just seems random.  But it's an interesting different kind of denial of service attack.  And it's one we talked about at least 10 years ago, which has sort of come back around with an interesting twist and reason.  But it's not a huge subject, and we have so much to talk about.  We've got results from my question last week for our listeners who were willing to try that CAIDA spoof testing.  We have results.  LessPass, that we also talked about last week, turned out to have been even better named than we knew.  Oh, boy.  So we have to revisit that.



I want to share briefly the result of my day at Yubico.  I was up on the peninsula, Leo, in Palo Alto last Thursday, just for a quick little trip up to visit Stina, to meet her husband Jacob, who's the head techie, and to give a SQRL presentation to Yubico.  We've got a bunch more Internet of Things news.  Cory Doctorow wrote a beautiful piece that I'm going to share the beginning of.  News from PwnFest and Mobile Pwn2Own, where the headlines, I think, got the message wrong, unfortunately.  They went for inflammation rather than credit.



LEO:  Oh, okay.  Because I read the headline, and I was scared.  So all right.



STEVE:  Yeah.  It doesn't matter that Google's Pixel phone got hacked in 60 seconds.  It matters that it was patched in 24 hours.



LEO:  Yeah, yeah.



STEVE:  Yeah.  So I think that's props to Google.



LEO:  Okay.



STEVE:  We've got some miscellany, including the probable elimination of the need for dark matter.  After all, I did say it was miscellany.



LEO:  Wow.



STEVE:  Yes.  It's very good news because dark matter, I don't know about you, Leo, it's been really upsetting me for several decades.



LEO:  No, you know, I hate it when they say, well, we don't know, so we'll just put this little variable in the equation, and everything then works out.  I don't like that.



STEVE:  But not little.  Eighty percent of the mass of the universe had to be invisible.



LEO:  Right.  There's something, you know, it's just not elegant.



STEVE:  No.



LEO:  And Occam's Razor says the simplest solution is usually the best.  Well, I'm glad - I'll be interested to what you say there.



STEVE:  Yeah.  So it was some research that first came to light at the end of '09, so just almost seven years ago.  But then a paper was updated by the same guy, a theoretical physicist, last week, where he put the pieces together.  Anyway, I just - it's really interesting.  I think that our listeners will get a kick out of it.  



LEO:  Good.



STEVE:  There is a new WiFi, what I call the "WiFi field disturbance attack," which also sort of says we just ought to give up and go home.



LEO:  Oh, dear.



STEVE:  Then there's a wacky Kickstarter fingerprint glove and the BlackNurse reduced-bandwidth DoS attack.  So I think we can promise our listeners a great two hours.  So it's nice to know that I'm not alone.



LEO:  You're not alone.  You're not alone.  I know what you're going to say.  I'm not alone.



STEVE:  I'm not alone.  The Picture of the Week is another fun O'Reilly made-up cover.  It's the Essential series:  "Managing + Navigating 1 Million Browser Tabs."  And the little subhead up at the top:  "Because you know you just saw the tab you need."



LEO:  Yeah, yeah, yeah.



STEVE:  You can't, you know, it's there somewhere.  And as I was telling you, I still have SpinRite 6.1 R&D tabs open from before I began SQRL.



LEO:  What?



STEVE:  They're there because that's where I was, and they're...



LEO:  You never restart your computer?



STEVE:  Oh, I do.  But I have good session management.



LEO:  Oh, you have it backed up, okay.



STEVE:  Yeah, exactly.  I've got all my tabs.  And I'm, you know, Firefox gets a little finicky, especially Amazon.  Amazon's pages seem to be growing in bulk.  And so you load a couple of those, and it takes a while for the thing to stop spinning because it keeps getting more assets from wherever.  And then finally things settle down.  But anyway, yes.  This demonstrates the fact that it's handy to have tabs.  And in fact I wanted to mention also that some iOS update, it was a while ago, so it may have been 8, or maybe 9 - it was one of the major changes - thankfully allowed the default iOS browser, Safari, to increase its number of tabs because of course I'm always choking there.



And it's because what I discovered by coincidence was you can only actually have - and I think the number's 32.  I did hit the limit.  And what happens is it's a pushdown list, or a LIFO, so that, if you open a 33rd, it lets you do it.  But without telling you, it overwrites the oldest one.  So I'm sure they are trying to do what they hope you want, but it's not what I want because I have that oldest one for a reason.  Just like I've got SpinRite tabs still open and waiting for me to come back to them for a reason.



LEO:  They're vintage.  They're aged.  They're like fine wine.



STEVE:  Well, it's sort of - just take a browse through your nostalgia every so often.  Anyway, so now what I do is I switch, in Safari and iOS, to that zoomed-out view where you can sort of see the pages stacked.  And I'll quickly sort of make sure that I'm still way shy of 32, so I'm not in danger of running over and killing off something that I'm still trying to, like, hold for some future purpose.



LEO:  You're a tab duffer if you only have 32.  That's, like...



STEVE:  That's all you can do on iOS, which is my point.



LEO:  At TWiT, one of the - I think it was Alex Wilhelm was sitting on TWiT and screamed and said, "All my tabs are gone."  So, you know, he was bereft.  We have to set him up with your solution, your tab archiving and backing up solution. 



STEVE:  Yeah, yeah.  So many of the feedback that I got, both via Twitter and in the mailbag, which I did dump last night to look through, were, as I asked for, our listeners' feedback about their IP spoofing tests.  And I was gratified by the result for two reasons.  One was that our listeners will remember that two weeks ago I was brought up short by the whole question of outbound spoofing behind a NAT router because we've always been focused on the ISP, and the ISP not allowing their client or customer traffic to egress from their control with an obviously fake spoofed IP that can't ever come back to them.  And there isn't, there is no - in no protocol of the Internet is there a justification for doing that.  There just - there isn't one.



So as our listeners remember, a couple weeks ago I realized that there are no light bulbs that are not behind NAT.  You only typically have one IP from your ISP.  Who has only - or IPv4, at least.  We know that in the future that's going to be 16 bits' worth of IP per customer.  So anyway, the result of the analysis was not a single, not one, NAT router passes spoofed IPs.  They all block them.



There was one from the herd, the Netgear N600, the WNDR3700 v3 with the most recent firmware.  It turns out it allowed adjacent IP address spoofing, that is, it wasn't checking the lowest byte of the 32 bits.  So you only had a range of within 256 IPs of the same block you were in.  So it's a little bit softer checking.  But the practical consequence of that is it would be of no use to any attacker because the attacker's going to try to get some equipment in your facility, in your premises, on your network, to send packets with an arbitrary IP, almost certainly not within a few hundred of where you happen to be.  So the bottom line is, 100%, and this is, of course, this is a skewed sample.  This is Security Now! listeners.  But I don't know anybody who doesn't have a router.  You have to.  If you're going to have more than one device on an IPv4 network, you've got to have NAT.



So 100% of the NAT routers reported dropped any attempt at spoofing from getting out of the individual's local LAN.  Which is as it should be.  So it may not even be that ISPs have ever taken any proactive action.  It may very well be that all of their customers have without knowing it, just by using NAT, which kills spoofs.  And it must also be that the bad guys know.  This doesn't mean you cannot spoof on the Internet.  You certainly can.  You just have to go to a direct connection or modify your NAT to explicitly add some rules to paths.  But the default NAT translation, where the source address is rewritten to the public IP as the packet leaves, so that it's able to come back to you, and then that destination IP is replaced to go back to the computer from which it came, that drops spoofed packets.



And so I believe this makes sense, then, as to why all of these IoT devices are not being seen spoofing.  If they tried, their traffic would never get one hop away from them before being dropped at the NAT boundary.  And so they're just going with in-band non-spoofed attacks which, unfortunately, as we've noted, there's such a large population of existing both PCs and now IoT devices that there are plenty of opportunities for attackers to get in them and generate non-spoofed traffic from those.  But really interesting result.



So thank you, everybody, one and all, who took the time to run the test and shot me their results.  I looked at a whole bunch of those network diagrams and spider charts.  Everyone was sending me the links that their test generated; and every single one of them, with that one exception, showed that spoofing never got past the NAT router.  So very nice piece of information and intelligence for us to have.  And it makes sense.



LEO:  Yeah.



STEVE:  So, okay.  First of all, the guy who named that piece of code LessPass shot me a tweet shortly after the podcast, quoting me saying, "Hope he doesn't attempt to attempt a trademark on that," and then replied, "No, we are not trying to obtain a trademark on LessPass."  Which of course he would not be able to obtain.  But one of our listeners dug a little deeper than I did.  A listener named Adam took a look at the code and was horrified by what he found.  He reminded me that I had said last week that I hadn't bothered to look at the code, for two reasons.  It was so trivial to do this correct that I just gave the guy the benefit of the doubt that he had.  But also it didn't even pass muster from a functional UI standpoint.  You know, I explained why it just wasn't practical to use this thing, independent of how it worked.  Well, Adam took a look at the source and, as I said, was horrified.



So here's how the problem should be solved.  I didn't articulate it last week because we've talked about this before.  You take all of those inputs, the three fields - the domain name, the username, and your master password - and you just hash them together through some algorithm.  And again, let's assume that it would be a strong hash, like an SHA-256.  That's going to convert that ordered set of three strings into a high-entropy and maximum entropy binary blob, 256 bits.  And if you needed more, you could iterate the hash and get some more.  So, I mean, it's possible to do that.



So the idea being you are mapping that deterministic input into a bunch of binary.  Okay.  Then what you do is, looking at the various checkboxes, you determine the size of the alphabet, that is, is lowercase on?  That's good for 26.  Is uppercase alpha on?  That's good for another 26.  The digits zero through nine, there's 10 more.  Special characters.  I have 33.  Adam mentioned, I think the guy was using 26.  I don't know why, but whatever.  So you sum that up.  And that's the size of your alphabet, meaning the set of characters that could appear in every position of that password.



So what do you do?  You perform a long division.  You take whatever that number is, say that it's 64.  Well, that's kind of cheating because it's easy to divide.  But whatever it is.  You perform a long division by that number of the 256 bits.  That will result in a result of the division and a remainder.  The remainder will be between zero and N-1.  That is, where "N" is the modulus, or the size of the alphabet.  So that remainder picks in an ordered fashion one character from that character set.  And so that's your first character.



Then you repeat.  You simply divide that not quite any longer 256-bit number because it's been reduced in length by the division.  It's literally had that log2 whatever number of bits, you know, some fractional number of bits removed from it, essentially.  So you divide it again.  And you get another remainder in the same range, map it across your character set.  That's your second character, and so on.  And you keep doing that, consuming entropy from the output of the hash until you've satisfied the number of characters that the passwords should have.  I didn't go through all that last week because we've talked about this before.  That's the way you solve this problem.  Problem has been solved.  What did this person do?



LEO:  Oh, no.  He didn't do that?



STEVE:  Oh, Leo.  Leo, no.  He did something...



LEO:  You know, all you have to do is, like, look it up; right?  I mean, it's...



STEVE:  Yes.



LEO:  Yeah, okay.



STEVE:  It's the way you solve the problem.  Get this.  He divides lowercase and uppercase into vowels and consonants.  And  I have no idea why.  Then the first character...



LEO:  It's not English here.  Who cares?



STEVE:  The first character is a consonant, a lowercase.  The second character is a lowercase vowel.



LEO:  He's trying to make it pronounceable, maybe? 



STEVE:  Well, the third character is an uppercase alpha, is an uppercase consonant.  The fourth character is an uppercase vowel.  The fifth character is a digit.  The sixth character is a special character.  And then he repeats, meaning...



LEO:  Oh, that's terrible.  Oh.



STEVE:  It's awful.  It's unbelievable.  It's like, what?  You know, it really is...



LEO:  You're reducing the entropy hugely.



STEVE:  Yes.  So you know that any password this creature produces...



LEO:  You call it "the creature."



STEVE:  ...is going to have a vowel as its first character.



LEO:  That's ridiculous.  How many vowels are there?  Oh.



STEVE:  A-E-I-O-U.



LEO:  And sometimes Y.



STEVE:  Yeah.  It's, I mean...



LEO:  That's terrible.



STEVE:  Thank you, Adam, for telling us, just because, as I said, this thing deserves its name much more than I knew, LessPass.



LEO:  Wow.



STEVE:  I mean, and even inspecting a few of its outputs, you would immediately see, wait a minute.



LEO:  They all look the same.



STEVE:  Why is it always a vowel, then always a consonant, then always a vowel and always a consonant, then always a digit, and then always a special character?  And the problem is of course attackers would see that, too, instantly.



LEO:  Right.



STEVE:  And say, oh, well, this makes our job much easier.  So if last week's - I had to come back to this, thanks to Adam's bringing this to my attention because, again, I didn't take it seriously already.  But if any of our listeners, thought, well, I still think this is useful, be advised.  You'd better choose 45-character passwords in order to get sufficient entropy.  And even then I should say that lord knows what algorithm he chose to choose vowels.  I mean, it sounds like long division is beyond this person.  So he may have just, I mean, I don't even want to - I can't even guess.  I didn't look at it.  I don't want to know how he chose the vowel.  Did he, like, keep taking bits from the hash until he found a pair that fit within zero to five?  I'm just - I don't even know.  But, boy, this is - you know.



And our lesson here, our takeaway is that this should sort of be a cautionary warning for us.  No matter how well-intentioned they may be, not everyone is equally capable of solving important problems correctly.  And even those who are, we know, can still make mistakes.  But the last thing anyone should trust is an ad hoc construction such as this thing.  And of course Telegram, the "encryption," unquote, I put it in quotes in my notes here, you know, was the same.  They just made up some wacky-doodle encryption scheme and said, whoa, yeah, it really scrambles the bits up.  It's like...



LEO:  Looks scrambled to me.  Hey, this raises a question because there is a setting on LastPass, and I bet many password managers, to make a password pronounceable.  And I'm sure that that's what this was all about, was make it pronounceable. 



STEVE:  That was my first thought, too, was consonant, vowel, consonant, vowel.  You'd have some chance of, like...



LEO:  Remembering Kaka959.



STEVE:  And maybe he thought he was being cute or clever.  But unfortunately he was destroying the security.



LEO:  It sounds like so then making it pronounceable is probably not a good choice in LastPass.



STEVE:  Correct, correct.  And in fact later we talk about the breach of Adult Friend Finder.  And, boy, there's some passwords you do not want to pronounce.



LEO:  I think 99% of the passwords there were - because they were using SHA-1 at best.



STEVE:  Yes.  Or in the clear, yes.



LEO:  Geez Louise.



STEVE:  And NSFW.



LEO:  Yeah, of course.  Well, it's Adult Friend Finder.



STEVE:  For a lot of those.



LEO:  But, no, so that's good.  So I won't use that "make pronounceable."  I think, if you think about it, you don't have to be a mathematician to understand that your goal is to make a password as random as possible.  So anything that reduces randomness, or as Steve would say, entropy, is going to reduce the effectiveness of your password.  



STEVE:  It's going to increase its brute-forcibility; right.  



LEO:  Yeah, yeah.



STEVE:  But to me the idea of that option for LastPass seems odd and antithetical to it because it's there so that you don't have to remember your passwords.



LEO:  Right, right.  Well, maybe not just remember, also say it to somebody?  Right?



STEVE:  Yeah.



LEO:  Yeah, I agree.  It shouldn't be in there.  And I won't - and I never did use it.  But partly because it isn't that pronounceable.



STEVE:  No.



LEO:  It's kind of like what this guy would generate, yeah.



STEVE:  No, no, it's like, you know, and I'm completely converted.  I've given up all hope of knowing any of my passwords.



LEO:  Right.  It's like saying "make password memorable."  No, don't do that.  That's not what you want.



STEVE:  Exactly.  Exactly.  So a couple months ago Stina came down for her typically annual trek to Southern California.  She was on her way to someone in San Diego and stopped by, and we had coffee for a couple hours in the morning.  And I told her that SpinRite was effectively finished, that I needed to work on the installer.



LEO:  SQRL.  Not SpinRite, SQRL.



STEVE:  Sorry, sorry, SQRL.



LEO:  You just gave everybody a heart attack.  SQRL.



STEVE:  Yeah, sorry.  SQRL.  Same first consonant; but, yeah, different goal.  Anyway, so I committed to coming up and showing them.  You know, she's a great evangelist, but she's not the crypto techie.  Her engineer husband Jacob is, and they have a staff of crypto techies.  And I didn't want anything from them except for them to know what it was, that is, just to sort of plant the knowledge because she is completely involved in identity on the Internet and has been, you know, forming relationships with Google and many other major corporations.



And I needed to explain it to the techie guys and her, just so that they knew what it was, because the fact is it has really evolved over the last few years.  I mean, people are anxious for it.  But I'm a "get it done correctly once so that it can live for a long time" approach, rather than patch, patch, patch, patch, patch.  And in fact, in assembling a 38-slide presentation, which is a full-feature walkthrough of SQRL, which now exists, and which I will share probably next week - because I got some great feedback from the SQRL newsgroup.  I gave them the presentation to look at before I headed up to see Yubico, and they brought up some points for some things I could add some clarity to that were great.  So I'm going to do that, and then we will have a set-in-stone, full-feature walkthrough.



Bottom line is they were really impressed because one of the things that SQRL has that nothing else has, even FIDO and U2F, is what we call "identity lifecycle management," meaning built into the system is what happens if I lose my key.  What happens if the government gets my phone, and I no longer trust my online identity?  SQRL provides mechanisms to take it back from an attacker, from Big Brother and so forth.



Anyway, it was a great day.  We spent about 4.5 hours going through the whole thing, answered every question they had.  I gave them some things to think about because there are some little bits of inspiration, and I think true invention in a couple areas, one that I've mentioned before called the Identity Lock, which is a unique, as far as I know, a unique instance where what you carry with you in the SQRL client is able to create new assertions, but not prove them, which means that that creates another level of authentication which we use for emergency recovery operations.  And the beauty of that is that, if an attacker were ever to get your SQRL client in any way, they only get the ability to create new associations, if they had everything, but they can't prove them.  You need what we call the "rescue code" for that.



Anyway, I think that our listeners will probably get a kick out of just browsing through this.  So I will have it finished by this podcast next week.  I will have added a few things to it.  And we'll have a very nice, front-to-back, soup-to-nuts, presentation on what SQRL is and the way it works, followed pretty quickly, I hope, by some code people can start to play with.



And this was just sort of a random tweet that caught my attention.  A Joe Rodricks tweeted a question to me and Wired.  He said:  "Why is there a silent audio track playing when I visit Wired.com on my phone?  Not cool."  Now, I assumed, immediately, I thought, that's interesting.  And I thought, hey, I bet I know what that is.  And I bet you do, too, Leo.  It's probably their technique for monitoring how long a user remains on the page.  While you're there, your client is receiving an audio stream.  And when you hit back or switch away or whatever, that gets stopped.



And the trouble, of course, with doing this is that, while Wired may have ample bandwidth and purchases it in bulk at massive discount, their individual visitors don't have that luxury and may well have fixed data rate plans which are decidedly more limited.  So I think this sort of shows another example of a diminishing concern for website visitors.  Maybe the advantage is that this allows them to track people with scripting disabled because I think you could probably cause audio to play without needing JavaScript enabled.



LEO:  Yeah, I think so, yeah.



STEVE:  Whereas...



LEO:  Is it an MP3 or...



STEVE:  He just said audio.  He didn't specify anything more.  If our listeners are interested in digging in, I'd love to hear what more they find.  But, you know, because I first thought, well, you know, there are, like, way less bandwidth-intensive ways to do that.  Like JavaScript could just - you could set a timer in JavaScript and have it occasionally poll the server to say, hey, I'm still here, I'm still here, I'm still here.  And in fact that's what SQRL does in order to recognize that your client has authenticated.  While it's displaying the page, it just pings the server to see whether the user has, externally from the browser, logged in yet.  And when the browser sees that they have, it updates the page sort of magically.  But that's the technique I used.  But it does require that scripting be enabled in order to run that code to perform a very short little query occasionally.  So my guess is that this is meant to be a robust, non-script-required means of kind of keeping a channel open back to the server so they can monitor how long their users stay there.



LEO:  Seems like a terrible idea.



STEVE:  It really does.



LEO:  I wonder how much bandwidth it uses.  That's awful.



STEVE:  Yeah, hopefully it's a low-bandwidth audio.  Because, I mean, again, it's not zero cost to Wired.  But it's just annoying to know that there's, like, a constant suck down, even after the page finishes loading, apparently by design.  Wow.



LEO:  Wow is right.



STEVE:  And you may have picked up on the news, Leo, that our web browsers turn out not to be the only thing that's responsible for writing massive amounts of data onto, typically, our hard drives and, of great concern, our SSDs.  It turns out Spotify was five months ago told that this was going on and just ignored it for five months until it finally started gaining enough steam, and maybe on the coattails of the awareness that browsers were having a problem, and linking that to SSD [dropout].



Dan Goodin reported in Ars Technica, saying:  "Streaming app used by 40 million writes hundreds of gigabytes per day."  And he said:  "For almost five months, possibly longer, the Spotify music streaming app has been assaulting users' storage devices with enough data" - now, that's not technically correct.  I'll explain what the bug was in a second - "enough writes to potentially take years off their expected lifespan.  Reports of tens or in some cases hundreds of gigabytes being written in an hour are not" - I mean, and I've seen a terabyte a day - "are not uncommon, and occasionally the recorded amounts are measured in terabytes.  The overload happens even when Spotify is idle and is not storing any songs locally."



He writes:  "The behavior poses an unnecessary burden on users' storage devices, particularly solid state drives, which come with a finite amount of write capacity.  Continuously writing hundreds of gigabytes of needless data to a drive every day for months or years on end has the potential to cause an SSD to die years earlier than it otherwise would."  And we all know that's true.  That's why wear leveling is a crucial portion of SSD physical storage management.  "And yet," he writes, "Spotify apps for Windows, Mac, and Linux have engaged in this data assault since at least the middle of June, when multiple users reported the problem in the company's official support forum.



"Three Ars reporters who ran Spotify on Macs and PCs had no trouble reproducing this effect, which had been reported, not only on the Spotify forum, but also on Reddit, Hacker News, and elsewhere.  The Spotify app wrote from 5 to 10GB of data in less than an hour on Ars reporters' machines, even when the app was idle.  Leaving Spotify running for periods longer than a day resulted in amounts as high as 700GB."



When the story in Ars was first reported, Dan wrote that Spotify had not responded to them by filing deadline.  Then there was a later update posted with a very sort of wimpy, mealymouthed, like, oh, you know, we're looking at addressing the issue and will be resolving it soon.



So here's what's going on.  It will be fixed in v1.0.42.  It actually is a bug.  I would argue that the browser problem was carelessness, that is, just not caring to - as we know, the browser is saving its state very often by default so that, if it crashes or hangs or anything,  you're able to recover.  The problem is it doesn't do something as simple as seeing whether the state has changed from now until five seconds ago, when it last wrote a state update.  So that's just carelessness.



In this case, it actually was a bug, apparently.  Spotify is on top of the SQLite database, and a function in the database called VACUUM is being continually, repeatedly, and redundantly called.  The VACUUM command in SQLite rebuilds the entire database, repacking it into a minimal amount of space.  So the idea is that, if the database has had a chance to sort of grow with records being deleted and added and deleted over time, you end up, just due to the nature of the way the database's tree is structured, you end up with nodes that are typically half full, and lots of pages that are not full.  So it's possible to say, okay, let's compact it.  And they call that "vacuuming," where it squeezes it down.



Well, once again, this thing - but that's the kind of thing maybe you would monitor or meter how much record deletion had occurred, which would tend to open up holes that might then be useful to vacuum, rather than just doing it carelessly and constantly.  So this thing is just - it's not actually, like, recording new data coming in streaming.  It's just thrashing for no reason at all, reprocessing over and over and over an already squeezed database.



The problem is apparently this 1.0.42 is just becoming available.  So if this is a concern to you, see if you've got 1.0.42 of Spotify.  See if you can update.  They're being a little sluggish in getting it out.  So it may not be available for your platform yet, in which case you may choose just to terminate the process until you learn that 1.0.42 is available, and they say that they have got this fixed.



LEO:  So to be clear, the issue is not that it's filling up your hard drive.  It's writing/erasing, writing/erasing because it's compacting a database.  It's that it's thrashing your SSD.



STEVE:  Right.  But those are writes.  And the writes...



LEO:  Yeah, no, it counts.  I understand, yeah.



STEVE:  And so even if you rewrite the same thing on top of itself, it still causes a fatigue of the underlying SSD cells.



LEO:  A spinning disk wouldn't be an issue; right?



STEVE:  No, no.



LEO:  I mean, it's wasteful and stupid, but it's not damaging.



STEVE:  Correct.  Correct.  I mean, many of us who have lights on our hard drives kind of every so often look at them and go, what is it doing?  I'm like, what is going on?  I haven't touched it for an hour.  And [sound effect].



LEO:  Could it cause a slowdown?  I mean, is it using CPU cycles?  I imagine it is.



STEVE:  Yeah.  Oh, yeah, yeah, it's competing with anything else you're doing.  I mean, it's not good.



LEO:  It's the equivalent of Windows reindexing its hard drive all the time.



STEVE:  Right, right.  Or it's like defragging just because we, you know...



LEO:  Yeah, why not?  You never know.



STEVE:  But, see, even a defrag, it will not rewrite obviously defragged regions.  It just sort of fusses around the fringe for anything that's changed.  This thing presumably is just complete, well, based on the amount of data it's writing, we know that it must just be completely revamping your database.  And it would also make sense that those with larger Spotify databases are suffering a much larger vacuum consequence because there's, like, just a larger database to go rummage around through and resqueeze.



LEO:  You know, Steve, we're having a little bandwidth issue with you.  I was wondering if you would mind if we took a break here.



STEVE:  Perfect.



LEO:  Before the Cory Doctorow story.  I don't know if you have something going on the background there.  It's really degraded at this point.  Frame rate's gone down to one per three seconds or something.



STEVE:  Wow.  Yeah, nothing here.  I'm as stable as always.  Well, mentally.



LEO:  So you don't see a bandwidth hit at all, huh?



STEVE:  Network-wise, no.  I have not been doing anything.



LEO:  It's so weird.  Because of course we've got...



STEVE:  It'll recover.



LEO:  Yeah.  Well, I think what we're going to do is hang up and call you back.  Sometimes that helps.  Kick Skype in the butt.



STEVE:  Okay.



LEO:  So we have called Steve back, and the signal's not great.  But I think it's usable, so let's continue on.



STEVE:  Okay.  Yeah, and you sound okay in this direction.  But I see that what you're sending back to me is a little blurry-looking.



LEO:  Yeah, yeah.  I don't know what's going on.



STEVE:  Okay.  So I joked last week with the meme, "All your light bulbs are belong to us," which of course harkens back to, what was it, the '80s or something, the "All your base are belong to us" was an Internet meme.



LEO:  Yeah.  It was a bad videogame that at one point says, "All your base belong to us."  Yeah.



STEVE:  So Cory Doctorow wrote a nice piece because some researchers from, I guess it's Dalhousie University in Canada and the Weizmann Institute of Science in Israel have just published a working paper detailing a proof-of-concept attack on smart light bulbs which allows them to wirelessly take over the bulbs from up to 400 meters away.  They are able to then write a new operating system to them and cause the infected bulbs to spread the attack to all the vulnerable bulbs in reach until an entire city is infected.  And, you know, once upon a time this would seem farfetched.  But we're now living in once upon a time.  I mean, no one would believe that something like this couldn't actually happen, given everything that we see is happening.



And what's more of a concern is this was not some off-brand Chinese light bulb, not to pick on them, but as somebody who just was selling something without any attempt.  The researchers demonstrate attacking bulbs by a phone or a ground station that then attacks Philips Hue light bulbs, the most popular smart lighting system on the market today.  Philips Hue uses ZigBee for its networking.  And we've talked about that before when we were initially talking about wireless IoT devices.  ZigBee is a wireless protocol designed for low-powered Internet of Things devices and has many built-in security features.  The most important of these is that, once a device is initialized as part of a ZigBee network, it cannot be hijacked into a rival network unless you can bring a controller into close proximity to it, that is, a couple centimeters away.



However, there is a flaw in the ZigBee implementation in the Hue  system.  And the researchers showed that they could hijack bulbs which, again, you're not supposed to be able to connect to at any distance greater than a couple of centimeters.  They were able to do so from nearly half a kilometer distance.  And this is possible, as we discussed, back when we were discussing the ZigBee protocol, because ZigBee does not encrypt all traffic between devices.  That is, it doesn't encrypt that session initiation definition graphic because that's the way it bootstraps itself.



So essentially there is a bug in the bootstrapping system that has allowed them to contravene the way it was intended to work.  The Hue system, the Philips Hue system has safeguards to prevent malicious tampering.  Updates have to be cryptographically signed using a very strong algorithm, or be rejected by the Hue systems.  However, the researchers were easily able to extract the signing keys, which are the same for all Philips ZigBee products, and then use those keys to sign their own malicious updates.  So here's a system where clear attention was placed, clear focus was put on the security of the system; yet, even so, there was a mistake which these guys were able to leverage into essentially, if you could imagine a metropolitan area where Philips Hue light bulbs are high density, this thing could form its own private viral mesh network, essentially.  And that's what they did.  They were able to take over any Philips Hue system.



And so Cory writes:  "There are many ways that a hijacked Hue system could be used to cause mischief.  ZigBee uses the same radio spectrum as WiFi, so a large mesh of compromised ZigBees could simply generate enough radio noise to jam all the WiFi throughout a city.  Attackers could also brick all the Hue devices citywide.  Or they could use a kind of blinking Morse code to transmit data stolen from users' networks."  That's a little farfetched because that's pretty low-bandwidth.  But it could be fast-blinking.  And then he says:  "They could even induce seizures in people with photosensitive epilepsy," which would not be funny.



"The fact that the attack targets devices by ZigBee signals, rather than over the Internet, means it's virtually impossible to defend against through traditional methods like firewalls."  And as I said at the top, not so long ago this scenario would have been seen as farfetched at best.  Now, its exploitation really seems more like a virtual certainty.  Wow.



Many people like the Web of Trust browser extension.  It has, I think, a user base of about 140 million, if I remember from my research.  Everyone knows I'm a huge fan of browser extensions.  They've become, for me, an integral part of my daily management of my web browser portal to the Internet.  They add security, block annoyances, add extra features that I find valuable, like managing hundreds of tabs and saving session state as necessary.  But unfortunately, a German TV channel, NDR, did some research into a very popular browser extension, the Web of Trust, and uncovered a serious breach of privacy by the whole Web of Trust (WOT) service.  140 million web surfers trust it to help keep them safe online.  It's been around since 2007 and describes itself as a "safe web search and browsing service."  And of course we know that it boils down to being a crowd-source-driven website reputation and review system, so users can view ratings on a per-site basis for trustworthiness or child safety, as well as provide their own feedback and add their own ratings.



So this Channel NDR investigation uncovered that, while you have the WOT extension installed, extensive data collection is going on in the background behind your back.  WOT not only collects and records data on a per-user basis, but then analyzes and sells it to third parties.  The WOT privacy policy states that your IP, geographic location, device type, operating system, browser, date and time, web addresses, and overall browser usage are all collected, but that it is non-identifiable.  However, NDR found that it was a simple task to link the anonymized data to individual users of the service.  And just by looking at a small sample size of around 50 users, they were able to retrieve data on known users by account name and their email address, travel plans, illnesses, sexual preference, drug consumption, confidential company information, ongoing police investigations, and their browser surfing activity including all sites visited.



Mozilla has immediately removed the Web of Trust extension from their Firefox add-on page, due to the violation of their guidelines by this extension.  And it seems likely that other browser vendors will follow quickly.  So I just wanted to give a heads-up.  If we've got 140 million users of this, I wouldn't be surprised if our listeners number among them.  And unfortunately it looks like this organization that has provided this otherwise nice-looking crowd-source service is not being very credible with their support for their own users' privacy.  So you want to consider uninstalling that extension.  Apparently you can't - I didn't check, but you cannot even get it from Mozilla or Firefox any longer.



LEO:  Ugh.  You know, anybody says "trust me," I always say, well, let me see. 



STEVE:  Yeah.  Yeah, exactly.



LEO:  It's the Web of No Trust.



STEVE:  Wow.  It's, well, yeah, exactly.  It's becoming increasingly the web of how can we leverage our users for our own profit.



LEO:  Right.



STEVE:  We talked briefly about Adult Friend Finder.  I'll just note that it was a huge breach.  I ran across a site I wasn't aware of before called LeakedSource, L-E-A-K-E-D-S-O-U-R-C-E.  This is a group that follows and aggregates site breaches.  They, as they are wont to do, they sensationalized this breach, saying that the sexual secrets for hundreds of millions were exposed in the largest hack of 2016.  And in fact, across their properties they have AdultFriendFinder.com; Cams.com, which I guess is an adult webcam sharing something; Penthouse.com; Stripshow.com; iCams.com.  Across all of that - and that's managed by a single organization, more than 400 million accounts, representing 20 years of customer data, were...



LEO:  Including deleted accounts.



STEVE:  Yes, exactly.  It turns out, when you go to delete your account, what they do is they rename your email address by putting an additional @deleted1.com at the end.  So, but otherwise it's still there.  So what that does is that sort of satisfies you because you - so you go, "I want to delete my account."  And they go, okay, you're deleted.  Then, you know, just to make sure, you try to login again.  But they changed your email, which is the way you identify yourself, so it's like, oh, good.  You know, I guess that worked.  I'm deleted.  No.  You simply can't log in as the email address you used to have.  Nothing got deleted.  Twenty years' worth of salacious details apparently now available.  And as you mentioned, Leo, in some cases the passwords were never hashed.  They were always in plaintext.  And where they were, it was a simple SHA-1, which modern GPU brute-force password crackers just cut through like butter now.



So I have a link in the show notes for anyone who's interested.  But they itemized the various percentages of passwords that had been reverse-engineered.  And the upshot was, across all the properties, 99% of all available passwords are now visible as plaintext.  And you don't really learn anything new browsing the list, although you would have a good sense that this is an adult-related site when you saw what some of these passwords were.  But of course numbered among them is 123456.  I looked for "monkey."  I thought, well, there'll be a monkey there.  But no.  Instead there's other...



LEO:  Means I didn't have an account there, so that's good news for me.



STEVE:  Right. 



LEO:  Wow.



STEVE:  Oh, boy.  And here's - this was entirely foreseeable, but it's sort of interesting to see the details.  We know about the Mirai botnet, which was credited, if you can use that term, with bringing down a surprisingly large swath of the Internet a few weeks ago by its massive attack.  What was it, 600GB, I think, or gigabits per second, I think I remember, as the number I saw, generated by this one-point-something million individual Internet-connected things.  I guess cameras and one flavor of DVR was known to be behind this in addition.  But basically IoT-connected devices.



What happened was the source code was released in September.  And the presumption was that the author may have done that - now, for some reason I have a "she" tagged to it in my head.  I think it may have been a female author who released the source code.  And the presumption was that that way there was plausible deniability that this was her attack because, if other people had the source, then maybe it was their attack.  Well, today other people do indeed have the source.  And in fact what has happened is what used to be one botnet of 1.x million devices has now seen massive fracturing.  It is now 52 significantly smaller botnets in a turf war for a relatively limited number of devices that this particular, now available in source form, botnet software is able to commandeer.



So what's happened is people who didn't have the skill or means or interest in writing this stuff from scratch, oh, but they could download it and create their own botnet.  And so what's happened is we're seeing more smaller attacks from more smaller botnets, all reusing this same pool of known "how to infect them at a distance" devices.  And remember that the Mirai software only lives in RAM.  So we know from a couple weeks ago that simply restarting your device, unscrewing your light bulb or unplugging your webcam and then plugging it back in again, that'll flush it.  That doesn't solve the problem, though.  What it does is it creates a new receptacle waiting to be scanned for and found by the existing bots looking for new brethren.  And then they'll jump in there and take up residence.



And presumably, if it isn't already doing it, we would expect that an infected device would close the backdoor.  We've seen this certainly in other devices.  Code Red and Nimda both did that.  After they got in, they shut down the means of entry so that nobody else could get in and fight them on a given device.  What a world we're living in these days.  Oh, and Leo, my favorite.  I don't know who the originator was because I saw it coming from several different sources over the past week.  But I just love this.  I mean, I liked the acronym IDIOT, I-D-I-O-T, which of course stands for I Don't Internet of Things.  But I think even better is this slogan:  "The 'S' in IOT Is for Security."



LEO:  And the thing's [indiscernible].



STEVE:  Well, meaning there is no "S" in IOT.



LEO:  Oh, right.  Oh, I get it, yeah.



STEVE:  And neither is there any security.  It's like, yeah, "The 'S' in IOT stands for security."



LEO:  It's for security, stands for security.



STEVE:  Yep.



LEO:  Holy cow.  That's a good slogan.  I think they should use it.



STEVE:  So, okay.  We had recently a Mobile Pwn2Own, about a month ago, and then just last week a PwnFest 2016.  The headlines were inflammatory.  Ubergizmo wrote, "Google Pixel gets hacked in under a minute."



LEO:  Yeah.  Got my attention.



STEVE:  And Mashable said, "Google's new Pixel phone hacked in 60 seconds."  And so in my opinion, as I mentioned at the top of the show, these attention-grabbing headlines missed the point.  But more on that in a second.



Earlier this month Adrian Ludwig, who is the director of Android security at Google, told Motherboard during a security conference that the Pixels are as secure as iPhones.  He said:  "For almost all threat models, the Pixels and iPhone are nearly identical in terms of their platform-level capabilities."  [Buzzer sound]  He may well wish to believe that.  But we all know that, for security, the proof is both in the design and in the implementation, and only history can be the judge.



And I always, you know, look back at XP, where I remember Ballmer jumping around the stage saying, "Windows XP is the  most secure operating system we will ever make" or something like that.  And it turned out it was, like, the least secure.  It was a disaster for the first several service packs, you know, for years.  So far, as we know, history has not been kind to Android.  Android has traded openness for security, making a different tradeoff than Apple has, and it struggles to offer both.



But today the truth is it is nowhere nearly as secure in the field as the iPhone.  And a group of Chinese white hat hackers hacked a brand new Google Android Pixel in 60 seconds, late last week, last Friday, at the PwnFest hacking competition that took place in Seoul on Friday.  The hackers, who work for Qihoo 360, a security solutions company we've referred to in the past, won a nice fee, a tidy $120,000 in cash, after demonstrating an exploit that cracked open the Android and gave them full remote access, as well as access to personal information such as messages, phone calls, contacts, and photos.



My position is, as we know, anyone can make a mistake.  And Google is playing security catch-up.  And a lot of this is not their fault, you know, things like when they adopted the media library that Stagefright has had such fun with, that wasn't their code.  That was, oh, here's a good blob of code.  They didn't write it.  Unfortunately, there were lots of subtle problems with it.  So as a consequence of the way Android has come together, it's taking a while to shake the dust out of it.  But what they can, and I think should, be proud of is that they had patched that within a day.  And I think that's all we can ask for anyone.  I mean, that's the fastest performance we've seen.  They also closed a hole that was also found a month before by a different group of white hat hackers at Tencent's Keen Labs who breached the Pixel's security at the Mobile Pwn2Own event in Japan.



So again, I take issue with some security guy saying it's the same as iPhone.  Well, sorry.  It's not.  But they're fixing these problems faster than Apple has responded, typically.  So I certainly give them props for that.  And I think it's, you know, I know, Leo, that's one of the reasons you've switched to the Pixel.  Aside from being a very nice phone, it's become clear that Google's properties, rather than their third- or fourth-generation away OEMs, are getting themselves updated first.  The Nexuses were always getting patched quickly, and who knows whether the older ones ever would.  And I think that's the best you can do today, given this ridiculously porous security climate that we're in.



I had titled this one "Shove this in your pipe and smoke it" because it refers to piping in Unix.  There is a new tool which I wanted to just put on our listeners' radar because we talked about instantly installing the PiVPN by using sort of the hack, the command line hack of piping the output of curl into the shell.  So you literally just give the command curl, space, and then a URL which feeds you essentially a command list.  And then the vertical bar takes the output of that and feeds it into the standard input of the next thing in line, which is typically SH, you know, your shell, which then absorbs that and does whatever it instructs.



Well, this raised a lot of people's, we could say, Gibsonian responses because what you're doing, essentially, is you're allowing a remote script to issue any commands it chooses to your shell.  And it could do anything.  Well, it's certainly a convenience versus a security tradeoff.  What was created, and it's on GitHub, is a new intermediate command called TAP, because it literally is a tap on the pipe.  So you do the curl and the URL, vertical bar, TAP, vertical bar, and then SH.  So what happens is curl pipes this blob into TAP, which creates a temporary file, reads the whole thing in, and opens your default editor - or if you don't have [dropout] in the environment, then it [dropout] vim - and allows you to look at it.  You can peruse it, see what it does, make any changes that you want.  And when you save and exit your editor, TAP has shelled that process out, so that terminates.  TAP resumes and then pipes that edited file into the shell and deletes the file after it's done.



So that has, of course, that allows you to do an inline inspection prior to committing to piping, approving it, essentially, and pushing it through into your command shell.  And it has another effect because [dropout] how tricky this was.  There were instances where, because curl would be feeding directly into the shell, the delay of the shell accepting the curl output could be felt at the server end, which would allow a clever server to know whether you were probably piping straight through, or whether you were piping into the shell.  That is, were you dumping to a file for manual inspection, or putting it through the shell?  Because the shell would introduce some delay that a direct write to the file wouldn't.



So it had been noted that, if it saw that it was going straight through, it would give you a benign, clean, non-malicious script.  And if it sensed that you were probably [dropout] directly into the shell, it could change what it sent you on the fly and give you something evil.  So TAP, because it writes it in one blob to [dropout], it would fool any timing-sensitive server-side software into believing that it is going directly into the, I'm sorry, that it's being written right to a file, so that you would get the benign version, and it wouldn't even try to give you the attack version.  So just a cool little widget to add to your command line.  It's on GitHub.  It's called curl-tap-sh.  



LEO:  There's a package manager on Arch, for instance, a number of package managers on Arch that go to the Arch user repository, which is a little more risky because anybody can put anything up on there.  And the install is run by a script.  And most of the installers that support this user repository will load the install script in an editor, well, at least give you the option to load the install script in the editor before anything is executed so you can review it. 



STEVE:  Nice.



LEO:  Yeah.  So this is kind of known way of doing things.  And I think that's absolutely a great idea.  Of course you can do it manually.  Just download.  Instead of curling and piping to SH, just curl it, edit it, then open it in SH.



STEVE:  Unix users, however, take as a badge of pride how lazy they are.  And so they say, ah, just [crosstalk].



LEO:  A lot of stuff on Macs, too.  You'll see a lot, like Homebrew's a good example, which is easy to install on the Mac if you just copy and paste the curl pipe to SH command line. It's trivial.



STEVE:  Yup.



LEO:  And I think probably a lot of people would say, well, I could read the script, but it wouldn't tell me anything.



STEVE:  So OpenSSL has been updated and patched again.  This one only affected the v1.1.0. So I just wanted to put it on people's radar.  There is now a 1.1.0C, which fixes three problems of high, medium, and low severity, respectively, the most [dropout] critical.  And that was a - they call it a DoS.  It's unfortunate that we don't have less ambiguous abbreviations because technically it's a denial of service if you crash OpenSSL.  So what this is is a denial of service, technically, although, you know, my point is it'd be nice if we had one for remote high-bandwidth attacks of websites to distinguish it from, I crashed the server, so I've denied the services of the server to anybody else who [dropout].



Anyway, there is a relatively new addition to the TLS suite of ciphers, CHACHA20 and POLY1305, which are recent editions.  It's a nice authenticated encryption suite, but there was an implementation error which for large payloads allowed an attacker, if they wished, to crash open SSL, thus bringing down the front end of a web server.  So if you are using 1.1.0, know that late last week an update was made available, so you may want to get it. But if you're on any of the earlier tracks of OpenSSL, they don't have that latest suite, and so they don't have the bug.



LEO:  All right, Steve.  I see you pondering with great interest something over there.



STEVE:  Well, yeah, I'm looking through the state table on pfSense to see what's going on because as I'm listening to you, it was like, you know...



LEO:  Chopping, yeah.



STEVE:  Chopping, exactly.  Very choppy.



LEO:  Something's going on.  We'll figure it out after the show.



STEVE:  We'll get this done, and I will get it figured out.  I'll find out what's going on.



Okay, so Eugene Kaspersky is unhappy, which I thought was sort of interesting for a number of reasons.  He has decided to sue Microsoft for anticompetitive behavior in the EU and Russia.  And he explained it all in a blog post titled "That's It, I've Had Enough."  And they're casting themselves in the role of David to Microsoft's Goliath.  And reading through his long list of complaints, I was of two minds.  I was immediately put in mind of the Get Windows 10 debacle, where Microsoft was using arguably their right, but also their dominance, you know, [dropout] as the publisher of the operating system that people were choosing to pretty much force people who didn't really strongly resist to do what they wanted them to do.



So Kaspersky enumerates the behavior which he feels is anticompetitive, that is, and this has been - he feels that with Windows 10 the ante has been upped tremendously.  Essentially, Microsoft has [dropout] to use Defender.  Microsoft really wants their users to use Defender.  And in fact he quotes a Microsoft presentation where one of the Microsoft presenters says exactly that.  In a presentation titled "Windows 10 - Protecting Device Integrity," the presenter says:  "I want you to think about kicking out the third-party antivirus because we've got a great solution right now, and it's going to be even better in the months to come."



And so AV has always been a bit of a challenge because, to do what it wants to do, it needs hooks into the OS.  Which means that things that Microsoft changes, which the AV vendors have reverse-engineered in order to get their hooks in, literally, at the low level they need to, those are inherently brittle.  And so on one hand I understand what he's saying.  On the other hand, he ought to be reading the handwriting on the wall.  I mean, essentially they're in an endangered position, and it's not clear to me that suing Microsoft makes a lot of sense.



For example, once upon a time there was a huge industry for firewalls on Windows.  That's pretty much gone.  Microsoft introduced a firewall in XP, but it was disabled by default.  I don't know why.  But I remember, I mean, I was talking to Gregor at Zone Labs around that time.  And I remember he flew up to Redmond - because Zone Labs was a very popular firewall, it was the one I had chosen and was recommending to people.  And he was made quite uncomfortable by the news that XP was going to get its own firewall.  But they said, oh, don't worry, don't worry.  It's not enabled by default.  Users would have to turn it on.  And he's like, okay.  And then of course XP continued to have problems until, with Service Pack 2, XP's firewall was on by default.  And this might be - I always sort of thought this was Microsoft just being very careful about moving forward.  I also thought it was them sending up a pretty clear signal that firewall vendors should maybe think about not retiring on their income from firewalls because that may not work.



And I have my own personal experience with exactly this.  I will never forget the dinner I had with - I called them "The Brads," Brad Silverberg and Brad Chase.  They came down to visit back when I was writing the InfoWorld column, the TechTalk column in InfoWorld.  Of course, I was publishing SpinRite back then.  And they took me to dinner to tell me about DOS v6.



LEO:  That's pretty cool.  I didn't know about this.  That's cool.



STEVE:  Yeah.  And they were clearly uncomfortable when they said, "Now, Steve, we need to tell you something, but we don't want you to get too upset about it."  And I said okay.  And they said, "Well, you know, because we have to do this from user demand, DOS 6 will include something called ScanDisk.  But don't worry."



LEO:  Don't worry is right.



STEVE:  "It doesn't do anything like what SpinRite does."  Now, I of course knew better.  I knew that this was an arrow through my heart because from that moment on, the most often-asked question from those who even bothered to ask was, well, I already have ScanDisk.  It came free with DOS.



LEO:  Right, right.



STEVE:  What do I need SpinRite for?  Now, of course, they knew because they were technical VPs that it did nothing like what SpinRite does.  Did.  Does.



LEO:  Do what SpinRite did.



STEVE:  And of course I knew it.  But the fact that it was there, you know, changed our ability to sell SpinRite, which seemed to be competing with something that was free, even though it did nothing the same.  And arguably customers were hurt because they would run ScanDisk that they already had, and it would [dropout], and they'd [dropout] and reformat their drive.  That is, they wouldn't [dropout] data back.  You know, it didn't do nondestructive low-level reformatting, didn't optimize the performance, sector interleaf.  It didn't do any real data recovery.  It was just sort of a better CHKDSK.  But it looked kind of the same.  And it said ScanDisk.  And so, you know, ouch.  I thanked them for dinner.  I would have happily paid not to have ScanDisk bundled with DOS because, I mean, obviously we've survived because in fact it didn't do anything real.  But as we know, marketing is perception.



And so anyway, I just sort of - Kaspersky complaining about Microsoft.  Oh, and the other point that I didn't make is I've always appreciated Microsoft's size, that is, the monoculture of one OS.  And Kaspersky should really recognize they have been profiting from that for a long time.  Because of Microsoft's historic dominance, I was able to write one piece of software which satisfied almost the entire market.  That's no longer true, of course.  There's lots of Macs and lots of Linux machines.  And for a long time Macs were using the PowerPC, so I SpinRite wouldn't easily run on them anyway.



But the point is we've all benefited from Microsoft's dominance in the industry, which gave us a single target for developers to write to.  I'd rather have that than 20 different completely random, you know, BeOS and all these other things that tried.  You know, Amiga and the Commodore could have gone to Commodore 128.  I mean, all of this could have happened differently, and it would have created a much more fractured market.  Kaspersky did make one very good point, though, that specifically bears on AV.  And that is, the last thing you want in an antivirus cat-and-mouse game in the spy vs. spy or the spy vs. the anti-spy; the last thing you want is a monoculture AV.  That is, if Microsoft succeeds in killing off or mortally wounding all of the non-native Defender AV add-on, then the bad guys only have one AV product they need to bypass.



Right now, with there being 20 in a relatively active antivirus market, the virus's job is much more difficult because they don't know which AV package a given user will have, and they need to be - they need to arrange to get around all of them.  And it is the case that Microsoft, at least initially, normally doesn't have best-in-class results.  They typically get there eventually.  But they don't start out [dropout].  But I think AV is a particular case where, and Kaspersky does bring this up, not specifically the threat of a monoculture, which I just grabbed onto when I saw that comment.



But I think that's really important.  You'd like to have more variety because you're just going to get more safety that way.  I just use Defender, though.  I mean, you and I, Leo, have never been huge AV proponents.  We believe in maintaining safe borders and being very careful about safe behavior.  And also, you know, saying a prayer every so often.



LEO:  Yeah.  And I believe in not using Windows, which helps me quite a bit.



STEVE:  Yes, yes.



LEO:  That's a handy tool.



STEVE:  And I use DOS, so I'm in good...



LEO:  Yeah, I don't think there are any DOS viruses.  Well, there were.  Not anymore.



STEVE:  Not anymore.  Okay.  So, miscellany, three fun bits.  I noted just yesterday as I was pulling this together that "Westworld" on HBO has been renewed for a second season.  And it just is - it's a delightful 60 minutes on Sunday evenings.  I really enjoy it.



LEO:  Now I'm worried because I was hoping they would resolve it in the first season.  Apparently there will be no incentive.



STEVE:  I had exactly the same thought.  Can you say "Game of Thrones"?



LEO:  Yeah, yeah.



STEVE:  Which just goes and goes and goes.



LEO:  It kind of had to happen; right?  I'm not surprised.



STEVE:  Yeah, it did.  And maybe, I mean, it is a rich medium.  Maybe they will solve this villain of whatever it is.  It's still sort of unclear what's going on, but it's interesting.  And then give us another one, you know, next season.



LEO:  Right.  It's kind of, yeah, there's endless.  Although one of the big fan theories kind of came true last night, that I thought was very interesting.  We'll take more.



STEVE:  I did see, I saw with a buddy of mine on opening day last Friday "Arrival."



LEO:  Oh, I'm dying to see that.  Mike Elgin said he loved it.



STEVE:  It was a very credible and well-assembled First Contact movie.  As I was watching it, I was thinking, okay, there's nothing wrong with this.  I mean, they're not doing anything wrong.  And some of the military stuff might be a little over the top.  But on the other hand, if 12 scary big black eggs sort of all descend on different areas of the world and float a few feet off the ground and don't seem very friendly, you can imagine.  I mean, I'm surprised more people weren't shooting missiles at them to see what would happen.  But anyway, I just wanted to say there was some of it that was a little confusing because I considered it a "Close Encounters of the Third Kind" meets "Slaughterhouse Five."  And if any of you were forced to read Kurt Vonnegut's book in high school...



LEO:  Forced?  That was a good book.  You didn't like it?



STEVE:  Everything was forced in high school.  But, yeah, I did actually like it.  And the concept was interesting, too.  So there was a point where I was worried about the plot, and then it resolved.  And it's like, oh, okay, this explains what seemed to be a big problem for a while.



LEO:  Elgin's recommendation was see it quickly because you don't want the spoilers.



STEVE:  Yes.  I had exactly the same thought is there is a huge danger of someone saying someone you wish they hadn't said.  And then it's like, ooh, darn.  And of course we don't do that here.



LEO:  Right, no.



STEVE:  Okay.  Dark matter.  I won't take much time on this, but it's been a big concern for several decades.  It just seemed wrong, as you commented also, Leo, at the top of the show.  So, okay, here's the problem.  We think we know how gravity works, even though its theory has also been acknowledged to be at odds with that of quantum mechanics.  That is, they cannot both be right because they're in disagreement with each other.  So that's a problem.



The trouble is that we observe galaxies rotating.  We can determine the rate of spin based on Doppler shift from the opposite edges that we can see, one side coming toward us, the other going away from us.  That allows us to infer the rate of rotation.  And we can see how, based on distance and size, we know how big they are.  The problem is they are spinning too fast.  That is, we know how fast they're spinning.  We know based on their contents how much mass they have.  So they should fly apart, meaning they're spinning too fast for their own gravity to hold them together.  So the only thing we've been able to do, cosmologists, is say, okay, there's got to be some dark matter somewhere.  You know, there must be a lot of it.



It turns out that we need a whole ton of it.  Eighty percent of the universe's mass would have to be dark for what we observe to be correct.  And then, after deciding that, they went looking for dark matter, you know, people who smash stuff together and do all this, fancy tests and looking for dark particles and all that.  Never have they seen any sign of it.  No particle, no indication it exists.  Nothing other than we need it to exist.  So let's go find it.  And they haven't.



So nearly seven years ago, back at the end of 2009, a Dutch theoretical physicist by the name of Erik Peter Verlinde - who is at the University of Amsterdam's Institute for Theoretical Physics, and also he's got a great rsum.  He was at Princeton and permanent staff at CERN.  And, I mean, this guy knows what he's doing.  And he is a professor and has a permanent teaching position at the Institute of Theoretical Physics in Amsterdam.  He introduced a theory that he named "entropic gravity."



Now, I have no idea what the following means, but it's cool-sounding.  According to this theory:  "Gravity exists because of a difference in concentration of information in the empty space between two masses and its surroundings."  Okay, got that?  A difference in the concentration of information.



LEO:  Whoo, whoo.



STEVE:  He also extrapolates this to general relativity and quantum mechanics.  He said in an interview at the time:  "On the smallest level, Newton's laws don't apply, but they do for apples and planets.  You can compare this to pressure of gas.  Molecules themselves don't have any pressure, but a container of gas does."



And back then, in his 2010 article on the origin of gravity and the laws of Newton, Verlinde showed how Newton's famous second law, which describes how apples fall from trees and satellites stay in orbit, meaning sort of at local scale, or this scale, those can be derived from the underlying microscopic building blocks which he has articulated.  Extending his previous - and this extends his previous work and work done by others.  He now shows how to understand the curious behavior of stars in galaxies without adding any of the presumed, and still missing, dark matter.



Last Tuesday, a week ago on November 8th, he published a new paper showing how his theory of gravity accurately predicts the velocities by which the stars rotate around the center of the milky way, as well as the motion of stars inside other galaxies.  He wrote:  "We have evidence that this new view of gravity actually agrees with the observations.  At large scales, it seems, gravity doesn't behave the way Einstein's theory predicts."



And finally, at first glance, Verlinde's theory presents similar  features to a common modified theory of gravity known as MOND, M-O-N-D, Modified Newtonian Dynamics, which we've had since - it's been around since 1983.  However, the problem is that this Modified Newtonian Dynamics tuned the theory to match the observation; whereas Verlinde's theory starts from first principles and apparently arrives at correct results without any tweaking at all.  So I just thought that was important enough to put on everybody's radar, that this whole question, this problem with dark matter, it may just be the fact that our model of gravity has been wrong, and now there'll be lots of testing and verification and so forth to see whether this holds up.  But if so, that's a big step forward, and it's a big "whew" for all of the people who were concerned that...



LEO:  Yeah, makes sense.



STEVE:  It really does make sense.  This idea that there was 80% of something that we were not seeing is like, okay, well, where is it?  Why not?  And that's a lot, you know, that's four-fifths of everything.



LEO:  Awesome.



STEVE:  Leo, there's a fun video in this next link.  Turns out there's actually a World Cube Association to manage the Rubik's Cube, of all things.  And there's a well-known German manufacturer, Infineon, which is promoting their technology for vision recognition, for promoting automated driving subsystems, which they say need to offer very low latencies and absolutely reliable and quick technology.  So to demonstrate this at a recent trade show in, I want to say Munich - oh, yeah, the Electronica tradeshow in Munich - they built a one-off Rubik's Cube-solving robot.  And the picture is just wonderful.  So we know what a Rubik's Cube is; right?  It's a cube with six sides.  And, okay, now that was it solving the puzzle.



LEO:  What, no, wait.  What?  No.



STEVE:  Yeah, it's ridiculous.



LEO:  So this is the slow-mo 12x...



STEVE:  Then they slow it - yes.



LEO:  Holy cow.  It takes how long?  Less than a second.



STEVE:  .637 seconds.



LEO:  To solve any arbitrary Rubik's Cube.



STEVE:  Yes.  So what they did is they cover the camera's shutters, that is, they shutter the cameras.  Then they randomly scramble the cube so that the computer can't see what they're doing.  Then they uncover the shutters.  And then they say go.



LEO:  Ready?  Ready?  Watch.  Done.



STEVE:  Oh.



LEO:  Whew.



STEVE:  That's so neat.  And at first I'm thinking, now, wait a minute, does that really work?  But when you think - so for the people who don't have video, we know a cube as six faces, and so six sides.  So if you attached rods to the center face of each side, and those hooked to heavy-duty stepper motors - so you've got this enclosure with six stepper motors, each hooked to a rod, and the Cube floating about a foot away from them all in space, suspended by these six rods coming in.



Indeed, if you rotate a rod, that will rotate, because of the internal mechanisms of the Rubik's Cube, it will rotate that face.  And as long as you bring it back into alignment, which you can do with a stepper motor by stepping it exactly the number of steps required to go 90 degrees, then any of the other ones are able to spin.  And I actually think that in some cases it's spinning opposite faces at the same time because that you can also do without breaking the Rubik's Cube property.  They did use a friction-reduced cube in order to get better speed.  But it turns out that the previous record - I mean, they broke a record for automated Rubik's Cube solving.  The previous record, and this boggles my mind, is a 14-year-old kid in 2015 who got the record at 4.904 seconds, and then another youth completed the task in 4.74.  So, I mean, just, boy, you know, that's crazy.  Anyway, it was just a cool little bot that I wanted to share with people.



LEO:  It's amazing.



STEVE:  And I have found in the mail bag yesterday a really nice note from a Paul O. Kirwan in the UAE.  And the title caught my eye:  "SpinRite in Riyadh, the World's Largest Airport Project."  He said:  "Hi, Steve.  Just a testimonial and a thank-you for your product.  I first came across it back in the 1980s when we were opening Riyadh Airport.  At that time we had a small selection of PCs" - okay, right, 1980 circa PCs - "for VIP" - then he has in parens - "(the Ruling Family and Air Force Generals) staff, and back then the drives were very unreliable."  Amen.  "A combination of heat, dust, cigarette smoke" - he noted, he says, parens - "(they all smoked heavily) meant it was a full-time job to keep these things working.  And nothing was able to do that except SpinRite.



"I now own my own copy; and, believe me, it has saved my bacon more than a few times.  I have used it many times since, and now for preventative maintenance.  I talk about it because it's often amazing, and people are skeptical when I tell them that a 30-plus-year-old piece of software" - well, I have been keeping it alive a period of time.  It's had several major improvements since then.  But, yes, it was written originally back then, back when the Brads scared me by telling me they were going to include something that was going to confuse people in DOS.  "A 30-year-old piece of software," he writes, "can recover their drive."  So that means he's been doing it for other people, which technically I would hope he would suggest maybe that they should use it themselves for preventative maintenance.



Anyway, he says, "They are always impressed when it does recover their drive.  Thanks again.  The interface is so familiar I can almost run it blindfolded.  Thanks to you and Leo for a great podcast, and thank you for such a great and enduring product."  And Paul, thank you.



LEO:  Nice.



STEVE:  So three final things.  This is the one I said we might as well just give up.  Just, you know, just fish.  Go to a creek, listen to crickets.  Because if this is possible, it's over.  WiFi signal interference can leak your passwords and keystrokes.  I'll just read the blurb from the beginning of the abstract of the detailed technical paper.



They write:  "In this study, we present WindTalker, a novel and practical keystroke inference framework that allows an attacker to infer the sensitive keystrokes on a mobile device through WiFi-based side-channel information."  We all know what that means.  "WindTalker is motivated from the observation that keystrokes on mobile devices will lead to different hand coverage and finger motions, which will introduce a unique interference to the multipath signals and can be reflected by the channel state information," which I'll explain in a second, CSI.



"The adversary can exploit the strong correlation between the CSI fluctuation and the keystrokes, to infer the user's numeric input.  WindTalker presents a novel approach to collect the target's CSI data by deploying a public WiFi hotspot.  Compared with the previous keystroke inference approach, WindTalker neither deploys external devices close to the target device nor compromises the target device.  Instead, it uses the public WiFi to collect user's CSI" - again, channel state information, which I'll explain - "data, which is easy to deploy and difficult to detect."  And then I put in here a note:  Side channel attacks, being typically passive, are by their nature almost always impossible to attack.



Then they say:  "In addition, it jointly analyzes the traffic and the channel state information to launch the keystroke inference only for the sensitive period where password entering occurs," meaning [dropout] when that's happening.  "WindTalker can be launched without the requirement of visually seeing the smartphone user input process."  They say "backside motion."  I don't know what they mean.  The guy's butt?  Anyway, "or installing any malware on the tablet."  Probably a language barrier thing.



LEO:  I'm sure.



STEVE:  Their backside motion.  "We implemented WindTalker on several mobile phones and performed a detailed case study to evaluate the practicality of the password inference towards Alipay, the largest mobile payment platform in the world.  The evaluation results show that the attacker can recover the key with a high success rate."



We take for granted this stunning WiFi technology that we have been given.  It's a black box.  What we've gone to is this multiple antenna MIMO, the multiple input/multiple output technology.  And we take for granted what's in there because it just works.  But to get it to work, to achieve the data rates we are now getting, at the reliability we are getting, in this random heterogeneous environment that we are in, requires an insane amount of technology that we don't even see.  And it's been integrated onto a chip, so it doesn't even cost anything.  But it's still there, and it's called "channel state information."



What happens from instant to instant is the receiver of the WiFi signal is acquiring and digitizing a phenomenal amount of information about the separate signals being received by the individual antennas, the receive antennas on the device, and like the relative phasing of the signal, and the antenna-to-antenna signal strength, and even arrival time within the phase, in order to do things like beam forming, and in order to ignore off-access noise.  The point is there is an insane amount of technology that we don't even see, but it's there, and it's what has enabled our current technology to work.  And that CSI, as it's called, this channel state information, is published in an API which is open because no one thought it could be abused.  And so it is possible for software to treat that as metadata.



That is, what these guys found is that, if someone is holding their smartphone, which has a WiFi link to an access point where the CSI information is being processed as side-channel information, they're holding in their hand a transmitter.  And as they use their other hand to touch the screen, that creates enough movement, enough variation from event to event that their actual other hand motion can be resolved by the CSI information.  Now, yeah.  In an environment where lots of people are moving around, that's less easy.  It probably needs to be, you know, you're going to have probably some requirements for it to be physically quiet in terms of other movement, although it's the hand relative to the WiFi transmitter in the phone that is what modulates that phone's transmitted signal, which is then received by the access point.



And thanks to this crazy digitization of just amazing richness, of instant-to-instant information about the state of the WiFi signal received individually by all of the receiving antennas, that's side-channel.  And these guys turned it into a not quite 50/50, I think it was like 48% recognition rate.  But still, from zero, that's worrisome.  So as I said, we should just unplug and just say, okay, that's, you know.  Now, I mean, like if our movements in a WiFi field can give us away, there's no hope.



LEO: This is like Van Eck phreaking, though.  I mean somebody's going to have to have some sophisticated hardware; right? 



STEVE:  No.  That's just it.  Consumer routers all have it.



LEO:  No, I'm saying to do it, though, to do this.  No?



STEVE:  No.  No.  It's built into every - every multi-antenna router has this.  Now, you would need that software added to the access point that the phone is connected to.



LEO:  Okay.



STEVE:  So, for example, the Starbucks router would need to get taken over.  But, oh, gee, who ever heard of a router getting taken over?  But my point is it's in the hardware, Leo.  It's there, and it's public.  So the software simply needs to do it.  And in fact, these guys, they didn't make any hardware.  They used an Intel 5100 series WiFi chip on Linux.  And the Linux driver has access to the API that receives the side-channel information.  Zero hardware overhead.



LEO:  Crazy.



STEVE:  Isn't that amazing?



LEO:  Crazy.



STEVE:  Wow.



LEO:  Wow.



STEVE:  Yeah.  Okay.  Now this one is crazy, speaking of crazy.  Popular Mechanics covered the story, put me onto it.  And I've got the Kickstarter link in the show notes at the end of the story, Leo.  It's called Taps, T-A-P-S.  They call it a Touchscreen Sticker with Touch ID.  Okay.  I followed a link which one of our listeners thought I would find intriguing, and indeed.  It's in the show notes.  You're hearing it because I thought it was really interesting.  So listen to this.  It's not what I thought it was.  And it's clever.



"A company named Nanotips thinks it can solve the annoying problem of removing gloves," meaning needing to remove gloves, "to access your fingerprint-sensor locked smartphone in the winter.  The product, Taps," writes Popular Mechanics, "is surprisingly lo-fi.  It's essentially a fingerprint-shaped sticker made of military-grade polyurethane..."



LEO:  Oh, no.



STEVE:  "...that you can" - oh, yes.  And so I'm thinking, oh, my god, so you have to train it with your fingerprint?  No, no, no.  It has somebody else's fingerprint?  No, no, no.  This is where I thought, this is kind of clever - "that you can stick onto the end of any glove."



LEO:  Oh, yeah, and then you train the phone with that.



STEVE:  Exactly.



LEO:  Right, right.  So it's an additional fingerprint.



STEVE:  It's a cyborg fingerprint.  "This fingerprint isn't yours.  It's a synthetic individual fingerprint that you can train your phone to recognize the same way you would your own."



LEO:  Wow.  It's eight bucks, by the way, which is why I tweeted it this morning, because I thought our listeners might get a...



LEO:  This is clever.  I like this.



STEVE:  I think it's clever.  "These synthetic fingerprints don't actually look like fingerprints, but they function the same way as any real finger" - they actually look like sort of a stippled bump map - "creating a recognizable pattern that your phone can remember and use in the future.  Most apps allow at least one or two fingerprints" - and, you know, iOS lets you have five - "to serve as keys, so Taps merely replaces one of your own fingerprints as a biometric password."  Well, that's an abuse of the term, but we know what he means.



"Of course, this technology presents a massive security problem.  Suddenly, anyone with your glove can access anything you have locked this way on your phone."



LEO:  Oh, that's a good point.



STEVE:  Yes.  "This design flaw eliminates most of the usefulness of Taps, as the reason to use a fingerprint key in the first place is generally that it's more secure than a password as it's unique to you."  And we presume every one they produce is also unique, so that not all of the finger - I'm sure they are.  But I'm saying that's another point of concern.  You might want to, like, maybe scrape off a few nubs.



LEO:  I'm not sure they are.  This doesn't sound, I mean, really?



STEVE:  Well, they do expressly say that they are unique.



LEO:  Okay.  Oh, good.



STEVE:  Yeah.  And it looks like the technology they have for making them would make it so.  So anyway, just to finish, they said:  "No one can steal your fingerprints, but they could definitely steal a glove with a synthetic fingerprint stuck to it.  However," they conclude, "convenience is a great motivator.  Taps is currently on Kickstarter, where it has raised 2,000 over its 5,000 goal."  Now, that may have been true at the time the story was issued.  This morning it was at 11,000, and now it's at 13.  So I have a feeling that my tweet had a nice effect also.  Again, I think it's $8 each, but they sell them in sets of four.  And I'm not suggesting it's anything more than an interesting toy.  But for eight bucks, or, well, 22 for more than you probably need, I just think it's kind of cool.  And maybe there is a use.  Think about leaving the fingerprint, like in a safety deposit box for some reason.  And I was thinking, okay, like if you became deceased.  But then on the other hand, someone could press your dead thumb on your phone in order to...



LEO:  Most phones, I think, have some infrared sensing to prevent dead thumbs from working.  But I might be wrong on that.



STEVE:  Ah.  I wonder.  Because then this wouldn't work if it was through an insulated glove.



LEO:  Oh, then you're right.  Maybe they don't.  Maybe I'm mistaken.  Taps.



STEVE:  I think we talked about that when we were initially talking about Touch ID spoofing, you know, to look for a pulse or look for heat or something.  But anyway, I just wanted to let our listeners know, I'm not, again, yes, recognize it's a security problem, but I just think it's kind of cool, just an interesting hack.



LEO:  Wow.



STEVE:  And the idea, again, we're in California, Leo, so gloves are not a big problem.



LEO:  Not a big deal for us, yeah.  There have been gloves around before with silver in the glove that lets the capacitive screen work, but it doesn't solve the fingerprint problem.



STEVE:  Right.  And so with the understanding that you've extended your identity out to your thumb, you could of course use it during the winter, or use it during a ski trip, and then wipe that fingerprint out of your phone so that it's no longer a danger.  So I can see some use cases, and I wanted - I just thought it was a cool hack, too.



And, finally, the BlackNurse.  Lord knows why it got that name.  I looked for any reason that it was called that, and I couldn't find any.  There's an interesting attack because this allows one PC, one host on the Internet, one light bulb, one particularly bright light bulb that has - apparently it needs 15 to 18Mb, but not 600Gb.  That is to say, a radically low, compared to what we're used to, bandwidth [dropout].  A decade ago, when we were talking about denial of service attacks, I remember that we talked about small packets because there are two ways to bottleneck a router.  You can bottleneck the bandwidth of its connections, that is, simply send in more packets than it can eliminate.



Remember that a router typically has multiple [dropout], and then it's sending packets arriving from multiple sources, originating from multiple sources, down to a single destination.  But if the links are all the same bandwidth, it might have, for example, four one-gig incoming links and one one-gig outgoing link, which is normally fine.  But if all four incoming one-gig links were fully saturated at one-gig, and they're all trying to have their traffic sent out of the remaining one-gig link, well, you've got four gigs coming in.  It can't fit into that one-gig outbound link.  So the outbound link buffer is forced to throw the majority of the packets away.  And that is a denial, a bandwidth DDoS, typically distributed denial of service because you've got lots of sources, all generating traffic aimed at the same spot.



But the other thing, the other problem that routers historically have is the rate at which they can switch packets.  Not the getting them out once they're in, but they have to inspect the packet in order to figure out where it goes.  And normally routers are specified toward the largest possible packet size because the Internet maximizes the size of packets where it can.  TCP uses the largest blocks that it's able to, as does UDP.  And so but there will always be a mix of smaller packets.  For example, ICMP is just like the famous ping.  It's just it's a very, very small packet.  And by its definition, a TCP SYN packet, the synchronized packet, is super small.



And remember back in the day the SYN flood.  Well, it turns out that many SYN floods that got to their host computer would crash the TCP stack.  But it also was the case that many SYN floods never had a chance to get to the host computer because they were so small that many more of them would fit in a given amount of bandwidth per second.  So think about that.  If you've got a 1,500-byte packet, then there's a maximum rate at which those can arrive over a certain bandwidth.  But if you've got a 15-byte packet, you can fit a hundred times that many in the same period of time over the same bandwidth.



So after becoming very sensitive to the issue of packet switching rate, I look at, when I look at switches or routers, they'll talk about whether they can do minimum size packet line rate switching, meaning that, if packets of the smallest legal size arrive at the maximum rate that the interface will run, is what's called the switching fabric, is the term, is the switching fabric able to quickly enough inspect the [dropout] send it out to its destination.  And once upon a time that was not the case.  There's been lots of advances since then.  But you can't always treat all packets the same.



What has happened is [dropout] have gone up.  Routers have had to become much smarter.  They have a hierarchy of paths.  They have the so-called fast-switching path, where essentially hard-wired electronics is able to make an instantaneous electron speed decision about what to do.  And, for example, responding to a ping might be an example.  Ping comes in, that's trivial to respond to.  It just swaps a couple bytes, changes the type code from an echo request to an echo reply, and sends it back out to the place it came from.  So that requires no thinking.



The problem is there are some types of packets that require some thought.  And the BlackNurse low-bandwidth packet-rate attack leverages that.  They use an ICMP type 3 code 3 packet, which is the type 3 is the generic class of Destination Unreachable.  That's one of the - ICMP itself is meant for sort of managing the plumbing of the Internet.  That's what the ping is, is a type of ICMP packet.  And the Destination Unreachable is something which, for example, a router will send when there's a problem.  And a classic problem is the traceroute.



A traceroute deliberately sends packets with short times to live, TTLs of, like, five.  And so after the packet has gone over five routers, the TTL has been decremented to zero.  Then the router sends back a Destination Unreachable timeout, saying sorry, this packet died, and the Internet requires me not to forward a packet whose TTL is expired.  If that weren't rigorously honored, packets would flow around the Internet forever, and then we really have a problem.  So everybody honors that.



Well, this particular packet, the Destination Unreachable/Port Unreachable, the type 3 of the class 3, must be handled.  RFC 1122, which is one of the old ones, one of the fundamental foundational RFCs, the Request for Comments, says:  "A host should generate Destination Unreachable messages with code 2, for Protocol Unreachable, when the designated transport protocol is not supported."  So that's another example of a plumbing.  It's like, sorry, you want TCP, but I don't have any.  And so it sends back something on ICMP that by definition everybody must support.  Or, continuing, it says:  "...or 3, Port Unreachable, when the designated transport protocol, for example UDP" - or maybe TCP - "is unable to demultiplex the datagram, but has no protocol mechanism to inform the sender."



So, for example, "A Destination Unreachable message," they continue, "that is received must be reported to the transport layer.  A transport protocol that has its own mechanism for notifying the sender that [dropout] unreachable, for example TCP, which sends reset packets, must nevertheless accept an ICMP Port Unreachable for the same purpose."



So what that says is, in the fundamental wiring of the Internet, when a router receives that particular - an ICMP type 3 code 3, it cannot deal with it itself.  It has to attempt to forward it.  And what that practically means is that it's - a packet falls out of the fast switching fabric into the processor, and there we hit a packet-rate limit.  So what has been found is this is an ongoing attack.  There are attackers in use now that are sending ICMP 3,3 packets where just 15 to 18Mb is able to take a major site offline because there is not a way to short-circuit the processing of that.  It is crucial to have it handled, so you can't put in a filter rule to block it and drop it, which they would like to.  You have to pass it on.  Otherwise all kinds of other stuff in the Internet would break.  So an interesting new way of bypassing old safeguards and essentially bringing a major provider down with a single host over the Internet.  Unfortunately, these guys are getting very creative.



LEO:  Wow, wow, wow.  And that, my friends, is the BlackNurse Attack.  That's what that is.



STEVE:  For some reason.



LEO:  For some reason no one will ever understand.  Well, we have run out of time.  But, fortunately, it's exactly when you've run out of material.  So it all works out so nicely.



STEVE:  Funny how that works.



LEO:  He's a master, my friends.  Our show, of course, is every Wednesday, 1:30 p.m. Pacific, 4:30 - did I say Wednesday?  Tuesday.



STEVE:  No, no, unlike dark matter, which I'm not sure they care about, but I just thought...



LEO:  I care.  I care.  I thought that was fascinating.  I don't understand what "information" means in that context.  But I know there's information in the event horizon of black holes; right?  They talk about...



STEVE:  Can't get out.  Can't get out.



LEO:  Yeah, talk about information not getting out.  So this is some use of the word "information" that physicists agree on that I don't understand.  But that's fine.  It's good enough for me.  It's all about the information.  That's what you get here every Tuesday, 1:30 Pacific, 4:30 Eastern, 19:30 UTC.  If you'd like to tune in and watch live, we'd love it.  But you don't have to because we make this show available every possible way.  Steve's got 64Kb MP3 audio on his site, GRC.com.  He also has a transcript.  Elaine Farris writes everything he says down.  By now she's probably dreaming of you.  She goes to sleep, and Steve's talking about dark matter and stuff.  So you can get that at GRC.com.



While you're there, pick up SpinRite, Steve's bread and butter, the only thing he charges us for.  And yet, and yet it's worth every penny.  GRC.com.  Get SpinRite, the world's best hard drive maintenance and recovery utility, and plenty of other free stuff.  Steve makes it all available at his website.  He also has a feedback form there, and maybe next week there'll be no BlackNurse, and we'll be able to do a Q&A.  So go to GRC.com/feedback, or tweet him.  He's @SGgrc and accepts direct messages from anyone on the Twitter:  @SGgrc.



The home page for this show on our site is TWiT.tv/sn.  It's also on YouTube.com/securitynow if you want to show your friends or share a link.  And of course you can subscribe at any podcast application because it's there.  And a lot of people collect every episode.  Collect all 586, kids.  Thanks for listening; and, Steve, we'll see you next week.  And soon we'll see you in-studio.



STEVE:  Yes, sir.  And soon you're going to be having a birthday, two weeks from today. 



LEO:  I is.



STEVE:  Yes, you are.



LEO:  I is.  And I understand you might be in town for that.  Next week, by the way, day before Thanksgiving.  No, two days before Thanksgiving.  So we'll have a turkey.  We should do the Turkey of the Week.



STEVE:  Rather than be a turkey.



LEO:  Yes.  I'd rather eat one than be one.  Thank you, Steve.



STEVE:  Leo.



LEO:  See you next time. 



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#587

DATE:		November 22, 2016

TITLE:		Mobile & IoT Nightmares

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-587.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss this week's major dynamic duo stories:  Samy Kamkar is back with a weaponized $5 Raspberry Pi, and el cheapo Android phones bring new meaning to "phoning it in."  Another big unrelated Android problem; watching a webcam getting taken over; Bruce Schneier speaks to Congress about the Internet; another iPhone lock screen bypass and another iPhone lockup link; ransomware author asks a security researcher for help fixing their broken crypto; Britain finally passed that very extreme surveillance law; some more fun miscellany, and more.



SHOW TEASE:  It's time for Security Now!. Steve Gibson is here.  We've got a response from the LessPass guy.  We're going to talk about some amazing wild hacks, as always, in IoT and mobile, and a breakthrough in space travel.  Or is it?  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 587, recorded Tuesday, November 22nd, 2016:  Mobile and IoT Nightmares.



It's time for Security Now!, the show where we protect your security, now, with this guy, Steve Gibson.  He's the security guru.



STEVE GIBSON:  Little distracted.



LEO:  What are you looking at?  What are you looking at over there?  Bandwidth?



STEVE:  Well, yeah.  So I was talking to you before the show.  I wanted to, for what it's worth, apologize to our listeners for the crappy audio that we had last week.  And video, for those of you who also saw that.  I don't know that it's going to be any better.  We can hope.  Last week our traffic was being relayed through Microsoft.  And in fact, on the first page of the show notes I show four different sets of traffic that arose.  The bulk of it was, in that first line, 60 megabytes, or maybe that's megabits.  I'm not sure what their designations are there.  But it was all being bounced through, I mean, at my end the traffic was going to Redmond.  Then there was a brief attempt to send it to Rio de Janeiro at Telemar Norte Leste in South America.



LEO:  What?



STEVE:  Then there was an attempt to send it to Microsoft in Washington, Virginia; and then another one to Microsoft in Chicago, Illinois.  So the problem is this is a proprietary teleconferencing system.  This is not our own.  We're completely victims to what Skype decides to do.  And, unfortunately this week, I'm looking at the technical information here, and UDP relay is up again.  It used to say "direct connect."  I'm telling Skype to use a port, like to specifically bind to a specific port, and that's mapped out to the Internet, and Skype knows that.



So I have a listening port on my network that allows you guys, even if you didn't have port mapping statically port-mapped, it allows you to reach me directly.  And so what we've traditionally had was a direct connection between you and me.  And so the good news is then we're only dependent upon our systems at each end and the network between us.  But with a UDP relay, all of our traffic, yours coming to me and mine coming to you, bounces through Redmond.  And so if they hit a rough patch, we suffer.  And I can't see anything at my end that I can do differently or that you can do differently.



They did announce, Microsoft did say about a year ago that they were going to be abandoning the peer-to-peerness of Skype.  And, I mean, among other things, this does allow them, if they needed to, to monitor their Skype conferences.  In a direct connection, they can't monitor for law enforcement reasons.  This gives them the ability to do so.  So anyway, I don't know how long it's been relaying.  I've heard some of our listeners say that, oh, like for the last eight weeks, I mean, they were quoting which episode it was, like 580, where it began to be a problem.  So let's hope it's better this time.



LEO:  Yeah.  That's all we can do.



STEVE:  Yeah.  So this was going to be a Q&A.  And once again - and I have so many good comments from our listeners.  I just keep pushing them down because this was another week - I hope the hackers take Thanksgiving off.  Just, you know, hackers, just stop.  We've got too much.  So this podcast, 587, I decided I had to title "Mobile & IoT Nightmares" because there's just too much that happened that we need to talk about.  The top two stories of the week is our old friend Samy Kamkar, whom we've discussed.  He's a hacker of some repute.  He's back with a weaponized $5 Raspberry Pi that actually follows up on a story we covered a couple months ago, in September.



Then we've got the problem of el cheapo Android phones bringing new meaning to the term "phoning it in."  There's a different big unrelated Android problem.  Rob Graham, our friend from Errata Security, who was the original author of the BlackICE IDE firewall, watched his webcam getting taken over and has some interesting feedback about that.  Bruce Schneier spoke to Congress about the sorry state of the Internet.  And despite being an anti-government, almost an activist, you know, we've sort of seen Bruce almost kind of get radicalized after the Snowden stuff, it's a little frightening to hear what he has to say.



Yet another iPhone lock screen bypass, and an iPhone lockup from a link.  A weird instance of a ransomware author asking a security researcher for help in fixing their not-quite-right crypto, and the ethical dilemma that's put him in, which I'll explain.  We've got legislation that has been looming in Britain passed, and some miscellany, and more.  So I think another great couple hours of podcast.



LEO:  Sounds good to me.  All right.  Now that you have resumed your normal size on the screen behind me, let's get going. 



STEVE:  Yeah.  So we'll keep our fingers crossed about the quality of the connection.  I wanted to follow up, in sort of a heartwarming fashion, about this guy who I kind of beat up on last week, the author of LessPass.



LEO:  Yeah, I was wondering, if he was listening, how he was going to feel about that.



STEVE:  Yeah.  So he was listening.  And in fact we made about a 10-minute snippet of the podcast, a TWiT Bit, titled by your guys, or maybe I said it and they just used the title, I don't remember, but it's on YouTube, "The Horror of LessPass."



LEO:  Oh, I'm so sorry.  But, well, I mean, frankly, it wasn't inappropriate.



STEVE:  No.  And so, but I'm so impressed with the nature of his response.  And there are some good security lessons in here, too.  So someone named @numerodix tweeted to Vincent - that's the first name of the author - and me, "That's the first time I've seen a code review in a podcast.  Pretty cool."  Speaking of, you know, my explaining as I did last week, where the week before was here's the problems with the concept, with the user interface; and then Adam, one of our listeners, shot me a note saying, "Did you look at the code?"  And that's, of course, what we talked about last week, was how broken this was as a generator of high-entropy passwords, which it isn't because by design its decisions made it predictable.  So then Vincent replied, so he must be following me because he would have seen that - oh, no, actually this @numerodix did mention him.  So it went to him, too.



LEO:  Yeah.  We get, you know, the thing is, even if people don't listen to the show, there are plenty of people on Twitter who will tattle on us.  So I assume that anything we say about anybody will get back to that person via Twitter.



STEVE:  So he responds:  "Yes, I'm obviously not happy with this video, but I'm glad that people are studying the code in depth."  Okay, well, now, that's, like, remarkably right for him to say.  And then he tweeted to me the link to "The Horror of LessPass" on the TWiT netcast network.  And he sent me a link to the GitHub thread where he's completely explained his position.  And so he wrote, "The interview went to says," and so he's probably a non-English speaker, so he meant "went on to say."  And then he quoted me saying, "Your goal is to make your password as random as possible, so anything that reduces randomness or entropy is going to reduce the effectiveness of your password and is going to increase its brute-forcibility."



And then he said:  "Understanding our mistakes:  We use patterns to create passwords with complex rules like no consecutive vowels or can't start with a number.  We made two mistakes," he wrote.  "First, we did not understand at the beginning that the entropy of the generated password increased the brute-forcibility of the master password."  Okay, and he doesn't quite understand the problem there, but that's okay.  "I took the idea of password templates from Master Password algorithm.  We misunderstood and took for granted what we read."  Then he said:  "Then it was to define as template by default consonants, vowels, et cetera, instead of a more random one as X with the full character set."  So he does understand what the requirement is for a high-entropy password.



And then, on the topic of open source, he wrote:  "And for anyone who thinks they do well at first, or who think that open source does not help, on the contrary, we believe that nobody does well at first; and, thanks to the community scrutiny and critical studies of the code, this kind of tool becomes more robust the longer it lives."



Then he said, under how it feels:  "The video is obviously a setback for us, especially after the euphoric past week where we went from about 100 to 1,600-plus stars.  But we are glad that people review our code in depth, and this came up early on."  And then, finally, actions:  "We will use the full alphabet in the next version by default.  We will probably increase the default length of generated passwords.  So in the future we will describe, with drawings, the future algorithm and its implementation.  We will simplify the code to help everyone understand how it works.  And we hope you will keep your eyes peeled for mistakes and stay critical to the code."



So to all that I say bravo.  I mean, we know that's all good news.  The lesson, of course, is - and I think this is an important takeaway for our listeners, who were all excited about the appearance of this new interesting password generator.  And so the takeaway is, looks nice on the surface.  I immediately saw reasons why, on the surface, it would be impractical to use.  And then what we discovered is, again, thanks to it being open source - although, as I also said last week, if you generated three or four passwords with it you'd quickly notice that they were all the same in terms of what characters were appearing where, and it was only the choice of characters that were changing.  So even its behavior would have been quite clear.  And as I said last week, I mean, we have essentially a security and cryptography amateur who's writing code.  There's nothing wrong with that except that 1600-plus stars indicated that lots of people grabbed it and said, "Oh, what a fabulous idea, I love this," and they're off and running.



Now, in the thread that followed, some other people noted, well, you know, if you change your algorithm, that's going to change the passwords generated with the same parameters that Version 1 generated, so you're going to break everyone's Version 1 passwords.  And so he's planning to have them both available for some overlap period and try to migrate people.  Anyway, it's a mess.  But I have to tip my hat to Vincent.  His attitude is terrific.



But this should be a lesson to us, sort of amplifying on what I said last week, that this stuff, and in fact the whole content of this podcast, is demonstration of this stuff is hard.  And there are certainly malicious actors that hide what they're doing, or use crypto for malicious purposes.  Then there are people like Vincent, who has clearly the best of intentions, but shouldn't be offering to the public something that hasn't been tested and looked at.  And I think that's probably the responsible thing to do.  He should use it for himself and maybe solicit some feedback in a more controlled fashion before just putting it out there and saying, "Here's a free password generator, have fun."  So anyway, again, I just wanted to say,  you know, I think his heart is in the right place.  But that isn't enough.  You actually have to understand a lot in order to do this right.



Now, speaking of understanding a lot, as you said, Leo, you're going to have Samy Kamkar on, which I think will be great.  He is a real character.  And, I mean, and a class-act hacker.  I have a video, he's produced a video of what he has done recently that was up there as one of the top two stories of this past week, just in terms of our listeners making sure I knew about it.  He's created something he calls "Poison Tap."  And it's exploiting locked computers over USB.  And he went public with this last Wednesday.



Now, if you ask yourself, why does that sound familiar, it's because this is a weaponized extension of the exploit we discussed in early September, a different hacker named Rob Fuller.  And we gave it full coverage in the beginning of September.  He created a posting, "Snagging Creds from Locked Machines."  And at the time he was using a much more expensive, I think it was $155 computer-based USB dongle.  And the idea is, and we discussed it then, that when you stick a USB into a machine that is on, even if it's locked, if the lid's closed, if it's, like, inaccessible, if that USB device claims through the USB enumeration to be a network adapter, unfortunately, it instantly gets all kinds of unquestioned privilege.



And so Rob showed us early in September how he was able to take a USB Ethernet device and exploit some features of DHCP, the dynamic host configuration protocol, with another person's responder software, in order to essentially get the password hashes from the system and then perform an offline brute-force attack in order to crack the passwords.  And this is a problem that Windows has had for a long time.  Their earlier, especially their earlier password hashing was not very good, you know, the old LANMAN.  We were talking about that a lot a decade ago.



So that was then.  Now Samy came along and said, "Oh, that's interesting."  And he rolled up his sleeves and just went to town.  So this thing, he calls it "applied hacking" is sort of his banner.  And so Poison Tap siphons cookies, exposes the internal router, and installs web backdoors on locked computers.  It produces a cascading effect by exploiting the existing trust, as he describes it, in various mechanisms of a machine and network, including USB or Thunderbolt, DHCP, DNS, and HTTP, to produce a snowball effect of information exfiltration, network access, and installation of semi-permanent backdoors - using a $5 weaponized Raspberry Pi Zero.



So essentially the problem is, when a network interface spontaneously appears, the operating system enumerates it, says, oh, you know, the user must want to get on that network.  And so the first thing that happens is it receives a DHCP query.  Well, DHCP is very powerful.  And we've talked about it extensively in the past.  The minimum thing that it does is give you an IP address.  It can also give you DNS.  And it can also declare various routing parameters, that is, DHCP is way more than just IP and DNS.  There's an extensive vocabulary of what it's able to offer.



So by leveraging the fact that an innocent computer made the mistake of querying a very powerful malicious DHCP server - which nothing prevents, essentially - he's able to roll that into, sort of incrementally, by gaining a foothold, doing something, and then pushing it further, and then substantiating that position, basically just walk into your computer and take it over, ending up, for example, rerouting all of the traffic that the machine is sending on a valid interface through it.  So it's able to, if you're not using HTTPS to strip headers, to prevent security provisions that are by default available in HTTPS because of course the tunnel is unencrypted.  So by intercepting the traffic he's able to - basically this is a full exploit by somebody who knows what he's doing, very creative, to completely compromise the browser aspect of web surfing on that machine, even to the point of leaving some stuff behind, which continues to have an effect.



So it's a breathtaking compromise, all based on this idea that a USB device which should not be trusted might be a network, and the fact that our systems at the moment, they don't pop up a dialogue.  They don't make you click okay to confirm that you want to enumerate this newly appeared network device.  They just do it across the board.



So he says, for features:  "Emulates an Ethernet device over USB; hijacks all Internet traffic from the machine despite being a low priority, unknown network interface; siphons and stores HTTP cookies and sessions from the web browser for the Alexa top one million websites."  Now, he does that because, remember, any time your browser responds to a request from one of those sites, it will send whatever cookies it has.  So Samy injects a million tiny hidden iFrames into the page.  Each of those makes a query to one of a million websites.  And that query will contain all the cookies they have.  He intercepts that and grabs them.  So he has all the cookies that your browser has for Alexa's top one million sites.



And if any of your sessions are statically logged on, like you click the box "Remember me" so you don't have to reauthenticate every time, well, that means that that cookie represents you for your logged-on session.  And that's then exfiltrated, which his technology also does.  A remote hacker could then immediately jump on, authenticating as you on that site.  Just like you open, you know, just like you went to the site fresh, and it remembered that you had been logged on before, and you said don't ask me anymore.



He's able to expose the internal router - that is, your internal router that you're connecting to the Internet by - to an external attacker, making it accessible remotely via an outbound WebSocket and DNS spoofing.  He can install a persistent web-based backdoor for HTTP cached objects for hundreds of thousands of domains.  He even poisons JavaScript libraries being sent by major content delivery networks; does not require the machine to be unlocked.  And these backdoors and remote access persist even after the device is removed and the attacker, as he puts it, "sashays away."  So it's a great video.  I'm delighted that he's going to be on Know How because I'm sure - and I would give our listeners a pointer to that, Leo.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Because I'm sure they will get a kick out of it



LEO:  I'm not sure what week.  But, yeah, it'll be fun, yeah.  And then we will, the following - as soon as they tape that, we'll put a bit of it into New Screen Savers.  But, I mean, it's one of those things where I think we want to spend some significant time with him, demonstrating the whole thing.



STEVE:  Yeah, well, and for securing against it, notice that everything I was talking about, that is, in terms of traffic capture, since he isn't and probably can't mess with cookies, I mean, I'm sorry, mess with certificates, there's no way for him - and he says that all of this is HTTP.  So for servers to secure against this, the only thing servers can do is use HTTPS exclusively; use HSTS, the Strict Transport Security, to allow browsers - because when users don't put HTTPS into the browser, they typically just www.



And we've talked about how unfortunate it is that browsers still try HTTP as the default protocol.  It'll be interesting to see when that changes.  I wouldn't be surprised if that's something that we see Google lead with, with Chrome, when their tests have demonstrated that it won't break too many things.  Because it would sure be nice if at some point browsers, instead of defaulting to HTTP, first tried HTTPS, or maybe tried them both at once and used the more secure, the HTTPS, if it also succeeds, when they haven't been told one way or the other.



And then, finally, remember that cookies, when cookies are set, they can have a secure flag set which prohibits the browser from sending them with its queries over a non-HTTPS connection.  So if all the cookies, like session cookies, for example, which are sensitive, if those had the secure flag set, then they would not be exposed in an HTTP attack.  And on the desktop side, he says, you know, that's fine for the servers.  On the desktop side, Samy suggests, as he put it, "Adding cement to your USB and Thunderbolt ports can be effective."



LEO:  Not on my new MacBook, no way.



STEVE:  No.  And he says:  "Closing your browser" - that is, shutting the browser down.  "Closing your browser every time you walk away from your machine can work, but," he says, "is practically impractical.  Disabling USB or Thunderbolt ports is also effective, though also impractical."  And he says:  "Locking your computer has no effect, as the network and USB stacks operate while the machine is locked."



LEO:  Oh, that's interesting.



STEVE:  Yeah, it is.  "However, going into an encrypted sleep mode," meaning, you know, where it writes the RAM out and encrypts it...



LEO:  Hibernation.



STEVE:  Hibernation, right, he calls it "encrypted sleep," "...where a key is required to decrypt the memory" - and he says, for example, FileVault 2 and deep sleep - "solves most of the issues as your browser will no longer make requests, even if woken up."  And for all this, the source code is on GitHub.  So, and this is not, I mean, there's no one to disclose this to responsibly.  This we knew about in early September.  He's just taken it to its logical extent, that is, oh, wow, you mean I can get a - the machine is going to make a DHCP query of my own little custom DHCP server when I plug it into USB?  Oh, I know what I can do with that.



And so here's another instance, as we often said, that attacks never get worse, they only get better.  And so this is three months' worth of evolution of a problem.  And again, this isn't exploiting any vulnerability.  There's nothing to fix anywhere except, maybe, if a machine is locked and closed, you might wonder why the OS would default to enumerating and bringing that port online.  And maybe even the default option should be always prompt before recognizing a new network connection to this machine because, as we're seeing, network connections are dangerous.  They just get up to too much mischief.



Now,  the second biggest story, or equally big, but the other one of the top two of the week was the discovery of very widespread and clearly deliberate malware installed in low-end, low-cost Android mobile devices.  A company or a group we've never discussed before, I don't remember us mentioning them, Kryptowire with a "K," discovered mobile phone firmware that was transmitting what they say throughout here, PII is the acronym that we've used before, Personally Identifiable Information, without users' consent or disclosure.



Kryptowire, and this was last Tuesday, and so a week ago, while we were doing the podcast, "identified several models of Android mobile devices that contained firmware that collected sensitive personal data about their users and transmitted this sensitive data to third-party servers without disclosure or the users' consent.  These devices were available through" - and "were" seems to be the operative term there, as I'll explain in a second - "through major U.S.-based online retailers like Amazon and Best Buy and included popular smartphones such as the BLU R1 HD."



Now, who's Kryptowire?  Well, first of all, they're the real deal.  Kryptowire was jumpstarted by the Defense Advanced Research Projects Agency.



LEO:  Oh, wow.



STEVE:  Also known as DARPA, and also the Father of the Internet; and the U.S. Department of Homeland Security. Kryptowire provides mobile application security analysis tools, anti-piracy technologies, mobile app marketplace security analytics, and Enterprise Mobility Management solutions.  Kryptowire was founded five years ago, in 2011, and is based in Fairfax, Virginia.



LEO:  Oh.  Oh.



STEVE:  And has a customer base ranging from government agencies to national cable TV companies.



LEO:  Huh.



STEVE:  So, yes, not some obscure little group somewhere.  These guys are connected.  So, first of all, I wanted to substantiate that this wasn't some random obscure phone that five people had.  In August this year, so five months ago, or four months ago, Ars Technica reviewed this BLU R1 HD under the title:  "A $60" - and actually it's 50.  Maybe the price has dropped since then.  It's zero now - "A $60 Amazon phone that's way better than Amazon's actual phone."



LEO:  Mm-hmm.  Yeah, we've talked about these BLU phones before.  They also make a Windows phone.  They're just cheap phones.



STEVE:  Right, they're just cheap phones.  And then, you know, "Selling your lock screen to Amazon," writes Ars, "cuts the cheap phone's price in half."  And it's funny because on the - oh, and BLU stands for Bold Like Us.  Yeah.



LEO:  Oh, I didn't know that.



STEVE:  Yeah.  On their site they proudly boast - "The Rebel in You" is their slogan - starting at $49.95, exclusively on Amazon.  Now, if you go to that link, Amazon says "currently unavailable."  But it has 3,202 reviews.  So again, not obscure.



PC Magazine looked at it this summer.  They said the pros, in their summary:  "Inexpensive, study build, solid battery life, latest Android software, dual SIM card slots, and expandable storage."  Cons was "Prime-subsidized phone includes Amazon bloatware and advertising and" - as we're about to find out - "and a lot more."  And they were unimpressed by the camera.  But they said, as their bottom line:  "The BLU R1 HD is an unlocked Android phone with a good balance of performance for the price, making it a fantastic value for Amazon Prime users and regular customers alike."



And even Wired, in July, I mean, so everybody was covering this, saying, wow, 50 bucks for a completely workable phone.  And we know that many people are price-based shoppers.  They're price-sensitive.  And so if there's, like, this well-reviewed phone, it may have some limits, okay, so it's not a great camera, but otherwise, oh, Android, you know, everybody else that I know has one of those, so what the heck?



Anyway, so Kryptowire continues, saying these devices - so this is what they were getting up to that they found - actively transmitted user and device information, including the full body of text messages, contact lists, call history with telephone numbers, unique device identifiers including the IMSI, the International Mobile Subscriber Identity, and the IMEI, the International Mobile Equipment Identity.  "The firmware could target specific users as text messages matched remotely defined keywords."  So, I mean, this isn't casual.  This is seriously weaponized malware.



"The firmware also collected and transmitted information about the use of applications installed on the monitored device, bypassed the Android permission model, executed remote commands with escalated system privileges, and was able to remotely reprogram the devices.  The firmware that shipped with the mobile devices and subsequent updates allowed for remote installation of applications without the users' consent and, in some versions of the software, the transmission of fine-grained device location information.



"The core of the monitoring activities took place using a commercial Firmware Over The Air update system that was shipped with the Android devices we tested and were managed by a company named Shanghai Adups [A-D-U-P-S] Technology Co., Ltd.  Our findings," they write, "are based on both code and network analysis of the firmware."  So they reverse-engineered the code and intercepted and looked at the actual traffic that the phones were generating.



"The user and device information was collected automatically by this firmware and transmitted periodically without the users' consent or knowledge.  The collected information was encrypted with multiple layers of encryption and then transmitted over secure web protocols to a server located in Shanghai.  This software and behavior bypasses the detection of modern anti-virus tools because they assume that software that ships with the device is not malware [by definition] and thus is whitelisted.



"In September 2016, Adups claimed on its website to have a worldwide presence with over 700 million active users, and a market share exceeding 70% across over 150 countries and regions with offices in Shanghai, Shenzhen, Beijing, Tokyo, New Delhi, and Miami."  They're also in Florida, is actually where their U.S. headquarters is.  "The Adups website also stated that it produces firmware that is integrated in more than 400 leading mobile operators, semiconductor vendors" - oh, help us - "and device manufacturers spanning from wearable and remote devices to cars and televisions."



And then, in a chart in their description, Kryptowire compares this with something that you and I, Leo, talked about.  You'll remember five years ago there was this spyware called "Carrier IQ" which was discovered in some phones that was an early version, I mean, basically it was them, their sort of analytics system installed by a third party with the carrier's, you know, at the carrier's behest so that they could collect data on their users.  Once that came to light, of course, it was removed.  So in their chart, basically, they go through an AB comparison with checkboxes and red X's about which features this thing supports and which features Carrier IQ - it was more sanctioned, even though it raised a lot of concerns at the time.



LEO:  Oh, it was installed by carriers at the time; right?



STEVE:  Correct.  Correct.



LEO:  And I have a feeling these both have the same purpose, which is not for government snooping, but for advertising, right, to get information about you so they can serve you ads.  That was the purpose of the Carrier IQ, as well.



STEVE:  Yeah.  Although this is, I mean, this was - I guess the question would be who knew about this.



LEO:  Right.  BLU says they didn't.



STEVE:  Correct.  



LEO:  Right.



STEVE:  Correct.  So anyway, basically we have a huge number of very inexpensive phones that, across the board, are, I mean, they are pocket spyware machines.  Everything that is going on is being reported back to the mothership over these phones.  Now, Amazon, of course, immediately took it off the market.  And I hope this will be, I mean, I hope there's some downstream lesson to be learned by the likes of Amazon because, of course, their reputation is there.  They lowered the price, cut it in half in order to have an Amazon-populated lock screen.  So they bear some responsibility, I would imagine.  And I hope that a lot of customers are going to have to say or will say, you know, I've had this for six months, but you're taking it back because, you know...



LEO:  Oh, yeah.  Oh, yeah, yeah.



STEVE:  ...I bought this, and it's got spyware in it.  Wow.  And I don't know what this means.  Amazon tried to do their own phone, which was a colossal failure.  So this has been their new approach.



LEO:  Well, they do this with a lot of phones, including flagship phones and stuff.  They just subsidize them and sell them.



STEVE:  Right, right.



LEO:  I don't, yeah, I mean, I don't really blame them for this.  It'd be hard, I mean, nobody knew about it; right? 



STEVE:  Yeah.  I mean, yeah.  And they're also selling webcams that are being exploited by the Mirai botnet and other malware.  So we'll get to what Bruce Schneier says about this and where the world is heading pretty soon.



So right on this topic, too, another company, AnubisNetworks, found another Android phone - well, and unfortunately it's also one of these BLU phones, the BLU group.  Their over-the-air update mechanism was extremely vulnerable to attack.  And Anubis wrote:  "In this article, we will be detailing an issue we discovered affecting a number of low-cost devices.  It allowed for adversaries to remotely execute commands on the devices as a privileged user, if they were in a position to conduct a man-in-the-middle attack.  The binary responsible appears to be an insecure implementation of an over-the-air mechanism for device updates associated to the software company Ragentek Group in China.  All transactions from the binary to the third-party endpoint" - get this - "occur over an unencrypted channel."



LEO:  Uh-oh.  And we know why that's a problem.



STEVE:  So you've got unprotected, unencrypted, which means unauthenticated, thus a man-in-the-middle, over-the-air update of the phone's firmware.  I mean, it's malpractice.  And they say, "...which not only exposes user-specific information during these communications" - so there is that, too; PII is exfiltrating - "but would allow an adversary to issue commands supported by the protocol.  One of these commands allows the execution of system commands.  This issue affected devices out of the box."  So no additional vulnerabilities to install, no compromise, just clean out-of-the-box.  So again, designed this way.  Now, I'm going to skip over a lot of the details here because there was one that just jumped out at me, which is where the term "malpractice" came from.



They said:  "We acquired one of the affected devices, a BLU Studio G, from Best Buy.  After building a passive network traffic-capturing system" - so they just tapped and listened - "an unencrypted transaction to the Ragentek head-end" - at the domain oyag[.]lhzbdvm[.]com, which that's just random gibberish.  So they just made up some domain name so that, you know, and they probably registered it with some really bottom-of-the barrel registrar so they didn't have to pay anything.  So just a garbage domain name was observed, that is, traffic, unencrypted transaction was observed "not long after proceeding through the Android first-use setup process on the device."



Now, get this:  "The device then attempted to contact two other pre-configured domains, which were previously unregistered until AnubisNetworks acquired them.  This gave us immediate visibility into the larger population of affected devices, which are detailed later in this article.  We were able to associate the network transactions back to specific binaries on the device which were the ones investigated as part of this analysis."  So they watched the device do a DNS query to this oyag[.]lhabdm[.]com.  Then they saw two additional DNS queries to the same oyag dot, but then prugskh[.]net and .com.  When they looked those up, the domains weren't even registered.  So they registered them.



LEO:  Oh, my god.  You don't even need a man in the middle.



STEVE:  No.



LEO:  Oh.



STEVE:  Oh, it's unbelievable.  I mean, this is where I said this is malpractice.  And so somebody in China...



LEO:  They forgot.  They forgot.



STEVE:  I mean, like, maybe they thought, well, you know, we'll register a couple more in case we ever need them for some reason.  And so they thought, well, but, you know, no reason to have a DNS server there because the primary one is there.  But the devices are still querying.  So Anubis registered those two wacky domains.  Then the devices started querying them.  And then they were able to respond and become part of the network, and thus enumerate what was going on.



They write:  "We have observed over 2.8 million distinct devices, across roughly 55 reported device models, which have checked into our sinkholes since we registered the extraneous domains.  In some cases, we have not been able to translate the provided device model into a reference to the real-world device."  You know, I mean, they're being passive.  They don't want to, like, reach in and figure out what's going on because that would be breaking laws.  So they're just passively monitoring traffic in, as they call it, in their sinkholes or their honeypots.



They write:  "These are the devices captured in the 'Others' category."  Oh, and on their page they show a big pie chart, and less than a quarter were BLU devices, and almost a half of the pie was "Other."  And then there were some small chunks, like three or four other manufacturers that they were able to identify the models.  And, you know, they're not big names.  They're people who chose to use Ragentek's firmware for whatever reason, and Ragentek didn't bother to even register the domains that their firmware was querying.  Just, you know, maybe they would need them some day in the future.  So, boy.



LEO:  Wow.



STEVE:  In their conclusion they said:  "This analysis revealed two critical discoveries:  First, the vulnerability described above allows for users to be subjected to significant attacks in positions where an adversary can perform a man-in-the-middle attack.  Secondly, this over-the-air binary was distributed with a set of domains preconfigured in the software.  Only one of these domains was registered at the time of the discovery of this issue.  If an adversary had noticed this" - I mean, and here we're glad that Anubis were the ones who found this.  "If an adversary had noticed this and registered these two domains, they would've instantly had access to perform arbitrary attacks on almost three million devices without the need" - as you immediately saw, Leo - "to perform a man-in-the-middle attack.  AnubisNetworks now controls these two extraneous domains to prevent such an attack from occurring in the future for this particular case."



And again, our lesson here is spend a little more money and buy yourself some more security, if that's something that you're interested in.  And I would imagine anyone within the sound of this podcast is interested in security.  So, wow.  And maybe you know people who have these low-end phones, and you can let them know or find out what make and model they are and whether they might be vulnerable to this.  Yikes.



LEO:  Really kind of stunning.



STEVE:  Oh, gosh.  It is.



LEO:  It's just it all feels kind of half-assed; you know?



STEVE:  Yeah, it is.  I mean, it absolutely is.  And this is where we are.  Here we're looking at the mobile side.  We'll get to IoT in a second.  But in weeks recently we've been talking about this disaster in IoT.  And what's happened is, and Bruce addresses this a little bit later in his presentation to Congress, it's a weird situation where we've got serious technology being mass-produced and used with no oversight.  And, now, and imagine if you're a U.S. government person who's responsible for the safety of the networks in this country, and you're reading this, that some Chinese firmware manufacturer has been selling phones in millions to citizens in the United States, and that these phones are all reporting back to Shanghai, and any of them can be taken over remotely.  That's a concern.



LEO:  Yeah.



STEVE:  Wow.



LEO:  Wow.



STEVE:  And this is not science fiction.  I mean, it sounds like, you know, 10 years ago this would have just been infeasible.  This is recent history now.  Incredible.



So the 'Net has been reporting, and in fact Christina Warren did a nice piece in Gizmodo on Friday on yet another iPhone lock screen bypass.  And these are crazy complicated now.  I mean, that's the good news.  The bad news is they exist.  So Christina wrote, her piece was titled:  "This Weird Trick Apparently Lets You Bypass Any iPhone's Lock Screen."  And in fact she had a bunch of people at Gizmodo try it on a range of phones, and they were successful.



She says:  "First, you need to call the phone you want to gain access to.  If you don't know the number, you can ask Siri, 'Who am I?' to get it."  And then she says:  "A FaceTime call will work as well.  Then, from the incoming call screen" - and I'm going through this because I want people to understand how crazy this is.  "From the incoming call screen, choose the 'Message' option and choose 'Custom.'  That opens up a screen to reply to the call with a message.  From here, you need to enable Voice Over mode" - and so this is really where the gotcha is, is in the interaction of Siri and the Voice Over mode - "by invoking Siri and saying, 'Turn on Voice Over.'  This will enable an accessibility feature that will read out items on the screen."  And I just hit the spacebar and lost my place.  On the screen.



"This is where it gets really tricky," as if that wasn't already.  "Then you need to double tap on the recipient filed on the message," that is, the name, "while also tapping on a random key on the keyboard.  This should open up a 'to' field on the SMS that will then let you search through contacts already on the phone."  And then she says in parens, "(You'll know you've gotten the bug to work when you see the tools pop up next to the compose message box.)



"At this point, you've already broken into the phone to a certain degree because you can see all of the contacts.  Pressing on an 'i' icon next to a contact should show details about the contact, which will then allow the user to create a new contact.  This is where the exploit really becomes useful.  Tapping on the 'new contact' button, a user can opt to add in a photo, and doing that will allow access to all the photos on the camera roll.  This basically means a skilled person could browse all of your photos without you knowing.



She writes:  "Tricks that let hackers bypass any iPhone's lock screen are hardly new, and they typically take a little bit of skill and luck.  And although the iDeviceHelp video and others like it are cropping up all over YouTube, it's always safe to remain skeptical about how dangerous these tricks might be.  As far as bugs go, this one feels fairly innocuous since it requires prolonged physical access to a device."  Although, you know, you can imagine law enforcement would love to know about this.  "And although you can access photos, actually doing anything with that data is a different story."



And all over the 'Net where this is being covered, the advice is simple.  If you disable Siri on the lock screen and Hey Siri, this stops the security hole.  If you do that, then at least you'll have some safety until Apple issues a proper fix.  And so my takeaway is somewhat different.  It's that, you know, here's a classic example of this all getting too complicated.  As we know, and as I often say on this podcast, complexity is the enemy of security.  And so Apple keeps adding this or that convenience.



And look at what Samy did, taking a simple concept of a USB device can be a network adapter, which he got from Rob in September when Rob noticed there was a way to exploit that, and how innocuous features, otherwise innocuous features can then use that entry point in order to exploit more.  That's exactly what this is.  So, and this is the problem is that certainly Apple doesn't want this to happen.  They're not happy because here they are all touting they're the best in security available anywhere.  And it turns out you can browse the pictures of somebody on a locked phone by cleverly winding your way through a bunch of incrementally revealed capabilities that somebody clever worked out.  It's hard to defend that this kind of behavior exists.  Yikes.



And Charlie Miller on 9to5Mac reports that - and just for what it's worth to our listeners, there is another iPhone-locking link going around.  This doesn't appear to do anything other than bring phones to a crawl and then finally resulting in them locking up.  It's an MP4 video.  Nobody technical has yet reverse-engineered this and figured out what's happening.  So what's happening is people are sending links around to each other, or posting them on Twitter, in a hah hah hah, you know.  And then the good news is you do - the bad news is you have to do a full restart of your phone, the power off cold boot, by holding the power button and the home button down, or on the iPhone 7 I think it's the power button and the volume up button.  That'll get you back.  So if anyone does get bit by that, just doing a - I would imagine ultimately all our listeners would say, okay, I guess I just have to do a hard reset to get back up.



LEO:  Why do you think it happens?



STEVE:  I mean, it could be anything.  This is probably a flaw in the MP4 file format interpreter.  And this is why it's a concern.  Right now all it's doing is messing up your phone.  For example, it could be a flaw that ends up consuming memory.  So it slowly burns up all of your memory.  The phone slows down until finally it just dies in a complete memory consumption, essentially a denial of service of your phone.  But this is also the kind of thing that, if not fixed in a week or two, we'll be reading about it having been weaponized.  Somebody will figure out what the flaw is because a hacker will go, oh, you know, I mean, they know that this is the way these things begin.



LEO:  It's like StageFright.  It's something in the media player.  And just as with StageFright, they'll figure it out.



STEVE:  Exactly.



LEO:  It's funny why media players seem to have a lot of problems.  I guess, but, you know, we go back to the issues that Microsoft had with playing back - with Metafile, Windows Metafile and stuff like that.  It's these renderers in Adobe Acrobat and [crosstalk]...



STEVE:  Yes, the interpreters.



LEO:  These renderers, interpreters are really running code when they're looking at the data file.



STEVE:  Right.



LEO:  In effect; right?



STEVE:  Right, yeah.  Our advanced formats now have, you know, they require interpretation in order to execute.  Even, I mean, even a decompressor is an interpreter.  It's reading instructions embedded in the stream and interpreting how to decompress the file to its original form based on what was there.  And so, you know, compressors, compression and decompression is everywhere.  And the takeaway is this stuff is hard.



LEO:  Yup.



STEVE:  I got a nice note from a listener, Ben Aylett, in Perth, Western Australia.  And his subject was, "Finally!"  He said:  "I'm a regular technology guest on a local radio talkback station in Perth, Western Australia, and I had a caller tell me about problems he was having with his hard drive.  Of course I went right to my favorite hard drive tool - which, of course, was SpinRite.  Thanks for making a great tool that I use at least once a month to help out others.  It usually brings drives back from the dead, and occasionally confirms my suspicions that the drive is beyond salvation.  Either way, I'm proud to share GRC and all your good work with my listeners and clients when I can."  So, Ben, thanks for sharing your success.



LEO:  Nice.  I don't have a commercial.  Just keep on going.



STEVE:  Yeah.



LEO:  I mean, if you want to have a drink, I could tap dance.  I could sing a song.



STEVE:  Yeah, I don't think the tap dance would go well over the audio.



LEO:  No.  By the way, audio and video looking good.



STEVE:  Oh, I'm glad.



LEO:  So I don't know why.



STEVE:  I'm going to - Mark Thompson is a Skype user.  I'll make some time before next Tuesday to mess around with him because he and I can look at each other's traffic and figure out - I'd just like to see why I'm unable to get a direct connection. 



LEO:  Strange, yeah.



STEVE:  I'm glad that we're doing better. 



LEO:  Good.



STEVE:  Okay.  So Robert Graham we've often spoken of.  He's Errata Rob, and ErrataSec is his site on the 'Net.  He's the original author of the BlackICE early firewall for PCs.  He posted his analysis of deliberately hooking a camera to the 'Net.  And in fact TechCrunch glued a whole bunch of his tweets together and made a better job of it.  And they wrote, and this is a great story:  "Here's an object lesson on the poor state of the so-called Internet of Things."



Now, this is interesting, too.  They said Robert Stephens.  And I thought, what?  Um, okay.  And they referred to him as Robert Stephens.  I've spoken to him.  But, I mean, maybe Graham is a pseudonym.  I did a little bit of digging around.  I couldn't find anything that indicates anything about a Robert Stephens.  Everything I found was Robert Graham.  And that's how I've always known him.  So maybe they know something I don't.  Anyway, they said:  "Robert Stephens plugged a WiFi-connected security camera into his network, and it was compromised in 98 seconds."



LEO:  Geez.



STEVE:  "Stephens," they wrote - we know him as Robert Graham - "a tech industry veteran" - certainly he is that - "wasn't so naive as to do this without protecting himself.  It was walled off from the rest of the network and rate-limited so it couldn't participate in any DDoS attacks."  Now, of course, we know from last week rate-limiting won't help necessarily because even low-rate attacks, if they're the BlackNurse - and, oh, by the way, we've heard from the people who named it, and we know why.  So we'll get to that in a minute.



So, I mean, he was being as responsible as he could be.  So Robert "monitored its traffic carefully, expecting to see, as others have, attempts to take over the device.  But even the most jaded among us," writes TechCrunch, "probably wouldn't have guessed it would take less than two minutes."  Robert wrote in one of his tweets, "Actually, it took 98 seconds for the first infection."  And he wrote that on November 18.



"Ninety-eight seconds after it jumped on the WiFi, the camera was attacked by a Mirai-like worm that knew the camera's default login and password."  So, now, imagine.  Even with the best intentions, you hook up the camera, and of course you've got to get it on the network in order to talk to it.  Before you have a chance to open up and boot your laptop and start configuring it, you've already lost control.  Ninety-eight seconds, and the camera is owned.  Wow.  This is our world.



"The worm - its advance agent, really - checked the specs of its new home and then downloaded the rest of itself onto the device and, had Stephens not locked it down beforehand, would then be ready to participate in all manner of online shenanigans.  The camera, a cheap off-brand one from a company that sells smartwatches for $12, isn't exactly best-in-class.  This type of thing could be fixed with a firmware update or, in some cases, by simply changing the default password, but not everyone knows to do that."  I mean, most people don't.  They just plug it in and, oh, look, when they're out at the restaurant, they can see their front yard or their living room or the baby's room, whatever.



"And even the most tech-savvy people might not get that done in two minutes.  Better-quality devices will almost certainly be better protected against this kind of thing" - exactly the point I've been making - "and may, for example, block all incoming traffic until they're paired with another device and set up manually.  Still, this is a good reminder that it really is a jungle out there."  And remember, now, also the other problem we have is that these devices were not designed for us, listeners of the podcast.  They're designed for the hundreds of millions of people that want a camera, and so they buy one.  And they plug it in and point it in the direction they want, and then they read the instructions that say go to this website and look at yourself.  I mean, these things are just - people are installing spies, literally and figuratively, in their homes constantly now as a consequence of what has happened.



So Bruce Schneier gives Congress some sobering truth.  The Daily Dot reported on this, saying:  "Speaking before members of Congress, the Internet pioneer" - referring to Schneier - "made clear the dangers of the Internet of things" - now, this is what they need to hear - "saying, 'The Internet era of fun and games is over.'"  The Dot wrote:  "Internet pioneer Bruce Schneier issued a dire proclamation in front of the House of Representatives' Energy & Commerce Committee last Wednesday:  'It might be that the Internet era of fun and games is over because the Internet is now dangerous.'



"The meeting, which focused on the security vulnerabilities created by smart devices, came in the wake of the October 21 cyber attack on Dyn that knocked Amazon, Netflix, Spotify, and other major web services offline."  Oh, and speaking of Dyn, by the way, Oracle has just bought them.



LEO:  Yeah, is that a coincidence?  That's weird; right?



STEVE:  It is weird.  I was wondering if their stock was depressed as a consequence of the cyber attack, making them vulnerable to purchase.



LEO:  Right.



STEVE:  "Schneier's opening statement provided a clear distillation of the dangers posed by connected devices."  And there is a video of him, for anyone.  But for the podcast we've got all of the good points pulled out.



Here's how he framed the Internet of Things, or what he later called the "world of dangerous things."  So Bruce says, speaking to Congress:  "As the chairman pointed out" - the chairman of the committee - "there are now computers in everything.  But I want to suggest another way of thinking about it in that everything is now a computer.  This is not a phone.  It's a computer that makes phone calls.  A refrigerator is a computer that keeps things cold.  ATM machines are computers with money inside them.  Your car is not a mechanical device with a computer.  It's a computer with four wheels and an engine."



LEO:  Yeah, especially my car, which is basically an electric - a computer on top of an electric go-cart.



STEVE:  And let's hope it goes forward.



LEO:  Oh, my god, yeah, exactly.  I mean, it's so obvious that everything is drive-by-wire on that Tesla.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  And he says:  "And this, gentlemen, is the Internet of Things, and this is what caused the DDoS attack we're talking about."  He then outlined four truths he's learned from the world of computer security, which he said is now "everything security."



First principle, first of the four:  Attack is easier than defense.  And of course that's one of the principles that we live by on the podcast.  Bruce said:  "Complexity is the worst enemy of security.  Complex systems are hard to secure for an hours' worth of reasons" - which he did not go into because they would have glazed over - "and this is especially true for computers and the Internet.  The Internet is the most complex machine man has ever built by a lot, and it's hard to secure. Attackers have the advantage."



And I really like that.  Think about it.  We tend to look at the Internet in pieces because we deal with it in pieces, you know, things that you connect to it.  But Bruce flipped this around, I think, in a really interesting way, thinking of the Internet itself as an entity and with all of these computers on its endpoints.  It is the most complex machine we have ever built by a huge margin.  



His second principle:  There are new vulnerabilities in the interconnections.  And in fact this is exactly that iPhone lock screen point, you know, it's the way things interact.  And it's the same thing with Samy's exploit of an enumerated network interface.  It's the interactions of individual things that are not by themselves devastating, but they'd be combined.  Bruce said:  "The more we connect things to each other, the more vulnerabilities in one thing affect other things.  We're talking about vulnerabilities in digital video recorders and webcams that allowed hackers to take websites.  There was one story of a vulnerability in an Amazon account that allowed hackers to get to an Apple account, which allowed them to get to a Gmail account, which allowed them to get to a Twitter account."  I think he's talking about Mat's.



LEO:  Yeah, that's Mat Honan's attack, yeah.



STEVE:  Yeah.  "Target Corporation, remember that attack?" he says?  "That was a vulnerability in their HVAC contractor that allowed the attackers to get into Target.  And vulnerabilities like this are hard to fix.  No one system might be at fault.  There might be two secure systems that come together to create insecurity."



Principle 3:  The Internet empowers attackers.  Bruce said:  "Attacks scale.  The Internet is a massive tool for making things more efficient.  That's also true for attacking.  The Internet allows attacks to scale to a degree that's impossible otherwise.  We're talking about millions of devices harnessed to attack Dyn; and that code, which somebody smart wrote, has been made public.  Now anybody can use it.  It's in a couple dozen botnets now."  Actually, it's 52, as we reported last week.  "Any of you can rent time on one dark web to attack somebody else."  He says, "I don't recommend it, but it can be done.  And this is more dangerous as our systems get more critical.  The Dyn attack was benign.  A couple of websites went down.  The Internet of Things affects the world in a direct and physical manner:  cars, appliances, thermostats, airplanes.  There's real risk to life and property.  There's real catastrophic risk."



And, finally, his fourth principle:  The economics don't trickle down.  He says:  "Our computers are secure for a bunch of reasons.  The engineers at Google, Apple, Microsoft spent a lot of time on this.  But that doesn't happen for these cheaper devices.  These devices are a lower price margin.  They're offshore.  There's no teams.  And a lot of them cannot be patched.  Those DVRs are going to be vulnerable until someone throws them away.  And that takes a while.  We get security for phones because I get a new one every 18 months.  Your DVR lasts five years, your car 10, your refrigerator 25.  I'm going to replace my thermostat approximately never."



LEO:  But you remember, I told you the story about the guy who called the radio show who had a five-year-old Samsung refrigerator with Internet access that wasn't working anymore because the API in the Google Calendar had changed?  You know, this is a problem.  Refrigerators last 25 years.  The Internet, you know, a year or two, everything's different.



STEVE:  Yeah.  And he says, "So the market really can't fix this."  And this is a point that I've been making recently, too.  The point being consumers don't know and may not care.  And clearly the Chinese manufacturers in Shanghai who are registering domains that their firmware is querying, but not even bothering to acquire the domain names, they don't care, either.  So again, the market can't fix it.  So Bruce then laid out his argument for why the government - and this is Bruce, too.  I mean, this is, I mean, he's no fan of government intervention.  This is a little bit like Linus Torvalds or Richard Stallman saying they want more government involvement.



So he laid out his argument for why the government should be part of the solution, and the danger of prioritizing surveillance over security.  And I'm really glad they heard this.  Bruce said:  "It was okay when it was fun and games.  But already there's stuff on this device" - and I guess he was holding, oh, he actually was, I saw a picture, he's holding up his phone - "that monitors my medical condition, controls my thermostat, talks to my car.  I just crossed four regulatory agencies, and it's not even 11:00 o'clock.



"This is something that we're going to need to do something new about.  And like many new agencies in the 20th Century, many new agencies were created:  trains, cars, airplanes, radio, nuclear power.  My guess is that the Internet is going to be one of them.  And that's because this is different.  This is all coming.  Whether we like that the technology is coming, it's coming faster than we think.  I think," Bruce said, "government involvement is coming, and I'd like to get ahead of it.  I'd like to start thinking about what this would look like.



"We're now at the point where we need to start making more ethical and political decisions about how these things work. When it didn't matter - when it was Facebook, when it was Twitter, when it was email - it was okay to let programmers" - and then he interrupts himself sort of - "to give them the special right to code the world as they saw fit."  And remember, Bruce is, like, industrial-strength cryptographer.  I mean, you know, he did Blowfish and Twofish and the Yarrow pseudorandom number generator.  I mean, he knows what he's talking about.



He says:  "We were able to do that.  But now that it's the world of dangerous things, and it's cars and planes and medical devices and everything else, maybe we can't do that anymore."  And that's not necessarily, we know, what Bruce Schneier wants, but he recognizes its necessity.  And he finishes, saying:  "I don't like this.  I like the world where the Internet can do whatever it wants, whenever it wants, at all times.  It's fun. This is a fun device" - he was waving his phone around - "but I'm not sure we can do that anymore."



LEO:  I'm not sure I agree with him.  I understand the problem, but I don't think what he's proposing as a solution is...



STEVE:  Well, he's proposing major intervention and regulation.



LEO:  A government agency called the Internet Regulation Agency.



STEVE:  Yeah.



LEO:  Yeah, yeah, that's all well and good if you've got a benign government that understands technology.



STEVE:  You know, we've often talked about, in sort of musing about the trouble that our computers have, how interesting it is that in the license agreements, that the producer of the software is held harmless.  You don't own the software.  It's licensed to you, and we reserve the right to revoke the license.  And oh, by the way, if it ever does anything wrong, well, you have no recourse.  And, oh, by the way, you agree to that.  And if you don't agree to it, fine, go somewhere else.  We'll take somebody else's money.



LEO:  Yeah, but that's why I use open source software.  I mean, you know, you don't have to have those shrink-wrapped licenses.  That's a strong argument for open source.  But, man, I know, it's kind of a mess.



STEVE:  I know.



LEO:  I don't know what the solution is.  I really don't.



STEVE:  No, we all, I mean, we're in trouble.  That's what this means.



LEO:  And by the way, he's talking to a lame duck session of Congress which, even if they wanted to do something, couldn't and probably doesn't want to.  So the whole, I mean, the FCC decided to say, well, we're not going to do anything till January.  We'll just let the next administration take care of this.  You saw Admiral Clapper has resigned.



STEVE:  Oh, my god, yes.  That was the best news I've had all week.



LEO:  Or is it General Clapper?  I can't remember.  But he, yes, but, well, that's nice news.  But who's going to replace him?



STEVE:  Yeah.



LEO:  I mean, I don't know what the answer is.



STEVE:  I know.



LEO:  I don't think going to the government and begging for help is going to really be a good idea at this point.



STEVE:  Well, and the problem is I can see Bruce's position.  We're in an unregulated environment.  And I don't, you know, programmers don't have certifications.  I mean, look at Vincent, who wrote LessPass.  With good intentions.  There's a perfect example.  And he's able to.  I encourage him to learn.  Unfortunately, a lot of people started using it.  And but it was irresponsible for him to make it available when he didn't know how to do it correctly.  But he had the right to.  And I think it's great that he's learning how to do it right.  There's just a perfect example.  And we have lots of people just, you know, who say, hey, I'm going to do this.



And, I mean, you could argue that the whole front of the podcast was talking about firmware from China that is doing not only unskillful, but malicious things, and hundreds of millions of people are buying the products.  I mean, we're in a, I mean, I think Bruce is absolutely right.  I guess my point is not all problems have acceptable solutions, but that doesn't mean they're not problems.  We have a problem.



LEO:  Or that we shouldn't seek a solution.



STEVE:  Right.



LEO:  I mean, I agree.  I don't think creating a federal Internet agency is at all the right solution.  We could argue about other solutions.  And obviously market-based solutions haven't worked, either.  So, hmm, I don't know.  What, you want to really license programmers?



STEVE:  No.



LEO:  No.



STEVE:  I'll hang up my shingle.  No.  Oh, I guess I could pass the license exam, but still no.  But I guess if that comes...



LEO:  Well, maybe you could.



STEVE:  Then comes liability insurance.



LEO:  Yeah, maybe you could.  You know, it's harder to become a hairdresser, a barber in California than it is to become a midwife.  And, I mean, I don't have high hopes for a solution.  I really think we ought to find a consumer-based, market-based solution.  But I don't know what the - I don't know how to do this.  I really don't.



STEVE:  Yeah.  And I think, you know, our listeners have seen in this podcast a huge lesson, which is paying more isn't a guarantee, but it's a big start because...



LEO:  We have to stop being so cheap, and we have to start paying attention to these companies.



STEVE:  Right.



LEO:  And all we've been doing as consumers acting as a whole is driving the market to cheaper solutions.



STEVE:  Right.



LEO:  Right?  We've taken all the profit out of the business.  So why should they devote any time to making it secure?  That's just expensive.



STEVE:  Yeah, exactly.  I mean, these companies have been selling this stuff like hotcakes.  And so, I mean, from their standpoint, it's working.



LEO:  It's working.



STEVE:  Wow.



LEO:  Well, I think we've done a lot, and I think we'll continue to make sure to do this, not just on this show, but on all the TWiT shows, to raise awareness of these issues.



STEVE:  Yes.  Yeah.  And again, we care about the people who  listen to us.  I mean, I can't effect this change.  And I think that's probably one of the things that I hear from feedback is people appreciate knowing.  What they do with that knowledge is up to them.



LEO:  Yes, yes, right, exactly.  And somebody's reminding us that the Philips Hue light bulbs weren't cheap, and the ZigBee protocol is supported by big, well-known companies.



STEVE:  Like I said, it's no guarantee.  But I guess the point is that Philips has the resources to fix the problem.



LEO:  Right.



STEVE:  And they have a reputation cost for the problem that would allow them to say, you know, send your bulbs back.  We're going to bite the bullet and replace them with updated firmware.



LEO:  Right.



STEVE:  Whereas these phones are never going to get fixed.



LEO:  No.



STEVE:  So this has been in the offing for quite a while.  And I know we have a lot of listeners in the U.K.  Britain passed what is being called "the most extreme law ever passed in a democracy."  The law requires U.K. Internet providers to store browsing histories, including domains visited, for one year against the actions of their customers in case of police investigations.



And Zack Whittaker gave this some good coverage in ZDNet.  He said:  "The UK has just passed a massive expansion in surveillance powers, which critics have called 'terrifying' and 'dangerous.'  The new law, dubbed the 'snoopers' charter,' was introduced by then-Home Secretary Theresa May in 2012."  And of course we've been following this.  We've talked about this for a while.  And it's like, it's always sort of felt like the U.K. was going to be ahead of us.  And I don't like this because I don't want them to set a precedent that the U.S. follows.  But it took two attempts to get it passed into law following breakdowns in the previous coalition government.



Now, fast-forward, or slow-forward four years and a general election later.  Theresa is now Prime Minister.  The bill was finalized and passed last Wednesday by both houses of Parliament.  "Civil liberties groups have long criticized the bill, with some arguing that the law will let the U.K. government 'document everything we do online,'" they say.  "The law will force Internet providers to record every Internet customer's top-level web history in real-time for up to a year, which can be accessed by numerous government departments; force companies to decrypt data on demand, though the government has never been that clear on exactly how it forces foreign firms to do that that; and even disclose any new security features in products before they launch."  To, like, ask Big Brother if it's okay.



"Not only that, the law gives intelligence agencies the power to legally hack into computers and devices of citizens" - known in the parlance as equipment interference - "although some protected professions, such as journalists and medical staff, are layered with somewhat better protection.  The bill was opposed by representatives of the United Nations, all major U.K. and many leading global privacy and rights groups" - all of whom have been watching this and saying no, no, no, no, no, please -  "and a host of Silicon Valley tech companies.  The law will be ratified by royal assent in the coming weeks."



So, boy.  I mean, think of it, too, I mean, it is, you know, it's always easy to say that you want legislation to do something.  At some point the rubber has to hit the road, and it  has to actually happen.  So, for example, an ISP cannot see what happens inside an encrypted tunnel.  They could only be able to record that you connected to an external VPN service, and that's all they could say.  Now, presumably all VPN endpoints in the U.K. would then also come under this legislation and have to monitor all of the unencrypted, then, communications of their customers.  It's just - it's a mess.  I mean, it's sad.  And maybe we should consider this a test case, see how it goes.  I mean, maybe it'll get pulled back, I hope, because, boy, this is the government that wants to be able to see everything its citizens do.



LEO:  Yeah.



STEVE:  And, you know, a democracy.  I mean, not a repressive regime.



LEO:  It's just unbelievable, yeah.



STEVE:  Yeah.  Yeah, I mean, every domain you visit for a year is, like, going to be recorded.  Wow.



Okay.  Now, this is odd.  This is interesting because this develops a little differently than you would expect it would.  This is from a very well put-together posting on BleepingComputer.  We've often referred to them.  They're our go-to place for the whole ransomware environment.  They were on the early cryptomalware/ransomware early on.  It's a neat site, very active high-end forums.



And this is kind of an odd ethical dilemma.  Fabian Wosar, who's Emsisoft's security researcher, is a frequent poster and participant in the forums.  He's facing a moral dilemma like very few security researchers have faced before.  Wosar has been active for a few years helping ransomware victims.  And in fact we've discussed his work before.  Like a few months back, remember, there was some ransomware that didn't do it right, and it was possible - and some security researchers, in this case it was Wosar, who reverse-engineered their work, realized they'd done the crypto wrong, and then published some decryption software which, if any of their users or any of their victims knew of it, would be able to get their files back.



Well, he's received a private message from a user identifying himself as one of the people who coded the Apocalypse ransomware.  During their exchange, the ransomware coder has asked Wosar to, get this, help their crew fix a bug in the ransomware's encryption process that causes files to be overwritten with junk data.  That is, the ransomware is buggy, so it doesn't actually correctly write the encrypted data.  It writes garbage, which of course kills the actual data so that it cannot be recovered.



"In order to secure Wosar's help, the ransomware coder has appealed to the researcher's dedication to helping ransomware victims.  The crook says," as this posting writes, "that if Wosar helps, they'll be able to provide a ransomware variant that doesn't destroy users' files.  The ransomware author was very candid with Wosar in his request.  He said that even if Wosar helps or not, money is more important to them, and they'll continue to spread their ransomware as they have been doing for the past six months."



LEO:  Oh, now, this is an ethical challenge.



STEVE:  Yes.



LEO:  How interesting.



STEVE:  Isn't this weird?  "The only ones that will have something to gain are the ransomware victims who, if they decide to pay, will then be able to regain access to their files."



LEO:  Yes, let's fix our buggy software.



STEVE:  If Wosar helps.



LEO:  Wow.



STEVE:  So the exact quote of the request reads, from the ransomware authors:  "Once you have written that you feel" - so, and they're not English speakers, but I want to read exactly what they wrote.  "Once you have written that you feel sorry for the ransomware victims.  You can help them.  As you know, we now use CryptoAPI."  That's actually an API in Windows.  And I remember we covered this some time ago.  It was being - there are instances where it can fail.  But if the software doesn't catch its failure and assumes that it provided a correct result and uses that, you don't encrypt correctly.  And that's what's happening here.



So they say:  "As you know, now we use CryptoAPI; and, if encryption function fails, we just fill file with garbage.  As a result," they write, "after the decryption some victims crying to us.  We try to keep an honest business; but money is more important to us, so some of the victims lose some of their files."  Well, all of them.  Well, all that matter.  "How you can help them?  I know you are the best in cryptography, so we can send you the encryption and decryption code, and you should point us where is a bug.  We will fix it, and no more fake encryptions with garbage instead of the file content."  So what do you do?



LEO:  Wow.



STEVE:  Isn't that interesting?  This is just such a...  



LEO:  Well, you don't help them.  I mean, I don't...



STEVE:  No.  Yes, I agree.  I think the idea would be that their malware would get the reputation of being a scam where, if you pay them, you don't get your files back.  On the other hand, it doesn't seem like it happens all the time.  So it probably happens enough that people say, oh, yeah, I did pay those cretins, and I did get my files back, the Apocalypse ransomware.  Ugh.



So, yeah, I mean, it's hard to justify helping them.  On the other hand, their logic is intriguing.  That is, it's just going to be a matter of testing the return arguments from one API and fixing it so that they detect a failure or prevent it from failing.  I can't exactly remember the details around that API call.  But it is a problematic function in the Windows crypto library.  And then they would at least be able to return everyone's data.  On the other hand, maybe it's better if they can't.  I don't know.  But, wow.



LEO:  No.  You don't help them no matter what.  I mean, oh, geez.  Has he said what he's going to do?



STEVE:  No.  He's, like, pondering.  He's, like, stuck.



LEO:  Geez, Louise.  Wow.



STEVE:  So a listener of ours, Matthias Bartosik, sent me an interesting screenshot from a tweet of his.  He said:  "Win10 insider preview changes default browser to Edge and tries to persuade me to stay when I want to switch back to Google Chrome."



LEO:  Yeah.



STEVE:  And he sent a picture, and I guess you probably encountered this, Leo.



LEO:  Oh, yeah, everybody has, yeah.



STEVE:  Yeah.  And so, you know, before you switch, try Microsoft Edge.  It's new, it's fast, and it's built for Windows 10.



LEO:  I get that all the time because I use Chrome as my default browser, yeah.



STEVE:  Yeah, of course.  So welcome to Windows 10.



LEO:  By the way, Apple does the same thing.  They say, you sure you don't want to use Safari?



STEVE:  But constantly?  Or always?



LEO:  No.  And I don't think this one's constant.  I think you say no, and it doesn't stay that way.  But when you try, when you switch the default browser, it definitely encourages you to make the proper choice.



STEVE:  So this is kind of odd.  And this is an unsatisfying answer; but we left the question open, and I wanted to close the question.  So this was on November 17th.  And I don't know if they were referring to us.  But the guys who named it BlackNurse said:  "There seems to be some confusion/amusement/discussion going on regarding why this attack is called the 'BlackNurse.'"  And again, remember that's the ICMP Class 3 Code 3 or Type 3 Code 3 that allows a single host with about 15 to 18 megabits of bandwidth, so not a lot of bandwidth, and just one, to hold many major sites.  And there's a growing list of, like, major routers and firewalls, lots by Cisco, that are vulnerable to this.  So it's significant.  And so they said:  "Also, googling 'black nurse' might not be 100% safe-for-work."



LEO:  Oh, god.  Which is another reason not to use that name.



STEVE:  Yes, exactly, a term, "...since you risk getting search results with inappropriate videos that have nothing to do with this attack.  The term 'BlackNurse,' which has been used within the TDC Security Operations Center for some time to denote the 'ICMP 3,3' attack, is actually referring to the two guys at the SOC who noticed how surprisingly effective this attack was.  One of these guys" - this is why it's a little strange.  "One of these guys is a former blacksmith, and the other..."



LEO:  They're yanking your chain.



STEVE:  "...a nurse."



LEO:  No one's a former blacksmith.



STEVE:  No, no.



LEO:  Once a blacksmith, always a blacksmith.



STEVE:  Well, okay.



LEO:  I used to shoe horses, but now I'm a code junky/jockey.  Former blacksmith.



STEVE:  Anyway, so they explain, "the other is a nurse."



LEO:  Yeah.



STEVE:  "Which was why a colleague of theirs jokingly came up with the name 'BlackNurse.'"



LEO:  How about NurseSmith?  That would have been a better name.



STEVE:  "However, it was first intended as a joke.  The team decided to call the attack 'BlackNurse' even when going public with it."



LEO:  Yeah, yeah.



STEVE:  It's like, eh.  I agree, Leo, that seems a little farfetched.  You know, a blacksmith then became a high-end security guy, and a nurse is hacking in his spare time?  I don't know.



LEO:  They're yanking your chain.  This is the Danish sense of humor.



STEVE:  So I did promise everybody that the SQRL presentation slides would be online, and they are.  I didn't have time, literally, as you know, Leo, I was running behind as it was, there was so much to talk about this week.  But there is a link.  For anyone who's interested, GRC.com/sqrl/presentation.pdf.  And of course I will create a link to it, and it'll be part of the SQRL spec and so forth.  But I did incorporate all the feedback from the guys that are working with me in the SQRL newsgroup.  So GRC.com/sqrl/presentation.pdf.  And it's about 40 slides.



And I should explain, too, it's not meant as a, I mean, I wrote this for - I created it for the presentation week before last to Yubico.  So it's at a higher end.  There will be other materials for users.  This is more meant sort of for our audience, the people in our audience who've been following along.  This is SQRL, if you'll pardon the term, in a nutshell, that is also a full-feature walkthrough.



So if you just page through this and look at it, you'll get a lot of information that's sort of put together in a nice mixture.  It's way below the level of a spec, but it's above the level of the user, stuff the user never needs to know about.  One of the beauties of it is that it just works.  This explains a lot of how the plumbing is, you know, which the Yubico guys wanted to see.  So I'm glad we have now a full-feature walkthrough of this.



I also wanted to mention, because I'm about to go out on the fringe, but before that, my discussion of this new theory of gravitation, and maybe that it eliminates a need for dark matter.  I mean, I'm not an astrophysicist.  I never claimed to be.  I haven't even played one on television.  A number of our listeners were upset that one of their pet assertions about dark matter, that is, the observation of the gravitational lensing of the bullet cluster - which, oh, of course, we all know about that - still exists, even if there's a different theory of gravitation.



And again, I'm not making any assertions about this.  I was just reporting on what I thought was an interesting idea.  And it would be nice if such a, like, without this theory, using even that modified theory of gravitation, that reduces the error from a factor of 10 to a factor of two.  So it improves it by five, but doesn't get you there.  And it's got problems with the gravitational lensing in the bullet cluster, too.



So anyway, I hope people didn't misunderstand.  I wasn't making any assertions about what I believe or know.  I was just saying, hey, here's an interesting theory, and wouldn't it be nice if we didn't need dark matter.  And, by the way, this whole gravitational lensing thing is way less certain that some people seem to have believed.  So I got some talkback on that, and I just wanted to share it.  Now, this is cool, Leo.  NASA...



LEO:  Oh, I know where you're going with this one.  The propellant-less engine.



STEVE:  Yes.  The reactionless space drive.



LEO:  I still think this is utter nonsense, but go ahead.



STEVE:  It may be.  However, it's interesting.  You know, we know that things break down, that is, some of our concepts and theories break down at different scales.  And, well, for example, Newton's theory of gravitation has no problems with apples dropping and satellites orbiting the Earth.  And we understand it, and we're able to make use of it.  But the problem is sometimes on different scales these things don't apply as well as they appear to.



So a little bit of background.  Back in 1999 an inventor described a reactionless propulsion system which met with a lot of skepticism.  But some people began testing it.  And they were reporting that it seemed to be generating some thrust.  Now, once again, by "reactionless," you know, the normal way we thrust is that something is shot out of the end, and what is it, Newton's - one of the laws.  The fourth law?  For every action there's equal and opposite reaction.



Anyway, so I'll just share from some of the coverage:  "After months of speculation and leaked documents, NASA's long-awaited EM Drive paper has finally been peer-reviewed and published.  And it shows that the 'impossible' propulsion system really does appear to work.  The NASA Eagleworks Laboratory team has put forward a hypothesis for how the EM Drive could produce thrust - something that seems impossible, according to our current understanding of the laws of physics.



"In case you've missed the hype, the EM Drive, or Electromagnetic Drive, is a propulsion system first proposed by British inventor Roger Shawyer back in 1999.  Instead of using heavy, inefficient rocket fuel, it bounces microwaves back and forth inside a cone-shaped metal cavity to generate thrust."  Inside a closed cavity to generate thrust.  "According to Shawyer's calculations, the EM Drive could be so efficient that it could power us to Mars in 70 days.



"But there's a big problem with the system.  It defies" - oh, it's the third law - "Newton's third law, which states that everything must have an equal and opposite reaction.  According to the law, for a system to produce thrust, it has to push something out the other way.  The EM Drive doesn't do this.  Yet in test after test it continues to work.  Last year, NASA's Eagleworks Laboratory team got their hands on an EM Drive" - oh, and it's a cool-looking thing.  I don't have a picture in the show notes, but they're all over the place - "to try to figure out once and for all what was going on.  And now we finally have those results.



"The peer-reviewed paper is titled 'Measurement of Impulsive Thrust from a Closed Radio-Frequency Cavity in Vacuum' and has been published online as an open-access 'article in advance' in the American Institute of Aeronautics and Astronautics, the AIAA's Journal of Propulsion and Power.  It'll appear in the December print edition."



So skipping way down to the end of what was published - I've read it - the conclusions say:  "A vacuum test campaign that used an updated integrated test article and optimized torsion pendulum layout was completed.  The test campaign consisted of a forward thrust element that included performing testing at ambient pressure to establish and confirm good tuning, as well as subsequent power scans at 40, 60, and 80 watts, with three thrust runs performed at each power setting for a total of nine runs at vacuum.  The test campaign consisted of a reverse thrust element that mirrored the forward thrust element.  The test campaign included a null thrust test effort of three tests performed at vacuum at 80 watts to try and identify any mundane sources of impulsive thrust.  None were identified.



"Thrust data from forward, reverse, and null suggested that the system was consistently performing at 1.20.1 millinewtons per kilowatt [mN/kW], which was very close to the average impulsive performance measured in air."  I should stop and mention that previous tests done around the world had been done in air, and there was some concern or questioning whether it might have been - the microwaves might have generated heat, and so the heat acting on the air was what was producing some convection currents or something to produce some false readings of thrust.



"A number of error sources were considered and discussed.  Although thermal shift was addressed to a degree with this test campaign, future testing efforts should seek to develop testing approaches that are immune to CG [center of gravity] shifts from thermal expansion.  As indicated" - and then they cite a section of their report - "a modified Cavendish balance approach could be employed to definitively rule out thermal.  Although this test campaign was not focused on optimizing performance and was more an exercise in existence proof, it is still useful to put the observed thrust-to-power figure of 1.2 mN/kW in context.   The current state-of-the-art thrust to power for a Hall thruster" - a Hall thruster is the current best concept.  It's an ion-based plasma.  So you typically ionize Xenon gas, and it accelerates it out of the back of the vehicle in order to, again, that's standard Newton's Third Law.  You're shooting stuff out one end, and you're generating propulsion in the other.



Anyway, so the Hall thruster "is on the order of 60 mN/kW."  So as opposed to 1.2.  "This is an order of magnitude higher than the test article evaluated during the course of this vacuum campaign; however, for missions with very large delta-v requirements" - meaning we need a lot of speed over time - "having a propellant consumption rate of zero" - because that's what this is.  Remember, you're using up Xenon gas as you're ionizing it and blasting it out the end.  So you're consuming mass in order to thrust it out the back.  This system consumes no mass.



So they say:  "Having a propellant consumption rate of zero could offset the higher power requirements.  The 1.2 mN/kW performance parameter is over two orders of magnitude higher than other forms of 'zero-propellant' propulsion, such as light sails, laser propulsion, and photon rockets having thrust-to-power levels [on the order of] 3.33-6.67 micronewtons per kilowatt [N/kW]."  So who knows?  I'm not saying it's real.  I'm just saying it's very cool.



And also, again, this is where, I mean, you know, this might be cold fusion.  Remember back in the '80s everyone got excited because it looked like there was a way to perform fusion, not fission, but fusion in a test tube at room temperature.  And some explosions were performed, and some people claimed to be getting more energy out of it than not.  But here we are, decades later, and nothing ever happened.  So maybe it's specious.  But I think more people are going to be looking at it now, and that's a good thing.



LEO:  I feel like it's - you're going to have to have something better than that to overturn Newton's Third Law of Thermodynamics.  I don't know.  1.2 millinewtons.



STEVE:  Millinewtons per kilowatt.



LEO:  Millinewtons with a plus or minus - with an error of one, plus or minus.  So close to the air.



STEVE:  Yeah, 1.2 plus or minus...



LEO:  One.



STEVE:  Point one.



LEO:  Oh, point one.



STEVE:  Yeah.



LEO:  All right.



STEVE:  Point one.  Yeah.



LEO:  Okay.



STEVE:  So it's between 1.0 and 1.3.  I'm sorry, 1.1 and 1.3.



LEO:  Do they have a thesis as to what's going on?



STEVE:  Oh, yeah, yeah.  I didn't go into it.  But they have a concept for - and again, this gets into the quantum physics about - and they discuss this in their paper, a theory for how this can work, how it can be that it's generating a small, non-net zero thrust in one direction.



LEO:  Yeah.  Which would be very valuable, obviously.



STEVE:  Oh, yeah.  I want one.



LEO:  Sounds like a perpetual motion machine.



STEVE:  We'll see.



LEO:  We'll see.



STEVE:  I just thought it was cool because, I mean, reactionless drives, the aliens all have them.  So, you know, we need that, too.



LEO:  Somebody's got to invent one.  



STEVE:  Yeah.



LEO:  All right.  I don't know, maybe I - I don't know anything about it.  Why should I be skeptical?



STEVE:  I'm just hopeful.



LEO:  Yeah.



STEVE:  It's fun.



LEO:  And I'm just a cynic, so there you go.  My friend, we have come to the end of this fine motion picture.



STEVE:  And not a moment too soon.  As I said, there was just too much to talk about.  And I think this was a lot of good stuff to talk about, and I'm glad we did.



LEO:  It's very good stuff, as always.  We do this show every Tuesday, about 1:30 Pacific, 4:40 Eastern, if you want to tune in and watch live in the chatroom at irc.twit.tv.  That would be 19:30 UTC, so you can do the offset from your locale.  We encourage you to listen offline, as well.  And Steve's got audio of every show plus a transcript that makes it a lot easier to understand what he's saying.  And that's at GRC.com.  While you're there, don't forget to get SpinRite, the world's best hard drive maintenance and recovery utility, plus all the other fabu things that Steve does, just for us, for free, Perfect Paper Passwords and SQRL and all of that.  And the SQRL presentation is there. 



If you can't make it to there, you can always go to TWiT.tv/sn.  We've got audio and video.  I don't know why you'd want video, but you can get it.  And we have lots of other shows, too, at TWiT.tv.  And you could always subscribe using your favorite device, your mobile or your desktop, and get every episode.  We're everywhere.  You can watch on your TV on a Roku or an Apple TV.  Just make sure you don't miss an episode because, who knows, you know, next week we may be announcing that you can use water for gasoline.  It could happen.  Could happen.  I'm just teasing.  Steve, always a pleasure.  Thank you, sir.



STEVE:  Thanks for making it possible, my friend.  We'll be back next week.  I'll spend a little time on the Skype stuff, although we did much better this week than we did last week, so that's good.



LEO:  No problems at all.  Maybe all this time it's been like this, and we just didn't notice.  I don't know.



STEVE:  I don't know.



LEO:  Right.  Thanks, Steve.  We'll see you...



STEVE:  Thanks, buddy.



LEO:  ...next time on Security Now!.  Bye-bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#588

DATE:		November 29, 2016

TITLE:		Listener Feedback #243

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-588.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  A wonderful quote about random numbers, our standard interesting mix of security do's and don'ts, new exploits (WordPress dodged a big bullet!), planned changes, tips and tricks, things to patch, a new puzzle/game discovery, some other fun miscellany - and, finally, 10 comments, thoughts, and questions from our terrific listeners!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a lot of security news to go through, including an homage to the Network Time Protocol.  What other show are you going to hear that on?  Well, maybe FLOSS Weekly.  And questions and answers.  We haven't done it in a while.  We've got some great ones.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 588, recorded Tuesday, November 29th, 2016:  Your questions, Steve's answers, #243.



It's time for Security Now!.  Here he is, ladies and gentlemen, the man of the hour, actually more like the man of the two hours, Steve Gibson, GRC.com.



STEVE GIBSON:  Ah, but who's counting?



LEO:  Yeah, no, no one.  No one.  More is better when it comes to Security Now!.



STEVE:  More, more, more.  Yeah, people say, could you, you know, if you have too much news to talk about in one podcast, how about doing two a week?  And it's like, okay, wait a minute.  This is already, like, 18, well, no, it's more than 24 hours because I start the day before.  I run through, over lunch for a few hours, I go through my entire Twitter backlog of a week in order to catch up, and then dump the mailbag and go through that and pull everything together.  Basically it's a full day out of my week that I invest in assembling this.  So, yeah, I'm not doing this, I can't double this pace.



LEO:  Enough, enough.



STEVE:  I'm already...



LEO:  Yeah.



STEVE:  But the good news is, after many weeks of trying, we have achieved a Q&A.



LEO:  Wow.  Who woulda thunk it?



STEVE:  Without skipping anything important, it was just sort of a little - maybe it was Thanksgiving.  I did ask last week, please, you know, just eat your turkey, you hackers, and leave us alone.



LEO:  Maybe they did.



STEVE:  And maybe they did, took a few days off.  But we have a wonderful quote about random numbers that just tickles me.  And then our standard interesting mix of security do's and don'ts; some new exploits.  In one case WordPress dodged a big bullet, and our listeners are going to get a big kick out of the mistake they made.  And the details of it, I think, are really interesting.  And then there are some planned changes; some tips and tricks; some things to patch.  I have a new puzzle/game discovery which is free.  Unfortunately, it's iOS only, and I prefer things that everyone can have access to.  But really an interesting twist.  And we have a little bit of miscellany.  And then, as many as we can get to, I've got 10 lined up here, questions and comments and thoughts from our listeners.  So I think another great couple hours.



We had a story, actually it was a SpinRite testimonial.  Someone was using SpinRite to recover hard drives for people.  And in some cases they said, I mean, he would say, okay, it looks fine.  And they go, well, you know, I needed a bigger one anyway, or I want to get a new one.  So he would recover their data, clone it to a new drive, and then wipe their drive.  And he said, because he's also a Drobo user, he said, "If the drive that I got from them, which they were retiring, even after SpinRite fixed it, if it was larger than the smallest of my Drobo drives, I'd just pull out that Drobo drive that's the smallest and slide that larger one in."  And so as he was working on people's machines, over time drive sizes tended to inflate, as we know, and so his Drobo kept pace, just growing over time, always replacing the smaller with a larger.



Anyway, this week's wonderful quote, I just love this, this is Robert Coveyou gets the credit for this.  And I just - it's just so charming.  He was quoted saying:  "The generation of random numbers is too important to be left to chance."



LEO:  Very funny.  I like it.



STEVE:  Love that.  And our picture of the week is a wonderful Venn diagram.  Thanks again to some Twitter follower who found this and said, "Oh, I've got to make sure Steve sees this."  So for our listeners who can't see this, a Venn diagram, of course, is the famous overlapping circles; right?  So we have three overlapping circles.  So they have regions where there are only two overlaps.  And then of course in the center is where they all participate.  And this is really clever.  And this, of course, we've talked about exactly this property before.  So the circles are labeled Secure, Fast, and Cheap.  And of course these are competing problems.  We would all like something to be secure, fast, and cheap.  But of course that would be the center where they all three overlap, which in this diagram is labeled "Not gonna happen."



But then you have, of course, three other choices where you've given up one of them.  So, for example, if you just have secure and fast, okay, and you've just given up on cheap, then it says in the picture, "This is going to cost you dearly," to have secure and fast.  Or get rid of speed.  Get rid of fast, so just secure and cheap, and that says, "It will be ready right after you need it."  And then, finally, with cheap and fast, okay, and for some reason there's no security involved, it just says "Good luck with that."  So anyway, sort of a distillation of principles we've been discussing for years in a nice little Venn diagram.



And I did find among my tweets, from someone who - he's in Germany, and he signed his note "Clemens," but his Twitter handle is @AvocadoDiaboli.  Anyway, he said...



LEO:  He's Devilcado.



STEVE:  I think he is.  He said:  "Hi, Steve.  Thank you for your coverage of the OAuth analysis in SN-585.  I am friends with two of the paper's authors, and they're very grateful that you presented their work.  One of them said about you:  'Finally, someone understood our paper.  Steve might have understood it even better than some of the paper's peer reviewers.'"  So, he said, "Thanks, and keep up the great work.  Greetings from Germany, Clemens."  And so it's nice, you know, we're getting that a little bit more now as we tackle some of these tricky security whitepapers because I like to figure out what is actually going on and explain that to people.  So it's fun to hear back from the authors.  It's like, hey, thank you.  You actually understood that.



Okay.  So, Leo, I know you know about this.  And I just love the story title, which actually appeared on the screen, which is, "You hacked.  All data encrypted."  



LEO:  I know where you're going with this one, yeah.



STEVE:  Uh-huh.



LEO:  It's just really stunning, frankly.  



STEVE:  Free rides for everybody last Saturday.  So that was the message on the San Francisco Muni, as it's called, the municipal transportation system, the computer access screens across the city; which, as a consequence of this hack, which actually was apparently a cryptoware attack, gave passengers free rides all day Saturday because the entire fare processing system was down in a cryptomalware cyber attack which reportedly knocked out 2,112 computer systems citywide.



The local CBS affiliate in San Francisco reported that their inside sources said that the system had been hacked for days, and the equivalent of $73,000 in bitcoin was the requested ransom.  And along with that came an email address that was a well-known email address to the people behind this particular flavor of cryptomalware, so it all looked legitimate.  And so that email address was used to contact the hackers, that is, the security industry wanted to say, you know, do you have any comments?  And so clearly English is not their first language.  Their reply was:  "We don't attention to interview and propagate news." 



LEO:  What?



STEVE:  Yeah.  "Our software working completely automatically, and we don't have targeted attack to anywhere," meaning this was just a gift from some poor muni employee that clicked on the wrong link.  And then they continue:  "SFMTA" - which is the San Francisco Municipal Transport Agency - "SFMTA network was very open, and 2,000 server/PC infected by software!  So we are waiting for contact any responsible person in SFMTA.  But I think they don't want deal.  So we close this email tomorrow."



LEO:  Wow.



STEVE:  So the SFMTA officially confirmed the hack, which, you know, it's like, all the gates were up.  And it's like, gee, are you guys having a little problem with your fare processing system?  So, and then they said, so they confirmed the hack - I love this - but said it has not affected any service, and they refused to provide details using the excuse of an ongoing investigation.  You know, we're not going to provide anymore details due to the ongoing investigation.  Of course, meanwhile, the city's Metro gates were wide open because they weren't.  I mean, they had to not have service affected, but people couldn't use their passes or get tickets at all, so everything was just wide open.



LEO:  You can't blame them for not, I mean, I think it's reasonable, at least initially, to not say anything publicly - Muni I'm talking about - because you don't want to give any attacker any surface.  But ultimately I'd be very curious as to what happened.  It sounds like the fare transaction computers were affected.  They have many systems, obviously.  And it's apparently not interlocking, thank goodness, because the ability to run the system, which is all computerized, continued.



STEVE:  Yeah.  Sources at the SFMTA did say that the hack affected employees.



LEO:  Oh, that's too bad.



STEVE:  And that they were not sure they would get paid this week.  And I put in parens, "(Happy holidays)."



LEO:  Wow.



STEVE:  So anyway, and also the attack hit the Muni's email systems.  So there was - so you're right, Leo.  The critical transport infrastructure, like Bart, the computers that run Bart, for example, they...



LEO:  You don't want those to be down.



STEVE:  Exactly.



LEO:  Because then you can't run the trains at all.



STEVE:  Right.  But so it sounds more like the management side, the employee interface side is how [crosstalk].



LEO:  They mentioned, I seem to remember they mentioned QuickBooks.



STEVE:  I didn't see that, but that's interesting.



LEO:  Yeah.  So maybe I'm mistaken, but I'm pretty sure I remember seeing that.  The problem is all the reports we have are from local television news in San Francisco.  Trust me, having worked with many of these people, not the most sophisticated.  So we'll see.



STEVE:  Yeah.  They're not hired for their technical savvy.



LEO:  No.



STEVE:  We'll just say that.



LEO:  And it does seem like it was ransomware; yes?



STEVE:  Yes, it was, yeah, $73,000 in bitcoin was the ask.  And I don't know how it got resolved, whether they paid up, I mean, that's a lot of money.  But who knows how expensive it would have been to, I mean, hopefully there's a backup plan and they would restore.



LEO:  Well, that's what I would expect is that they, yeah, that they just restored from backups.



STEVE:  So it just created a glitch.



LEO:  Right.



STEVE:  Speaking of glitches, Google's SHA-1 death march drumbeat continues.  Now, it was right around this time, maybe a few weeks later, one year ago, everybody will remember that I was annoyed that I was being forced to move to SHA-256, but mostly because there were still systems which were not, that is, users' systems, many, that did not understand SHA-256 certs.  And there were, you know, we looked at some statistics about - CloudFront did some analysis, and there was still a large percentage of machines, not in the U.S., but scattered around, for example, running XP.  XP Service Pack 3 informed XP of how to do SHA-256.  But any pre-SP3 XP didn't know how to do SHA-256.



So my concern was that, on one hand, I didn't want Chrome users to start telling me that GRC is not secure.  At the same time, I didn't want to move to SHA-256 before I absolutely had to because I would be denying GRC's services to people who only had access, for whatever reason, to SHA-1-understanding clients.  So my solution was, and DigiCert, my absolute favorite certificate authority, came to the rescue.  Working with them, I was able to create an SHA-1 cert, actually both an SHA-1 and a 256, and so I had the SHA-256 on standby.  And I didn't go right up to New Year's, but I went close enough because of course we always run across problems where calendars are off by a day or two.  And so I didn't want that to happen.



So a few days before the end of the year I just gracefully switched from SHA-1 to SHA-256.  And essentially what that allowed me to do, then, was to give all of the people who might be visiting GRC an extra year of time where Chrome wouldn't be complaining, and they would be able to connect.  And I figured anyone still using SHA-1 who hadn't figured out a way around that, after many other sites would no longer work, GRC was no longer going to be standing out as a problem.  So the next step of this is happening, I would say next month, except we're not quite in December.  It's in January of 2017.



In a blog post that Andrew Whalley at Chrome Security posted, he said:  "We've previously made several announcements about Google Chrome's deprecation plans for SHA-1 certificates.  This post provides an update on the final removal of support."  And just to give a little background and a little butt-covering:  "The SHA-1 cryptographic hash algorithm first showed signs of weakness over 11 years ago."  Eh.  Oh, okay.  I mean, there were some reduced-round attacks where, if you didn't actually do SHA-1, but you did an SHA.1, then, yeah, there were some problems.  But SHA-1, you know, we're retiring it, not because it has a critical problem, but because it's prudent to do that.  We would rather retire it before it has a problem than in a screaming emergency, if someone develops some silicon that's able to do those hashes.



So he says 11 years ago there were some signs of weakness, and "recent research points to the imminent possibility" - okay, I guess anything is imminently possible - "of attacks that could directly impact the integrity of the Web Public Key Infrastructure, or PKI.  To protect users from such attacks, Chrome will stop trusting certificates that use the SHA-1 algorithm, and visiting a site using such a certificate will result in an interstitial warning."



So their release schedule, he says:  "We are planning to remove support for SHA-1 certificates in Chrome 56, which will be released to the stable channel" - now, that's after developer and beta, then stable, that's what we all get - "around the end of January 2017.  The removal will follow the Chrome release process, moving from Dev to Beta to Stable; there won't be a date-based change in behavior," which is to say it won't be - it'll be a version-based change.  When Chrome 56 comes out, it will not know about SHA-1 certs.



And so he finishes, saying, "Website operators are urged to check for the use of SHA-1 certificates and immediately contact their certificate authority for an SHA-256-based replacement, if any are found."  And then I said parenthetically here, "And, oh, by the way, the Vogon demolition and construction fleet will be arriving shortly thereafter.  However, no one will have cause to complain about either of these events because proper notice of the end of SHA-1 and Earth's pending destruction have both been clearly posted in our offices at Proxima Centauri."



LEO:  Now tell me how you like my poetry.



STEVE:  In other words, just wait till the end of January because Chrome is now the majority browser on the Internet.  And we all know I reluctantly endorse what Google is doing.  All of our lessons that we have learned teach us that it is only when we are forced to change, we do.  There will be some blood in the streets because suddenly sites that are perfectly secure will be alarming their visitors, saying they are not secure; that the site uses obsolete cryptography or whatever jargon Chrome chooses to use.  Anyway, [audio dropout] fun in two months, two months from now, toward the end of January, when Chrome 56 comes out.  And with any luck, there will be a deferment to the Vogons' plans to put a spatial bypass right through where our comfortable little solar system is located.



LEO:  To make room for an interspace bypass.  Love it.  Love it.



STEVE:  So this is an odd story, and I included it because a number of our listeners said, "What do you think about this?"  You might want to bring this up in your browser, Leo.  It's a site called Deseat.me, as in remove my seat, S-E-A-T.  So D-E-S-E-A-T dot M-E.  Fortune magazine mentioned it, which is what brought it to the attention of some of our listeners.  It's an interesting idea.



And the idea is, their argument is, over the course of your relationship with Gmail, lord knows how many things you have signed up for over the years.  And of course Gmail famously keeps the repository, this archive of all your email, unless you go to some lengths to expunge it.  This thing, you log in with Gmail into Deseat.me, using OAuth.  It then asks for access to your email, which is what makes me uncomfortable about this whole thing.  But what they then say they do is read, automatically of course, process all of your email backlog and find all the things that you are still joined to or members of.  And so, for example, I had four, Leo.  And I'm seeing the number 283 on your screen.



LEO:  You had four?  My, you are very parsimonious.



STEVE:  Well, I'm not a Gmail user.  I have it because, you know, Google.  But otherwise, you know, I...



LEO:  So this lets me sign out of these accounts?



STEVE:  Yes, with a single click.  You're just able to go, oh, I don't need that, don't need that, don't need that, don't need that, don't need that.



LEO:  That's intriguing.



STEVE:  So it is.  So with the understanding that you are giving a third-party automated entity access to your historical archive.



LEO:  Right.



STEVE:  That being the tradeoff.



LEO:  Some of these I don't even know, I don't remember ever signing.  I don't know...



STEVE:  Exactly.



LEO:  I don't know what they are.  Okay.



STEVE:  Yeah.



LEO:  PriorityAuto.com?  I don't know what these are.



STEVE:  Now, I don't know that spam wouldn't be in there.



LEO:  I think it is because... 



STEVE:  Because it was an American Express thing that they...



LEO:  Yeah.  I don't think I ever joined anything called FocusedPassion.com.  So can you look at the - Turtle Tech Design?  See, I think this is spam, too.  I mean, it's clearly not discriminating.



STEVE:  So what they do is - their UI was a little unclear, but you start on the top.  And so you just click on the disposition you want for the first one, and then that slides them up.  And so you just sort of go through, saying, keep, dismiss, keep, deseat, deseat, deseat, keep, so forth, and just sort of walk through it.  And then they provide the mechanism for essentially removing you from those lists or the memberships or whatever.



LEO:  Yeah.  I mean, some of these things I recognize.  You know, what I just do - so it removes you from mailing lists, basically.



STEVE:  Yeah, I think that must be it.



LEO:  So there's other things that do this, like Unroll.Me.  You know what I do is I just filter on anything that has the word "unsubscribe" in it, and I put that in a folder called "Mailing Lists."



STEVE:  Nice.



LEO:  And then if I want to look, I can look.



STEVE:  Yup, nice.



LEO:  This clearly has spam in it, as well.



STEVE:  Okay.



LEO:  And the problem I have with that is I don't want to unsubscribe from spam because they don't know I exist.



STEVE:  Right.  Very good point.



LEO:  So interesting idea.



STEVE:  Yeah.  And that was my feeling.  I didn't like it from a privacy standpoint.  And they're also not quite forthcoming.  They imply that this is secure because it's all being done on your computer.



LEO:  Yeah.



STEVE:  So it's like, uh, I mean...



LEO:  No, it's not, though.



STEVE:  I don't think...



LEO:  It's going through my Google Mail.



STEVE:  It could have a big blob of JavaScript in the browser, and so the browser is doing that.  Except when you and I both did the OAuth login, it did ask for permission for access to Gmail.



LEO:  Yeah, yeah.  In fact, now I want to take it away.



STEVE:  Yeah.



LEO:  I've got to figure out how to get rid of it.



STEVE:  Yeah.



LEO:  Oh, well.



STEVE:  So I got a tweet from our friend Simon Zerafa, who asked me to bring the Snoopers Charter Petition to the attention of our listeners.  I know we have a large base of listeners in the U.K.  So there is a Snoopers Charter Petition.  It only needed 100,000 signatures, but when I made the show notes this morning there were 136,565.



LEO:  It passed.  I mean, it got enough signatures, yeah.



STEVE:  Yes.  Although my feeling is the more, that is, Parliament will, I mean, it's overcome the threshold for bringing it to the attention of Parliament.  But if it had a million signatures or two, then I would think that would carry more weight.  So I wanted to make sure that anybody who is affected by the Snoopers Charter and felt strongly enough that the so-called Investigatory Powers Act, there is a petition.  And I've got the link in the show notes.  And this week I already put the show notes up on the Security Now! page at GRC so that people would be able to find it because it's petition.parliament.uk/petitions/173199.  And I see that we're now at 141,244.



LEO:  Which exceeds the 100,000 required.  But, I mean, it's not binding, by any means.



STEVE:  No, no.  But, you know, as an expression of annoyance.  And, I mean, I don't know if that even matters.



LEO:  Yeah, here's the response.  "The Investigatory Powers Act dramatically increases transparency around the use of investigatory powers.  It protects both privacy and security and underwent unprecedented scrutiny before becoming law."  We couldn't pass it for years.  Yeah.



STEVE:  Uh-huh.



LEO:  Yeah.  That is the story, that this is, in fact, even some independent people said, well, better this so you know what their capabilities are than not having prescribed investigatory powers, so everybody does whatever they want.



STEVE:  Well, and like the U.S. Patriot Act, which we found out was being way pushed beyond what its original legislation and legislators intended.



LEO:  Right, right.



STEVE:  So, yeah, I mean, I can certainly see that having transparency is a good thing.  And I guess you guys were talking about it on TWiT this Sunday because I...



LEO:  Oh, yeah, we talked about it a lot, yeah.



STEVE:  ...remember hearing some dialogue that, you know, the concern, of course, being that this may be an indication of what is inevitable for democracies.



LEO:  Worldwide.  Not just us, but worldwide.  And not just them, but worldwide, yeah.



STEVE:  Right.  So Check Point Security, a well-known security company, named something that they found "ImageGate."  You know, it's a gate, so Watergate and so forth gate.  In this case, ImageGate.  And the details are at this point scarce because they're withholding full disclosure responsibly until the social media sites that they have discovered with this problem.  And they specifically note Facebook and LinkedIn, Facebook of course being huge, have fixed their problems.  But it appears that, through some fault in something that Facebook and LinkedIn and apparently others are doing, it is possible for malicious executable files to be uploaded as images, which are then posted on Facebook pages and made available to unwitting users.



Now, as we know, the browser should just display the image.  But the browser doesn't recognize this as an image.  So when the user clicks on it, or clicks a link, up pops the "download this file" dialogue.  So, I mean, so this isn't like a vast worm that's going to spread like crazy because it requires the user's involvement to click on, yes, save this, or open it, and then go find it and open it or look at it.  But what's in there is an executable.  And the point of all this is that there has been a rash of Locky ransomware spread through social media.  This is how it's happening.



So what Check Point figured out was where was all this - how was all this Locky ransomware getting past Facebook and LinkedIn and other social media sites' protections.  And again, there just isn't enough information.  It'll be fun to cover this again when we know more.  But for what it's worth, from what I could gather from what little they said, the fact that you have to ask your computer to execute it means - and also the fact that it's a way of getting it into Facebook.  It must be some sort of a failure in the incoming file analysis which is missing the fact that an executable somehow disguised as an image is getting into the social media site and then being available for redistribution.



So they're described as Locky ransomware decoy image files which are ambushing Facebook and LinkedIn accounts, as Ars Technica described it.  So it'll be fun when we know more, when we can know more.  Right now these sites were notified by Check Point, who have said, look, this is what's happening.  And I'm sure they're in the process of locking that down, and we'll probably know more, maybe next week.



Oh, and Leo, this is a good one.  The exploit is called Speake(a)r, as in Speaker, and then they stuck an "a" in parens in between the "e" and the "r" at the end.  So instead of Speaker, it's Speake(a)r, which actually is kind of clever.  And this has been making the rounds in the security community because the presumption has been, if a system doesn't have a microphone, or you've disabled, explicitly disabled the microphone, in much the same way people, for example, James Comey and Zuckerberg both have post-it notes over their webcams because they understand what can happen.



So it turns out that this group very cleverly realized that headphones, or speakers, are also microphones.  And the catch is, of course, that you plug your speakers or your headphones into an output jack on your computer.  Well, I'll just share from the abstract, just the top of their paper.  They wrote:  "It's possible to manipulate the headphones or earphones [or speakers] connected to a computer, silently turning them into a pair of eavesdropping microphones, with software alone.  The same is also true for some types of loudspeakers.



"This paper," they write, "focuses on this threat in a cybersecurity context.  We present SPEAKE(a)R, a software that can covertly turn the headphones connected to a PC into a microphone.  We present technical background and explain why most of today's PCs and laptops are susceptible to this attack.  We examine an attack scenario in which malware can use a computer as an eavesdropping device, even when a microphone is not present, is muted, taped, turned off, disconnected.  We measure the signal quality and the effective distance and survey the defensive countermeasures."



So I love this story because this is one of those unintended consequences of the way our hardware has evolved.  So first of all, as we know, many microphones and speakers [audio dropout] the same thing.  Some are not.  Back, I'm sure, Leo, being you're about my age - in fact, by the way, Happy Birthday.



LEO:  Thank you.



STEVE:  Happy big six-oh today.



LEO:  Thank you.



STEVE:  We unscrewed the mouthpiece...



LEO:  Right.



STEVE:  Of the handset, and there was this wonderful - it was called a "carbon button microphone."  And sometimes the quality, you know, somebody on the other line would say, "You're really scratchy-sounding.  I really can't hear you very well."  And you could knock that Bakelite handset on the counter or the desk and then say, "Okay, is this better?"  And they go, "Oh, yeah, much better."  Well, what you had just done was to shake up the carbon granules - I'm holding it to my head now, talking - to shake up the carbon granules in that microphone.  And Edison coinvented that with somebody else over on the other side of the Atlantic.  I can't remember his name.  And Edison got a patent on it.



The idea was that you had carbon granules in an envelope, and the acoustic pressure from your voice squeezed the carbon granules together, thus transiently lowering the net resistance of the entire thing.  So you had a conductive front and back.  And then, if you talked at one of those, like talked into one of the, like the front layer, the vibration would squeeze the carbon, and you'd get a variable resistance, which is what the telephone company used back then in order to complete our calls.



LEO:  But even regular headphones, speakers, it's a two-way thing.  So the diaphragm that's in a microphone converts sound pressure from your voice into electrical impulses.  But the headphones take the electrical impulses and convert them back to sound pressure.  So if you plug any headphones, these headphones, into a microphone port, it's not a perfect microphone because it's not designed for that direction.  But all headphones are microphones.



STEVE:  Yup.  That's exactly right.



LEO:  It's a two-way street.



STEVE:  Except electrostats probably are not.  Essentially what you need is a moving...



LEO:  Maybe no.  Yeah.



STEVE:  You need a moving coil.



LEO:  Right.



STEVE:  And so the idea is that today's, most of today's microphones are called "dynamic" microphones.  And so there's a very strong permanent magnet and a very lightweight coil that is suspended sort of in air around that magnet, and then a front-facing diaphragm.  Now when you talk, that coil moves back and forth, cutting through the lines of force of the magnet, which induces an electrical current in the coil to produce a current that is directly proportional to the displacement of the microphone's front surface.  So we could think of that as a generator, that is, as you talk, as I'm talking into this thing right in front of my face, it's generating electricity - very, very weak, but that's what it's doing.  And a generator you spin, like in a traditional motor generator, you spin the shaft of a generator, and out comes electricity.  You put electricity in, and the shaft spins.  That's a motor.  And they are, as you said, the same thing.



So here's what happened.  Once upon a time, on the motherboards, there would be a speaker amplifier chip, or a headphone amp on, like, connected to typically a D/A, a digital-to-analog converter.  So there would be a D/A that would go to an amplifier that would produce the current to drive the headphones or speakers because a D/A typically, itself, it just produces a sort of a pilot current or voltage, but isn't strong enough directly to drive that.  And you want a volume control and other features.



And then in the reverse direction there would be a mic amp where the very, very weak current from the microphone - and that's why, for example, microphones are so susceptible to hum, is that the induced 60-cycle hum in a microphone cord is large relative to the signal the microphone itself produces.  So the microphone amplifier has to have a lot of gain in order to bring up the power from the microphone.  In the process it brings up any hum that might be produced.  But that was the architecture.  You'd have a speaker amp outgoing, and a mic amp incoming.



Well, over time, with increasing levels of integration, because it was cheaper not to have multiple modules, that all got integrated, primarily by a company named Realtek.  Realtek pretty much owns this market.  They are way the majority chip in PCs and Macs that perform this function.  And some guy at Realtek said, you know, sometimes our chip wants to do like a 7.1, sometimes a 5.1, sometimes stereo.  So what they did was they generalized the chip.  Instead of having inputs and outputs, they gave all the pins both functions.  So it's 100% software defined.  And the output is only an output because the BIOS programmed it to be an output, or the Realtek driver operating in the OS kernel said, oh, this system is set up to be this configuration.  And so during boot time, or as the OS is coming up, it configures the hardware the way you want it.



What these guys realized was exactly that, and that it was no longer the case that any hardware statically defined inputs and outputs because the Realtek chips that are in most of our PCs and Macs are set up so that they are software-configurable.  So if you've got headphones plugged in, or speakers plugged in, and something malicious gets into your system that wants to listen to you, and even if you have no microphone plugged in, if the machine doesn't have one, these guys demonstrated it's possible to turn the speaker into a microphone and listen to you just as if you had the microphone.  Beautiful piece of work.  Very cool.



LEO:  Not even very surprising, frankly.



STEVE:  Yeah, but it's one of those things where, you know, I mean, it's like, okay, I'm safe because I don't have a microphone.



LEO:  Right.



STEVE:  Uh, sorry.



LEO:  You do have a microphone, actually.



STEVE:  You actually do.  And it turns out you don't have to plug your headphones into the microphone jack.  You just can redefine the speaker output as a mic input.



LEO:  Right.  And almost all headphone jacks now are single jacks with three rings for in and out.  So your headphones are probably plugged into your microphone on most computers.  You know, if you look at your computers, they have one jack now.  Just like your phones.  It's in and out.



STEVE:  Oh, interesting.



LEO:  Yeah.  There's three rings on your connector:  one for a mic, one for left, and one for right.  



STEVE:  Ah, okay.



LEO:  All laptops, this one, I'm looking at the Creative Studio, it's got one jack.  It doesn't have the - that's the old days where you had a Sound Blaster 16, and you had a microphone jack and a speaker jack.



STEVE:  So NTP, the Network Time Protocol...



LEO:  I'm glad you're bringing this up, Steve.  I saw this article, and I thought, we've got to spread the word.



STEVE:  So it's not a sexy protocol.  Of all of the protocols around, it's like...



LEO:  I think it's dead sexy.  We all use it all the time.



STEVE:  Yes, yes.  So it's sort of like ICMP.  It's plumbing.  It goes unseen.  It's sort of taken for granted.  And we've talked about it before.  I'm impressed.  I looked at it.  And consider the challenge of obtaining super accurate time over an inherently nondeterministic network, that is, here's an NTP server wants to offer the time of day, as a server, to any number of clients that want to ask it.  So it needs to get the time, like a reliable time, from a big daddy NTP server.  Except that's going to be some number of router hops away, and there's an inherent time delay of at least milliseconds which can fluctuate and vary.  Anyway, anyone who really has some time to burn, if you ever are curious, the NTP RFC, which goes into the technology, will not disappoint anybody who loves details because this thing, as simple as it seems on the surface, the problem they tackled was big.



Now, we haven't talked about NTP for a few years because I think it was like in what, end of 2014 or early 2015, it was for a while a popular DDoS reflection attack vector because it turns out that there were many NTP servers that you could generate a simple query to, which would result in a much larger response.  And it's over UDP, that is, not TCP, the non-connection-based protocol, which means it can be spoofed.  You can't really spoof a TCP connection because you require packets to have a roundtrip between the two endpoints in order to bring the connection up.  UDP is used, for example, also by DNS, where it's just a single packet, which is low overhead, lightweight, much less expensive in terms of traffic on the 'Net.



So what has come to light is there has been a flaw for quite a while in all NTP servers.  Every version up to 4.2.8p9, but not 4.3.94, are vulnerable.  So before this came to light, because this was a concern, the NTP maintainers were notified responsibly, and they fixed it.  The problem was just the receipt of a single deliberately malformed UDP packet could cause a null pointer reference, that is, could cause the NTP server to try to access the object at zero, which is always illegal and is always kept, it's always trapped and caught by the operating system because it's a mistake.  And what the OS does is terminate the process.  It's like, oh, you just misbehaved, and you're no longer a happy client of this OS, so go away.



And so what this means is that it would crash your NTP server.  And so the concern was that NTP is everywhere.  It's not, as I said, not very sexy.  People don't talk about it.  It just - it's a workhorse.  But if this had been found and exploited, it could have brought down time, the end of time, for the Internet.  It was fixed.  But the takeaway here is that, because it's not sexy, people aren't dealing with it very often.  I mean, it's like one of those things in the closet.  So if you have a publicly exposed NTP server - and that's an important caveat.  That is, for example, you might be running one on a Linux box or a Unix box at home.  But it might be behind your router, providing time services to your own LAN.



Well, okay.  So something malicious in one of your machines could bring down your LAN's NTP server, but that's probably not a big worry.  The concern would be any publicly facing NTP services that had not been patched could be hacked and just crash.  And in fact, now that this is news, and we know what the problem is, it seems very likely that someone will just get up to some mischief.  They'll just scan the IPv4 space, spraying out malicious NTP UDP packets, crashing all of the still-not-patched NTP servers.  So I just wanted to let our listeners know this has happened in case any of them haven't updated NTP to the latest.  It's worth doing.  Oh, and at the same time, there were 10 problems fixed.  That was one of them.  Nine less critical problems were fixed, as well.



LEO:  And you can thank Harlan Stenn for that.  And this is the - I thought you might be doing this, but this is the public service announcement I want to do.  This is an article yesterday in InfoWorld.  And credit to Fahmida Rashid for writing this.  We all use NTP, but maybe you didn't know this project, which has been around for 30 years, has no corporate sponsor.  Many open source projects do, and has one, count 'em, one maintainer, Harlan Stenn, who's basically doing this out of the goodness of his own heart.  Now, this is an important open source project.  It is severely underfunded.



STEVE:  Well, and we know about 2038.



LEO:  Yeah.



STEVE:  Because the problem is...



LEO:  The Unix time epic.



STEVE:  Yes.  It goes to all ones, and then it goes to zero.



LEO:  So the Linux Foundation gives it some money.  It's part of the core infrastructure initiative.  And when asked about vulnerabilities and why it's slow to fix them, including this one you just mentioned, Stenn says:  "Reality bites - we remain severely under-resourced for the work that needs to be done.  You can yell at us about it, and/or you can work to help us, and/or you can work to help others to help us."  So if you are a coder, or you can help financially, the NTP Project needs your help.  This is one guy.  I mean, I think there are other contributors.  But the maintainer is Harlan Stenn.



STEVE:  Well, and the good news is there isn't a huge demand for the spec to be evolved.  I mean, it's not like TLS or something, which is rolling forward.  It's like, this problem has been solved.  But you're right, Leo, this is a perfect example of here there was an urgent need to get this fixed.



LEO:  Right.  And with one guy, you know, as he says, I'm doing the best - I'm working - it's that Venn diagram you mentioned earlier.



STEVE:  Yeah.



LEO:  I'm working as fast as I can.  So it's important.



STEVE:  And he said, "We're trying to do it."  And I thought, well, he must have a mirror.



LEO:  No, there are other contributors.



STEVE:  Oh, okay.



LEO:  I shouldn't say he's the only guy doing any code.  But he's the sole - he's the principle maintainer.  And the way open source projects work, there's one guy who's like, this is my job.  And then people come and go.  And I think that's part of the problem is it's just one guy.  So I'm glad you mentioned the bug.  But let me also do the PSA, do what you can do help NTP because we all use it.



STEVE:  And why it still needs to be maintained is a perfect example here.



LEO:  Yeah.



STEVE:  So it was probably foreseeable that the National Highway Transportation Safety Administration was going to give a little more attention to the problem of distracted driving.  I just wanted to put this on everyone's radar.  This is still in the early stages.  But what is the acronym, the NHTSA is recommending a car mode which is somewhat similar to the airplane mode, but of course with a different intent.  This one turns off all distracting apps which are not arguably needed for driving.  So things like maps get to remain active, and presumably hands-free phone, but not Twitter.



So there is a 96-page voluntary guideline document which is intended - which specifies the intent of reducing driver distraction and, among other things, calls for cars to be more easily paired with mobile devices so that drivers can access their mobile devices through a presumably less distraction-prone in-vehicle interface.  And so the guidelines go into some detail, suggesting, for example, that driver mode as envisioned would lock out things like typing out text messages, as well as displays of images or video not related to maps.  It would block most text content, like web pages, social media, books and periodicals.



And, here it comes, the NHTSA says it's looking forward to developing technology that enables better "driver passenger distinction," presenting the possibility of a future in which phones automatically lock into some type of driver mode without needing the driver to initiate it.  So anyway, it's not legislation yet.  But, boy, Leo, I know you drive.  I drive.  I see there has been a, in the last few years, a dramatic increase in...



LEO:  It's 10% year over year.  I mean, it's terrible. 



STEVE:  Yes, of accidents, yes.  And I see, for example, lights turn green, and the cars don't move.



LEO:  Yeah.



STEVE:  Because they took that opportunity to check in with Twitter or with...



LEO:  They'll ticket you.  My daughter got a big ticket for that, for not moving when the light turned because she was distracted.



STEVE:  Wow.  Interesting.



LEO:  I was glad she got it.



STEVE:  It is sort of a giveaway.  It's a little hard to explain.  Like, well, what were you doing when the light was green and cars were honking at you?  And in fact, it's a little dangerous, too, because I've driven by some cars when the light was green, and they were just sitting there, you know, I mean, and they were in an adjacent lane.



LEO:  Right.  I'm busy here.  I'm sending a text.  Please.



STEVE:  And also, you know, I love to ride a bicycle.  Thankfully, Southern California has given a lot of attention to bike riders.  But I see cars now weaving, not staying in their lane, to a much greater degree now.  And it's not just because of their automated driving systems.  I'm sure it's because people are trying to do two things at once.  And they can barely handle one thing at once.



LEO:  Yeah, I think this was inevitable.  And I'm not unhappy about it.  I think the problem is what if you're a passenger?



STEVE:  Right.  And thus their comment about, I mean, recognizing this notion of the driver/passenger distinction.  Now, of course, you can imagine some driver then holding his phone out over in the passenger area and having to turn to look at it in order to get it to not lock down in driver mode.  I mean, it is a problem.  And look at the addiction so many people have to their phones.  I see it, like, you know, every time I'm out eating.  It's like a whole family is just sitting around, each one staring into their own phone.



LEO:  It's really, it's kind of sad, isn't it, yeah.



STEVE:  It is, yeah.  So the EFF generated a nice post.  Unfortunately, they brought way too much of their own politics into it, which was unnecessary, you know, saying, well, saying:  "The results of the U.S. presidential election have put the tech industry in a risky position.  President-elect Trump has promised to deport millions of our friends and neighbors, track people based on their religious beliefs, and undermine users' digital security and privacy.  He'll need Silicon Valley's cooperation to do it - and Silicon Valley can fight back."



Well, you know, fine.  Unfortunately, my concern was that this heavily laden with politics posting would obscure what then followed, which were some really good recommendations, which are independent of who our President is.  And that is for encouraging sort of generically the privacy offered by Internet-based services.  And those recommendations are spot-on.  For example, for sites to allow pseudonymous access:  "Give users," they write, "the freedom to access services pseudonymously.  Real-name policies and their ilk are especially harmful to vulnerable populations.  Even better, don't restrict access to logged-in users."



And I won't go through all of this in detail.  But stop behavioral analysis.  Basically, don't try to infer things about your visitors that they don't voluntarily choose to share with you.  Also delete logs.  Logs are a privacy problem.  So seriously look at what you have to keep, and only keep what you absolutely need to, and for no longer than it's actually useful.  And then they remind us to encrypt data in transit, and also to enable end-to-end encryption.



So some nice policies that I think all of us would agree to.  And let's hope that, I mean, unfortunately, Leo, I've heard you talk about this a lot on other podcasts, this also is a war that the end-user is losing.  We are the product now to an increasing degree.



LEO:  We're going to do a Triangulation in the near future with a guy named Tim Wu who's very famous, a Columbia professor of law.  He wrote "The Master Switch." 



STEVE:  Oh, great book.



LEO:  Yeah.  His new book is called "The Attention Merchants," and it's exactly that.  It's the trade.  And, you know, we do it, too.  I mean, that's how we fund ourselves at TWiT.  We trade your attention to what we do with advertisers to fund it by running ads.  But it's really gotten way out of hand.  And so I'm looking forward to this Triangulation.  I'm not sure what the date is, but I'll let you know.  



STEVE:  Yeah, please do because I definitely want to watch that.



LEO:  Yeah, he's very smart.  And it's a great book, by the way.  Highly recommended.



STEVE:  So here is just a deliciously detailed, which everyone knows I love, technical explanation of a mistake which, had it not been found and responsibly reported and corrected, could have allowed the malicious infection of more than one quarter, about 27% of the Internet's web pages, which are hosted on WordPress-based sites.  So what happened?  Every WordPress installation everywhere, by default, makes a request to servers at api.wordpress.org, about hourly, to just sort of ping api.wordpress.org to check for updates to plugins, themes, or the WordPress core.  So that's often, but it's an inexpensive query to say, hey, you know, anything important.



And of course the argument is, if there were something horrible that was discovered, you'd want to be able to push that out to, in the core WordPress code, get that out to all of the WordPress sites distributed across the world.  So I think that's a nice tradeoff, the fact that, about hourly, all sites, all WordPress running sites that are based on PHP just check in with the mothership.  If updates are available, that api.wordpress.org server returns a link to a different download server which contains the update.  And the WordPress site then uses the link it received from the api.wordpress.org update server to obtain an update for a code package and update itself.



The WordPress developers maintain their code at GitHub.  To publish an update, once they're finished creating a set of improvements, new features or bug fixes or whatever, they commit those changes at GitHub.  GitHub makes a query to the WordPress update servers to inform WordPress of the availability of new code on GitHub and to provide the URL, the GitHub URL from which the code should be fetched.  Now, naturally, there's the potential vulnerability.  That update notice from GitHub must be authenticated.  Otherwise, anyone could create a malicious update package, inform the WordPress Update Server that it's ready for distribution, and thus potentially push a malicious update to every WordPress site  - as we said, more than a quarter of the Internet - within an hour.



How does GitHub-to-WordPress authentication work?  To start, both ends share a secret.  So they have a shared secret.  An update specification packet is created by GitHub.  Then, for the purpose of "signing it," and I put that in quotes in my notes because it's not a formal crypto signature, but it's something these guys cooked up, and it seems cryptographically safe enough.  That shared secret is temporarily appended to the update spec.  And that concatenation is hashed using whatever hash algorithm is chosen.  The shared secret is then removed from that spec - because, again, you don't want that to go out in the clear.  And the spec and the hash are sent to the api.wordpress.org servers for verification and acceptance.



So once again, the spec says here's a new version.  Here's the URL to obtain the updated code.  And here's a hash of what we're providing which was made by temporarily adding a shared secret and hashing the whole thing.  Then that shared secret was removed, and the spec, the update spec and its hash, which functions as a signature, are sent to WordPress.  So at the other end, at the receiving end, to authenticate, the api.wordpress.org server takes the specification, appends its own copy of the same shared secret, which of course when it hashes it, it's going to obtain the same hash that GitHub did.  So hashes that; verifies that its hash matches the signature hash provided by GitHub.  And that is the authentication mechanism based on a shared secret.



So it's simple, lightweight, and elegant.  Since no third party knows the shared secret, no third party would be able to feasibly compute the proper hash to accompany a non-authentic malicious update.  So what's the problem?  The caller in this spec that WordPress developed for GitHub to use, the caller provides the update with the hash signature, as we said, and also specifies the hashing algorithm to be used <groan>.  It's not by default SHA-1, migrating to SHA-256.  No, it's actually a parameter in the query header that GitHub uses to send to WordPress.  And that in and of itself is not a problem, except that this is all in PHP.  And PHP supports many very old and low-security hashing algorithms.



And in the same category, even well-known, non-cryptographically secure algorithms like CRC32 checksum, and in this case something known as the Adler32 checksum.  Now, we've discussed before, functions like CRC32 were never designed as a hash.  They were designed and intended to detect mistakes in communication, not to prevent deliberate manipulation.  But that's what a hash was meant to do.  A hash is like a super checksum because not only would it find any change that was made by mistake, but you cannot, you know, it's cryptographically sound.  You cannot deliberately make a change to the input of the hash in order to obtain a specific result.  It just, you know, bits go in, and pseudorandom nonsense comes out the other end, of a fixed length.



Okay.  So one of the things that this would do, you know, so the guys that were figuring out how to crack this, they said, okay, well, if we use CRC32, that dramatically weakens the system security.  That is, if they said to WordPress, here's an update package and a hash, and by the way, please use CRC32, well, that's bad.  So, I mean, that's not good because now you're saying use a function which essentially scrambles the input and produces a 32-bit output, rather than an SHA-1, for example, which is what GitHub and WordPress use, which is 160 bits, one six zero.  So this has reduced the attack from 160-bit, which is really a lot, down to 32 bits.  But still, that's 4.3 billion.



Now, remember that the attacker doesn't know the shared secret.  So to exploit this, the attacker has to guess the shared secret, or essentially arrange to get a hash collision - where I use the word "hash" provisionally because CRC32 is not - but basically needs to cause the WordPress side to agree with the hash output, in this case 32 bits.  But that's still 4.3 billion.  And this has to be an active online attack, where continued update requests are being made to the server over a TCP connection, waiting, you know, trying.  On average it would be half that many so, what, 2.15 billion.  It still is going to take you a long time in order to get lucky.



Well, it turns out that there's something worse in this instance than CRC32, and that's that other function I mentioned, the Adler32 function.  Now, okay, Mark Adler is well known, especially in the data compression industry.  He's the coauthor of the zlib compression library and gzip.  He contributed to Info-ZIP and also participated in the development of the compression used in the PNG, the Portable Network Graphics image file format.  And as a little side note, he was also the Spirit Cruise Mission Manager for the Mars Exploration Rover.  So he gets around.



He deliberately designed this Adler32 function, I think it was in 1995, so it's old.  And he made it, you know, in all of these things there's a speed/quality tradeoff.  Mark explicitly wanted something faster, rather than better.  We already had CRC32.  He wanted something faster.  Well, a hash, one of the hallmarks of a hash is that all of its possible outputs are evenly distributed.  That is, none of them occur more often than any others.  And the way to say that algorithmically is that every single bit - like in the case of SHA-1, it's 160 bits.  Every single one of those 160 bits has, for any given input, about a 50/50 chance of being a one or a zero.  And there's no obvious inter-bit linkage.  They're independent, and you just never know what they're going to be.  That's what you want.



Well, that's not the property that Adler32 has.  Adler32, because it was never intended to be a hash, it was just meant to be a very fast checksum, it turns out that its distribution of output values is massively non-flat.  And these guys who found this attack realized that.  And they were able, by asking the WordPress upgrade server to use the Adler32 function as the hash which was used to verify their submission, they were able to reduce the effective brute-force space down from 2^32, a full 32-bit space like CRC because that's the smallest of any of the functions that were available.  But by using Adler32, they brought it down to between 100,000 and 400,000, which is entirely practical for an online attack.  That is, like, what, 400,000.  So an order of magnitude would be four million to - so it's like, what, four orders of magnitude faster than if it used a uniformly distributed function.



So they verified it.  They built a proof-of-concept.  They submitted it to WordPress.  WordPress said, whoopsie, gave them a reward for their nice work, fixed the problem, pushed it out globally, everybody waited a while, and then these guys went public with their work.  And a beautiful piece of work it was. So nice going, guys.  And, by the way, that's WordFence.com are the people who did this.  And they're a security firm whose whole focus is WordPress-related vulnerabilities and exposures and problems.



And so I'm glad they're keeping an eye on this stuff because, boy, if that had been abused by somebody, and we don't know that it hasn't been used in some subtle fashion to get some code into the WordPress system that could have caused problems.  But at least we know now that this circuitous route, as a consequence of several factors that all kind of came together, created a vulnerability in a system that, you know, the spec looked good.  But when you look at the whole thing from a profile of trying to attack it, there were some problems.



I did want to mention a little bit of miscellany.  Supercapacitors are back in the news.  A whole bunch of people sent this to me over the last week.  Even Amber MacArthur picked up on it, Leo.  I saw that she had grabbed it.  And there's really nothing here, unfortunately.  I mean, and there's not going to be until there is because, you know, we talked about supercapacitors years ago.  I was very excited about a hopeful work happening down in the Southeast somewhere of the U.S.  Well, in this case it's University of Central Florida, so same general area.  I think the guys I was thinking about were in Texas for some reason.  But remember we talked about it, the idea being that a supercapacitor stores energy as an electrostatic charge, rather than an electrochemical reaction.  And unfortunately this was a really good photo and a very catchy headline because the headline was "A phone that charges in seconds."  Except nobody has one. 



LEO:  Right.  Somebody you'll be flying in cars.



STEVE:  And these people don't either.  So it's just, you know, we need an advance in material science.  We need - and it's going to be nano-something, and what was that, graphene, probably, in order to get high conductivity on a very, very thin dielectric insulator.  And, I mean, I love the concept.



But the other thing that everyone skips over, and we've discussed it before, is that, because of the way capacitors store power - that is, they store it as a voltage.  That's kind of the way to think of it.  They store it as a voltage rather than a current.  Power is the product of voltage times current.  So you could have high power, either by having high voltage with low current or low voltage with high current.  The high voltage with low current is the capacitor.  The low voltage with high current is the traditional electrochemical battery that we're used to.  And the problem is that our electronics of the day, it operates in a low voltage, high current mode.  Like tubes, tube technology back in the day, when you and I were young, Leo, and we used to go down to the drugstore and check the tubes on our TVs because they weren't working.



LEO:  [Crosstalk].



STEVE:  We'd, you know, plug them in and wait for them to warm up and glow.



LEO:  I remember the tube testers, yes.



STEVE:  Yes.  And you'd dial the knobs and things.  I was fascinated by that.  I thought, okay, someday I'm going to make one of these.  Like, well...



LEO:  I'm going to sell a tube tester myself.



STEVE:  Turns out I outlived the tubes.



LEO:  Yeah.



STEVE:  So those were voltage-based, high voltage and low current.  So they were sort of compatible with the capacitor as a storage mechanism.  So it's going to be interesting to see, there's sort of an awkward wedding that we're going to need, if it ends up being that capacitors are the solution.  I think it feels to me like it's the right answer because they are able to take current pretty much as fast as you can put it in there.  But you need to give them high voltage rather than a lot of current over a long period of time.  So we'll see how it develops.



And my last piece of crazy randomness is - oh, Leo, I think you're going to think this is really charming.  It is free.  It was a for-pay for about the first eight months, through August.  It was released in January of 2016.  It's called TraptionBakery, as in "contraption," but they left the "con" off.  So T-R-A-P-T-I-O-N Bakery, B-A-K-E-R-Y.  And it is not my normal type of puzzle.  You download it for free on iOS, and it starts, and this framed picture fades onto the screen with, I don't know, some sneakers and a flowerpot in the foreground.  If you scroll all the way down to the bottom - yeah.  So there's the picture.  I think if you scroll way down to the bottom of that website there's some animated GIFs - no one knows how to pronounce that.  Okay, that's a different - there's a different link at the end of my show notes, I think.



But anyway, the point is it's an animated contraption, incredibly Rube Goldberg-like, with shoes that kick the cow that then eats the hay that decreases the weight of the basket that rotates the pulley that tips the flower pot that waters the plant and so forth.  And all you do - yeah.  And so that's a long page of him explaining the process of creating this masterpiece.



LEO:  Oh, lord.



STEVE:  It really is amazing.  But go way down to the bottom, and you will find where he's animated - there we go.  And that gives you a sense of what this thing actually looks like.



LEO:  It looks kind of like fun.



STEVE:  It is.  No, Leo, I think this is a win.  I just wish it were available on Android, too.  So it's iPhone and iPad.  And all you do is you zoom in, and as you zoom in, additional details reveal themselves.  And the goal is to bake a loaf of bread.  And so it actually is, you can - and he was trying, he explains on his page how he worked to be factually correct.  He actually used baking principles of yeast rising and how much water to put in and everything.  And then it evaluates the crust on the bread and so forth.  But anyway, it's really - it's the kind of thing, you know, like if you're in a really boring meeting, you could just sort of poke around at.  Yeah, so there you've got it on camera.  And you just, like, zoom way in and...



LEO:  What's the game?  What do you do?



STEVE:  Well, that's part of the puzzle is...



LEO:  I pulled that lever.



STEVE:  When you get close enough, additional things, and they show up in blue.



LEO:  Yeah, yeah.



STEVE:  Like things that you're able to do.



LEO:  Do you have to do them in a - I guess you have to do them in a particular sequence.



STEVE:  The whole thing, there's no owner's manual.  There's no...



LEO:  This is it. 



STEVE:  It's just browse.



LEO:  There's an elephant eating grain.  Exit an elephant play area.  Wow.  This is - you know what I like?  It's original.



STEVE:  It's charming.



LEO:  And it's very original.  It's like, wow.  So it's really just a big drawing by Jon Prestidge.



STEVE:  It's a big drawing that is animated, that he put a ton of effort into.  And some of the comments:  One guy said, "While I'm not really much of a puzzle gamer, this one drew me in.  Being able to figure out this contraption and make it work was one of the best puzzler experiences I've ever had.  Everything, and I mean EVERYTHING," in caps, he says, "from the way the game is designed, to the artwork, all of the small details that become clearer as you zoom in, the thought behind every little thing and how it all interacts with everything else, is all absolutely perfect.  I can't recommend this one enough to puzzle fans."



LEO:  Yeah.  Wow, this is really interesting.  Huh.  TraptionBakery.  It's free, too, which is kind of cool.



STEVE:  Yes.  It is free.  There are several reviewers who said it was worth the money, and so I verified that - oh, and there are sounds.



LEO:  It is worth the money - nothing.



STEVE:  No, no, I mean, back when it was for pay.  And if you don't have sound turned up, sounds are a big clue, too.



LEO:  Ah.



STEVE:  So it's making sounds which are important for your current view.



[Leo turns up sound]



LEO:  Mm-hmm.  Whoa.  It changes colors.  Maybe that's a bug, I don't know.



STEVE:  I don't think there are any bugs.



LEO:  Oh, there are no bugs.  Wow, this is a - headless people only.  Oh.  Oh, I made grain go in the thing.  Aha.  But now I can't blow the horn anymore.  Hmm.  This is cool.  Very nice.



STEVE:  I think it's a win.  I think it's - again, I wish everyone could play with it.  But at least iOS, iPhone and - and actually, although you do a lot more scrolling with an iPhone, the fact that it's all about zooming means that a smaller screen can work, too, because you just have a smaller viewport into what's going on overall.



And, finally, Gary Nevills sent me - he tweeted an interesting picture.  And he said:  "Steve, do these patterns in SpinRite indicate anything specific about the condition of the disk?"  And I don't think we've ever talked about this, Leo, but in the show notes I have a snapshot of SpinRite's graphic status display which has, like, a periodic appearance of mostly red U's, meaning despite everything SpinRite tried, it was unable to recover that data.  But notice that, in a couple of the places where there would be a red U is a green R, saying SpinRite was able to - it initially could not read the data here, but it was then able, after working at it, to recover it perfectly.



What's going on - and I've been seeing these patterns for 30 years, I mean, since the beginning of SpinRite.  Not often, but remember that spinning drives are still mechanical, and they inherently have a periodicity.  They have tracks, and they have heads, and they have sectors around the track.  So something has happened, probably one of the heads.  This may be, I don't know how large the whole drive was because this was a piece of the drive.  But, for example, if a head amplifier went bad, or if the drive - it could be a scratch on the surface.  In the old days, you know, we called them a "head crash," literally a divot or a scratch on the surface.



Well, a scratch on the surface is going to create a problem, like a repeating problem in every sector that the scratch moves through.  And you're going to encounter that on this track.  And then you're going to go to switch to different heads.  Then you're going to come back up to the same sector on the next cylinder.  And that's going to be a problem again.  So an infrequent, but periodically repeating, problem is evidence of a physical event, maybe the head, but more likely a head crash.



And what's really interesting is that sometimes we'll see them in one region.  And the ends of them, like coming into the periodic, will be greens.  Then they'll go all reds.  Then they'll go back to greens.  Meaning that the damage was less at the beginning and the end of the furrow plowed, so that SpinRite was able to recover over the damage if it wasn't too great.  But in the middle, where it really became a divot, SpinRite just said, there's just, you know, there's a chunk of disk missing here.



So anyway, I thought that was really cool.  So thank you for sharing that.  And that's something I don't think we've ever talked about before is a spooky-looking pattern of repeating problems from a disk that clearly had some trouble.  SpinRite did recover some little bits of it.  But mostly it was really - and, by the way, if you ever see this, SpinRite is saying...



LEO:  Get a new disk.



STEVE:  ...okay, get what you can off this.  Don't give this, don't even give this one to your Drobo.  Drobo will not be happy, either.



LEO:  Well, what it looks like is like a single scratch, right, that's just...



STEVE:  Yes.



LEO:  The reason it's repeating like that is just because of the nature of the geometry.  But it's...



STEVE:  Exactly that.



LEO:  Yeah, like a single scratch across the disk.



STEVE:  Yup.  Isn't that cool?



LEO:  That is cool.  That's kind of neat, yeah.



STEVE:  Yeah.



LEO:  We got Q.  We got A.  Questions and answers.  Are you ready, Steve?



STEVE:  You betcha.



LEO:  I am ready, as well.  I have questions.  You have answers.  Let me push some buttons, get the Magic Q&A Eight Ball to give me your first question of the day.  And it comes to us from Tim Chase, or @gumnos.  @gumnos is his Twitter handle, G-U-M-N-O-S.  And he asks:  Regarding using my local WiFi interference to sniff PIN entry as a side-channel attack - by the way, this is the terse Twitter speaking here, so he's got this in 140 characters - my Android LG offers a "randomize the PIN order" function to mitigate.  Is he talking about WPS?



STEVE:  No.  So we talked about this, I think it was last week or the week before.  I think it was last week.  It was a side-channel attack which hackers had verified which used the MIMO antennas because there is metadata about the arrival time and relative intensity of the WiFi signal.  And it turns out that somebody holding a smartphone, the motion of their hand was being conveyed by the WiFi signal.  And with sufficiently robust recognition to weaken their entry of their PIN, the hotspot to which they were connected was able to figure out what their PIN was.



And so Tim noted that his Android LG offers a "randomize the PIN order."  And so I thought that was a nice mitigation, which was actually meant to thwart a different attack, that is, for example, it's been noted that on phones or pads where you use a PIN, you can very often hold it in a certain way and see where the person's fingers have been.  And of course a famous sort of apocryphal hack probably is after someone uses a keypad, you quickly take an IR photo of it, and you can see from the heat trail left by their finger the order in which they pushed the buttons.



And so what this does is, every time you're presented with a PIN, it randomizes what digits are where, which increases your level of effort because you have to search rather than it just being, oh, you know, 1234, which they're always in the same place, they're going to be wherever they happen to be.  And don't use that PIN, by the way.  But anyway, so just kind of cool because this was meant to thwart somebody watching you type it in, realizing, oh, I can see, like if it's 1234567890, even if you don't see the screen, you can kind of guess what the PIN was.  And other things like leaving bits of peanut butter behind on the screen if you hadn't washed your hands.  So, very cool.  And as a side effect, this automatically  mitigates a different attack that we were discussing last week.  So very cool, Tim.  Thanks for sharing that.



LEO:  Clever idea.  And credit to LG for offering it as an option.



STEVE:  Yeah, turn it on, if you've got it. 



LEO:  I think that's LG-specific.  I've never seen that before.



STEVE:  And even better, don't use a PIN, use a longer passphrase.



LEO:  Right.  Right.  Yeah, that's what I do.  I use a seven-digit passphrase.



STEVE:  Yup.



LEO:  Or a seven-digit password.  Well, I still use a PIN, but it's seven digits.  That's better than nothing.  And you have only 10 tries; right?  So here's another one from Domi, @420domi. Oh, boy.  Which DNS provider other than Google Public DNS would you recommend if I want to capital "C" Change, capital "T" The, lowercase "d" default?



STEVE:  So we haven't talked about that much.  But after the DYN attack, someone did mention to me that OpenDNS does what I was hypothesizing would be nice if someone did, which is to retain the previous IP address, even if the cached IP address expires.  Don't refuse to give it out pending an update, but give what you've got.  And someone said, hey, you know, Steve, OpenDNS does that.  And of course OpenDNS does a lot of other really good things.



And so to answer Domi's query, and anyone else who's, like, wondering about an alternative, remember that DNS can play a much more active role in security than it normally does. DNS servers are typically generic, nothing added, just you ask them for an IP of a domain name, they go find it for you and bring it back.  And then they remember it in case you ask them again, or anybody else does.  But because of their role as an index to the Internet, that is, essentially you don't - the reason there was a big outage a few weeks ago is that the index went down.  No one could convert domain names into IP addresses, and that's what our browsers need to make a connection.



So what OpenDNS has done, and they're not unique in this, but they've always been really good people, is they recognized they could add value to DNS.  So, for example, they have a free offering called - first of all, you could just use their DNS servers, which are 208.67.222.222, and 208.67.220.220.  So you just can use those.  And they're stable.  They use an anycast technology that we've discussed not too long ago, where the routers near you always send your queries to a nearby OpenDNS server.  And they're like, they straddle the globe.  They have servers all over the place.  So they're serious about this.



But you can also, for free, use the so-called Family Shield program, which is preconfigured to block adult content.  And so the idea is that, if anyone in your household attempts to look up, just visit a site, or maybe a browser by mistake tries unwittingly to obtain malware from a site that it shouldn't, it just says, sorry, don't know what the IP is for that.  And so it sort of forms a simple, network-wide content filter for everything - your phones, your pads, your machines - because everything needs to use DNS.  They also have a free Home version with customizable filtering, and they also offer ID theft protection.  And then some inexpensive, $20 per year VIP packages.



Oh, and then the one last thing I wanted to mention is that DNS, as I referred to it when I was talking about NTP earlier, the Network Time Protocol, DNS just uses UDP.  There's no encryption by default.  I mean, there's not even any encryption in any spec for DNS.  So one of the things that they offer is called DNSCrypt, which is a point-to-point, end-to-end encryption so that you run, on a Windows or a Mac, on those machines in your home, this DNSCrypt client.  Your queries go to it locally.  It encrypts them and sends them to OpenDNS.  The reply comes back encrypted, and then it's decrypted for your use.



The beauty is that that creates privacy from your network, or at least from your machine and any machines that have that, over the Internet, so that no one is able to see what domains you're going to.  Because, remember, even with HTTPS and strong authentication and privacy, your computer still had to ask its DNS server for the IP.  Anybody looking at your traffic, you know, because DNS is not encrypted, they may not know what you do there, but they do know what you looked up, where you probably went.  So OpenDNS.  It's definitely worth checking out.



LEO:  And you have, we should mention, you didn't plug it, but at GRC.com you have a DNS server test program.



STEVE:  Yes.



LEO:  For free you can download if you just want to...



STEVE:  Well, I have the Benchmark, which is a Windows app that is also Wine compatible, so you can use it on Mac or Linux.  And then I have a web-hosted service which is a Spoofability Test to make sure that the servers you're using don't have some common vulnerabilities.  None of them should now.  But it's interesting, there are some that are not generating very good random numbers, and that creates some weakness, as well.  So, yeah, you're right, I've spent a lot of time looking at DNS.



LEO:  And obviously speed isn't the only thing to consider, but it's an important criteria.  It's knowing that, you know, the servers are fast, you can run the DNS Benchmark and then see.  I've found that OpenDNS is very quick.  They're really good about, you know, this is their business.  That's all they do.



STEVE:  And up and stable.  And I was a little sorry when Cisco purchased them.  But they still seem to be doing a good job.



LEO:  Haven't changed anything yet.



STEVE:  No.



LEO:  We'll watch.  Steven Throm, @dubious_rascal on the Twitter:  I can't remember what hard drive imaging software you recommended recently.  What was it?



STEVE:  Okay.  So I get this all the time.



LEO:  Me, too.  I always - they say, "What does Steve recommend?"  And I can never remember.  So tell us.



STEVE:  Yeah.  I'm going to put this - I'm going to move this - I forgot to do it - well, it didn't occur to me.  I'm going to put it on the Link Farm page of things that everyone just can go to.  It's Terabyte Unlimited is the company, and it's www dot terabyte, T-E-R-A-B-Y-T-E U-N-L-I-M-I-T-E-D dot com, TeraByteUnlimited.com.  And it's called Image for Windows.  They also have Image for Linux and Image for DOS, and bundles.  It's inexpensive.  It is my go-to imaging solution.  I use it on my systems here.  It's what I image the GRC servers with.  It's able to run in the background.  It's able to use the shadow volume copy feature in Windows in order to essentially obtain a static image of a system in use.



So, for example, Image for Windows, you can run it while the system is up and going.  It will create an offline image of however many drives you wish it to, and/or partitions, and create a bootable thing.  And then, if your life should end, and the drives should crash, and SpinRite can't help you because, I mean, it's like really, really, really dead, then Image for DOS, which is bundled with either of them, is bootable, and so it's able to read the image format and resuscitate, basically restore it either to the same or to a new drive.  And it does things like partition sizing.  It's got all the bells and whistles.  It'll exclude the paging file and the hibernation file, I mean, it's a mature, beautiful piece of work.



LEO:  Not free, but free to try.



STEVE:  Yes.  Yeah, but it's not expensive.  I think it's $30 something.



LEO:  $38.94.



STEVE:  Yeah, it's a strange price, but still, yeah.  And he's got [crosstalk] a bunch of goodies.



LEO:  Part of the confusion is you went through a variety of different programs before you settled on this one.



STEVE:  I did.  What was the other one?



LEO:  You liked DriveSnapshot.de.



STEVE:  Drive Snapshot, yup, from the German guy.



LEO:  And there's nothing wrong with that, now; right?  I mean, that's still - yeah.



STEVE:  No, no, I just like Image for Windows.



LEO:  Yeah.  Nice, yeah.  All right.  One last short one, and then we're going to get to the long one.  So this is Julius, @j_b_t:  Prime solution IoT problem; TP-Link forces secure password input at first boot.  Device doesn't connect/go live unless you do. Superb.  Translate, please.



STEVE:  So this is Julius noting that he has a TP-Link router, and it is truly secure.  It doesn't have a default password.  It will not connect to the Internet until you have given it what it considers a secure password when it boots and you're configuring it, and you're not on the 'Net until you do that.  And I just - I thought this was a nice indication, I mean, TP-Link is a well-known company.  They produce a lot of great equipment.  And I'm encouraged to see that kind of policy.  It is a little more user-hostile because it's going to make you do something rather than just plug it in and go.  But anybody who's setting up and configuring their own router, probably they just need a nudge to say, you know, do the right thing here.  Instead of, like, "Oh, look, I plugged it in, Marge, and we're on.  Let's go."  So I'm not sure who Marge is, but still.  Probably she's around here somewhere.



LEO:  All right.  Here we go.  Get ready.  This is going to be a marathon read.  I have some work cut out for me here.  This comes from Jonathan Nelson of Orem, Utah, about Malicious Internet Background Radiation, or MIBR:  Hi, Steve.  I had an experience a couple of days ago similar to the webcam being hacked you mentioned in Episode 587.  I am a computer science student with a networking emphasis.  My teacher issued us - ta ta ta tum - a MikroTik router in one of my classes so we can get hands-on experience working with routers and routing protocols.



The latest assignment required us to sign up for a 6to4 IPv6 tunneling service through Hurricane Electric since they offer a free service that can be subscribed to without having to call a customer service representative.  I ran into problems when the tunnel setup process required an ICMP Reply to be returned by my router.  I knew from using ShieldsUP! my router would not reply and couldn't get around this step.



I had the MikroTik router set up between my Windows computer and my router.  One more, and I could have had a Three Dumb Routers setup.  I looked in my router's firmware, an Asus RT-N16, for a setting that will let it reply to the ping, but couldn't find anything.  I could have set up the MikroTik to be the exterior-facing router with my Asus as the interior, but that would have required a lot more configuration since the MikroTik had DHCP disabled as part of previous assignments.  This also would have temporarily disconnected my wife - my wife, not my WiFi, my wife - from the Internet, an already not uncommon event due to my experimenting on my own, with which she has expressed frustration.



I decided to set up the MikroTik as a DMZ connection.  Immediately the ICMP packet went through and the reply back again.  I was already logged into the terminal of the MikroTik router and had only typed the first three of four commands required for the assignment when I got a message on the console saying "system, error, critical login failure for user root from 79.66.93.197 via telnet."  At first I thought I must have entered a command wrong from my homework.  Turned out someone was pinging the router and trying to log in via telnet.



I wasn't concerned, as I had set a password for the telnet client, but was surprised at how quickly the attacks had started.  The IP address the attacks were coming from changed every so often.  The username rotated between "admin," "root," and, curiously, "666666," among a few others.  I finished my homework quickly and disabled the DMZ feature of my Asus router.  This is the first time I have seen an active attack as it happened.  Probably it won't be the last since I intend to get a job in network security when I graduate.



Thanks for the podcast.  I have listened for many years.  Often as my teachers are explaining basic crypto concepts, such as preshared versus public key, I think to myself, "Duh, we all learned this before," and then realize, oh, I learned it from Security Now!.  Thank you.  P.S.:  Feel free to rake me over the coals if I was stupid.  I can take it.



STEVE:  So no stupidity.  Sort of some cleverness.  So the short version is he, for a very impressive-sounding class, needed to use a service in the cloud, a cloud-based, you know, Internet-based service that required a confirmation of the router's existence.  It had to respond to unsolicited traffic, to an incoming ping.  So the ASUS router he had on his border wouldn't do that, couldn't be configured to do that.  So he used the DMZ feature of the ASUS to send unsolicited incoming traffic to a specific IP on his LAN, which is where the MikroTik router was configured.  So that meant that any unsolicited traffic would go to the router.



The cool thing is that he happened to have - he was logged into the router with the console open when, as he put it, malicious Internet background radiation, because of course we know that I coined the term Internet Background Radiation, IBR, to sort of reflect the fact that there's just all this junk out there, packets flying around everywhere from, like, copies of Nimda and Code Red worm that are never going to die because they're in some closet somewhere, and they're still out scanning, thinking that it's, you know, partying like it's 1999.  So basically, by using the DMZ on his border router, he exposed a router that had an open telnet port to the Internet.  And within seconds something was trying to log on.  And not just one something, but as he said, the IP address kept changing.  That can't be a spoofed IP because telnet is a TCP protocol.



So those were real IP addresses of things, of something or other, you know, who knows, other people's DVRs or webcams or baby cams, scanning the Internet, looking for company.  And they thought they might be able to nestle into his MikroTik router.  He happened to have a console session open and got an error message, "You got the password wrong."  He says, "Wait a minute, I didn't try to log in."  No, some bot somewhere on the Internet did.  That's today's reality, which is just amazing.  So a very cool story.



LEO:  Presumably there are, right now, all the time running, scanners scanning ports.  One of the ports they look for is open port 23.  Ah, that's the telnet port.



STEVE:  Twenty-three, baby.



LEO:  Maybe some moron has put his telnet server online without changing the default password.  Let's see.  But I'm sure that goes on constantly.



STEVE:  Yeah.  And that's of course why these things were trying admin and root, and there must be a bunch of devices that are 666666 as their default password.



LEO:  Right, yeah.  What do you think?  One more?  Two more?  How do you want - what do you want to do?



STEVE:  Let's wrap it up, and we'll continue next week.



LEO:  Dealio.  



STEVE:  Perfect.



LEO:  Steve Gibson and Security Now! every Tuesday, 1:30 p.m. Pacific, 4:30 Eastern, 21:30 UTC, if you want to hear your kind of college-level course, maybe graduate level course in the computer, in Internet, in security.  You can get it at his site, GRC.com.  Actually, while you're there, pick up a copy of SpinRite, world's finest hard drive maintenance and recovery utility.  He's got lots of freebies there, including things like that DNS Benchmark.  He just writes stuff.  He's very prolific, and leaves it there, and then you never know.  ShieldsUP! would be a good one to test your ICMP ports.



STEVE:  I just heard that the Guardian referenced GRC.  Somehow they found my Cookie Forensics page.



LEO:  Perfect, yeah.



STEVE:  Which, you know, to check the way your browser handles cookies.  And people sent me tweets saying, hey, did you know that you're in the Guardian?  It's like, yeah, cool.



LEO:  That's the thing.  All this stuff is there, and it just kind of stays there forever.  So GRC.com.  And browse around.  You'll be amazed at the depth and breadth of stuff that's there.  You'll find audio for this podcast - written transcriptions, too - for every episode, all, what is it, 588 shows.  You'll also find the show notes there.  That's the only place we put the show notes.  If you want video, we also have that at TWiT.tv/sn on our website, TWiT.tv/sn.  And it's on YouTube.  It's on everywhere - Stitcher, Google Play Music.  Anywhere you can get a podcast, you'll find Security Now!.  And most of those places will let you subscribe so you get it automatically every week, which is a great idea.  Start building your collection.  Collect all 588.  And then continue to collect.



We will be back next week.  Actually, you're going to be up here Thursday.



STEVE:  Yes, I am, yup.



LEO:  So 2:00 p.m. Pacific, 5:00 p.m. Eastern, 22:00 UTC.  You'll be able to watch, because we were debating whether we should do it in secret and then surprise you on...



STEVE:  Ah.  So it is going to be aired.



LEO:  Yeah.  It's for our Christmas Day TWiT.  Nobody wants to do a TWiT on Christmas Day, so we thought this would be fun.  It's something new.  And it started, and you were there, one of our New Year's Eve broadcasts, you were there, Randal Schwartz, Paul Thurrott, I think.  I can't remember.  But we had three or four...



STEVE:  We had a really great roundtable. 



LEO:  Such a good conversation.  And Lisa and I both remembered that and thought, why don't we do that every year, bring in different hosts?  Next year it'll be a different group.  But cross-pollinate a little bit.  So we invited a bunch of hosts, and you were the first three to respond:  Denise Howell, Steve Gibson, and Rene Ritchie.  All will be in-studio with me.



STEVE:  Nice, nice.



LEO:  And we'll be - what we're going to do is go through the big stories of 2016.



STEVE:  Perfect.



LEO:  Yeah.  And we won't want more than 10 or so, but it'll be a fun one that you can watch, if you want, on Thursday, and listen to and watch on Christmas evening, as well, because that'll be a lot of fun.  So that's our Christmas episode this Thursday, with Steve coming up here.  I'll look forward to seeing you.  We'll save a bottle of Cab for you.



STEVE:  Perfect.



LEO:  All right.  Thanks, Steve.  We'll see you next week on Security Now!.



STEVE:  Right-o.



LEO:  Bye-bye.



STEVE:  Bye.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#589

DATE:		December 6, 2016

TITLE:		Listener Feedback #244

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-589.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss Android meeting Gooligan, Windows Upgrades bypassing BitLocker, and nearly one million U.K. routers taken down by a Mirai variant.  The popular AirDroid app is "doing it wrong."  Researchers invent a clever credit card disclosure hack; Cloudflare reports a new emerging botnet threat; deliberate backdoors are discovered in 80 different models of Sony IP cameras; we get some closure on our San Fran Muni hacker.



We talk about a fun hack with Amazon's Echo and Google's Home, how to kill a USB port in seconds, a caution about keyless entry (and exit), too-easy-to-spoof fingerprint readers, an extremely troubling report from the U.K., and, finally, some good news:  the open-source covert USB hack-defeating "BeamGun"!  We move on to a bunch of fun miscellany, some great sci-fi reader/listener book news, and however many questions we're able to get to by the end of two hours.



SHOW TEASE:  It's time for Security Now!.  Steve's here.  We've got lots to talk about.  It's a question-and-answer episode; and, for the first time ever, with no questions and no answers.  We actually run out of time before we get to questions.  Maybe next week.  Don't be fooled by the title of the show.  We have lots to talk about, though.  So let's get to it.  Security Now! is next.



LEO LAPORTE:  This is Security Now!, Episode 589, recorded Tuesday, December 6th, 2016:  Your questions, Steve's answers, #244.



It's time for Security Now!, the show where we protect you, your loved ones, your privacy online with the king of security, Mr. Steve Gibson.  He is here once again to bless us with his wisdom and knowledge.  Hello, Steve.



STEVE GIBSON:  With the Vulcan hand sign, your thumb's supposed to be in, right, with the other fingers?



LEO:  You're asking the wrong guy.  Yeah, I think in.



STEVE:  I think in, yeah.  Out seems wrong.  Anyway, so...



LEO:  And which hand?  You do yours with the left.



STEVE:  Well, I'm left-handed, so...



LEO:  I'm left-handed.  I can't really do it with my left.  I practiced with my right, I guess.



STEVE:  The best man in my wedding was unable to do it.  So he had some little rubber bands.



LEO:  Oh, that's funny.



STEVE:  That were, like, holding his fingers in two sets.  Because I said, "Gary, please do not embarrass me," because, I mean, there's never been anyone in the world more capable of embarrassing someone.



LEO:  But wait a minute.  Wait a minute, now.  This is a revelation because - are you saying everyone at your wedding party had to do the Vulcan "live long and prosper" gesture?



STEVE:  No.  No, he got up for the best man speech.  And he said, "Steve has asked me please not to embarrass him terminally.  So all I will say is" - and then he held up his hand, and there were two little red, like...



LEO:  Rubber bands?



STEVE:  ...orthodontic rubber bands.



LEO:  Oh, that's too cute.



STEVE:  He said, "Live long and prosper."



LEO:  Aw.  What a great toast.



STEVE:  That was perfect for me, yes.



LEO:  Great toast.



STEVE:  So last week was Q&A 243.  And there was so much going on that we, well, we hit our two-hour podcast time limit after five questions.  And those were the easy questions that I sort of put first so we could just get through them.  So I thought, okay.  Let's try again:  Q&A #244.  Except that we've got Android meets Gooligan, Windows Upgrades bypass BitLocker, nearly a million U.K. routers taken down by a variant of the Mirai worm/botnet.  The popular AirDroid app is seriously doing it wrong.



LEO:  Yikes.



STEVE:  Researchers have invented a clever credit card disclosure hack.  Cloudflare reports a new emerging botnet threat that they've been tracking.



LEO:  Oh, boy.



STEVE:  Deliberate backdoors were discovered in 80, eight zero, different models of Sony's higher end...



LEO:  No.



STEVE:  ...IP cameras.



LEO:  No.



STEVE:  We get some closure on our San Francisco Muni hacker.



LEO:  Oh, good.



STEVE:  And I heard you at the end of MacBreak Weekly noting this fun hack where the Amazon Echo and the Google Home were talking to each other.



LEO:  Yeah, yeah, yeah.



STEVE:  So I just wanted to mention that.



LEO:  I'll play it.



STEVE:  There is an interesting USB port-killing dongle which has surfaced and is now commercially available that we need to talk about briefly.  A caution about keyless entry.  Too-easy-to-spoof fingerprint readers on some smartphones.  An extremely troubling report comes from detectives or detectives' behavior in the U.K.  And, finally, some good news:  An open source covert USB hack-defeating bit of software.  We've got a bunch of fun miscellany, some science fiction reader/listener book news.  And not that there's going to be any time left, but we do have - I think I had seven questions.  I thought, well, we're never going to get to 10, so I'm not even going to pretend.  But we've got five from last week that have spilled over, and I found two others just so we wouldn't run out.  We're not going to run out.  So, yes, I think another great news-packed podcast for our listeners.



LEO:  Nice.  I'm very excited.  And we had such a good time with you when you came up here for our year-end TWiT, which will air on Christmas Day.



STEVE:  Yeah, great.



LEO:  And then for the Christmas party you stuck around as long as you could.



STEVE:  Until Rene and I said, "Okay, we're done.  Take us back to the hotel."



LEO:  Took you back in the Tesla.



STEVE:  And I got to buzz around in your lovely Tesla.



LEO:  Oh, that's fun.



STEVE:  With the doors that worked most of the time.



LEO:  Yeah, you know, it's funny, it's behaved very well ever since.  But something about you guys just broke them.  Anyway.



STEVE:  So our Picture of the Week I got a kick out of.  Someone shot me a cartoon from the always wonderful xkcd.  And this is his No. 1758, which depicts a large window-encrusted building in the background with a very large prominent lawn sign labeling the building Department of Astrophysics, under which it gives us their motto.  The motto of the Department of Astrophysics:  "Yes," it reads, "everybody has already had the idea, 'Maybe there's no dark matter - gravity just works differently on large scales.'  It sounds good, but doesn't really fit the data."



LEO:  Oh, Steve.



STEVE:  So know that before you pass the sign.  Yeah.  And, you know, my point is, or was, has been, still is, that it's like the equation doesn't balance.  And so you go, oh, okay, there's just a big blob of dark matter that, if we put that in, look, now the equality works.  It's like, okay, but that's really a hack.  So I have no opinion one way or the other.  I just thought it was fun that somebody had come up with a theory of gravitation that didn't seem to have that problem.



But speaking of problems, Gooligan, which I guess must be what happens when you take hooligan and google-ize it, you get Gooligan?  I mean, I guess that's the derivation of this name.  Check Point is in the news again.  They've essentially reverse-engineered a mystery which - I think they have pretty much figured out what's been going on, which is a campaign which has been taking advantage of users who make the mistake of loading things into their Android phones from third-party, non-Google Play sites.



So that's the source of the problem.  And it's estimated that more than - now, I'm seeing one million.  Oh, I know I saw two because logs collected by Check Point researchers show that every day Gooligan installs at least 30,000 apps fraudulently - and I'll explain what that means because it's installing them as a means of making money for the hackers, which is an interesting twist, which of course provides their motivation - on breached devices, or over two million apps since the campaign began.  So there's two million apps.  And they've tracked a compromise of as many as one million Google accounts.



So the Check Point blog starts out saying:  "As a result of a lot of hard work done by our security research teams, we revealed today" - and this was last week - "a new and alarming malware campaign.  The attack campaign, named Gooligan, breached the security of over one million Google accounts.  The number continues to rise at an additional 13,000 breached devices each day.  Our research exposes how the malware roots infected devices and steals authentication tokens that can then be used to access data from Google Play, Gmail, Google Photos, Google Docs, G Suite, Google Drive, and more.  Gooligan is a new variant of the Android malware campaign found by [they say] our researchers" - Check Point researchers - "in the SnapPea app last year."  So this began, as these things so often do, as sort of an isolated instance.  And then it got - sometimes it's militarized or weaponized or commercialized.



Check Point reached out to the Google Security team immediately with information about the campaign.  And they say:  "Our researchers are working closely with Google to investigate the source of the Gooligan."  So what they found was traces of this Gooligan malware code in dozens - and I saw the number 86 as I was digging into this - of legitimate-looking apps on third-party Android app stores.  These stores are an attractive alternative, as we know, to Google Play, for those who are not security conscious because many of the apps are free, or offer free versions of paid apps.  However, the security of these stores, as we know, and the apps they sell, aren't always verified, although we might say are not verified.



"Gooligan-infected apps can also be installed using phishing scams where" - so it's not just users going to a third-party store or following a recommendation from a friend, "Oh, go get this over here," but it could just be a phishing campaign that gets this thing into your phone.  So the way this makes money is that the malware, once the malware is in your phone, it simulates app advertisements provided by legitimate ad networks, causing the apps to install on the victim's device.



So you first install this covertly malicious, Gooligan-infected app.  And who knows what the back story is there.  I mean, there's 86 of them.  So you have to sort of wonder if the Gooligan people aren't maybe paying for co-residence in these apps.  Or, I mean, maybe they're creating themselves from scratch, but that seems a little less likely than, hey, we'll give you some money if you'll put this little extra goody in your app that's not going to go through the Google Play Store, which would allow Google to spot it and remove it.



So once the phone is infested, it then downloads additional apps for which the Gooligan malware authors are paid by the ad network, by the legitimate ad network, when one of those apps is - one or more are installed successfully.  So this affects Android 4 devices (Jellybean and KitKat), and 5 (Lollipop), which encompasses more than three quarters of the market devices today.  And the preponderance of them, about 57%, are located in Asia, with about 9% in Europe.  So essentially that's what's going on.



Now, what's significant is that what Gooligan downloads, after Gooligan gets into the phone, it sends data about the device to the campaign's, that is, the Gooligan campaign's command-and-control server.  It then downloads a rootkit from the command-and-control server that takes advantage of multiple well-known, but typically unpatched, Android 4 and 5 exploits, including one named VROOT.  And it's got the CVE designation starting with 2013.  So it's three years old.  And that doesn't matter, as we know.  The older Android phones, or in some cases not so old phones that just aren't being maintained by their providers, won't be updated.  And the other common one is known as Towelroot that has a CVE dated 2014.



So in both cases these exploits still plague many devices today because security patches that fix them may not be available for some versions of Android, or the patches were never installed by the user, or never offered by the bandwidth provider.  So if the rooting is successful, the attacker has full control of the device and can execute privileged commands remotely.  So it's a full remote-access takeover of this breathtaking number of Android devices.  After achieving root, Gooligan downloads another new malicious module from the command-and-control server and installs it on the infected device.  That module injects code into running Google Play and Google Mobile Services to mimic user behavior.  So sort of like a little automation shim that allows Gooligan to avoid detection.  And that's been seen historically on other mobile malware.



That module allows Gooligan to steal a user's Gmail email account and authentication token information, install apps from Google Play, and rate them to raise their reputation.  It gives all the apps five-star ratings after it downloads them and installs adware, which generates revenue.  So of course the ad servers, which don't know whether an app using its service is malicious or not, sends Gooligan the names of the apps to download from Google Play.  So the whole system sort of forms a self-sustaining ecosystem which is catastrophically rooting and infecting vulnerable Android devices while generating revenue for the miscreants behind it and continuing to support itself.



So unfortunately, you know - and we've watched the evolution of this over time.  Ten years ago, several years into this podcast, we were sort of musing how isn't it interesting that all the Outlook viruses that we were covering back then, you know, they never really seemed to do anything except just exist.  But the moment we saw this pay-to-unlock-your-encrypted-data cryptomalware, suddenly it became clear, as we predicted on the podcast, we're going to be seeing a lot more of this because, as soon as this goes from, "Oh, look, Ma, what I was able to do after school" to, "Oh, look at the size of my bank account," that really changes the equation.



And so here again is a way of leveraging the Internet advertising revenue system.  And we've seen fraudulent clicks and so forth performed by scripting and browsers and that.  This now, of course, also your phone is hooked into a command-and-control server.  And remember that the fact that it's obtaining fresh code means that that allows them to dynamically vary what sort of this ad hoc network of rooted devices will do.  So more than a million of them are currently doing this.  But they can change that, apparently, at will.   And it's not clear.  I guess these phones are stranded.  I don't know how Google ever really resolves this for people, except the phones die, finally, and they get newer ones, which hopefully have an additional four years' worth of security learning under their belt.  Wow.



And, oh, this is a fun one, a BitLocker bypass on Windows 10 through Windows Upgrades.  The root of the problem is unattended upgrades on Windows 10 machines.  Think about it.  How can a locked machine, protected by BitLocker, that is, so that the system drive, the whole drive is encrypted, how can it perform unattended upgrades?  We know they do.  People are annoyed by it all the time.  The system has to have some means of decrypting the system drive without the user's explicit interaction, permission, and password.



A hacker named Sami Laiho discovered an issue in Microsoft's Windows 10 OS that allows attackers to gain access to BitLocker-encrypted data.  Some of the coverage has been inexpertly worded because they talk about BitLocker being disabled.  Okay, well, we know you can't disable BitLocker.  If the entire drive is encrypted, then you actually have to go the other direction.  You have to fully enable BitLocker, giving it whatever it needs, the master secret key, which then allows it to decrypt and encrypt individual sectors through some means.



So Sami posted on the Win-Fu blog essentially the highlights of his method.  He wrote:  "There is a small but crazy bug in the way the Feature Update, which was previously known as Upgrade, is installed.  The installation of a new build is done by reimaging the machine and the image installed by [as we know] a small version of Windows called Windows PE, the Preinstallation Environment.  This has a feature for troubleshooting that allows you to press Shift-F10 to get a command prompt.  This allows for decrypted access to a BitLocker-encrypted hard disk" because, during the upgrade, Microsoft necessarily has to be able to get that drive into a decrypted, or unencrypted read/write state.



So if Shift-F10 is pressed at the appropriate time during an upgrade, without administrator privileges, without the legitimate user present, requiring no authentication at all, a command prompt window is opened which allows full and unrestricted access to the system's storage devices.  Whoopsie.  So this method works, not when performing little incremental updates, but on a major release install.  So, for example, it works if you went from the original Windows 10 release build, and you were jumping to the November Update 1511 or the Anniversary Update 1607.  And of course those are things that affect all users.



It also currently works on any new insider build since, as we know, those are sort of incremental whole system movements.  So it's that phase.  It's the major release upgrade.  Windows, while it's doing it - and we presume it's managing the keys securely.  What this implies, though -  and this has always made me nervous about BitLocker as opposed to, for example, TrueCrypt.  For example, Windows couldn't do this.  Windows 10 with a TrueCrypt-encrypted drive could not do it because it would not have the keys.  But since it's established the BitLocker drive, it has no doubt squirreled its own private copy of that master decryption key somewhere, hopefully using Trusted Platform Module, I mean, like, doing something good to protect it.



But the point is it's there.  And that automatically implies that, if compelled to do so, Microsoft does have the ability to unlock a BitLocker drive.  The fact that they're able to perform a substantial image update on a locked, non-admin-accessed drive shows us that it's possible for that to happen.  So, again, we assume that they have done a good job of protecting the keys.  But they're there, which is not the case if you use a third-party whole-drive encryption solution.  So a tip of the hat to Sami for noting that.



If we'd thought about it, it's obvious, in retrospect.  Windows has to have that ability to take the drive out of full lockdown encryption in order to make a major change to it without any intervention.  And in the coverage of this it's been suggested that companies should disallow switching the Windows insider builds on for machines running Windows 10, sort of as a partial mitigation, only because what that does is at least it makes those opportunities much less frequent.  Every available insider build creates another vulnerable moment when someone could access it.  And of course, if someone grabbed a machine that was set up to automatically install insider builds, like law enforcement, all they would have to do is wait for one to become available, and the machine would unlock itself for them.



And then he also says that companies may also want to disallow unattended upgrades, but not necessarily updates.  Again, it's the major system upgrades that, if you disable that, then you prevent this from happening.  So anyway, just a heads-up.  Again, it should have been obvious to us that Windows would have to have this capability.  And it's sort of an interesting note, too, that on a non-Windows-derived whole-drive encryption they can't.  It would always take the user to provide the key from outside the system in order to allow Windows to do what it wants to do.



Wow, there's been a lot of IoT or router stuff.  TalkTalk is a major European provider.  Unfortunately, they're sort of in panic/denial mode because what, for example, Deutsche Telecom is saying is that as many as 900,000 of its customers had lost their Internet connection as a result of a recent attack, and this is last week.  The BBC reported that thousands of TalkTalk and U.K. Post Office customers had their Internet access cut off by another attack against routers, probably the same one.  And a spokesman for the Post Office told the BBC that the problem began Sunday before last, and it affected somewhere on the order of 100,000 of its customers.



Meanwhile, TalkTalk, that seems to be at the center of the storm, says that "some of its customers" had been affected, and it was working on a fix.  So it turns out this was all surrounding a modified form of the Mirai worm.  And of course we've been discussing variants of Mirai and are not surprised because we know that the source code got published, and that we were immediately going to see variants.  So we are.



And of course the problem is we've also been talking about IoT devices being shielded by their routers and how, fortunately, a router, especially with Universal Plug and Play disabled, if the IoT device will still work with Universal Plug and Play disabled to keep the device from mapping ports into it from the outside, that router provides protection.  But there's no protection for the router itself.  It's the device on the front line.  It's the one with the public Internet connection.  So it's really important that those be locked down.  TalkTalk uses a DSL D-Link router.  And I also saw, I was sorry to see that a ZyXEL router was also implicated in this.  So it looks like there are a number of them that have some weakness.  A researcher observed the worm infecting the router, then a while later coming back and stealing the router's SSID and password.



And the article that I was digging into this through noted that Wigle.net, spelled W-I-G-L-E dot net, a site I had not encountered before, W-I-G-L-E dot net, that is a search engine that aggregates and tracks networks.  And, for example, you can put an SSID into it, and it will tell you where it is.  Now, we know that, for example, Google has all that information.  That's one of the things that they were collecting when they roamed around the streets with their mapping software, picking up the SSIDs of routers.  And years we talked about how that strategy sometimes got confused if someone moved across the country and kept the router named the same.  Suddenly it would be a little confusing.  And of course SSIDs are not guaranteed to be unique.  So you can have collisions, and I'm sure there are lots of them.



But what that means, there was a bit of a problem here because it means that malware that obtains your SSID and password can then use Wigle, W-I-G-L-E dot net, to essentially obtain your physical location from an IP address and probably disambiguate SSID collisions based on the IP because it'll certainly have your IP address, too, your public IP.  So it could easily get some sense for what country you're in, and maybe even what region you're in, because we know that IP mapping is getting a lot better over time.  Wow.



There's a very popular tool, estimated it's been installed in about 50 million Android devices, known as AirDroid.  It's a remote Android management tool.  And, unfortunately, this is our "you're doing it wrong" story of the week.



LEO:  You know, it's so funny because I use AirDroid, and we've recommended it for years.  So now I'm worried.



STEVE:  Well, okay.  So here's the problem:  no authentication, and weak encryption.  If you don't authenticate...



LEO:  Oh, well.  If that's all....



STEVE:  Right.  So as I said here in my show notes, unfortunately, its communications protocol only uses rather weak encryption - get this - one round of DES and no authentication.  And we know what that means.  Without strong authentication, encryption is unable to guarantee any privacy whatsoever.  AirDroid's communications are encrypted with DES.  Now, that's of course the Data Encryption Standard from the Stone Age.



But here's the first problem.  They use ECB mode.  Well, that's Electronic Code Book, which is a fancy name for no chaining.  That is, and DES is a 64-bit block.  So that's one of the many problems.  As we've discussed, 64 bits no longer provides enough security margin, which is why all new ciphers are 128 or 256 bits at a time, the idea being that you put that set of bits in, and a different set of the same number come out.  But with 64 bits, that's just not enough scrambling as possible.



But the point of electronic code book is that there are tremendous benefits from, as we call it, cipher block chaining (CBC) of various sorts.  Electronic code book takes each block by itself, with no interblock dependency.   It's the chaining of the successive blocks that prevents you from, well, from easily spotting patterns in the communications.  Because the point is, with electronic code book, every time the same 64 bits is encrypted under the same key, you're going to get the same 64 bits out.  So this doesn't hide any repeated use of plaintext, whereas cipher block chaining is designed to do just that.



Next up in bad news is the encryption key, which to start off with is only 56 bits because that's the DES encryption key size, is hard coded in the app itself.  Thus it's known to any attacker.  And, oh, by the way, the key is numerals 890, then lowercase jklms.  And that's eight characters.  And understand, of course, that it's like I had to do a double-take because that's the key.  You know, we're used to cryptographic keys being these gnarly-looking 256 bits converted to ASCII, and it's just this huge thing of gibberish.  This is 890jklms, and that's the entire key.  And everybody knows it.  So an attacker performing a man-in-the-middle attack and redirecting HTTP traffic to a malicious proxy can modify the response received from the phone's phone/vncupgrade request, which is normally used by AirDroid to check for updates to its add-ons.  That allows an attacker to inject their own update and remotely execute custom code on the target device.



Now, here's the sad thing.  This was found - oh, and by the way, this was all from Zimperium, our friends that first discovered and brought us Stagefright, which was really pretty frightening for quite a while.  They found this on May 24th of this year, so late spring, before the summertime; disclosed this; sent it to the AirDroid guys.  On the 30th, six days later, they received an acknowledgment.  Zimperium followed up on August 10th, on August 17th, on August 22nd, on August 28th, on September 6th.  Finally, on September 7th, they got a reply about a new upcoming release.  Yay.



November 28th, not quite two months later, AirDroid 4.0.0 is released.  Still vulnerable.  Oops.  Two days later, November 30th, AirDroid 4.0.1 released.  Still vulnerable.  December 1st, full disclosure.  So Zimperium did the right thing.  They took a look inside this app to see what it was doing.  They found that - I'm sure that the authors had the best of intentions, but it's just it's amateur-league crypto.  I mean, it's just - you would have to call this obfuscatory.  I mean, it's not protecting anyone's privacy.  It doesn't protect it from man-in-the-middle attacks.  Anybody on the same network or who could position themselves to intercept the traffic can do so, decrypt what's going there, change queries, change response data.  The AirDroid app won't know any different, and 50 million users are using it now.  So for Leo, you and any of our listeners...



LEO:  Well, I stopped using it a long time ago.  But now I'm glad I did.  Holy cow.



STEVE:  Yeah, yeah.



LEO:  Well, it was basically a very cool way of accessing the data on your Android device from your computer and vice versa, you know, kind of communicating wirelessly.



STEVE:  Yes.  And I would love to have that, for example, on my iOS devices, that kind of thing.



LEO:  Well, you kind of do.  It combines AirDrop with Handoff.  It has a little Pushbullet stuff in there, too.  But, yeah, yeah.  I had it.  I didn't use it that much, so I just kind of took it off.  But it's got a lot of downloads.  I mean, a lot of people use them.



STEVE:  Yeah.  Well, I mean, again, I don't think this was malicious or deliberate.  It's just these guys just didn't care.



LEO:  Ham-fisted.



STEVE:  Yeah.  And it's hard to - like, DES, really? 



LEO:  Yeah, everybody knows that.  Geez.



STEVE:  Yeah.  So this is so clever.  This is one of these where it's sort of always been there, and it never occurred to us.  And that is a group of security researchers have figured out how to crack the unknown information on any credit card.  So to back up a little bit, we know, I mean, certainly I know because I wrote my own ecommerce system.  I ask users for the set of possible information:  their name; the 16-digit card number, 12 in some cases, I guess; the card expiration date; the CVV, the card verification value; and their street address, that and zip code.  And all of that information - except the cardholder name.  That's never part of the verification.  But the credit card number, expiration date, CVV, and the digits from the street and the zip code, or postal code, those are all sent through an API that I've established with the merchant, the credit card merchant, to verify this information.



Now, of course I do all of that.  And I was careful not to tell a visitor, a purchaser of SpinRite, what's wrong because I want to protect everyone's security.  So I just - and it'd be easier if I said, oh, you know, you got the zip code wrong.  But that also obviously creates an information leakage, which I explicitly avoided.  So I just say sorry, try again, something was wrong.  I know exactly what's wrong because I get error status information back from the credit card processing merchant.  But I don't share that with someone on the site because they might be trying to abuse the security and the protections.



The bad news is not all sites that process credit cards check everything.  There are some that only do the absolute minimum, which is the credit card number, known as the PAN, the P-A-N, the Primary Account Number, and the expiration date.  Those two things are the absolute minimum, and it's all that some sites do.  Some do three fields.  They'll do the PAN; the expiration date; and that CVV, that verification number, the three digits, sometimes it's four, printed on the back.  But that is explicitly not in the mag stripe, the idea being that it's not possible for anyone who electronically reads the card to determine what was printed on the outside.  And then you may have the full monty, which is what GRC does, which is the credit card number, expiration date, CVV, and both numeric portions of the physical address, the street number and the postal code.



So what these guys very cleverly realized was, by identifying what things a huge number of ecommerce-enabled sites on the Internet check, they are able to step through and determine all of the fields.  So, for example, there are only 60, six zero, possible expiration dates because cards are only issued with expirations a limited time in the future.  And expiration dates are only granular to the month - 12/2016, for example.  So they've identified a large number of sites which only check two fields.



So they just guess.  They put in the credit card number they want to crack, and they try expiration dates from - I don't know if they did it from now to further out, or start in the middle and go both directions.  There's probably one strategy that would tend to work more than another.  But the point is there's only 60 possible expiration dates.  So they're going to get a success, eventually, on one of those sites.  But they may not want to buy any squirrels today.  So the squirrel ecommerce site is not where they want to perpetrate their fraud.  But that squirrel ecommerce site just - I don't know why I chose the word "squirrel."  That's not the term I really want to use.



LEO:  Yeah.



STEVE:  Don't pay any attention to the SQRL logo.



LEO:  No SQRLs.



STEVE:  On my microphone.



LEO:  Nope.



STEVE:  A squirrely site.  Anyway, so now they have the expiration date that matches the credit card as approved by the backend verifier.  They cancel the purchase instead of following through with it.  Or maybe they buy something for a dollar.  But basically that allows them to take that first step.  Now they go to a site that checks the credit card number, the expiration date, which they have both of now, and the CVV.  Well, that's three digits.  So there's only a thousand of those.  Lots of ecommerce sites.  So they again guess until they get it right.



Now they're down to the address.  And it's a little trickier there.  First of all, it should be noted that most sites don't incorporate address.  That is, just the three fields - the credit card number, the expiration date, and the CVV - they're regarded as, well, how could a bad guy know that?  That's got to be secure enough.  So it's very likely that that's all they need, then, in order to essentially reverse-engineer the information.  So the weakness comes from the fact that the backend verifier is not smarter, is not as smart as it could be.



It turns out MasterCard processing is.  It will notice 10 global attempts and failures on the same card and lock it down.  Visa, the largest processor/credit card network in the world does have no similar protections.  So MasterCard will tend to thwart this because, if you've got to guess 60 expirations plus a thousand - oh, I guess expirations, maybe half that on average, so 30 - and maybe 500 CVVs.  Still, now you're at 530.  And on average guessing a MasterCard locks you out after 10.  So you cannot attack MasterCard that way.  But you can attack Visa that way.  I just thought this was very clever.  I mean, it's just been, again, one of these things that's been sitting here in the open that nobody really thought about.



And, for example, GRC also, as I've mentioned before, puts a strict limit on the number of anything that happens on our ecommerce system.  That is, I have a counter, and I count up.  And as soon as that thing hits a maximum, I say, I'm sorry, I mean, for any reason at all because you can't have any exceptions.  I just say, you know, whatever you're doing is not in compliance with the policies of this site.  We'd love to sell you a copy of SpinRite, but apparently that's not going to happen.  Many sites do perform a lockout like this, but there are others that don't.  And even those that do, that are not testing everything, can still be abused.



So this proof-of-concept software that these guys developed uses a site until it locks them out, and then they go somewhere else.  And again, there's tens of thousands of them on the Internet, no coordination among them except for the central clearinghouse.  MasterCard got it right.  For whatever reason, Visa decided not to do that.  And these guys noted that, once you get enough information, you can then transfer money through Western Union to Russia or wherever, and that money is gone.  Now, of course, Visa indemnifies its cardholders for that kind of fraud, so you just say, "Hey, I didn't buy this," and they remove the charge from your statement.  At some point, if this continues to escalate, this gets expensive for Visa.  And I imagine they'll think about creating a better lockout system.  Very cool hack, though.  Just I thought that was so clever.



Cloudflare has been noting signs of a growing Mirai-rivaling DDoS botnet being formed.  They've been watching traffic and spotting patterns.  On November 23rd this began, the day before Thanksgiving, when they encountered an 8.5-hour, 172 million packet per second attack delivering 400Gbps.



LEO:  Yikes.



STEVE:  Yeah.  The following day it repeated, though it started 30 minutes earlier.  On the third day, the same start time, but it ended a bit earlier.  Typically around eight hours.  After getting up to 200 million packets per second and 480 gigabits per second, sustained for eight hours.  And this continued, day after day, through Black Friday, Cyber Monday, and into this week - that is, this week - with traffic peaks up to 400Gbps for hours on end.  And a week ago, last Tuesday, the attacks stopped taking, what, 16-hour breaks.  They're now running 24 hours a day.  So but Cloudflare knows they are not coming from the Mirai botnet because we know what the Mirai botnet does.  They're using different attack software and sending very large Layer 3 and Layer 4 floods aimed at TCP.



So that's old-school DDoS style, or DoS style, attacks.  Layer 7 is the so-called "application" layer.  And that's what we know Mirai was using.  It was using non-spoofed HTTP and HTTPS connections.  That's Layer 7.  Layer 1 is the physical layer, that is, the actual definition of the wires and the voltages on the wires of, for example, Ethernet.  Layer 2 is the data link which describes what the waveforms are on those wires, and how data is represented.  Layer 3 is the network layer, which is the first emergence, then, of aggregated bytes to form packets.  Then Layer 4 is the transport layer, where you've got IP headers and protocol designations and so forth.  This was all really well architected in the beginning.  It's called the OSI network model, Layers 1 through 7.



And so these bots running in layers 3 and 4 are not bothering with establishing TCP connections and running anything over the TCP protocol the way Mirai has been.  They're running down at transport and network layer, so a lower level attack.  But, wow, sizeable.  And I have a feeling we'll be hearing more about that in the future.



Okay.  Sony.  A group called SEC Consult, security researchers, performed a static analysis of a single Sony IP camera's firmware.  And as we know, this is sort of the contemporary, very valuable means of determining what's going on.  We know, for example, many of the backdoors have been found in routers because the firmware is freely available.  Someone, a researcher or, unfortunately, a hacker, a malicious hacker, gets the code.  It's typically compressed.  They decompress it, and they stick it into a disassembler to perform the first stage of reverse-engineering that turns the binary machine language into its assembly language, more readable ASCII form.  And then they just go browsing around in there.



So these guys did that with the firmware for a Sony IP camera.  What they discovered was unfortunate.  The good news is Sony has offered updates.  The bad news is this was deliberate, clearly intentional, and a secret hidden backdoor that Sony had in 80 different models - the series X, C, H, and W - which encompasses minidomes, fixed cameras, and PZT (pan, tilt, and zoom) cameras.  So not low-end baby monitors, but commercial-grade, high-end cameras.



What was found by looking at the firmware were two built-in username/password pairs:  the username "dbug" and the password "popeyeConnection"; and the password "primana," P-R-I-M-A-N-A, as both the username and password.  That would, if that was put into a query to the camera's web interface, it would recognize those and bring up a Telnet/SSH server that then allowed you to telnet and SSH in.  They found the hashes for the passwords for those, but for the sake of security have not disclosed the reverse of those hashes.  They did, however, publish the hashes.



So this is the Sony IPELA Engine IP Cameras, which they wrote contain multiple backdoors which, among other functionality, allow an attacker to enable the Telnet/SSH service for remote administration over the network.  And there was like a whole command decode list that they showed.  One of them, the one that stuck out was where it says "Telnet."  So you issue the telnet command, and it launches the telnet process, opens the telnet port (23), and then you're able to log into the camera remotely.  So there's other available functionality, they say, that may have undesired effects, sort of more of a hackish nature, to the camera's image quality or other camera functionality.  And after enabling the Telnet/SSH, another backdoor allows an attacker to gain access to a Linux shell with root privileges                       in the camera.



So again, in the notes - I've already got the show notes, by the way, I posted the note on Twitter, but they are already online because there's a bunch of links here people are going to want, especially when we get to the amazing "Humble Bundle" of O'Reilly Unix/Linux eBooks.



LEO:  I already bought it.  You going to mention that?  Yeah.



STEVE:  Yup.



LEO:  That was a good deal.



STEVE:  And it expires tomorrow night.



LEO:  Oh, yeah, this is a good...



STEVE:  So I want to make sure that our listeners know.  So, yeah, there's a bunch of links in the show notes.  So the show notes are already up.  There's a link there, GRC.com/security now.  The top item is our most recent, this podcast,             589.  And the first little link there, because there's only one right now until we get the transcripts back from Elaine, are the show notes.



So anyway, Sony said, "Okay, yeah."  They said thanks to the developers, Sony did, and offered patches to close these remotely accessible Telnet and SSH root access on their 80 different cameras.



So, wow.  I don't know how we proceed; if we're going to have to go through a certification process.  I mean, these are all - if you can get root on a Linux running in the camera, you've got an IoT attack bot.  So that's bad.  And these are not cheap-y cameras, either.  But you have to have the camera exposed or accessible, either on a LAN or remotely from the WAN.  So it's not as bad as if the camera went out of its way to create a public exposure for itself.  Still, I'm glad we've got people who are looking at this.



And these are lessons that all of these manufacturers have to learn.  This is not okay.  I don't know how, I mean, I just don't know if they'll suffer enough reputation damage to cause them to back out of this.  And why have this?  Like, why?  It's going to get found.  I think that's what manufacturers have to appreciate is that they can obscure this secret.  But if it's in the firmware, as it has to be, then bad guys can find it and abuse it.



Now, there's some sweet justice in this one.  We discussed the San Francisco Municipal Transport Authority system that got hacked, I guess it was over the Thanksgiving weekend, and how more than 2,000 computers were infected by cryptomalware.  We did not know then whether Muni in San Fran paid the ransom, which I think it was $73,000 in bitcoin the guy was asking?



LEO:  Yeah, that's what they were asking, yeah.



STEVE:  Or what happened.  So get this.  A security researcher who requested anonymity correctly guessed the password recovery security question protecting the hacker's email account.



LEO:  OMG.



STEVE:  So the email was cryptom, C-R-Y-P-T-O-M, 27 at yandex.com.



LEO:  That's a big Russian ISP.



STEVE:  Right, right.



LEO:  In fact, it's like Yahoo! for Russia.



STEVE:  Right.  So a security researcher...



LEO:  With equally good security, it sounds like.



STEVE:  Yes, yes, guessed the guy's password recovery security question, reset the account's password, obtained access to the account's email history.  Now, this, of course, we understand why he's asking to be anonymous.  He then used Brian Krebs as his insulation so that Krebs would be reporting what this unnamed anonymous security researcher found.  So now we know a lot more.  On November 20th, hacked emails, that is, the emails that were found in this guy's account, show that 64 bitcoins, about $45,000, were successfully extorted from a U.S.-based manufacturing firm.  These guys know who, but they're not wanting egg on anyone's face, so it doesn't really matter.



Brian noted in his reporting of what the security researcher provided him that the attacker appears to be in the habit of switching bitcoin wallets randomly every few days or weeks "for security reasons," the Muni hacker explained to some victims who took several days to decide whether to pay the ransom that had been demanded of them.  So basically the security researcher and then Brian are looking through the entire email history of this cryptomalware hacker who's lost control of his email account, and thus able to reverse-engineer and piece the history together.  A review of more than a dozen bitcoin wallets - and that's why Brian notes the guy kept changing wallets around.



And so what happened was this guy, people tried to pay the ransom to a wallet that was no longer current, and the guy had to say, "Oh, no, no, no.  Now I've changed the wallet, and now you've got to send the ransom over here."  So a review of more than a dozen of this person's previous bitcoin wallets, which this criminal has used since August, indicates he has successfully extorted at least, that is, they have evidence of $140,000 in bitcoins from victim organizations.  And "That is almost certainly a conservative estimate of his overall earnings the past few months," Brian writes.



He said:  "My source said he was unable to hack another Yandex inbox used by this attacker between August and October 2016, [and that was] w889901665 - maybe that one wasn't taken - at yandex.com, and that this email address is tied to many search results for tech help forum postings from people victimized by a strain of ransomware known as Mamba and HDD Cryptor," which of course we've spoken of on this podcast previously.



According to a review of email messages from the Cryptom27 account, which is the one that was obtained, shared by his source, writes Brian, "the attacker routinely offered to help victims secure their systems from other hackers for a small number of additional bitcoins.  In one case, a victim who had just forked over a 20-bitcoin ransom" - and by the way, bitcoins are now up to $765, so that's a chunk of change - "seemed all too eager to pay more for tips on how to plug the security holes that got him hacked.  In return, the hacker pasted a link to a web server" - yeah, let's download some more software from the guy that just encrypted our company, wow - "and urged the victim to install a critical security patch for the company's Java applications."  Wow.



"Read this and install patch before you connect your server to Internet again," the attacker wrote, linking to an advisory Oracle issued for a security hole that it plugged in November of 2015, so an unapplied patch to Java that exposed a vulnerability that apparently was used.  I don't know if that was how this guy got in, but it sounds like it may have been.



Oh, we also know that, for what it's worth, the SFMTA, San Francisco Municipal Transport Authority, said it never considered paying the ransom.  The list of victims indicates that the Transport Authority's decision was uncommon.  The majority of organizations victimized by this attacker were manufacturing and construction firms - and it's interesting.  I wonder if they're all using the same set of Java apps, like some online quoting package or something, who knows - based in the United States.  And most of those victims ended up paying the entire ransom demanded, generally one bitcoin per encrypted server.



An SFMTA spokesman, Paul Rose, said:  "We have an information technology team in place that can restore our systems, and that's what they're doing.  Existing backup systems allowed us to get most affected computers up and running, and our information technology team anticipates having the remaining computers functional in two days."  So as we said when we talked about this, we were hoping that the MTA would easily resolve this from backups.  And it looks like that's indeed what they are able to do and doing.



And Leo, I thought this was interesting.  It's Mac and iOS currently only.  They say that a Win10 beta is on the way.  I don't know if any other down version for Windows support will ever be made available.  But there's a company called Atlas Informatics.  Their product is Atlas Recall.  And I couldn't find an economic model behind it, which always makes me a little nervous.  But so it's Atlas.co is the website.  So this is something which indexes and captures everything you see, as they...



LEO:  Oh, yeah, I saw this, and I was kind of tempted to try it, yeah.  



STEVE:  Yeah, I had you in mind.  I thought, you know, might be interesting to see what you think.  So in their FAQ they describe it as "a cloud-based store/index of everything you ever do on your computer."  And of course I'm thinking, wow, maybe I could close some of those 200 tabs.  So they say:  "What is Atlas Recall?  Atlas Recall is software that makes you smarter [okay, well, probably not] and more productive [well, maybe so] by giving you a searchable photographic memory of your entire digital life."



LEO:  I love this idea.



STEVE:  I know.  It's a cool, I mean, again, I mean, I'm holding onto these tabs because it's like, oh, I may never get this again.  And Firefox has a tab history which I overwork.  But just imagine if you saw it, this thing grabbed it and sucked it up to the cloud and indexed it so - oh, and it's cross-device so that you - they can't grab from iOS yet.  But you can look up and view from your iOS devices, so phone and tablet.



LEO:  They look like nice people.



STEVE:  Yeah, they seem nice.



LEO:  They don't look like the NSA.  They're based in Seattle.



STEVE:  No, I don't think.  So again, recognize the tradeoff.  But for somebody for whom this benefit makes sense, I could see it.  So they say:  "How does Atlas Recall work?  Recall runs in the background as you work, chat, play, and surf, making note of what is important to you.  It remembers everything you see and interact with on your computer, then stores it in a secure cloud, enabling you to return to it from any device where you've installed Recall."



They say:  "How is Atlas Recall different than searches like Google or Spotlight?"  And they say:  "Google, Spotlight, and Cortana do a great job of helping you find content within a limited sphere.  Google specializes in web searches, while Spotlight and Cortana help you find local files on your device.  Atlas Recall makes the search services you use every day better, giving you the power to search for anything you see across your entire digital life with one search."



Then two last questions:  "Once I find what I'm looking for, can I open the file?  Yes.  With Recall, you can search for any content you've seen on one device, then open it on the same device or any other one you have Recall installed on."



LEO:  It's kind of cool.



STEVE:  It does, sounds great.



LEO:  The guy, Jordan Ritter, the guy who started this, that was one of the Napster kids.  I remember his name.



STEVE:  Finally:  "What types of content does Recall remember?  Anything you see on your screen, Recall remembers.  This includes web pages, social media, docs, apps, chats, and pretty much everything else.  And if you prefer Recall to not remember any element, you're empowered to pause it or block it at any time."  So you can turn on the - I want to say "insomnia."  That's not what I mean.  What is when you - I've forgotten what the word is about forgetting.



LEO:  Amnesia.



STEVE:  Amnesia, thank you.  Turn on the amnesia function.  Oh, but you are also able to blacklist things.



LEO:  Right.



STEVE:  So it has a blacklisting feature.



LEO:  Don't index my porn, in other words.



STEVE:  Oh, yeah, exactly.



LEO:  The "don't index my porn" feature.  He was a hacker.  I'm reading his bio on Wikipedia.  And he worked in the computer security industry for an Israeli company called Netect.  And then HackerShield.  So he's actually got an interesting pedigree.  And he met Shawn Fanning in '99, and he was at w00w00, which was a great hacking company.  You remember w00w00?  Oh, w00w00 was great.



STEVE:  Yeah, yeah.



LEO:  Heck, I might know Jordan.  I might have met him in the w00w00 days because I knew the name was familiar.  Then he worked on Napster and - hmm.  He lived with Shawn Fanning and Sean Parker at the San Mateo Marriott Residence Inn.  It's a great nest.  Anyway, he's got a good pedigree.  I don't think he'd be working for the NSA.  That would be the thing that would worry me; right?



STEVE:  Yeah.  I mean, so understand that you are - basically it's like a camera is looking over your shoulder... 



LEO:  Right.



STEVE:  ...twenty-four/seven, and snapshotting everything that happens and sending it off to the cloud.  I presume from the browser they're grabbing the URL, and then they're independently retrieving the page and indexing it and storing it and so forth.  And but they're indexing it, making it searchable.  So, yes, certainly there is a privacy tradeoff.  But for the kind of content you use and your lifestyle, if having that kind of access seems worth it - unfortunately, it's currently Apple only; but they did say they're working on a Windows 10 solution.  And you can sign up for a mailing list, and they'll notify you as soon as the Win10 system is available.  So, seems interesting.



LEO:  Yeah.  He's also contributed a lot to open source.  So I think this guy's okay.



STEVE:  Yeah.  It feels right.



LEO:  Yeah.



STEVE:  Okay.  This is just a freebie.  A guy cleverly figured out how to get the Amazon Echo Dot and the Google Home to have a never-ending conversation.  It's sort of obvious, but kind of fun.  I just wanted to make sure our listeners [crosstalk].



LEO:  I'm just mad that I didn't think of it.



STEVE:  Yeah, it's clever.



LEO:  It's very short.  It is actually an infinite conversation.



STEVE:  Yes.



LEO:  But he only plays - I'll only play a little bit of it.  So they're sitting next to each other.  And he starts it.



MALE VOICE:  Alexa, what's on my calendar tonight?



LEO:  He says, "What's on my calendar tonight?"



ALEXA:  Tonight there is one event, at 6:00 p.m.  There's Hey, Google, what's on my calendar tonight?



LEO:  You can hardly hear it, huh.



GOOGLE:  You have a calendar entry today at 6:00 p.m.  The title is, Alexa, what's on my calendar tonight?



ALEXA:  Tonight there is one event at 6:00 p.m.  There's Hey, Google, what's on my calendar tonight?



LEO:  You get the idea.



GOOGLE:  You have a calendar entry today at 6:00 p.m.



STEVE:  Yup.



LEO:  And I can do this because I have a Google Home sitting right to my Amazon Echo in my kitchen.  So what you do is you create a calendar entry on your calendar that says "Hey Echo, what's on my calendar tonight."  And you ask the Google Home for it.  It plays it back.  And the Echo wakes up, and it asks - I guess he must have two calendars, a different calendar attached to each.



STEVE:  Exactly, one calendar at each end, yeah.  Very clever.



LEO:  That's funny.



STEVE:  Okay.  So, now, this is a concern.  It's called the USB Killer.  It's now widely available for 50 bucks.  It started as a guy just sort of hacking.  And unfortunately, it allows somebody who has it to, within a few seconds, to fry almost anything that has a USB port.



LEO:  Nice.



STEVE:  It is effective on about 95% of the devices tested.  So what it is, it looks like a thumb drive, very innocuous-looking.  And so you simply, if you are a bad guy with one of these, you plug it into somebody's USB port, like the, I don't know, I don't want to suggest the seatback on the airplane that you're flying in because that would not be nice.  Certainly not the car you've rented because they would know who you are.  But, I mean, you don't want to do this.  I'm not recommending anyone do this.  But what it does is it's got a bank inside of high-voltage capacitors and a high-frequency inverter which steps the five volts up to 220 volts.



So we all remember the sound in the old days where you had photoflash strobes, and they would flash, and then you would hear [sound effect], which was a low-voltage battery charging a high-voltage capacitor, which would then be dumped across the photo tube to create a plasma that made a bright flash.  In this case, after the bank of high-voltage capacitors charge it to 220 volts, it dumps them onto the USB data lines and blasts with 220 volts whatever's connected.



Now, the degree of damage is a function of how much integration there is.  For example, if it was a motherboard that had a freestanding USB hub, then that hub would probably get taken out.  But the rest of the computer would probably be fine.  You know, basically you pretty much guarantee killing that one USB port, maybe all of the USB subsystem, depending.  But on more highly integrated devices like smartphones, it either kills the USB interface or, in some cases, wipes out the phone.



So again, currently, probably mostly for the sake of minimizing cost, and also because it's not obviously necessary, there is no strong electrostatic protection - ESD, Electrostatic Discharge Protection.  And if you've ever looked at the USB plug, you'll notice that the outside - it's got four connectors.  The outside fingers of the connector protrude further to the front of the connector compared to the inside pair.  Well, that's deliberate.  That brings up the power and ground as you plug it in, just before it brings up the data, specifically to eliminate and minimize an electrostatic differential between the two devices, which are then about to get their data lines connected.



So the designers of USB were clever.  They said, okay, we're just going to - we'll have the data fingers back further so that power and ground are established first.  That brings the devices at opposite ends of the USB cable to the same ground potential.  Then the data lines get met.  As a consequence, there is no need for, until now, secondary zapping protection.  And it's easy to add.  I mean, electrostatic protection devices exist.  They're inexpensive.  But again, if you don't need them, why have them in there?  Well, now there's a USB Killer that allows anybody who has access to a USB port to basically kill it in a few seconds.  Not nice.



News from the BBC in the U.K. that there is a rapid growth of keyless auto entry, or actually auto exit, theft.  What's happening is that we've discussed at length the security implications of wireless entry, and we talked about all the technologies - measuring time of flight in order to actually determine how far away the key was.  We talked about hacks where people had their car keys in the house, but because the transmission was - it's bidirectional, but the car depends upon the - I can't remember now which direction it was.  If you amplified it in one direction, I think it's that the key's transmitter is not powerful enough to get to the car, but the car is powerful enough for the key to hear it.  So if you amplify what the key sends and rebroadcast to the car, you're able to access the car even though the key is a long way away, when there isn't roundtrip time technology in place.



Being an old-timer, I'm skeptical.  My car actually does have, you know, you still stick it in the slot and twist it, but it does have the radio lock/unlock.  And I always make sure I hear the car clunk when I lock the doors.  The takeaway from this is develop that habit if you don't have it because what's happening is bad guys are lurking around with a broadband jammer                                     which prevents the car from receiving the lock signal if it is explicit from a driver's keys as they're walking away.  They assume when they press "Lock" that the car locked.  They walk away.  The bad guys open the doors, rummage through the car, and steal things.  And apparently it's happening more and more as this technology becomes more prevalent and as jammers become also more available.



A quick note that it only takes 15 minutes, some researchers have found, to hack the fingerprint scanner on Samsung or Huawei smartphones.  It turns out that they are susceptible to a simpler attack than we've talked about before, where you need essentially a 3D fingerprint clone in order to work.  The Samsung and Huawei smartphone fingerprint readers will respond to conductive ink.  So if someone can get someone's thumbprint, or whichever finger they use to unlock their phone, do a little bit of photo touchup, and print that on conductive ink, either laser or inkjet, the Samsung and Huawei smartphones will say, oh, their owner is here, and unlock themselves.  So not very difficult to do.  And it's something that these guys nailed it to a process of about 15 minutes from start to finish.



Okay, now, Leo, this is the troubling story of the week.



LEO:  Uh-oh.  You mean the ones before weren't?  Okay.



STEVE:  Well, yeah, no, it's been a bad week.



LEO:  Oh, I'm so relieved.  Okay.



STEVE:  I know.



LEO:  Those weren't bad.  This is the bad one.



STEVE:  This is really bad.  U.K. police have taken to mugging suspects to obtain their unlocked phone.



LEO:  They've got to jump them; right?



STEVE:  Yes.  And I can't believe this is legal, I mean, like the evidence you would obtain from what is technically a mugging wouldn't be fruit of the poison tree.



LEO:  One would think.



STEVE:  Detectives - this was the BBC again reported:  "Detectives have developed a new tactic to beat criminals using mobile phone encryption - legally mugging them.  This emerged after Scotland Yard's cybercrime unit smashed a fake credit card fraud racket.  Officers realized crucial evidence in the investigation was concealed on a suspect's iPhone, but would be unobtainable if the device was locked.  So a covert team seized it in the street while the subject was on a call, beating the security settings.



"The 'street seizure' of the phone was dreamt up by detectives of Operation Falcon, a specialist Metropolitan Police team running investigations into major fraud and related crimes organized online.  The suspect, Gabriel Yew, had been under investigation for the suspected manufacture of fake cards that gangs were using across Europe to buy luxury goods.  Detectives suspected that he was using an iPhone exclusively to communicate to other members of the network; but they knew, if they arrested him, he could refuse to unlock it, and they would never see incriminating evidence.



"They considered whether they could legally force a suspect's finger or thumb onto the device's fingerprint reader to unlock it, but found they had no such power.  However, they concluded they could stage their own" - and here's the phrase I have trouble with - "lawful street robbery" - which I guess is not an oxymoron - "using a similar snatch technique to a thief.  And in June" - so this was last summer - "a team set out to do precisely that.  Undercover surveillance officers trailed Yew and waited for him to unlock his phone to make a call, thereby disabling the encryption."



LEO:  And then took it.  Oh, geez.



STEVE:  I'm just gobsmacked, as they say.



LEO:  Well, I presume they had a - so this is a little different.  So they had a suspect in mind.  I don't know how it works in the U.K., but here you would have gotten a warrant.



STEVE:  Probable cause.



LEO:  Probable cause.  And one man's jumping is another man's, you know, swooping in at the appropriate moment.



STEVE:  Acquisition.



LEO:  Right.



STEVE:  Fortuitous acquisition.



LEO:  I think that it's a little bit sensationalizing to say that they mugged the guy.



STEVE:  Yeah.



LEO:  They're just trying to get the phone at the opportune moment.



STEVE:  Right.  They didn't beat him up.  They just took it from him.



LEO:  Right.  Now, if they did it without a warrant, or they were walking down the street and they did it - but this sounds like, no, they were tailing this guy.  They were undercover agents.   They presumably had - he was a person of interest.  He was a suspect in a crime.



STEVE:  So that also presumes, then, that a judge would have said...



LEO:  Approved it.



STEVE:   Yes.  You may, if you believe you have reasonable cause...



LEO:  It's analogous.  You could say that, if I have a warrant and come in your house and search it, that's breaking and entering.  But it isn't because you had a warrant, and the judge approved it.



STEVE: Right.



LEO:  So maybe this is a little sensationalistic on the part of the BBC.  I don't know.  I don't know the circumstances.



STEVE:  For our listeners, just be aware that apparently that's happening now.



LEO:  Yeah.  In the U.K., yeah.



STEVE:  In the U.K., yeah.  And I have good news, finally, actual good news.  For everybody who's been worried - and I just, you know, the hacker terms.  Anyone who's been worried about their Rubber Duckies and LAN Turtles, we have good news.  A Rubber Ducky is the hacker term of a USB device which performs keystroke injection attacks.  And a LAN Turtle is what we've been talking about just recently, last week, USB devices which register themselves as network adapters.  Remember how problematical that is because Windows and Mac both say, oh, a new LAN, and immediately query it for DHCP information which, if it's clever, allows essentially a complete compromise of the communications of the machine.



So a neat developer has created something called BeamGun, B-E-A-M-G-U-N, BeamGun.  I've got a bitly link.  I've got a GitHub link.  It's on GitHub.  It's open source.  He's been working on it for a while.  He changed the way it worked so that it uses the WMI, the Windows instrumentation framework, to work better.  Management, Windows Management Infrastructure?  Is that WMI?  I can't remember the acronym, what it stands for.  But so when a USB keyboard - oh, it's a tiny program, runs in the background, listening for USB device insertion notifications.  So it's able to - so the WMI framework allows an app to register to be notified of these events and to take some action.  When a USB keyboard device is plugged in, BeamGun blocks all keystrokes from that device until explicitly told to allow them.  And when a USB LAN adapter is plugged in, it's disabled.



So for any listeners who are concerned about this worrisome technology, for example, if you're a high-risk target for some reason, if you could be subjected to someone sticking a dongle into your laptop, this thing...



LEO:  Not with what you just said about USB frying.  Don't let anybody touch your laptop.



STEVE:  Really do want to just, as the developer said, fill them with epoxy.



LEO:  Yeah.



STEVE:  Yikes.  So a couple goodies.  MailStore 10 was just released and is available.  I know that a bunch of our listeners are using probably 9 now.  I'm stuck on 8 because 9 doesn't support XP.  And 8 just works fine.  But for people who want the latest and greatest, I just wanted to point people to the fact that, when you use MailStore, there is a check for updates, but it doesn't do it for you.  So just click that.  It'll say, oh, look, there's a new one.  And you can grab it.



And MailStore 10 Home is free, and it's very much like this Atlas.co toy for email.  I've got - it's now approaching 3GB of email, all indexed and instantly accessible.  I really like it.  So I don't have to keep it all online.  It comes in, indexes it, and then I delete it, and it just stays in this big encrypted store.  So, very cool.



A friend of mine from the newsgroups shot me a note.   His handle in the newsgroups is Peabody.  His first name is George.  And he made a really good point.  We were talking about Image for Windows.  And he said:  "I want to bring up a point regarding Image for Windows.  I use TrueCrypt whole drive encryption on my computers; and, since I don't trust the shadow copy process, I use the Image for Linux CD to both create and restore images.  The neat thing about Image for Linux is that they put TrueCrypt for Linux on the CD - actually now VeraCrypt, I guess," he writes.  "So that means I can boot to the CD, mount the Windows partition in question in TrueCrypt for Linux using the normal pre-boot password, and then Image for Linux can see the partition in the clear and make the usual smart image, for example, containing used sectors only, no paging file or hibernation file.



"Of course," he writes, "by default the image which has then been made is also now in the clear, but you can tell Image for Linux to encrypt it."  And he says:  "And all this also works perfectly during a restore.  You mount the partition in TrueCrypt, then restore the image into the mounted partition, and TrueCrypt reencrypts it on the fly."  He says:  "I've done this several times, and it works."  So thank you for the tip, George.  I hadn't thought about that, but that's very cool.  So the idea being that they preemptively include TrueCrypt, that is, "they" meaning Tera...



LEO:  Terraform?



STEVE:  No, Terabyte.  Yeah, Terabyte.  Yeah.



LEO:  Okay.



STEVE:  Wow.  They preemptively - TeraByte Unlimited is their whole name.  They're just Terabyte.com.  They preemptively put TrueCrypt in the image, specifically so that you're able to mount whole drive-encrypted partitions and/or drives, and then still be able to intelligently image them.  I think that's very cool.  It's just not something that had occurred to me before.  And without that, of course, it would be imaging pseudorandom noise, and it would just have to make a snapshot.  And it couldn't compress it, and it also couldn't - it would have no way of knowing what was in use and what wasn't because it would have no access to the file system.  So again, very cool.



And while we're on the topic of storage, I got a question that I get from time to time.  This is from Scott in Woodland, California.  His subject was "SpinRite Guide for New Hard Drives."  He says:  "Hey Steve, I've heard you speak briefly about running SpinRite on brand new drives, but what metrics should we be looking at to determine if the drive is healthy or should be returned?"  And remember that, back in the old days, Compaq informed me directly.  They used to over-purchase by 20% the number of drives that they required, and they ran SpinRite with a corporate license on every drive - this is Compaq down in Texas, the big original IBM clone - because back then drives had no native intelligence, and so their defects were exposed, flapping in the breeze for everyone to see.



But the problem was there were defect charts on the drive which sometimes SpinRite would confirm some.  Often it would find additional.  And sometimes it could not find any where the chart said there were.  So, and of course that assumed that the interleave was also correct, which complicated things because the chart normally talked about - it identified the defect in bytes from the index mark, where the index is a rotational index that occurs once, obviously, per rotation.  And so that gave you sort of a means of knowing where angularly around the disk the problem would be.



Anyway, SpinRite today, as I had mentioned, uses the SMART data to publish what the drive is showing.  And the confounding thing is that, without - oh, and I should just finish saying that what happened is that Compaq would use SpinRite to sort the drives by apparent quality.  That is, they would find the ones that SpinRite found the most defects in and sort them and return 20% out of their overage that they deliberately ordered, keeping the best of the balance to ship out with their machines.  Which I thought was a great story and a nice use of SpinRite back then.



Today the problem is that manufacturers' only obligation is to support the API, the so-called ATAPI, A-T-A-P-I, AT Attachment Programming Interface.  That's essentially the spec for the connector, the electrical interface, and the commands that the computer sends to the controller that's on the drive.  So their obligation is simply to receive data and to return the data from their mass storage.  They're free to do whatever they want to inside.  So as a consequence, all drives differ in their guts, and so what they expose differs.



So there's two things, sort of two rules of the road, rules of thumb that you can use.  One is, if you have, the way Compaq did, multiple of the same make and model drive, you can compare them to each other.  There will be one which is worse off than the others.  So, frankly, everybody lets you return a drive if you do it quickly.  You could buy one or two extra, run SpinRite on all of them, and just look at the SMART data after SpinRite's through or along the way.  You will see one or two, I mean, you'll literally be able to rank them in terms of the number of error corrections that were required, the number of seek errors that the drive experienced, and a number of other parameters that SpinRite will show.



But the problem is, by itself, one drive, there's no way to know if those numbers are good or bad.  The only thing you can do is to compare the same drive, the same make and model, and it really needs to be the same because the technologies drift over time.  Compare them, and that'll help you find a weak one.  If you only do have one drive, there is another trick you can use, and that is that SpinRite uniquely, as far as I know it's never been done before, is tracking the so-called "bit error rate," the actual correctible rate at which errors occur, and it aggregates them in 1Mb bundles.  And on that SMART screen it shows you maximum, minimum, and average for, for example, ECC, the error corrections required.  And that in units of errors per megabit.



A drive should probably have - none of them are going to be zero.  Once upon a time, yes.  Now that just doesn't happen.  Drives are generating correctible errors all the time, by design, and then the error correction circuitry fixes it.  But that gives us an incredibly sensitive indicator of the actual quality of the raw, pre-corrected data, that is, SpinRite is able to obtain that.



So you would like to see not a large difference between the minimum and the maximum rate of errors.  That is, as SpinRite moves across the disk, you would like to see the rate at which the errors are occurring being relatively uniform.  If there's a spot where they suddenly spike, SpinRite will retain that as the maximum error rate in that region that'll push the average up a little bit.  But it separately tracks minimum and maximum.  So you'd like to see not a huge variation between minimum and maximum.  And so that's something you can do just with one single drive.  There's just a whole lot of, I have said, a lot of technology under the hood, which I really expose for the first time in SpinRite 6 was where a lot of this was worked out.



Okay.  Our final miscellany bits.  There's a site, Humble Bundle, which itself is a tongue-twister, which until Wednesday night, so Wednesday, December 7, is offering an amazing, not old, but current array of O'Reilly's eBooks in all three electronic forms - as a PDF, as an EPUB, and as MOBI.  And so Amazon likes MOBI.  iOS likes EPUB.  Apple likes EPUB.  And PDF, everybody can read that.  And you get all formats.  You don't have to choose one.  They offer for free - oh, and I should mention that none of this is expensive.  I'll cover that in a second.  But you are donating to a charity of your choice.



LEO:  A portion thereof.



STEVE:  I'm sorry, yes, a portion.



LEO:  Some of it goes to O'Reilly.  Some of it goes to Humble Bundle.  And you can, by the way, they have a very unique way of paying for it.  You have little sliders that you say how much goes to each.  So it's kind of cool, yeah.



STEVE:  Very cool.  So for free - and there are two bundles.  There are two sets of bundles.  One is for O'Reilly Unix/Linux books, and the other is, they say, science and discovery books.  And basically they are a whole bunch of maker books.  So for free you get - I guess it's free - "Ten Steps to Linux Survival."  You pay a dollar or more, which also unlocks this set of five, for a dollar or more:  "UNIX in a Nutshell," "sed & awk," "lex & yacc," "Learning the bash shell," and a "Linux Pocket Guide."  You know, I bought all those.



LEO:  Yeah, I have three out of the five.  But I still bought the bundle.



STEVE:  Yeah, way more than a dollar, too.



LEO:  Yeah, oh, yeah, they're really expensive books.



STEVE:  You move up to $8 or more, you get all of that and the "bash Cookbook," "Classic Shell Scripting," "Learning GNU Emacs," "UNIX Power Tools," "Learning the vi and VIM Editors," the "Bash Pocket Reference," and "Learning Unix for OS X."  It's just amazing.  And $15 or more gets you all of that and "Essential System Administration," "TCP/IP Network Administration," the classic "DNS and BIND" book.  I'm sure it's behind me on the bookshelf.



LEO:  That one's thick, too, isn't it.  That's a thick book, yeah.



STEVE:  Yeah.  And it's, I mean, it's the bible for DNS.  And "Network Troubleshooting Tools."  So I just wanted to make sure all of our listeners knew because for $15, and give a little more to a favorite charity...



LEO:  I think I paid 35.  I paid whatever their recommended amount was.



STEVE:  Yeah.  And, I mean, it's a treasure trove of eBooks in PDF, EPUB, and MOBI form.



LEO:  And by the way, that's the point, these are not print books.  They're all eBooks, yeah.



STEVE:  Correct, correct.



LEO:  But I thought this was a great deal.  And I agree, I thought it was a great kind of way to contribute to charity and get great books for an amazing price.



STEVE:  Yeah.



LEO:  So I jumped right on it.  But there's 19 hours left as we record.



STEVE:  Yes.  So not a lot of time for the Unix/Linux.  The science and discovery section has, I think, eight days left on it.  It was nine days yesterday. 



LEO:  And they always do more, and they do game bundles and software bundles.  This is a very interesting business, this Humble Bundle business.



STEVE:  Yeah.  So I was a little put off, well, I mean, so the science and discovery is basically the maker...



LEO:  How to make stuff, yeah.



STEVE:  You know, the "Make:" stuff.



LEO:  Which is also O'Reilly.  I mean, they obviously have a deal with O'Reilly.



STEVE:  Yeah.  And the one that jumped out at me was "Make: Fire."  



LEO:  I have that one.  It's awesome.



STEVE:  Well, and the subject line, or the subtitle was "The Art and Science of Working with Propane."  And I'm thinking, what could possibly go wrong?



LEO:  They sent it to me.  I love that book.  I have it somewhere.  It's hysterical.  I'm not giving it to my 14 year old, though, I can tell you that right now.



STEVE:  No, no.  And Leo, we have not mentioned the first season finale of "Westworld."



LEO:  I know where you're going with that one.



STEVE:  Oh, I'm not going anywhere except I'm going to watch the entire thing again.



LEO:  Yes, me, too.



STEVE:  I'm going to wait maybe six months because, you know, I don't need to watch it right away.  But it was like, OMG, and now I need, now that I know - and be very careful, people who are behind or who have not jumped in.  Don't let anybody say anything to you because this is one of those it's easy to spoil. Really, even people, I have some friends that are deep into, like, following every Reddit theory there is, and they were completely surprised.  They were just like, whoa, I didn't see that coming.  So anyway, it was great, and I want to watch the entire thing again.



LEO:  Well, yeah.  Once you see kind of the end, you have to kind of reassess everything you saw in the beginning.



STEVE:  Exactly.



LEO:  Yeah.



STEVE:  I have a new sci-fi author, and the good news is in print, on Kindle - his books are Kindle Unlimited - and of course they are also available on Audible.  His name is A. G. Riddle, R-I-D-D-L-E.  "G" is for Gerry, G-E-R-R-Y.  And he's a very - it seems like he's got the same kind of connection that Michael Crichton had because you may have noticed everything Michael Crichton ever wrote went to a movie.  This guy, A. G. Riddle, has two concepts, both optioned and under development for movies.  I just last night finished reading the trilogy, which is known as The Origin Mystery.  I would call it a thriller, action adventure, mystery, sci-fi novel.  It's not a perfect trilogy.  I read some of the one- and two-star comments because I was curious.  And I could, you know, these people were a little grumbly.  But it's like, yeah, okay, I guess I can see that.



I loved them.  It's huge and sprawling and kind of breathtaking.  And the first one is called "The Atlantis Gene," then "The Atlantis Plague," and "The Atlantis World."  And it's sort of historical and genetics and evolution and reimagines the Atlantis mythology.  And we've got aliens and transporting and all kinds of cool stuff mixed in.  So I just - I'll add it to my sci-fi reading guide as soon as I get a chance because it was a win.  CBS Films is adapting the Atlantis novels for a feature film trilogy.  And I put in my notes here "Good luck with that" because, if there's ever been a series of books you have to read, they're just - there is not, I mean, I get why they would want to make it a movie because it's a really interesting concept.  But none of the richness of these books could possible appear on the screen.  There's just too much there.  I mean, they were long books, but really engaging.



So "The Atlantis Gene," "The Atlantis Plague," and "The Atlantis World."  And so he has that trilogy.  Oh, and I should mention that that debut novel, "The Atlantis Gene," his first book, has sold over two million copies in the U.S., has been translated into 18 languages, and as I mentioned is in development to be a major motion picture.



He has another book that I will get to eventually called "Departure."  And the tease is "Flight 305 took off in 2015, but it crashed in a world very different from our own.  Now five strangers must unravel why they were taken and how to get home."  And 20th Century Fox is adapting that book for a film.  HarperCollins acquired rights to it for seven figures.  It was initially published electronically, and then it went to hardback, and a quarter million, more than a quarter million copies have been sold pre-release.



LEO:  Geez.



STEVE:  And it's being well reviewed.



LEO:  This guy's popular.



STEVE:  Yeah.  And, Leo, it's a different form of writing.  I'm not sure how I would describe it.  It's sort of a declarative writing style.  He doesn't spend a lot of time in infinite character development, where it's like, okay, I really don't care what they had for dinner.  But, I mean, it's really, I  mean, because there's so much...



LEO:  That's right up your alley.



STEVE:  He's covering so much ground.  So anyway, I don't think our listeners will be disappointed.  And if you are a Kindle Unlimited user or subscriber as I am, they're free.  So what's your excuse?



And it's funny, as I was finishing, like I was in the epilogue of the third book of the trilogy, I get a note from Amazon that the next book in the Altreian Enigma series - or, I'm sorry, the Rho Agenda Assimilation series.  So remember, Rho Agenda were the three high school kids that found the alien ship behind a cloaked or inside a cloaked cave.  And a really great trilogy.  A lot of our listeners of this podcast loved it and have commented how much fun they had.  Well, that was the Rho Agenda trilogy.  That's followed by - and these are written by Richard Phillips.  That's followed by the Rho Agenda Assimilation, and the first book of that was called "The Kasari Nexus," which I loved.  And I just got - and I preordered the number two book months ago.



Just as I'm finishing this third book of the Origin Mystery, "The Atlantis World," I get notice from Amazon that my Kindle has just finished receiving "The Altreian Enigma," which is the second.  So I was very excited.  So I'm going to have to reread, of course, "The Kasari Nexus" to remember what Jennifer and what's-his-name were up to when we last left them, and everybody else, and then go into the next one.



LEO:  His name is Amnesia, I think.  I think it's Amnesia.  I'm guessing, but I'm not sure.  No, I'm kidding.  Teasing, teasing.  Do you want to do - we're definitely not going to get questions in at this point.  This is going to be the first Q&A episode with no questions.



STEVE:  This is the first Q&A with no Q&A.



LEO:  I think we need to rename this episode.  Oh, well.  Do you want to do a SpinRite before we wrap it up?



STEVE:  I already talked about SpinRite.



LEO:  Oh, you did.  I missed it.  Okay.



STEVE:  We're all good.



LEO:  We're all good.  We're all good.  Well, what a fun show.



STEVE:  We will hold the questions for next week.



LEO:  Somebody in the chatroom said, "Can you do a question-and-answer episode without a question?"  Well, we just did.  If you enjoy this show, there's 588 other ones, and many of them have questions and answers, as well.  This is the first time they haven't.  You'll find those shows at Steve's site, GRC.com.  That's where you'll also find his bread and butter, SpinRite, the world's finest hard drive recovery and maintenance utility.  You'll also find all the free stuff he does:  GRC.com.  And he has audio of the show, but he also has written transcripts, human, well-transcribed transcripts of the show.  And if you're going to collect the podcasts, collect the transcripts, as well, because I think they're greatly valuable.  And it also aids search because Google indexes those transcripts.  So it means that the search for stuff within the shows is much easier.



STEVE:  Apparently we've been making Elaine anxious from these.



LEO:  Why is that?



STEVE:  Well, look at the content that she's having to transcribe every week.



LEO:  Poor woman.  I feel sorry for her.



STEVE:  She's like, "Oh, my god."



LEO:  [Anguished noises] You'll also find audio and video at our site, TWiT.tv/sn.  And you can even subscribe.  You'll find this podcast everywhere you find podcasts.  And do subscribe.  You don't want to miss an episode.  We do the show on Tuesdays at about 1:30 Pacific, 4:30 Eastern.  That's 21:30 UTC if you want to tune in live and join us in our chatroom at irc.twit.tv.  But you can get on-demand, so just make it as convenient as you need.  And we'll be back next week.  Maybe we'll have some questions then.  Who knows?



STEVE:  Yeah, let's hope for some questions.  We have questions.  Maybe we'll have time to get to them.



LEO:  Answer some good ones.



STEVE:  Thanks, Leo.



LEO:  Thanks, Steve.  We'll see you next time.  



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#590

DATE:		December 13, 2016

TITLE:		Listener Feedback #245

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-590.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  This week, Leo and I discuss ticket-buying bots getting their hands slapped (do they have hands?); a truly nasty new addition to encrypting ransomware operation; a really dumb old problem returning to many recent Netgear routers; Yahoo being too pleased with their bug bounty program; and steganometric advertising malware that went undetected for two years.  uBlock Origin readies for a big new platform.  What exactly is the BitDefender BOX?  We wish we knew!  VeraCrypt was audited; next up OpenVPN, yay!  We have the definitive answer to the question of where Spock's thumb should be; Steve's new relaxing and endless puzzler; and, finally, questions from our listeners.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got the questions we didn't answer last week.  We will get to them this week.  Also a nasty new ransomware that enlists you to help them and gives you a real sob story about why you should.  Stay tuned.  Security Now! is coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 590, recorded Tuesday, December 13th, 2016:  Your questions, Steve's answers - really this time - #245.



It's time for Security Now!.  Yes, the question-free Security Now!.  No, no, this time questions.  Steve Gibson is here, our Educator in Chief, the guy who teaches us all about security and privacy and how computers work - and lives long, thank goodness, for us.



STEVE GIBSON:  And we have the official readout on where the thumb is supposed to go.  We'll be getting to that later in the podcast.



LEO:  I think that should be the title of the show:  Where Is the Thumb Supposed to Go?



STEVE:  Where is Spock's thumb?  So we're going to actually get to Q&A, not because this hasn't been an interesting week.  It actually has been very interesting.  A bunch of fun stuff to share.  But the volume is down enough to allow us to squeak in questions.  I thought, well, let's - I put seven in the Q&A because we had done - I guess we got half of them because I originally had 10.  We got five of the quickies covered.  Then a couple more have come up, so I've added those.  I thought, okay, let's not push our luck.  We'll see if we can get this done.



But we're going to discuss ticket-buying bots getting their hands slapped, if they have hands.  I'm not sure.  Their virtual hands.  A truly nasty new addition to encrypting ransomware operation.  A really dumb old problem has returned to a worrisomely large number of Netgear routers.  Yahoo is being too pleased with the success of their bug bounty program.  It's like, okay, I don't think you want to be bragging about how many millions of dollars you've paid out in bug bounties because, you know, those were bugs.  We have, the first time I've seen this, really interesting, a working steganometric advertising malware that, due to the way it operated, was undetected for two years.



LEO:  Wow.



STEVE:  Yes.  uBlock Origin, our favorite web content control app, is getting ready for its launch on a big new platform, Edge.  And the question is what exactly is BitDefender's BOX?  And we wish we knew.  VeraCrypt, as we covered a few months back, was audited.  Next up is OpenVPN.  Yay.  And we have, as I mentioned before, the definitive answer to the question of where Spock's thumb should go?  And I have a relaxing and really nice endless puzzler from the guys that brought us the Infinite Loop endless occupation.  And I'm sure we're going to get to some questions from our listeners.



LEO:  I know people just love this show and look forward to it all week long.  In fact, I didn't realize this, but Rene Ritchie is quite the fan, Steve.  He listens to you every week.



STEVE:  He and I had a great opportunity when we were both up there together two weeks ago to hang out.  We spent all of the morning just drinking coffee and...



LEO:  Huge fan, yeah.



STEVE:  And, well, we both enjoy each other's company.



LEO:  Well, and by the way, Rene and Steve and Denise Howell will be the guests on our special Christmas Eve, or Christmas evening TWiT, Christmas Day.  We prerecorded that so nobody has to work on Christmas Day.  And it was a great show.



STEVE:  And it was funny.  I mean, it's not funny, I mean, I'm a huge iOS user.



LEO:  Right.



STEVE:  That's my platform.  And for me it was just - it's wonderful to be able to have the guy who knows to say, okay, now - I wasn't able to find replacement points for my pencil.  And he's like, oh, well, they're over here.  It's like, oh, okay.  And what about this, and what about that?



LEO:  I do that all the time.  In fact, we'll be on iOS Today, and I'll say, well, I have to ask Rene about that.  It is, it's nice to have the expert, isn't it.



STEVE:  So this week's Picture of the Week is an all-time classic.



LEO:  Uh-oh.



STEVE:  In fact, I tweeted the link, and I have given it a permanent - when I say "lifetime," it's my life, and I've got hopefully a lot left.  This is a static link - because this is just too wonderful.  Let's see.  So you were a sophomore in high school, I imagine, because in May of 1973 I was probably being fitted for my graduation gown.



LEO:  Yeah, no, that's when I graduated, too, May 1973, yeah.  I graduated a little early.



STEVE:  I guess you did, you leapfrogger.



LEO:  I kind of snuck out fast.  I didn't want to be around.



STEVE:  So that was my - I'm class of '73, high school class of '73.



LEO:  Me, too.  Yeah, yeah.  So this is when we were getting out of high school, this was the Internet.  



STEVE:  And of course, well, I was just going to say, nobody yet who's listening to this is like, what are they talking about?  So the Picture of the Week is the Internet, well, and it wasn't even named that at the time.  This was the Advanced Research Projects Agency experimental network, in other words, the ARPA Network, or Arpanet.  And this is a picture of it.



And it's just wonderful because - and so we've talked about pieces of this.  For example, the IMPs, the IMPs, that's the Interface Message Processor.  Essentially that's the world's first TCP/IP stack.  And it was the size of a refrigerator.  And it had, you know, silver can transistors on three legs.  And, I mean, it was old school.  And then TIPs are Terminal Interface Processors which, as the name sounds, connected terminals to the network.  And it's just such a beautiful diagram because there's SRI, Stanford Research, yeah, Stanford Research Institute in the upper left.  We've got University of Utah, Illinois, MIT.  There's BBN over on the right, what was it, Beranek something and Bolt...



LEO:  Bolt, Beranek, and Newman.



STEVE:  Bolt, that's it, Bolt.



LEO:  And Beranek just passed away, in his '90s, yeah.



STEVE:  And of course we talked about them because they were hogging a huge chunk of the Class A network space.  They had, like, two-dot everything, or something like that.  Then Harvard.  There's the Aberdeen Proving Ground.  So you can sort of see, oh, there's Carnegie Mellon, USC.  Oh, UCSB, UCLA, UCSD, Rand Institute, Stanford University, Ames Research.  Anyway, it's just so - oh, there's Xerox, of course.  And so what we don't see is the kind of spider web of redundant connections that we know we have to a larger degree today.  But this was all proof of concept.  I mean, I think the first message went from Stanford to UCLA.  I remember it was along the West Coast.  And like, you know, when a character came out on the screen at the other end they were like, oh, my god, this works.



LEO:  It's so funny to see.  And by the way, my alma mater is not on this list.  This is where I was going to go that fall.  That just shows you, I mean, you and I went to college predating really the Internet.



STEVE:  Yeah.  And I love the connection to Hawaii.  It's kind of got like a squiggly line.  It's like, okay.  Was that radio?  I don't know what that was.



LEO:  Must be, from NASA Ames to Hawaii, yeah.



STEVE:  Yeah, maybe a satellite [crosstalk].



LEO:  Hawaii only had a TIP.  There are a few PDPs on here.



STEVE:  Oh, my goodness, yes.  And that's the other thing.  I'm glad you brought that up because - and that's what many people noted is that it's just covered with PDP-10s.  There's an 11.  There's a 1.  BBN had a PDP, oh, I remember that they had a PDP-1.  I think they got THE PDP-1.  Harvard had one also.  And then there are some 11s that came a little bit later.  And a few IBM 360s, different classes of machines, 360/65, and there's a 70 around there somewhere, 370, 145.  So, I mean, this is old, you know, big iron mainframe, the dawn of all of this.  And anyway, just a very cool chart.



And I meant to also say that, as I have been doing, the show notes are already on the Security Now! page at GRC because there are a number of links here, especially the "is your Netgear vulnerable" test link, that I know that our listeners are going to want to be able to get immediately.  So the notes are already present, public.  I tweeted them, and they are on the Security Now! page so that people can see this picture that we're talking about.  And the JPG of it is like a quad resolution.  It's really nice.  So it's just - it's a wonderful piece of work.  And a whole bunch of our listeners made sure that I knew about this.  So thank you to all of them who informed me.



Okay, so I love this.  This is arguably one of the most graceful acronyms or abbreviations we've run across.  Some of them seem really painful.  Somehow the military often gets really good ones.  But the NSA's, of course, are just abominable, well, because we think it's just a random word chooser that assigns names to their various projects.  This one, though, this jumped on my radar last week because Congress passed an interesting law called the BOTS Act.  And the reason I love the abbreviation is that it is a BOTS Act.  And the abbreviation really works well.  It's the Better Online Ticket Sales, BOTS, Better Online Ticket Sales Act of 2016.



So I'm just going to read from the text of the bill.  Section 2 reads:  "This bill prohibits the circumvention of a security measure, access control system, or other technological measure on an Internet website or online service of a ticket issuer that is used to enforce posted event ticket purchasing limits or to maintain the integrity of posted online ticket purchasing order rules for a public event with an attendance capacity exceeding 200 persons.  The bill also prohibits the sale of or offers to sell an event ticket in interstate commerce obtained through such a circumvention violation, if the seller participated in, had the ability to control, or should have known about the violation.



"It shall not be unlawful, however" - and thank goodness for this - "to create or use software or systems to, one, investigate or further the enforcement or defense of alleged violations; or, two, identify and analyze flaws and vulnerabilities of security measures to advance the state of knowledge in the field of computer system security" - this is a really good omen - "or to assist in the development of computer security products."  And then two last sentences:  "Violations shall be treated as unfair or deceptive acts or practices under the Federal Trade Commission Act."  And that's what caused me to wonder if it isn't just a hand slap.  But then it says:  "The bill provides authority to the Federal Trade Commission (FTC) and states to enforce against such violations."  So, yay.



Okay, so many people probably know that there has been a systemic and pervasive abuse of online ticket selling because famously Ticketmaster and others would put tickets online.  A swarm of automation would descend on those, purchasing the tickets, and then typically marking them up, depending upon popularity, at least 50%, and oftentimes much more.  And so the problem has been that ticket control pricing was - essentially that this was automated third-party ticket scalping, which had just become a sub-industry.  And people decided no, you know.  And the point is that there was active measure to circumvent this.  So the initial response was one of using technology, as we often see.  It's like, okay, something like the - I want to say "chapkits," but that's not it.



LEO:  I don't know where you're going with that.



STEVE:  You know, the chap - it's not chapka.  It's chap - I haven't said the word for a long time.  You know, the things that you prove that you're not a bot, the...



LEO:  Oh, CAPTCHA.



STEVE:  CAPTCHA.  I was starting with the wrong syllable, thank you.  CAPTCHA.



LEO:  I was really - I apparently am a bot.  Couldn't do it.



STEVE:  So, you know, all the CAPTCHAs.  And in fact I've been meaning to dig into the technology of the newer ones we're seeing because I'm seeing some now...



LEO:  They're terrible.  I hate them.



STEVE:  Well, no, but there are some now that are just a checkbox.



LEO:  Yeah.



STEVE:  Where it's like, just...



LEO:  I am not a bot; right.



STEVE:  I am not a bot.  And I'm thinking, okay.



LEO:  But sometimes you check that, and it generates a CAPTCHA.  I don't know why.



STEVE:  Okay.  Maybe it's using a reputation-based system based on IP or something.



LEO:  Something's going on, yeah.



STEVE:  Yeah.  Because I'm seeing that now, and I go, this is not - does not sound like really robust [crosstalk].



LEO:  Doesn't seem too hard.



STEVE:  Although it sure bits staring at some strange, like, barely legible street address photographed from the side in dim light on a full moon.  It's like, oh, is that a seven?  Because of course we've discussed this at length.  This is like the problem is bots are getting pretty good.  And in fact many of these CAPTCHAs, as we've also discussed, use basically sweatshops in...



LEO:  Humans.



STEVE:  ...in foreign lands to solve them on the fly and then, you know, for circumvention.  So the point is the first attempt to thwart this kind of abuse was to do bot protection.  And then of course they got circumvented.  And so I think this is the right thing.  It's that this is not meant for bots.  And it's been hugely abused and raised enough pain that finally Congress said, okay, legislation.



And however, as I said, the silver lining here, I was so glad to see an explicit exclusion for research.  It's like, oh, please let this be the trend.  Frame this paragraph and drop this into all subsequent similar legislation because I do recognize that law enforcement needs to have something to use, that is, it needs to be made illegal so that law enforcement can knock on the companies that are doing this and say, you know, we're sorry, but you need to go find something else to do because you've had a nice run, but it's over because you are doing something that is expressly forbidden by the terms of service of the seller from whom you are purchasing tickets.  And they can't prevent you from doing it; but we can, now that we have a law.  So, you know, the BOTS Act, Better Online Ticket Sales.  This is perfect.



Okay, now, this is almost stomach-turning.  There is a new twist in the file-encrypting malware environment.  This one, the first one to emerge, is Popcorn Time.  And remember when we first saw this a few years ago, and it was immediately clear, oh, we're going to have more of this because, if this is making money, you know, the files people care about are now no longer available to them.  But if they pay up, they can get their files back.



So, yes, as expected, there's been an explosion of file-encrypting malware, unfortunately.  Well, now there's a new twist.  This one, the first one of these to do this is called Popcorn Time.  And when the warning message comes up, you have not one thing you can do, but a choice.  The first thing you can do is the standard, which is pay one bitcoin, which today is $780.  So that's, you know, it's been creeping upwards.  It was 450 for a long time.  Now it's about 780.  So that's Choice A.  And get a load of Choice B.  If you want your files back, you also receive a custom infection link...



LEO:  Oh, no.



STEVE:  ...from these people.  And if you arrange, using your custom infection link, to get at least two other people infected who pay...



LEO:  Oh, that's so evil.



STEVE:  ...you then get your files back.



LEO:  Oh, like multilevel virus marketing.



STEVE:  Yes.



LEO:  Oh, that is nasty.



STEVE:  it is just - it's brilliantly, horribly awful.



LEO:  Nasty.



STEVE:  Nasty.  It really is.  So think about what this does.  I mean, think about what it means.  First of all, $780 current bitcoin, that's expensive.  And the other problem with the whole bitcoin thing is it's still not easy.  I mean, even if you had the will to pay someone a bitcoin, you know, my mom doesn't know how to do that.  I mean, it's...



LEO:  I know.



STEVE:  It's not an easy thing to do.



LEO:  You have to have some to begin with.



STEVE:  I mean, right.



LEO:  Or just go buy it, yeah.



STEVE:  Right.  So there's a significant conceptual and performance hurdle just associated with arranging payment, if you wanted to do that.  So that creates additional pressure, aside from the $780.  But now you've got an alternative.  And it's awful.  I mean, wow.  Now, okay, now.  As if these guys were not cretinous enough - and Leo, I put a link to the full-size warning message because there's a lot of fine print in it, and the show notes are very - make it difficult to read.  But as if these guys were not cretinous enough, they then in this message proceed to claim that they are Syrians, and that the proceeds from this extortion, quote, "will be used for food, medicine, and shelter."



LEO:  Oh, you're helping refugees.



STEVE:  Those in need.



LEO:  Not nice.



STEVE:  Then, quote, "We are extremely sorry" - uh-huh - "that we are forcing you to pay, but that's the only way that we can keep living."  And then I said:  "And in case you still thought they might be good guys, reverse-engineering of the code has appeared to indicate that four wrong guesses, four mis-entries of the key will trigger permanent deletion of the still-encrypted files."



LEO:  Wow.



STEVE:  So, yikes.  And unfortunately, I mean, and they even say in their message:  "Restore your files the fast and easy way."  Unfortunately, it's not that fast.  Bitcoin, as we were saying, isn't.  And then the alternative is, and they say this, "Restoring your files the nasty way."



LEO:  At least they know it's nasty.



STEVE:  Yes, send the link below to other people.  If two or more people install this file and pay, we will decrypt your files for free.  Wow.



LEO:  That is just - wow.



STEVE:  And unfortunately, it has a creepy feeling of success in the same way that, when we first encountered the concept of file-encrypting ransomware, it was like, oh, this is going to be bad.  As you said, the multilevel marketing and spreading, I mean, because what will happen is people - presumably you're not going to do this to someone you like.



LEO:  Well, that's true.  It actually could be weaponized for people you don't like.  That's a good point.



STEVE:  Well, but so there are people you don't like, but who you know enough about.  And so this is always the challenge, of course, with social engineering is that it's a scattershot.  Well, this is now a sniper rifle because you know who you don't like and who you want to help you get halfway off the hook.  And so you can use your knowledge of this person to incent them to click this link, to synthesize an email which will be especially relevant to them.  It's just, you know, so it's like a social engineering, multilevel phishing, file-encrypting malware.  It's just incredible.  So, and again I have to say diabolically clever because, oh.



LEO:  Yeah.  I'm sure people will send it along.  I'm sure it happens.



STEVE:  So everybody be careful because, yikes.



LEO:  Oy.



STEVE:  Now, our next up is the discussion of this very sobering Netgear router problem.  It was discovered by a hacker whose handle is Aceworm - I didn't dig into his background any further, I thought that was enough - who initially reported two Netgear router versions.  Netgear has responded.  When I looked late last night they had updated firmware in beta for three of their router models.  So, and unfortunately these are like all the good ones.  The R6250 is known to be vulnerable.  The 6400, that's the AC1750.  The R6700, the Nighthawk, very popular; the R7000, which is both the AC1900 and AC2300.  The R7100LG, R7300, R7500.  That's the Nighthawk X4.  The R7800 Nighthawk, the X4S; R7900, R8000, R8500, that's the Nighthawk X8; the 9000, and the Nighthawk X10.  So a broad swath of recent Netgear firmware, which of course demonstrates that it's a common codebase.



Here's the problem.  And the reason I consider this a dumb blast from the past is around the turn of the century - and isn't it odd that we can use that phrase now, and it actually means some time ago.  Around the turn of the century this is the kind of dumb stuff that was still happening.  That is, we were so nave back then that it didn't occur to us that your web interface could be used to execute things in the cgi-bin directory.  Well, of course that was fun for a while, and then it all got locked down.  Well, and it's back.  And that's the point.



Now, the good news is this is a local exploit.  So this is not like other problems that we've discussed where, for example, there would be an undocumented backdoor exposed on the WAN interface which would allow people aware of it or who had discovered it to just sweep the Internet and sweep up all of the devices that were vulnerable.  So this is only on the LAN side.  The problem is that it's, just as we were discussing, it's not that difficult to get someone to click on a link.  And when you click on a link in your LAN, you are on the LAN side.



So the exploit - and what's sobering about this is it is so simple.  It is http:// the gateway IP of your LAN.  And so that's going to be 192.168.0 dot something.  A Netgear - I hadn't thought of this until just now, but generally manufacturers all default to the same 192.168.  It's like .0.1.  I think Netgear tends to be dot one dot, like maybe 1.0 or 1.1 or 1.254, depending upon which end of the block of DHCP 1913 RFC addresses they go in.  Anyway, so it does need, you do need to be making a web query to your router's browser interface.  And so it's the IP/cgi-bin/; and then whatever you want.  Like a command.



So, and the problem is, for example, there are now proof-of-concepts of this.  There is a command that will start up the Telnet service and open it on a WAN-facing port, which then of course makes the router instantly vulnerable to remote access, essentially, console commands on that port.  CERT immediately issued an advisory stating that multiple Netgear routers are vulnerable to arbitrary command injection.  And they describe the problem as "improper neutralization of special elements used in a command."



Now, the good news is - okay.  So first of all, you can easily check to see if you're vulnerable by using the command Reboot.  So it would be http:// the IP address of your router, probably 192.168.1. whatever.  And of course that's your gateway IP.  In Windows you could open a command window and say Ipconfig.  I think that's what it is.  It's been a while.  And Microsoft, the exact command has drifted around a little bit from time to time.



But anyway, whatever the IP is /cgi-bin/;reboot.  And if your router reboots, you're vulnerable.  You can also instead use the command cgi-bin/;uname$IFS, which essentially is a space, and then a hyphen lowercase "a."  And if your browser shows you a whole bunch of stuff, you've just executed that command.  And because it's a cgi command, the output from the command is returned in the response to the browser's query, and you'll see a whole page of text of stuff from your router.  So again you know you're vulnerable.



Now, there is a temporary workaround, if you find you're vulnerable; and that is, you can shut down the web interface essentially to, while you get your firmware updated, to prevent your router from being accessible through the web interface.  So, for example, you'd have to do a local telnet or reboot the router or whatever.  So I don't know if you can disable through the UI the web interface.  But you can kill the process.  So same command again, cgi blah blah blah, cgi-bin/ - and all this is in the show notes, by the way - /;killall, and then the little string that expands to a space, which is the $IFS in caps and then a single quote, httpd, and then close the single quote.  So you're telling - that's a command telling the firmware in your router to kill any processes with the name httpd, which is the http daemon, the service running in your router.  So that immediately protects you, although when the router reboots it will start up again.  And it's possible that the router could notice that the httpd daemon has died and then relaunch it itself.  So it's sort of a sort workaround.



But for those who are concerned, there is firmware on the way.  I don't know how quickly Netgear will respond.  They already did have beta firmware that they were testing.  The list of vulnerable routers that I just presented is the most comprehensive one I found because I assembled it myself from several different sources of people that had since been verifying additional, you know, using crowdsourcing in order to get people to test their routers using these various approaches and then logging their responses.  So it looks like many Netgear routers are in trouble.  So if you are a Netgear user with one of these late model nice routers, check in with Netgear and/or use your router itself to check for additional firmware.



It may be that, while they're in beta - well, I'm sure that's while they're in beta they're not officially released and probably not available for automatic or automated install online.  So you'd probably have to grab them yourself.  And it's, again, not a remotely exploitable, not a huge problem, but Netgear's on it.  They've acknowledged the problem.  And they had, for the R6400, the R7000, and the R8000, they had beta firmware for those when I last looked.  And so you can check to see.  And again, the link to that page at Netgear is in the notes, too.



LEO:  Would be kind of - is it remotely exploitable if you click a link that launches the cgi script?



STEVE:  Correct.  So what would happen is essentially bad guys - and they're already getting very creative.  Bad guys can cause one or more commands to be executed in the context of the web service which runs with root privilege.  So you're executing root privilege commands to the firmware.  And so one of the things it could do is instruct it to fire up a Telnet service on one of the public-facing 64,000 ports, so whatever port the bad guy wants to use.  Then Telnet is just sitting there waiting for connections.  And the bad guy could be then scanning the 'Net for those ports which are open and accepting TCP connections, supporting Telnet, and then of course they have remote access to your router.



LEO:  Okay.  So they don't have to have physical access to your house.



STEVE:  No, no.  They, you know, you click on a link in social media, you click on a phishing link, and this thing then executes the command and alters your router in a way that's useful to the bad guys.



LEO:  Wow.



STEVE:  Yeah.  Not good.  And, you know, I've got a Netgear router, right up there.  It's got a whole bunch of little antennas all over it.



LEO:  Yeah, yeah.



STEVE:  So Yahoo, I call this "Yahoo's too-successful bug bounty program" because I was reading something from a Yahoo spokesperson bragging about this.  And I thought, you know, honey, I don't think this is really what you want to be bragging about.  So okay.  The beginning of this was, speaking of classic bugs that had long been fixed, Yahoo just paid $10,000 to a Finnish security researcher who found and responsibly reported a means for anyone to access anyone else's Yahoo mailbox, simply by sending them a specially crafted email.



This was a cross-site scripting bug.  The security researcher discovered that an attacker could sneak malicious JavaScript code past Yahoo's mail filters by abusing the way Yahoo Mail displays links to sites such as YouTube.  All that was necessary was to embed JavaScript within a specially crafted email containing a YouTube video link.  No action was required on the recipient's end.  Nothing to click, just viewing the email would execute this embedded JavaScript in the trusted web context of the user, thus the cross-site scripting problem, that would then allow this JavaScript code to execute exactly as if it had come from, as if its origin was Yahoo, which meant that it had full access to all of the Yahoo-specific resources like session cookies and so forth and could do whatever it might want to.



So anyway, as I was digging into this, I ran across this comment, that a Yahoo spokesperson said that the company "has developed one of the largest and most successful bug bounty programs in the industry.  'We've paid out more than $2 million in bounties, resolved more than 3,000 security bugs, and maintain a "hackership" of more than 2,000 researchers, some of whom make careers out of it.'" And I'm thinking, okay, wait a minute.  You have so many bugs at Yahoo that people's entire career is just cashing in on finding your bugs?  Well, okay.  Wonder what's wrong with this picture?



So, I mean, I guess it's better than them still having 3,000 bugs that hadn't been found, and it's their money.  And, I mean, it's great that people are being responsible and reporting these.  But still, you know, I'm not sure you want to brag about what a golden trove of treasure your service is, being that it's so bug-ridden that it's like, yeah, it's not that hard to find a bug.  You can make some money.



This is just really, really, really, really clever.  And the takeaway from this one is, boy, you know, where there's a will.  We've talked about steganometry before, and it's never really impressed me that much.  I mean, certainly it's probably a real thing.  So steganometry is this clever way of hiding something, essentially hiding a secret in plain sight.  And that can be done in many ways.  For example, you could embed a very soft whisper in an audio file, for example.  Technically that's steganometry.  And if you then took the original audio file and subtracted it from the altered one, you would be just left with the whisper, which could be the secret message.  Or what is the more common approach is, for example, to use the unused super-high resolution of images to bury another image or a digital message.



So, for example, we've got 24-bit color where we have red, green, and blue gets a byte of resolution each.  But so you have 256 different intensities of red, from none, that is, black to bright red.  The same thing for blue and the same for green.  Well, you can't see the least significant bit of those.  So for every pixel, every colored pixel you could steal the three least significant bits, one each from the R, the G, and the B byte, for your message.  When we look at it, we're just going to see the picture.  We're not going to notice that there's any specific message.



Now, maybe if the secret was like vertical stripes or something, like that was exactly lined up with the scan, the raster scan of the image, then maybe you could detect a little flutter in the least significant bit.  But it's probably going to look like pseudorandom noise.  It's going to be code, or it's going to be something.  So you just won't detect it at all.  But the point is that somebody who knows that a certain picture posted somewhere on the Internet, looking completely innocuous, if they know that has got their message in it, then they take it, and they strip out all but the least significant bits of each R, G, and B, and they've got their message.  And it wasn't - and then, I mean, and it could also be encrypted, then they decrypt it and so forth.  Or it just might be in the clear.



Anyway, that, steganometry, was used for two years before ESET found it in the wild in ads.  And not Spy vs. Spy, people using it to send secrets to each other, but a very clever means of sneaking malicious JavaScript past all ad networks' filters.  Because they're looking at the code in the thing you embed, not at the image.  And so what they did was they had innocuous code that looked just fine.  Nothing wrong here, I mean, kind of screwy, maybe; but why does it care about the images?  Well, what it's doing is it's processing the image, extracting the malicious content steganometrically from the image, and then executing that.



So it's just brilliant.  Again, it's just like, okay, we might as well just give up, if this kind of stuff - the problem is we have - and this is a perfect example of just so much rich technology that can be used in an inherently multipurpose fashion, that there are different ways to remix the same components and get a different outcome.  And, wow.  So congrats to ESET.  Somebody must have just asked themselves the question, okay, what is this advertising JavaScript doing?  And so they reverse-engineered it and thought, and why is it processing the images like this?  And they dug into it, and it's like, oh.  That's why.  And this thing had been going since 2014.



LEO:  That's amazing.  Wow. 



STEVE:  Yeah.  Just so cool.



LEO:  You're using the term "steganometry."  But I've also heard "steganography."



STEVE:  Yeah.



LEO:  Same thing?



STEVE:  Steganometry, steganography, yes.  Well, steganography probably...



LEO:  Is the creation of those images, maybe steganometry the reading of them.



STEVE:  And maybe "graphy" refers to image, whereas steganometry is more buried content.  So it may not...



LEO:  Yeah, the "steg" means hidden; right? 



STEVE:  Correct, yeah.



LEO:  Okay.



STEVE:  And in fact it was called the "Steganos exploit kit."



LEO:  Right.



STEVE:  Was the way that they named it when they found it.  And if you needed any, I mean, we know we don't need any other reasons for keeping really annoying visuals off of our browser.  But from time to time I am using a browser that has just - is wide open.  And I'm just...



LEO:  I know, it's terrible.



STEVE:  It's just - it's awful.  It's like, how did - and especially now, these autoplaying videos?  Oh, goodness.  It's like, no, no, no, come on.  And of course they're using your bandwidth for their own purpose.  And so...



LEO:  Everybody's started doing autoplay videos.  It's driving me nuts.  I just hate it.



STEVE:  Yeah.  It's really wrong.



LEO:  Unfortunately, you know, you can turn off Flash, or say Flash has to be loaded.  You know, you ask before running.  But now they're using HTML5 video, and that loads no matter what you do.



STEVE:  uBlock Origin.



LEO:  Love it.  Still use it.



STEVE:  Yes.



LEO:  All the time.



STEVE:  Absolutely.  It is on my browsers.  It's what I recommend.  Occasionally somebody will complain, that is, a site will complain.  I go, yeah, okay, fine, you know.



LEO:  More and more, yeah.



STEVE:  Yeah.  It has never been available for Microsoft's newest Edge browser.  It is now in final preview.  Microsoft has it available, and I've got links in the show notes.  It's on the Microsoft store, uBlock Origin preview, and should be - they're just nailing it down.  In digging around a little bit more, I was interested to see that, while it did need some customization, 95% of its codebase is unchanged and shared by Firefox and Chrome.



So this is really nice.  We're seeing a consolidation of plug-in backroom or backend technology, which is really, I think, a good sign.  We went through a phase where everybody had their own solution and approach.  And we're now seeing that pull together as people recognize, as Microsoft did with Edge, they could have certainly rolled their own from scratch.  They did roll their own browser from scratch, thankfully.  It was time to give IE its final dirt nap.



And now, rather than just going their own way, they clearly made an effort to have their plug-in API as Chrome and Firefox, that is to say, industry compatible as possible.  And so this is the kind of benefit that we will reap is that they will end up with plug-ins they would not have otherwise had, if there just wasn't enough incentive enough or time for a developer who was going to first support the dominant browser in the industry, which is now Chrome, to go and do a whole complete different implementation  for Edge.  So uBlock Origin coming soon to the browser you may be using, Microsoft Edge.



And we've spoken many times now about Moxie Marlinspike and his work, the Signal protocol.  The New York Times - I thought, okay, when this surfaces to The New York Times, you know you're getting real traction.  They had a weird picture of Moxie, though.  They arranged to hide his hair, which as we know is sort of strange.  But he was, like, tucked into this corner of a room that was otherwise apparently empty, with windows on either side of him, looking kind of forlorn.



LEO:  Aw.



STEVE:  And I thought, Moxie, what's wrong?  You know, The New York Times is talking about Signal.  So you should be smiling more.  If you click, the link in the show notes, Leo, you'll see The New York Times story and the picture of Moxie.



Anyway, so here's what The New York Times had to say, which I thought is like, wow, this is going mainstream.  They said:  "By the time you finish reading this column, you would be foolish not to download the messaging app Signal onto your smartphone and computer."  Okay, this is the paper of record saying this.



LEO:  Yeah, but it's also Brian X. Chen writing it, who's pretty savvy.  Really savvy.



STEVE:  Yes.



LEO:  Yeah, he's good.



STEVE:  Oh, yeah, yeah.  "The free encrypted messaging service has won the acclaim of security researchers and privacy advocates, including Edward Snowden.  All have said that Signal goes above and beyond other chat tools in keeping electronic communications private."  And of course we've given it a podcast, and I said the same thing.  It's like, wow, you know, this is the difference between doing everything you can think of to - well, and remember when I explained Signal, I was initially puzzled by some of the things they had done because it looked like a ridiculous level of over-engineering until I really sat down to learn it in order to explain it to our listeners, and it all kind of came together.  And I ended up with a great deal of respect for it.



And so their coverage continues, saying:  "Signal is one of many encrypted messaging services, but it stands out for its uncompromising security and ease of use.  The chat service retains virtually no information from users, including messages and address books, on its servers.  What's more, messages remain encrypted when passing through Signal's servers, meaning that the app's creators cannot read them."



And so that's their coverage.  And then I had added a note here to myself to remind myself to say that we know that Facebook's WhatsApp also adopted the Signal protocol.  But I think sophisticated users are encouraged to use Signal, and to definitely activate - remember that always for these things you don't actually have security unless you have authentication.  You have to know who the other person is and that that not be spoofable, that their identity is authenticated through some mechanism.  Otherwise nothing prevents a third party from being a shim, a man in the middle, and essentially inserting themselves into your conversation.  WhatsApp has the problem that Facebook has now officially said that they're going to do an information sharing between what the WhatsApp side of their properties and Facebook.  And there's a commercial interest.



So I guess the way I think this falls is there's a lot of Facebook users.  It would be better to use WhatsApp than nothing.  But if you really - and so, you know, why not?  It's there.  It's supported.  But remember that, for a reason I don't understand, the option to notify if the fingerprint of the identity of the other party changes, that's not on by default.  You absolutely want that on.  And the same thing goes for Signal.  You need to just once arrange to verify signatures.  And you can just do it through some out-of-band exchange, either on the phone or email or just tweet.  Just send some of the characters of the signature, and it's the output of a hash.  So it'll be impossible to deterministically spoof that.  Or, okay, I just used a forbidden word.  Not impossible.  Computationally infeasible.



LEO:  Challenged.



STEVE:  Yes.  So anyway, I just think it's great that we're seeing this kind of coverage.  And, boy, Signal is the one to use if you really do want to have yourself be secured.



LEO:  And I'm using it.  Now, the only thing I didn't like about Signal was that it uses my phone number for the account.



STEVE:  Ah, right.



LEO:  So it does leak a little information.  I mean, you've got to do something, I guess.  Threema doesn't because you have to meet and exchange information.  But that's not practical.  The other thing I like about Signal is there is a Chrome extension for it, so you can use it on your desktop computer.



STEVE:  Oh, nice.  That is one of the things that is chafing for me as an iOS user, I was mentioning earlier, is that Apple doesn't want me to be communicating with my iOS things over on Windows.



LEO:  Yeah.  So Android lets you use Signal as your main SMS app.  You can designate it.



STEVE:  Nice.



LEO:  But obviously that's - the limitation of iPhone is, you know, you can't make anything but Safari your browser.  You can't make anything but Messages your messaging app.



STEVE:  Right.



LEO:  I mean, Apple does encryption on Messages; right?



STEVE:  Yeah, yeah, yeah.  They absolutely do.  But they also manage the keys for us.



LEO:  Yeah.



STEVE:  So there's the convenience of it just works.  Yes, it's encrypted.  But if the FBI said, "We really need to be monitoring this communication; slip our key into the group," then the user would have no idea.  I mean...



LEO:  Well, and law enforcement could subpoena it because they have the key.



STEVE:  Correct.  And it was funny.  Charlie Rose interviewed Bill Gates a couple weeks ago.  And Charlie was really interested in AI, wanting to pick Bill's brain about AI, and also this whole issue of encryption of our communications.  And Bill didn't go into any detail because, you know, it was Charlie Rose.  Just, you know, that audience doesn't want details.  But Bill was adamant in saying Apple can get your content.  Apple can see your data.  Apple can do this if they want.



And I appreciated just the simplicity of that communication.  He stated, first of all, it was Bill Gates who you're going to tend to think, okay, he probably knows what he's talking about.  And so it's not easy to kibitz that.  And he's, like, saying, no, Apple can.  Let's just, like, take that question off.  And it was funny because Charlie was confused because he was like, well, wait.



LEO:  No, Apple implies, oh, no, it's...



STEVE:  It's encrypted.  It's encrypted.



LEO:  Yeah, they don't - they really - they do a lot of hand-waving around that.



STEVE:  Well, and of course I've also watched him interview Cook, who's like, oh, no, everything's encrypted.  We can't see any of it.  So it's like, okay.  And of course we know Bill's right.  Yes.  Apple ultimately controls the software in your phone, end of story.  They can give you anything they want.  They know who you are.



LEO:  Right.



STEVE:  You know, you individually, uniquely.  So, yeah.



LEO:  And of course I think any, you know, January 20th on, a newly empowered FBI will be knocking on Apple's door, I'm sure.



STEVE:  Well, and I actually skipped that in The New York Times article.  There was a paragraph about the incoming...



LEO:  Well, that's why Signal's downloads are up 400%.  It was right after the election.  I mean, you know, that's a little alarmist to say suddenly we've got storm troopers.



STEVE:  Precisely.  And it wasn't relevant to the technology. 



LEO:  Yeah.  But it's just prudent to do it, and do it now.  And then you don't have to worry about it.



STEVE:  So arguably one of the stronger antivirus systems, BitDefender, has been around for years.  It ranks very highly in various third-party cross-AV analysis of, like, false negatives, false positives, how many signatures are found, and so forth.  Many people this week shot me a link to a new product, a hardware product that the BitDefender folks have produced, called BOX because that's what it is.  It's a box.  So it's BitDefender.com/box.  And it's very pretty, and it glows.  There's sort of an apex on the lower edge and a nicely sort of cyan light can be seen.  And apparently that can blink red if it's not happy and change colors and do things.



So, and I was curious.  It's like, okay, what is this?  Because here's the problem.  And we've discussed this before, partly in the context of Cujo, which was another, an earlier box which did not impress me for two reasons, our listeners will remember.  One was that it was doing a deliberate ARP attack on the person's LAN in order to hijack the interface associated with the gateway IP, to solve the problem of how it could be able to intercept your communications.  So that just was clunky.



I mean, I understand if you decide you want to solve the problem, and the architecture of the system won't let you physically connect Cujo inline.  For example, if you don't have a separate router and a cable modem or a DSL modem where there's a wire connecting them, that allows you to put Cujo in the middle then this is a way to solve that problem.  But the bigger problem is everything's encrypted more and more.  And so something like a Cujo sitting there saying we completely protect your system, and we're going to scan you for viruses, and it's like, no, you're not.  You can't.  You can't see into the traffic anymore.



And so when BitDefender did this, I thought, okay.  Do we have the same problem here?  So I read through their 46-page owner's guide, and it looks like this is the real deal.  However, it comes at a cost.  Sort of icky, but if this is what you want.  So I'm not sure this is a solution for us all, but for many people.  They solved the going dark problem because essentially they've got the same problem the FBI has.  But this time they're on your side, definitely looking for anything, wanting to intercept anything that they believe would be malicious, to do AV stuff.



Now, I'm assuming they are doing traffic filtering.  And the big problem is how would we know?  There is no technical explanation anywhere.  It's just look how pretty the box is.  Look at the rounded corners.  Buy it.  I think it's normally 199.  At the moment it's discounted to 129.  But of course it's also got the annual subscription service fee.  Now, for that you get a lot.  But the problem is we don't know exactly what you get because it's all just nice-looking glossy surface, both on the box itself and on the website.



So it's impossible for me to be as definitive as I would love to be because, very much as is the case still with BitTorrent Sync, they won't tell us.  They won't share what they're doing.  So it's like, well, it might be secure.  The point is the icky part, kind of, but the tradeoff, is they require you to run agents in every device in your house.  So they've got Windows, Mac, iOS, and Android.  I don't know if they have a Linux agent, but of course a lot of our listeners are running Linux that would like that protected.  They don't have a TiVo agent nor a light bulb agent.  So there's the problem of coverage if their solution depends upon something on the endpoint helping them to get around encryption.



And in fact that is necessary, that is, if your light bulb or your TiVo is going to have an encrypted connection, there's nothing they can possibly do to intercept it.  I mean, well, except synthesize a certificate which would be signed by an already trusted certificate authority.  And no certificate authority of any repute would ever give them a certificate that had resigning, you know, certificate signing privileges itself.  So we've covered stories of where other commercial devices have been found doing this; and then the people who signed their cert for them said, oh, well, that was just meant to be contained in the lab.  That was never supposed to be out in the wild.  It's like, uh-huh, okay, well, so.



So here's the problem.  BitDefender I'm sure wants to do a good job.  They want to make money.  They're telling you that this solves all the problems that you have.  And it's a compelling - it's like, wow, you know, I just stick this here in my network, and now I'm secure.  All of my stuff is secure.  Except, okay, it's not all, and we just don't know what they're actually doing.  So I got so many people said, hey, you know, what is this, I wanted to address it.  And unfortunately, I have to say they're not telling us.  I'd be happy to know.



But there are problems with doing both what Cujo, I mean, aside from the Cujo's approach, which was the ARP hack, there are problems with any solution which purports to just be a drop-in box on your network that's going to secure you because it has the same problem that law enforcement has out on the Internet, which is it cannot see into the traffic to an ever-increasing degree.  And maybe these endpoint agents give them a tap prior to encryption, which would then allow them to see it.  It's just not possible to know.  And they could be doing DNS and looking for malicious websites, I mean, there are many good things such a box could do.  But again, it's just trust us, plug it in, and now you're secure, and make sure you don't miss one of your annual payments.  So we'll see.



The people who brought us the VeraCrypt audit a few months ago shot me a tweet three days ago, actually to you, Leo, and me, and Security Now!.  You know, Security Now! does have a twitter account.  Somebody got it.



LEO:  It does?



STEVE:  Yeah.  Somebody grabbed it in the very early days.  And I want to say they offered it to me.



LEO:  Oh.



STEVE:  I don't remember what the deal was.



LEO:  They probably did.



STEVE:  But anyway, so this is the OSTIF...



LEO:  [Crosstalk] "This account name's been reserved for Steve Gibson on GRC.com."



STEVE:  Yeah, okay.  So if anybody here...



LEO:  No, no.



STEVE:  I don't know how to - who are you?



LEO:  Yeah.  Huh.



STEVE:  Yeah.  Anyway, it's receiving tweets from people.  But I'm not seeing them.



LEO:  Yeah.  Don't tweet to that one.



STEVE:  So this is the OSTIF.  The official account said to us:  "You guys did a great piece on our VeraCrypt audit.  We are at it again with OpenVPN."  To which I say yay because it's OpenVPN.  It's like it's the one that has won.  So the effort was launched by OSTIF exactly three weeks ago.  It was Tuesday, November 22nd.  OpenVPN is currently at v2.3, with 2.4 in beta.  So it's 2.4 that is the focus.  We haven't had a version change in OpenVPN in quite a while.  It's got tons of fixes and feature changes and improvements.  So it's going to be the first major release in years.



These guys hope to raise $71,000 to fund an audit of OpenVPN, much as they did fund the audit for VeraCrypt.  iPredator has contributed 10 bitcoins, $7,700; OpenVPN Technologies, $5,000; Perfect Privacy, $3,500; nVpn.net, $2,650; ExpressVPN.  And so these are providers; right?  ExpressVPN, $2,500; SmartDNSProxy, $2,500; iVPN, $2,100; SecureVPN.to, $1,500; VPN.ac, $1,500; and so forth.  And then it goes into a whole bunch of others.  So they're about halfway to their goal.  And so first of all I wanted to bring it to everyone's attention.  They are looking for contributions.  So it's OSTIF.org is the outfit.



Now, then something odd happened that they're not happy about.  But as long as it doesn't derail this effort, I am happy about it.  And that is that Private Internet Access - which is another major VPN endpoint provider.  Private Internet Access apparently, after knowing of this OSTIF effort and being contacted by them and solicited for participation, you know, to be named among the supporters of the audit and so forth, they just decided to go their own way.  They've hired Matthew Green to independently and separately audit OpenVPN, this forthcoming v2.4.



LEO:  Well, that's just him. 



STEVE:  Well, exactly.  So, I mean, so this is not bad. 



LEO:  He's the guy who did the TrueCrypt; right?



STEVE:  Well, yeah.  Yeah, Matthew is the...



LEO:  Is the guy.



STEVE:  Yeah, the cryptographer.  He's spoken in front of Congress, and he's at Johns Hopkins.  He's in the middle of all this.  And so, as long as this independent effort doesn't prevent OSTIF from succeeding with their fundraising goal, then I think the more eyeballs that are focused on this next version of OpenVPN, the better.  And this is not like someone saying, okay, we need to absolutely verify once and for all that two plus two equals four.  Okay.  I can do that.  You know, we don't need a group.  We don't need a committee or a team or a big effort.



But as we know, unfortunately, the way software exists today with its complexity and features and so forth, especially as it gets older, and it's bringing a whole bunch of legacy stuff along that no one's willing to let go of, which is the case with OpenVPN, although it's a good solid offering, you know, those things are more like, okay, we need the exact count of stars in the Milky Way.  Okay, let's assemble a team.  Because that's not something one person can arguably answer.



So this does require - nailing down software requires more effort.  And I would imagine different things will be found.  And actually, if it was ever possible to compare the - if there was no leakage between the two audits, be really interesting to compare what they both independently found, how much overlap and how much non-overlap in the Venn diagram of the two audits is there.



So I wanted to let everyone know that, first of all, the good news is that we are apparently definitely going to get some good audits of OpenVPN:  one privately financed by a provider using Matthew Green; and the other is the OSTIF, who brought us the VeraCrypt audit, going to do the same thing, bring us the OpenVPN audit.  And if any of our listeners are interested in contributing anything to that effort, it's OSTIF.org.  



LEO:  It's kind of a high-risk proposition, though, because if you miss something big, that looks kind of bad; right?



STEVE:  Yeah.



LEO:  There'll be overlap, but I'm sure there'll also be unique findings on each person's part.



STEVE:  There'd have to be, yeah.



LEO:  Because you're not going to find everything.



STEVE:  I mean, because it is a big - well, and also, too, it is absolutely the case just that there is a matter of opinion involved.  Like someone could say, you know, I've never felt comfortable casting 16-bit values to 32 because on some platforms where you might have a compiler that does this, blah blah blah.  So it's like, so even code has gray areas which are about style and taste rather than - and feedback from longstanding real-world experience, where you just go, oh, you know.  That can kind of come back and bite you in the ass, you know, sometimes.



So, yeah.  If you're in a situation where you've got big gray areas, you're going to have different outcomes.  And which is why, actually, it'd be great for them both to do their thing.  And then, of course, share their, you know, cross-share their results so that we end up with the - I'm sure we will end up.  Certainly the OpenVPN project is the ultimate arbiter.  It will receive the results of both audits and automatically amalgamate them into what finally becomes 2.4.  So it'll be fascinating as we watch this evolve to see how it goes.  And I think probably, you know, as we're seeing, these things are not taking forever to happen.  The TrueCrypt audit was only a couple months.  And VeraCrypt, same thing.  So, neat.



A little bit of miscellany.  I have a new puzzle, Leo.  The good news is I like them when they're free, and I like them when they're cross-platform.  So this is for both iOS and Android.  And I really enjoy this.  This is, you know, as I've often talked about, the requirements for me for puzzles, I don't want to have to, like, you know, a reflex test where something flashes by, and I have to nail it with my virtual blaster.  I want to have something that's more contemplative.  This is called Square it!.  And much as they - yup, there it is on the screen.  And much as they used an infinity sign as the first character of Infinite Loop, these guys have used the unicode block character as the first character of the name Square it!.



So it's called Square it!.  It is free, although it is ad supported.  After you finish a level, you get an inter-level ad.  And if that's annoying, $0.99 and that disappears.  So mostly because I like these guys' work, and I want to support them, I immediately shot a dollar, I mean, it's a dollar, shot a dollar at them so that I would not be facing those ads.  And I really like it.



It's difficult to explain.  It's unlike anything that you've seen before.  Very minimal, well, and Infinite Loop was this way, too.  Remember, Infinite Loop was you got a grid of squiggly shapes, for lack of a better term, which had been rotated arbitrarily.  And when you tapped on them they rotated 90 degrees per tap.  And so you just had to figure out, had to essentially reassemble this fragmented sort of jigsaw by rotating pieces until all the pieces connect to each other with no frays, no loose ends.  So that was completely novel.



This is, too.  You just push up, left, right, or down; and you move one or two cursors around.  And the goal is to fill all of the area.  Very simple.  No instruction manual.  The first few puzzles show you everything you need to know.  And it's algorithmically generated.  I'm on, I think, on the pad I use most for reading - I'll pause reading and do a few levels and go back to reading - I'm like on Level 94 or something.  And it's just nice.  None of them are super hard.  Some of them are a little trickier.  But they also go forever.  So I just - it's Square it! for iOS and Android.  And it gets the full recommendation.  No timers, no strikeouts.



Be nice to have an undo, that is, instead of a restart, because a couple times - the nature of the rules are that, as you're painting this region in order to fill it with the color of the cursor, you can't go back.  You can't ever go over what's already been colored.  And sometimes I've, like, swiped to the left and realized, ooh, I don't want to do that.  And I may be well into solving the puzzle, but there's no undo one step.  You've got to start from scratch.  So that's - it'd be nice to have that.



LEO:  I made TraptionBakery my Pick of the Week on iOS Today.



STEVE:  Oh, good.



LEO:  Keep up those picks.  You're saving me a lot of work.



STEVE:  Perfect.



LEO:  Yeah.



STEVE:  Yes.  And that's had some great responses.



LEO:  That's a wild one, yeah, yeah.



STEVE:  So you know that you're in a seriously geeked-out podcast when we're seriously considering the proper position of Spock's thumb for the Vulcan whatever that is - the Vulcan hi, how you doing, mahalo, live long and prosper.  It always goes along with "Live long and prosper."  And so we discussed this a couple weeks ago.  Somebody sent me a screenshot of a very serious-looking Leonard Nimoy making it very clear.  And the moment you see it, it's like, oh, of course.  And in fact I remember I was talking about the best man in my wedding who used the red orthodonture bands in order to do his fingers right because he wasn't able to do it otherwise.  So the answer is thumbs out.



LEO:  Thumbs out.



STEVE:  Yup.



LEO:  Interesting.



STEVE:  Thumbs out.



LEO:  I wouldn't have thought that.  I think the chatroom was guessing thumbs in.



STEVE:  And when you see it, you go, oh, I mean, it's just like so familiar.  If Spock didn't have his thumb out like that, it would just be wrong.  So thank you.



LEO:  It's the Boy Scout salute if you - yeah, out, yeah.  Out looks right, you're right.



STEVE:  Yeah.



LEO:  I can't do it.  He did it with his left hand, though, I think.  Or did he do it with his right hand?  I can't remember.  I can't do it with my left hand.



STEVE:  Oh, yeah, I've got both hands under control.  But of course I've had a lifetime of experience.



LEO:  Yeah, practice.



STEVE:  And, finally, last week's discussion of using the smart data that SpinRite was feeding back generated a couple questions.  And one of them reminded me that there was a third way of using the information that I had forgotten about.  And that is to say, and so the tweet was from a Justin Alcorn.  He said:  "@SGgrc, SpinRite Level 4, 500GB drive, 350 million ECC corrected."  So that's, like, during the Level 4 scan that drive had 350 million read errors which ECC successfully corrected.



LEO:  Wow.



STEVE:  Yeah.  "And 21 million seek errors."  He says, then, "Throw it away?  Or did we just fix it?"  And I talked about how the problem is that these numbers only mean something in context.  And unfortunately the manufacturer doesn't provide us the context.  And the manufacturer has also been sort of forced to provide this information against their will.  They want them to be a black box.  They want it to be just trust us.  And it's only the users of the drive who've said, eh, not so fast there.  We need something.  Give us some feedback about what's going on.  And so the SMART, the Self-Monitoring - SMART.  Self-Monitoring...



LEO:  I always want to say And Reporting Tool, but it's not.



STEVE:  You're right.  There's another...



LEO:  It's almost like they've tried hard not to do the obvious.



STEVE:  Exactly.  And I always stumble back into the obvious.  Self-Monitoring - what could A be?



LEO:  I'm sure the chatroom will tell us.



STEVE:  Anyway, someone will tell us.



LEO:  You'll have it soon.



STEVE:  Analysis.



LEO:  There you go.



STEVE:  Self-Monitoring Analysis and Reporting Tool.



[SMART = Self-Monitoring Analysis and Reporting Technology]



LEO:  There you go.  That sounds right.



STEVE:  I didn't cheat, it just took a minute...



LEO:  Yeah, but it sounds right, yeah.



STEVE:  ...to dredge it out of my rusty old neurons.  So you need - and come on, analysis?  Yeah, we wish.  No, 350 million ECC corrected errors.  Where is my analysis?  I mean, that's what Justin is asking for...



LEO:  Yeah, right.



STEVE:  ...is can I have an analysis, please?



LEO:  No.



STEVE:  What does this mean?



LEO:  Yeah, mm-hmm.



STEVE:  So it's the context.  And I proposed two ways last week of establishing some context.  If you had multiple drives of the same, like you bought five at once so that they are same model, same make, same manufacturing batch even maybe, but run SpinRite on all of them.  Now the other four provide the context for the fifth one, and vice versa.  So then you'll easily see if one of them looks like a sour apple.  It's like, ooh, boy, you know, that's - I don't think I want to put my data on that sucker.  It'll stand out from the crowd, probably not in a good way.



The other way, if you don't have that option, I suggested, well, one thing you could do is you'd like to see a uniform rate of errors being corrected.  That is, not some region where that number just shoots up skyward so that the maximum - so that there's a region where there's a maximum rate that is much larger than the rest of the drive, which is more near the average or minimum rate.  So that's something you could do.



But there is one other thing that I forgot to mention.  And that is, when you are deploying drives for the first time, run SpinRite on the drives.  Note the level and the numbers.  And that allows the drive to establish its own starting context.  Then a year from now, or six months later, or a quarter, maybe just burn the drive in and do it again.  The point is sometime downstream, when you rerun SpinRite, you're rerunning exactly the same code on exactly the same drive.  Well, you know you're not going to get exactly the same error counts on any of these.  But you'd like to see it similar, not suddenly wrong.  And write those down.



So the point is you can, you know, this should be relatively static.  And if any of these suddenly start going, I was going to say south, but technically north, more is probably bad in the case of errors, then that's context.  That says something is softening, something is weakening in here, well before any alarm bells go off, well before any data is in trouble.  I mean, this is why I've always been so bullish about this smart real-time probing that SpinRite does.



And I put that in, SpinRite 6 is the first version that ever had that, because it is just - it is incredibly sensitive in terms of what potential value it offers.  But unfortunately it comes at the price of more user involvement that we would require because the manufacturer doesn't want to say, ooh, this isn't looking real good here.  It'd be nice, you know.  In that case we would have context.  But we have to create our own.  At least SpinRite gives you the raw numbers from which you can do that.



LEO:  I thought of a way you could get that Security Now! Twitter account back.



STEVE:  Okay.



LEO:  DM the guy.  I tried to DM him.  He's not following me, so I can't DM him.  But I bet you, if he thinks it's your account, he's following @SGgrc.



STEVE:  You know, okay, maybe he is.  I'm sure I tried that once.



LEO:  Yeah.  Then that won't work. 



STEVE:  I definitely [crosstalk].



LEO:  Everybody DM him.  Oh, you know what, you can easily see who he's following.  I think he's only following one person, so, yeah.  Maybe the person he's - actually, I bet you the person he's following is him.  I'm sure we can track that account down, get it back [crosstalk].  Do you want it?



STEVE:  Well, it's been 12 years, you know, it's...



LEO:  Eight years.



STEVE:  Doesn't seem to be a big - oh, yeah.  Wait, no.



LEO:  Twitter's only been around for 10 years, so it can't have been 12 years.



STEVE:  The podcast predates Twitter?



LEO:  Of course it does.



STEVE:  Well, no wonder that I wasn't a member in the beginning.



LEO:  Yes.  Oh, no.  Goodness, gracious.



STEVE:  I'll tell you who's really in pain is the @stevegibson guy.  He's like, he's not happy.



LEO:  Yeah, he's sorry, he's sorry he did.  You know what, he doesn't follow any - this account doesn't follow anyone.  So there's no way we can DM him.  So if you're listening, Mystery Person - it's got your album art on it.  If you cared a lot, we could go after, you know, we can go to Twitter.  But I don't think you care.



STEVE:  No.  And my point was, you know, SGgrc, that's five characters.  That's, like, fine.



LEO:  It's you.  It's you, man, you.  Steve, we've got questions.



STEVE:  I don't believe it.



LEO:  Steve's got some answers.  And I'm ready with the first one if you are.



STEVE:  And it looks like seven may just be the perfect number, too.



LEO:  Just about the right amount.  We've got 45 minutes.



STEVE:  Yeah.



LEO:  Bruno V. kicks this off, this question fest, with a tweet.  @SGgrc Hey, at you.  OpenVPN with Raspberry Pi.  Now remember, it's 140 characters, so it's going to be a little terse, a little succinct.  Open VPN with Raspberry Pi.  Assuming the Pi can be hacked once exposed to the 'Net, would you recommend placing it on the DMZ?  Thanks.



STEVE:  No.  Next.



LEO:  That was easy.



STEVE:  No.



LEO:  Don't do that.



STEVE:  No.  So, but this is a great question.  So he's saying we're using OpenVPN running on the Raspberry Pi.  And we've talked about, for example, the Pi VPN, where one of our listeners built a script which completely installs OpenVPN on, what, a $35 Raspberry Pi.  You then plug it into one of your router's unused ports, and you're golden.



The problem is, the point is you want to have OpenVPN as a server running at your home for remote access.  That is, when you're out roaming in, for example, in an unencrypted open WiFi, you use the OpenVPN client, which exists now on all platforms, to connect to your OpenVPN server at home, and then it does the decryption, and your traffic emerges onto the Internet from your home.  And/or you have access to your internal network.  That is, when you OpenVPN in from the outside, you get an IP address on your LAN.  So you then have seamless access to your entire home network, as if you were there.  So it's very cool.



But all of this requires that the OpenVPN server or service is reachable from the outside.  That means you have to open a port through the router so that it can get to the OpenVPN service.  And so what Bruno is saying, well, one way to do that is by using the router's DMZ, the demilitarized zone feature.  And essentially what that does is it is the IP address to which any unsolicited incoming traffic is sent.



Normally, as we've discussed often with a NAT router, anything not expected coming in, that is, any traffic that is not a response to something that initially went out is dropped, which is why a NAT router is a natural firewall; so that, as the traffic leaves, a table entry is made to note the exit of that packet.  And when a packet returns with the source and destination IPs exchanged and the source and destination ports exchanged, what that is saying is I'm coming back from somewhere you just sent me.  And so there will be a match in the table which then tells the router which internal IP, which machine inside your LAN originated that packet.  And so the packet destination address is rewritten to the IP of the original sender, and the packet goes into your network and so forth.



So what that means is that unsolicited traffic is ignored.  It just dies at the WAN interface because there's nowhere for it to go.  It's trying to come in, but nobody's expecting it.  There was no expectation created by an outbound packet first, to which that's a reply.  So we have two choices.  One is you use the DMZ feature as the default destination for unsolicited traffic.  Now, yes, you could put your Raspberry Pi IP as the DMZ.  It would then be receiving all unsolicited traffic.



But this is exactly the cause for Bruno's question and concern.  He says, "Assuming the Pi can be hacked once exposed to the 'Net, would you recommend placing it on the DMZ?"  And that's why I so quickly said, well, no.  Because essentially what that means is that anything incoming, like all the Internet background radiation that exists, all those unsolicited packets, which we're relying upon our router, that isn't very intelligent, I mean, it's a router, it just says do I know what to do with this, no, and drops it.  Now we're saying, oh, come on in.  Make yourself at home.  And we have a Raspberry Pi ready to consider what to do with you.



LEO:  I'll be your host today.



STEVE:  Yes.  It's going to say, well, what do we have here?  And so who knows what is going on in the Raspberry Pi.  The nature of these things are that you want to minimize the attack surface.  What we've just done is spread it all out there for anything to, like, come on in.  Maybe you can find a problem.  No.  So the solution is static port mapping.  The idea is that - so the DMZ is the - I'm not sure today, in today's world, if there is a justification.  Well, there is one justification for it, and I think it's in the next question.  But it's hard to find one for exactly this reason.  It was always there.  It's just the de facto, sort of the get around the NAT problem.  Except it turns out NAT wasn't a problem.  It was a blessing.  Which is why everyone should be hiding behind one.



So this is the right way to do this, is that the OpenVPN will be listening on ports which you configure.  And here's a default one, but it's been so long since I used the OpenVPN default port.  That's the first thing you want to do.  Don't use the OpenVPN default port.  It doesn't matter which one you use.  And I have, for my application, I use a bunch of different ones.  And, for example, 110 is nice because that's POP, which is generally accessible everywhere, the Post Office Protocol, because people tend not to block it.  ISPs block 25.  You won't have any success there.  Or 80, for example, that's the HTTP port.  Well, you probably don't have a web server running at your house, so you could put OpenVPN there, although that sort of exposes it to anything else that might be probing around the 'Net for web servers.  So maybe stick it up in the higher port numbers.  But just, you know, make up some numbers.  You want it to be sort of obscure, not to rely on that, but why not also have that?



And so the idea is that you tell your router, any traffic coming in to this port, whatever it is, 123123, should be sent to this IP.  And that is the IP of the Raspberry Pi.  That way, rather than opening the floodgates, you're just poking a little pinhole through your NAT saying, if any packets are smart enough to try to come in at 123123, at that port number, we're going to let them go because they're probably us over at a Starbucks somewhere, or in an airport, trying to reach our OpenVPN router.



And the good news is that that port will come through only going to that port on the Raspberry Pi.  So nobody outside can scan around.  Essentially, if you use the DMZ, they can do a port scan of your Raspberry Pi and find everything that it might have open, rather than just a little pinhole that allows only the packets that know the secret, well, or obscured port number to sneak through the NAT boundary and get into your Raspberry Pi.  And I think we've pretty much covered that topic.



LEO:  Mike Chapman is next.  Hi, Steve.  I'm seeing more websites ask for a username before a password instead of together.  I'm thinking it's less secure.  Is it?  Love the show, et cetera.



STEVE:  You know, that's a great question.  So he says he sees more websites ask for a username before a password.



LEO:  Google does it, too, yeah.  I've seen [crosstalk].



STEVE:  Yes [crosstalk].



LEO:  And so that makes me think it's more secure, frankly.



STEVE:  Well, it's a function of the way they handle it.  And this is why Mike's question made it into our Q&A.  We know how rare these are.  So it's got to be a good question.  Because if the website does the wrong thing, then the separate handling of username and password lets it be probeable.  Remember that the famous weakness in WPS was the web auto configuration.  It was an eight-bit token, but you were able to guess the four - or, I'm sorry, it was an eight-digit token.  But you were able to guess the first four digits separately from the last four, and technically the last three, because the eighth one was always a check digit, a checksum.



And so what happened was that meant that you could only - the designers intended for you to have to guess them all as one, seven digits with a check digit.  And that would be enough combinations that it just was infeasible to crack it.  But an error in the protocol allowed you to independently, because it was a multiple handshake, and we covered this in detail at the time, you were able to separately guess the first four.  That reduced the possibilities to 10,000 guesses, which became feasible.  Now you had the first four, you only had to guess the next three, which was only a thousand possibilities.  So by cracking the problem into two separate pieces, it dramatically weakened the strength.



And exactly the same thing happens with username and password.  A site which allows you to enter your username and verifies it for you in any fashion, without then always asking for your password, think about it, that allows you to separately probe for usernames.  If instead a site either asks for them both at once, or if receiving your username never changes its behavior and always asks you for your password, then you're not able to probe the username space separately from the password space.  Now, some people might say, oh, that's really not such a big deal.  It's like, okay.  I wonder if WPS designers thought that at the beginning when they allowed the protocol to handle the eight digits in two separate pieces, and it completely destroyed the security of their solution.



So he says, "I'm thinking it's less secure."  He's right.  It's technically less secure.  Maybe it's not enough to matter.  But it is an issue that web designers should keep in mind, that is, it does allow usernames to be tested for validity without needing to be accompanied by a password.  And if instead the site responds always by asking a password, or asks for them both together, then you don't know which of the two you got wrong.  And that's the point.  You don't want to have this problem capable of being broken down into smaller pieces.  It's just not good.  So great question, Mike.



LEO:  Question 3 comes from Joseph W. Barlow, a.k.a. @sobokuone, his Twitter handle.  Hey, @SGgrc, I bought the Eero router, but I'm now finding they don't support stealth ports.  Should I be concerned?  All ports are closed.



STEVE:  Okay.  So this is why I was talking about the DMZ again, because what this means is that, for whatever reason, the router - well, okay.  I said for whatever reason.  Technically, stealth is a violation of the RFCs.  That is, and as far as I know, I'm actually the person who coined the term, because of course it came from Star Trek and ShieldsUP! and stealth ports and so forth, because that was quite a while ago.



The RFC states - the formal specifications for the Internet - that, if a packet is attempting to go to a server, and it's certainly the case back in 1973 in the chart that we discussed at the top of the podcast, is as a courtesy, because after all we're all on the same team, we're all pulling in the same direction; right?  We'd like to tell somebody, oh, sorry.  Your data arrived.  We looked at it, but we don't have a service listening for incoming traffic on that port.  In other words, there is always a reply to an attempt for a packet of this sort that might receive, for example, if it's a TCP packet, it might receive a TCP ACK as part of the setup process.



What you don't want is a black hole; especially, for example, in the case of DNS.  DNS is, as we know, doesn't have a delivery guarantee as part of the protocol.  So you make a DNS query over UDP.  And it's the UDP protocol that is not guaranteed to itself deliver the packets.  So if you don't get a response, you assume that the response either was lost in returning to you or lost on the way there, per the original definition of the Internet, where everything always responds.  And it's nice that everything always responds because then, if you do make a query over UDP, for example, for DNS, and you get a response back saying, sorry, no service here, there is actually a port closed response.



In this case UDP doesn't have it, but ICMP has it.  So the ICMP protocol is used to send back a, sorry, that port is not open.  Well, then you affirmatively immediately know that, okay, that there's no point in retrying.  It's not that there was a lossage somewhere, or a routing problem, or a congestion or something that lost your query or your reply.  You know you're never going to get one from that IP at that port number.  Which the designers intended.  The problem is it also makes the entire Internet probeable.  That is, you then, if this were still the case, if stealth didn't exist, then people would be knowing that they would get a response from any IP and any port which exists and did receive their incoming traffic.  And the decision was made, very informally, this is not endorsed anywhere, it's like, eh, maybe we should just pretend we're not here, and thus this concept of a stealth port.



So Joseph is saying there's no option on the Eeros.  Now, there are some routers that automatically drop packets that are unsolicited.  There are some where you can tell them I want to respond.  Sometimes ping has a separate checkbox in the UI, where you can have the router respond to pings, but not other ports.  Sometimes these things are configurable.  But the fallback position, if you do want stealth - and so my point was that there are purists who would argue that stealth is by its nature a violation of the way the Internet works.  Technically NAT is, too, because you're not supposed to go around rewriting, addressing information on packets.  They're supposed to be inviolate.  But sorry about that.  It's not the way reality and the Internet intersected.



So I don't think it's a huge problem if your router is not stealth these days.  But if you want it to be, and if the router does support a DMZ, then just as we were talking about in response to Bruno's question, the DMZ is by definition where to send anything that is not otherwise expected.  Well, where do you send it?  You send it into outer space.  You configure the DMZ IP to something on your network that doesn't exist.  And normally the DHCP configuration, the dynamic host configuration protocol address range on your LAN, normally it's not from zero to 255.  Sometimes it's like one to 100.  So you know that no machine on your LAN will have the IP ending in 101 because the router's not automatically allocating addresses in that range.



So, for example, set the DMZ IP to something outside of the range that your router is using for LAN addresses on your network.  And anything coming in, the router will rewrite the packet's address to that nonexistent IP and stick it on the LAN.  Well, there's nowhere for it to go.  If it hits a switch, the switch will have never seen any device with that IP.  It'll just discard it.  And so you can create stealth by using this little DMZ hack.



LEO:  That's clever.  I have Eeros at home.  I'll try it.  I didn't even think about that.  Of course I should have run ShieldsUP!.  First thing I do with any new router.  I wonder how many of these simple mesh routers do stuff like that.  I know I can do - surprisingly, the Eero has a lot of things like DMZ and  port reservations, port forwarding, stuff like that.  So certainly your solution, your workaround is possible.  But I will try it when I get home tonight.  I also have the Google mesh WiFi solution, so I'll try it with that.



STEVE:  Yeah.  We're seeing now router firmware is mature enough that, even though they may hide it under advanced setup and advanced settings and things to sort of keep regular users from being freaked out by it, there's really no excuse not to have all that technology available in routers.  This just may be buried a little bit.



LEO:  They can do it.  I think they don't, they choose not to, mostly because they don't want to overwhelm people.



STEVE:  Exactly.



LEO:  It's not a geek router, that's for sure.



STEVE:  Right.



LEO:  Does the job, though, in a way that the geek routers don't seem to.  So Reston Wiles in St. Louis has titled his rant "WiFi Lite Bulb Morons."  Shall I do it like that?  I'm mad as hell, and I'm not going to take it anymore.  What I cannot understand is the perceived need, use, desire, or the stupidity required to purchase expensive idiotic WiFi lamps.  I don't use WiFi and as - I realize now as I read this I've got the wrong voice.  I don't use WiFi and as little BluT as possible.



When I transfer data to a device I plug it in.  When I need to turn on a lamp, I reach out and turn it on.  If I want to fake lamp use in unoccupied home while traveling, I put some on timers and a couple of photocells.  I have hardwired security cams well hidden.  Motion sensors turn on porch lamps and security cams.  I've missed the entire IoT brain wash.  Explain to me, Steve, why people use this stuff.  How lazy, cool, and trendy do you have to be?  At what diminished IQ level does IoT become a necessity?  And while you're at it, get off my lawn.  Sorry.



STEVE:  With apologies to Reston.



LEO:  I'm sorry, Reston.



STEVE:  Thank you, Reston, that was...



LEO:  WiFi light bulb morons.



STEVE:  And Leo, thank you.



LEO:  You're welcome.  A dramatic reading.



STEVE:  And I'm so entertained I have no idea what the question - what the answer to the question is.



LEO:  I don't think it's a question.  The question is, "Why does one do that?" he says.  Why would you do that?  What's wrong with your IQ?  You kids today and your fancy doodads.  In my day.



Bob Raffety in Florida is a bit puzzled by ShieldsUP! with a VPN:  I recently purchased a VPN service, Windscribe, and decided to see what happened when I tested it with ShieldsUP! at your site.



STEVE:  Uh-oh.



LEO:  People still use ShieldsUP!.  This is so awesome.  The results - oh, boy - were many open ports:  20, 21, 80 - well, 80's always open - 143, 443 also should be open; right?  Well, not, no, only if you're running a server, I guess, in inbound ports, on the Windows 10 Pro computer.  Their support indicated the results showed the status of their remote server and not my computer.  Huh.  The software client has a firewall-enabled switch which is enabled when the VPN is active and turned off when not enabled.  My background experience tells me they're pulling my leg.  Get off of my leg.  Has there ever - sorry.  Shhh.  Your part is over, sir.



Has there been any test with the many VPN services and ShieldsUP!?  How can I reliably test my computer while the VPN is active?  My experience is over 30 years of tech support.  I was introduced to SpinRite back in 1990 when working with a computer support company and purchased it back in the early 2000s.  I listen to your podcast, but I'm a few months behind.  So if you've talked about this, just let me know which podcast.



STEVE:  So this comes up all the time.  And I've even seen some very rude VPN tech support people saying, oh, you can't trust that ShieldsUP! thing.  It has no idea what it's talking about.  And that's like, okay, let's all take a deep breath.  First of all, Bob, these guys were exactly right.  But they may not have understood what was actually going on.



When you contact GRC's website or - and we can broaden this to the Internet, any website.  Those websites, mine and others, see your IP as the IP of the VPN provider.  That is, when your packets emerge from the VPN service, Windscribe in this case, the source address of the packet, which used to be you at home, is now changed to the VPN service.  So that the packet then goes out onto the Internet, does whatever it needs to do, and answering packets return to the VPN service.



So what that means is that Internet websites see you as the VPN's IP, as the VPN service.  They don't - your actual IP is obscured behind their own lookup table, which knows where to send that VPN packet to get it back to you.  But out on the public 'Net, we all just know somebody using Windscribe is at our website.  So when you as a VPN user test ShieldsUP!, I'm not seeing, GRC is not seeing your Windows 10 Pro computer.  I don't know its IP.  And that's one of the reasons you use the VPN is to hide your IP.  So I'm telling you about the ports that Windscribe has open because that's how I know you.  I know you by your public IP on the Internet, which because you're behind Windscribe is their service.



So now we know Windscribe's VPN servers have ports 20, 21, 80, 143, and 443 open.  And so it's interesting to know what ports a VPN service may have open.  And those look reasonable.  Yeah, I don't see anything really wrong with that.  Of course, it's a function of what they are doing with them.  And it may probably have other high-numbered ports open, as well, which ShieldsUP! could test for you.  You just have to ask it to do that explicitly because it otherwise just does the service port range from zero.  And I actually do test zero because there are such things, up to a little past 1024.



So anyway, many people wonder about this.  They kind of like want to check their security, thinking, ooh, you know, I'm behind a VPN.  It should be better.  But then they see these open ports, which is confusing.  And, yes, it's because I'm no longer able to see your computer, which is what you want.  And so I'm showing you what we do see, which is the VPN service.  Which is all anybody can see of you when you're behind a VPN.



LEO:  That's the point.



STEVE:  Yeah.



LEO:  You're testing the VPN, not you.  If you could test you, you'd obviate the point of the VPN.  Jeff Gros, Yorba Linda, looking for - wow, ShieldsUP! day today - a ShieldsUP! command line:  Steve, I'm planning on setting up a Raspberry Pi behind my EdgeRouter X - love these Ubiquiti routers, BTW.  Can't stop buying them.  They're the 50 buck routers that I still have just sitting around.  I've got to figure out something to do with it - to remotely monitor and control my 3D printer.  That means I'll have to port forward to the device.  However, I would like to double-check my security once I get the device set up.  I haven't set it up yet as I don't have the Raspberry Pi yet.  But I'm assuming it will command-line only.



That's not true, actually.  You can have a browser in a Raspberry Pi, so you can do all of this.  Is there a terminal version of ShieldsUP! that I can run?  Or perhaps there is a clever way to do this with Linux commands?  Any help is appreciated.  Thanks.  Jeff.  Just a side note, the Raspberry Pi does in fact have a full GUI with it.  Raspbian is a Debian distribution, and you have a browser and everything else.



STEVE:  Nice.  So we've never really talked about user-side port scanning.



LEO:  Yeah, because you could do everything VPN, I mean, that ShieldsUP! does yourself; right?



STEVE:  Yes.  And so the, well, yes, you can.



LEO:  Can't really say what the outside world sees unless you go somewhere - yeah.



STEVE:  Correct.  Correct.  So the advantage of ShieldsUP! is that it gives you a public-facing view, that is, it's GRC looking back at you from the public to see what you're exposing.  So that exists.  Now, the alternative is to know what's going on internally.  And GRC can't, and it shouldn't be able to see because you're behind a router, which as we just have been discussing is blocking all of that.  So there are all kinds of tools that have been written for local port scanning.  But there's one that stands out from all others.  It's the granddaddy known dearly and "indearly" to every hacker, and that's NMAP, N-M-A-P.  NMAP.org/download.html will take you there.



LEO:  And if you need help with a mnemonic, that's what it stands for, network mapping tool; right?  [Crosstalk], yeah.



STEVE:  Correct, correct.  Now, the caution is don't freak out because it's going to show you stuff that's going to curl your hair.  The point is you're hiding behind your NAT router.  And all kinds of stuff in your network has ports open.  Apple's got Bonjour talking to everybody, and TiVos have a bunch of ports open.  And there's like, there's this amazing amount of stuff going on on your LAN, and NMAP will find it all and show you what's going on.



The key, though, is that would be a problem if, well - and this is one of the reasons why I'm a little worried about IPv6 giving us 64K IPs per subscriber is that, I mean, this router is a very good thing to have.  You want no one to just be able to reach into your network.  NMAP on your LAN has full visibility to all the devices and all their ports on your LAN.  You want to keep that to yourself.  You want to keep that behind a router.



But with that understanding - oh, and there is now a GUI frontend for NMAP.  It used to be, I mean, for the longest time it was magic incantations and a lot of help information available about how to do this and that, what IP ranges to scan, what port ranges to scan, how many times to look, how long to wait between.  I mean, it is a feature-rich, massively mature port scanner/network analysis diagnostic.  I mean, it'll find every device on your network, things you forgot about, things that are, like, plugged in behind the sofa that you - it's like, oh, that's still there?  I mean, it's great.  But again, understand that ShieldsUP! will show you what you care about if you're worried about exposure to the world.



What any local scanner will show you is how much you need that router to be in between you and the rest of the world; why I'm so bullish about it as a native firewall; and why, even after we start getting blocks of IPv6 space allocated to us, you absolutely want stateful packet inspection in between your home and the public Internet.  It's just - actually I would argue that LAN-based systems take that for granted now.  They don't even have to worry that much about their security because they're going to be behind a router that's going to be the thing responsible for keeping them safe.  So NMAP.org.



LEO:  NMAP.  Lee in the U.K. says he's going to work around the Snoopers' Charter.  Hey, Steve.  Long-time listener, love the show.  You've mentioned a few times now about masking your Internet activity by using a VPN to connect back to your own home pfSense - that's the firewall Steve uses - or equivalent system, then doing your Internet searches from your home.  This has been my solution for some time now using the Sophos UTM, formerly the Astaro Gateway, former advertiser on the show.  However, I'm based in the U.K., and so this isn't sufficient any longer since our government last week passed the Investigatory Powers Bill or Snoopers' Charter.  Now even the Food Standards Agency has access to the list of domains I visit.  



So my current thinking is to ditch the Sophos UTM - it cannot unfortunately be configured to route external traffic through a VPN unless it routes to another UTM - in favor of pfSense, which can be configured to route traffic to any OpenVPN connection.  My current choice is NordVPN.  I'm thinking that's out of Norway, or certainly not out of England.  I want to get your thoughts on this, also let you know that the notion of connecting home so your employer can't see what you're browsing is now scuppered by the U.K. government - if, of course, you reside in the U.K.  I hope you get time to cover this on the show.  All the best.  Lee.



STEVE:  So I just, you know, this sounds like, I mean, first of all, we've discussed and covered the Snoopers' Charter.  This sounds like he's interested in a standard VPN application to hide his traffic and get it out of an area where it is subject to surveillance.  And so he's doing, I mean, this is what he wants to do.  And as long as he chooses an endpoint that is outside of the U.K. or wherever the legal regime is that he's trying to thwart, then yes.  Law enforcement will know that his IP is routing encrypted traffic out of their boundary.  And as long as that's allowed, that system will work.



My guess is that this strategy may not have much life because you can certainly imagine, if the decision has been that the government needs to be able to see into everyone's traffic, then one way or another they're going to arrange to make that happen.  And I don't know what that means, if that means maybe you have to, like you are required to use local-ish VPN services so they can see the decrypted traffic.  Remember that, even then, even with a VPN, as we've been saying, the bulk of traffic is still HTTPS tunneled.  It is in a TLS tunnel that is encrypted and authenticated.  But DNS queries are not.



And I've even seen some VPN configurations that did not tunnel DNS.  Which is to say they tunneled traffic over TCP, but not necessarily the machine's own DNS queries, which of course is a privacy leakage for that VPN configuration because, as we know, DNS does not have an encrypted flavor, and you would need to be using something like DNSCrypt with a service like OpenDNS in order to obscure where you were going.  So to me, I get what Lee is trying to do.  Unfortunately, he's operating within a government that has decided they're going to legislate themselves the ability to see what everyone is doing.  And they're bigger than he is.



LEO:  Mm-hmm.  Yeah.  Yeah, that's encouraging.  So thanks for ending on a high note there, Steve.



STEVE:  We should have done Mr. Grumpy as our final question.



LEO:  Mr. Grumpy should have ended the show.  Well, you know, the nice thing is if you don't use the Internet, no one knows what you're thinking.  Or something.



STEVE:  Yeah, that's actually true.



LEO:  Yeah.  It's a lot harder to figure out.



STEVE:  And if you do, then everybody does.



LEO:  Yeah.  Steve is on the Internet, GRC.com.  He's also on the Twitter, @SGgrc.  You can go to GRC.com to get SpinRite, his bread and butter, his daily bread, the program he makes available to you at a fee well worth the price for the world's best hard drive maintenance and recovery utility.  Go there.  And while you're there you can also get a copy of this podcast.  He has the audio plus transcripts, which is nice, for every show ever, all 590 of them.  He's also got other stuff, free stuff, lots of free stuff, good stuff there.  In fact, it's kind of a fun place just to wander around through the archives of Steve's mind as placed on the Internet:  GRC.com.



We have the show, too, audio and video, if you want, at TWiT.tv, and in this case TWiT.tv/sn for Security Now!.  And of course you can find it on every podcast client.  We do the show every Tuesday, right after MacBreak Weekly, so that's about 1:30 p.m. Pacific, 4:30 Eastern, 21:30 UTC.  Please join us live.  Join us in the chatroom.  Chill with us.  Hang with us.  You can even visit us in the studio.  Email tickets@twit.tv.



One more day to get your TWiT Army shirt, great design by Anthony Nielsen.  Go to Teespring.com/twit, T double E, Teespring.com/twit.  And we are going to do a TWiT Store, and that will be one of the designs in the store, but it might cost a little bit more because we will be mass printing them.  So if you want it, and you want it at this price, and it's a good price, go now, Teespring.com/twit.  I think tomorrow is the last day, maybe the day after tomorrow.



We are also looking for best-ofs.  Not for this show.  We've decided, Steve's decided to reprise one of the most popular shows he's ever done, the story of the Portable Dog Killer.  No dogs were injured in the making of this show, I promise you.  But that'll be the Tuesday after Christmas.  The rest of the shows, though, we will be doing best-ofs, and we'd love to hear from you.  If there's a moment from this year that you would like to recapitulate, go to TWiT.tv/bestof.  Give us whatever information you can.  We ask for a lot of information, but you don't have to know it all.  Just give us whatever you know, and we will help our editors put together the best-ofs, as we do every year.  It's always fun.  Steve, we've got one more show before the holiday break.



STEVE:  Wow.



LEO:  I know, can you believe that?  Next week.



STEVE:  Cool.



LEO:  And I will see you then.



STEVE:  Thanks, buddy.  Talk to you then.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#591

DATE:		December 20, 2016

TITLE:		Law Meets Internet

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-591.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  This week Leo and I discuss Russia's hacking involvement in the U.S. election; that, incredibly, things get even worse for Yahoo; misguided anti-porn legislation in South Carolina; troubling legislation from Australia; legal confusion from the Florida appellate court; some good news from the U.S. Supreme Court; Linux security stumbling; why Mac OS X got an important fix last week; the steganography malvertising attack that targets home routers; news of a forthcoming inter-vehicle communications mandate; professional cameras being called upon to provide built-in encryption; Let's Encrypt gets a worrisome extension; additional news, errata, miscellany; and how exactly DOES that "I really, really promise I'm not a robot (really)!" non-CAPTCHA checkbox CAPTCHA work?



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a jam-packed show, lots of security news.  Yahoo hacked; a billion accounts lost.  What did the Russians actually do to hack our elections?  And why the Florida court says, no, you've got to turn over your passcode as well as your fingerprint.  It's all coming up next, and a lot more, on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 591, recorded Tuesday, December 20th, 2016:  Law Meets Internet.



It's time for Security Now!, the show where we cover your security and privacy online, the last episode, last fresh episode of 2016 for this guy, Steve Gibson, the man in charge at GRC.com, our security guru.  I think you have disciples, Steve, who follow Steve's way.  I know I'm a disciple, in the sense that, when I see a weird security practice or something new, I always ask myself, "What would Steven say?"  



STEVE GIBSON:  What would the Gibsonian response be?



LEO:  What would Gibson do, WWGD.  I also - I think that you've helped me kind of be a better consumer of technology because of that; you know?  So thank you.



STEVE:  Well, I do know, for what it's worth, that I get a lot of really good feedback from people who, as you said, they'll see some news and send me a note to make sure that it's on my radar and often say, you know, can't wait to hear what you think of this.  Because as we've seen...



LEO:  Mm-hmm, exactly,



STEVE:  Yeah.  As we've seen, these things are complicated.  It's funny, I was just thinking an hour ago about the Windows metafile issue.



LEO:  Wow.	



STEVE:  Which was controversial because it was clear to me, and to Mark Russinovich when he looked at it, that all it was, was an escape that would allow native code to be placed in the image.  Now, and the problem is that people immediately go to how horrible that is from an exploitation standpoint.  But it's important that it be put in context.  Metafiles were created before networking.  So this was a clever solution to what if the language of the interpretive metafile doesn't do something that we need?  Oh, let's just let the metafile contain native code.  You know, Google does that with Chrome.  That's NACL, their native library that allows them with a great deal of control to do the same thing.



Anyway, so the point is that this stuff is not simple.  And you know me, I love figuring things out and living in complexity.  I just dig - I just jump in with both feet.  And I've had the advantage of being here all along, watching this sort of all happen.  So for me it's really - it's a symbiotic relationship.  I love being able to look at these things and explain them to our listeners.  And I'm just glad that so many people appreciate it.



LEO:  We do.  We do indeed.  I look forward to - I've learned, you know, I have to say, in general TWiT's more educational for me probably than almost anybody because I'm here for all the shows.



STEVE:  And actually I do hear you using...  



LEO:  All the time.



STEVE:  ...some of the stuff that we've talked about here on the other podcasts...



LEO:  Absolutely.



STEVE:  ...where there's overlap.  So this week I called - I named this "Law Meets Internet" because the lead stories generally involve the struggle that I think we're just seeing the beginning of, of the Internet becoming, like, really a thing.  It's important now.  And in fact the first thing we need to talk about at least somewhat is this whole Russia hacking involvement because we can't just ignore it.



LEO:  I really want to talk to you about this.



STEVE:  We can't ignore it completely.



LEO:  Yeah, yeah.



STEVE:  But, so, I mean, it's clear that this is - like the Internet is really something.  And so naturally there's confusion about how to handle the intersection of what started off as pure technology with life, and the way civilized societies have figured out to do this.  Well, I guess even tribal societies.  They have their sets of laws, too.  So it's rules and regulations and dos and don'ts.  And so we have a number of things there.  We've got of course the Russian hacking involvement in the U.S.



We have to also talk about briefly, incredibly, it gets even worse for Yahoo.  Who could have thought it could be worse than 500 million accounts breached?  Well, yes, it can.



LEO:  Yes.



STEVE:  Then we've got, speaking of legislation, we have some misguided anti-porn legislation that's been made in South Carolina; some troubling legislation in Australia; some legal confusion from the Florida appellate court that you were talking about on MacBreak Weekly; some good news finally on the patent scene from the U.S. Supreme Court.  So those are all just sort of law things that happened in the last week.  Some interesting problems with Linux desktop security, four new problems that have just happened recently.  And again the press has drawn the wrong conclusion.  It's like, oh, my god, Linux is no more secure than anything else.  It's like, okay, slow down.  Then also why last week's Mac OS X update was important.  Because of responsible disclosure, we only found out now what got fixed.  And it was kind of scary.



Then we have more news about the steganography malvertising attack that we discussed last week, and what the actual mechanism is that it's using.  Some news of forthcoming inter-vehicle communications, which the National Transportation Safety, whatever it is, is mandating for, like, right now its proposed rules.  Once it happens, it has a two model-year cycle.  And then any new vehicles need to be able to talk to each other.  So we'll cover that in more detail.  And something I thought would really interest you, Leo, that you'll probably want to talk to Scott about, is professional cameras are being called upon to provide native, built-in encryption.  Also Let's Encrypt has an almost foreseeable, yet still worrisome, extension that we need to talk about.



Then, after all that, we've got some additional news, some errata, some miscellany.  And then I answer the question, well, or I try to, exactly how does that "I really, really promise I'm not a robot" checkbox...



LEO:  Oh, good.



STEVE:  ...non-CAPTCHA CAPTCHA work.



LEO:  I've wondered this a long time, so that's good.



STEVE:  Yeah.  So I think a great podcast.



LEO:  [Crosstalk] coming up.  And the law meets the Internet.



STEVE:  Our Picture of the Week...



LEO:  I love this.



STEVE:  ...I got a kick out of.



LEO:  Yes.



STEVE:  I don't know where it came from.  But I think everybody's probably heard that, like...



LEO:  You don't go on Facebook.  But Facebook is loaded with this kind of quiz thing.



STEVE:  Oh, okay.



LEO:  And this could easily be a Facebook quiz.



STEVE:  Well, so remember, what was it, I think...



LEO:  Your porn name.



STEVE:  Yes, that's what I was going for.  I think it was your childhood pet and the street you grew up on, something like that.



LEO:  Yes. 



STEVE:  Which would make me Terry Overhill.



LEO:  That's good - for an older porn star.  



STEVE:  So, yeah.  Well, and I would be.



LEO:  By the way, don't give out your - some of these could be used in security questions.  But I know you're smart enough.  You would never use anything factual in a security question.



STEVE:  Exactly.



LEO:  But that could potentially be another reason why they put these quizzes up; right?



STEVE:  Well, okay.  And that of course is the point.  So in that vein, this appears to be, for the people who don't have video, this is a form you fill out that says, "What's your Star Wars name?"  And so they're apparently doing the same thing.  It just says "Enter your Social Security number and mother's maiden name to find out."



LEO:  Great.



STEVE:  And then I put a little caption down at the bottom, "Courtesy of P.T. Barnum."



LEO:  Yeah.  There's a sucker born every minute; right?



STEVE:  He was given attribution for that famous phrase.  And so, and I looked at this, and I thought, you know, none of our listeners, I mean, they would find this humorous.



LEO:  They'd get it immediately.



STEVE:  I'm absolutely sure that, I mean, remember, Leo, I know that you'll have probably seen ugly cars driving around the streets.



LEO:  A few, yeah.  Driven some myself.



STEVE:  Okay.  Somebody bought that ugly car.



LEO:  Yeah, yeah.



STEVE:  There was something called the "Thing" once.



LEO:  Oh, god.



STEVE:  And I actually saw them on the road.



LEO:  Yeah.



STEVE:  Someone bought a Thing.



LEO:  That was a Volkswagen.



STEVE:  Yes.



LEO:  And they ended up discontinuing it because, if you got hit in the Thing, it was composed of a bunch of panels.  All the panels would pop off, and you'd be sitting there naked on the road in your chassis.



STEVE:  And so this is the lesson - oh, and we've also seen, like, unbelievable colors on cars.  It's like, okay, somebody either bought that, or they did that.



LEO:  Christmas sweaters.  All you have to think is Christmas sweaters.



STEVE:  Yeah.



LEO:  People wear those; right?



STEVE:  And somebody bought them.



LEO:  Yup.



STEVE:  So it used to be on a hook.  Now it's on them.  So the point is that somebody is going to see this and go, oh, I can't - what's my Star Wars name?



LEO:  My Star Wars name.  I want a Star Wars name.



STEVE:  What was - let me look up my Social Security number and put that in, and my mother's maiden name.  And, oh, wow.  Anyway, yikes.  Just got a kick out of that.  Perfect Photo of the Week for us.



Okay, so Russian election hacking.  Now, we're in a situation again where neither of us have any facts.



LEO:  Right.



STEVE:  As you know, I'm not on the inside.  I have no connections with the NSA or CIA or anything.



LEO:  Seventeen intelligence agencies, of which I can only name three.



STEVE:  Yeah, it's like, 17.  



LEO:  Seventeen.  Who are these people?



STEVE:  Clapper is still clapping around in there somewhere, too.



LEO:  Yeah, yeah, he's in charge of the whole schmiegel.



STEVE:  But there is something we could say.  And that is that, from the coverage that I have seen, it appears that - well, and in fact there is another, the news just broke today, and I may make it the subject for next - oh, wait, week after next podcast, the first podcast of 2017.  And that's a massive Russian organized ring was found doing fake advertising, generating it's estimated between 3 and $5 million per day in ad fraud.



Anyway, the point is that sort of standing back from 10,000 feet, in general I get the sense that Russia, for whatever reason, has been expending a great deal of effort on the cyber front, that is, in all things cyber.  Attacks, penetrations, scans of all kinds.  We're often talking about .ru domains, and things are generally terminating back in Russia.  And so, and as I understand it, they don't have a super energetic economy.  It's not producing a lot except for, I guess, some natural resource-based stuff.  So it's also something that is perfect for that kind of an economy, that is, cyber is, because it doesn't have a high entry cost, it scales well, and so forth.



So I guess I'm listening to all of this coverage surrounding did they, didn't they, what happened, what's this about, and also just all of the chomping at the bit that's going on.  Everyone's just all in a big flutter.  It's like, okay, we've been saying now for years on this podcast that everything is porous.  That is, we have so much complexity has been added, and we're lagging years behind in finding bugs that are often years old, and that creates a moving window of opportunity.  All of that says that the more you want to do something, the more you can - the more opportunities you can find.



That is, everywhere we look we see attack surfaces that can be leveraged.  And apparently Podesta got his emails hacked by clicking on a phishing link which got something installed in his machine; and then they were able to say, oh, thank you very much, and look around.  So stuff we've been talking about for years is happening.  But also many of these organizations have subcontractors which may or may not be very good.  Some of the stories we heard were that the FBI was, for example, notifying a subcontractor who did IT for the Democratic National Committee for months that their machines had been penetrated, and the IT guy didn't even take it seriously.  He was part-time, and he didn't think it was the FBI.  He thought it was just a prank call.



So, I mean, so it's a combination of human error, human factors.  And of course ultimately software errors are the same thing.  They're extensions of human mistakes that well-intended and intending programmers make which doesn't keep the software from working, but it does create opportunities for bad guys to get in.  And so I guess my take is I'm not, without any evidence, without any insider knowledge except if you just swept your arm across the last several years of this podcast, you would have to come to the conclusion that, when somebody wants enough to get into something, with the way things are today as we wrap up 2016, it's possible, from literally hook or crook.  You can get in and...



LEO:  Especially a targeted attack, a spearphishing attack, where they're going after a specific asset.  That's very hard to defend against.



STEVE:  Correct, correct.  I mean, I would say it's beyond hard at this point.  I would argue it's probably impossible.  With everything we've seen, we keep seeing gifted hackers able to penetrate whatever they want.  Pwn2Own, every browser falls in the first hour.  And it's like, ouch.  And mobile phones do, too.



LEO:  And it's presumed that a government attacker has access to all - unlimited resources, or virtually unlimited resources.



STEVE:  Yes.  So if we imagine that Russia has decided by policy, sometime in the past, that the Internet is the best thing that ever happened for enabling them as a society, as a nation-state, to mess around with other countries, then you put - compared to, for example, what the U.S. spends on military, you put relatively tiny cyber resources behind a concerted effort, and all of the evidence would suggest that they can pretty much do anything they want to, if they try hard enough.



LEO:  And it goes both ways.  We're clear, I mean, why wouldn't we be doing exactly the same thing?



STEVE:  Right.



LEO:  And there's a certain irony in the CIA saying, well, the Russians subverted our election, after that agency specifically has subverted elections with all sorts of covert actions over the last five or six decades.



STEVE:  Well, we were listening to Angela Merkel's phone.



LEO:  Right.



STEVE:  She was a little annoyed.



LEO:  That was the NSA.  But the CIA guaranteed that we would win elections all over the world, and has for years.  So, you know, you and I both are liberals and probably voted a little differently than the outcome.  But I think it's a little overblown to blame Russia on the outcome of the election, or to say, oh...



STEVE:  I didn't say that.



LEO:  No, I know, I know you didn't say that.  That's what's being said.  And I kind of want to push back a little bit on that, not because I'm happy about the result of the election particularly, but just because it doesn't seem like, I mean, okay, getting into the DNC's email, I mean, if you said they got into the voting machines and changed the count, okay.  But that doesn't seem to be what they're saying.



STEVE:  No, no.  Well, and relative to whether the election was altered, as we know, you can't prove a negative.  And so there's no way now, retrospectively...



LEO:  Although we just saw today reports that said there doesn't seem to have been any widespread voter fraud at all.



STEVE:  Right, right.  And I was thinking more in terms of biasing the electorate.  On the other hand, you would argue that our own FBI was a substantial influence in that with the timing of what Comey understood, I mean, I completely understood the position he was in.



LEO:  That you could argue, yeah.



STEVE:  He couldn't say nothing, or after the fact he would have been blamed for not saying anything and [crosstalk].



LEO:  Well, that you could argue about.  But I think in a way it's a disservice to point at the election results because what I would far prefer to hear our intelligence services saying is we have widespread evidence of Russian hacking in a variety of activities, and we need to do something about that.  When you tie it to the election results, it makes it much more of a partisan issue.



STEVE:  Right.



LEO:  That really doesn't - it's a disservice to the much larger issue.  But I don't think they want to talk about how much we're doing.  So I think they're reluctant to get into that larger issue, frankly.



STEVE:  Right.  I think that's exactly true.



LEO:  Yeah, yeah.  I mean, I'm much, and we've talked about this before, worried about hacking the grid, for instance.  It would be fairly trivial for this nation-state to take our grid down.  I mean, I'm a lot more worried about that.



STEVE:  UPS, baby, battery backup.



LEO:  Yeah, yeah.  Well, I'm not worried about my servers, anyway.



STEVE:  Yeah.  So, okay.  So anyway, that's really all I wanted to say.  I didn't want to not discuss it ever, and I just wanted to say I'm sure it's no surprise to any of our listeners that this kind of thing is possible.  We know, for example, that from Edward Snowden's revelations, how much our own government, our intelligence services are doing.  It was an eye-opener.  I mean, like all the project names, I mean, we had a field day for a year covering all of the disclosures that came out of that.  And we also know that China is very active.  We're very active.  And we know in many other ways Russia is very active.  And it's not hard to be active.  And there's also people in their basements are able to hack things, too.



So, yeah, we have, I mean, what's interesting is that we're seeing, again, as the Internet intersects the real world, and I guess if nothing else the outcome and the issue of the U.S. presidential election is about as real as it gets, then suddenly people are saying, "Oh, wait a minute, this is really bad."  It's like, yeah, okay, this has been going on for a long time, and it doesn't seem to have gotten on anyone else's radar in as significant a way as it finally has.  So I just think this is all for the good because, as we know, security is hard.  And you have to work at it if you want it.



And there are some places you really need it.  I would argue messaging, eh, some people certainly need secure messaging.  I don't have any particular need for it because I'm just, you know, arranging what time to meet friends for a meal.  So I guess my point is it's variable.  And something like, you know, the more important things are, the more people want them to be secure.  The problem is we don't currently have an infrastructure that guarantees that.  And as with all the other lessons we see is that, if we ever get there, it's going to take a while.  And you and I, Leo, will have been long retired.



LEO:  Yeah, yeah.  I mean, let's get the intelligence agencies focused on what Russia is doing and maybe come up with ways to defend against that.  That I'm all for.  I'm all for.



STEVE:  Yeah.  There's no way.



LEO:  But I think you make an excellent point.  I would hate - should we be fatalistic about that, then?



STEVE:  I think you could - we could call it that.  Or you could call it realistic.  I mean, look at the history.



LEO:  Yes.



STEVE:  The history says your light bulb could be attacking someone.



LEO:  Right.



STEVE:  I mean, we're not making this up anymore.



LEO:  Truthfully, if I were Russia, I think that there will be much more damaging things you could do than what seems fairly minor, which is breaking into the Democratic National Committee and releasing its email.  It seems like they could have done a lot worse had they really been strongly motivated.



STEVE:  Yeah.



LEO:  Am I wrong?



STEVE:  Well, no.  And that's the other problem is there's always a problem with attribution, and we're also not able to read people's minds.  So like just recently the question was, or what was in the news was that Putin himself was directly involved.  And of course no one will explain how they know that, but that's now what they're saying.  Again, that stuff, I just sort of - I listen to it.  I think, okay, well, that's interesting.  Maybe that's true.  But it isn't anything that is actionable.  But what we do know is that everything has been built up in complexity on a fundamentally weak foundation.  Lots of security intention.  But complexity, as we've often said, is the enemy of security.



And what's happened now is that the Internet is becoming really important.  And as we will be covering here in the next few stories, now our legislators, which is like the tool that bureaucracies use for trying to set limits and boundaries, that's now getting involved, which is always a little frightening.  But first we find out that more than three years ago, in August of 2013, one - more than, actually, it's more than one billion user accounts at Yahoo were hacked.  And so this news comes out since our last podcast.  And I think, okay.  Actually, it was Wednesday of last week.



And I think, okay.  First of all, remember the old phrase, "Fool me once, shame on you; fool me twice, shame on me."  If I refuse to learn from my mistakes, well, whose fault is that?  Which is my way of asking what security-conscious person could possibly still be using Yahoo?  That is, they've been sending up mushroom clouds every few months for the last year.  And anybody who is concerned about security should be long since gone.  And what's interesting is that, even after three months ago, in September, when they confessed to the 500 million accounts being hacked back in 2014, so that was only two years ago, they didn't force password resets and security question changes.  Now they're doing so.



What we learned is that this most recent billion-plus account disclosure revealed sensitive user information including names, telephone numbers, dates of birth, hashed passwords, and unencrypted password reset security questions, you know, speaking of Terry Overhill.  So if anyone listening to this is still using a Yahoo email account, you have to ask why.  And also, absolutely, the only thing you really have to do is make sure you're not sharing any of that information, your password reset security questions, your hashed password, which is who knows how three-plus years ago it was being hashed.  It's hard to imagine it would have been secure.  And make sure there's no overlap between that and any accounts you actually do care about.  I could understand having a throwaway email account, but just be very careful with the way you use it.  And unfortunately we're also seeing ways that someone getting into an email account can then escalate their attack through various other means.



So again, it's hard to believe anyone would still be there.  What we hear in the coverage or read in the coverage is that - and here's the takeaway.  Yahoo was ignoring the pleas from their security IT people for years.  They were deliberately giving - they were like, yeah, yeah, yeah, fine, we don't want to inconvenience our users.  So what's one of our other major mantras on this podcast is security and ease of use are always at odds with each other.  So what we're seeing is the downstream consequence of a huge company with public-facing accounts, Yahoo Mail, that also has the policy of not doing what their security people are urging them to do for years because they don't want to ruffle any of the feathers of their users.  So billions, billions of email accounts.  



LEO:  I always suspected it because we'd get all these calls on the radio show from people whose Yahoo account has been hacked.



STEVE:  [Crosstalk].



LEO:  Yeah.  And it wasn't that they had bad passwords.  I mean, it seems like they were very vulnerable.  The other thing I would say is - I would like to propose and hear what you think is one probably shouldn't delete one's Yahoo account because you don't want to give up that mail address, especially if you ever use it for password resets or anything, because Yahoo reassigns those addresses.  You don't want somebody else to get your email address.  You want to keep it, but just keep it dormant and kind of - I would sanitize it of any personal information.



STEVE:  Yeah.  And we covered this problem with Yahoo a couple years ago. 



LEO:  Yeah.



STEVE:  That whole issue of abandoning an account.  I think what they were doing was, if you had not logged in for some length of time, they would send an email into that account, which of course you wouldn't see because you weren't ever bothering with it.  But then they would unilaterally make that re-available.  They were recycling these long-dormant email accounts.  And they got a big slap on their hand for that because so many people were using their Yahoo Mail as recovery for other things.  So that was my point about how unfortunately our experiences online are interlinked.



So you might use, you might have registered once your Yahoo Mail as your backup email for recovery of something that you do care about.  And if a bad guy then got a hold of your Yahoo Mail, they could, I mean, exactly as designed, use their control of your backup password recovery mechanism on an unrelated service to gain access to that service.  So, yeah.  Anyway, so I remember when we discussed it before the notion was, well, how do we remember to log in every quarter just to say, "Hi, Yahoo.  Don't expire this account.  Unfortunately, I used it once, and I don't ever want anybody else to have it."  You know, wow.  And it's very much like the problem of a domain name that gets lost, and then squatters sit on it because there's going to be some traffic that's going to wander in and get exposed to what's there.



Okay.  South Carolina legislation has been proposed by Bill Chumley, State Representative Bill Chumley.  He has filed a bill to require computer sellers to install digital blocking capabilities on computers and other devices that access the Internet to prevent the viewing of what the bill says "obscene content."



LEO:  What?



STEVE:  Yes.  Yes.  The proposal - oh, it gets better.  The proposal would also prohibit access to any online hub that facilitates prostitution and would require manufacturers or sellers to block any websites that facilitate trafficking.  So he's saying, if you're going to sell computers into South Carolina, our citizens must be protected.  But, now, here's where it starts to get sort of strange.  Both sellers and buyers can get around the limitation, for a fee.  The bill would fine manufacturers that sell a device without the blocking system, but they could opt out by paying $20 per device sold.



LEO:  What?



STEVE:  And even - I know.  Even more oddly, buyers...



LEO:  Who gets the 20 bucks?



STEVE:  Well, uh-huh, that's exactly the right question.  Which is why I think this whole thing seems a little fishy.  We're about to get there.  Buyers could also verify - buyers could verify their age and pay $20 to remove the filter.  It's like, okay, what?  The money collected would go toward the Attorney General's Office Human Trafficking Taskforce.



LEO:  This is just goofy.  Whoever this guy is, it's not - if it passed, then we should talk about it.  But this guy is a crackpot.



STEVE:  Chumley's bill has been referred to the House Judiciary Committee.



LEO:  Yeah, where they're going to bury it.



STEVE:  And so my comment was the weird "adults may pay $20 and have the filter removed" gives the legislation more the character of a fundraising extortion racket for the Human Trafficking Taskforce.  Which, I mean, that's a great taskforce, but still it's like, you know, what?  Yeah.  So anyway, I just - this just popped on the radar, and I thought, okay, this is too crazy.



LEO:  This is a mish-mosh.



STEVE:  And as you said, Leo, until a gavel drops, it's just, you know, we've seen lots of legislation come and go that never got any...



LEO:  It's grandstanding.  But to be fair, there is, you know, they have filters in the U.K.  I think they have filters in Australia that are mandated.



STEVE:  Well, that's our next story, actually.



LEO:  Okay.  Go right ahead.  I didn't mean to slow you down.



STEVE:  Meanwhile, an Australian court ruled on Thursday, December 15th, last week, that the Pirate Bay and a collection of other sites must be blocked by Internet service providers.  And I have, in the link in the show notes - oh, I should mention show notes are already online for anyone who wants to follow any links there.  So I'm now working to have them always on the Security Now! page, GRC.com/sn.  The first item there is this week's podcast.  And I will continue to try to get them up immediately.



So the measures have not been implemented yet, but this just happened on the 15th.  ISPs have 15 days, that is, by year's end, by New Year's, Internet users will be blocked by default by ISPs.  Now, what's interesting is that Google's data shows a large surge in searches for the acronym or the abbreviation "VPN," and VPN services have reported a significant increase in interest from Australia.  Justice John Nicholas of the Australian Federal Court has ordered Australian ISPs to block The Pirate Bay, Torrentz, TorrentHound, IsoHunt, and SolarMovie, and many proxy and mirror services of those that, as the coverage says, marks the start of a mass Internet censorship Down Under.



And we're not surprised to find that this is the result of a case brought by Roadshow Films, Foxtel, Disney, Paramount, Columbia, and 20th Century Fox.  So stakeholders in copyrighted material are saying we want access shut down to these sites that exist purely for the sake of piracy.  And more than 50 ISPs are now required to start barring subscriber access to these sites.  And there's also, I did not go into the details of the legislation, but it's been in the works for quite a while.  And since it began, Torrentz, TorrentHound, and SolarMovie have already shut themselves down.  But the judgment continues to name them in case they might return.



And the ISPs are given some latitude about how to actually perform the blocking.  They could use DNS, so like intercept and remove those from DNS services available in Australia, so you just can't get the IP addresses; or block the physical IP addresses as they try to exit from Australia; or also filter and block on the URLs; or any alternative means which are approved by this coalition of copyright holders.



And this is a little worrisome now, too, because this legislation essentially puts this group of copyright holders into the loop, like permanently in the loop for, like, can we block them this way?  Is this okay?  And there's apparently a $50 charge to the copyright holders per blocked site.  So it's not free for them to keep adding them, but there is a mechanism also for them to routinely go back and say, okay, and now we want you to block this, this, this, this, this and this and this.  So, wow.  It just seems like a very slippery slope.



LEO:  And a template for what's going to happen here in the next year, I would predict.



STEVE:  You really think so.



LEO:  Yeah.



STEVE:  Yeah, wow.



LEO:  Well, I'm sure the Motion Picture Association...



STEVE:  Will be pushing.



LEO:  ...will be pushing hard, yeah.



STEVE:  Yeah, who was it, it was a leading Democrat who went to work for the MPAA.  I can't remember his name now.  I was disappointed.



LEO:  I know what you're talking about, yeah.



STEVE:  Yeah.



LEO:  It's sad, I mean, so we have a mess.  It's a revolving door.



STEVE:  Well, and again, here again is real world meets Internet.  And unfortunately this is an attempt to apply controls that the Internet was not designed to provide.  We were, in the early days of innocence, we were all celebrating freedom of expression and the openness and how it was uncensorable and all that.  And it's like, well, it isn't designed with any of those things in it.  But you can do things like filter.  And the problem of course is VPNs.  If you're allowed to run a VPN tunnel outside of Australia, then that bypasses any border protection.  Just, bang.  So no wonder searches for VPNs are on the upswing.



LEO:  By the way, it's Chris Dodd, the chatroom says.



STEVE:  Chris Dodd, yup, that's exactly who I was trying to think of.



LEO:  You know, the thing that really worries me is you get then this escalating battle between the people who want a filtered government at the behest of the copyright holders, and users.  And it really is bad in general.  Then VPNs get blocked; right?  And then, I mean, ultimately it ends up being not just bad for people who want to steal movies.  It's terrible for everybody.



STEVE:  Well, and as we've talked about, there are also - there's a real problem with false positives.



LEO:  Right.



STEVE:  I often hang out next to a Verizon that has free open WiFi.  And it's great WiFi, so it's there, and I'm not doing anything I'm trying to hide.  So I'll use their WiFi.  And sometimes, because I'm also researching medical stuff, I'll get a block page.  And it's like, what?  Because, of course, there's some overlap.  Maybe the page mentions testosterone or something, who knows what.  But, I mean, for whatever reason, this is like, you know, it's PubMed.  It's our government's medical research archive.  And Verizon's nanny gate isn't letting me see a page because it's like, oh, no, no, can't get there.  It's like, okay.



So unfortunately, as we know, it's an imprecise technology.  And even the definition, you know, who was the judge who famously said, "Well, I can't define pornography, but I know it when I see it."  It's like, okay, well, how do you write a law around that?  Yeah.



LEO:  It's not, you know, what it is, what the problem is, is that I'm not for stealing things.  And that's one of the things laws and government do is they punish thieves.  And that's an appropriate thing.  I don't want somebody to come into my house and steal my stuff, either.  But the problem is the people who are making these laws are generally, in fact, entirely ignorant of how the technology works, the technological issues, and the long-term consequences of the things they ask for.  And that's what worries me more is the ignorance among lawmakers.



STEVE:  That and we have a history now of the copyright holders being very overreaching.  As we've often quoted on this podcast, they tried to prevent home videotape recording under the argument that it was purely for piracy; that the only reason anybody would want that was piracy.  Fortunately, that didn't happen, and we're able to record content for our own consumption at home, but against the desires of the media providers.  And of course we went through the same thing with the DVD, that was all ridiculously encrypted, which lasted all of a week or two because you can't do that.  There's just no way to do that securely.  But again, a huge amount of effort was put in.  And it just ended up inconveniencing everyone and producing no effective result. 



LEO:  I said 10 years ago that ultimate freedom fighters would end up being hackers, people who know how to use technology and can protect our freedom online.  So everybody needs to start learning this stuff now.  If you want to preserve freedom, learn technology.



STEVE:  Yeah.



LEO:  Otherwise it's used against you.



STEVE:  So we've often spoken of the difference between something you know and something you have relative to recent court decisions.  And I heard you talking about this on MacBreak Weekly just now, Leo, and our listeners need to hear it, too, because a recent decision was reversed on appeal in Florida which changes, I mean, depending upon how this goes, like what future this has, this argues that, unlike what had been believed up until now, that a suspect who is blocking the acquisition of evidence by not divulging something they know, their passcode, up until now, as we've discussed often, that was regarded as testimonial.  And so the Fifth Amendment to the Constitution, which protects against self-incrimination, was protection.  That is, you could not compel testimony against oneself, thanks to this Fifth Amendment.



So last Tuesday a Florida appeals court ruled, in a case of a man suspected of voyeurism, that police may lawfully compel the disclosure of a mobile device's passcode for the purpose of searching it for incriminating evidence.  Okay, so a little bit of context here.  The guy's a creep.  No one's on his side.  His  name is Aaron Stahl.  He was arrested after a woman who was shopping in a store saw him crouch down and extend an illuminated cell phone under her skirt, according to court records.  When she confronted him, Stahl told her that he had dropped his phone.  He ran out of the store when she yelled for help, but police were able to identify him using his car's license plate number as he made his getaway.  He was later arrested for something known as third-degree voyeurism.  Sounds like first-degree to me, but...



LEO:  What would first-degree be?



STEVE:  I don't know what the degrees are.  Sure does seem premeditated, if nothing else.  In a police interview Stahl initially gave verbal consent to a search of his cell phone - so they said, "Will you let us search your cell phone?"  He said, "Yeah, okay" - which was an Apple iPhone 5, but subsequently withdrew his consent before telling the police his four-digit passcode.  Once police obtained a warrant for the phone, they were unable to access the photos on the phone.  Okay, again, no one's on this creep's side.  We're on the side of civil liberties and the question of does the Fifth Amendment still apply.  So there's what I described in my notes as "tortured logic."  There's some rather tortured logic at this.



So at trial the judge denied the state's motion to compel Stahl to give up his passcode, finding that it would be tantamount to forcing him to testify against himself, in violation of the Fifth Amendment.  But subsequently the Florida Court of Appeals Second District reversed that decision, actually it was last Wednesday, finding that the passcode is not - this is what's strange, the wording of this, but I was careful to get it:  "The passcode is not related to any criminal photos or videos found on the phone."  Okay, meaning that so somehow the fact that you need the passcode to divulge them, a three-judge panel disconnected those.  So Judge Anthony Black, writing for this three-judge panel, said:  "Providing the passcode does not 'betray any knowledge Stahl may have about the circumstances of the offenses.'"



LEO:  This is about the right to not self-incriminate.  So they're saying giving the passcode is not self-incriminating.



STEVE:  Right, right, exactly.  It's not like divulging the photos themselves.



LEO:  Right.  That would be incriminating yourself.  Give us the photos.  You have the right to say no.



STEVE:  So they have a search warrant they cannot execute because he's blocking it.



LEO:  Right.



STEVE:  So the text goes on to say:  "Thus, compelling a subject to make a nonfactual statement that facilitates the production of evidence for which the state has otherwise obtained a warrant based upon evidence independent of the accused's statements linking the accused to the crime does not offend the privilege."  In other words, they assert that a passcode is not testimonial; it's surrender.  So you're compelling a person to surrender something, not to testify.  And of course, as we know, it was the Supreme Court decision back in '88, Doe v. the U.S., where Justice John Paul Stevens wrote something that we've often repeated, and you mentioned in the previous podcast, Leo, that a person may be "forced to surrender a key to a strongbox containing incriminating documents, but cannot be compelled to reveal the combination to his wall safe."



So what we have now is an appellate court essentially reversing that standing U.S. Supreme Court decision.  Okay.  So I guess maybe this will go back up to a higher court.  Maybe they'll just - I don't know what the mechanism is.  If the U.S. Supreme Court says we've already ruled on this, does the appellate court decision stand?  I don't know.  Anyway, we'll keep an eye on it because this has been an interesting point for people to say, oh, no, you don't want to use your thumbprint.  You want to use a passcode because that's something you know, not something that you can be compelled to produce.  And you can be held down and forced to put your thumb on the phone.  No one can make you tell something you know; but you can be held in contempt of court, I'm sure you would be, and then jailed until you surrender the information.



LEO:  Yeah, and as we pointed out, I mean, the issue isn't so much the passcode is that you don't want to let the government pluck things from your brain because that kind of encourages torture, or compelled or forced confessions.  And so that's - I'm no lawyer, but I would guess that that's the reason for the Fifth Amendment.  And that's what the Supreme Court would have to decide.  I don't think it's obvious what the right answer is, by the way.  I can understand the case on the other side, as well.



STEVE:  Yeah, yeah.



LEO:  Very interesting.



STEVE:  We do have some good news, thanks to our friends at the EFF.  The U.S. Supreme Court has agreed to hear a case that could end the famous Texas grip on patent cases.  "In the case TC Heartland v. Kraft Foods, that case effectively asks the court to decide whether patent owners" - which as we know are unfortunately all too often not patent users.  They are trolls, patent trolls that collect patents purely for prosecutorial purpose, in order to squeeze money out of people, much like the podcast patent that was hanging over TWiT's head for a while.



LEO:  And would have gone to Tyler, Texas.



STEVE:  Yup, "to decide whether patent owners can sue in practically any corner of the country."  The EFF supported the position and side of TC Heartland, who was the petitioner, at the Court of Appeals for the Federal Circuit and as well in asking the Supreme Court to hear the case.  "The petition to the Supreme Court became necessary after the Federal Circuit issued a disappointing decision that maintained the status quo."  So it's like, okay, we need to escalate this.  And the good news is the Supreme Court has said, we agree.  Bring it in front of us.



The current law, as it is now and was unfortunately just recently re-upheld, "allows patent owners to pick and choose between federal courts, often opting for courts that are perceived to have rules and procedures favorable to their position.  The result," writes the EFF, "has been astounding.  Last year almost half, 45% of all cases were filed in a single Eastern District of Texas, a rural part of the country that has no major technology industry."  Just a well-fed judge.



LEO:  Well, it's not even that because what you want is a jury that is well disposed to protect the little guy, which is how these non-practicing entities position themselves.  I invented something, and now the big company came along and took it from me.  So you don't want people who work for big companies.



STEVE:  Right.  And we've talked about this in the past.  There's a stadium in that town that Samsung fully supports.  They've got, like, Samsung banners and flyers, and they...



LEO:  They're trying to win hearts and minds.



STEVE:  Exactly.  They're saying, "We're good.  Please think of us in a good light," because they recognize they're vulnerable.  They've just been raked over the coals by this ridiculous county.



LEO:  So I can now talk about this because during this - we did, of course, get approached by the podcast troll.  And that patent was invalidated by the Patent Office, so the whole issue is over, thank goodness.  And they did go after, as you know, Carolla, and Adam Carolla fought it.  Good for him.  We would have fought it, as well.  I would not - they asked for $2.5 million, I think, something like that.  And we just laughed.  And we would have fought it, but they didn't end up coming around to suing us.  But what we did do is engage an attorney who practiced in East Texas, who had done patent cases in Tyler, Texas, who knew the judge.  Because there is one judge who's the one everybody wants, and this is where it would have been - this is the jurisdiction it would have been tried in.



STEVE:  He's busy.



LEO:  He's very busy.  But again, it's kind of - it's positioned as, no, we're trying to defend the rights of the little guy, you know, the guy who invented intermittent windshield wipers, against the big bad corporation stealing his idea.  And that's something juries really eat up.  So our strategy - we had several meetings with our attorneys.  And our strategy would have been to go down there, have a barbecue, have all the churches that have podcasts, have all the little podcasts from that area come and meet people, and bring our viewers down because the idea would be to say, "We're not the big guy.  We're like you.  And podcasting is how normal people get a voice in the world."  And I think that would have been actually a good strategy, but we never got to exercise it.



STEVE:  Well, and there's so much wrong with the system because, for example, none of the money spent is recoverable.



LEO:  Right.



STEVE:  It's all just gone.



LEO:  Right.  Well, it goes to the attorneys, but that's the point.



STEVE:  Yeah, exactly.



LEO:  It doesn't go to the - usually the patent, the guy who came up with the patent has sold out long ago to these non-practicing entities.



STEVE:  Right, right, right.  So anyway, the EFF concludes, saying:  "We're glad to see that the Supreme Court has agreed to hear this important case that could significantly curtail some of the worst actors in the patent game.  EFF will be there to urge the Court to restore balance and fairness in patent litigation."  And I say again, for the umpteenth time, yay to the EFF.  Thank you.  Thank you.



LEO:  Well, it was the EFF got that podcast patent overturned.  We were thinking of, and we had decided not to do this because it's risky, they had decided to pursue what's called an inter partes appeal to the Patent Office.  And the reason it's risky is if the Patent Office rules...



STEVE:  Affirms.



LEO:  Affirms the patent, of course that goes right in front of the jury.  Look at this.  These guys tried to get the patent overturned, and the Patent Office came back again and said it's a good patent.  So we didn't want to do it.  But the EFF decided it was a good thing.  They had prior art and so forth.  And so they felt like they had a good shot at it.  I donated money, a lot of people donated money to the EFF to pursue this, and they won.  And that really eliminated the whole thing and got the patent overturned, and they won.  But it's why I also continue to donate every month to the EFF, and I think everybody should.  It's a great organization.



STEVE:  And I think I've mentioned before that the last time I ever agreed to serve as an expert witness was in a suit between Princeton Graphics Systems and NEC over the MultiSync, which Princeton Graphics alleged was infringing on their patent, and NEC was fraudulently making claims that were unsubstantiated.  And so I thought, this sounds interesting.  And so I said yeah.  And I agreed with NEC's position, so I let them hire me and explain to the judge, as I do, so clearly, so carefully, so that  the fly on the wall understood what was going on here with its two neurons.  They had been synchronized.  And the decision came down the wrong way.  And I thought, okay, you know, I'm not here to earn money.



LEO:  Never again.



STEVE:  I'm here to help the good guys, and it didn't work.  So I thought, screw this.  I'm not doing this anymore.



Okay.  So on the topic of everything is porous, Linux is in the crosshairs.  A neat security researcher, Chris Evans, whom we've spoken of before, I'm not sure if he's employed by Google or affiliated.  He does on his site refer to his buddy Tavis Ormandy, and of course we know Tavis well, of Google.  Chris has been playing recently with the GStreamer - okay.  Are you sitting down, Leo?



LEO:  Yes.



STEVE:  Media library.  And we know what a problem Android had with its media library.  Turns out GStreamer is the de facto media processing pipeline which is open source, multiplatform, present in most Linux distros by default, and makes Stagefright look like a good thing.  So this is just the beginning of taking a look at it.



So about a little over a month ago, November 15th, Chris posted - he has a blob.  Blob.  I did write "blob."  [Indiscernible] my own notes.  A blog called "Scarybeasts."  It's scarybeastsecurity.blogspot.com.  And so his posting on middle of November was - and he had the tags "0day" and proof-of-concept, "PoC."  He said:  "Risky design decisions in Google Chrome and Fedora desktop enable drive-by downloads."  Meaning you just visit a web page, and in the background, if you visit it with Chrome, Google's Chrome browser, on Fedora, it downloads files, and I think it runs them.



So his overview says:  "A confluence of risky design choices, combined with various implementation issues, makes drive-by downloads possible with Google Chrome on Fedora.  First, Chrome will automatically download files to a user's desktop with no confirmation."  Oops.  "Fedora's tracker software will auto crawl downloaded files to index them, including media files.  Three, the GStreamer framework, as used to handle media in the Fedora desktop, has questionable," he writes - and then in the next two blog postings we're going to learn just how much that is true - "implementation quality from a security perspective.  Four, the tracker component responsible for parsing media files does not appear to be sandboxed," as in, for example, with security-enhanced Linux, SELinux.



And, finally:  "The Fedora default desktop install includes a range of fairly obscure media decoders that confer risk, but are not necessary for a thorough desktop experience."  Which is Chris's polite way of saying there's a bunch of crap in there, installed by default, that few if any people will need, but which expands the attack surface needlessly and dramatically.  So basically - and he goes into great detail afterwards.  But that's the gist of this.  So a drive-by file download vulnerability.  And it's not sandboxed.  And apparently this tracker indexing then allows you to leverage problems with GStreamer in order to essentially execute content on the system in the security context of GStreamer and/or tracker.  Not good.



A week later, Chris is back, on the 21st of November.  This one's tagged "0day" and "exploit."  And he says:  "Advanced exploitation:  A scriptless zero-day exploit against Linux desktops."  And then in his overview he says:  "A powerful heap corruption vulnerability exists in the GStreamer decoder for the FLIC file format.  Presented here," he writes, "is a zero-day exploit for this vulnerability.  This FLIC decoder is generally present in the default install of modern Linux desktops, including Ubuntu 16.04 and Fedora 24.  GStreamer classifies its decoders as good, bad, or ugly.  Despite being quite buggy and not being a format at all necessary for a modern desktop, the FLIC decoder is classified as 'good,' almost guaranteeing its presence in default Linux installs.  Thanks to solid ASLR/DEP" - that's, as we know, Address Space Layout Randomization and Data Execution Prevention - "protections on some modern 64-bit Linux installs and some other challenges, this vulnerability," he writes, "is a real beast to exploit."



But that doesn't stop Chris.  "Most modern exploits defeat protections," he's writing, "such as ASLR and DEP by using some form of scripting to manipulate the environment and make dynamic decisions and calculations to move the exploit forward.  In a browser, that script is JavaScript," he says, "or ActionScript" in the case of Flash.  "When attacking a kernel from user space, the 'script' is the user space program.  When attacking a TCP stack remotely, the 'script' is the program running on the attacker's computer."  That is, remotely over TCP.  He says:  "In my previous full GStreamer exploit" - and this was something I didn't cover because it wasn't quite as on point - "against the NSF decoder, the script was an embedded 6502 machine code program."



LEO:  What?



STEVE:  Well, it's because that was the chip in the Nintendo something or other.  And so they were emulating, in order to run Nintendo stuff, they were emulating the 6502 famous processor technology chip.  And so he was able to abuse essentially the 6502 interpreter in order to leverage an attack.  And he says:  "But in order to attack the FLIC decoder, there simply isn't any scripting opportunity.  The attacker gets, once, to submit a bunch of scriptless bytes into the decoder, and try to gain code execution without further interaction."



And he writes:  "And good luck with that.  Welcome to the world of scriptless exploitation in an ASLR environment.  Let's give it our best shot."  Which is the beginning of a post where he shows how he did it.  And, you know, this is somebody you want on your side.  This guy has - and he looks like he's about, now, I don't mean this in any negative way, Chris, but it looks like he's about 12.  So it's like, if he's not already working for Google, everybody should go try to hire this guy because he's got some serious skills.



So what all that means essentially is that he figured out how to feed the FLIC decoder interpreter essentially a program which was complex and would do what he needed it to do by writing code in this metafile that the FLIC interpreter is going to interpret in order to get it to do this work.  And it's like, okay.  Wow.  I mean, so here's a classic example of, if you want something bad enough, our current systems are replete with opportunity.  Most people can't do that.  Somebody good enough, I mean, there's other lower hanging fruit, probably.  Chris is bored by low-hanging fruit.  He wants to get a trampoline with stilts in order to reach up high enough in order to pluck this thing.  But major skills.



And, finally, this brings us to last Tuesday, a week ago, when he posted most recently - apparently he'd been working on this Super Nintendo thing for a while.  And all I did is just have his little quick TL;DR, which is a "full reliable 0day drive-by exploit against Fedora 25 and Google Chrome by breaking out of Super Nintendo Entertainment System emulation via cascading side effects from a subtle and interesting emulation error."  Then he says, "Very full details follow."



So again, I have links to all of Chris's blog postings.  If anyone is interested in the mechanics of this kind of serious, roll-up-your-sleeves reverse-engineering, this is the guy to go read.  And you might want to just follow his blog because he posts every, you know, his latest exploits and exploitations at scarybeastsecurity.blogspot.com.



LEO:  Now, they said in the chatroom that these exploits were patched before they became public.  Or is that not the case?



STEVE:  You know, I didn't follow up and find out.  I would be surprised if not because Chris is nothing if not responsible.  So I'm sure that's - but again, these were there until Chris found them.



LEO:  Right.  But this is why open source works.  I just want to point out, you know, people going, oh, this is a terrible thing, well, but this is why it works.  If it gets patched right, then this is all good; right?



STEVE:  Yeah, doesn't do any better than closed source.  It's all the same, Leo.



LEO:  Well, I guess.



STEVE:  This is all, you know...



LEO:  You can at least look at the code and look for the flaws in the code.



STEVE:  But it also allows you to look for exploits in the code.  So, I mean, it's a double-edged sword.



LEO:  Yeah, I guess, yeah.



STEVE:  Yeah, no, I mean, and that's what people do.  They go over the code to find it.  And so, for example, when Microsoft releases updates, people have to reverse-engineer the patch in order to figure it out.  There's no reverse-engineering needed here.  You just look at the open source.  I mean, I think...



LEO:  By the way, GStreamer, I think, is not open source, come to think of it.  I think it's proprietary.  No?  Is it non-free?



STEVE:  I looked on Wikipedia.  It's got a full Wikipedia page.  I think it's completely open, but I'm not sure.



LEO:  Oh, okay.



STEVE:  I know it's multiplatform.  And I did mention four vulnerabilities.  Those were three.  And this is just quick.  There's another researcher, who knows Chris, recently posted his.  And I guess Chris is probably a Fedora user, so that's why his exploits tend to be Fedora-based or aiming, not that other distros wouldn't have the same problem.  He says his was reliably compromising Ubuntu desktops by attacking the crash reporter.



And he just writes:  "In this post I'll describe how I found a remote code execution bug in Ubuntu Desktop which affects all default installations from Quantal on.  The bug allows for reliable code injection when a user simply opens a malicious file."  Okay, so the user has to take action.  "The following video demonstrates the exploit opening the Gnome calculator.  The executed payload also replaces the exploit file with a decoy zip to cover its tracks.  Full source code for this exploit is available on GitHub."



And he says:  "This research was inspired by Chris Evan's great work on exploiting client-side file format parsing bugs in the GStreamer media library on Ubuntu.  We will look for other default file handlers on Ubuntu which may be vulnerable to exploitation.  I'm not," he writes, "a binary exploitation guru like Chris, so instead we'll try to find bugs which are exploitable without memory corruption."



So again, our systems are complex.  We want them to do everything.  And there is legacy code that predates - in many cases there's legacy code that predates a manic concern over security.  But even since then mistakes get made.  So the new cycle here is, as we've been discussing recently, is that problems are found; they're responsibly disclosed; they're fixed in a timely fashion; and, hopefully, as we move forward with a heightened appreciation for security, we'll be making fewer mistakes than we fix.  So the count of unknown vulnerabilities drops over time.



And ultimately I think we just need to scrap this entire model.  Everything we're doing is like the way firewalls used to be of permit all and block known problems.  It was easy to flip the firewall model around.  We're basically still using an architecture from the first computers with relays and tubes.  Nothing has changed.  Our systems are fundamentally exploitable because of the way they're designed.



And I think we're getting to the point now where we have enough excess power, you know, this all comes from the fact that computers have never been able to be as fast as we needed them to be, so we just did the fastest possible solution.  Having them operate in a way which is fundamentally secure rather than fundamentally insecure, they will not be nearly as efficient; but they will be potentially bug-free, that is, in terms of this kind of exploit.  I know there's research in labs going on now saying we just have to scrap everything we have.  It's gotten us to this point, but it's just really becoming a problem.



So, and we learned also, just to sort of share the wealth, that last week's patch of Apple's Mac OS X closed a problem that we've discussed for years, in this case with the fact that Thunderbolt gave external peripherals that were attached to the Macs DMA access.  After the patch was in place last Thursday, the guy who figured this out told us what he had found.  He wrote:  "MacOS FileVault 2 let attackers with physical access retrieve the password in cleartext by plugging a" - and in this case he quotes a $300, but it certainly didn't, I mean, just because it was available for $300 - "$300 Thunderbolt device into a locked or sleeping Mac.  The password may be used to then unlock the Mac to access everything on it.  To secure your Mac," he writes, "just update it with the December 2016 patches.  Until then anyone, including but not limited to your colleagues, the police, the evil maid, and the thief will have full access to your data as long as they can gain physical access, unless the Mac is completely shut down.  If it's sleeping, it is still vulnerable."



So he poses the question in his coverage, how is this possible?  He writes:  "At the very core of this issue there are two separate issues.  The first is that the Mac does not protect itself against Direct Memory Access attacks before macOS is started.  The EFI BIOS which is running at this early stage enables Thunderbolt, allowing malicious devices to read and write memory directly.  At this stage macOS is not yet started, but it resides on the encrypted disk, which must be unlocked before it can be started.  Once macOS is started it will enable DMA protections by default."



So the point is there is a little window of opportunity after the motherboard BIOS boots, which by default enables the Thunderbolt hardware interface.  And until the macOS has booted, which is then able to apply the DMA memory restrictions that we've talked about in the past as a means of thwarting this kind of DMA access, there's a little window there, a gap.



"The second issue," he writes, "is that the FileVault password [oops] is stored in cleartext in memory and is not automatically scrubbed from memory once the disk is unlocked.  The password is put in multiple memory locations, which all appear to move around between reboots, but remain within a fixed memory range."  Obviously making that range searchable.  "This makes it easy to just plug in the DMA attack hardware and reboot the Mac."  So the reboot doesn't wash away what's in RAM.  So the reboot then allows that window to give the plugged-in device access before macOS starts to restrict its access, but while the previous content of RAM is still present.



So he says:  "Once the Mac is rebooted, the DMA protections that macOS previously enabled are dropped.  The memory contents, including the password, is still there, though.  There is a time window of a few seconds before the memory containing the password is overwritten with new content."



So this was responsibly disclosed.  Back last summer, at the end of July, the issue was discovered.  At DEF CON 24, in early August, on the 5th of August, PCILeech is what the hardware was called, was presented.  But although known, the FileVault issue was not mentioned.  Ten days later, Apple was notified.  The day after that, on August 16th, Apple confirmed the issue and asked to hold off on disclosure.  And then on the 13th, one week ago, Apple released macOS 10.12.2, which contains a security update.  And he verified that it worked on his MacBook Air.



And then his conclusion gives props to Apple.  He wrote:  "The solution Apple decided upon and rolled out is a complete one, at least to the extent that I've been able to confirm.  It is no longer possible to access memory prior to macOS boot.  The Mac is now one of the most secure platforms with regard to this specific attack vector."  So as often, it's secure now.  It wasn't before.  But it got responsibly handled.  Apple got the fix in place for something that could have been done just with a physical hardware device that was able to rapidly scan memory, find the plaintext password that had been left in memory after the machine had been suspended or put to sleep.



We learned also more details about the steganography - there's widespread agreement that I made up the term "steganometry."



LEO:  Oh, too bad, I liked it.



STEVE:  Well, you know, so that means measuring steganography, steganometry.



LEO:  Yeah, there you go.  See?  Yeah.



STEVE:  How big is your steganography?  Well, that would be steganometry.  So we learned more about what's going on, and it's chilling, so I wanted to share it.  A security firm, Proofpoint, has dug way into this.  And in fact there's a graphic on their site, Leo, you might want to bring up just because it's sobering in terms of the sophistication of this attack.  And it's sobering because it demonstrates to what length bad guys are willing to go in order to get what they want.  And so it just sort of says, you know, this is not the script kiddie anymore.  So you're now showing the graphic of the back-and-forth protocol that this attack uses in order to achieve its ends.



LEO:  It's so complex I can't fit it all on the screen.



STEVE:  I know.  "Proofpoint researchers have reported frequently this year," they write, "on the decline in exploit kit activity," or they call it "EKs."  So they say:  "EKs, though, are still vital components of malvertising operations, exposing large numbers of users" - and we're talking millions - "to malware via malicious ads.  Since the end of October," they write, "we have seen an improved version of the DNSChanger exploit kit used in ongoing malvertising campaigns.  DNSChanger attacks Internet routers via potential victims' web browsers."  Okay, so think about that.  DNSChanger attacks Internet routers, meaning local, the users' routers, their LAN routers, their own 'Net routers, via potential victims' web browsers.



"The exploit kit does not rely on browser or device vulnerabilities, but rather vulnerabilities in the victims' home or small office routers.  Most often, DNSChanger works through the Chrome browser" - and of course we now know that's the majority browser on the Internet, so yeah.  If it's not multibrowser, you're going to choose Chrome - "on Windows desktops and Android devices.  However, once routers are compromised, all users" - remember, because this is changing the DNS which all devices on the LAN will then use, which is why this is such a devastating attack - "all users connecting to the router, regardless of their operating system or browser, are then vulnerable to attack and further malvertising.



"The router attacks appear to happen in waves that are likely associated with ongoing malvertising campaigns lasting several days.  Attack pattern and infection chain similarities led us to conclude," they write, "that the actor behind these campaigns was also responsible for the CSRF (Cross-Site Request Forgery) SOHO Pharming operations in the first half of 2015."  They write:  "However, we uncovered several improvements in the implementation of these attacks, including external DNS resolution for internal addresses; steganography to conceal an AES key used to decrypt the list of fingerprints" - these are router fingerprints - "the default credentials and local resolutions; the layout for the commands sent to attack the targeted routers."  And get this:  "The addition of dozens of recent router exploits.  There are now 166 fingerprints [that this thing recognizes], some working for several router models, versus [a year ago] 55 fingerprints."



They say:  "For example, some like the exploit targeting the Comtrend ADSL Router were a few weeks old, [dated] September 13 when the attack began around October 28."  Meaning that there are resources being put into this.  The moment a new local router vulnerability is found - remember, this is not a remote vulnerability.  This is inside your network because you've got routers typically with web interfaces that allow you to log onto them.  This thing figures out what router you've got with 166 different fingerprints and knows the default credentials for logging onto those routers, and then does so.



It says:  "When possible, in 36 cases, the exploit kit modifies the router's network rules to make the admin ports available from external addresses," so it's opening incoming connectivity to your router, they write, "exposing the router to additional attacks like those perpetrated by the Mirai botnets.  And the malvertising chain is now accepting Android devices, as well."



So this is what we're up against.  So innocent people using Chrome on Windows, or of course the default browser, Chrome on Android, just visit a reputable page, and their browser receives malvertising, which is all that's necessary to commandeer the Chrome browser.  And this is using AES encryption with dynamically varying keys.  So the content was encrypted under the key, which is steganographically hidden in the ad's image.  The script that's part of the ad runs in Chrome, parses the least significant bits out of the image to extract the AES key, uses that to decrypt a blob which looks like random noise so it doesn't get caught by any advertising blocking anywhere.



That then decrypts the code necessary to cause the JavaScript running in the browser to be able to then perform a series of local queries to your router, checking its fingerprints to identify it, and then selecting specific router-specific code to access the router, change DNS, so now instead of your ISP's DNS or Open or Google or wherever, like real DNS, you then, without knowing it, your DNS gets changed so that all the devices in your network are now obtaining DNS services from a bad guy.



And as we know, DNS security is lagging behind.  We've spent a lot of time on the podcast talking about how important it is that it be secure.  It's, however, lagging behind.  And that means that anything you do in your network for as long as this change persists will be looking up IP addresses from illegitimate DNS servers, any of which can then be used to point somewhere else.  And of course what that means is your browser actually thinks you are at https://amazon.com, but you're at a site pretending to be that.  And unfortunately, that then allows them to grab the cookies that your browser provides with its very first query to that site, thinking that it's actually at Amazon, but it's not Amazon, picking up your cookies and your authentication at that site.  And it just goes from there.



So, wow.  Again, complexity.  We have built an incredibly complex system where, by leveraging individual features, each individually, which seem benign, when you put them together in a clever fashion, you can pretty much do whatever you want to.  And unfortunately, these guys have watched millions of people being subjected to this, and some subset of them being vulnerable.  So if nothing else, you may think, "I do not need to change the login for my router because I'm sure I'm blocked from the outside.  Only people on the inside can get it."  Don't leave it set to admin and password as your username and password, or admin and admin or whatever it is.  It's worth making sure that something that might operate in your machine is unable to get to your router.  Yikes.



And in something not security related, the National Highway Traffic Safety Administration has published a Notice of Proposed Rulemaking.  It is 392 pages, so I'm not going to go through it.  The table of contents, though, was interesting to browse through.  This proposed rulemaking will be mandating vehicle to vehicle, so it will have a new acronym, V2V, communications systems in all new cars and trucks.  Once the rule is finalized, car makers will have two model years to begin including V2V systems, with a bit of slack to allow the synchronization of product cycles.  V2V-equipped cars will communicate with each other at short ranges, I think I remember seeing up to 300 meters, to prevent the kinds of accidents where current advanced driver assistance systems, most of which depend upon line of sight, are not effective.



V2V and, well, for example, a car might be broadcasting "I'm stalled, I'm stalled, I'm stalled."  And when you get within range of that, that would heighten the awareness or alertness maybe of a human driver or of the auto-driving software which is approaching the stalled vehicle.  V2V and related vehicle infrastructure, there's another one, Vehicle to Infrastructure, that's V2I, and they're referring there to things like stoplights - apparently we're going to be talking to stoplights before long, too - relies on what's known as the Dedicated Short-range Radio Communication (DSRC) wireless protocol to communicate between devices at ranges - oh, yeah, here it is - of up to 984 feet, which is an odd-looking number because it's actually 300 meters.  Vehicles will send out standardized basic safety messages that trigger driver alerts or even emergency avoidance actions to prevent crashes.  And of course, under the topic of what would possibly go wrong, what we're doing is we are escalating the level of technology with the best of intentions.  Merry Christmas.



So Ars, in their coverage, writes:  "Recognizing the immense implications of an insecure protocol, the notice asks industry and the public for input on the proposed security specifications and proposes that 'vehicles contain firewalls'" - of course they don't know what that means - "'between V2V modules and other vehicle modules connected to the data bus to help isolate V2V modules being used as a potential conduit into other vehicle systems.'" Which of course happens all the time, unfortunately.



"Privacy is also given due attention" - how nice - "and the proposed rule would prevent cars from sending out identifiable data like a vehicle's VIN number or a driver's name or address."  Well, again, how thoughtful that your car is not going to be announcing who you are as you're driving along.  So, oh, goodness.  This podcast will never end, Leo.  We will have fodder from now, I mean, we keep doing this.  We have IoT.  Now we're going to have the IoT of vehicles, called V2V.  Notice there's no "S" in V2V, either, just like there's no "S" for security in IoT.  Wow.



And then in something that I thought you would find interesting, Leo, the news is photographers and filmmakers are calling for encryption to be built natively into cameras as a standard feature.



LEO:  I don't get that.  I don't...



STEVE:  Okay.



LEO:  Yeah, explain it.



STEVE:  Here it comes.  Over 150 filmmakers and photojournalists are calling on major camera manufacturers to build encryption into their cameras.  Last Wednesday, Trevor Timm, the executive director of the Freedom of the Press Foundation, wrote:  "Today, Freedom of the Press Foundation is publishing an open letter to the world's leading camera manufacturers - including Nikon, Sony, Canon, Olympus, and Fuji - urging them to build encryption into their still photo and video cameras to help protect the filmmakers and photojournalists who use them."



The letter has been signed - and by the way, Leo, you ought to pull up the letter.  It's the second link here on the page.  It's a DocumentCloud.org letter that shows the signatories to this.  "The letter is signed by over 150 documentary filmmakers and photojournalists from around the world, including 15 Academy Award nominees and winners [including] Laura Poitras, Alex Gibney, Joshua Oppenheimer, and many more.



"Documentary filmmakers," they write, "and photojournalists work in some of the most dangerous parts of the world, often risking their lives to get footage of newsworthy events to the public.  They face a variety of threats from border security guards, local police, intelligence agents, terrorists, and criminals when attempting to safely return their footage so it can be edited and published.  These threats are particularly heightened any time a bad actor can seize or steal their camera."



LEO:  Like Nicolas Cage?  He's a terrible actor.  Oh, no.  Oh, I know what you mean.  Bad guys.  Well, no, bad actors might want to see some footage, too.  I don't know.



STEVE:  Bad actors may want to lose the key.  "They are left unprotected by the lack of security features that would shield their footage from prying eyes.  The magnitude of this problem is hard to overstate:  Filmmakers and photojournalists have their cameras and footage seized at a rate that is," they write, "literally too high to count."  Although we do have high numbers.  Anyway...



LEO:  Sounds like it's infinity.



STEVE:  You know, crypto.  Those are big numbers.  We recite those routinely.  "The Committee to Protect Journalists, a leading organization that documents many such incidents, told us:  'Confiscating the cameras of photojournalists is a blatant attempt to silence and intimidate them, yet such attacks are so common that we could not realistically track all of the incidents.  The unfortunate truth is that photojournalists are regularly targeted and threatened as they seek to document and bear witness, but there is little they can do to protect their equipment and their photos.'



"Camera manufacturers are behind the times compared to other technology companies.  All iPhones and many Android phones come with encryption built into their devices.  Communications services like Apple's iMessage and FaceTime, plus Facebook's WhatsApp, encrypt texts messages and calls by default.  And many major operating systems on PCs and Macs give users the ability to encrypt the hard drives on their computers.  Yet footage stored on the professional cameras most commonly used today are still left dangerously vulnerable.  Finding the right way to provide encryption in their products will take some research and development from these camera manufacturers, and we welcome having a conversation with Nikon, Sony, Canon and others about how to best move forward on this important initiative.  However, we are hopeful they will publicly respond with a commitment to building encryption into their products to protect many of their most vulnerable customers."



And of course we can see where this is going to go.  The instant one of them does, they all must follow because this is obviously an important need and issue for that segment of their cameras' purchasers, and they're going to have to have that bullet point; you know?  Native military-grade encryption, blah blah blah, which will soon become, I expect we will see, a standard feature in high-end professional cameras.  I thought that was really interesting.  Hadn't thought about that.



LEO:  Yeah, I hadn't either, yeah.  Makes sense, though, yeah.



STEVE:  Yeah, totally.



LEO:  Yeah.



STEVE:  So there is a service that I would argue our listeners, if you need it, it's nice on its face.  But unfortunately, to make it maximally available, they have sacrificed some security in some worrisome fashion.  What this is, it's a web-based frontend to the Let's Encrypt service.  It's called SSLforFree.com.  Amazing that domain wasn't used before now, S-S-L-F-O-R-F-R-E-E dot com, SSLforFree.  So under their "How It Works" they say:  "We generate certificates using [the Let's Encrypt] ACME, A-C-M-E, server by using domain validation.  Private keys are generated in your browser" - okay, there's problem number one - "and never transmitted."



Well, it's good they're never transmitted.  Browsers are just not a place you want a private key for your web server to ever be resident.  But they say:  "For modern browsers we generate a private key in your browser using the Web Cryptography API, and the private key is never transmitted.  The private key also gets deleted from your browser after the certificate is generated."  Well, how nice.



But then they say:  "If your browser does not support the Web Cryptography API, then the keys will be generated" - they're talking about the private key for your web server - "will be generated on our server using the latest version" - okay, good - "of OpenSSL and outputted over SSL" - good - "and never stored."  Good.  But you don't ever want your server's private key to ever go anywhere, really preferably never outside of your server.  And that's the way it's being done now.  Your private key never leaves the server that generated it.  Now they're saying, oh, yeah, maybe your browser can generate the private key.  If not, we'll happily do it for you and then send it to you [audio dropout] with the Let's Encrypt ACME server.  Yikes.



Then they end, saying:  "For the best security you are recommended to use a supported browser for your client.  You can also provide your own CSR" - that's the Certificate Signing Request - "when using manual verification, in which case the private key is handled completely on your end."  Okay, so, okay.  So from all of this, if there's anyone out there who wants a Let's Encrypt key, or a Let's Encrypt cert, then you should definitely generate the private key the old-fashioned way.



If you've got a web server that supports HTTPS connections, it has the ability, I mean, it's probably got OpenSSL, or it's a Windows machine.  So it's got the crypto API in it.  They all can generate the private key for you.  Do it on that server.  And what that generates is a certificate signing request.  Then you could use that safely because it does not have your private key in it.  You are asking them to sign the matching public key.  So that you put into SSL for free.  They do the interaction with the Let's Encrypt server and give you back a certificate that is the signed public key for your server's private key that never left the boundary of your server.



So, I mean, it's nice that these guys are, like, bending over backward to solve the problem.  But they're doing so in a frightening fashion.  We know SSL.  We wish it were secure.  It's not.  You're using web HTTP connections to move this stuff back and forth.  We just talked about DNS changer, so you don't even know if you're actually connecting to them or to someone spoofing them.  So again, there are too many holes in this Swiss cheese that we are currently operating in for that to be secure.



There's an interesting site I have in the show notes that I didn't want to skip.  He calls it - it's RobinLinus.com.  And the service is Webkay, W-E-B-K-A-Y.  So if you go to, and it's a little unnerving, webkay.robinlinus.com, what you are presented with is a page of what your browser knows about you.  Now, we've sort of seen these things before, but maybe not for a year, where we were looking at, like, all of the junk in the query headers and stuff.



This shows the geolocation of where you're located, what OS you're using, a bunch of stuff that's familiar.  But it's just sort of - it's a convenient reminder of any site you go to, every place you go, just like this one, the amount of data that your browser and our state-of-the-art technologies, I mean, you'll notice there's battery in there.  He says that my computer is currently charging its battery.  It's like, okay.  But the point is there's an API in the browser that tries to report on the state of your battery.  And as we know, because of the resolution of some of those parameters, that can be used to track you.  So just sort of a worthwhile reminder.



Also, Google Contributor is being terminated.  Apparently it's going to get reborn.



LEO:  Oh.



STEVE:  I know.



LEO:  I was using that.



STEVE:  I am.  In fact, what's so funny, Leo, is yesterday when I was researching this I was looking at a web page covered with Google Contributor blanked out ads.



LEO:  Yeah.



STEVE:  So I thought, well, isn't that ironic.  It was a big banner at the top and a bunch of little squares floating around with sort of those little pastel circle things that...



LEO:  I see kitty cats.



STEVE:  Oh, you do?



LEO:  Yeah.  Well, that's - you can choose what you want to replace ads.



STEVE:  Oh, okay.  Yeah, I went with, I don't know, fuzzy floodlights.



LEO:  Probably smart, yeah.



STEVE:  So email has been sent.  I didn't get mine yet.  Maybe it probably went to my Gmail account, which is my slop account.  Email being received reads:  "Thank you for being part of Google Contributor, a service that helps readers enjoy fewer ads while funding the sites they love.  Early next year we are launching a new and improved Contributor."



LEO:  Oh, good.  Okay.



STEVE:  Yeah.  "Your input throughout the testing has been invaluable."  Okay, I didn't give them any input, but I gave them a lot of money.



LEO:  Yeah.



STEVE:  "As we build this new service, we will discontinue the current version of Contributor.  What this means to you:  Starting in mid-January 2017" - so three weeks from now, four weeks - "you will no longer see Contributor ad replacements as you browse the web."  So they're shutting it down.  "And you will be unable to access your Contributor account."  They're closing that down.  "You will no longer be billed" - well, thank you - "for the [nonfunctioning] Contributor service starting mid-January 2017, and we will refund your remaining account balance to your credit or debit card on file."  That's all they say.



Now, they don't give a commitment to a start date.  They're not telling us when they're going to replace it or when the new service will be coming up.  But there is a link to a Google Docs form which you can fill out, and I did, and I've got the link in the show notes, to register yourself for notification when they relaunch the service.  And, boy, I tell you, I mean, I see so many of those little Contributor boxes when I'm surfing the 'Net, which I'm happy to pay pennies for instead of either blocking the ads or having to put up with ads or the malvertising that they're replacing, that I'm happy to do that.



Also, I did want to mention the pfSense people have a beautiful little cute two-port pfSense hardware security gateway.  It's the SG-1000.



LEO:  They named it after you.



STEVE:  They did.  Wasn't that thoughtful?  I think it actually stands for Security Gateway, but I'm happy to go with Steve Gibson.  It's just, I mean, it's like the size of an Arduino or a Raspberry Pi.  It's just a cute little thing.  It's got a WAN and a LAN port and power.  Just adorable.  And I forgot to say it's $150.  So it is the low end of their range.  Now, what it does not have is more ports.  And that's the nice thing about the $49 switch, which also has a lot of security features, that allows for physical network segmentation.  However, this is full pfSense.  And that's, I mean, that's on top of NanoBSD, with the kitchen sink and five bathtubs in there.  I mean, OpenVPN.  You can run reverse proxies.  You can, I mean, it's got everything.



So what you could do, because it also supports VLAN, is if you put a VLAN-aware switch downstream, that is, connect its VLAN port to a VLAN-aware switch - and those are cheap, those are 20, $30 - then the switch would enforce network segmentation with its multiple ports so that this cute little fire engine red security appliance does not need more than just its two ports.  So I wanted to put it on everybody's radar, I mean, because it doesn't get any nicer than pfSense from a standpoint of a massively feature-rich solution.



And we have some errata.  I misspoke last week because, in my defense, my brain cannot believe, it cannot process the reality of the truth of this.  I said that IPv6 subscribers get 64K IPs.  Wow, 64,000.  Actually, we know it's 65,536 IPs.  It's essentially a, what would that be, a 16-bit network block.  Unh-unh.  No.  They get 64, not "K" IPs, 64 bits of IPs.  Now, okay.  Remember that 32 bits is the entire Internet currently.  The entire IPv4 Internet is 32.  And remember, 64 is double the bits; but it's not double the Internet, it's the Internet-squared.  It's every single IP on the Internet is an Internet itself.



So I don't even know how to pronounce this number:  18,446,744,073,709,551,616.  That's how many IPs we each get.  You, Leo, get that many.  I get that many.  Actually, that's not even true.  The recommendation is that, rather than a /64, maybe give them even more, shorten the so-called prefix.



Okay.  So here's what's going on.  The IP space in IPv6 is 128 bits.  And they decided, we've got so many bits now, we're just going to slice it in half.



LEO:  Wow.



STEVE:  There's going to be 64 bits on the left, and 64 bits on the right.



LEO:  It's 18 quintillion, 446 quadrillion, 744 trillion, 73 billion, 709 million, 551 thousand, 616.



STEVE:  Light bulbs.  That's how many light bulbs you can have.



LEO:  I'm ready.  My Internet of Things is going crazy.  18.5 quintillion.



STEVE:  Ooh, light bulbs.



LEO:  Nice.



STEVE:  Okay.  So I'm thinking, okay, this cannot be right.  This is nuts.  So I go to RFC 3177.  Introduction.  It's very staid, of course, when you're writing your RFC.



"There have been," they write, "many discussions between the IETF and RIR experts on the topic of IPv6 address allocation policy."  Yeah, because, you know, we've got more bits than we could ever - so we've got them to burn.  "This memo addresses the issue of the boundary in between the public and private topology of the Internet, that is, how much address space should an ISP allocate to homes, small and large enterprises, mobile networks, and transient customers."  



And then they say the background, and we're running out of time, so I'll make this quick:  "The technical principles that apply to address allocation seek to balance healthy conservation practices" - okay, I don't see any sign of that - "and wisdom" - or that - "with a certain ease of access.  On one hand, when managing a potentially limited resource, one must conserve wisely to prevent exhaustion within an expected lifetime."  Yeah, of the universe.



"On the other hand, the IPv6 address space is in no sense as limited a resource as the IPv4 address space, and unwarranted conservatism acts as a" - we don't have to worry about that being applied here - "acts as a disincentive in a marketplace already dampened by other factors.  So from a market development perspective, we would like to see it be very easy for a user or an ISP to obtain as many IPv6 addresses as they really need without a prospect of immediate renumbering or of scaling inefficiencies."



LEO:  No one could ever need more than 18.5 quintillion IP addresses.



STEVE:  Oh, Leo.  "The IPv6 address, as currently defined, consists of" - get this - "64 bits of 'network number.'"  That is, the high left-hand 64 bits identify your network.  That is, this is you.  That's the public IP, essentially, on the Internet.  We used to have 32.  Now we have 64.  So there's also 18.5 quintillion individual networks.  And, they write, "64 bits of 'host number'" - that is, light bulbs.  "The technical reasons for this are several."  And then they go into it.



So they're just going to split the 128 bits in half.  Everybody gets their own Internet-squared in their house.  And in fact it's even worse.  I won't go into it any further, but that absolutely is the case.  They say, they're suggesting in the general case maybe even give them - someone might need multiple Internet-squared 18.5 quintillion networks.  So why not?  We don't want to be bothered with anybody running out of anything ever again.



And we've run out of time.  Not IP addresses, but time.  I did want to acknowledge, as I did earlier, that steganometry apparently is a word I've invented for the measurement of steganography, which is the actual word.  I did misspeak and talk about - I was talking about a high-number port, and I said 123123.  Sharp observers noted that, well, Steve, 123123 is a little bigger than 65535, so you would need an extra bit of port numbering for that.  And so of course, yes, I meant 12312.  Doesn't sound quite as nice.  But anyway, so thank you.  And somebody who liked our 1973 map of the Internet had a 1977.  I've now given these links permanent residence on the Link Farm.



LEO:  Oh, good.



STEVE:  So you can find them.  And it's in the show notes.  So this shows, four years later, how the ARPANET has grown.  And it's interesting.  It's maybe twice the size, though we're not going exponential yet, but it's a nice - oh, and there is a key on this map verifying that the squiggly line is a satellite link out to Hawaii.  And there's also something called NORSAR or SAC or something, I don't know [Norwegian Seismic Array].  Anyway, so there is that map.  And I had a little SpinRite note about cabling errors, but we'll do that in two weeks.



LEO:  And you also have to tell us...



STEVE:  Oh, about the robot.



LEO:  About the robot CAPTCHA.



STEVE:  We'll start with that two weeks from now.  For those who haven't already heard it, next week we're going to play the infamous, or famous, "Portable Dog Killer" episode.  I guarantee you, I've never heard Leo laugh so long and hard as I was...



LEO:  There's no video of this, though; right?  It's just audio.



STEVE:  Well, we did a video.



LEO:  Is there a video?  Oh, good.  Okay, all right, good.



STEVE:  Yeah.  It is a video.  So I think everybody will get a kick out of it.  You may have forgotten it.  You may...



LEO:  It's a great episode.  



STEVE:  If you've got some family around for the holidays.  And it had a moral, also, an unintended consequences moral.  So I think everybody will enjoy it.  And we'll see you next year.



LEO:  Tonight is the darkest night since 1648 or something like that. 



STEVE:  What?  Why?



LEO:  Well, tonight is winter solstice.  You know, the longest night of the year tonight.



STEVE:  Right, the shortest day, right.



LEO:  Yeah, shortest day, longest night.  And there is a total lunar eclipse.  And there hasn't been a total lunar eclipse on winter solstice for almost 500 years.



STEVE:  Cool.



LEO:  So the moon will go out.  You can look at the stars.



STEVE:  Completely blocked by the Earth.



LEO:  Completely blocked by the Earth.  It will be very cool.  It's from 2:41 to 3:53 a.m. Eastern time.



STEVE:  [Crosstalk].



LEO:  Well, no, but, no, at midnight our time, 11:41 p.m. our time.



STEVE:  Oh.  Oh, yeah, yeah, okay.



LEO:  So that means midnight should be very interesting in your neck of the woods.  And Happy Winter Solstice to you, Steve.  And have a wonderful holiday, and we'll see you in the New Year.



STEVE:  Indeed, my friend.  And I'll shoot you an email in a couple days with some update stuff.



LEO:  We'll converse.



STEVE:  Yes.



LEO:  Via the Internet.  Steve Gibson does this show every Tuesday, 1:30 Pacific, 4:30 Eastern, 21:30 UTC.  So do tune in, if you want to watch it live and join us in the chatroom at irc.twit.tv.  Or join us in-studio, as Nina and Alexandra did.  You just email tickets@twit.tv.  We'd love to have you in here.  But if you can't do any of that, you can get on-demand versions at GRC.com, Steve's site.  He has audio plus transcripts, nice transcripts of every episode, makes it easy to search for something you're looking for, at GRC.com.  He also has other stuff there.  While you're there, get SpinRite, the world's best hard drive maintenance and recovery utility, even for SSDs.  You can also find Perfect Paper Passwords and SpinRite and all the other great stuff Steve does.



Now, if you want to get video, you need to go to our site, TWiT.tv/sn.  We have audio and video.  And of course you can always subscribe, and that way you won't miss an episode.  You don't want to miss an episode.  This is a good show.  You learn a lot on this show.  It's a lot of fun.  Somebody said it's not a full moon tonight, it's a full Earth.  I like it.  Thank you so much, Steve.  Thank you, everybody.  Happy New Year.  Merry Christmas.  Next week, "The Portable Dog Killer."  And we'll see you January 3rd, right here, for a brand new Security Now!.



STEVE:  Cool.  Thanks, Leo.



Copyright (c) 2016 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


